{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from models.resnet import resnet18im, resnet18\n",
    "import os, random\n",
    "import copy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pyhocon import ConfigFactory\n",
    "from options import Option\n",
    "from dataset import create_loader\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from log_utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./save_log/resnet18_cifar100/log_cifar100_resnet18_bs128_ep200_seed_5/ is exists\n",
      "load log path ./save_log/resnet18_cifar100/log_cifar100_resnet18_bs128_ep200_seed_5/\n"
     ]
    }
   ],
   "source": [
    "option = Option(\"./cifar100.hocon\", \"test\")\n",
    "# 기존에 있는 log 를 불러오기 위해 log_override를 false로 하고 진행\n",
    "option.log_override=False\n",
    "option.set_save_path()\n",
    "\n",
    "\n",
    "torch.manual_seed(option.seed)\n",
    "torch.cuda.manual_seed(option.seed)\n",
    "np.random.seed(option.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1470, 1.0576, 0.9212, 1.0043])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = torch.randn([3, 4, 5, 6])\n",
    "\n",
    "s.transpose(0, 1).reshape(4, -1).var(axis=1, unbiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compare_BatchNorm_Precision(nn.Module):\n",
    "    # this is custom batchnorm different precision\n",
    "    # Considered https://github.com/ptrblck/pytorch_misc/blob/master/batch_norm_manual.py and rangeBN \n",
    "\n",
    "    def __init__(self, num_features, dim=1, momentum=0.9, affine=True, eps=1e-5, compute_type=torch.float16):\n",
    "        super(Compare_BatchNorm_Precision, self).__init__()\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.zeros(num_features))\n",
    "\n",
    "        self.momentum = momentum\n",
    "        self.dim = dim\n",
    "        self.eps = 1e-10\n",
    "        if affine:\n",
    "            self.bias = nn.Parameter(torch.Tensor(num_features))\n",
    "            self.weight = nn.Parameter(torch.Tensor(num_features))\n",
    "        self.compute_type = compute_type\n",
    "        self.eps = eps\n",
    "        self.reset_params()\n",
    "\n",
    "    def reset_params(self):\n",
    "        if self.weight is not None:\n",
    "            self.weight.data.uniform_()\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.zero_()\n",
    "\n",
    "    def load_params(self, weight, bias, running_mean, running_var):\n",
    "        self.weight=weight\n",
    "        self.bias=bias\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var\n",
    "        \n",
    "\n",
    "    def forward(self, x, inference=True):\n",
    "        x_ch = x.type(self.compute_type)        \n",
    "        if inference:\n",
    "            mean = self.running_mean\n",
    "            scale = self.running_var\n",
    "            mean_ch = self.running_mean.type(self.compute_type)\n",
    "            scale_ch = self.running_var.type(self.compute_type)\n",
    "\n",
    "            out = (x - mean.view(1, mean.size(0), 1, 1)) * \\\n",
    "                scale.view(1, scale.size(0), 1, 1)\n",
    "\n",
    "            out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) * \\\n",
    "                scale_ch.view(1, scale_ch.size(0), 1, 1)\n",
    "\n",
    "\n",
    "        else:\n",
    "            c = x_ch.shape[1]\n",
    "            mean = x.transpose(0,1).reshape(c, -1).mean(dim=-1)\n",
    "            scale = x.transpose(0,1).reshape(c, -1).var(dim=-1, unbiased=False)\n",
    "            mean_ch = x_ch.transpose(0,1).reshape(c, -1).mean(dim=-1)\n",
    "            scale_ch = x_ch.transpose(0,1).reshape(c, -1).var(dim=-1, unbiased=False)\n",
    "\n",
    "            out = (x - mean.view(1, mean.size(0), 1, 1)) * \\\n",
    "                torch.sqrt(scale.view(1, scale.size(0), 1, 1) + self.eps)\n",
    "\n",
    "            out_ch = (x_ch - mean_ch.view(1, mean_ch.size(0), 1, 1)) * \\\n",
    "                torch.sqrt(scale_ch.view(1, scale.size(0), 1, 1) + self.eps.type(self.compute_type))\n",
    "        \n",
    "        if self.weight is not None:\n",
    "            \n",
    "            weight = self.weight\n",
    "            weight_ch = self.weight.type(self.compute_type)\n",
    "            out = out * weight.view(1, weight.size(0), 1, 1)\n",
    "            out_ch = out_ch * weight_ch.view(1, weight_ch.size(0), 1, 1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            bias =self.bias\n",
    "            out = out * bias.view(1, bias.size(0), 1, 1)\n",
    "            bias_ch = self.bias.type(self.compute_type)\n",
    "            out_ch = out_ch * bias_ch.view(1, bias_ch.size(0), 1, 1)\n",
    "\n",
    "        return out, out_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_csv_path = os.path.join(option.save_path, \"batchnorm_param.csv\")\n",
    "batchnorm_df = pd.read_csv(batchnorm_csv_path)\n",
    "\n",
    "\n",
    "# csv에 저장된 batch_norm 데이터를 읽어오는 함수\n",
    "\n",
    "def csv_txt_to_param(txt):\n",
    "    temp_txt = txt\n",
    "    temp_txt = temp_txt.replace(\"[\", \"\")\n",
    "    temp_txt = temp_txt.replace(\"]\", \"\")\n",
    "    temp_list = temp_txt.split()\n",
    "\n",
    "    np_txt = np.array(temp_list, dtype=np.float32)\n",
    "    torch_result = torch.Tensor(np_txt)\n",
    "    return torch_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 7, 14]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option.activation_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.5179169920997992e-08\n",
      "bn.bias mse distance 1.2109795111125976e-10\n",
      "bn.avg mse distance 2.539544796675841e-09\n",
      "bn.var mse distance 1.8388015554648973e-09\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 1.1077389672209392e-06\n",
      "bn.bias mse distance 8.529898565257099e-09\n",
      "bn.avg mse distance 1.5773014183650957e-07\n",
      "bn.var mse distance 1.2950454220117535e-07\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.4793691605063941e-08\n",
      "bn.bias mse distance 1.378347574965133e-10\n",
      "bn.avg mse distance 2.9327800188383435e-09\n",
      "bn.var mse distance 5.129983660090431e-10\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 9.197601684718393e-07\n",
      "bn.bias mse distance 7.590191586359651e-09\n",
      "bn.avg mse distance 2.006550232636073e-07\n",
      "bn.var mse distance 3.6266214920033235e-08\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.9873571233119947e-08\n",
      "bn.bias mse distance 3.048450381015755e-10\n",
      "bn.avg mse distance 4.097434835870217e-09\n",
      "bn.var mse distance 6.461784995970277e-10\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 1.3120226185492356e-06\n",
      "bn.bias mse distance 2.0996473892864742e-08\n",
      "bn.avg mse distance 2.572563460034871e-07\n",
      "bn.var mse distance 3.743029708402901e-08\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "60\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 6.086486425971316e-09\n",
      "bn.bias mse distance 1.4926485047972449e-10\n",
      "bn.avg mse distance 9.652649790581336e-10\n",
      "bn.var mse distance 1.7667618756878056e-10\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 3.883530439452443e-07\n",
      "bn.bias mse distance 9.400833000938746e-09\n",
      "bn.avg mse distance 9.336901740653047e-08\n",
      "bn.var mse distance 1.139141136974331e-08\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 4.260560793056811e-09\n",
      "bn.bias mse distance 9.799871331095389e-11\n",
      "bn.avg mse distance 7.509822208540129e-10\n",
      "bn.var mse distance 2.948761373966491e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 2.3235094204210327e-07\n",
      "bn.bias mse distance 6.2208243001293795e-09\n",
      "bn.avg mse distance 4.074957971056392e-08\n",
      "bn.var mse distance 2.3373480928512436e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 4.879249893008364e-09\n",
      "bn.bias mse distance 5.91747095768369e-10\n",
      "bn.avg mse distance 5.923556645193173e-10\n",
      "bn.var mse distance 2.0494559174744076e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 3.257837022374588e-07\n",
      "bn.bias mse distance 4.1295667330132346e-08\n",
      "bn.avg mse distance 4.173618961544889e-08\n",
      "bn.var mse distance 1.2706153906805184e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "90\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 2.8215445535551e-09\n",
      "bn.bias mse distance 8.632101977656959e-11\n",
      "bn.avg mse distance 6.312292910592987e-10\n",
      "bn.var mse distance 4.293027044965925e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 2.0502676534306374e-07\n",
      "bn.bias mse distance 1.0639711334192725e-08\n",
      "bn.avg mse distance 4.16263539193551e-08\n",
      "bn.var mse distance 2.113921038215949e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.5767197547589262e-09\n",
      "bn.bias mse distance 4.2404579847499235e-11\n",
      "bn.avg mse distance 2.4716459434692695e-10\n",
      "bn.var mse distance 4.3708561076050145e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 8.917729132917884e-08\n",
      "bn.bias mse distance 3.179295049449138e-09\n",
      "bn.avg mse distance 1.563334528498217e-08\n",
      "bn.var mse distance 3.1857239068955323e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.4104204471010462e-09\n",
      "bn.bias mse distance 4.671441011794286e-10\n",
      "bn.avg mse distance 3.5887767757536437e-10\n",
      "bn.var mse distance 4.4361476297938296e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 8.796503436769854e-08\n",
      "bn.bias mse distance 2.9708814963669283e-08\n",
      "bn.avg mse distance 1.9780419080461797e-08\n",
      "bn.var mse distance 2.595220149892441e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "120\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 2.493708128881167e-09\n",
      "bn.bias mse distance 1.507177299631124e-10\n",
      "bn.avg mse distance 4.459758673469594e-10\n",
      "bn.var mse distance 2.912744698213565e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 1.0329590338642447e-07\n",
      "bn.bias mse distance 1.204087851647273e-08\n",
      "bn.avg mse distance 3.2978320518850524e-08\n",
      "bn.var mse distance 2.103995422331195e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.0709320097390673e-09\n",
      "bn.bias mse distance 3.767524139886014e-11\n",
      "bn.avg mse distance 2.0736996841907995e-10\n",
      "bn.var mse distance 2.5080269892147067e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 6.35212060728918e-08\n",
      "bn.bias mse distance 2.5803834624582578e-09\n",
      "bn.avg mse distance 1.2459285159138744e-08\n",
      "bn.var mse distance 1.581583058962721e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.1979369718417843e-09\n",
      "bn.bias mse distance 4.413301113448398e-10\n",
      "bn.avg mse distance 3.575335583150263e-10\n",
      "bn.var mse distance 2.0542374225274163e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 7.32440241790755e-08\n",
      "bn.bias mse distance 2.515701957861438e-08\n",
      "bn.avg mse distance 2.0142724821425873e-08\n",
      "bn.var mse distance 1.1719489267925098e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "150\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 2.162983347986369e-09\n",
      "bn.bias mse distance 2.2550539213739285e-10\n",
      "bn.avg mse distance 6.494720317107294e-10\n",
      "bn.var mse distance 2.008323715663174e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 1.3644955743075116e-07\n",
      "bn.bias mse distance 1.2869767473944194e-08\n",
      "bn.avg mse distance 3.8131343416125674e-08\n",
      "bn.var mse distance 1.2428387208274216e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 7.964385817516018e-10\n",
      "bn.bias mse distance 3.252213776061552e-11\n",
      "bn.avg mse distance 1.65682273456369e-10\n",
      "bn.var mse distance 2.469793683804178e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 7.699895121504596e-08\n",
      "bn.bias mse distance 2.1657537985220188e-09\n",
      "bn.avg mse distance 1.2333916110662813e-08\n",
      "bn.var mse distance 1.3349918392968618e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.2429764995047776e-09\n",
      "bn.bias mse distance 4.26469637382354e-10\n",
      "bn.avg mse distance 2.934539833354677e-10\n",
      "bn.var mse distance 1.4511085475593655e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 7.58039817583267e-08\n",
      "bn.bias mse distance 2.120680164807709e-08\n",
      "bn.avg mse distance 2.2722050019297058e-08\n",
      "bn.var mse distance 9.837419767677602e-11\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "180\n",
      "epoch :  2\n",
      "layer name :  conv2_x.0.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.7904140392488443e-09\n",
      "bn.bias mse distance 2.1635079838766558e-10\n",
      "bn.avg mse distance 5.321588725237802e-10\n",
      "bn.var mse distance 1.4397601166837859e-11\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 1.2550010808354273e-07\n",
      "bn.bias mse distance 1.69285279127962e-08\n",
      "bn.avg mse distance 2.8478016389499317e-08\n",
      "bn.var mse distance 1.1555922885264636e-09\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  7\n",
      "layer name :  conv3_x.0.shortcut.1\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 9.51828837969515e-10\n",
      "bn.bias mse distance 2.1850458942207496e-11\n",
      "bn.avg mse distance 2.1550719542240415e-10\n",
      "bn.var mse distance 1.6895904163607978e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 5.5850790658951155e-08\n",
      "bn.bias mse distance 2.3519797220927785e-09\n",
      "bn.avg mse distance 1.0754372503640752e-08\n",
      "bn.var mse distance 1.3263087850212685e-10\n",
      "-------------- FP32 - BF16 end --------------------\n",
      "epoch :  14\n",
      "layer name :  conv4_x.1.residual_function.4\n",
      "-------------- FP32 - FP16 distance --------------------\n",
      "bn.weight mse distance 1.2203940080723896e-09\n",
      "bn.bias mse distance 4.590796631731564e-10\n",
      "bn.avg mse distance 2.9587093886007665e-10\n",
      "bn.var mse distance 1.5230674794280974e-12\n",
      "-------------- FP32 - FP16 end --------------------\n",
      "-------------- FP32 - BF16 distance --------------------\n",
      "bn.weight mse distance 7.577317262530414e-08\n",
      "bn.bias mse distance 2.8638854843165973e-08\n",
      "bn.avg mse distance 2.0868304417831496e-08\n",
      "bn.var mse distance 1.0382427556576701e-10\n",
      "-------------- FP32 - BF16 end --------------------\n"
     ]
    }
   ],
   "source": [
    "result_df =pd.DataFrame()\n",
    "for epoch in option.activation_step:\n",
    "    epoch_df = batchnorm_df[batchnorm_df.epoch == epoch]\n",
    "    print(epoch)\n",
    "    for index in option.activation_index:\n",
    "        alpha_trigger = False\n",
    "        beta_trigger =False\n",
    "        avg_trigger = False\n",
    "        var_trigger =False\n",
    "        for key in sorted(epoch_df.keys()): # alpha, avg, beta, var and find index\n",
    "            if str(index) == key.split(\"_\")[0]:\n",
    "                file_name = '_'.join(key.split(\"_\")[1:-1])\n",
    "                target_key = key\n",
    "                target_df = epoch_df[key].iloc[0]\n",
    "                \n",
    "                if \"alpha\" in key:\n",
    "                    bn_weight = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    alpha_trigger=True\n",
    "                elif \"beta\" in key :\n",
    "                    bn_bias = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    beta_trigger= True\n",
    "                elif \"avg\" in key:\n",
    "                    bn_running_mean = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    avg_trigger = True\n",
    "                elif \"var\" in key:\n",
    "                    bn_running_var = nn.Parameter(csv_txt_to_param(target_df))\n",
    "                    var_trigger = True\n",
    "        \n",
    "        if alpha_trigger and beta_trigger and var_trigger and avg_trigger:\n",
    "\n",
    "            print(\"epoch : \", index)\n",
    "            print(\"layer name : \", file_name)\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                BatchNorm_fp16_layer = Compare_BatchNorm_Precision(num_features=bn_weight.shape, compute_type=torch.float16)\n",
    "                BatchNorm_fp16_layer.load_params(bn_weight, bn_bias, bn_running_mean, bn_running_var)\n",
    "                print(\"-------------- FP32 - FP16 distance --------------------\")\n",
    "                print(f\"bn.weight mse distance {((bn_weight - bn_weight.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.bias mse distance {((bn_bias - bn_bias.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.avg mse distance {((bn_running_mean - bn_running_mean.type(torch.float16))**2).mean()}\")\n",
    "                print(f\"bn.var mse distance {((bn_running_var - bn_running_var.type(torch.float16))**2).mean()}\")\n",
    "                print(\"-------------- FP32 - FP16 end --------------------\")\n",
    "                \n",
    "\n",
    "                print(\"-------------- FP32 - BF16 distance --------------------\")\n",
    "                print(f\"bn.weight mse distance {((bn_weight - bn_weight.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.bias mse distance {((bn_bias - bn_bias.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.avg mse distance {((bn_running_mean - bn_running_mean.type(torch.bfloat16))**2).mean()}\")\n",
    "                print(f\"bn.var mse distance {((bn_running_var - bn_running_var.type(torch.bfloat16))**2).mean()}\")\n",
    "                \n",
    "                print(\"-------------- FP32 - BF16 end --------------------\")\n",
    "                \n",
    "\n",
    "                BatchNorm_bf16_layer = Compare_BatchNorm_Precision(num_features=bn_weight.shape, compute_type=torch.bfloat16)\n",
    "                BatchNorm_bf16_layer.load_params(bn_weight, bn_bias, bn_running_mean, bn_running_var)\n",
    "\n",
    "            \n",
    "                input_pkl_file_name = f\"idx_{index}_{file_name}_{epoch}_input.pkl\"\n",
    "                input_pkl_file_path = os.path.join(option.save_path, input_pkl_file_name)\n",
    "\n",
    "                with open(input_pkl_file_path, \"rb\") as f:\n",
    "                    input_tensor = pickle.load(f)\n",
    "\n",
    "                output, output_fp16 = BatchNorm_fp16_layer.forward(input_tensor)\n",
    "                _, output_bf16 = BatchNorm_bf16_layer.forward(input_tensor)\n",
    "\n",
    "                C = output.shape[1]\n",
    "\n",
    "                output_t = output.transpose(0, 1).reshape(C, -1)\n",
    "                output_fp16_t = output_fp16.transpose(0, 1).reshape(C, -1)\n",
    "                fp16_mse_dist = ((output_t - output_fp16_t)**2).mean(-1)\n",
    "                fp16_L_inf = ((output_t - output_fp16_t)**2).abs().max(-1)[0]\n",
    "                \n",
    "                output_bf16_t = output_bf16.transpose(0, 1).reshape(C, -1)\n",
    "                bf16_mse_dist = ((output_t - output_bf16_t)**2).mean(-1)\n",
    "                bf16_L_inf = ((output_t - output_bf16_t)**2).abs().max(-1)[0]\n",
    "                \n",
    "                csv_dict = {\"epoch\": epoch, \"layer\": file_name, \"FP32-FP16_mse\": fp16_mse_dist, \"fp32-bf16_mse\" : bf16_mse_dist, \"FP32-FP16_L_inf\":fp16_L_inf, \"FP32-bf16_L_inf\":bf16_L_inf}\n",
    "                result_df = result_df.append(csv_dict, ignore_index=True)\n",
    "\n",
    "result_df.to_csv(\"./precision_compare.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5620, -1.9661, -3.0356,  0.8310],\n",
      "        [ 0.6103, -4.3786,  1.1484,  1.2283],\n",
      "        [-1.9923, -1.5068,  1.3988,  0.7608],\n",
      "        [-0.6837,  2.0734, -0.2611,  1.1067]])\n",
      "tensor([[ -53.3104,  -25.1412,  -42.7485,  -10.4547],\n",
      "        [  -4.5836,  417.6140,   97.5966, -121.7484],\n",
      "        [  90.8732,    7.7128,   37.9682,    6.2883],\n",
      "        [  85.6161,  -83.0889,   58.3947,   23.5319]])\n",
      "tensor([[ 1509.1896, -1294.6725,  1129.1266,  -498.7359],\n",
      "        [   93.0727,  -363.6360,   781.1904,   952.4703],\n",
      "        [  774.4670,   105.3691,   819.2181,   -91.3680],\n",
      "        [  378.5849,  1088.7861,  -332.2303,  -269.4368]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 5)\n",
    "b = torch.randn(5, 4)\n",
    "\n",
    "c=a @ b\n",
    "\n",
    "c_fp16=a.type(torch.float16) @ b.type(torch.float16)\n",
    "\n",
    "c_bf16=a.type(torch.bfloat16) @ b.type(torch.bfloat16)\n",
    "\n",
    "print(c)\n",
    "print(((c-c_fp16)*1e+5).type(torch.float32))\n",
    "print(((c-c_bf16)*1e+5).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
