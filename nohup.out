[2022-03-28 22:49:10 | train] - -------start batchnorm param logging -----------

[2022-03-28 22:49:11 | train] - -------end batchnorm param logging -----------

[2022-03-28 22:49:11 | train] - -------10 epoch start-----------
/data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
load log path /data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/
load pretrained model : epoch 10
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
[2022-03-28 22:49:13 | train] - Train Epoch: [10] [0/1281167 (0%)]	Loss: 2.161712
[2022-03-28 22:49:32 | train] - Train Epoch: [10] [12800/1281167 (1%)]	Loss: 2.409122
[2022-03-28 22:49:53 | train] - Train Epoch: [10] [25600/1281167 (2%)]	Loss: 1.959437
[2022-03-28 22:50:13 | train] - Train Epoch: [10] [38400/1281167 (3%)]	Loss: 1.972976
[2022-03-28 22:50:33 | train] - Train Epoch: [10] [51200/1281167 (4%)]	Loss: 1.831354
[2022-03-28 22:50:53 | train] - Train Epoch: [10] [64000/1281167 (5%)]	Loss: 2.167671
[2022-03-28 22:51:12 | train] - Train Epoch: [10] [76800/1281167 (6%)]	Loss: 2.296982
[2022-03-28 22:51:32 | train] - Train Epoch: [10] [89600/1281167 (7%)]	Loss: 2.104122
[2022-03-28 22:51:52 | train] - Train Epoch: [10] [102400/1281167 (8%)]	Loss: 2.331330
[2022-03-28 22:52:12 | train] - Train Epoch: [10] [115200/1281167 (9%)]	Loss: 2.375121
[2022-03-28 22:52:31 | train] - Train Epoch: [10] [128000/1281167 (10%)]	Loss: 2.175969
[2022-03-28 22:52:51 | train] - Train Epoch: [10] [140800/1281167 (11%)]	Loss: 2.434605
[2022-03-28 22:53:11 | train] - Train Epoch: [10] [153600/1281167 (12%)]	Loss: 2.152368
[2022-03-28 22:53:31 | train] - Train Epoch: [10] [166400/1281167 (13%)]	Loss: 2.306703
[2022-03-28 22:53:50 | train] - Train Epoch: [10] [179200/1281167 (14%)]	Loss: 2.459234
[2022-03-28 22:54:10 | train] - Train Epoch: [10] [192000/1281167 (15%)]	Loss: 2.196261
[2022-03-28 22:54:30 | train] - Train Epoch: [10] [204800/1281167 (16%)]	Loss: 2.046909
[2022-03-28 22:54:49 | train] - Train Epoch: [10] [217600/1281167 (17%)]	Loss: 2.342044
[2022-03-28 22:55:08 | train] - Train Epoch: [10] [230400/1281167 (18%)]	Loss: 2.273527
[2022-03-28 22:55:29 | train] - Train Epoch: [10] [243200/1281167 (19%)]	Loss: 2.386712
[2022-03-28 22:55:49 | train] - Train Epoch: [10] [256000/1281167 (20%)]	Loss: 2.274318
[2022-03-28 22:56:09 | train] - Train Epoch: [10] [268800/1281167 (21%)]	Loss: 2.599663
[2022-03-28 22:56:28 | train] - Train Epoch: [10] [281600/1281167 (22%)]	Loss: 2.076169
[2022-03-28 22:56:47 | train] - Train Epoch: [10] [294400/1281167 (23%)]	Loss: 1.879164
[2022-03-28 22:57:07 | train] - Train Epoch: [10] [307200/1281167 (24%)]	Loss: 1.787887
[2022-03-28 22:57:27 | train] - Train Epoch: [10] [320000/1281167 (25%)]	Loss: 2.478638
[2022-03-28 22:57:46 | train] - Train Epoch: [10] [332800/1281167 (26%)]	Loss: 1.941544
[2022-03-28 22:58:06 | train] - Train Epoch: [10] [345600/1281167 (27%)]	Loss: 2.512127
[2022-03-28 22:58:25 | train] - Train Epoch: [10] [358400/1281167 (28%)]	Loss: 2.261036
[2022-03-28 22:58:44 | train] - Train Epoch: [10] [371200/1281167 (29%)]	Loss: 2.005009
[2022-03-28 22:59:04 | train] - Train Epoch: [10] [384000/1281167 (30%)]	Loss: 2.114996
[2022-03-28 22:59:24 | train] - Train Epoch: [10] [396800/1281167 (31%)]	Loss: 1.984299
[2022-03-28 22:59:43 | train] - Train Epoch: [10] [409600/1281167 (32%)]	Loss: 2.648017
[2022-03-28 23:00:02 | train] - Train Epoch: [10] [422400/1281167 (33%)]	Loss: 2.123561
[2022-03-28 23:00:22 | train] - Train Epoch: [10] [435200/1281167 (34%)]	Loss: 2.087974
[2022-03-28 23:00:41 | train] - Train Epoch: [10] [448000/1281167 (35%)]	Loss: 1.919544
[2022-03-28 23:01:01 | train] - Train Epoch: [10] [460800/1281167 (36%)]	Loss: 2.159519
[2022-03-28 23:01:21 | train] - Train Epoch: [10] [473600/1281167 (37%)]	Loss: 2.173993
[2022-03-28 23:01:40 | train] - Train Epoch: [10] [486400/1281167 (38%)]	Loss: 2.072418
[2022-03-28 23:01:59 | train] - Train Epoch: [10] [499200/1281167 (39%)]	Loss: 1.897285
[2022-03-28 23:02:20 | train] - Train Epoch: [10] [512000/1281167 (40%)]	Loss: 2.100882
[2022-03-28 23:02:39 | train] - Train Epoch: [10] [524800/1281167 (41%)]	Loss: 2.195388
[2022-03-28 23:02:59 | train] - Train Epoch: [10] [537600/1281167 (42%)]	Loss: 2.030927
[2022-03-28 23:03:19 | train] - Train Epoch: [10] [550400/1281167 (43%)]	Loss: 1.972465
[2022-03-28 23:03:39 | train] - Train Epoch: [10] [563200/1281167 (44%)]	Loss: 1.943525
[2022-03-28 23:03:58 | train] - Train Epoch: [10] [576000/1281167 (45%)]	Loss: 2.127518
[2022-03-28 23:04:18 | train] - Train Epoch: [10] [588800/1281167 (46%)]	Loss: 2.493281
[2022-03-28 23:04:38 | train] - Train Epoch: [10] [601600/1281167 (47%)]	Loss: 2.395936
[2022-03-28 23:04:57 | train] - Train Epoch: [10] [614400/1281167 (48%)]	Loss: 1.815636
[2022-03-28 23:05:17 | train] - Train Epoch: [10] [627200/1281167 (49%)]	Loss: 1.987906
[2022-03-28 23:05:37 | train] - Train Epoch: [10] [640000/1281167 (50%)]	Loss: 2.122547
[2022-03-28 23:05:57 | train] - Train Epoch: [10] [652800/1281167 (51%)]	Loss: 2.166516
[2022-03-28 23:06:16 | train] - Train Epoch: [10] [665600/1281167 (52%)]	Loss: 2.307940
[2022-03-28 23:06:35 | train] - Train Epoch: [10] [678400/1281167 (53%)]	Loss: 2.016093
[2022-03-28 23:06:55 | train] - Train Epoch: [10] [691200/1281167 (54%)]	Loss: 2.045726
[2022-03-28 23:07:15 | train] - Train Epoch: [10] [704000/1281167 (55%)]	Loss: 2.480647
[2022-03-28 23:07:35 | train] - Train Epoch: [10] [716800/1281167 (56%)]	Loss: 2.066381
[2022-03-28 23:07:54 | train] - Train Epoch: [10] [729600/1281167 (57%)]	Loss: 1.647776
[2022-03-28 23:08:14 | train] - Train Epoch: [10] [742400/1281167 (58%)]	Loss: 2.359830
[2022-03-28 23:08:33 | train] - Train Epoch: [10] [755200/1281167 (59%)]	Loss: 2.273887
[2022-03-28 23:08:53 | train] - Train Epoch: [10] [768000/1281167 (60%)]	Loss: 2.162942
[2022-03-28 23:09:13 | train] - Train Epoch: [10] [780800/1281167 (61%)]	Loss: 1.790186
[2022-03-28 23:09:32 | train] - Train Epoch: [10] [793600/1281167 (62%)]	Loss: 2.061715
[2022-03-28 23:09:52 | train] - Train Epoch: [10] [806400/1281167 (63%)]	Loss: 2.082514
[2022-03-28 23:10:12 | train] - Train Epoch: [10] [819200/1281167 (64%)]	Loss: 2.072120
[2022-03-28 23:10:32 | train] - Train Epoch: [10] [832000/1281167 (65%)]	Loss: 2.259666
[2022-03-28 23:10:51 | train] - Train Epoch: [10] [844800/1281167 (66%)]	Loss: 2.080099
[2022-03-28 23:11:11 | train] - Train Epoch: [10] [857600/1281167 (67%)]	Loss: 2.183816
[2022-03-28 23:11:30 | train] - Train Epoch: [10] [870400/1281167 (68%)]	Loss: 1.914848
[2022-03-28 23:11:50 | train] - Train Epoch: [10] [883200/1281167 (69%)]	Loss: 2.191899
[2022-03-28 23:12:09 | train] - Train Epoch: [10] [896000/1281167 (70%)]	Loss: 2.103278
[2022-03-28 23:12:28 | train] - Train Epoch: [10] [908800/1281167 (71%)]	Loss: 2.116351
[2022-03-28 23:12:48 | train] - Train Epoch: [10] [921600/1281167 (72%)]	Loss: 2.561473
[2022-03-28 23:13:07 | train] - Train Epoch: [10] [934400/1281167 (73%)]	Loss: 1.996350
[2022-03-28 23:13:27 | train] - Train Epoch: [10] [947200/1281167 (74%)]	Loss: 2.169622
[2022-03-28 23:13:47 | train] - Train Epoch: [10] [960000/1281167 (75%)]	Loss: 2.199235
[2022-03-28 23:14:07 | train] - Train Epoch: [10] [972800/1281167 (76%)]	Loss: 2.317887
[2022-03-28 23:14:26 | train] - Train Epoch: [10] [985600/1281167 (77%)]	Loss: 2.181515
[2022-03-28 23:14:47 | train] - Train Epoch: [10] [998400/1281167 (78%)]	Loss: 2.094069
[2022-03-28 23:15:06 | train] - Train Epoch: [10] [1011200/1281167 (79%)]	Loss: 2.116717
[2022-03-28 23:15:26 | train] - Train Epoch: [10] [1024000/1281167 (80%)]	Loss: 2.111092
[2022-03-28 23:15:46 | train] - Train Epoch: [10] [1036800/1281167 (81%)]	Loss: 2.286906
[2022-03-28 23:16:06 | train] - Train Epoch: [10] [1049600/1281167 (82%)]	Loss: 2.495611
[2022-03-28 23:16:25 | train] - Train Epoch: [10] [1062400/1281167 (83%)]	Loss: 2.104181
[2022-03-28 23:16:45 | train] - Train Epoch: [10] [1075200/1281167 (84%)]	Loss: 2.571917
[2022-03-28 23:17:05 | train] - Train Epoch: [10] [1088000/1281167 (85%)]	Loss: 1.720141
[2022-03-28 23:17:24 | train] - Train Epoch: [10] [1100800/1281167 (86%)]	Loss: 2.207074
[2022-03-28 23:17:44 | train] - Train Epoch: [10] [1113600/1281167 (87%)]	Loss: 1.801264
[2022-03-28 23:18:04 | train] - Train Epoch: [10] [1126400/1281167 (88%)]	Loss: 2.054371
[2022-03-28 23:18:23 | train] - Train Epoch: [10] [1139200/1281167 (89%)]	Loss: 2.479814
[2022-03-28 23:18:43 | train] - Train Epoch: [10] [1152000/1281167 (90%)]	Loss: 2.497447
[2022-03-28 23:19:03 | train] - Train Epoch: [10] [1164800/1281167 (91%)]	Loss: 2.446051
[2022-03-28 23:19:22 | train] - Train Epoch: [10] [1177600/1281167 (92%)]	Loss: 2.729967
[2022-03-28 23:19:42 | train] - Train Epoch: [10] [1190400/1281167 (93%)]	Loss: 2.223429
[2022-03-28 23:20:02 | train] - Train Epoch: [10] [1203200/1281167 (94%)]	Loss: 2.160149
[2022-03-28 23:20:21 | train] - Train Epoch: [10] [1216000/1281167 (95%)]	Loss: 2.062988
[2022-03-28 23:20:41 | train] - Train Epoch: [10] [1228800/1281167 (96%)]	Loss: 1.942717
[2022-03-28 23:21:01 | train] - Train Epoch: [10] [1241600/1281167 (97%)]	Loss: 2.284845
[2022-03-28 23:21:21 | train] - Train Epoch: [10] [1254400/1281167 (98%)]	Loss: 1.836218
[2022-03-28 23:21:40 | train] - Train Epoch: [10] [1267200/1281167 (99%)]	Loss: 2.383372
[2022-03-28 23:22:00 | train] - Train Epoch: [10] [1280000/1281167 (100%)]	Loss: 2.185941
[2022-03-28 23:22:02 | train] - Train Epoch: [10]	 Average Loss: 2.201339	 Total Acc : 50.9203	 Total Top5 Acc : 74.3932
[2022-03-28 23:22:02 | train] - -------10 epoch end-----------
========================================
-------10 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-28 23:23:34 | train] - 
Epoch [10] Test set: Average loss: 1.8899, Accuracy: 27889/50000 (55.7401%), Top-5 Accuracy: 79.8414%

[2022-03-28 23:23:34 | train] - save intermediate epoch [10] result


[2022-03-28 23:23:35 | train] - logging best performance 10 epoch
[2022-03-28 23:23:36 | train] - -------11 epoch start-----------
========================================
----- test end -------------------------


logging best performance 10 epoch
[2022-03-28 23:23:37 | train] - Train Epoch: [11] [0/1281167 (0%)]	Loss: 2.309672
[2022-03-28 23:23:57 | train] - Train Epoch: [11] [12800/1281167 (1%)]	Loss: 1.960256
[2022-03-28 23:24:17 | train] - Train Epoch: [11] [25600/1281167 (2%)]	Loss: 2.261237
[2022-03-28 23:24:36 | train] - Train Epoch: [11] [38400/1281167 (3%)]	Loss: 1.931951
[2022-03-28 23:24:56 | train] - Train Epoch: [11] [51200/1281167 (4%)]	Loss: 2.042898
[2022-03-28 23:25:17 | train] - Train Epoch: [11] [64000/1281167 (5%)]	Loss: 2.194170
[2022-03-28 23:25:38 | train] - Train Epoch: [11] [76800/1281167 (6%)]	Loss: 1.952302
[2022-03-28 23:25:57 | train] - Train Epoch: [11] [89600/1281167 (7%)]	Loss: 2.010090
[2022-03-28 23:26:17 | train] - Train Epoch: [11] [102400/1281167 (8%)]	Loss: 2.108241
[2022-03-28 23:26:36 | train] - Train Epoch: [11] [115200/1281167 (9%)]	Loss: 1.747474
[2022-03-28 23:26:55 | train] - Train Epoch: [11] [128000/1281167 (10%)]	Loss: 1.968970
[2022-03-28 23:27:15 | train] - Train Epoch: [11] [140800/1281167 (11%)]	Loss: 2.015729
[2022-03-28 23:27:34 | train] - Train Epoch: [11] [153600/1281167 (12%)]	Loss: 2.081944
[2022-03-28 23:27:54 | train] - Train Epoch: [11] [166400/1281167 (13%)]	Loss: 2.605653
[2022-03-28 23:28:13 | train] - Train Epoch: [11] [179200/1281167 (14%)]	Loss: 2.321627
[2022-03-28 23:28:33 | train] - Train Epoch: [11] [192000/1281167 (15%)]	Loss: 2.030257
[2022-03-28 23:28:52 | train] - Train Epoch: [11] [204800/1281167 (16%)]	Loss: 1.859027
[2022-03-28 23:29:12 | train] - Train Epoch: [11] [217600/1281167 (17%)]	Loss: 2.077052
[2022-03-28 23:29:32 | train] - Train Epoch: [11] [230400/1281167 (18%)]	Loss: 2.092195
[2022-03-28 23:29:51 | train] - Train Epoch: [11] [243200/1281167 (19%)]	Loss: 2.155271
[2022-03-28 23:30:11 | train] - Train Epoch: [11] [256000/1281167 (20%)]	Loss: 1.993039
[2022-03-28 23:30:31 | train] - Train Epoch: [11] [268800/1281167 (21%)]	Loss: 1.958186
[2022-03-28 23:30:50 | train] - Train Epoch: [11] [281600/1281167 (22%)]	Loss: 2.239910
[2022-03-28 23:31:10 | train] - Train Epoch: [11] [294400/1281167 (23%)]	Loss: 2.047460
[2022-03-28 23:31:29 | train] - Train Epoch: [11] [307200/1281167 (24%)]	Loss: 2.321235
[2022-03-28 23:31:49 | train] - Train Epoch: [11] [320000/1281167 (25%)]	Loss: 2.436086
[2022-03-28 23:32:09 | train] - Train Epoch: [11] [332800/1281167 (26%)]	Loss: 2.259874
[2022-03-28 23:32:28 | train] - Train Epoch: [11] [345600/1281167 (27%)]	Loss: 2.245209
[2022-03-28 23:32:48 | train] - Train Epoch: [11] [358400/1281167 (28%)]	Loss: 2.211603
[2022-03-28 23:33:08 | train] - Train Epoch: [11] [371200/1281167 (29%)]	Loss: 2.204838
[2022-03-28 23:33:28 | train] - Train Epoch: [11] [384000/1281167 (30%)]	Loss: 2.451944
[2022-03-28 23:33:47 | train] - Train Epoch: [11] [396800/1281167 (31%)]	Loss: 2.133258
[2022-03-28 23:34:07 | train] - Train Epoch: [11] [409600/1281167 (32%)]	Loss: 1.923624
[2022-03-28 23:34:26 | train] - Train Epoch: [11] [422400/1281167 (33%)]	Loss: 2.107567
[2022-03-28 23:34:46 | train] - Train Epoch: [11] [435200/1281167 (34%)]	Loss: 2.245619
[2022-03-28 23:35:05 | train] - Train Epoch: [11] [448000/1281167 (35%)]	Loss: 2.361391
[2022-03-28 23:35:25 | train] - Train Epoch: [11] [460800/1281167 (36%)]	Loss: 1.858514
[2022-03-28 23:35:45 | train] - Train Epoch: [11] [473600/1281167 (37%)]	Loss: 1.996331
[2022-03-28 23:36:05 | train] - Train Epoch: [11] [486400/1281167 (38%)]	Loss: 2.103940
[2022-03-28 23:36:25 | train] - Train Epoch: [11] [499200/1281167 (39%)]	Loss: 2.330343
[2022-03-28 23:36:45 | train] - Train Epoch: [11] [512000/1281167 (40%)]	Loss: 2.033004
[2022-03-28 23:37:04 | train] - Train Epoch: [11] [524800/1281167 (41%)]	Loss: 1.950334
[2022-03-28 23:37:24 | train] - Train Epoch: [11] [537600/1281167 (42%)]	Loss: 2.258508
[2022-03-28 23:37:44 | train] - Train Epoch: [11] [550400/1281167 (43%)]	Loss: 2.272273
[2022-03-28 23:38:04 | train] - Train Epoch: [11] [563200/1281167 (44%)]	Loss: 2.008210
[2022-03-28 23:38:24 | train] - Train Epoch: [11] [576000/1281167 (45%)]	Loss: 2.255821
[2022-03-28 23:38:43 | train] - Train Epoch: [11] [588800/1281167 (46%)]	Loss: 1.975116
[2022-03-28 23:39:03 | train] - Train Epoch: [11] [601600/1281167 (47%)]	Loss: 2.045206
[2022-03-28 23:39:23 | train] - Train Epoch: [11] [614400/1281167 (48%)]	Loss: 2.260544
[2022-03-28 23:39:43 | train] - Train Epoch: [11] [627200/1281167 (49%)]	Loss: 2.117718
[2022-03-28 23:40:02 | train] - Train Epoch: [11] [640000/1281167 (50%)]	Loss: 1.856310
[2022-03-28 23:40:22 | train] - Train Epoch: [11] [652800/1281167 (51%)]	Loss: 2.066170
[2022-03-28 23:40:41 | train] - Train Epoch: [11] [665600/1281167 (52%)]	Loss: 2.306053
[2022-03-28 23:41:01 | train] - Train Epoch: [11] [678400/1281167 (53%)]	Loss: 2.227484
[2022-03-28 23:41:21 | train] - Train Epoch: [11] [691200/1281167 (54%)]	Loss: 2.314928
[2022-03-28 23:41:41 | train] - Train Epoch: [11] [704000/1281167 (55%)]	Loss: 2.024762
[2022-03-28 23:42:01 | train] - Train Epoch: [11] [716800/1281167 (56%)]	Loss: 1.956196
[2022-03-28 23:42:20 | train] - Train Epoch: [11] [729600/1281167 (57%)]	Loss: 1.923245
[2022-03-28 23:42:40 | train] - Train Epoch: [11] [742400/1281167 (58%)]	Loss: 2.507926
[2022-03-28 23:43:00 | train] - Train Epoch: [11] [755200/1281167 (59%)]	Loss: 2.137671
[2022-03-28 23:43:20 | train] - Train Epoch: [11] [768000/1281167 (60%)]	Loss: 2.099302
[2022-03-28 23:43:40 | train] - Train Epoch: [11] [780800/1281167 (61%)]	Loss: 1.964536
[2022-03-28 23:44:00 | train] - Train Epoch: [11] [793600/1281167 (62%)]	Loss: 2.240400
[2022-03-28 23:44:19 | train] - Train Epoch: [11] [806400/1281167 (63%)]	Loss: 2.279390
[2022-03-28 23:44:39 | train] - Train Epoch: [11] [819200/1281167 (64%)]	Loss: 1.733402
[2022-03-28 23:44:58 | train] - Train Epoch: [11] [832000/1281167 (65%)]	Loss: 2.040739
[2022-03-28 23:45:18 | train] - Train Epoch: [11] [844800/1281167 (66%)]	Loss: 2.212094
[2022-03-28 23:45:37 | train] - Train Epoch: [11] [857600/1281167 (67%)]	Loss: 2.018199
[2022-03-28 23:45:57 | train] - Train Epoch: [11] [870400/1281167 (68%)]	Loss: 2.179954
[2022-03-28 23:46:16 | train] - Train Epoch: [11] [883200/1281167 (69%)]	Loss: 1.704717
[2022-03-28 23:46:36 | train] - Train Epoch: [11] [896000/1281167 (70%)]	Loss: 2.681340
[2022-03-28 23:46:56 | train] - Train Epoch: [11] [908800/1281167 (71%)]	Loss: 1.958446
[2022-03-28 23:47:15 | train] - Train Epoch: [11] [921600/1281167 (72%)]	Loss: 2.003166
[2022-03-28 23:47:34 | train] - Train Epoch: [11] [934400/1281167 (73%)]	Loss: 2.264982
[2022-03-28 23:47:54 | train] - Train Epoch: [11] [947200/1281167 (74%)]	Loss: 1.889398
[2022-03-28 23:48:14 | train] - Train Epoch: [11] [960000/1281167 (75%)]	Loss: 2.389880
[2022-03-28 23:48:33 | train] - Train Epoch: [11] [972800/1281167 (76%)]	Loss: 2.222549
[2022-03-28 23:48:54 | train] - Train Epoch: [11] [985600/1281167 (77%)]	Loss: 2.277138
[2022-03-28 23:49:13 | train] - Train Epoch: [11] [998400/1281167 (78%)]	Loss: 2.229224
[2022-03-28 23:49:33 | train] - Train Epoch: [11] [1011200/1281167 (79%)]	Loss: 1.793883
[2022-03-28 23:49:53 | train] - Train Epoch: [11] [1024000/1281167 (80%)]	Loss: 2.253606
[2022-03-28 23:50:12 | train] - Train Epoch: [11] [1036800/1281167 (81%)]	Loss: 2.469333
[2022-03-28 23:50:31 | train] - Train Epoch: [11] [1049600/1281167 (82%)]	Loss: 2.093170
[2022-03-28 23:50:51 | train] - Train Epoch: [11] [1062400/1281167 (83%)]	Loss: 2.029936
[2022-03-28 23:51:11 | train] - Train Epoch: [11] [1075200/1281167 (84%)]	Loss: 2.307634
[2022-03-28 23:51:31 | train] - Train Epoch: [11] [1088000/1281167 (85%)]	Loss: 1.729252
[2022-03-28 23:51:50 | train] - Train Epoch: [11] [1100800/1281167 (86%)]	Loss: 2.261989
[2022-03-28 23:52:10 | train] - Train Epoch: [11] [1113600/1281167 (87%)]	Loss: 2.419942
[2022-03-28 23:52:30 | train] - Train Epoch: [11] [1126400/1281167 (88%)]	Loss: 1.944691
[2022-03-28 23:52:50 | train] - Train Epoch: [11] [1139200/1281167 (89%)]	Loss: 1.966854
[2022-03-28 23:53:10 | train] - Train Epoch: [11] [1152000/1281167 (90%)]	Loss: 2.097611
[2022-03-28 23:53:29 | train] - Train Epoch: [11] [1164800/1281167 (91%)]	Loss: 1.732971
[2022-03-28 23:53:49 | train] - Train Epoch: [11] [1177600/1281167 (92%)]	Loss: 2.025919
[2022-03-28 23:54:09 | train] - Train Epoch: [11] [1190400/1281167 (93%)]	Loss: 2.091994
[2022-03-28 23:54:29 | train] - Train Epoch: [11] [1203200/1281167 (94%)]	Loss: 1.907978
[2022-03-28 23:54:48 | train] - Train Epoch: [11] [1216000/1281167 (95%)]	Loss: 2.107759
[2022-03-28 23:55:08 | train] - Train Epoch: [11] [1228800/1281167 (96%)]	Loss: 1.976208
[2022-03-28 23:55:28 | train] - Train Epoch: [11] [1241600/1281167 (97%)]	Loss: 2.152775
[2022-03-28 23:55:48 | train] - Train Epoch: [11] [1254400/1281167 (98%)]	Loss: 2.092782
[2022-03-28 23:56:07 | train] - Train Epoch: [11] [1267200/1281167 (99%)]	Loss: 2.096217
[2022-03-28 23:56:27 | train] - Train Epoch: [11] [1280000/1281167 (100%)]	Loss: 2.096167
[2022-03-28 23:56:29 | train] - Train Epoch: [11]	 Average Loss: 2.128021	 Total Acc : 52.2868	 Total Top5 Acc : 75.5104
[2022-03-28 23:56:30 | train] - -------11 epoch end-----------
========================================
-------11 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-28 23:58:21 | train] - 
Epoch [11] Test set: Average loss: 1.8378, Accuracy: 28549/50000 (57.0756%), Top-5 Accuracy: 80.6881%

[2022-03-28 23:58:21 | train] - save intermediate epoch [11] result


[2022-03-28 23:58:21 | train] - logging best performance 11 epoch
[2022-03-28 23:58:23 | train] - -------12 epoch start-----------
========================================
----- test end -------------------------


logging best performance 11 epoch
[2022-03-28 23:58:25 | train] - Train Epoch: [12] [0/1281167 (0%)]	Loss: 2.062566
[2022-03-28 23:58:51 | train] - Train Epoch: [12] [12800/1281167 (1%)]	Loss: 2.121174
[2022-03-28 23:59:18 | train] - Train Epoch: [12] [25600/1281167 (2%)]	Loss: 2.261203
[2022-03-28 23:59:44 | train] - Train Epoch: [12] [38400/1281167 (3%)]	Loss: 1.722100
[2022-03-29 00:00:11 | train] - Train Epoch: [12] [51200/1281167 (4%)]	Loss: 1.635096
[2022-03-29 00:00:37 | train] - Train Epoch: [12] [64000/1281167 (5%)]	Loss: 1.909394
[2022-03-29 00:01:02 | train] - Train Epoch: [12] [76800/1281167 (6%)]	Loss: 2.156729
[2022-03-29 00:01:29 | train] - Train Epoch: [12] [89600/1281167 (7%)]	Loss: 2.549808
[2022-03-29 00:01:54 | train] - Train Epoch: [12] [102400/1281167 (8%)]	Loss: 2.071275
[2022-03-29 00:02:20 | train] - Train Epoch: [12] [115200/1281167 (9%)]	Loss: 2.052360
[2022-03-29 00:02:46 | train] - Train Epoch: [12] [128000/1281167 (10%)]	Loss: 1.843315
[2022-03-29 00:03:09 | train] - Train Epoch: [12] [140800/1281167 (11%)]	Loss: 2.183492
[2022-03-29 00:03:33 | train] - Train Epoch: [12] [153600/1281167 (12%)]	Loss: 2.327066
[2022-03-29 00:03:57 | train] - Train Epoch: [12] [166400/1281167 (13%)]	Loss: 2.178730
[2022-03-29 00:04:22 | train] - Train Epoch: [12] [179200/1281167 (14%)]	Loss: 2.030590
[2022-03-29 00:04:45 | train] - Train Epoch: [12] [192000/1281167 (15%)]	Loss: 1.974946
[2022-03-29 00:05:09 | train] - Train Epoch: [12] [204800/1281167 (16%)]	Loss: 1.651860
[2022-03-29 00:05:33 | train] - Train Epoch: [12] [217600/1281167 (17%)]	Loss: 2.045759
[2022-03-29 00:05:57 | train] - Train Epoch: [12] [230400/1281167 (18%)]	Loss: 2.258110
[2022-03-29 00:06:20 | train] - Train Epoch: [12] [243200/1281167 (19%)]	Loss: 2.058219
[2022-03-29 00:06:43 | train] - Train Epoch: [12] [256000/1281167 (20%)]	Loss: 1.962523
[2022-03-29 00:07:07 | train] - Train Epoch: [12] [268800/1281167 (21%)]	Loss: 2.212537
[2022-03-29 00:07:31 | train] - Train Epoch: [12] [281600/1281167 (22%)]	Loss: 1.833629
[2022-03-29 00:07:54 | train] - Train Epoch: [12] [294400/1281167 (23%)]	Loss: 1.786264
[2022-03-29 00:08:17 | train] - Train Epoch: [12] [307200/1281167 (24%)]	Loss: 2.071304
[2022-03-29 00:08:41 | train] - Train Epoch: [12] [320000/1281167 (25%)]	Loss: 2.019487
[2022-03-29 00:09:07 | train] - Train Epoch: [12] [332800/1281167 (26%)]	Loss: 1.980881
[2022-03-29 00:09:33 | train] - Train Epoch: [12] [345600/1281167 (27%)]	Loss: 2.093909
[2022-03-29 00:09:58 | train] - Train Epoch: [12] [358400/1281167 (28%)]	Loss: 2.493886
[2022-03-29 00:10:23 | train] - Train Epoch: [12] [371200/1281167 (29%)]	Loss: 2.086890
[2022-03-29 00:10:49 | train] - Train Epoch: [12] [384000/1281167 (30%)]	Loss: 1.998278
[2022-03-29 00:11:14 | train] - Train Epoch: [12] [396800/1281167 (31%)]	Loss: 2.114329
[2022-03-29 00:11:41 | train] - Train Epoch: [12] [409600/1281167 (32%)]	Loss: 1.898207
[2022-03-29 00:12:05 | train] - Train Epoch: [12] [422400/1281167 (33%)]	Loss: 2.018666
[2022-03-29 00:12:31 | train] - Train Epoch: [12] [435200/1281167 (34%)]	Loss: 1.970649
[2022-03-29 00:12:55 | train] - Train Epoch: [12] [448000/1281167 (35%)]	Loss: 2.239552
[2022-03-29 00:13:19 | train] - Train Epoch: [12] [460800/1281167 (36%)]	Loss: 2.037623
[2022-03-29 00:13:44 | train] - Train Epoch: [12] [473600/1281167 (37%)]	Loss: 2.009242
[2022-03-29 00:14:09 | train] - Train Epoch: [12] [486400/1281167 (38%)]	Loss: 1.900584
[2022-03-29 00:14:33 | train] - Train Epoch: [12] [499200/1281167 (39%)]	Loss: 1.955863
[2022-03-29 00:14:58 | train] - Train Epoch: [12] [512000/1281167 (40%)]	Loss: 2.084188
[2022-03-29 00:15:22 | train] - Train Epoch: [12] [524800/1281167 (41%)]	Loss: 2.190875
[2022-03-29 00:15:48 | train] - Train Epoch: [12] [537600/1281167 (42%)]	Loss: 1.822104
[2022-03-29 00:16:13 | train] - Train Epoch: [12] [550400/1281167 (43%)]	Loss: 1.749083
[2022-03-29 00:16:37 | train] - Train Epoch: [12] [563200/1281167 (44%)]	Loss: 2.261610
[2022-03-29 00:17:02 | train] - Train Epoch: [12] [576000/1281167 (45%)]	Loss: 1.891995
[2022-03-29 00:17:28 | train] - Train Epoch: [12] [588800/1281167 (46%)]	Loss: 1.776626
[2022-03-29 00:17:53 | train] - Train Epoch: [12] [601600/1281167 (47%)]	Loss: 1.970668
[2022-03-29 00:18:18 | train] - Train Epoch: [12] [614400/1281167 (48%)]	Loss: 2.380486
[2022-03-29 00:18:43 | train] - Train Epoch: [12] [627200/1281167 (49%)]	Loss: 1.990688
[2022-03-29 00:19:08 | train] - Train Epoch: [12] [640000/1281167 (50%)]	Loss: 2.001173
[2022-03-29 00:19:34 | train] - Train Epoch: [12] [652800/1281167 (51%)]	Loss: 1.925372
[2022-03-29 00:20:00 | train] - Train Epoch: [12] [665600/1281167 (52%)]	Loss: 1.869504
[2022-03-29 00:20:25 | train] - Train Epoch: [12] [678400/1281167 (53%)]	Loss: 2.114436
[2022-03-29 00:20:51 | train] - Train Epoch: [12] [691200/1281167 (54%)]	Loss: 1.879611
[2022-03-29 00:21:17 | train] - Train Epoch: [12] [704000/1281167 (55%)]	Loss: 2.245800
[2022-03-29 00:21:42 | train] - Train Epoch: [12] [716800/1281167 (56%)]	Loss: 2.472882
[2022-03-29 00:22:08 | train] - Train Epoch: [12] [729600/1281167 (57%)]	Loss: 1.878334
[2022-03-29 00:22:34 | train] - Train Epoch: [12] [742400/1281167 (58%)]	Loss: 2.020975
[2022-03-29 00:22:58 | train] - Train Epoch: [12] [755200/1281167 (59%)]	Loss: 2.033150
[2022-03-29 00:23:22 | train] - Train Epoch: [12] [768000/1281167 (60%)]	Loss: 2.002548
[2022-03-29 00:23:47 | train] - Train Epoch: [12] [780800/1281167 (61%)]	Loss: 1.856741
[2022-03-29 00:24:12 | train] - Train Epoch: [12] [793600/1281167 (62%)]	Loss: 1.802783
[2022-03-29 00:24:38 | train] - Train Epoch: [12] [806400/1281167 (63%)]	Loss: 2.078866
[2022-03-29 00:25:03 | train] - Train Epoch: [12] [819200/1281167 (64%)]	Loss: 1.763853
[2022-03-29 00:25:27 | train] - Train Epoch: [12] [832000/1281167 (65%)]	Loss: 2.265388
[2022-03-29 00:25:51 | train] - Train Epoch: [12] [844800/1281167 (66%)]	Loss: 1.890848
[2022-03-29 00:26:15 | train] - Train Epoch: [12] [857600/1281167 (67%)]	Loss: 2.251972
[2022-03-29 00:26:40 | train] - Train Epoch: [12] [870400/1281167 (68%)]	Loss: 2.024813
[2022-03-29 00:27:04 | train] - Train Epoch: [12] [883200/1281167 (69%)]	Loss: 1.956296
[2022-03-29 00:27:29 | train] - Train Epoch: [12] [896000/1281167 (70%)]	Loss: 2.043484
[2022-03-29 00:27:54 | train] - Train Epoch: [12] [908800/1281167 (71%)]	Loss: 2.064459
[2022-03-29 00:28:19 | train] - Train Epoch: [12] [921600/1281167 (72%)]	Loss: 2.148074
[2022-03-29 00:28:44 | train] - Train Epoch: [12] [934400/1281167 (73%)]	Loss: 1.960005
[2022-03-29 00:29:08 | train] - Train Epoch: [12] [947200/1281167 (74%)]	Loss: 2.267030
[2022-03-29 00:29:32 | train] - Train Epoch: [12] [960000/1281167 (75%)]	Loss: 1.951478
[2022-03-29 00:29:56 | train] - Train Epoch: [12] [972800/1281167 (76%)]	Loss: 2.057787
[2022-03-29 00:30:21 | train] - Train Epoch: [12] [985600/1281167 (77%)]	Loss: 2.091345
[2022-03-29 00:30:44 | train] - Train Epoch: [12] [998400/1281167 (78%)]	Loss: 1.892713
[2022-03-29 00:31:08 | train] - Train Epoch: [12] [1011200/1281167 (79%)]	Loss: 1.855746
[2022-03-29 00:31:34 | train] - Train Epoch: [12] [1024000/1281167 (80%)]	Loss: 2.047754
[2022-03-29 00:31:58 | train] - Train Epoch: [12] [1036800/1281167 (81%)]	Loss: 2.110014
[2022-03-29 00:32:22 | train] - Train Epoch: [12] [1049600/1281167 (82%)]	Loss: 2.342970
[2022-03-29 00:32:47 | train] - Train Epoch: [12] [1062400/1281167 (83%)]	Loss: 2.062125
[2022-03-29 00:33:12 | train] - Train Epoch: [12] [1075200/1281167 (84%)]	Loss: 2.018559
[2022-03-29 00:33:36 | train] - Train Epoch: [12] [1088000/1281167 (85%)]	Loss: 1.958296
[2022-03-29 00:34:02 | train] - Train Epoch: [12] [1100800/1281167 (86%)]	Loss: 1.800126
[2022-03-29 00:34:26 | train] - Train Epoch: [12] [1113600/1281167 (87%)]	Loss: 2.109403
[2022-03-29 00:34:51 | train] - Train Epoch: [12] [1126400/1281167 (88%)]	Loss: 1.912388
[2022-03-29 00:35:15 | train] - Train Epoch: [12] [1139200/1281167 (89%)]	Loss: 1.918260
[2022-03-29 00:35:39 | train] - Train Epoch: [12] [1152000/1281167 (90%)]	Loss: 2.075429
[2022-03-29 00:36:04 | train] - Train Epoch: [12] [1164800/1281167 (91%)]	Loss: 2.138470
[2022-03-29 00:36:29 | train] - Train Epoch: [12] [1177600/1281167 (92%)]	Loss: 2.253204
[2022-03-29 00:36:53 | train] - Train Epoch: [12] [1190400/1281167 (93%)]	Loss: 2.091112
[2022-03-29 00:37:18 | train] - Train Epoch: [12] [1203200/1281167 (94%)]	Loss: 2.293616
[2022-03-29 00:37:41 | train] - Train Epoch: [12] [1216000/1281167 (95%)]	Loss: 2.235261
[2022-03-29 00:38:06 | train] - Train Epoch: [12] [1228800/1281167 (96%)]	Loss: 2.414549
[2022-03-29 00:38:30 | train] - Train Epoch: [12] [1241600/1281167 (97%)]	Loss: 1.589218
[2022-03-29 00:38:55 | train] - Train Epoch: [12] [1254400/1281167 (98%)]	Loss: 2.102565
[2022-03-29 00:39:20 | train] - Train Epoch: [12] [1267200/1281167 (99%)]	Loss: 2.120762
[2022-03-29 00:39:45 | train] - Train Epoch: [12] [1280000/1281167 (100%)]	Loss: 2.207155
[2022-03-29 00:39:48 | train] - Train Epoch: [12]	 Average Loss: 2.057131	 Total Acc : 53.6564	 Total Top5 Acc : 76.6008
[2022-03-29 00:39:50 | train] - -------12 epoch end-----------
========================================
-------12 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 00:41:50 | train] - 
Epoch [12] Test set: Average loss: 1.7627, Accuracy: 29170/50000 (58.3032%), Top-5 Accuracy: 81.6256%

[2022-03-29 00:41:50 | train] - save intermediate epoch [12] result


[2022-03-29 00:41:52 | train] - logging best performance 12 epoch
[2022-03-29 00:41:53 | train] - -------13 epoch start-----------
========================================
----- test end -------------------------


logging best performance 12 epoch
[2022-03-29 00:41:55 | train] - Train Epoch: [13] [0/1281167 (0%)]	Loss: 1.748077
[2022-03-29 00:42:26 | train] - Train Epoch: [13] [12800/1281167 (1%)]	Loss: 1.677008
[2022-03-29 00:42:55 | train] - Train Epoch: [13] [25600/1281167 (2%)]	Loss: 1.781377
[2022-03-29 00:43:25 | train] - Train Epoch: [13] [38400/1281167 (3%)]	Loss: 1.831831
[2022-03-29 00:43:54 | train] - Train Epoch: [13] [51200/1281167 (4%)]	Loss: 1.809916
[2022-03-29 00:44:23 | train] - Train Epoch: [13] [64000/1281167 (5%)]	Loss: 2.134797
[2022-03-29 00:44:53 | train] - Train Epoch: [13] [76800/1281167 (6%)]	Loss: 1.867033
[2022-03-29 00:45:22 | train] - Train Epoch: [13] [89600/1281167 (7%)]	Loss: 1.914499
[2022-03-29 00:45:51 | train] - Train Epoch: [13] [102400/1281167 (8%)]	Loss: 2.052336
[2022-03-29 00:46:20 | train] - Train Epoch: [13] [115200/1281167 (9%)]	Loss: 1.873043
[2022-03-29 00:46:49 | train] - Train Epoch: [13] [128000/1281167 (10%)]	Loss: 2.236614
[2022-03-29 00:47:19 | train] - Train Epoch: [13] [140800/1281167 (11%)]	Loss: 2.236004
[2022-03-29 00:47:48 | train] - Train Epoch: [13] [153600/1281167 (12%)]	Loss: 2.218646
[2022-03-29 00:48:16 | train] - Train Epoch: [13] [166400/1281167 (13%)]	Loss: 2.092579
[2022-03-29 00:48:45 | train] - Train Epoch: [13] [179200/1281167 (14%)]	Loss: 1.943066
[2022-03-29 00:49:15 | train] - Train Epoch: [13] [192000/1281167 (15%)]	Loss: 1.568094
[2022-03-29 00:49:45 | train] - Train Epoch: [13] [204800/1281167 (16%)]	Loss: 2.262414
[2022-03-29 00:50:14 | train] - Train Epoch: [13] [217600/1281167 (17%)]	Loss: 2.126563
[2022-03-29 00:50:43 | train] - Train Epoch: [13] [230400/1281167 (18%)]	Loss: 1.796914
[2022-03-29 00:51:12 | train] - Train Epoch: [13] [243200/1281167 (19%)]	Loss: 1.734562
[2022-03-29 00:51:42 | train] - Train Epoch: [13] [256000/1281167 (20%)]	Loss: 1.951458
[2022-03-29 00:52:11 | train] - Train Epoch: [13] [268800/1281167 (21%)]	Loss: 2.141985
[2022-03-29 00:52:40 | train] - Train Epoch: [13] [281600/1281167 (22%)]	Loss: 2.400998
[2022-03-29 00:53:09 | train] - Train Epoch: [13] [294400/1281167 (23%)]	Loss: 1.583659
[2022-03-29 00:53:39 | train] - Train Epoch: [13] [307200/1281167 (24%)]	Loss: 1.930486
[2022-03-29 00:54:08 | train] - Train Epoch: [13] [320000/1281167 (25%)]	Loss: 1.759207
[2022-03-29 00:54:37 | train] - Train Epoch: [13] [332800/1281167 (26%)]	Loss: 2.046866
[2022-03-29 00:55:06 | train] - Train Epoch: [13] [345600/1281167 (27%)]	Loss: 2.043583
[2022-03-29 00:55:36 | train] - Train Epoch: [13] [358400/1281167 (28%)]	Loss: 1.832170
[2022-03-29 00:56:05 | train] - Train Epoch: [13] [371200/1281167 (29%)]	Loss: 2.027964
[2022-03-29 00:56:34 | train] - Train Epoch: [13] [384000/1281167 (30%)]	Loss: 2.136894
[2022-03-29 00:57:03 | train] - Train Epoch: [13] [396800/1281167 (31%)]	Loss: 1.705454
[2022-03-29 00:57:32 | train] - Train Epoch: [13] [409600/1281167 (32%)]	Loss: 1.839179
[2022-03-29 00:58:01 | train] - Train Epoch: [13] [422400/1281167 (33%)]	Loss: 2.137393
[2022-03-29 00:58:31 | train] - Train Epoch: [13] [435200/1281167 (34%)]	Loss: 2.043418
[2022-03-29 00:59:00 | train] - Train Epoch: [13] [448000/1281167 (35%)]	Loss: 2.110557
[2022-03-29 00:59:29 | train] - Train Epoch: [13] [460800/1281167 (36%)]	Loss: 1.943195
[2022-03-29 00:59:58 | train] - Train Epoch: [13] [473600/1281167 (37%)]	Loss: 1.687703
[2022-03-29 01:00:27 | train] - Train Epoch: [13] [486400/1281167 (38%)]	Loss: 1.999315
[2022-03-29 01:00:57 | train] - Train Epoch: [13] [499200/1281167 (39%)]	Loss: 1.841198
[2022-03-29 01:01:26 | train] - Train Epoch: [13] [512000/1281167 (40%)]	Loss: 2.390061
[2022-03-29 01:01:56 | train] - Train Epoch: [13] [524800/1281167 (41%)]	Loss: 2.150510
[2022-03-29 01:02:25 | train] - Train Epoch: [13] [537600/1281167 (42%)]	Loss: 2.029231
[2022-03-29 01:02:54 | train] - Train Epoch: [13] [550400/1281167 (43%)]	Loss: 2.058315
[2022-03-29 01:03:24 | train] - Train Epoch: [13] [563200/1281167 (44%)]	Loss: 1.892978
[2022-03-29 01:03:53 | train] - Train Epoch: [13] [576000/1281167 (45%)]	Loss: 2.152967
[2022-03-29 01:04:22 | train] - Train Epoch: [13] [588800/1281167 (46%)]	Loss: 2.171184
[2022-03-29 01:04:51 | train] - Train Epoch: [13] [601600/1281167 (47%)]	Loss: 2.021967
[2022-03-29 01:05:20 | train] - Train Epoch: [13] [614400/1281167 (48%)]	Loss: 1.885379
[2022-03-29 01:05:49 | train] - Train Epoch: [13] [627200/1281167 (49%)]	Loss: 2.047703
[2022-03-29 01:06:19 | train] - Train Epoch: [13] [640000/1281167 (50%)]	Loss: 2.554738
[2022-03-29 01:06:48 | train] - Train Epoch: [13] [652800/1281167 (51%)]	Loss: 1.768709
[2022-03-29 01:07:17 | train] - Train Epoch: [13] [665600/1281167 (52%)]	Loss: 2.022292
[2022-03-29 01:07:46 | train] - Train Epoch: [13] [678400/1281167 (53%)]	Loss: 1.792922
[2022-03-29 01:08:15 | train] - Train Epoch: [13] [691200/1281167 (54%)]	Loss: 1.511316
[2022-03-29 01:08:44 | train] - Train Epoch: [13] [704000/1281167 (55%)]	Loss: 1.809054
[2022-03-29 01:09:14 | train] - Train Epoch: [13] [716800/1281167 (56%)]	Loss: 2.404324
[2022-03-29 01:09:43 | train] - Train Epoch: [13] [729600/1281167 (57%)]	Loss: 2.215246
[2022-03-29 01:10:12 | train] - Train Epoch: [13] [742400/1281167 (58%)]	Loss: 1.750982
[2022-03-29 01:10:42 | train] - Train Epoch: [13] [755200/1281167 (59%)]	Loss: 1.970006
[2022-03-29 01:11:11 | train] - Train Epoch: [13] [768000/1281167 (60%)]	Loss: 1.519688
[2022-03-29 01:11:40 | train] - Train Epoch: [13] [780800/1281167 (61%)]	Loss: 2.342016
[2022-03-29 01:12:09 | train] - Train Epoch: [13] [793600/1281167 (62%)]	Loss: 1.683061
[2022-03-29 01:12:38 | train] - Train Epoch: [13] [806400/1281167 (63%)]	Loss: 2.196554
[2022-03-29 01:13:08 | train] - Train Epoch: [13] [819200/1281167 (64%)]	Loss: 1.782922
[2022-03-29 01:13:37 | train] - Train Epoch: [13] [832000/1281167 (65%)]	Loss: 2.000603
[2022-03-29 01:14:06 | train] - Train Epoch: [13] [844800/1281167 (66%)]	Loss: 2.324727
[2022-03-29 01:14:35 | train] - Train Epoch: [13] [857600/1281167 (67%)]	Loss: 1.822439
[2022-03-29 01:15:04 | train] - Train Epoch: [13] [870400/1281167 (68%)]	Loss: 2.192555
[2022-03-29 01:15:33 | train] - Train Epoch: [13] [883200/1281167 (69%)]	Loss: 1.953662
[2022-03-29 01:16:02 | train] - Train Epoch: [13] [896000/1281167 (70%)]	Loss: 1.843633
[2022-03-29 01:16:32 | train] - Train Epoch: [13] [908800/1281167 (71%)]	Loss: 1.918296
[2022-03-29 01:17:01 | train] - Train Epoch: [13] [921600/1281167 (72%)]	Loss: 2.170965
[2022-03-29 01:17:31 | train] - Train Epoch: [13] [934400/1281167 (73%)]	Loss: 2.135582
[2022-03-29 01:18:01 | train] - Train Epoch: [13] [947200/1281167 (74%)]	Loss: 2.093191
[2022-03-29 01:18:30 | train] - Train Epoch: [13] [960000/1281167 (75%)]	Loss: 2.029411
[2022-03-29 01:19:00 | train] - Train Epoch: [13] [972800/1281167 (76%)]	Loss: 2.111154
[2022-03-29 01:19:28 | train] - Train Epoch: [13] [985600/1281167 (77%)]	Loss: 2.020974
[2022-03-29 01:19:57 | train] - Train Epoch: [13] [998400/1281167 (78%)]	Loss: 1.932663
[2022-03-29 01:20:26 | train] - Train Epoch: [13] [1011200/1281167 (79%)]	Loss: 1.993028
[2022-03-29 01:20:55 | train] - Train Epoch: [13] [1024000/1281167 (80%)]	Loss: 1.887523
[2022-03-29 01:21:24 | train] - Train Epoch: [13] [1036800/1281167 (81%)]	Loss: 1.699831
[2022-03-29 01:21:53 | train] - Train Epoch: [13] [1049600/1281167 (82%)]	Loss: 1.818927
[2022-03-29 01:22:22 | train] - Train Epoch: [13] [1062400/1281167 (83%)]	Loss: 2.128523
[2022-03-29 01:22:52 | train] - Train Epoch: [13] [1075200/1281167 (84%)]	Loss: 1.930580
[2022-03-29 01:23:21 | train] - Train Epoch: [13] [1088000/1281167 (85%)]	Loss: 2.166081
[2022-03-29 01:23:51 | train] - Train Epoch: [13] [1100800/1281167 (86%)]	Loss: 1.815316
[2022-03-29 01:24:21 | train] - Train Epoch: [13] [1113600/1281167 (87%)]	Loss: 1.875065
[2022-03-29 01:24:50 | train] - Train Epoch: [13] [1126400/1281167 (88%)]	Loss: 2.107627
[2022-03-29 01:25:19 | train] - Train Epoch: [13] [1139200/1281167 (89%)]	Loss: 1.607796
[2022-03-29 01:25:49 | train] - Train Epoch: [13] [1152000/1281167 (90%)]	Loss: 2.133653
[2022-03-29 01:26:18 | train] - Train Epoch: [13] [1164800/1281167 (91%)]	Loss: 2.243359
[2022-03-29 01:26:47 | train] - Train Epoch: [13] [1177600/1281167 (92%)]	Loss: 2.017480
[2022-03-29 01:27:16 | train] - Train Epoch: [13] [1190400/1281167 (93%)]	Loss: 2.055293
[2022-03-29 01:27:46 | train] - Train Epoch: [13] [1203200/1281167 (94%)]	Loss: 1.557388
[2022-03-29 01:28:15 | train] - Train Epoch: [13] [1216000/1281167 (95%)]	Loss: 2.201633
[2022-03-29 01:28:44 | train] - Train Epoch: [13] [1228800/1281167 (96%)]	Loss: 1.907043
[2022-03-29 01:29:13 | train] - Train Epoch: [13] [1241600/1281167 (97%)]	Loss: 1.839429
[2022-03-29 01:29:42 | train] - Train Epoch: [13] [1254400/1281167 (98%)]	Loss: 2.376330
[2022-03-29 01:30:12 | train] - Train Epoch: [13] [1267200/1281167 (99%)]	Loss: 1.825607
[2022-03-29 01:30:41 | train] - Train Epoch: [13] [1280000/1281167 (100%)]	Loss: 1.836950
[2022-03-29 01:30:44 | train] - Train Epoch: [13]	 Average Loss: 1.995574	 Total Acc : 54.7936	 Total Top5 Acc : 77.5227
[2022-03-29 01:30:46 | train] - -------13 epoch end-----------
========================================
-------13 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 01:32:55 | train] - 
Epoch [13] Test set: Average loss: 1.7378, Accuracy: 29623/50000 (59.2060%), Top-5 Accuracy: 82.1008%

[2022-03-29 01:32:55 | train] - save intermediate epoch [13] result


[2022-03-29 01:32:56 | train] - logging best performance 13 epoch
[2022-03-29 01:32:57 | train] - -------14 epoch start-----------
========================================
----- test end -------------------------


logging best performance 13 epoch
[2022-03-29 01:33:00 | train] - Train Epoch: [14] [0/1281167 (0%)]	Loss: 1.604113
[2022-03-29 01:33:31 | train] - Train Epoch: [14] [12800/1281167 (1%)]	Loss: 2.242199
[2022-03-29 01:34:01 | train] - Train Epoch: [14] [25600/1281167 (2%)]	Loss: 1.849496
[2022-03-29 01:34:31 | train] - Train Epoch: [14] [38400/1281167 (3%)]	Loss: 1.859609
[2022-03-29 01:35:01 | train] - Train Epoch: [14] [51200/1281167 (4%)]	Loss: 2.027625
[2022-03-29 01:35:31 | train] - Train Epoch: [14] [64000/1281167 (5%)]	Loss: 2.343433
[2022-03-29 01:36:01 | train] - Train Epoch: [14] [76800/1281167 (6%)]	Loss: 1.867569
[2022-03-29 01:36:31 | train] - Train Epoch: [14] [89600/1281167 (7%)]	Loss: 1.929411
[2022-03-29 01:37:01 | train] - Train Epoch: [14] [102400/1281167 (8%)]	Loss: 2.163522
[2022-03-29 01:37:31 | train] - Train Epoch: [14] [115200/1281167 (9%)]	Loss: 2.124203
[2022-03-29 01:38:01 | train] - Train Epoch: [14] [128000/1281167 (10%)]	Loss: 2.030345
[2022-03-29 01:38:31 | train] - Train Epoch: [14] [140800/1281167 (11%)]	Loss: 2.211654
[2022-03-29 01:39:01 | train] - Train Epoch: [14] [153600/1281167 (12%)]	Loss: 2.263291
[2022-03-29 01:39:31 | train] - Train Epoch: [14] [166400/1281167 (13%)]	Loss: 1.949874
[2022-03-29 01:40:01 | train] - Train Epoch: [14] [179200/1281167 (14%)]	Loss: 1.739340
[2022-03-29 01:40:31 | train] - Train Epoch: [14] [192000/1281167 (15%)]	Loss: 1.855392
[2022-03-29 01:41:01 | train] - Train Epoch: [14] [204800/1281167 (16%)]	Loss: 1.561553
[2022-03-29 01:41:31 | train] - Train Epoch: [14] [217600/1281167 (17%)]	Loss: 1.664247
[2022-03-29 01:42:01 | train] - Train Epoch: [14] [230400/1281167 (18%)]	Loss: 1.994081
[2022-03-29 01:42:31 | train] - Train Epoch: [14] [243200/1281167 (19%)]	Loss: 1.985534
[2022-03-29 01:43:02 | train] - Train Epoch: [14] [256000/1281167 (20%)]	Loss: 2.135564
[2022-03-29 01:43:31 | train] - Train Epoch: [14] [268800/1281167 (21%)]	Loss: 1.980565
[2022-03-29 01:44:01 | train] - Train Epoch: [14] [281600/1281167 (22%)]	Loss: 2.235817
[2022-03-29 01:44:31 | train] - Train Epoch: [14] [294400/1281167 (23%)]	Loss: 1.900643
[2022-03-29 01:45:01 | train] - Train Epoch: [14] [307200/1281167 (24%)]	Loss: 2.034292
[2022-03-29 01:45:31 | train] - Train Epoch: [14] [320000/1281167 (25%)]	Loss: 1.662365
[2022-03-29 01:46:02 | train] - Train Epoch: [14] [332800/1281167 (26%)]	Loss: 2.038812
[2022-03-29 01:46:31 | train] - Train Epoch: [14] [345600/1281167 (27%)]	Loss: 1.960576
[2022-03-29 01:47:01 | train] - Train Epoch: [14] [358400/1281167 (28%)]	Loss: 1.893101
[2022-03-29 01:47:31 | train] - Train Epoch: [14] [371200/1281167 (29%)]	Loss: 1.876889
[2022-03-29 01:48:01 | train] - Train Epoch: [14] [384000/1281167 (30%)]	Loss: 1.922440
[2022-03-29 01:48:31 | train] - Train Epoch: [14] [396800/1281167 (31%)]	Loss: 1.805371
[2022-03-29 01:49:01 | train] - Train Epoch: [14] [409600/1281167 (32%)]	Loss: 1.702739
[2022-03-29 01:49:31 | train] - Train Epoch: [14] [422400/1281167 (33%)]	Loss: 1.990339
[2022-03-29 01:50:01 | train] - Train Epoch: [14] [435200/1281167 (34%)]	Loss: 1.950565
[2022-03-29 01:50:31 | train] - Train Epoch: [14] [448000/1281167 (35%)]	Loss: 1.681147
[2022-03-29 01:51:01 | train] - Train Epoch: [14] [460800/1281167 (36%)]	Loss: 1.880740
[2022-03-29 01:51:31 | train] - Train Epoch: [14] [473600/1281167 (37%)]	Loss: 2.236612
[2022-03-29 01:52:01 | train] - Train Epoch: [14] [486400/1281167 (38%)]	Loss: 2.056310
[2022-03-29 01:52:31 | train] - Train Epoch: [14] [499200/1281167 (39%)]	Loss: 1.807485
[2022-03-29 01:53:01 | train] - Train Epoch: [14] [512000/1281167 (40%)]	Loss: 1.942376
[2022-03-29 01:53:32 | train] - Train Epoch: [14] [524800/1281167 (41%)]	Loss: 1.759759
[2022-03-29 01:54:01 | train] - Train Epoch: [14] [537600/1281167 (42%)]	Loss: 1.898448
[2022-03-29 01:54:32 | train] - Train Epoch: [14] [550400/1281167 (43%)]	Loss: 1.968772
[2022-03-29 01:55:02 | train] - Train Epoch: [14] [563200/1281167 (44%)]	Loss: 1.851803
[2022-03-29 01:55:32 | train] - Train Epoch: [14] [576000/1281167 (45%)]	Loss: 2.021990
[2022-03-29 01:56:02 | train] - Train Epoch: [14] [588800/1281167 (46%)]	Loss: 1.939567
[2022-03-29 01:56:32 | train] - Train Epoch: [14] [601600/1281167 (47%)]	Loss: 1.550846
[2022-03-29 01:57:02 | train] - Train Epoch: [14] [614400/1281167 (48%)]	Loss: 1.722443
[2022-03-29 01:57:32 | train] - Train Epoch: [14] [627200/1281167 (49%)]	Loss: 2.026360
[2022-03-29 01:58:02 | train] - Train Epoch: [14] [640000/1281167 (50%)]	Loss: 2.075589
[2022-03-29 01:58:32 | train] - Train Epoch: [14] [652800/1281167 (51%)]	Loss: 1.810394
[2022-03-29 01:59:03 | train] - Train Epoch: [14] [665600/1281167 (52%)]	Loss: 2.136687
[2022-03-29 01:59:33 | train] - Train Epoch: [14] [678400/1281167 (53%)]	Loss: 2.086977
[2022-03-29 02:00:02 | train] - Train Epoch: [14] [691200/1281167 (54%)]	Loss: 1.833141
[2022-03-29 02:00:32 | train] - Train Epoch: [14] [704000/1281167 (55%)]	Loss: 2.064126
[2022-03-29 02:01:03 | train] - Train Epoch: [14] [716800/1281167 (56%)]	Loss: 1.522953
[2022-03-29 02:01:33 | train] - Train Epoch: [14] [729600/1281167 (57%)]	Loss: 1.653504
[2022-03-29 02:02:03 | train] - Train Epoch: [14] [742400/1281167 (58%)]	Loss: 1.797915
[2022-03-29 02:02:32 | train] - Train Epoch: [14] [755200/1281167 (59%)]	Loss: 2.119280
[2022-03-29 02:03:03 | train] - Train Epoch: [14] [768000/1281167 (60%)]	Loss: 1.946424
[2022-03-29 02:03:33 | train] - Train Epoch: [14] [780800/1281167 (61%)]	Loss: 1.701904
[2022-03-29 02:04:04 | train] - Train Epoch: [14] [793600/1281167 (62%)]	Loss: 1.817036
[2022-03-29 02:04:33 | train] - Train Epoch: [14] [806400/1281167 (63%)]	Loss: 1.823223
[2022-03-29 02:05:03 | train] - Train Epoch: [14] [819200/1281167 (64%)]	Loss: 1.679409
[2022-03-29 02:05:34 | train] - Train Epoch: [14] [832000/1281167 (65%)]	Loss: 2.104387
[2022-03-29 02:06:04 | train] - Train Epoch: [14] [844800/1281167 (66%)]	Loss: 1.742620
[2022-03-29 02:06:33 | train] - Train Epoch: [14] [857600/1281167 (67%)]	Loss: 1.781935
[2022-03-29 02:07:03 | train] - Train Epoch: [14] [870400/1281167 (68%)]	Loss: 1.925161
[2022-03-29 02:07:33 | train] - Train Epoch: [14] [883200/1281167 (69%)]	Loss: 1.713776
[2022-03-29 02:08:04 | train] - Train Epoch: [14] [896000/1281167 (70%)]	Loss: 1.765488
[2022-03-29 02:08:34 | train] - Train Epoch: [14] [908800/1281167 (71%)]	Loss: 2.128194
[2022-03-29 02:09:05 | train] - Train Epoch: [14] [921600/1281167 (72%)]	Loss: 2.115133
[2022-03-29 02:09:35 | train] - Train Epoch: [14] [934400/1281167 (73%)]	Loss: 1.793525
[2022-03-29 02:10:05 | train] - Train Epoch: [14] [947200/1281167 (74%)]	Loss: 1.648643
[2022-03-29 02:10:36 | train] - Train Epoch: [14] [960000/1281167 (75%)]	Loss: 1.872603
[2022-03-29 02:11:07 | train] - Train Epoch: [14] [972800/1281167 (76%)]	Loss: 1.923077
[2022-03-29 02:11:37 | train] - Train Epoch: [14] [985600/1281167 (77%)]	Loss: 1.761548
[2022-03-29 02:12:07 | train] - Train Epoch: [14] [998400/1281167 (78%)]	Loss: 2.064313
[2022-03-29 02:12:37 | train] - Train Epoch: [14] [1011200/1281167 (79%)]	Loss: 1.782529
[2022-03-29 02:13:08 | train] - Train Epoch: [14] [1024000/1281167 (80%)]	Loss: 1.677217
[2022-03-29 02:13:38 | train] - Train Epoch: [14] [1036800/1281167 (81%)]	Loss: 2.056054
[2022-03-29 02:14:08 | train] - Train Epoch: [14] [1049600/1281167 (82%)]	Loss: 2.021554
[2022-03-29 02:14:39 | train] - Train Epoch: [14] [1062400/1281167 (83%)]	Loss: 2.048256
[2022-03-29 02:15:09 | train] - Train Epoch: [14] [1075200/1281167 (84%)]	Loss: 1.796996
[2022-03-29 02:15:39 | train] - Train Epoch: [14] [1088000/1281167 (85%)]	Loss: 1.690069
[2022-03-29 02:16:10 | train] - Train Epoch: [14] [1100800/1281167 (86%)]	Loss: 1.904226
[2022-03-29 02:16:40 | train] - Train Epoch: [14] [1113600/1281167 (87%)]	Loss: 1.934319
[2022-03-29 02:17:10 | train] - Train Epoch: [14] [1126400/1281167 (88%)]	Loss: 1.818365
[2022-03-29 02:17:40 | train] - Train Epoch: [14] [1139200/1281167 (89%)]	Loss: 2.150462
[2022-03-29 02:18:10 | train] - Train Epoch: [14] [1152000/1281167 (90%)]	Loss: 2.085592
[2022-03-29 02:18:41 | train] - Train Epoch: [14] [1164800/1281167 (91%)]	Loss: 1.921366
[2022-03-29 02:19:11 | train] - Train Epoch: [14] [1177600/1281167 (92%)]	Loss: 1.958270
[2022-03-29 02:19:40 | train] - Train Epoch: [14] [1190400/1281167 (93%)]	Loss: 1.781895
[2022-03-29 02:20:10 | train] - Train Epoch: [14] [1203200/1281167 (94%)]	Loss: 1.839906
[2022-03-29 02:20:40 | train] - Train Epoch: [14] [1216000/1281167 (95%)]	Loss: 1.982308
[2022-03-29 02:21:11 | train] - Train Epoch: [14] [1228800/1281167 (96%)]	Loss: 1.766283
[2022-03-29 02:21:40 | train] - Train Epoch: [14] [1241600/1281167 (97%)]	Loss: 2.017398
[2022-03-29 02:22:10 | train] - Train Epoch: [14] [1254400/1281167 (98%)]	Loss: 1.816677
[2022-03-29 02:22:41 | train] - Train Epoch: [14] [1267200/1281167 (99%)]	Loss: 1.626383
[2022-03-29 02:23:11 | train] - Train Epoch: [14] [1280000/1281167 (100%)]	Loss: 2.077888
[2022-03-29 02:23:14 | train] - Train Epoch: [14]	 Average Loss: 1.937790	 Total Acc : 55.9444	 Total Top5 Acc : 78.3941
[2022-03-29 02:23:16 | train] - -------14 epoch end-----------
========================================
-------14 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 02:25:22 | train] - 
Epoch [14] Test set: Average loss: 1.6708, Accuracy: 30154/50000 (60.2753%), Top-5 Accuracy: 82.8872%

[2022-03-29 02:25:22 | train] - save intermediate epoch [14] result


[2022-03-29 02:25:24 | train] - logging best performance 14 epoch
[2022-03-29 02:25:26 | train] - -------15 epoch start-----------
========================================
----- test end -------------------------


logging best performance 14 epoch
[2022-03-29 02:25:28 | train] - Train Epoch: [15] [0/1281167 (0%)]	Loss: 1.583958
[2022-03-29 02:25:58 | train] - Train Epoch: [15] [12800/1281167 (1%)]	Loss: 1.840191
[2022-03-29 02:26:27 | train] - Train Epoch: [15] [25600/1281167 (2%)]	Loss: 1.640063
[2022-03-29 02:26:57 | train] - Train Epoch: [15] [38400/1281167 (3%)]	Loss: 2.219719
[2022-03-29 02:27:26 | train] - Train Epoch: [15] [51200/1281167 (4%)]	Loss: 1.651543
[2022-03-29 02:27:55 | train] - Train Epoch: [15] [64000/1281167 (5%)]	Loss: 1.588711
[2022-03-29 02:28:25 | train] - Train Epoch: [15] [76800/1281167 (6%)]	Loss: 2.091962
[2022-03-29 02:28:54 | train] - Train Epoch: [15] [89600/1281167 (7%)]	Loss: 1.977972
[2022-03-29 02:29:23 | train] - Train Epoch: [15] [102400/1281167 (8%)]	Loss: 2.218689
[2022-03-29 02:29:52 | train] - Train Epoch: [15] [115200/1281167 (9%)]	Loss: 1.728065
[2022-03-29 02:30:21 | train] - Train Epoch: [15] [128000/1281167 (10%)]	Loss: 1.806370
[2022-03-29 02:30:51 | train] - Train Epoch: [15] [140800/1281167 (11%)]	Loss: 1.784430
[2022-03-29 02:31:19 | train] - Train Epoch: [15] [153600/1281167 (12%)]	Loss: 1.743340
[2022-03-29 02:31:48 | train] - Train Epoch: [15] [166400/1281167 (13%)]	Loss: 1.670946
[2022-03-29 02:32:18 | train] - Train Epoch: [15] [179200/1281167 (14%)]	Loss: 1.935022
[2022-03-29 02:32:47 | train] - Train Epoch: [15] [192000/1281167 (15%)]	Loss: 2.261834
[2022-03-29 02:33:17 | train] - Train Epoch: [15] [204800/1281167 (16%)]	Loss: 1.800585
[2022-03-29 02:33:46 | train] - Train Epoch: [15] [217600/1281167 (17%)]	Loss: 1.868617
[2022-03-29 02:34:16 | train] - Train Epoch: [15] [230400/1281167 (18%)]	Loss: 1.736931
[2022-03-29 02:34:45 | train] - Train Epoch: [15] [243200/1281167 (19%)]	Loss: 1.735336
[2022-03-29 02:35:15 | train] - Train Epoch: [15] [256000/1281167 (20%)]	Loss: 1.769635
[2022-03-29 02:35:44 | train] - Train Epoch: [15] [268800/1281167 (21%)]	Loss: 1.882404
[2022-03-29 02:36:13 | train] - Train Epoch: [15] [281600/1281167 (22%)]	Loss: 1.953105
[2022-03-29 02:36:42 | train] - Train Epoch: [15] [294400/1281167 (23%)]	Loss: 1.861454
[2022-03-29 02:37:11 | train] - Train Epoch: [15] [307200/1281167 (24%)]	Loss: 2.011141
[2022-03-29 02:37:40 | train] - Train Epoch: [15] [320000/1281167 (25%)]	Loss: 1.615392
[2022-03-29 02:38:10 | train] - Train Epoch: [15] [332800/1281167 (26%)]	Loss: 1.969515
[2022-03-29 02:38:39 | train] - Train Epoch: [15] [345600/1281167 (27%)]	Loss: 1.813167
[2022-03-29 02:39:08 | train] - Train Epoch: [15] [358400/1281167 (28%)]	Loss: 2.089820
[2022-03-29 02:39:37 | train] - Train Epoch: [15] [371200/1281167 (29%)]	Loss: 2.059877
[2022-03-29 02:40:06 | train] - Train Epoch: [15] [384000/1281167 (30%)]	Loss: 2.013812
[2022-03-29 02:40:35 | train] - Train Epoch: [15] [396800/1281167 (31%)]	Loss: 1.640946
[2022-03-29 02:41:05 | train] - Train Epoch: [15] [409600/1281167 (32%)]	Loss: 1.711871
[2022-03-29 02:41:35 | train] - Train Epoch: [15] [422400/1281167 (33%)]	Loss: 1.862535
[2022-03-29 02:42:05 | train] - Train Epoch: [15] [435200/1281167 (34%)]	Loss: 1.686321
[2022-03-29 02:42:34 | train] - Train Epoch: [15] [448000/1281167 (35%)]	Loss: 2.209795
[2022-03-29 02:43:03 | train] - Train Epoch: [15] [460800/1281167 (36%)]	Loss: 1.732362
[2022-03-29 02:43:33 | train] - Train Epoch: [15] [473600/1281167 (37%)]	Loss: 1.566333
[2022-03-29 02:44:02 | train] - Train Epoch: [15] [486400/1281167 (38%)]	Loss: 1.940070
[2022-03-29 02:44:32 | train] - Train Epoch: [15] [499200/1281167 (39%)]	Loss: 2.202797
[2022-03-29 02:45:01 | train] - Train Epoch: [15] [512000/1281167 (40%)]	Loss: 1.968642
[2022-03-29 02:45:30 | train] - Train Epoch: [15] [524800/1281167 (41%)]	Loss: 2.018476
[2022-03-29 02:45:59 | train] - Train Epoch: [15] [537600/1281167 (42%)]	Loss: 1.446966
[2022-03-29 02:46:28 | train] - Train Epoch: [15] [550400/1281167 (43%)]	Loss: 1.471625
[2022-03-29 02:46:58 | train] - Train Epoch: [15] [563200/1281167 (44%)]	Loss: 1.780048
[2022-03-29 02:47:28 | train] - Train Epoch: [15] [576000/1281167 (45%)]	Loss: 1.725912
[2022-03-29 02:47:57 | train] - Train Epoch: [15] [588800/1281167 (46%)]	Loss: 1.634147
[2022-03-29 02:48:26 | train] - Train Epoch: [15] [601600/1281167 (47%)]	Loss: 1.939568
[2022-03-29 02:48:56 | train] - Train Epoch: [15] [614400/1281167 (48%)]	Loss: 1.655555
[2022-03-29 02:49:24 | train] - Train Epoch: [15] [627200/1281167 (49%)]	Loss: 1.510224
[2022-03-29 02:49:54 | train] - Train Epoch: [15] [640000/1281167 (50%)]	Loss: 2.009141
[2022-03-29 02:50:24 | train] - Train Epoch: [15] [652800/1281167 (51%)]	Loss: 1.764746
[2022-03-29 02:50:53 | train] - Train Epoch: [15] [665600/1281167 (52%)]	Loss: 1.898107
[2022-03-29 02:51:22 | train] - Train Epoch: [15] [678400/1281167 (53%)]	Loss: 1.781532
[2022-03-29 02:51:51 | train] - Train Epoch: [15] [691200/1281167 (54%)]	Loss: 1.554952
[2022-03-29 02:52:20 | train] - Train Epoch: [15] [704000/1281167 (55%)]	Loss: 2.105302
[2022-03-29 02:52:50 | train] - Train Epoch: [15] [716800/1281167 (56%)]	Loss: 1.630588
[2022-03-29 02:53:19 | train] - Train Epoch: [15] [729600/1281167 (57%)]	Loss: 1.904894
[2022-03-29 02:53:49 | train] - Train Epoch: [15] [742400/1281167 (58%)]	Loss: 1.807029
[2022-03-29 02:54:18 | train] - Train Epoch: [15] [755200/1281167 (59%)]	Loss: 1.890626
[2022-03-29 02:54:48 | train] - Train Epoch: [15] [768000/1281167 (60%)]	Loss: 1.972379
[2022-03-29 02:55:17 | train] - Train Epoch: [15] [780800/1281167 (61%)]	Loss: 2.362908
[2022-03-29 02:55:47 | train] - Train Epoch: [15] [793600/1281167 (62%)]	Loss: 1.716018
[2022-03-29 02:56:16 | train] - Train Epoch: [15] [806400/1281167 (63%)]	Loss: 2.092211
[2022-03-29 02:56:46 | train] - Train Epoch: [15] [819200/1281167 (64%)]	Loss: 1.877815
[2022-03-29 02:57:15 | train] - Train Epoch: [15] [832000/1281167 (65%)]	Loss: 1.842272
[2022-03-29 02:57:44 | train] - Train Epoch: [15] [844800/1281167 (66%)]	Loss: 2.032931
[2022-03-29 02:58:14 | train] - Train Epoch: [15] [857600/1281167 (67%)]	Loss: 1.744721
[2022-03-29 02:58:43 | train] - Train Epoch: [15] [870400/1281167 (68%)]	Loss: 1.786090
[2022-03-29 02:59:12 | train] - Train Epoch: [15] [883200/1281167 (69%)]	Loss: 1.567186
[2022-03-29 02:59:41 | train] - Train Epoch: [15] [896000/1281167 (70%)]	Loss: 1.841907
[2022-03-29 03:00:10 | train] - Train Epoch: [15] [908800/1281167 (71%)]	Loss: 1.815614
[2022-03-29 03:00:40 | train] - Train Epoch: [15] [921600/1281167 (72%)]	Loss: 1.685246
[2022-03-29 03:01:09 | train] - Train Epoch: [15] [934400/1281167 (73%)]	Loss: 2.146813
[2022-03-29 03:01:38 | train] - Train Epoch: [15] [947200/1281167 (74%)]	Loss: 1.828570
[2022-03-29 03:02:07 | train] - Train Epoch: [15] [960000/1281167 (75%)]	Loss: 1.732620
[2022-03-29 03:02:36 | train] - Train Epoch: [15] [972800/1281167 (76%)]	Loss: 1.682056
[2022-03-29 03:03:05 | train] - Train Epoch: [15] [985600/1281167 (77%)]	Loss: 1.720195
[2022-03-29 03:03:34 | train] - Train Epoch: [15] [998400/1281167 (78%)]	Loss: 1.674118
[2022-03-29 03:04:04 | train] - Train Epoch: [15] [1011200/1281167 (79%)]	Loss: 1.914645
[2022-03-29 03:04:33 | train] - Train Epoch: [15] [1024000/1281167 (80%)]	Loss: 2.042488
[2022-03-29 03:05:02 | train] - Train Epoch: [15] [1036800/1281167 (81%)]	Loss: 1.607499
[2022-03-29 03:05:31 | train] - Train Epoch: [15] [1049600/1281167 (82%)]	Loss: 1.716321
[2022-03-29 03:06:00 | train] - Train Epoch: [15] [1062400/1281167 (83%)]	Loss: 1.824160
[2022-03-29 03:06:29 | train] - Train Epoch: [15] [1075200/1281167 (84%)]	Loss: 2.087536
[2022-03-29 03:06:59 | train] - Train Epoch: [15] [1088000/1281167 (85%)]	Loss: 1.667952
[2022-03-29 03:07:29 | train] - Train Epoch: [15] [1100800/1281167 (86%)]	Loss: 1.653902
[2022-03-29 03:07:58 | train] - Train Epoch: [15] [1113600/1281167 (87%)]	Loss: 1.611407
[2022-03-29 03:08:27 | train] - Train Epoch: [15] [1126400/1281167 (88%)]	Loss: 2.069837
[2022-03-29 03:08:57 | train] - Train Epoch: [15] [1139200/1281167 (89%)]	Loss: 1.844533
[2022-03-29 03:09:26 | train] - Train Epoch: [15] [1152000/1281167 (90%)]	Loss: 1.641476
[2022-03-29 03:09:55 | train] - Train Epoch: [15] [1164800/1281167 (91%)]	Loss: 1.357505
[2022-03-29 03:10:25 | train] - Train Epoch: [15] [1177600/1281167 (92%)]	Loss: 1.944546
[2022-03-29 03:10:54 | train] - Train Epoch: [15] [1190400/1281167 (93%)]	Loss: 1.846559
[2022-03-29 03:11:23 | train] - Train Epoch: [15] [1203200/1281167 (94%)]	Loss: 1.811313
[2022-03-29 03:11:53 | train] - Train Epoch: [15] [1216000/1281167 (95%)]	Loss: 1.814898
[2022-03-29 03:12:22 | train] - Train Epoch: [15] [1228800/1281167 (96%)]	Loss: 2.116775
[2022-03-29 03:12:51 | train] - Train Epoch: [15] [1241600/1281167 (97%)]	Loss: 2.132433
[2022-03-29 03:13:21 | train] - Train Epoch: [15] [1254400/1281167 (98%)]	Loss: 2.041933
[2022-03-29 03:13:51 | train] - Train Epoch: [15] [1267200/1281167 (99%)]	Loss: 1.838066
[2022-03-29 03:14:20 | train] - Train Epoch: [15] [1280000/1281167 (100%)]	Loss: 1.884431
[2022-03-29 03:14:23 | train] - Train Epoch: [15]	 Average Loss: 1.887663	 Total Acc : 56.9198	 Total Top5 Acc : 79.1341
[2022-03-29 03:14:25 | train] - -------15 epoch end-----------
========================================
-------15 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 03:16:26 | train] - 
Epoch [15] Test set: Average loss: 1.6722, Accuracy: 30316/50000 (60.5942%), Top-5 Accuracy: 83.2345%

[2022-03-29 03:16:26 | train] - save intermediate epoch [15] result


[2022-03-29 03:16:28 | train] - logging best performance 15 epoch
[2022-03-29 03:16:30 | train] - -------16 epoch start-----------
========================================
----- test end -------------------------


logging best performance 15 epoch
[2022-03-29 03:16:32 | train] - Train Epoch: [16] [0/1281167 (0%)]	Loss: 1.723228
[2022-03-29 03:17:00 | train] - Train Epoch: [16] [12800/1281167 (1%)]	Loss: 1.751895
[2022-03-29 03:17:28 | train] - Train Epoch: [16] [25600/1281167 (2%)]	Loss: 1.911578
[2022-03-29 03:17:56 | train] - Train Epoch: [16] [38400/1281167 (3%)]	Loss: 1.923402
[2022-03-29 03:18:23 | train] - Train Epoch: [16] [51200/1281167 (4%)]	Loss: 2.005628
[2022-03-29 03:18:51 | train] - Train Epoch: [16] [64000/1281167 (5%)]	Loss: 1.800585
[2022-03-29 03:19:18 | train] - Train Epoch: [16] [76800/1281167 (6%)]	Loss: 1.916722
[2022-03-29 03:19:46 | train] - Train Epoch: [16] [89600/1281167 (7%)]	Loss: 2.157738
[2022-03-29 03:20:13 | train] - Train Epoch: [16] [102400/1281167 (8%)]	Loss: 1.842161
[2022-03-29 03:20:41 | train] - Train Epoch: [16] [115200/1281167 (9%)]	Loss: 2.258334
[2022-03-29 03:21:08 | train] - Train Epoch: [16] [128000/1281167 (10%)]	Loss: 1.885428
[2022-03-29 03:21:36 | train] - Train Epoch: [16] [140800/1281167 (11%)]	Loss: 2.079896
[2022-03-29 03:22:04 | train] - Train Epoch: [16] [153600/1281167 (12%)]	Loss: 2.192471
[2022-03-29 03:22:31 | train] - Train Epoch: [16] [166400/1281167 (13%)]	Loss: 2.080735
[2022-03-29 03:22:58 | train] - Train Epoch: [16] [179200/1281167 (14%)]	Loss: 1.698242
[2022-03-29 03:23:25 | train] - Train Epoch: [16] [192000/1281167 (15%)]	Loss: 1.706058
[2022-03-29 03:23:53 | train] - Train Epoch: [16] [204800/1281167 (16%)]	Loss: 1.860719
[2022-03-29 03:24:20 | train] - Train Epoch: [16] [217600/1281167 (17%)]	Loss: 1.826167
[2022-03-29 03:24:47 | train] - Train Epoch: [16] [230400/1281167 (18%)]	Loss: 1.595627
[2022-03-29 03:25:14 | train] - Train Epoch: [16] [243200/1281167 (19%)]	Loss: 1.744670
[2022-03-29 03:25:42 | train] - Train Epoch: [16] [256000/1281167 (20%)]	Loss: 2.171509
[2022-03-29 03:26:09 | train] - Train Epoch: [16] [268800/1281167 (21%)]	Loss: 1.730757
[2022-03-29 03:26:36 | train] - Train Epoch: [16] [281600/1281167 (22%)]	Loss: 1.572821
[2022-03-29 03:27:04 | train] - Train Epoch: [16] [294400/1281167 (23%)]	Loss: 1.825315
[2022-03-29 03:27:32 | train] - Train Epoch: [16] [307200/1281167 (24%)]	Loss: 1.619094
[2022-03-29 03:27:59 | train] - Train Epoch: [16] [320000/1281167 (25%)]	Loss: 1.629483
[2022-03-29 03:28:27 | train] - Train Epoch: [16] [332800/1281167 (26%)]	Loss: 2.198293
[2022-03-29 03:28:55 | train] - Train Epoch: [16] [345600/1281167 (27%)]	Loss: 1.419156
[2022-03-29 03:29:22 | train] - Train Epoch: [16] [358400/1281167 (28%)]	Loss: 1.978766
[2022-03-29 03:29:48 | train] - Train Epoch: [16] [371200/1281167 (29%)]	Loss: 1.884259
[2022-03-29 03:30:16 | train] - Train Epoch: [16] [384000/1281167 (30%)]	Loss: 2.048597
[2022-03-29 03:30:44 | train] - Train Epoch: [16] [396800/1281167 (31%)]	Loss: 2.324451
[2022-03-29 03:31:11 | train] - Train Epoch: [16] [409600/1281167 (32%)]	Loss: 2.016349
[2022-03-29 03:31:39 | train] - Train Epoch: [16] [422400/1281167 (33%)]	Loss: 1.931368
[2022-03-29 03:32:06 | train] - Train Epoch: [16] [435200/1281167 (34%)]	Loss: 1.586317
[2022-03-29 03:32:33 | train] - Train Epoch: [16] [448000/1281167 (35%)]	Loss: 1.710589
[2022-03-29 03:33:01 | train] - Train Epoch: [16] [460800/1281167 (36%)]	Loss: 1.819921
[2022-03-29 03:33:28 | train] - Train Epoch: [16] [473600/1281167 (37%)]	Loss: 1.764577
[2022-03-29 03:33:56 | train] - Train Epoch: [16] [486400/1281167 (38%)]	Loss: 2.024259
[2022-03-29 03:34:23 | train] - Train Epoch: [16] [499200/1281167 (39%)]	Loss: 2.242710
[2022-03-29 03:34:50 | train] - Train Epoch: [16] [512000/1281167 (40%)]	Loss: 2.151659
[2022-03-29 03:35:18 | train] - Train Epoch: [16] [524800/1281167 (41%)]	Loss: 1.299145
[2022-03-29 03:35:45 | train] - Train Epoch: [16] [537600/1281167 (42%)]	Loss: 1.697203
[2022-03-29 03:36:13 | train] - Train Epoch: [16] [550400/1281167 (43%)]	Loss: 1.964098
[2022-03-29 03:36:42 | train] - Train Epoch: [16] [563200/1281167 (44%)]	Loss: 1.510647
[2022-03-29 03:37:09 | train] - Train Epoch: [16] [576000/1281167 (45%)]	Loss: 2.081765
[2022-03-29 03:37:36 | train] - Train Epoch: [16] [588800/1281167 (46%)]	Loss: 1.868454
[2022-03-29 03:38:03 | train] - Train Epoch: [16] [601600/1281167 (47%)]	Loss: 1.737095
[2022-03-29 03:38:31 | train] - Train Epoch: [16] [614400/1281167 (48%)]	Loss: 1.905312
[2022-03-29 03:38:58 | train] - Train Epoch: [16] [627200/1281167 (49%)]	Loss: 1.584937
[2022-03-29 03:39:26 | train] - Train Epoch: [16] [640000/1281167 (50%)]	Loss: 1.878854
[2022-03-29 03:39:53 | train] - Train Epoch: [16] [652800/1281167 (51%)]	Loss: 1.826047
[2022-03-29 03:40:21 | train] - Train Epoch: [16] [665600/1281167 (52%)]	Loss: 1.591151
[2022-03-29 03:40:48 | train] - Train Epoch: [16] [678400/1281167 (53%)]	Loss: 1.905161
[2022-03-29 03:41:16 | train] - Train Epoch: [16] [691200/1281167 (54%)]	Loss: 1.888063
[2022-03-29 03:41:43 | train] - Train Epoch: [16] [704000/1281167 (55%)]	Loss: 2.000944
[2022-03-29 03:42:11 | train] - Train Epoch: [16] [716800/1281167 (56%)]	Loss: 1.921314
[2022-03-29 03:42:38 | train] - Train Epoch: [16] [729600/1281167 (57%)]	Loss: 1.899750
[2022-03-29 03:43:06 | train] - Train Epoch: [16] [742400/1281167 (58%)]	Loss: 1.889936
[2022-03-29 03:43:34 | train] - Train Epoch: [16] [755200/1281167 (59%)]	Loss: 1.887510
[2022-03-29 03:44:01 | train] - Train Epoch: [16] [768000/1281167 (60%)]	Loss: 1.788360
[2022-03-29 03:44:29 | train] - Train Epoch: [16] [780800/1281167 (61%)]	Loss: 1.583433
[2022-03-29 03:44:57 | train] - Train Epoch: [16] [793600/1281167 (62%)]	Loss: 2.053928
[2022-03-29 03:45:24 | train] - Train Epoch: [16] [806400/1281167 (63%)]	Loss: 1.797205
[2022-03-29 03:45:52 | train] - Train Epoch: [16] [819200/1281167 (64%)]	Loss: 1.771509
[2022-03-29 03:46:20 | train] - Train Epoch: [16] [832000/1281167 (65%)]	Loss: 1.818270
[2022-03-29 03:46:48 | train] - Train Epoch: [16] [844800/1281167 (66%)]	Loss: 1.864000
[2022-03-29 03:47:15 | train] - Train Epoch: [16] [857600/1281167 (67%)]	Loss: 1.702041
[2022-03-29 03:47:43 | train] - Train Epoch: [16] [870400/1281167 (68%)]	Loss: 1.631335
[2022-03-29 03:48:10 | train] - Train Epoch: [16] [883200/1281167 (69%)]	Loss: 1.960333
[2022-03-29 03:48:38 | train] - Train Epoch: [16] [896000/1281167 (70%)]	Loss: 1.662704
[2022-03-29 03:49:05 | train] - Train Epoch: [16] [908800/1281167 (71%)]	Loss: 1.904970
[2022-03-29 03:49:33 | train] - Train Epoch: [16] [921600/1281167 (72%)]	Loss: 1.890108
[2022-03-29 03:50:01 | train] - Train Epoch: [16] [934400/1281167 (73%)]	Loss: 1.708591
[2022-03-29 03:50:28 | train] - Train Epoch: [16] [947200/1281167 (74%)]	Loss: 1.911209
[2022-03-29 03:50:57 | train] - Train Epoch: [16] [960000/1281167 (75%)]	Loss: 1.764355
[2022-03-29 03:51:24 | train] - Train Epoch: [16] [972800/1281167 (76%)]	Loss: 1.599140
[2022-03-29 03:51:51 | train] - Train Epoch: [16] [985600/1281167 (77%)]	Loss: 1.544675
[2022-03-29 03:52:18 | train] - Train Epoch: [16] [998400/1281167 (78%)]	Loss: 1.896399
[2022-03-29 03:52:47 | train] - Train Epoch: [16] [1011200/1281167 (79%)]	Loss: 1.705504
[2022-03-29 03:53:14 | train] - Train Epoch: [16] [1024000/1281167 (80%)]	Loss: 1.672255
[2022-03-29 03:53:41 | train] - Train Epoch: [16] [1036800/1281167 (81%)]	Loss: 2.024127
[2022-03-29 03:54:08 | train] - Train Epoch: [16] [1049600/1281167 (82%)]	Loss: 1.918282
[2022-03-29 03:54:36 | train] - Train Epoch: [16] [1062400/1281167 (83%)]	Loss: 1.558927
[2022-03-29 03:55:04 | train] - Train Epoch: [16] [1075200/1281167 (84%)]	Loss: 1.687844
[2022-03-29 03:55:31 | train] - Train Epoch: [16] [1088000/1281167 (85%)]	Loss: 1.892486
[2022-03-29 03:55:59 | train] - Train Epoch: [16] [1100800/1281167 (86%)]	Loss: 1.624334
[2022-03-29 03:56:27 | train] - Train Epoch: [16] [1113600/1281167 (87%)]	Loss: 1.673166
[2022-03-29 03:56:55 | train] - Train Epoch: [16] [1126400/1281167 (88%)]	Loss: 1.963408
[2022-03-29 03:57:22 | train] - Train Epoch: [16] [1139200/1281167 (89%)]	Loss: 1.884923
[2022-03-29 03:57:50 | train] - Train Epoch: [16] [1152000/1281167 (90%)]	Loss: 1.709587
[2022-03-29 03:58:17 | train] - Train Epoch: [16] [1164800/1281167 (91%)]	Loss: 1.927688
[2022-03-29 03:58:45 | train] - Train Epoch: [16] [1177600/1281167 (92%)]	Loss: 1.905702
[2022-03-29 03:59:12 | train] - Train Epoch: [16] [1190400/1281167 (93%)]	Loss: 1.544651
[2022-03-29 03:59:40 | train] - Train Epoch: [16] [1203200/1281167 (94%)]	Loss: 1.956825
[2022-03-29 04:00:07 | train] - Train Epoch: [16] [1216000/1281167 (95%)]	Loss: 1.940413
[2022-03-29 04:00:34 | train] - Train Epoch: [16] [1228800/1281167 (96%)]	Loss: 2.138392
[2022-03-29 04:01:02 | train] - Train Epoch: [16] [1241600/1281167 (97%)]	Loss: 2.094452
[2022-03-29 04:01:29 | train] - Train Epoch: [16] [1254400/1281167 (98%)]	Loss: 1.750069
[2022-03-29 04:01:57 | train] - Train Epoch: [16] [1267200/1281167 (99%)]	Loss: 1.908773
[2022-03-29 04:02:24 | train] - Train Epoch: [16] [1280000/1281167 (100%)]	Loss: 1.617780
[2022-03-29 04:02:27 | train] - Train Epoch: [16]	 Average Loss: 1.837820	 Total Acc : 57.9035	 Total Top5 Acc : 79.8354
[2022-03-29 04:02:29 | train] - -------16 epoch end-----------
========================================
-------16 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 04:04:24 | train] - 
Epoch [16] Test set: Average loss: 1.6470, Accuracy: 30312/50000 (60.5862%), Top-5 Accuracy: 83.4175%

[2022-03-29 04:04:24 | train] - save intermediate epoch [16] result


[2022-03-29 04:04:28 | train] - -------17 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 04:04:30 | train] - Train Epoch: [17] [0/1281167 (0%)]	Loss: 1.979004
[2022-03-29 04:04:57 | train] - Train Epoch: [17] [12800/1281167 (1%)]	Loss: 1.653870
[2022-03-29 04:05:23 | train] - Train Epoch: [17] [25600/1281167 (2%)]	Loss: 1.404812
[2022-03-29 04:05:49 | train] - Train Epoch: [17] [38400/1281167 (3%)]	Loss: 1.934886
[2022-03-29 04:06:15 | train] - Train Epoch: [17] [51200/1281167 (4%)]	Loss: 1.855016
[2022-03-29 04:06:41 | train] - Train Epoch: [17] [64000/1281167 (5%)]	Loss: 1.811552
[2022-03-29 04:07:07 | train] - Train Epoch: [17] [76800/1281167 (6%)]	Loss: 1.693842
[2022-03-29 04:07:33 | train] - Train Epoch: [17] [89600/1281167 (7%)]	Loss: 1.532961
[2022-03-29 04:07:58 | train] - Train Epoch: [17] [102400/1281167 (8%)]	Loss: 1.728639
[2022-03-29 04:08:24 | train] - Train Epoch: [17] [115200/1281167 (9%)]	Loss: 1.514501
[2022-03-29 04:08:51 | train] - Train Epoch: [17] [128000/1281167 (10%)]	Loss: 1.812082
[2022-03-29 04:09:17 | train] - Train Epoch: [17] [140800/1281167 (11%)]	Loss: 1.681161
[2022-03-29 04:09:43 | train] - Train Epoch: [17] [153600/1281167 (12%)]	Loss: 1.556880
[2022-03-29 04:10:08 | train] - Train Epoch: [17] [166400/1281167 (13%)]	Loss: 2.031852
[2022-03-29 04:10:35 | train] - Train Epoch: [17] [179200/1281167 (14%)]	Loss: 1.388625
[2022-03-29 04:11:01 | train] - Train Epoch: [17] [192000/1281167 (15%)]	Loss: 2.047062
[2022-03-29 04:11:27 | train] - Train Epoch: [17] [204800/1281167 (16%)]	Loss: 1.688307
[2022-03-29 04:11:53 | train] - Train Epoch: [17] [217600/1281167 (17%)]	Loss: 1.873161
[2022-03-29 04:12:18 | train] - Train Epoch: [17] [230400/1281167 (18%)]	Loss: 1.831629
[2022-03-29 04:12:45 | train] - Train Epoch: [17] [243200/1281167 (19%)]	Loss: 1.697409
[2022-03-29 04:13:11 | train] - Train Epoch: [17] [256000/1281167 (20%)]	Loss: 1.666968
[2022-03-29 04:13:37 | train] - Train Epoch: [17] [268800/1281167 (21%)]	Loss: 1.964522
[2022-03-29 04:14:03 | train] - Train Epoch: [17] [281600/1281167 (22%)]	Loss: 1.999041
[2022-03-29 04:14:29 | train] - Train Epoch: [17] [294400/1281167 (23%)]	Loss: 1.596189
[2022-03-29 04:14:55 | train] - Train Epoch: [17] [307200/1281167 (24%)]	Loss: 1.993139
[2022-03-29 04:15:21 | train] - Train Epoch: [17] [320000/1281167 (25%)]	Loss: 1.914916
[2022-03-29 04:15:47 | train] - Train Epoch: [17] [332800/1281167 (26%)]	Loss: 1.950222
[2022-03-29 04:16:13 | train] - Train Epoch: [17] [345600/1281167 (27%)]	Loss: 1.863659
[2022-03-29 04:16:39 | train] - Train Epoch: [17] [358400/1281167 (28%)]	Loss: 1.749392
[2022-03-29 04:17:04 | train] - Train Epoch: [17] [371200/1281167 (29%)]	Loss: 1.956114
[2022-03-29 04:17:31 | train] - Train Epoch: [17] [384000/1281167 (30%)]	Loss: 1.491249
[2022-03-29 04:17:57 | train] - Train Epoch: [17] [396800/1281167 (31%)]	Loss: 1.642209
[2022-03-29 04:18:23 | train] - Train Epoch: [17] [409600/1281167 (32%)]	Loss: 1.581923
[2022-03-29 04:18:49 | train] - Train Epoch: [17] [422400/1281167 (33%)]	Loss: 1.636411
[2022-03-29 04:19:15 | train] - Train Epoch: [17] [435200/1281167 (34%)]	Loss: 2.171954
[2022-03-29 04:19:41 | train] - Train Epoch: [17] [448000/1281167 (35%)]	Loss: 2.048059
[2022-03-29 04:20:07 | train] - Train Epoch: [17] [460800/1281167 (36%)]	Loss: 1.883723
[2022-03-29 04:20:33 | train] - Train Epoch: [17] [473600/1281167 (37%)]	Loss: 1.667904
[2022-03-29 04:20:59 | train] - Train Epoch: [17] [486400/1281167 (38%)]	Loss: 1.628802
[2022-03-29 04:21:24 | train] - Train Epoch: [17] [499200/1281167 (39%)]	Loss: 1.813832
[2022-03-29 04:21:50 | train] - Train Epoch: [17] [512000/1281167 (40%)]	Loss: 2.220041
[2022-03-29 04:22:16 | train] - Train Epoch: [17] [524800/1281167 (41%)]	Loss: 1.593035
[2022-03-29 04:22:42 | train] - Train Epoch: [17] [537600/1281167 (42%)]	Loss: 1.558862
[2022-03-29 04:23:08 | train] - Train Epoch: [17] [550400/1281167 (43%)]	Loss: 2.096128
[2022-03-29 04:23:33 | train] - Train Epoch: [17] [563200/1281167 (44%)]	Loss: 1.892593
[2022-03-29 04:23:59 | train] - Train Epoch: [17] [576000/1281167 (45%)]	Loss: 1.756479
[2022-03-29 04:24:25 | train] - Train Epoch: [17] [588800/1281167 (46%)]	Loss: 1.489208
[2022-03-29 04:24:51 | train] - Train Epoch: [17] [601600/1281167 (47%)]	Loss: 1.818915
[2022-03-29 04:25:17 | train] - Train Epoch: [17] [614400/1281167 (48%)]	Loss: 2.075168
[2022-03-29 04:25:43 | train] - Train Epoch: [17] [627200/1281167 (49%)]	Loss: 1.822975
[2022-03-29 04:26:08 | train] - Train Epoch: [17] [640000/1281167 (50%)]	Loss: 1.802240
[2022-03-29 04:26:35 | train] - Train Epoch: [17] [652800/1281167 (51%)]	Loss: 2.237498
[2022-03-29 04:27:01 | train] - Train Epoch: [17] [665600/1281167 (52%)]	Loss: 1.690599
[2022-03-29 04:27:26 | train] - Train Epoch: [17] [678400/1281167 (53%)]	Loss: 1.527878
[2022-03-29 04:27:52 | train] - Train Epoch: [17] [691200/1281167 (54%)]	Loss: 2.048765
[2022-03-29 04:28:18 | train] - Train Epoch: [17] [704000/1281167 (55%)]	Loss: 1.410225
[2022-03-29 04:28:44 | train] - Train Epoch: [17] [716800/1281167 (56%)]	Loss: 1.626898
[2022-03-29 04:29:10 | train] - Train Epoch: [17] [729600/1281167 (57%)]	Loss: 1.809141
[2022-03-29 04:29:35 | train] - Train Epoch: [17] [742400/1281167 (58%)]	Loss: 1.701232
[2022-03-29 04:30:01 | train] - Train Epoch: [17] [755200/1281167 (59%)]	Loss: 1.854778
[2022-03-29 04:30:27 | train] - Train Epoch: [17] [768000/1281167 (60%)]	Loss: 1.882567
[2022-03-29 04:30:53 | train] - Train Epoch: [17] [780800/1281167 (61%)]	Loss: 1.689832
[2022-03-29 04:31:19 | train] - Train Epoch: [17] [793600/1281167 (62%)]	Loss: 1.583983
[2022-03-29 04:31:44 | train] - Train Epoch: [17] [806400/1281167 (63%)]	Loss: 1.643480
[2022-03-29 04:32:10 | train] - Train Epoch: [17] [819200/1281167 (64%)]	Loss: 2.115163
[2022-03-29 04:32:36 | train] - Train Epoch: [17] [832000/1281167 (65%)]	Loss: 1.832677
[2022-03-29 04:33:02 | train] - Train Epoch: [17] [844800/1281167 (66%)]	Loss: 2.013052
[2022-03-29 04:33:28 | train] - Train Epoch: [17] [857600/1281167 (67%)]	Loss: 1.708160
[2022-03-29 04:33:53 | train] - Train Epoch: [17] [870400/1281167 (68%)]	Loss: 1.398171
[2022-03-29 04:34:20 | train] - Train Epoch: [17] [883200/1281167 (69%)]	Loss: 1.854272
[2022-03-29 04:34:46 | train] - Train Epoch: [17] [896000/1281167 (70%)]	Loss: 1.799575
[2022-03-29 04:35:11 | train] - Train Epoch: [17] [908800/1281167 (71%)]	Loss: 1.870786
[2022-03-29 04:35:37 | train] - Train Epoch: [17] [921600/1281167 (72%)]	Loss: 1.758301
[2022-03-29 04:36:03 | train] - Train Epoch: [17] [934400/1281167 (73%)]	Loss: 1.678831
[2022-03-29 04:36:29 | train] - Train Epoch: [17] [947200/1281167 (74%)]	Loss: 1.912463
[2022-03-29 04:36:55 | train] - Train Epoch: [17] [960000/1281167 (75%)]	Loss: 1.825677
[2022-03-29 04:37:21 | train] - Train Epoch: [17] [972800/1281167 (76%)]	Loss: 1.917392
[2022-03-29 04:37:47 | train] - Train Epoch: [17] [985600/1281167 (77%)]	Loss: 1.841700
[2022-03-29 04:38:13 | train] - Train Epoch: [17] [998400/1281167 (78%)]	Loss: 1.452494
[2022-03-29 04:38:39 | train] - Train Epoch: [17] [1011200/1281167 (79%)]	Loss: 1.894901
[2022-03-29 04:39:05 | train] - Train Epoch: [17] [1024000/1281167 (80%)]	Loss: 1.632430
[2022-03-29 04:39:30 | train] - Train Epoch: [17] [1036800/1281167 (81%)]	Loss: 1.616987
[2022-03-29 04:39:56 | train] - Train Epoch: [17] [1049600/1281167 (82%)]	Loss: 1.656258
[2022-03-29 04:40:22 | train] - Train Epoch: [17] [1062400/1281167 (83%)]	Loss: 1.906155
[2022-03-29 04:40:48 | train] - Train Epoch: [17] [1075200/1281167 (84%)]	Loss: 1.850391
[2022-03-29 04:41:14 | train] - Train Epoch: [17] [1088000/1281167 (85%)]	Loss: 1.959718
[2022-03-29 04:41:39 | train] - Train Epoch: [17] [1100800/1281167 (86%)]	Loss: 2.130411
[2022-03-29 04:42:05 | train] - Train Epoch: [17] [1113600/1281167 (87%)]	Loss: 1.924622
[2022-03-29 04:42:32 | train] - Train Epoch: [17] [1126400/1281167 (88%)]	Loss: 1.589754
[2022-03-29 04:42:57 | train] - Train Epoch: [17] [1139200/1281167 (89%)]	Loss: 1.755512
[2022-03-29 04:43:23 | train] - Train Epoch: [17] [1152000/1281167 (90%)]	Loss: 1.890327
[2022-03-29 04:43:50 | train] - Train Epoch: [17] [1164800/1281167 (91%)]	Loss: 1.543956
[2022-03-29 04:44:15 | train] - Train Epoch: [17] [1177600/1281167 (92%)]	Loss: 1.555257
[2022-03-29 04:44:41 | train] - Train Epoch: [17] [1190400/1281167 (93%)]	Loss: 1.719238
[2022-03-29 04:45:07 | train] - Train Epoch: [17] [1203200/1281167 (94%)]	Loss: 1.668822
[2022-03-29 04:45:34 | train] - Train Epoch: [17] [1216000/1281167 (95%)]	Loss: 1.603654
[2022-03-29 04:46:00 | train] - Train Epoch: [17] [1228800/1281167 (96%)]	Loss: 2.003298
[2022-03-29 04:46:25 | train] - Train Epoch: [17] [1241600/1281167 (97%)]	Loss: 2.195616
[2022-03-29 04:46:51 | train] - Train Epoch: [17] [1254400/1281167 (98%)]	Loss: 1.629126
[2022-03-29 04:47:17 | train] - Train Epoch: [17] [1267200/1281167 (99%)]	Loss: 1.901519
[2022-03-29 04:47:43 | train] - Train Epoch: [17] [1280000/1281167 (100%)]	Loss: 1.675407
[2022-03-29 04:47:45 | train] - Train Epoch: [17]	 Average Loss: 1.795033	 Total Acc : 58.8092	 Total Top5 Acc : 80.4635
[2022-03-29 04:47:47 | train] - -------17 epoch end-----------
========================================
-------17 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 04:49:41 | train] - 
Epoch [17] Test set: Average loss: 1.6205, Accuracy: 30726/50000 (61.4182%), Top-5 Accuracy: 83.9166%

[2022-03-29 04:49:41 | train] - save intermediate epoch [17] result


[2022-03-29 04:49:44 | train] - logging best performance 17 epoch
[2022-03-29 04:49:45 | train] - -------18 epoch start-----------
========================================
----- test end -------------------------


logging best performance 17 epoch
[2022-03-29 04:49:47 | train] - Train Epoch: [18] [0/1281167 (0%)]	Loss: 1.712905
[2022-03-29 04:50:13 | train] - Train Epoch: [18] [12800/1281167 (1%)]	Loss: 1.888643
[2022-03-29 04:50:38 | train] - Train Epoch: [18] [25600/1281167 (2%)]	Loss: 1.949273
[2022-03-29 04:51:04 | train] - Train Epoch: [18] [38400/1281167 (3%)]	Loss: 1.739927
[2022-03-29 04:51:29 | train] - Train Epoch: [18] [51200/1281167 (4%)]	Loss: 1.809546
[2022-03-29 04:51:54 | train] - Train Epoch: [18] [64000/1281167 (5%)]	Loss: 1.774846
[2022-03-29 04:52:19 | train] - Train Epoch: [18] [76800/1281167 (6%)]	Loss: 1.588581
[2022-03-29 04:52:44 | train] - Train Epoch: [18] [89600/1281167 (7%)]	Loss: 1.717080
[2022-03-29 04:53:09 | train] - Train Epoch: [18] [102400/1281167 (8%)]	Loss: 1.517315
[2022-03-29 04:53:35 | train] - Train Epoch: [18] [115200/1281167 (9%)]	Loss: 1.793097
[2022-03-29 04:54:00 | train] - Train Epoch: [18] [128000/1281167 (10%)]	Loss: 2.006957
[2022-03-29 04:54:25 | train] - Train Epoch: [18] [140800/1281167 (11%)]	Loss: 1.923747
[2022-03-29 04:54:50 | train] - Train Epoch: [18] [153600/1281167 (12%)]	Loss: 1.685029
[2022-03-29 04:55:15 | train] - Train Epoch: [18] [166400/1281167 (13%)]	Loss: 1.882589
[2022-03-29 04:55:40 | train] - Train Epoch: [18] [179200/1281167 (14%)]	Loss: 1.699108
[2022-03-29 04:56:05 | train] - Train Epoch: [18] [192000/1281167 (15%)]	Loss: 1.721040
[2022-03-29 04:56:30 | train] - Train Epoch: [18] [204800/1281167 (16%)]	Loss: 1.950139
[2022-03-29 04:56:56 | train] - Train Epoch: [18] [217600/1281167 (17%)]	Loss: 1.838152
[2022-03-29 04:57:21 | train] - Train Epoch: [18] [230400/1281167 (18%)]	Loss: 1.859378
[2022-03-29 04:57:47 | train] - Train Epoch: [18] [243200/1281167 (19%)]	Loss: 1.559833
[2022-03-29 04:58:12 | train] - Train Epoch: [18] [256000/1281167 (20%)]	Loss: 1.686751
[2022-03-29 04:58:37 | train] - Train Epoch: [18] [268800/1281167 (21%)]	Loss: 1.487550
[2022-03-29 04:59:02 | train] - Train Epoch: [18] [281600/1281167 (22%)]	Loss: 1.836908
[2022-03-29 04:59:28 | train] - Train Epoch: [18] [294400/1281167 (23%)]	Loss: 2.001133
[2022-03-29 04:59:53 | train] - Train Epoch: [18] [307200/1281167 (24%)]	Loss: 1.832005
[2022-03-29 05:00:19 | train] - Train Epoch: [18] [320000/1281167 (25%)]	Loss: 1.189760
[2022-03-29 05:00:43 | train] - Train Epoch: [18] [332800/1281167 (26%)]	Loss: 2.081138
[2022-03-29 05:01:09 | train] - Train Epoch: [18] [345600/1281167 (27%)]	Loss: 1.791260
[2022-03-29 05:01:34 | train] - Train Epoch: [18] [358400/1281167 (28%)]	Loss: 1.863857
[2022-03-29 05:01:59 | train] - Train Epoch: [18] [371200/1281167 (29%)]	Loss: 2.095318
[2022-03-29 05:02:25 | train] - Train Epoch: [18] [384000/1281167 (30%)]	Loss: 1.741745
[2022-03-29 05:02:50 | train] - Train Epoch: [18] [396800/1281167 (31%)]	Loss: 1.965054
[2022-03-29 05:03:15 | train] - Train Epoch: [18] [409600/1281167 (32%)]	Loss: 2.261329
[2022-03-29 05:03:41 | train] - Train Epoch: [18] [422400/1281167 (33%)]	Loss: 1.667161
[2022-03-29 05:04:06 | train] - Train Epoch: [18] [435200/1281167 (34%)]	Loss: 1.698560
[2022-03-29 05:04:30 | train] - Train Epoch: [18] [448000/1281167 (35%)]	Loss: 1.802602
[2022-03-29 05:04:56 | train] - Train Epoch: [18] [460800/1281167 (36%)]	Loss: 1.924829
[2022-03-29 05:05:21 | train] - Train Epoch: [18] [473600/1281167 (37%)]	Loss: 1.667113
[2022-03-29 05:05:47 | train] - Train Epoch: [18] [486400/1281167 (38%)]	Loss: 1.677439
[2022-03-29 05:06:13 | train] - Train Epoch: [18] [499200/1281167 (39%)]	Loss: 1.742801
[2022-03-29 05:06:38 | train] - Train Epoch: [18] [512000/1281167 (40%)]	Loss: 1.617539
[2022-03-29 05:07:03 | train] - Train Epoch: [18] [524800/1281167 (41%)]	Loss: 1.545690
[2022-03-29 05:07:28 | train] - Train Epoch: [18] [537600/1281167 (42%)]	Loss: 1.830745
[2022-03-29 05:07:53 | train] - Train Epoch: [18] [550400/1281167 (43%)]	Loss: 1.798130
[2022-03-29 05:08:19 | train] - Train Epoch: [18] [563200/1281167 (44%)]	Loss: 1.932214
[2022-03-29 05:08:44 | train] - Train Epoch: [18] [576000/1281167 (45%)]	Loss: 1.729932
[2022-03-29 05:09:09 | train] - Train Epoch: [18] [588800/1281167 (46%)]	Loss: 1.845232
[2022-03-29 05:09:34 | train] - Train Epoch: [18] [601600/1281167 (47%)]	Loss: 1.568290
[2022-03-29 05:09:59 | train] - Train Epoch: [18] [614400/1281167 (48%)]	Loss: 2.016977
[2022-03-29 05:10:25 | train] - Train Epoch: [18] [627200/1281167 (49%)]	Loss: 1.605012
[2022-03-29 05:10:50 | train] - Train Epoch: [18] [640000/1281167 (50%)]	Loss: 1.680782
[2022-03-29 05:11:15 | train] - Train Epoch: [18] [652800/1281167 (51%)]	Loss: 2.280745
[2022-03-29 05:11:40 | train] - Train Epoch: [18] [665600/1281167 (52%)]	Loss: 1.699145
[2022-03-29 05:12:05 | train] - Train Epoch: [18] [678400/1281167 (53%)]	Loss: 1.893273
[2022-03-29 05:12:30 | train] - Train Epoch: [18] [691200/1281167 (54%)]	Loss: 1.343208
[2022-03-29 05:12:55 | train] - Train Epoch: [18] [704000/1281167 (55%)]	Loss: 2.003660
[2022-03-29 05:13:21 | train] - Train Epoch: [18] [716800/1281167 (56%)]	Loss: 1.750395
[2022-03-29 05:13:46 | train] - Train Epoch: [18] [729600/1281167 (57%)]	Loss: 1.575494
[2022-03-29 05:14:11 | train] - Train Epoch: [18] [742400/1281167 (58%)]	Loss: 1.658177
[2022-03-29 05:14:36 | train] - Train Epoch: [18] [755200/1281167 (59%)]	Loss: 1.631765
[2022-03-29 05:15:01 | train] - Train Epoch: [18] [768000/1281167 (60%)]	Loss: 1.554636
[2022-03-29 05:15:27 | train] - Train Epoch: [18] [780800/1281167 (61%)]	Loss: 1.679789
[2022-03-29 05:15:51 | train] - Train Epoch: [18] [793600/1281167 (62%)]	Loss: 1.788557
[2022-03-29 05:16:17 | train] - Train Epoch: [18] [806400/1281167 (63%)]	Loss: 1.703608
[2022-03-29 05:16:42 | train] - Train Epoch: [18] [819200/1281167 (64%)]	Loss: 1.573251
[2022-03-29 05:17:07 | train] - Train Epoch: [18] [832000/1281167 (65%)]	Loss: 2.026862
[2022-03-29 05:17:33 | train] - Train Epoch: [18] [844800/1281167 (66%)]	Loss: 1.548197
[2022-03-29 05:17:59 | train] - Train Epoch: [18] [857600/1281167 (67%)]	Loss: 1.721472
[2022-03-29 05:18:23 | train] - Train Epoch: [18] [870400/1281167 (68%)]	Loss: 1.843666
[2022-03-29 05:18:49 | train] - Train Epoch: [18] [883200/1281167 (69%)]	Loss: 1.605685
[2022-03-29 05:19:14 | train] - Train Epoch: [18] [896000/1281167 (70%)]	Loss: 1.492669
[2022-03-29 05:19:39 | train] - Train Epoch: [18] [908800/1281167 (71%)]	Loss: 1.948263
[2022-03-29 05:20:04 | train] - Train Epoch: [18] [921600/1281167 (72%)]	Loss: 1.975467
[2022-03-29 05:20:29 | train] - Train Epoch: [18] [934400/1281167 (73%)]	Loss: 1.635102
[2022-03-29 05:20:54 | train] - Train Epoch: [18] [947200/1281167 (74%)]	Loss: 1.901528
[2022-03-29 05:21:20 | train] - Train Epoch: [18] [960000/1281167 (75%)]	Loss: 1.916923
[2022-03-29 05:21:45 | train] - Train Epoch: [18] [972800/1281167 (76%)]	Loss: 1.913586
[2022-03-29 05:22:10 | train] - Train Epoch: [18] [985600/1281167 (77%)]	Loss: 1.746575
[2022-03-29 05:22:36 | train] - Train Epoch: [18] [998400/1281167 (78%)]	Loss: 1.734335
[2022-03-29 05:23:01 | train] - Train Epoch: [18] [1011200/1281167 (79%)]	Loss: 1.905191
[2022-03-29 05:23:26 | train] - Train Epoch: [18] [1024000/1281167 (80%)]	Loss: 1.703170
[2022-03-29 05:23:51 | train] - Train Epoch: [18] [1036800/1281167 (81%)]	Loss: 2.182088
[2022-03-29 05:24:16 | train] - Train Epoch: [18] [1049600/1281167 (82%)]	Loss: 2.017694
[2022-03-29 05:24:41 | train] - Train Epoch: [18] [1062400/1281167 (83%)]	Loss: 1.917928
[2022-03-29 05:25:06 | train] - Train Epoch: [18] [1075200/1281167 (84%)]	Loss: 2.059564
[2022-03-29 05:25:32 | train] - Train Epoch: [18] [1088000/1281167 (85%)]	Loss: 1.801742
[2022-03-29 05:25:57 | train] - Train Epoch: [18] [1100800/1281167 (86%)]	Loss: 1.965784
[2022-03-29 05:26:22 | train] - Train Epoch: [18] [1113600/1281167 (87%)]	Loss: 1.767362
[2022-03-29 05:26:47 | train] - Train Epoch: [18] [1126400/1281167 (88%)]	Loss: 1.692178
[2022-03-29 05:27:13 | train] - Train Epoch: [18] [1139200/1281167 (89%)]	Loss: 1.929483
[2022-03-29 05:27:38 | train] - Train Epoch: [18] [1152000/1281167 (90%)]	Loss: 1.531700
[2022-03-29 05:28:03 | train] - Train Epoch: [18] [1164800/1281167 (91%)]	Loss: 1.659237
[2022-03-29 05:28:28 | train] - Train Epoch: [18] [1177600/1281167 (92%)]	Loss: 1.748183
[2022-03-29 05:28:53 | train] - Train Epoch: [18] [1190400/1281167 (93%)]	Loss: 1.845064
[2022-03-29 05:29:18 | train] - Train Epoch: [18] [1203200/1281167 (94%)]	Loss: 1.869235
[2022-03-29 05:29:44 | train] - Train Epoch: [18] [1216000/1281167 (95%)]	Loss: 1.677211
[2022-03-29 05:30:09 | train] - Train Epoch: [18] [1228800/1281167 (96%)]	Loss: 1.763477
[2022-03-29 05:30:35 | train] - Train Epoch: [18] [1241600/1281167 (97%)]	Loss: 1.818030
[2022-03-29 05:31:00 | train] - Train Epoch: [18] [1254400/1281167 (98%)]	Loss: 1.563837
[2022-03-29 05:31:26 | train] - Train Epoch: [18] [1267200/1281167 (99%)]	Loss: 1.781690
[2022-03-29 05:31:51 | train] - Train Epoch: [18] [1280000/1281167 (100%)]	Loss: 1.702826
[2022-03-29 05:31:54 | train] - Train Epoch: [18]	 Average Loss: 1.756640	 Total Acc : 59.5116	 Total Top5 Acc : 81.0575
[2022-03-29 05:31:56 | train] - -------18 epoch end-----------
========================================
-------18 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 05:33:46 | train] - 
Epoch [18] Test set: Average loss: 1.5930, Accuracy: 31151/50000 (62.2674%), Top-5 Accuracy: 84.3622%

[2022-03-29 05:33:46 | train] - save intermediate epoch [18] result


[2022-03-29 05:33:49 | train] - logging best performance 18 epoch
[2022-03-29 05:33:50 | train] - -------19 epoch start-----------
========================================
----- test end -------------------------


logging best performance 18 epoch
[2022-03-29 05:33:53 | train] - Train Epoch: [19] [0/1281167 (0%)]	Loss: 1.584299
[2022-03-29 05:34:18 | train] - Train Epoch: [19] [12800/1281167 (1%)]	Loss: 1.987473
[2022-03-29 05:34:42 | train] - Train Epoch: [19] [25600/1281167 (2%)]	Loss: 1.613599
[2022-03-29 05:35:06 | train] - Train Epoch: [19] [38400/1281167 (3%)]	Loss: 1.510525
[2022-03-29 05:35:30 | train] - Train Epoch: [19] [51200/1281167 (4%)]	Loss: 1.729240
[2022-03-29 05:35:55 | train] - Train Epoch: [19] [64000/1281167 (5%)]	Loss: 1.787177
[2022-03-29 05:36:19 | train] - Train Epoch: [19] [76800/1281167 (6%)]	Loss: 1.529733
[2022-03-29 05:36:43 | train] - Train Epoch: [19] [89600/1281167 (7%)]	Loss: 1.772227
[2022-03-29 05:37:08 | train] - Train Epoch: [19] [102400/1281167 (8%)]	Loss: 1.579553
[2022-03-29 05:37:32 | train] - Train Epoch: [19] [115200/1281167 (9%)]	Loss: 1.542487
[2022-03-29 05:37:57 | train] - Train Epoch: [19] [128000/1281167 (10%)]	Loss: 1.371945
[2022-03-29 05:38:21 | train] - Train Epoch: [19] [140800/1281167 (11%)]	Loss: 1.584861
[2022-03-29 05:38:45 | train] - Train Epoch: [19] [153600/1281167 (12%)]	Loss: 2.107211
[2022-03-29 05:39:10 | train] - Train Epoch: [19] [166400/1281167 (13%)]	Loss: 1.721867
[2022-03-29 05:39:35 | train] - Train Epoch: [19] [179200/1281167 (14%)]	Loss: 1.747563
[2022-03-29 05:39:59 | train] - Train Epoch: [19] [192000/1281167 (15%)]	Loss: 2.148423
[2022-03-29 05:40:24 | train] - Train Epoch: [19] [204800/1281167 (16%)]	Loss: 1.983054
[2022-03-29 05:40:49 | train] - Train Epoch: [19] [217600/1281167 (17%)]	Loss: 1.924199
[2022-03-29 05:41:13 | train] - Train Epoch: [19] [230400/1281167 (18%)]	Loss: 2.096977
[2022-03-29 05:41:38 | train] - Train Epoch: [19] [243200/1281167 (19%)]	Loss: 1.734881
[2022-03-29 05:42:02 | train] - Train Epoch: [19] [256000/1281167 (20%)]	Loss: 1.819649
[2022-03-29 05:42:26 | train] - Train Epoch: [19] [268800/1281167 (21%)]	Loss: 1.272245
[2022-03-29 05:42:51 | train] - Train Epoch: [19] [281600/1281167 (22%)]	Loss: 1.709437
[2022-03-29 05:43:14 | train] - Train Epoch: [19] [294400/1281167 (23%)]	Loss: 1.520698
[2022-03-29 05:43:39 | train] - Train Epoch: [19] [307200/1281167 (24%)]	Loss: 1.294338
[2022-03-29 05:44:03 | train] - Train Epoch: [19] [320000/1281167 (25%)]	Loss: 1.778095
[2022-03-29 05:44:28 | train] - Train Epoch: [19] [332800/1281167 (26%)]	Loss: 1.644174
[2022-03-29 05:44:52 | train] - Train Epoch: [19] [345600/1281167 (27%)]	Loss: 1.629813
[2022-03-29 05:45:16 | train] - Train Epoch: [19] [358400/1281167 (28%)]	Loss: 1.705985
[2022-03-29 05:45:41 | train] - Train Epoch: [19] [371200/1281167 (29%)]	Loss: 1.426814
[2022-03-29 05:46:05 | train] - Train Epoch: [19] [384000/1281167 (30%)]	Loss: 1.973361
[2022-03-29 05:46:29 | train] - Train Epoch: [19] [396800/1281167 (31%)]	Loss: 1.906896
[2022-03-29 05:46:54 | train] - Train Epoch: [19] [409600/1281167 (32%)]	Loss: 1.845882
[2022-03-29 05:47:18 | train] - Train Epoch: [19] [422400/1281167 (33%)]	Loss: 1.617562
[2022-03-29 05:47:43 | train] - Train Epoch: [19] [435200/1281167 (34%)]	Loss: 1.823146
[2022-03-29 05:48:08 | train] - Train Epoch: [19] [448000/1281167 (35%)]	Loss: 1.762240
[2022-03-29 05:48:32 | train] - Train Epoch: [19] [460800/1281167 (36%)]	Loss: 1.355329
[2022-03-29 05:48:56 | train] - Train Epoch: [19] [473600/1281167 (37%)]	Loss: 1.472571
[2022-03-29 05:49:20 | train] - Train Epoch: [19] [486400/1281167 (38%)]	Loss: 1.809283
[2022-03-29 05:49:44 | train] - Train Epoch: [19] [499200/1281167 (39%)]	Loss: 1.710203
[2022-03-29 05:50:09 | train] - Train Epoch: [19] [512000/1281167 (40%)]	Loss: 1.450160
[2022-03-29 05:50:33 | train] - Train Epoch: [19] [524800/1281167 (41%)]	Loss: 2.184625
[2022-03-29 05:50:57 | train] - Train Epoch: [19] [537600/1281167 (42%)]	Loss: 1.594833
[2022-03-29 05:51:21 | train] - Train Epoch: [19] [550400/1281167 (43%)]	Loss: 1.536708
[2022-03-29 05:51:46 | train] - Train Epoch: [19] [563200/1281167 (44%)]	Loss: 1.946126
[2022-03-29 05:52:10 | train] - Train Epoch: [19] [576000/1281167 (45%)]	Loss: 1.653130
[2022-03-29 05:52:35 | train] - Train Epoch: [19] [588800/1281167 (46%)]	Loss: 2.023074
[2022-03-29 05:53:00 | train] - Train Epoch: [19] [601600/1281167 (47%)]	Loss: 1.544613
[2022-03-29 05:53:24 | train] - Train Epoch: [19] [614400/1281167 (48%)]	Loss: 1.326005
[2022-03-29 05:53:49 | train] - Train Epoch: [19] [627200/1281167 (49%)]	Loss: 1.789018
[2022-03-29 05:54:13 | train] - Train Epoch: [19] [640000/1281167 (50%)]	Loss: 1.851347
[2022-03-29 05:54:37 | train] - Train Epoch: [19] [652800/1281167 (51%)]	Loss: 1.699873
[2022-03-29 05:55:01 | train] - Train Epoch: [19] [665600/1281167 (52%)]	Loss: 1.330813
[2022-03-29 05:55:26 | train] - Train Epoch: [19] [678400/1281167 (53%)]	Loss: 1.888844
[2022-03-29 05:55:50 | train] - Train Epoch: [19] [691200/1281167 (54%)]	Loss: 1.767382
[2022-03-29 05:56:15 | train] - Train Epoch: [19] [704000/1281167 (55%)]	Loss: 1.708149
[2022-03-29 05:56:39 | train] - Train Epoch: [19] [716800/1281167 (56%)]	Loss: 1.420266
[2022-03-29 05:57:04 | train] - Train Epoch: [19] [729600/1281167 (57%)]	Loss: 2.022393
[2022-03-29 05:57:28 | train] - Train Epoch: [19] [742400/1281167 (58%)]	Loss: 1.743005
[2022-03-29 05:57:52 | train] - Train Epoch: [19] [755200/1281167 (59%)]	Loss: 1.436764
[2022-03-29 05:58:17 | train] - Train Epoch: [19] [768000/1281167 (60%)]	Loss: 1.814552
[2022-03-29 05:58:41 | train] - Train Epoch: [19] [780800/1281167 (61%)]	Loss: 1.403456
[2022-03-29 05:59:06 | train] - Train Epoch: [19] [793600/1281167 (62%)]	Loss: 1.723473
[2022-03-29 05:59:30 | train] - Train Epoch: [19] [806400/1281167 (63%)]	Loss: 1.639326
[2022-03-29 05:59:54 | train] - Train Epoch: [19] [819200/1281167 (64%)]	Loss: 1.786554
[2022-03-29 06:00:19 | train] - Train Epoch: [19] [832000/1281167 (65%)]	Loss: 1.546862
[2022-03-29 06:00:44 | train] - Train Epoch: [19] [844800/1281167 (66%)]	Loss: 1.631350
[2022-03-29 06:01:08 | train] - Train Epoch: [19] [857600/1281167 (67%)]	Loss: 1.634899
[2022-03-29 06:01:34 | train] - Train Epoch: [19] [870400/1281167 (68%)]	Loss: 1.576781
[2022-03-29 06:01:57 | train] - Train Epoch: [19] [883200/1281167 (69%)]	Loss: 1.849171
[2022-03-29 06:02:21 | train] - Train Epoch: [19] [896000/1281167 (70%)]	Loss: 1.531533
[2022-03-29 06:02:47 | train] - Train Epoch: [19] [908800/1281167 (71%)]	Loss: 1.392946
[2022-03-29 06:03:11 | train] - Train Epoch: [19] [921600/1281167 (72%)]	Loss: 1.545621
[2022-03-29 06:03:35 | train] - Train Epoch: [19] [934400/1281167 (73%)]	Loss: 1.622747
[2022-03-29 06:04:00 | train] - Train Epoch: [19] [947200/1281167 (74%)]	Loss: 1.629028
[2022-03-29 06:04:25 | train] - Train Epoch: [19] [960000/1281167 (75%)]	Loss: 1.556128
[2022-03-29 06:04:49 | train] - Train Epoch: [19] [972800/1281167 (76%)]	Loss: 1.505656
[2022-03-29 06:05:13 | train] - Train Epoch: [19] [985600/1281167 (77%)]	Loss: 1.382014
[2022-03-29 06:05:38 | train] - Train Epoch: [19] [998400/1281167 (78%)]	Loss: 1.676631
[2022-03-29 06:06:02 | train] - Train Epoch: [19] [1011200/1281167 (79%)]	Loss: 1.709726
[2022-03-29 06:06:27 | train] - Train Epoch: [19] [1024000/1281167 (80%)]	Loss: 1.855869
[2022-03-29 06:06:51 | train] - Train Epoch: [19] [1036800/1281167 (81%)]	Loss: 1.629023
[2022-03-29 06:07:16 | train] - Train Epoch: [19] [1049600/1281167 (82%)]	Loss: 1.893603
[2022-03-29 06:07:40 | train] - Train Epoch: [19] [1062400/1281167 (83%)]	Loss: 1.819243
[2022-03-29 06:08:04 | train] - Train Epoch: [19] [1075200/1281167 (84%)]	Loss: 1.658332
[2022-03-29 06:08:28 | train] - Train Epoch: [19] [1088000/1281167 (85%)]	Loss: 1.775007
[2022-03-29 06:08:53 | train] - Train Epoch: [19] [1100800/1281167 (86%)]	Loss: 1.688601
[2022-03-29 06:09:17 | train] - Train Epoch: [19] [1113600/1281167 (87%)]	Loss: 1.810873
[2022-03-29 06:09:42 | train] - Train Epoch: [19] [1126400/1281167 (88%)]	Loss: 1.686236
[2022-03-29 06:10:06 | train] - Train Epoch: [19] [1139200/1281167 (89%)]	Loss: 1.754875
[2022-03-29 06:10:30 | train] - Train Epoch: [19] [1152000/1281167 (90%)]	Loss: 1.361065
[2022-03-29 06:10:55 | train] - Train Epoch: [19] [1164800/1281167 (91%)]	Loss: 1.650817
[2022-03-29 06:11:20 | train] - Train Epoch: [19] [1177600/1281167 (92%)]	Loss: 2.033972
[2022-03-29 06:11:44 | train] - Train Epoch: [19] [1190400/1281167 (93%)]	Loss: 1.534384
[2022-03-29 06:12:08 | train] - Train Epoch: [19] [1203200/1281167 (94%)]	Loss: 1.707007
[2022-03-29 06:12:32 | train] - Train Epoch: [19] [1216000/1281167 (95%)]	Loss: 1.784618
[2022-03-29 06:12:57 | train] - Train Epoch: [19] [1228800/1281167 (96%)]	Loss: 1.934043
[2022-03-29 06:13:22 | train] - Train Epoch: [19] [1241600/1281167 (97%)]	Loss: 1.469385
[2022-03-29 06:13:47 | train] - Train Epoch: [19] [1254400/1281167 (98%)]	Loss: 1.470064
[2022-03-29 06:14:11 | train] - Train Epoch: [19] [1267200/1281167 (99%)]	Loss: 1.585641
[2022-03-29 06:14:35 | train] - Train Epoch: [19] [1280000/1281167 (100%)]	Loss: 1.609384
[2022-03-29 06:14:37 | train] - Train Epoch: [19]	 Average Loss: 1.717069	 Total Acc : 60.3285	 Total Top5 Acc : 81.5780
[2022-03-29 06:14:40 | train] - -------19 epoch end-----------
========================================
-------19 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 06:16:25 | train] - 
Epoch [19] Test set: Average loss: 1.5718, Accuracy: 31296/50000 (62.5535%), Top-5 Accuracy: 84.4222%

[2022-03-29 06:16:25 | train] - save intermediate epoch [19] result


[2022-03-29 06:16:28 | train] - logging best performance 19 epoch
[2022-03-29 06:16:30 | train] - -------20 epoch start-----------
========================================
----- test end -------------------------


logging best performance 19 epoch
[2022-03-29 06:16:32 | train] - Train Epoch: [20] [0/1281167 (0%)]	Loss: 1.568262
[2022-03-29 06:16:57 | train] - Train Epoch: [20] [12800/1281167 (1%)]	Loss: 1.249946
[2022-03-29 06:17:21 | train] - Train Epoch: [20] [25600/1281167 (2%)]	Loss: 1.645025
[2022-03-29 06:17:45 | train] - Train Epoch: [20] [38400/1281167 (3%)]	Loss: 1.862562
[2022-03-29 06:18:08 | train] - Train Epoch: [20] [51200/1281167 (4%)]	Loss: 1.803262
[2022-03-29 06:18:32 | train] - Train Epoch: [20] [64000/1281167 (5%)]	Loss: 1.870082
[2022-03-29 06:18:56 | train] - Train Epoch: [20] [76800/1281167 (6%)]	Loss: 1.632652
[2022-03-29 06:19:20 | train] - Train Epoch: [20] [89600/1281167 (7%)]	Loss: 1.787803
[2022-03-29 06:19:43 | train] - Train Epoch: [20] [102400/1281167 (8%)]	Loss: 1.324911
[2022-03-29 06:20:07 | train] - Train Epoch: [20] [115200/1281167 (9%)]	Loss: 1.522789
[2022-03-29 06:20:32 | train] - Train Epoch: [20] [128000/1281167 (10%)]	Loss: 1.828334
[2022-03-29 06:20:56 | train] - Train Epoch: [20] [140800/1281167 (11%)]	Loss: 1.659832
[2022-03-29 06:21:20 | train] - Train Epoch: [20] [153600/1281167 (12%)]	Loss: 1.530899
[2022-03-29 06:21:44 | train] - Train Epoch: [20] [166400/1281167 (13%)]	Loss: 1.793403
[2022-03-29 06:22:07 | train] - Train Epoch: [20] [179200/1281167 (14%)]	Loss: 1.909068
[2022-03-29 06:22:31 | train] - Train Epoch: [20] [192000/1281167 (15%)]	Loss: 2.076733
[2022-03-29 06:22:55 | train] - Train Epoch: [20] [204800/1281167 (16%)]	Loss: 1.472484
[2022-03-29 06:23:19 | train] - Train Epoch: [20] [217600/1281167 (17%)]	Loss: 1.472646
[2022-03-29 06:23:44 | train] - Train Epoch: [20] [230400/1281167 (18%)]	Loss: 1.540145
[2022-03-29 06:24:07 | train] - Train Epoch: [20] [243200/1281167 (19%)]	Loss: 1.945788
[2022-03-29 06:24:32 | train] - Train Epoch: [20] [256000/1281167 (20%)]	Loss: 1.741651
[2022-03-29 06:24:55 | train] - Train Epoch: [20] [268800/1281167 (21%)]	Loss: 1.556244
[2022-03-29 06:25:19 | train] - Train Epoch: [20] [281600/1281167 (22%)]	Loss: 1.611309
[2022-03-29 06:25:43 | train] - Train Epoch: [20] [294400/1281167 (23%)]	Loss: 1.567453
[2022-03-29 06:26:07 | train] - Train Epoch: [20] [307200/1281167 (24%)]	Loss: 1.605847
[2022-03-29 06:26:31 | train] - Train Epoch: [20] [320000/1281167 (25%)]	Loss: 1.854352
[2022-03-29 06:26:55 | train] - Train Epoch: [20] [332800/1281167 (26%)]	Loss: 1.988877
[2022-03-29 06:27:19 | train] - Train Epoch: [20] [345600/1281167 (27%)]	Loss: 1.680932
[2022-03-29 06:27:43 | train] - Train Epoch: [20] [358400/1281167 (28%)]	Loss: 1.585754
[2022-03-29 06:28:07 | train] - Train Epoch: [20] [371200/1281167 (29%)]	Loss: 1.713392
[2022-03-29 06:28:32 | train] - Train Epoch: [20] [384000/1281167 (30%)]	Loss: 1.897277
[2022-03-29 06:28:55 | train] - Train Epoch: [20] [396800/1281167 (31%)]	Loss: 1.722282
[2022-03-29 06:29:19 | train] - Train Epoch: [20] [409600/1281167 (32%)]	Loss: 2.011132
[2022-03-29 06:29:43 | train] - Train Epoch: [20] [422400/1281167 (33%)]	Loss: 1.936494
[2022-03-29 06:30:07 | train] - Train Epoch: [20] [435200/1281167 (34%)]	Loss: 1.722976
[2022-03-29 06:30:32 | train] - Train Epoch: [20] [448000/1281167 (35%)]	Loss: 1.846141
[2022-03-29 06:30:55 | train] - Train Epoch: [20] [460800/1281167 (36%)]	Loss: 1.588376
[2022-03-29 06:31:19 | train] - Train Epoch: [20] [473600/1281167 (37%)]	Loss: 1.558747
[2022-03-29 06:31:42 | train] - Train Epoch: [20] [486400/1281167 (38%)]	Loss: 2.037251
[2022-03-29 06:32:06 | train] - Train Epoch: [20] [499200/1281167 (39%)]	Loss: 1.732277
[2022-03-29 06:32:31 | train] - Train Epoch: [20] [512000/1281167 (40%)]	Loss: 1.451127
[2022-03-29 06:32:55 | train] - Train Epoch: [20] [524800/1281167 (41%)]	Loss: 1.616225
[2022-03-29 06:33:18 | train] - Train Epoch: [20] [537600/1281167 (42%)]	Loss: 1.983657
[2022-03-29 06:33:42 | train] - Train Epoch: [20] [550400/1281167 (43%)]	Loss: 2.171894
[2022-03-29 06:34:06 | train] - Train Epoch: [20] [563200/1281167 (44%)]	Loss: 1.911235
[2022-03-29 06:34:30 | train] - Train Epoch: [20] [576000/1281167 (45%)]	Loss: 1.472258
[2022-03-29 06:34:54 | train] - Train Epoch: [20] [588800/1281167 (46%)]	Loss: 1.661683
[2022-03-29 06:35:18 | train] - Train Epoch: [20] [601600/1281167 (47%)]	Loss: 1.564164
[2022-03-29 06:35:42 | train] - Train Epoch: [20] [614400/1281167 (48%)]	Loss: 1.631668
[2022-03-29 06:36:06 | train] - Train Epoch: [20] [627200/1281167 (49%)]	Loss: 1.653280
[2022-03-29 06:36:30 | train] - Train Epoch: [20] [640000/1281167 (50%)]	Loss: 1.831926
[2022-03-29 06:36:54 | train] - Train Epoch: [20] [652800/1281167 (51%)]	Loss: 1.351126
[2022-03-29 06:37:18 | train] - Train Epoch: [20] [665600/1281167 (52%)]	Loss: 1.439592
[2022-03-29 06:37:41 | train] - Train Epoch: [20] [678400/1281167 (53%)]	Loss: 1.817324
[2022-03-29 06:38:05 | train] - Train Epoch: [20] [691200/1281167 (54%)]	Loss: 1.824353
[2022-03-29 06:38:29 | train] - Train Epoch: [20] [704000/1281167 (55%)]	Loss: 1.822010
[2022-03-29 06:38:53 | train] - Train Epoch: [20] [716800/1281167 (56%)]	Loss: 1.971963
[2022-03-29 06:39:17 | train] - Train Epoch: [20] [729600/1281167 (57%)]	Loss: 1.381163
[2022-03-29 06:39:40 | train] - Train Epoch: [20] [742400/1281167 (58%)]	Loss: 2.188261
[2022-03-29 06:40:03 | train] - Train Epoch: [20] [755200/1281167 (59%)]	Loss: 1.913822
[2022-03-29 06:40:27 | train] - Train Epoch: [20] [768000/1281167 (60%)]	Loss: 1.704169
[2022-03-29 06:40:51 | train] - Train Epoch: [20] [780800/1281167 (61%)]	Loss: 1.854725
[2022-03-29 06:41:15 | train] - Train Epoch: [20] [793600/1281167 (62%)]	Loss: 1.644122
[2022-03-29 06:41:39 | train] - Train Epoch: [20] [806400/1281167 (63%)]	Loss: 1.389258
[2022-03-29 06:42:03 | train] - Train Epoch: [20] [819200/1281167 (64%)]	Loss: 1.855249
[2022-03-29 06:42:27 | train] - Train Epoch: [20] [832000/1281167 (65%)]	Loss: 1.858750
[2022-03-29 06:42:51 | train] - Train Epoch: [20] [844800/1281167 (66%)]	Loss: 1.632221
[2022-03-29 06:43:15 | train] - Train Epoch: [20] [857600/1281167 (67%)]	Loss: 1.987930
[2022-03-29 06:43:39 | train] - Train Epoch: [20] [870400/1281167 (68%)]	Loss: 1.968006
[2022-03-29 06:44:03 | train] - Train Epoch: [20] [883200/1281167 (69%)]	Loss: 1.898613
[2022-03-29 06:44:27 | train] - Train Epoch: [20] [896000/1281167 (70%)]	Loss: 1.916057
[2022-03-29 06:44:51 | train] - Train Epoch: [20] [908800/1281167 (71%)]	Loss: 2.099077
[2022-03-29 06:45:14 | train] - Train Epoch: [20] [921600/1281167 (72%)]	Loss: 1.748729
[2022-03-29 06:45:38 | train] - Train Epoch: [20] [934400/1281167 (73%)]	Loss: 1.700252
[2022-03-29 06:46:02 | train] - Train Epoch: [20] [947200/1281167 (74%)]	Loss: 1.361998
[2022-03-29 06:46:26 | train] - Train Epoch: [20] [960000/1281167 (75%)]	Loss: 1.635790
[2022-03-29 06:46:50 | train] - Train Epoch: [20] [972800/1281167 (76%)]	Loss: 1.537206
[2022-03-29 06:47:13 | train] - Train Epoch: [20] [985600/1281167 (77%)]	Loss: 1.755834
[2022-03-29 06:47:37 | train] - Train Epoch: [20] [998400/1281167 (78%)]	Loss: 1.849252
[2022-03-29 06:48:01 | train] - Train Epoch: [20] [1011200/1281167 (79%)]	Loss: 1.716231
[2022-03-29 06:48:25 | train] - Train Epoch: [20] [1024000/1281167 (80%)]	Loss: 1.549971
[2022-03-29 06:48:48 | train] - Train Epoch: [20] [1036800/1281167 (81%)]	Loss: 1.549389
[2022-03-29 06:49:12 | train] - Train Epoch: [20] [1049600/1281167 (82%)]	Loss: 1.580038
[2022-03-29 06:49:36 | train] - Train Epoch: [20] [1062400/1281167 (83%)]	Loss: 1.515124
[2022-03-29 06:49:59 | train] - Train Epoch: [20] [1075200/1281167 (84%)]	Loss: 2.007539
[2022-03-29 06:50:23 | train] - Train Epoch: [20] [1088000/1281167 (85%)]	Loss: 1.663599
[2022-03-29 06:50:47 | train] - Train Epoch: [20] [1100800/1281167 (86%)]	Loss: 1.598163
[2022-03-29 06:51:11 | train] - Train Epoch: [20] [1113600/1281167 (87%)]	Loss: 1.688574
[2022-03-29 06:51:36 | train] - Train Epoch: [20] [1126400/1281167 (88%)]	Loss: 1.434005
[2022-03-29 06:51:59 | train] - Train Epoch: [20] [1139200/1281167 (89%)]	Loss: 1.590053
[2022-03-29 06:52:23 | train] - Train Epoch: [20] [1152000/1281167 (90%)]	Loss: 1.815664
[2022-03-29 06:52:47 | train] - Train Epoch: [20] [1164800/1281167 (91%)]	Loss: 1.707646
[2022-03-29 06:53:11 | train] - Train Epoch: [20] [1177600/1281167 (92%)]	Loss: 1.924278
[2022-03-29 06:53:35 | train] - Train Epoch: [20] [1190400/1281167 (93%)]	Loss: 1.789634
[2022-03-29 06:53:59 | train] - Train Epoch: [20] [1203200/1281167 (94%)]	Loss: 1.623311
[2022-03-29 06:54:23 | train] - Train Epoch: [20] [1216000/1281167 (95%)]	Loss: 2.083507
[2022-03-29 06:54:47 | train] - Train Epoch: [20] [1228800/1281167 (96%)]	Loss: 1.854439
[2022-03-29 06:55:11 | train] - Train Epoch: [20] [1241600/1281167 (97%)]	Loss: 1.540853
[2022-03-29 06:55:35 | train] - Train Epoch: [20] [1254400/1281167 (98%)]	Loss: 1.710007
[2022-03-29 06:55:59 | train] - Train Epoch: [20] [1267200/1281167 (99%)]	Loss: 1.815742
[2022-03-29 06:56:23 | train] - Train Epoch: [20] [1280000/1281167 (100%)]	Loss: 2.257694
[2022-03-29 06:56:26 | train] - Train Epoch: [20]	 Average Loss: 1.731148	 Total Acc : 60.0439	 Total Top5 Acc : 81.3992
[2022-03-29 06:56:28 | train] - -------20 epoch end-----------
========================================
-------20 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 06:58:14 | train] - 
Epoch [20] Test set: Average loss: 1.5388, Accuracy: 31601/50000 (63.1738%), Top-5 Accuracy: 84.8893%

[2022-03-29 06:58:14 | train] - save intermediate epoch [20] result


[2022-03-29 06:58:17 | train] - logging best performance 20 epoch
[2022-03-29 06:58:19 | train] - -------21 epoch start-----------
========================================
----- test end -------------------------


logging best performance 20 epoch
[2022-03-29 06:58:21 | train] - Train Epoch: [21] [0/1281167 (0%)]	Loss: 1.703853
[2022-03-29 06:58:45 | train] - Train Epoch: [21] [12800/1281167 (1%)]	Loss: 1.549757
[2022-03-29 06:59:08 | train] - Train Epoch: [21] [25600/1281167 (2%)]	Loss: 1.466965
[2022-03-29 06:59:31 | train] - Train Epoch: [21] [38400/1281167 (3%)]	Loss: 1.869177
[2022-03-29 06:59:55 | train] - Train Epoch: [21] [51200/1281167 (4%)]	Loss: 1.761632
[2022-03-29 07:00:18 | train] - Train Epoch: [21] [64000/1281167 (5%)]	Loss: 1.715626
[2022-03-29 07:00:41 | train] - Train Epoch: [21] [76800/1281167 (6%)]	Loss: 1.719671
[2022-03-29 07:01:04 | train] - Train Epoch: [21] [89600/1281167 (7%)]	Loss: 1.824061
[2022-03-29 07:01:27 | train] - Train Epoch: [21] [102400/1281167 (8%)]	Loss: 1.325616
[2022-03-29 07:01:50 | train] - Train Epoch: [21] [115200/1281167 (9%)]	Loss: 1.854197
[2022-03-29 07:02:13 | train] - Train Epoch: [21] [128000/1281167 (10%)]	Loss: 1.665906
[2022-03-29 07:02:36 | train] - Train Epoch: [21] [140800/1281167 (11%)]	Loss: 1.881398
[2022-03-29 07:03:00 | train] - Train Epoch: [21] [153600/1281167 (12%)]	Loss: 2.215919
[2022-03-29 07:03:23 | train] - Train Epoch: [21] [166400/1281167 (13%)]	Loss: 1.836951
[2022-03-29 07:03:46 | train] - Train Epoch: [21] [179200/1281167 (14%)]	Loss: 1.739230
[2022-03-29 07:04:09 | train] - Train Epoch: [21] [192000/1281167 (15%)]	Loss: 1.803602
[2022-03-29 07:04:32 | train] - Train Epoch: [21] [204800/1281167 (16%)]	Loss: 1.771698
[2022-03-29 07:04:56 | train] - Train Epoch: [21] [217600/1281167 (17%)]	Loss: 1.830289
[2022-03-29 07:05:18 | train] - Train Epoch: [21] [230400/1281167 (18%)]	Loss: 1.631753
[2022-03-29 07:05:42 | train] - Train Epoch: [21] [243200/1281167 (19%)]	Loss: 1.615022
[2022-03-29 07:06:05 | train] - Train Epoch: [21] [256000/1281167 (20%)]	Loss: 1.927652
[2022-03-29 07:06:29 | train] - Train Epoch: [21] [268800/1281167 (21%)]	Loss: 1.594013
[2022-03-29 07:06:52 | train] - Train Epoch: [21] [281600/1281167 (22%)]	Loss: 1.841036
[2022-03-29 07:07:15 | train] - Train Epoch: [21] [294400/1281167 (23%)]	Loss: 1.633021
[2022-03-29 07:07:38 | train] - Train Epoch: [21] [307200/1281167 (24%)]	Loss: 2.019685
[2022-03-29 07:08:02 | train] - Train Epoch: [21] [320000/1281167 (25%)]	Loss: 1.595475
[2022-03-29 07:08:26 | train] - Train Epoch: [21] [332800/1281167 (26%)]	Loss: 2.081642
[2022-03-29 07:08:48 | train] - Train Epoch: [21] [345600/1281167 (27%)]	Loss: 2.099819
[2022-03-29 07:09:11 | train] - Train Epoch: [21] [358400/1281167 (28%)]	Loss: 1.623388
[2022-03-29 07:09:35 | train] - Train Epoch: [21] [371200/1281167 (29%)]	Loss: 1.583835
[2022-03-29 07:09:58 | train] - Train Epoch: [21] [384000/1281167 (30%)]	Loss: 1.737803
[2022-03-29 07:10:21 | train] - Train Epoch: [21] [396800/1281167 (31%)]	Loss: 1.701334
[2022-03-29 07:10:45 | train] - Train Epoch: [21] [409600/1281167 (32%)]	Loss: 1.845542
[2022-03-29 07:11:08 | train] - Train Epoch: [21] [422400/1281167 (33%)]	Loss: 1.598140
[2022-03-29 07:11:31 | train] - Train Epoch: [21] [435200/1281167 (34%)]	Loss: 1.779113
[2022-03-29 07:11:54 | train] - Train Epoch: [21] [448000/1281167 (35%)]	Loss: 1.789824
[2022-03-29 07:12:18 | train] - Train Epoch: [21] [460800/1281167 (36%)]	Loss: 1.200044
[2022-03-29 07:12:41 | train] - Train Epoch: [21] [473600/1281167 (37%)]	Loss: 1.713129
[2022-03-29 07:13:04 | train] - Train Epoch: [21] [486400/1281167 (38%)]	Loss: 1.748143
[2022-03-29 07:13:27 | train] - Train Epoch: [21] [499200/1281167 (39%)]	Loss: 1.993997
[2022-03-29 07:13:51 | train] - Train Epoch: [21] [512000/1281167 (40%)]	Loss: 1.917173
[2022-03-29 07:14:14 | train] - Train Epoch: [21] [524800/1281167 (41%)]	Loss: 1.596759
[2022-03-29 07:14:36 | train] - Train Epoch: [21] [537600/1281167 (42%)]	Loss: 1.740285
[2022-03-29 07:14:59 | train] - Train Epoch: [21] [550400/1281167 (43%)]	Loss: 1.421176
[2022-03-29 07:15:23 | train] - Train Epoch: [21] [563200/1281167 (44%)]	Loss: 1.438253
[2022-03-29 07:15:45 | train] - Train Epoch: [21] [576000/1281167 (45%)]	Loss: 1.572830
[2022-03-29 07:16:09 | train] - Train Epoch: [21] [588800/1281167 (46%)]	Loss: 1.871753
[2022-03-29 07:16:32 | train] - Train Epoch: [21] [601600/1281167 (47%)]	Loss: 2.051812
[2022-03-29 07:16:55 | train] - Train Epoch: [21] [614400/1281167 (48%)]	Loss: 1.640727
[2022-03-29 07:17:17 | train] - Train Epoch: [21] [627200/1281167 (49%)]	Loss: 1.792582
[2022-03-29 07:17:40 | train] - Train Epoch: [21] [640000/1281167 (50%)]	Loss: 1.827637
[2022-03-29 07:18:02 | train] - Train Epoch: [21] [652800/1281167 (51%)]	Loss: 1.487411
[2022-03-29 07:18:25 | train] - Train Epoch: [21] [665600/1281167 (52%)]	Loss: 1.740519
[2022-03-29 07:18:49 | train] - Train Epoch: [21] [678400/1281167 (53%)]	Loss: 1.876402
[2022-03-29 07:19:11 | train] - Train Epoch: [21] [691200/1281167 (54%)]	Loss: 1.730799
[2022-03-29 07:19:34 | train] - Train Epoch: [21] [704000/1281167 (55%)]	Loss: 1.719048
[2022-03-29 07:19:57 | train] - Train Epoch: [21] [716800/1281167 (56%)]	Loss: 1.623552
[2022-03-29 07:20:21 | train] - Train Epoch: [21] [729600/1281167 (57%)]	Loss: 1.613630
[2022-03-29 07:20:44 | train] - Train Epoch: [21] [742400/1281167 (58%)]	Loss: 1.831357
[2022-03-29 07:21:06 | train] - Train Epoch: [21] [755200/1281167 (59%)]	Loss: 1.723954
[2022-03-29 07:21:29 | train] - Train Epoch: [21] [768000/1281167 (60%)]	Loss: 1.522348
[2022-03-29 07:21:52 | train] - Train Epoch: [21] [780800/1281167 (61%)]	Loss: 1.628691
[2022-03-29 07:22:15 | train] - Train Epoch: [21] [793600/1281167 (62%)]	Loss: 1.691122
[2022-03-29 07:22:38 | train] - Train Epoch: [21] [806400/1281167 (63%)]	Loss: 1.649280
[2022-03-29 07:23:01 | train] - Train Epoch: [21] [819200/1281167 (64%)]	Loss: 1.749794
[2022-03-29 07:23:24 | train] - Train Epoch: [21] [832000/1281167 (65%)]	Loss: 1.846036
[2022-03-29 07:23:47 | train] - Train Epoch: [21] [844800/1281167 (66%)]	Loss: 1.766932
[2022-03-29 07:24:10 | train] - Train Epoch: [21] [857600/1281167 (67%)]	Loss: 1.493025
[2022-03-29 07:24:33 | train] - Train Epoch: [21] [870400/1281167 (68%)]	Loss: 1.719181
[2022-03-29 07:24:56 | train] - Train Epoch: [21] [883200/1281167 (69%)]	Loss: 1.815775
[2022-03-29 07:25:19 | train] - Train Epoch: [21] [896000/1281167 (70%)]	Loss: 1.677894
[2022-03-29 07:25:42 | train] - Train Epoch: [21] [908800/1281167 (71%)]	Loss: 2.249804
[2022-03-29 07:26:05 | train] - Train Epoch: [21] [921600/1281167 (72%)]	Loss: 1.847349
[2022-03-29 07:26:29 | train] - Train Epoch: [21] [934400/1281167 (73%)]	Loss: 1.468108
[2022-03-29 07:26:51 | train] - Train Epoch: [21] [947200/1281167 (74%)]	Loss: 1.698873
[2022-03-29 07:27:14 | train] - Train Epoch: [21] [960000/1281167 (75%)]	Loss: 1.924609
[2022-03-29 07:27:37 | train] - Train Epoch: [21] [972800/1281167 (76%)]	Loss: 1.958365
[2022-03-29 07:28:01 | train] - Train Epoch: [21] [985600/1281167 (77%)]	Loss: 1.762016
[2022-03-29 07:28:24 | train] - Train Epoch: [21] [998400/1281167 (78%)]	Loss: 1.559300
[2022-03-29 07:28:47 | train] - Train Epoch: [21] [1011200/1281167 (79%)]	Loss: 1.922605
[2022-03-29 07:29:10 | train] - Train Epoch: [21] [1024000/1281167 (80%)]	Loss: 2.062298
[2022-03-29 07:29:33 | train] - Train Epoch: [21] [1036800/1281167 (81%)]	Loss: 1.788563
[2022-03-29 07:29:57 | train] - Train Epoch: [21] [1049600/1281167 (82%)]	Loss: 1.948837
[2022-03-29 07:30:20 | train] - Train Epoch: [21] [1062400/1281167 (83%)]	Loss: 1.817335
[2022-03-29 07:30:43 | train] - Train Epoch: [21] [1075200/1281167 (84%)]	Loss: 1.276437
[2022-03-29 07:31:06 | train] - Train Epoch: [21] [1088000/1281167 (85%)]	Loss: 1.755664
[2022-03-29 07:31:30 | train] - Train Epoch: [21] [1100800/1281167 (86%)]	Loss: 1.680830
[2022-03-29 07:31:53 | train] - Train Epoch: [21] [1113600/1281167 (87%)]	Loss: 1.837789
[2022-03-29 07:32:17 | train] - Train Epoch: [21] [1126400/1281167 (88%)]	Loss: 1.716291
[2022-03-29 07:32:40 | train] - Train Epoch: [21] [1139200/1281167 (89%)]	Loss: 1.456759
[2022-03-29 07:33:03 | train] - Train Epoch: [21] [1152000/1281167 (90%)]	Loss: 1.468825
[2022-03-29 07:33:26 | train] - Train Epoch: [21] [1164800/1281167 (91%)]	Loss: 1.618870
[2022-03-29 07:33:49 | train] - Train Epoch: [21] [1177600/1281167 (92%)]	Loss: 1.817283
[2022-03-29 07:34:13 | train] - Train Epoch: [21] [1190400/1281167 (93%)]	Loss: 1.637545
[2022-03-29 07:34:36 | train] - Train Epoch: [21] [1203200/1281167 (94%)]	Loss: 1.412922
[2022-03-29 07:35:00 | train] - Train Epoch: [21] [1216000/1281167 (95%)]	Loss: 1.931804
[2022-03-29 07:35:23 | train] - Train Epoch: [21] [1228800/1281167 (96%)]	Loss: 2.014281
[2022-03-29 07:35:46 | train] - Train Epoch: [21] [1241600/1281167 (97%)]	Loss: 1.762497
[2022-03-29 07:36:09 | train] - Train Epoch: [21] [1254400/1281167 (98%)]	Loss: 1.949179
[2022-03-29 07:36:33 | train] - Train Epoch: [21] [1267200/1281167 (99%)]	Loss: 1.826723
[2022-03-29 07:36:56 | train] - Train Epoch: [21] [1280000/1281167 (100%)]	Loss: 1.517962
[2022-03-29 07:36:58 | train] - Train Epoch: [21]	 Average Loss: 1.702114	 Total Acc : 60.5954	 Total Top5 Acc : 81.8158
[2022-03-29 07:37:00 | train] - -------21 epoch end-----------
========================================
-------21 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 07:38:45 | train] - 
Epoch [21] Test set: Average loss: 1.5215, Accuracy: 31777/50000 (63.5254%), Top-5 Accuracy: 85.4927%

[2022-03-29 07:38:45 | train] - save intermediate epoch [21] result


[2022-03-29 07:38:49 | train] - logging best performance 21 epoch
[2022-03-29 07:38:50 | train] - -------22 epoch start-----------
========================================
----- test end -------------------------


logging best performance 21 epoch
[2022-03-29 07:38:53 | train] - Train Epoch: [22] [0/1281167 (0%)]	Loss: 1.811134
[2022-03-29 07:39:16 | train] - Train Epoch: [22] [12800/1281167 (1%)]	Loss: 1.405013
[2022-03-29 07:39:39 | train] - Train Epoch: [22] [25600/1281167 (2%)]	Loss: 1.496976
[2022-03-29 07:40:03 | train] - Train Epoch: [22] [38400/1281167 (3%)]	Loss: 1.622910
[2022-03-29 07:40:25 | train] - Train Epoch: [22] [51200/1281167 (4%)]	Loss: 1.463996
[2022-03-29 07:40:49 | train] - Train Epoch: [22] [64000/1281167 (5%)]	Loss: 1.782139
[2022-03-29 07:41:12 | train] - Train Epoch: [22] [76800/1281167 (6%)]	Loss: 1.759356
[2022-03-29 07:41:34 | train] - Train Epoch: [22] [89600/1281167 (7%)]	Loss: 1.430258
[2022-03-29 07:41:58 | train] - Train Epoch: [22] [102400/1281167 (8%)]	Loss: 1.476963
[2022-03-29 07:42:21 | train] - Train Epoch: [22] [115200/1281167 (9%)]	Loss: 1.159646
[2022-03-29 07:42:44 | train] - Train Epoch: [22] [128000/1281167 (10%)]	Loss: 1.784565
[2022-03-29 07:43:07 | train] - Train Epoch: [22] [140800/1281167 (11%)]	Loss: 1.795921
[2022-03-29 07:43:30 | train] - Train Epoch: [22] [153600/1281167 (12%)]	Loss: 1.549530
[2022-03-29 07:43:53 | train] - Train Epoch: [22] [166400/1281167 (13%)]	Loss: 1.918574
[2022-03-29 07:44:16 | train] - Train Epoch: [22] [179200/1281167 (14%)]	Loss: 1.686568
[2022-03-29 07:44:39 | train] - Train Epoch: [22] [192000/1281167 (15%)]	Loss: 1.653553
[2022-03-29 07:45:02 | train] - Train Epoch: [22] [204800/1281167 (16%)]	Loss: 1.673016
[2022-03-29 07:45:25 | train] - Train Epoch: [22] [217600/1281167 (17%)]	Loss: 1.964644
[2022-03-29 07:45:48 | train] - Train Epoch: [22] [230400/1281167 (18%)]	Loss: 1.960047
[2022-03-29 07:46:11 | train] - Train Epoch: [22] [243200/1281167 (19%)]	Loss: 1.873221
[2022-03-29 07:46:34 | train] - Train Epoch: [22] [256000/1281167 (20%)]	Loss: 1.761501
[2022-03-29 07:46:57 | train] - Train Epoch: [22] [268800/1281167 (21%)]	Loss: 1.435581
[2022-03-29 07:47:19 | train] - Train Epoch: [22] [281600/1281167 (22%)]	Loss: 1.987311
[2022-03-29 07:47:43 | train] - Train Epoch: [22] [294400/1281167 (23%)]	Loss: 1.705278
[2022-03-29 07:48:06 | train] - Train Epoch: [22] [307200/1281167 (24%)]	Loss: 1.481216
[2022-03-29 07:48:28 | train] - Train Epoch: [22] [320000/1281167 (25%)]	Loss: 1.428918
[2022-03-29 07:48:51 | train] - Train Epoch: [22] [332800/1281167 (26%)]	Loss: 1.795241
[2022-03-29 07:49:14 | train] - Train Epoch: [22] [345600/1281167 (27%)]	Loss: 1.380055
[2022-03-29 07:49:37 | train] - Train Epoch: [22] [358400/1281167 (28%)]	Loss: 1.654242
[2022-03-29 07:50:00 | train] - Train Epoch: [22] [371200/1281167 (29%)]	Loss: 1.627547
[2022-03-29 07:50:23 | train] - Train Epoch: [22] [384000/1281167 (30%)]	Loss: 1.635526
[2022-03-29 07:50:46 | train] - Train Epoch: [22] [396800/1281167 (31%)]	Loss: 1.778192
[2022-03-29 07:51:09 | train] - Train Epoch: [22] [409600/1281167 (32%)]	Loss: 1.437096
[2022-03-29 07:51:32 | train] - Train Epoch: [22] [422400/1281167 (33%)]	Loss: 1.652023
[2022-03-29 07:51:55 | train] - Train Epoch: [22] [435200/1281167 (34%)]	Loss: 1.713538
[2022-03-29 07:52:19 | train] - Train Epoch: [22] [448000/1281167 (35%)]	Loss: 1.376211
[2022-03-29 07:52:42 | train] - Train Epoch: [22] [460800/1281167 (36%)]	Loss: 1.907517
[2022-03-29 07:53:05 | train] - Train Epoch: [22] [473600/1281167 (37%)]	Loss: 1.638090
[2022-03-29 07:53:27 | train] - Train Epoch: [22] [486400/1281167 (38%)]	Loss: 1.786067
[2022-03-29 07:53:51 | train] - Train Epoch: [22] [499200/1281167 (39%)]	Loss: 1.565146
[2022-03-29 07:54:14 | train] - Train Epoch: [22] [512000/1281167 (40%)]	Loss: 1.749999
[2022-03-29 07:54:37 | train] - Train Epoch: [22] [524800/1281167 (41%)]	Loss: 1.557847
[2022-03-29 07:55:00 | train] - Train Epoch: [22] [537600/1281167 (42%)]	Loss: 1.647531
[2022-03-29 07:55:23 | train] - Train Epoch: [22] [550400/1281167 (43%)]	Loss: 1.581928
[2022-03-29 07:55:46 | train] - Train Epoch: [22] [563200/1281167 (44%)]	Loss: 1.608151
[2022-03-29 07:56:09 | train] - Train Epoch: [22] [576000/1281167 (45%)]	Loss: 1.251397
[2022-03-29 07:56:32 | train] - Train Epoch: [22] [588800/1281167 (46%)]	Loss: 1.547524
[2022-03-29 07:56:55 | train] - Train Epoch: [22] [601600/1281167 (47%)]	Loss: 1.812597
[2022-03-29 07:57:17 | train] - Train Epoch: [22] [614400/1281167 (48%)]	Loss: 1.607665
[2022-03-29 07:57:40 | train] - Train Epoch: [22] [627200/1281167 (49%)]	Loss: 1.648850
[2022-03-29 07:58:04 | train] - Train Epoch: [22] [640000/1281167 (50%)]	Loss: 1.788173
[2022-03-29 07:58:26 | train] - Train Epoch: [22] [652800/1281167 (51%)]	Loss: 1.662639
[2022-03-29 07:58:50 | train] - Train Epoch: [22] [665600/1281167 (52%)]	Loss: 1.368388
[2022-03-29 07:59:13 | train] - Train Epoch: [22] [678400/1281167 (53%)]	Loss: 1.660807
[2022-03-29 07:59:36 | train] - Train Epoch: [22] [691200/1281167 (54%)]	Loss: 1.611421
[2022-03-29 07:59:59 | train] - Train Epoch: [22] [704000/1281167 (55%)]	Loss: 1.541791
[2022-03-29 08:00:22 | train] - Train Epoch: [22] [716800/1281167 (56%)]	Loss: 1.778533
[2022-03-29 08:00:45 | train] - Train Epoch: [22] [729600/1281167 (57%)]	Loss: 1.542171
[2022-03-29 08:01:08 | train] - Train Epoch: [22] [742400/1281167 (58%)]	Loss: 1.539924
[2022-03-29 08:01:31 | train] - Train Epoch: [22] [755200/1281167 (59%)]	Loss: 1.565243
[2022-03-29 08:01:54 | train] - Train Epoch: [22] [768000/1281167 (60%)]	Loss: 1.746331
[2022-03-29 08:02:17 | train] - Train Epoch: [22] [780800/1281167 (61%)]	Loss: 1.826854
[2022-03-29 08:02:40 | train] - Train Epoch: [22] [793600/1281167 (62%)]	Loss: 1.463111
[2022-03-29 08:03:03 | train] - Train Epoch: [22] [806400/1281167 (63%)]	Loss: 1.881938
[2022-03-29 08:03:26 | train] - Train Epoch: [22] [819200/1281167 (64%)]	Loss: 1.765086
[2022-03-29 08:03:49 | train] - Train Epoch: [22] [832000/1281167 (65%)]	Loss: 1.942572
[2022-03-29 08:04:13 | train] - Train Epoch: [22] [844800/1281167 (66%)]	Loss: 1.572441
[2022-03-29 08:04:36 | train] - Train Epoch: [22] [857600/1281167 (67%)]	Loss: 1.467169
[2022-03-29 08:04:59 | train] - Train Epoch: [22] [870400/1281167 (68%)]	Loss: 1.794269
[2022-03-29 08:05:23 | train] - Train Epoch: [22] [883200/1281167 (69%)]	Loss: 1.610670
[2022-03-29 08:05:46 | train] - Train Epoch: [22] [896000/1281167 (70%)]	Loss: 1.526955
[2022-03-29 08:06:09 | train] - Train Epoch: [22] [908800/1281167 (71%)]	Loss: 1.615984
[2022-03-29 08:06:32 | train] - Train Epoch: [22] [921600/1281167 (72%)]	Loss: 1.881869
[2022-03-29 08:06:56 | train] - Train Epoch: [22] [934400/1281167 (73%)]	Loss: 2.086215
[2022-03-29 08:07:19 | train] - Train Epoch: [22] [947200/1281167 (74%)]	Loss: 1.602863
[2022-03-29 08:07:42 | train] - Train Epoch: [22] [960000/1281167 (75%)]	Loss: 1.543716
[2022-03-29 08:08:05 | train] - Train Epoch: [22] [972800/1281167 (76%)]	Loss: 1.881551
[2022-03-29 08:08:28 | train] - Train Epoch: [22] [985600/1281167 (77%)]	Loss: 1.620305
[2022-03-29 08:08:51 | train] - Train Epoch: [22] [998400/1281167 (78%)]	Loss: 1.715240
[2022-03-29 08:09:14 | train] - Train Epoch: [22] [1011200/1281167 (79%)]	Loss: 1.504455
[2022-03-29 08:09:37 | train] - Train Epoch: [22] [1024000/1281167 (80%)]	Loss: 1.526221
[2022-03-29 08:10:00 | train] - Train Epoch: [22] [1036800/1281167 (81%)]	Loss: 2.059838
[2022-03-29 08:10:23 | train] - Train Epoch: [22] [1049600/1281167 (82%)]	Loss: 1.622907
[2022-03-29 08:10:46 | train] - Train Epoch: [22] [1062400/1281167 (83%)]	Loss: 1.789995
[2022-03-29 08:11:10 | train] - Train Epoch: [22] [1075200/1281167 (84%)]	Loss: 1.551991
[2022-03-29 08:11:33 | train] - Train Epoch: [22] [1088000/1281167 (85%)]	Loss: 1.736762
[2022-03-29 08:11:55 | train] - Train Epoch: [22] [1100800/1281167 (86%)]	Loss: 1.745255
[2022-03-29 08:12:19 | train] - Train Epoch: [22] [1113600/1281167 (87%)]	Loss: 1.766026
[2022-03-29 08:12:41 | train] - Train Epoch: [22] [1126400/1281167 (88%)]	Loss: 1.905730
[2022-03-29 08:13:04 | train] - Train Epoch: [22] [1139200/1281167 (89%)]	Loss: 1.533882
[2022-03-29 08:13:27 | train] - Train Epoch: [22] [1152000/1281167 (90%)]	Loss: 1.733438
[2022-03-29 08:13:51 | train] - Train Epoch: [22] [1164800/1281167 (91%)]	Loss: 1.545449
[2022-03-29 08:14:14 | train] - Train Epoch: [22] [1177600/1281167 (92%)]	Loss: 1.618076
[2022-03-29 08:14:37 | train] - Train Epoch: [22] [1190400/1281167 (93%)]	Loss: 1.525885
[2022-03-29 08:15:00 | train] - Train Epoch: [22] [1203200/1281167 (94%)]	Loss: 1.847096
[2022-03-29 08:15:23 | train] - Train Epoch: [22] [1216000/1281167 (95%)]	Loss: 1.468149
[2022-03-29 08:15:46 | train] - Train Epoch: [22] [1228800/1281167 (96%)]	Loss: 1.775225
[2022-03-29 08:16:09 | train] - Train Epoch: [22] [1241600/1281167 (97%)]	Loss: 1.364854
[2022-03-29 08:16:32 | train] - Train Epoch: [22] [1254400/1281167 (98%)]	Loss: 1.648324
[2022-03-29 08:16:55 | train] - Train Epoch: [22] [1267200/1281167 (99%)]	Loss: 1.637682
[2022-03-29 08:17:18 | train] - Train Epoch: [22] [1280000/1281167 (100%)]	Loss: 1.790562
[2022-03-29 08:17:21 | train] - Train Epoch: [22]	 Average Loss: 1.674071	 Total Acc : 61.1437	 Total Top5 Acc : 82.1907
[2022-03-29 08:17:23 | train] - -------22 epoch end-----------
========================================
-------22 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 08:19:05 | train] - 
Epoch [22] Test set: Average loss: 1.5009, Accuracy: 32078/50000 (64.1184%), Top-5 Accuracy: 85.5874%

[2022-03-29 08:19:05 | train] - save intermediate epoch [22] result


[2022-03-29 08:19:09 | train] - logging best performance 22 epoch
[2022-03-29 08:19:10 | train] - -------23 epoch start-----------
========================================
----- test end -------------------------


logging best performance 22 epoch
[2022-03-29 08:19:12 | train] - Train Epoch: [23] [0/1281167 (0%)]	Loss: 1.413567
[2022-03-29 08:19:36 | train] - Train Epoch: [23] [12800/1281167 (1%)]	Loss: 1.462708
[2022-03-29 08:19:59 | train] - Train Epoch: [23] [25600/1281167 (2%)]	Loss: 1.662346
[2022-03-29 08:20:22 | train] - Train Epoch: [23] [38400/1281167 (3%)]	Loss: 1.889145
[2022-03-29 08:20:45 | train] - Train Epoch: [23] [51200/1281167 (4%)]	Loss: 1.666843
[2022-03-29 08:21:08 | train] - Train Epoch: [23] [64000/1281167 (5%)]	Loss: 1.321064
[2022-03-29 08:21:31 | train] - Train Epoch: [23] [76800/1281167 (6%)]	Loss: 1.387999
[2022-03-29 08:21:53 | train] - Train Epoch: [23] [89600/1281167 (7%)]	Loss: 1.618169
[2022-03-29 08:22:15 | train] - Train Epoch: [23] [102400/1281167 (8%)]	Loss: 2.051200
[2022-03-29 08:22:38 | train] - Train Epoch: [23] [115200/1281167 (9%)]	Loss: 1.629178
[2022-03-29 08:23:01 | train] - Train Epoch: [23] [128000/1281167 (10%)]	Loss: 1.760707
[2022-03-29 08:23:24 | train] - Train Epoch: [23] [140800/1281167 (11%)]	Loss: 1.572224
[2022-03-29 08:23:47 | train] - Train Epoch: [23] [153600/1281167 (12%)]	Loss: 2.092922
[2022-03-29 08:24:10 | train] - Train Epoch: [23] [166400/1281167 (13%)]	Loss: 1.440445
[2022-03-29 08:24:32 | train] - Train Epoch: [23] [179200/1281167 (14%)]	Loss: 1.987623
[2022-03-29 08:24:55 | train] - Train Epoch: [23] [192000/1281167 (15%)]	Loss: 1.630768
[2022-03-29 08:25:18 | train] - Train Epoch: [23] [204800/1281167 (16%)]	Loss: 1.369070
[2022-03-29 08:25:41 | train] - Train Epoch: [23] [217600/1281167 (17%)]	Loss: 1.426797
[2022-03-29 08:26:04 | train] - Train Epoch: [23] [230400/1281167 (18%)]	Loss: 1.609110
[2022-03-29 08:26:27 | train] - Train Epoch: [23] [243200/1281167 (19%)]	Loss: 1.436852
[2022-03-29 08:26:49 | train] - Train Epoch: [23] [256000/1281167 (20%)]	Loss: 1.427351
[2022-03-29 08:27:12 | train] - Train Epoch: [23] [268800/1281167 (21%)]	Loss: 1.822834
[2022-03-29 08:27:35 | train] - Train Epoch: [23] [281600/1281167 (22%)]	Loss: 1.708913
[2022-03-29 08:27:58 | train] - Train Epoch: [23] [294400/1281167 (23%)]	Loss: 1.676165
[2022-03-29 08:28:20 | train] - Train Epoch: [23] [307200/1281167 (24%)]	Loss: 1.534596
[2022-03-29 08:28:44 | train] - Train Epoch: [23] [320000/1281167 (25%)]	Loss: 1.355648
[2022-03-29 08:29:06 | train] - Train Epoch: [23] [332800/1281167 (26%)]	Loss: 1.619300
[2022-03-29 08:29:29 | train] - Train Epoch: [23] [345600/1281167 (27%)]	Loss: 1.394488
[2022-03-29 08:29:51 | train] - Train Epoch: [23] [358400/1281167 (28%)]	Loss: 1.515419
[2022-03-29 08:30:14 | train] - Train Epoch: [23] [371200/1281167 (29%)]	Loss: 1.637206
[2022-03-29 08:30:36 | train] - Train Epoch: [23] [384000/1281167 (30%)]	Loss: 1.410661
[2022-03-29 08:30:59 | train] - Train Epoch: [23] [396800/1281167 (31%)]	Loss: 1.625806
[2022-03-29 08:31:21 | train] - Train Epoch: [23] [409600/1281167 (32%)]	Loss: 1.968852
[2022-03-29 08:31:44 | train] - Train Epoch: [23] [422400/1281167 (33%)]	Loss: 1.484428
[2022-03-29 08:32:07 | train] - Train Epoch: [23] [435200/1281167 (34%)]	Loss: 1.722530
[2022-03-29 08:32:29 | train] - Train Epoch: [23] [448000/1281167 (35%)]	Loss: 1.959300
[2022-03-29 08:32:52 | train] - Train Epoch: [23] [460800/1281167 (36%)]	Loss: 1.642647
[2022-03-29 08:33:15 | train] - Train Epoch: [23] [473600/1281167 (37%)]	Loss: 1.866178
[2022-03-29 08:33:37 | train] - Train Epoch: [23] [486400/1281167 (38%)]	Loss: 1.331819
[2022-03-29 08:34:00 | train] - Train Epoch: [23] [499200/1281167 (39%)]	Loss: 1.462672
[2022-03-29 08:34:22 | train] - Train Epoch: [23] [512000/1281167 (40%)]	Loss: 1.793078
[2022-03-29 08:34:45 | train] - Train Epoch: [23] [524800/1281167 (41%)]	Loss: 1.611673
[2022-03-29 08:35:09 | train] - Train Epoch: [23] [537600/1281167 (42%)]	Loss: 1.743793
[2022-03-29 08:35:33 | train] - Train Epoch: [23] [550400/1281167 (43%)]	Loss: 1.650778
[2022-03-29 08:35:55 | train] - Train Epoch: [23] [563200/1281167 (44%)]	Loss: 1.585172
[2022-03-29 08:36:18 | train] - Train Epoch: [23] [576000/1281167 (45%)]	Loss: 1.927750
[2022-03-29 08:36:41 | train] - Train Epoch: [23] [588800/1281167 (46%)]	Loss: 1.652820
[2022-03-29 08:37:04 | train] - Train Epoch: [23] [601600/1281167 (47%)]	Loss: 1.802625
[2022-03-29 08:37:27 | train] - Train Epoch: [23] [614400/1281167 (48%)]	Loss: 1.897735
[2022-03-29 08:37:49 | train] - Train Epoch: [23] [627200/1281167 (49%)]	Loss: 1.407890
[2022-03-29 08:38:11 | train] - Train Epoch: [23] [640000/1281167 (50%)]	Loss: 1.534305
[2022-03-29 08:38:34 | train] - Train Epoch: [23] [652800/1281167 (51%)]	Loss: 1.863663
[2022-03-29 08:38:58 | train] - Train Epoch: [23] [665600/1281167 (52%)]	Loss: 1.484666
[2022-03-29 08:39:20 | train] - Train Epoch: [23] [678400/1281167 (53%)]	Loss: 2.089035
[2022-03-29 08:39:43 | train] - Train Epoch: [23] [691200/1281167 (54%)]	Loss: 1.717887
[2022-03-29 08:40:07 | train] - Train Epoch: [23] [704000/1281167 (55%)]	Loss: 1.828406
[2022-03-29 08:40:30 | train] - Train Epoch: [23] [716800/1281167 (56%)]	Loss: 1.555686
[2022-03-29 08:40:52 | train] - Train Epoch: [23] [729600/1281167 (57%)]	Loss: 1.328694
[2022-03-29 08:41:15 | train] - Train Epoch: [23] [742400/1281167 (58%)]	Loss: 1.586702
[2022-03-29 08:41:38 | train] - Train Epoch: [23] [755200/1281167 (59%)]	Loss: 1.741538
[2022-03-29 08:42:01 | train] - Train Epoch: [23] [768000/1281167 (60%)]	Loss: 1.730112
[2022-03-29 08:42:24 | train] - Train Epoch: [23] [780800/1281167 (61%)]	Loss: 1.753421
[2022-03-29 08:42:46 | train] - Train Epoch: [23] [793600/1281167 (62%)]	Loss: 1.728233
[2022-03-29 08:43:09 | train] - Train Epoch: [23] [806400/1281167 (63%)]	Loss: 1.781708
[2022-03-29 08:43:32 | train] - Train Epoch: [23] [819200/1281167 (64%)]	Loss: 1.413777
[2022-03-29 08:43:55 | train] - Train Epoch: [23] [832000/1281167 (65%)]	Loss: 1.667434
[2022-03-29 08:44:17 | train] - Train Epoch: [23] [844800/1281167 (66%)]	Loss: 1.854353
[2022-03-29 08:44:40 | train] - Train Epoch: [23] [857600/1281167 (67%)]	Loss: 1.612804
[2022-03-29 08:45:03 | train] - Train Epoch: [23] [870400/1281167 (68%)]	Loss: 1.516784
[2022-03-29 08:45:25 | train] - Train Epoch: [23] [883200/1281167 (69%)]	Loss: 1.580894
[2022-03-29 08:45:47 | train] - Train Epoch: [23] [896000/1281167 (70%)]	Loss: 1.677457
[2022-03-29 08:46:10 | train] - Train Epoch: [23] [908800/1281167 (71%)]	Loss: 1.752092
[2022-03-29 08:46:33 | train] - Train Epoch: [23] [921600/1281167 (72%)]	Loss: 1.741691
[2022-03-29 08:46:56 | train] - Train Epoch: [23] [934400/1281167 (73%)]	Loss: 1.580076
[2022-03-29 08:47:18 | train] - Train Epoch: [23] [947200/1281167 (74%)]	Loss: 1.476115
[2022-03-29 08:47:40 | train] - Train Epoch: [23] [960000/1281167 (75%)]	Loss: 1.724974
[2022-03-29 08:48:03 | train] - Train Epoch: [23] [972800/1281167 (76%)]	Loss: 1.424252
[2022-03-29 08:48:27 | train] - Train Epoch: [23] [985600/1281167 (77%)]	Loss: 1.593932
[2022-03-29 08:48:49 | train] - Train Epoch: [23] [998400/1281167 (78%)]	Loss: 1.681210
[2022-03-29 08:49:11 | train] - Train Epoch: [23] [1011200/1281167 (79%)]	Loss: 1.755661
[2022-03-29 08:49:35 | train] - Train Epoch: [23] [1024000/1281167 (80%)]	Loss: 1.595534
[2022-03-29 08:49:58 | train] - Train Epoch: [23] [1036800/1281167 (81%)]	Loss: 1.342578
[2022-03-29 08:50:20 | train] - Train Epoch: [23] [1049600/1281167 (82%)]	Loss: 1.471774
[2022-03-29 08:50:44 | train] - Train Epoch: [23] [1062400/1281167 (83%)]	Loss: 1.215898
[2022-03-29 08:51:07 | train] - Train Epoch: [23] [1075200/1281167 (84%)]	Loss: 1.526980
[2022-03-29 08:51:30 | train] - Train Epoch: [23] [1088000/1281167 (85%)]	Loss: 1.576274
[2022-03-29 08:51:52 | train] - Train Epoch: [23] [1100800/1281167 (86%)]	Loss: 1.722122
[2022-03-29 08:52:16 | train] - Train Epoch: [23] [1113600/1281167 (87%)]	Loss: 1.614382
[2022-03-29 08:52:39 | train] - Train Epoch: [23] [1126400/1281167 (88%)]	Loss: 1.407722
[2022-03-29 08:53:01 | train] - Train Epoch: [23] [1139200/1281167 (89%)]	Loss: 1.673002
[2022-03-29 08:53:24 | train] - Train Epoch: [23] [1152000/1281167 (90%)]	Loss: 1.741575
[2022-03-29 08:53:47 | train] - Train Epoch: [23] [1164800/1281167 (91%)]	Loss: 1.876101
[2022-03-29 08:54:10 | train] - Train Epoch: [23] [1177600/1281167 (92%)]	Loss: 1.913821
[2022-03-29 08:54:33 | train] - Train Epoch: [23] [1190400/1281167 (93%)]	Loss: 1.575137
[2022-03-29 08:54:56 | train] - Train Epoch: [23] [1203200/1281167 (94%)]	Loss: 1.772317
[2022-03-29 08:55:19 | train] - Train Epoch: [23] [1216000/1281167 (95%)]	Loss: 1.514634
[2022-03-29 08:55:42 | train] - Train Epoch: [23] [1228800/1281167 (96%)]	Loss: 1.887740
[2022-03-29 08:56:04 | train] - Train Epoch: [23] [1241600/1281167 (97%)]	Loss: 1.514507
[2022-03-29 08:56:27 | train] - Train Epoch: [23] [1254400/1281167 (98%)]	Loss: 1.792102
[2022-03-29 08:56:49 | train] - Train Epoch: [23] [1267200/1281167 (99%)]	Loss: 1.768152
[2022-03-29 08:57:13 | train] - Train Epoch: [23] [1280000/1281167 (100%)]	Loss: 1.510327
[2022-03-29 08:57:15 | train] - Train Epoch: [23]	 Average Loss: 1.645533	 Total Acc : 61.7908	 Total Top5 Acc : 82.6037
[2022-03-29 08:57:17 | train] - -------23 epoch end-----------
========================================
-------23 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 08:59:00 | train] - 
Epoch [23] Test set: Average loss: 1.4879, Accuracy: 32293/50000 (64.5588%), Top-5 Accuracy: 86.1093%

[2022-03-29 08:59:00 | train] - save intermediate epoch [23] result


[2022-03-29 08:59:04 | train] - logging best performance 23 epoch
[2022-03-29 08:59:05 | train] - -------24 epoch start-----------
========================================
----- test end -------------------------


logging best performance 23 epoch
[2022-03-29 08:59:08 | train] - Train Epoch: [24] [0/1281167 (0%)]	Loss: 1.757693
[2022-03-29 08:59:31 | train] - Train Epoch: [24] [12800/1281167 (1%)]	Loss: 1.618804
[2022-03-29 08:59:53 | train] - Train Epoch: [24] [25600/1281167 (2%)]	Loss: 1.847449
[2022-03-29 09:00:16 | train] - Train Epoch: [24] [38400/1281167 (3%)]	Loss: 1.820687
[2022-03-29 09:00:38 | train] - Train Epoch: [24] [51200/1281167 (4%)]	Loss: 1.300145
[2022-03-29 09:01:01 | train] - Train Epoch: [24] [64000/1281167 (5%)]	Loss: 1.891976
[2022-03-29 09:01:23 | train] - Train Epoch: [24] [76800/1281167 (6%)]	Loss: 1.603613
[2022-03-29 09:01:45 | train] - Train Epoch: [24] [89600/1281167 (7%)]	Loss: 1.367153
[2022-03-29 09:02:08 | train] - Train Epoch: [24] [102400/1281167 (8%)]	Loss: 1.529755
[2022-03-29 09:02:30 | train] - Train Epoch: [24] [115200/1281167 (9%)]	Loss: 1.524631
[2022-03-29 09:02:52 | train] - Train Epoch: [24] [128000/1281167 (10%)]	Loss: 1.502315
[2022-03-29 09:03:15 | train] - Train Epoch: [24] [140800/1281167 (11%)]	Loss: 1.678742
[2022-03-29 09:03:37 | train] - Train Epoch: [24] [153600/1281167 (12%)]	Loss: 1.571414
[2022-03-29 09:03:59 | train] - Train Epoch: [24] [166400/1281167 (13%)]	Loss: 1.738555
[2022-03-29 09:04:22 | train] - Train Epoch: [24] [179200/1281167 (14%)]	Loss: 1.433295
[2022-03-29 09:04:45 | train] - Train Epoch: [24] [192000/1281167 (15%)]	Loss: 1.521318
[2022-03-29 09:05:07 | train] - Train Epoch: [24] [204800/1281167 (16%)]	Loss: 1.799764
[2022-03-29 09:05:30 | train] - Train Epoch: [24] [217600/1281167 (17%)]	Loss: 1.588233
[2022-03-29 09:05:52 | train] - Train Epoch: [24] [230400/1281167 (18%)]	Loss: 1.402837
[2022-03-29 09:06:14 | train] - Train Epoch: [24] [243200/1281167 (19%)]	Loss: 1.582432
[2022-03-29 09:06:37 | train] - Train Epoch: [24] [256000/1281167 (20%)]	Loss: 1.844592
[2022-03-29 09:06:59 | train] - Train Epoch: [24] [268800/1281167 (21%)]	Loss: 1.662804
[2022-03-29 09:07:22 | train] - Train Epoch: [24] [281600/1281167 (22%)]	Loss: 1.543829
[2022-03-29 09:07:44 | train] - Train Epoch: [24] [294400/1281167 (23%)]	Loss: 1.922179
[2022-03-29 09:08:07 | train] - Train Epoch: [24] [307200/1281167 (24%)]	Loss: 1.889887
[2022-03-29 09:08:29 | train] - Train Epoch: [24] [320000/1281167 (25%)]	Loss: 1.497404
[2022-03-29 09:08:51 | train] - Train Epoch: [24] [332800/1281167 (26%)]	Loss: 1.619442
[2022-03-29 09:09:14 | train] - Train Epoch: [24] [345600/1281167 (27%)]	Loss: 1.574092
[2022-03-29 09:09:37 | train] - Train Epoch: [24] [358400/1281167 (28%)]	Loss: 2.023671
[2022-03-29 09:09:59 | train] - Train Epoch: [24] [371200/1281167 (29%)]	Loss: 1.898592
[2022-03-29 09:10:21 | train] - Train Epoch: [24] [384000/1281167 (30%)]	Loss: 1.220608
[2022-03-29 09:10:44 | train] - Train Epoch: [24] [396800/1281167 (31%)]	Loss: 1.618841
[2022-03-29 09:11:06 | train] - Train Epoch: [24] [409600/1281167 (32%)]	Loss: 1.494244
[2022-03-29 09:11:28 | train] - Train Epoch: [24] [422400/1281167 (33%)]	Loss: 1.561693
[2022-03-29 09:11:50 | train] - Train Epoch: [24] [435200/1281167 (34%)]	Loss: 1.826272
[2022-03-29 09:12:13 | train] - Train Epoch: [24] [448000/1281167 (35%)]	Loss: 1.502962
[2022-03-29 09:12:35 | train] - Train Epoch: [24] [460800/1281167 (36%)]	Loss: 1.362150
[2022-03-29 09:12:57 | train] - Train Epoch: [24] [473600/1281167 (37%)]	Loss: 1.741823
[2022-03-29 09:13:20 | train] - Train Epoch: [24] [486400/1281167 (38%)]	Loss: 1.424670
[2022-03-29 09:13:43 | train] - Train Epoch: [24] [499200/1281167 (39%)]	Loss: 1.493464
[2022-03-29 09:14:05 | train] - Train Epoch: [24] [512000/1281167 (40%)]	Loss: 1.731737
[2022-03-29 09:14:28 | train] - Train Epoch: [24] [524800/1281167 (41%)]	Loss: 1.786180
[2022-03-29 09:14:51 | train] - Train Epoch: [24] [537600/1281167 (42%)]	Loss: 1.693586
[2022-03-29 09:15:13 | train] - Train Epoch: [24] [550400/1281167 (43%)]	Loss: 1.674491
[2022-03-29 09:15:36 | train] - Train Epoch: [24] [563200/1281167 (44%)]	Loss: 1.789366
[2022-03-29 09:15:59 | train] - Train Epoch: [24] [576000/1281167 (45%)]	Loss: 1.822648
[2022-03-29 09:16:21 | train] - Train Epoch: [24] [588800/1281167 (46%)]	Loss: 1.425592
[2022-03-29 09:16:43 | train] - Train Epoch: [24] [601600/1281167 (47%)]	Loss: 1.682968
[2022-03-29 09:17:06 | train] - Train Epoch: [24] [614400/1281167 (48%)]	Loss: 1.891729
[2022-03-29 09:17:28 | train] - Train Epoch: [24] [627200/1281167 (49%)]	Loss: 1.496727
[2022-03-29 09:17:50 | train] - Train Epoch: [24] [640000/1281167 (50%)]	Loss: 1.220682
[2022-03-29 09:18:13 | train] - Train Epoch: [24] [652800/1281167 (51%)]	Loss: 1.828744
[2022-03-29 09:18:35 | train] - Train Epoch: [24] [665600/1281167 (52%)]	Loss: 1.472545
[2022-03-29 09:18:57 | train] - Train Epoch: [24] [678400/1281167 (53%)]	Loss: 1.464661
[2022-03-29 09:19:20 | train] - Train Epoch: [24] [691200/1281167 (54%)]	Loss: 1.646077
[2022-03-29 09:19:42 | train] - Train Epoch: [24] [704000/1281167 (55%)]	Loss: 1.720696
[2022-03-29 09:20:04 | train] - Train Epoch: [24] [716800/1281167 (56%)]	Loss: 1.857591
[2022-03-29 09:20:27 | train] - Train Epoch: [24] [729600/1281167 (57%)]	Loss: 2.002949
[2022-03-29 09:20:49 | train] - Train Epoch: [24] [742400/1281167 (58%)]	Loss: 1.925319
[2022-03-29 09:21:11 | train] - Train Epoch: [24] [755200/1281167 (59%)]	Loss: 1.618234
[2022-03-29 09:21:34 | train] - Train Epoch: [24] [768000/1281167 (60%)]	Loss: 1.807158
[2022-03-29 09:21:56 | train] - Train Epoch: [24] [780800/1281167 (61%)]	Loss: 1.936179
[2022-03-29 09:22:19 | train] - Train Epoch: [24] [793600/1281167 (62%)]	Loss: 1.804221
[2022-03-29 09:22:41 | train] - Train Epoch: [24] [806400/1281167 (63%)]	Loss: 1.367577
[2022-03-29 09:23:04 | train] - Train Epoch: [24] [819200/1281167 (64%)]	Loss: 1.493809
[2022-03-29 09:23:27 | train] - Train Epoch: [24] [832000/1281167 (65%)]	Loss: 1.998706
[2022-03-29 09:23:49 | train] - Train Epoch: [24] [844800/1281167 (66%)]	Loss: 1.633520
[2022-03-29 09:24:12 | train] - Train Epoch: [24] [857600/1281167 (67%)]	Loss: 1.520717
[2022-03-29 09:24:34 | train] - Train Epoch: [24] [870400/1281167 (68%)]	Loss: 1.481450
[2022-03-29 09:24:57 | train] - Train Epoch: [24] [883200/1281167 (69%)]	Loss: 1.365379
[2022-03-29 09:25:19 | train] - Train Epoch: [24] [896000/1281167 (70%)]	Loss: 1.681385
[2022-03-29 09:25:42 | train] - Train Epoch: [24] [908800/1281167 (71%)]	Loss: 1.560567
[2022-03-29 09:26:04 | train] - Train Epoch: [24] [921600/1281167 (72%)]	Loss: 1.480632
[2022-03-29 09:26:26 | train] - Train Epoch: [24] [934400/1281167 (73%)]	Loss: 1.697573
[2022-03-29 09:26:48 | train] - Train Epoch: [24] [947200/1281167 (74%)]	Loss: 1.787324
[2022-03-29 09:27:10 | train] - Train Epoch: [24] [960000/1281167 (75%)]	Loss: 1.449390
[2022-03-29 09:27:32 | train] - Train Epoch: [24] [972800/1281167 (76%)]	Loss: 1.601328
[2022-03-29 09:27:55 | train] - Train Epoch: [24] [985600/1281167 (77%)]	Loss: 1.389915
[2022-03-29 09:28:18 | train] - Train Epoch: [24] [998400/1281167 (78%)]	Loss: 1.378394
[2022-03-29 09:28:40 | train] - Train Epoch: [24] [1011200/1281167 (79%)]	Loss: 1.503593
[2022-03-29 09:29:03 | train] - Train Epoch: [24] [1024000/1281167 (80%)]	Loss: 1.276682
[2022-03-29 09:29:25 | train] - Train Epoch: [24] [1036800/1281167 (81%)]	Loss: 1.312702
[2022-03-29 09:29:47 | train] - Train Epoch: [24] [1049600/1281167 (82%)]	Loss: 1.627183
[2022-03-29 09:30:11 | train] - Train Epoch: [24] [1062400/1281167 (83%)]	Loss: 1.340872
[2022-03-29 09:30:33 | train] - Train Epoch: [24] [1075200/1281167 (84%)]	Loss: 1.515240
[2022-03-29 09:30:55 | train] - Train Epoch: [24] [1088000/1281167 (85%)]	Loss: 1.382288
[2022-03-29 09:31:18 | train] - Train Epoch: [24] [1100800/1281167 (86%)]	Loss: 1.394415
[2022-03-29 09:31:41 | train] - Train Epoch: [24] [1113600/1281167 (87%)]	Loss: 1.684003
[2022-03-29 09:32:03 | train] - Train Epoch: [24] [1126400/1281167 (88%)]	Loss: 1.993273
[2022-03-29 09:32:25 | train] - Train Epoch: [24] [1139200/1281167 (89%)]	Loss: 1.441013
[2022-03-29 09:32:48 | train] - Train Epoch: [24] [1152000/1281167 (90%)]	Loss: 1.952624
[2022-03-29 09:33:10 | train] - Train Epoch: [24] [1164800/1281167 (91%)]	Loss: 1.802688
[2022-03-29 09:33:32 | train] - Train Epoch: [24] [1177600/1281167 (92%)]	Loss: 1.596114
[2022-03-29 09:33:55 | train] - Train Epoch: [24] [1190400/1281167 (93%)]	Loss: 1.599444
[2022-03-29 09:34:17 | train] - Train Epoch: [24] [1203200/1281167 (94%)]	Loss: 1.543523
[2022-03-29 09:34:40 | train] - Train Epoch: [24] [1216000/1281167 (95%)]	Loss: 1.509140
[2022-03-29 09:35:02 | train] - Train Epoch: [24] [1228800/1281167 (96%)]	Loss: 1.607976
[2022-03-29 09:35:25 | train] - Train Epoch: [24] [1241600/1281167 (97%)]	Loss: 1.544897
[2022-03-29 09:35:48 | train] - Train Epoch: [24] [1254400/1281167 (98%)]	Loss: 1.769505
[2022-03-29 09:36:11 | train] - Train Epoch: [24] [1267200/1281167 (99%)]	Loss: 1.635622
[2022-03-29 09:36:33 | train] - Train Epoch: [24] [1280000/1281167 (100%)]	Loss: 1.779126
[2022-03-29 09:36:35 | train] - Train Epoch: [24]	 Average Loss: 1.619973	 Total Acc : 62.2821	 Total Top5 Acc : 82.9696
[2022-03-29 09:36:38 | train] - -------24 epoch end-----------
========================================
-------24 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 09:38:19 | train] - 
Epoch [24] Test set: Average loss: 1.4894, Accuracy: 32142/50000 (64.2595%), Top-5 Accuracy: 85.9407%

[2022-03-29 09:38:19 | train] - save intermediate epoch [24] result


[2022-03-29 09:38:25 | train] - -------25 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 09:38:27 | train] - Train Epoch: [25] [0/1281167 (0%)]	Loss: 1.572810
[2022-03-29 09:38:51 | train] - Train Epoch: [25] [12800/1281167 (1%)]	Loss: 1.664840
[2022-03-29 09:39:14 | train] - Train Epoch: [25] [25600/1281167 (2%)]	Loss: 1.495576
[2022-03-29 09:39:36 | train] - Train Epoch: [25] [38400/1281167 (3%)]	Loss: 1.605989
[2022-03-29 09:39:58 | train] - Train Epoch: [25] [51200/1281167 (4%)]	Loss: 1.834725
[2022-03-29 09:40:19 | train] - Train Epoch: [25] [64000/1281167 (5%)]	Loss: 1.689638
[2022-03-29 09:40:42 | train] - Train Epoch: [25] [76800/1281167 (6%)]	Loss: 1.466432
[2022-03-29 09:41:04 | train] - Train Epoch: [25] [89600/1281167 (7%)]	Loss: 1.697428
[2022-03-29 09:41:25 | train] - Train Epoch: [25] [102400/1281167 (8%)]	Loss: 1.702867
[2022-03-29 09:41:47 | train] - Train Epoch: [25] [115200/1281167 (9%)]	Loss: 1.562971
[2022-03-29 09:42:10 | train] - Train Epoch: [25] [128000/1281167 (10%)]	Loss: 1.582568
[2022-03-29 09:42:32 | train] - Train Epoch: [25] [140800/1281167 (11%)]	Loss: 1.459425
[2022-03-29 09:42:54 | train] - Train Epoch: [25] [153600/1281167 (12%)]	Loss: 1.706983
[2022-03-29 09:43:16 | train] - Train Epoch: [25] [166400/1281167 (13%)]	Loss: 1.276083
[2022-03-29 09:43:38 | train] - Train Epoch: [25] [179200/1281167 (14%)]	Loss: 2.048338
[2022-03-29 09:44:00 | train] - Train Epoch: [25] [192000/1281167 (15%)]	Loss: 1.611970
[2022-03-29 09:44:22 | train] - Train Epoch: [25] [204800/1281167 (16%)]	Loss: 1.984628
[2022-03-29 09:44:45 | train] - Train Epoch: [25] [217600/1281167 (17%)]	Loss: 1.455065
[2022-03-29 09:45:07 | train] - Train Epoch: [25] [230400/1281167 (18%)]	Loss: 1.535813
[2022-03-29 09:45:30 | train] - Train Epoch: [25] [243200/1281167 (19%)]	Loss: 1.689840
[2022-03-29 09:45:52 | train] - Train Epoch: [25] [256000/1281167 (20%)]	Loss: 1.697924
[2022-03-29 09:46:15 | train] - Train Epoch: [25] [268800/1281167 (21%)]	Loss: 2.004133
[2022-03-29 09:46:37 | train] - Train Epoch: [25] [281600/1281167 (22%)]	Loss: 1.692612
[2022-03-29 09:47:00 | train] - Train Epoch: [25] [294400/1281167 (23%)]	Loss: 1.807976
[2022-03-29 09:47:22 | train] - Train Epoch: [25] [307200/1281167 (24%)]	Loss: 1.914254
[2022-03-29 09:47:44 | train] - Train Epoch: [25] [320000/1281167 (25%)]	Loss: 1.699624
[2022-03-29 09:48:06 | train] - Train Epoch: [25] [332800/1281167 (26%)]	Loss: 1.452690
[2022-03-29 09:48:28 | train] - Train Epoch: [25] [345600/1281167 (27%)]	Loss: 1.534325
[2022-03-29 09:48:50 | train] - Train Epoch: [25] [358400/1281167 (28%)]	Loss: 1.470292
[2022-03-29 09:49:12 | train] - Train Epoch: [25] [371200/1281167 (29%)]	Loss: 1.857520
[2022-03-29 09:49:35 | train] - Train Epoch: [25] [384000/1281167 (30%)]	Loss: 1.449756
[2022-03-29 09:49:57 | train] - Train Epoch: [25] [396800/1281167 (31%)]	Loss: 1.477320
[2022-03-29 09:50:19 | train] - Train Epoch: [25] [409600/1281167 (32%)]	Loss: 1.533659
[2022-03-29 09:50:42 | train] - Train Epoch: [25] [422400/1281167 (33%)]	Loss: 1.528533
[2022-03-29 09:51:03 | train] - Train Epoch: [25] [435200/1281167 (34%)]	Loss: 1.859926
[2022-03-29 09:51:26 | train] - Train Epoch: [25] [448000/1281167 (35%)]	Loss: 1.502812
[2022-03-29 09:51:48 | train] - Train Epoch: [25] [460800/1281167 (36%)]	Loss: 1.757481
[2022-03-29 09:52:10 | train] - Train Epoch: [25] [473600/1281167 (37%)]	Loss: 1.559822
[2022-03-29 09:52:32 | train] - Train Epoch: [25] [486400/1281167 (38%)]	Loss: 1.624854
[2022-03-29 09:52:54 | train] - Train Epoch: [25] [499200/1281167 (39%)]	Loss: 1.695820
[2022-03-29 09:53:16 | train] - Train Epoch: [25] [512000/1281167 (40%)]	Loss: 1.765938
[2022-03-29 09:53:39 | train] - Train Epoch: [25] [524800/1281167 (41%)]	Loss: 1.654905
[2022-03-29 09:54:01 | train] - Train Epoch: [25] [537600/1281167 (42%)]	Loss: 1.652414
[2022-03-29 09:54:23 | train] - Train Epoch: [25] [550400/1281167 (43%)]	Loss: 1.198845
[2022-03-29 09:54:45 | train] - Train Epoch: [25] [563200/1281167 (44%)]	Loss: 1.563865
[2022-03-29 09:55:08 | train] - Train Epoch: [25] [576000/1281167 (45%)]	Loss: 1.637579
[2022-03-29 09:55:30 | train] - Train Epoch: [25] [588800/1281167 (46%)]	Loss: 1.498051
[2022-03-29 09:55:51 | train] - Train Epoch: [25] [601600/1281167 (47%)]	Loss: 1.741985
[2022-03-29 09:56:13 | train] - Train Epoch: [25] [614400/1281167 (48%)]	Loss: 1.697477
[2022-03-29 09:56:35 | train] - Train Epoch: [25] [627200/1281167 (49%)]	Loss: 1.466716
[2022-03-29 09:56:58 | train] - Train Epoch: [25] [640000/1281167 (50%)]	Loss: 1.534151
[2022-03-29 09:57:20 | train] - Train Epoch: [25] [652800/1281167 (51%)]	Loss: 1.794033
[2022-03-29 09:57:42 | train] - Train Epoch: [25] [665600/1281167 (52%)]	Loss: 1.436479
[2022-03-29 09:58:05 | train] - Train Epoch: [25] [678400/1281167 (53%)]	Loss: 1.555664
[2022-03-29 09:58:27 | train] - Train Epoch: [25] [691200/1281167 (54%)]	Loss: 1.378303
[2022-03-29 09:58:49 | train] - Train Epoch: [25] [704000/1281167 (55%)]	Loss: 1.981752
[2022-03-29 09:59:11 | train] - Train Epoch: [25] [716800/1281167 (56%)]	Loss: 1.565862
[2022-03-29 09:59:33 | train] - Train Epoch: [25] [729600/1281167 (57%)]	Loss: 1.863094
[2022-03-29 09:59:54 | train] - Train Epoch: [25] [742400/1281167 (58%)]	Loss: 1.735520
[2022-03-29 10:00:16 | train] - Train Epoch: [25] [755200/1281167 (59%)]	Loss: 1.566873
[2022-03-29 10:00:38 | train] - Train Epoch: [25] [768000/1281167 (60%)]	Loss: 1.563408
[2022-03-29 10:01:00 | train] - Train Epoch: [25] [780800/1281167 (61%)]	Loss: 1.385453
[2022-03-29 10:01:22 | train] - Train Epoch: [25] [793600/1281167 (62%)]	Loss: 1.855579
[2022-03-29 10:01:44 | train] - Train Epoch: [25] [806400/1281167 (63%)]	Loss: 1.772265
[2022-03-29 10:02:07 | train] - Train Epoch: [25] [819200/1281167 (64%)]	Loss: 1.911304
[2022-03-29 10:02:29 | train] - Train Epoch: [25] [832000/1281167 (65%)]	Loss: 1.736660
[2022-03-29 10:02:52 | train] - Train Epoch: [25] [844800/1281167 (66%)]	Loss: 1.486306
[2022-03-29 10:03:14 | train] - Train Epoch: [25] [857600/1281167 (67%)]	Loss: 1.657770
[2022-03-29 10:03:36 | train] - Train Epoch: [25] [870400/1281167 (68%)]	Loss: 1.929208
[2022-03-29 10:03:59 | train] - Train Epoch: [25] [883200/1281167 (69%)]	Loss: 1.615612
[2022-03-29 10:04:21 | train] - Train Epoch: [25] [896000/1281167 (70%)]	Loss: 1.897008
[2022-03-29 10:04:43 | train] - Train Epoch: [25] [908800/1281167 (71%)]	Loss: 1.618297
[2022-03-29 10:05:06 | train] - Train Epoch: [25] [921600/1281167 (72%)]	Loss: 1.548119
[2022-03-29 10:05:28 | train] - Train Epoch: [25] [934400/1281167 (73%)]	Loss: 1.386852
[2022-03-29 10:05:50 | train] - Train Epoch: [25] [947200/1281167 (74%)]	Loss: 1.789172
[2022-03-29 10:06:12 | train] - Train Epoch: [25] [960000/1281167 (75%)]	Loss: 1.363623
[2022-03-29 10:06:34 | train] - Train Epoch: [25] [972800/1281167 (76%)]	Loss: 1.505856
[2022-03-29 10:06:56 | train] - Train Epoch: [25] [985600/1281167 (77%)]	Loss: 1.748852
[2022-03-29 10:07:19 | train] - Train Epoch: [25] [998400/1281167 (78%)]	Loss: 1.661490
[2022-03-29 10:07:41 | train] - Train Epoch: [25] [1011200/1281167 (79%)]	Loss: 1.367331
[2022-03-29 10:08:04 | train] - Train Epoch: [25] [1024000/1281167 (80%)]	Loss: 1.779693
[2022-03-29 10:08:26 | train] - Train Epoch: [25] [1036800/1281167 (81%)]	Loss: 1.482743
[2022-03-29 10:08:49 | train] - Train Epoch: [25] [1049600/1281167 (82%)]	Loss: 1.993106
[2022-03-29 10:09:11 | train] - Train Epoch: [25] [1062400/1281167 (83%)]	Loss: 1.344652
[2022-03-29 10:09:33 | train] - Train Epoch: [25] [1075200/1281167 (84%)]	Loss: 1.461084
[2022-03-29 10:09:55 | train] - Train Epoch: [25] [1088000/1281167 (85%)]	Loss: 1.595557
[2022-03-29 10:10:17 | train] - Train Epoch: [25] [1100800/1281167 (86%)]	Loss: 1.415995
[2022-03-29 10:10:40 | train] - Train Epoch: [25] [1113600/1281167 (87%)]	Loss: 1.529178
[2022-03-29 10:11:02 | train] - Train Epoch: [25] [1126400/1281167 (88%)]	Loss: 1.385695
[2022-03-29 10:11:24 | train] - Train Epoch: [25] [1139200/1281167 (89%)]	Loss: 1.665239
[2022-03-29 10:11:46 | train] - Train Epoch: [25] [1152000/1281167 (90%)]	Loss: 1.726501
[2022-03-29 10:12:09 | train] - Train Epoch: [25] [1164800/1281167 (91%)]	Loss: 1.287795
[2022-03-29 10:12:30 | train] - Train Epoch: [25] [1177600/1281167 (92%)]	Loss: 1.630409
[2022-03-29 10:12:53 | train] - Train Epoch: [25] [1190400/1281167 (93%)]	Loss: 1.507238
[2022-03-29 10:13:15 | train] - Train Epoch: [25] [1203200/1281167 (94%)]	Loss: 1.389912
[2022-03-29 10:13:37 | train] - Train Epoch: [25] [1216000/1281167 (95%)]	Loss: 1.550436
[2022-03-29 10:13:59 | train] - Train Epoch: [25] [1228800/1281167 (96%)]	Loss: 1.677652
[2022-03-29 10:14:21 | train] - Train Epoch: [25] [1241600/1281167 (97%)]	Loss: 1.457975
[2022-03-29 10:14:43 | train] - Train Epoch: [25] [1254400/1281167 (98%)]	Loss: 1.219228
[2022-03-29 10:15:05 | train] - Train Epoch: [25] [1267200/1281167 (99%)]	Loss: 1.776826
[2022-03-29 10:15:27 | train] - Train Epoch: [25] [1280000/1281167 (100%)]	Loss: 1.871081
[2022-03-29 10:15:30 | train] - Train Epoch: [25]	 Average Loss: 1.596505	 Total Acc : 62.7368	 Total Top5 Acc : 83.3050
[2022-03-29 10:15:32 | train] - -------25 epoch end-----------
========================================
-------25 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 10:17:10 | train] - 
Epoch [25] Test set: Average loss: 1.4628, Accuracy: 32507/50000 (64.9852%), Top-5 Accuracy: 86.2140%

[2022-03-29 10:17:10 | train] - save intermediate epoch [25] result


[2022-03-29 10:17:15 | train] - logging best performance 25 epoch
[2022-03-29 10:17:16 | train] - -------26 epoch start-----------
========================================
----- test end -------------------------


logging best performance 25 epoch
[2022-03-29 10:17:19 | train] - Train Epoch: [26] [0/1281167 (0%)]	Loss: 1.513195
[2022-03-29 10:17:41 | train] - Train Epoch: [26] [12800/1281167 (1%)]	Loss: 1.394643
[2022-03-29 10:18:03 | train] - Train Epoch: [26] [25600/1281167 (2%)]	Loss: 1.755636
[2022-03-29 10:18:25 | train] - Train Epoch: [26] [38400/1281167 (3%)]	Loss: 1.659306
[2022-03-29 10:18:47 | train] - Train Epoch: [26] [51200/1281167 (4%)]	Loss: 1.600321
[2022-03-29 10:19:08 | train] - Train Epoch: [26] [64000/1281167 (5%)]	Loss: 1.593723
[2022-03-29 10:19:30 | train] - Train Epoch: [26] [76800/1281167 (6%)]	Loss: 2.000144
[2022-03-29 10:19:52 | train] - Train Epoch: [26] [89600/1281167 (7%)]	Loss: 1.699251
[2022-03-29 10:20:14 | train] - Train Epoch: [26] [102400/1281167 (8%)]	Loss: 1.511308
[2022-03-29 10:20:36 | train] - Train Epoch: [26] [115200/1281167 (9%)]	Loss: 1.172545
[2022-03-29 10:20:58 | train] - Train Epoch: [26] [128000/1281167 (10%)]	Loss: 1.352304
[2022-03-29 10:21:20 | train] - Train Epoch: [26] [140800/1281167 (11%)]	Loss: 1.673118
[2022-03-29 10:21:41 | train] - Train Epoch: [26] [153600/1281167 (12%)]	Loss: 1.645810
[2022-03-29 10:22:03 | train] - Train Epoch: [26] [166400/1281167 (13%)]	Loss: 2.026014
[2022-03-29 10:22:25 | train] - Train Epoch: [26] [179200/1281167 (14%)]	Loss: 1.505397
[2022-03-29 10:22:47 | train] - Train Epoch: [26] [192000/1281167 (15%)]	Loss: 1.759608
[2022-03-29 10:23:09 | train] - Train Epoch: [26] [204800/1281167 (16%)]	Loss: 1.846927
[2022-03-29 10:23:30 | train] - Train Epoch: [26] [217600/1281167 (17%)]	Loss: 1.289117
[2022-03-29 10:23:52 | train] - Train Epoch: [26] [230400/1281167 (18%)]	Loss: 1.722957
[2022-03-29 10:24:14 | train] - Train Epoch: [26] [243200/1281167 (19%)]	Loss: 1.417554
[2022-03-29 10:24:36 | train] - Train Epoch: [26] [256000/1281167 (20%)]	Loss: 1.814525
[2022-03-29 10:24:58 | train] - Train Epoch: [26] [268800/1281167 (21%)]	Loss: 1.519524
[2022-03-29 10:25:21 | train] - Train Epoch: [26] [281600/1281167 (22%)]	Loss: 1.452500
[2022-03-29 10:25:43 | train] - Train Epoch: [26] [294400/1281167 (23%)]	Loss: 1.408451
[2022-03-29 10:26:04 | train] - Train Epoch: [26] [307200/1281167 (24%)]	Loss: 1.791057
[2022-03-29 10:26:27 | train] - Train Epoch: [26] [320000/1281167 (25%)]	Loss: 1.661984
[2022-03-29 10:26:48 | train] - Train Epoch: [26] [332800/1281167 (26%)]	Loss: 1.483636
[2022-03-29 10:27:11 | train] - Train Epoch: [26] [345600/1281167 (27%)]	Loss: 1.409101
[2022-03-29 10:27:33 | train] - Train Epoch: [26] [358400/1281167 (28%)]	Loss: 1.739544
[2022-03-29 10:27:54 | train] - Train Epoch: [26] [371200/1281167 (29%)]	Loss: 1.596247
[2022-03-29 10:28:16 | train] - Train Epoch: [26] [384000/1281167 (30%)]	Loss: 1.513364
[2022-03-29 10:28:38 | train] - Train Epoch: [26] [396800/1281167 (31%)]	Loss: 1.616364
[2022-03-29 10:29:00 | train] - Train Epoch: [26] [409600/1281167 (32%)]	Loss: 1.729293
[2022-03-29 10:29:21 | train] - Train Epoch: [26] [422400/1281167 (33%)]	Loss: 1.900646
[2022-03-29 10:29:43 | train] - Train Epoch: [26] [435200/1281167 (34%)]	Loss: 1.683218
[2022-03-29 10:30:04 | train] - Train Epoch: [26] [448000/1281167 (35%)]	Loss: 1.303031
[2022-03-29 10:30:26 | train] - Train Epoch: [26] [460800/1281167 (36%)]	Loss: 1.706193
[2022-03-29 10:30:48 | train] - Train Epoch: [26] [473600/1281167 (37%)]	Loss: 2.049467
[2022-03-29 10:31:09 | train] - Train Epoch: [26] [486400/1281167 (38%)]	Loss: 1.769900
[2022-03-29 10:31:31 | train] - Train Epoch: [26] [499200/1281167 (39%)]	Loss: 1.547290
[2022-03-29 10:31:52 | train] - Train Epoch: [26] [512000/1281167 (40%)]	Loss: 1.698303
[2022-03-29 10:32:14 | train] - Train Epoch: [26] [524800/1281167 (41%)]	Loss: 1.621249
[2022-03-29 10:32:36 | train] - Train Epoch: [26] [537600/1281167 (42%)]	Loss: 1.578758
[2022-03-29 10:32:58 | train] - Train Epoch: [26] [550400/1281167 (43%)]	Loss: 1.279446
[2022-03-29 10:33:20 | train] - Train Epoch: [26] [563200/1281167 (44%)]	Loss: 1.601146
[2022-03-29 10:33:43 | train] - Train Epoch: [26] [576000/1281167 (45%)]	Loss: 1.308683
[2022-03-29 10:34:04 | train] - Train Epoch: [26] [588800/1281167 (46%)]	Loss: 1.638359
[2022-03-29 10:34:27 | train] - Train Epoch: [26] [601600/1281167 (47%)]	Loss: 1.553117
[2022-03-29 10:34:49 | train] - Train Epoch: [26] [614400/1281167 (48%)]	Loss: 1.405133
[2022-03-29 10:35:11 | train] - Train Epoch: [26] [627200/1281167 (49%)]	Loss: 1.415254
[2022-03-29 10:35:33 | train] - Train Epoch: [26] [640000/1281167 (50%)]	Loss: 1.601006
[2022-03-29 10:35:55 | train] - Train Epoch: [26] [652800/1281167 (51%)]	Loss: 1.731873
[2022-03-29 10:36:17 | train] - Train Epoch: [26] [665600/1281167 (52%)]	Loss: 1.467219
[2022-03-29 10:36:39 | train] - Train Epoch: [26] [678400/1281167 (53%)]	Loss: 1.756208
[2022-03-29 10:37:01 | train] - Train Epoch: [26] [691200/1281167 (54%)]	Loss: 1.425306
[2022-03-29 10:37:22 | train] - Train Epoch: [26] [704000/1281167 (55%)]	Loss: 1.655046
[2022-03-29 10:37:44 | train] - Train Epoch: [26] [716800/1281167 (56%)]	Loss: 1.523915
[2022-03-29 10:38:06 | train] - Train Epoch: [26] [729600/1281167 (57%)]	Loss: 1.460172
[2022-03-29 10:38:28 | train] - Train Epoch: [26] [742400/1281167 (58%)]	Loss: 1.551270
[2022-03-29 10:38:50 | train] - Train Epoch: [26] [755200/1281167 (59%)]	Loss: 1.877420
[2022-03-29 10:39:12 | train] - Train Epoch: [26] [768000/1281167 (60%)]	Loss: 1.735691
[2022-03-29 10:39:33 | train] - Train Epoch: [26] [780800/1281167 (61%)]	Loss: 1.573665
[2022-03-29 10:39:56 | train] - Train Epoch: [26] [793600/1281167 (62%)]	Loss: 1.598093
[2022-03-29 10:40:18 | train] - Train Epoch: [26] [806400/1281167 (63%)]	Loss: 1.691297
[2022-03-29 10:40:39 | train] - Train Epoch: [26] [819200/1281167 (64%)]	Loss: 1.693039
[2022-03-29 10:41:02 | train] - Train Epoch: [26] [832000/1281167 (65%)]	Loss: 2.007770
[2022-03-29 10:41:24 | train] - Train Epoch: [26] [844800/1281167 (66%)]	Loss: 1.523665
[2022-03-29 10:41:45 | train] - Train Epoch: [26] [857600/1281167 (67%)]	Loss: 2.006976
[2022-03-29 10:42:07 | train] - Train Epoch: [26] [870400/1281167 (68%)]	Loss: 1.567783
[2022-03-29 10:42:29 | train] - Train Epoch: [26] [883200/1281167 (69%)]	Loss: 1.733609
[2022-03-29 10:42:50 | train] - Train Epoch: [26] [896000/1281167 (70%)]	Loss: 1.650344
[2022-03-29 10:43:13 | train] - Train Epoch: [26] [908800/1281167 (71%)]	Loss: 1.492624
[2022-03-29 10:43:34 | train] - Train Epoch: [26] [921600/1281167 (72%)]	Loss: 1.680371
[2022-03-29 10:43:56 | train] - Train Epoch: [26] [934400/1281167 (73%)]	Loss: 1.795077
[2022-03-29 10:44:18 | train] - Train Epoch: [26] [947200/1281167 (74%)]	Loss: 1.329848
[2022-03-29 10:44:40 | train] - Train Epoch: [26] [960000/1281167 (75%)]	Loss: 2.021082
[2022-03-29 10:45:03 | train] - Train Epoch: [26] [972800/1281167 (76%)]	Loss: 1.745995
[2022-03-29 10:45:25 | train] - Train Epoch: [26] [985600/1281167 (77%)]	Loss: 1.657188
[2022-03-29 10:45:47 | train] - Train Epoch: [26] [998400/1281167 (78%)]	Loss: 1.435791
[2022-03-29 10:46:09 | train] - Train Epoch: [26] [1011200/1281167 (79%)]	Loss: 1.704745
[2022-03-29 10:46:31 | train] - Train Epoch: [26] [1024000/1281167 (80%)]	Loss: 1.544684
[2022-03-29 10:46:53 | train] - Train Epoch: [26] [1036800/1281167 (81%)]	Loss: 1.625064
[2022-03-29 10:47:15 | train] - Train Epoch: [26] [1049600/1281167 (82%)]	Loss: 1.598819
[2022-03-29 10:47:37 | train] - Train Epoch: [26] [1062400/1281167 (83%)]	Loss: 1.349699
[2022-03-29 10:47:58 | train] - Train Epoch: [26] [1075200/1281167 (84%)]	Loss: 1.531989
[2022-03-29 10:48:20 | train] - Train Epoch: [26] [1088000/1281167 (85%)]	Loss: 1.720480
[2022-03-29 10:48:42 | train] - Train Epoch: [26] [1100800/1281167 (86%)]	Loss: 1.234183
[2022-03-29 10:49:05 | train] - Train Epoch: [26] [1113600/1281167 (87%)]	Loss: 1.532842
[2022-03-29 10:49:26 | train] - Train Epoch: [26] [1126400/1281167 (88%)]	Loss: 1.449485
[2022-03-29 10:49:48 | train] - Train Epoch: [26] [1139200/1281167 (89%)]	Loss: 1.564132
[2022-03-29 10:50:10 | train] - Train Epoch: [26] [1152000/1281167 (90%)]	Loss: 1.564491
[2022-03-29 10:50:32 | train] - Train Epoch: [26] [1164800/1281167 (91%)]	Loss: 1.962366
[2022-03-29 10:50:54 | train] - Train Epoch: [26] [1177600/1281167 (92%)]	Loss: 1.377785
[2022-03-29 10:51:16 | train] - Train Epoch: [26] [1190400/1281167 (93%)]	Loss: 1.443394
[2022-03-29 10:51:38 | train] - Train Epoch: [26] [1203200/1281167 (94%)]	Loss: 1.702647
[2022-03-29 10:52:00 | train] - Train Epoch: [26] [1216000/1281167 (95%)]	Loss: 1.207406
[2022-03-29 10:52:21 | train] - Train Epoch: [26] [1228800/1281167 (96%)]	Loss: 1.443092
[2022-03-29 10:52:44 | train] - Train Epoch: [26] [1241600/1281167 (97%)]	Loss: 1.699865
[2022-03-29 10:53:06 | train] - Train Epoch: [26] [1254400/1281167 (98%)]	Loss: 1.422821
[2022-03-29 10:53:29 | train] - Train Epoch: [26] [1267200/1281167 (99%)]	Loss: 1.277321
[2022-03-29 10:53:51 | train] - Train Epoch: [26] [1280000/1281167 (100%)]	Loss: 1.602362
[2022-03-29 10:53:53 | train] - Train Epoch: [26]	 Average Loss: 1.573616	 Total Acc : 63.1896	 Total Top5 Acc : 83.6179
[2022-03-29 10:53:55 | train] - -------26 epoch end-----------
========================================
-------26 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 10:55:33 | train] - 
Epoch [26] Test set: Average loss: 1.4708, Accuracy: 32450/50000 (64.8677%), Top-5 Accuracy: 86.0450%

[2022-03-29 10:55:33 | train] - save intermediate epoch [26] result


[2022-03-29 10:55:39 | train] - -------27 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 10:55:41 | train] - Train Epoch: [27] [0/1281167 (0%)]	Loss: 1.633513
[2022-03-29 10:56:04 | train] - Train Epoch: [27] [12800/1281167 (1%)]	Loss: 1.674803
[2022-03-29 10:56:26 | train] - Train Epoch: [27] [25600/1281167 (2%)]	Loss: 1.690767
[2022-03-29 10:56:48 | train] - Train Epoch: [27] [38400/1281167 (3%)]	Loss: 1.619927
[2022-03-29 10:57:10 | train] - Train Epoch: [27] [51200/1281167 (4%)]	Loss: 1.535617
[2022-03-29 10:57:32 | train] - Train Epoch: [27] [64000/1281167 (5%)]	Loss: 1.910867
[2022-03-29 10:57:54 | train] - Train Epoch: [27] [76800/1281167 (6%)]	Loss: 1.335101
[2022-03-29 10:58:16 | train] - Train Epoch: [27] [89600/1281167 (7%)]	Loss: 1.660761
[2022-03-29 10:58:38 | train] - Train Epoch: [27] [102400/1281167 (8%)]	Loss: 1.776338
[2022-03-29 10:58:59 | train] - Train Epoch: [27] [115200/1281167 (9%)]	Loss: 1.602967
[2022-03-29 10:59:21 | train] - Train Epoch: [27] [128000/1281167 (10%)]	Loss: 1.337473
[2022-03-29 10:59:42 | train] - Train Epoch: [27] [140800/1281167 (11%)]	Loss: 1.421298
[2022-03-29 11:00:04 | train] - Train Epoch: [27] [153600/1281167 (12%)]	Loss: 1.261072
[2022-03-29 11:00:26 | train] - Train Epoch: [27] [166400/1281167 (13%)]	Loss: 1.269309
[2022-03-29 11:00:48 | train] - Train Epoch: [27] [179200/1281167 (14%)]	Loss: 1.672111
[2022-03-29 11:01:09 | train] - Train Epoch: [27] [192000/1281167 (15%)]	Loss: 1.514326
[2022-03-29 11:01:31 | train] - Train Epoch: [27] [204800/1281167 (16%)]	Loss: 1.714687
[2022-03-29 11:01:52 | train] - Train Epoch: [27] [217600/1281167 (17%)]	Loss: 1.705366
[2022-03-29 11:02:14 | train] - Train Epoch: [27] [230400/1281167 (18%)]	Loss: 1.392433
[2022-03-29 11:02:36 | train] - Train Epoch: [27] [243200/1281167 (19%)]	Loss: 1.733020
[2022-03-29 11:02:57 | train] - Train Epoch: [27] [256000/1281167 (20%)]	Loss: 1.877856
[2022-03-29 11:03:19 | train] - Train Epoch: [27] [268800/1281167 (21%)]	Loss: 1.747199
[2022-03-29 11:03:41 | train] - Train Epoch: [27] [281600/1281167 (22%)]	Loss: 1.421105
[2022-03-29 11:04:03 | train] - Train Epoch: [27] [294400/1281167 (23%)]	Loss: 1.236359
[2022-03-29 11:04:25 | train] - Train Epoch: [27] [307200/1281167 (24%)]	Loss: 1.400422
[2022-03-29 11:04:46 | train] - Train Epoch: [27] [320000/1281167 (25%)]	Loss: 1.957673
[2022-03-29 11:05:08 | train] - Train Epoch: [27] [332800/1281167 (26%)]	Loss: 1.479296
[2022-03-29 11:05:30 | train] - Train Epoch: [27] [345600/1281167 (27%)]	Loss: 1.653558
[2022-03-29 11:05:52 | train] - Train Epoch: [27] [358400/1281167 (28%)]	Loss: 1.582559
[2022-03-29 11:06:13 | train] - Train Epoch: [27] [371200/1281167 (29%)]	Loss: 1.431085
[2022-03-29 11:06:35 | train] - Train Epoch: [27] [384000/1281167 (30%)]	Loss: 1.271919
[2022-03-29 11:06:57 | train] - Train Epoch: [27] [396800/1281167 (31%)]	Loss: 1.517060
[2022-03-29 11:07:18 | train] - Train Epoch: [27] [409600/1281167 (32%)]	Loss: 1.489735
[2022-03-29 11:07:40 | train] - Train Epoch: [27] [422400/1281167 (33%)]	Loss: 1.740944
[2022-03-29 11:08:01 | train] - Train Epoch: [27] [435200/1281167 (34%)]	Loss: 1.533439
[2022-03-29 11:08:23 | train] - Train Epoch: [27] [448000/1281167 (35%)]	Loss: 1.698311
[2022-03-29 11:08:45 | train] - Train Epoch: [27] [460800/1281167 (36%)]	Loss: 1.520127
[2022-03-29 11:09:07 | train] - Train Epoch: [27] [473600/1281167 (37%)]	Loss: 1.251284
[2022-03-29 11:09:28 | train] - Train Epoch: [27] [486400/1281167 (38%)]	Loss: 1.283272
[2022-03-29 11:09:50 | train] - Train Epoch: [27] [499200/1281167 (39%)]	Loss: 1.597817
[2022-03-29 11:10:11 | train] - Train Epoch: [27] [512000/1281167 (40%)]	Loss: 1.335289
[2022-03-29 11:10:33 | train] - Train Epoch: [27] [524800/1281167 (41%)]	Loss: 1.344098
[2022-03-29 11:10:54 | train] - Train Epoch: [27] [537600/1281167 (42%)]	Loss: 1.673829
[2022-03-29 11:11:16 | train] - Train Epoch: [27] [550400/1281167 (43%)]	Loss: 1.550651
[2022-03-29 11:11:38 | train] - Train Epoch: [27] [563200/1281167 (44%)]	Loss: 1.691078
[2022-03-29 11:12:00 | train] - Train Epoch: [27] [576000/1281167 (45%)]	Loss: 1.619235
[2022-03-29 11:12:21 | train] - Train Epoch: [27] [588800/1281167 (46%)]	Loss: 1.633954
[2022-03-29 11:12:42 | train] - Train Epoch: [27] [601600/1281167 (47%)]	Loss: 1.442374
[2022-03-29 11:13:04 | train] - Train Epoch: [27] [614400/1281167 (48%)]	Loss: 1.655550
[2022-03-29 11:13:27 | train] - Train Epoch: [27] [627200/1281167 (49%)]	Loss: 1.564363
[2022-03-29 11:13:49 | train] - Train Epoch: [27] [640000/1281167 (50%)]	Loss: 1.571989
[2022-03-29 11:14:11 | train] - Train Epoch: [27] [652800/1281167 (51%)]	Loss: 1.547873
[2022-03-29 11:14:33 | train] - Train Epoch: [27] [665600/1281167 (52%)]	Loss: 1.674865
[2022-03-29 11:14:54 | train] - Train Epoch: [27] [678400/1281167 (53%)]	Loss: 1.358333
[2022-03-29 11:15:16 | train] - Train Epoch: [27] [691200/1281167 (54%)]	Loss: 1.327713
[2022-03-29 11:15:38 | train] - Train Epoch: [27] [704000/1281167 (55%)]	Loss: 1.489887
[2022-03-29 11:16:00 | train] - Train Epoch: [27] [716800/1281167 (56%)]	Loss: 1.639982
[2022-03-29 11:16:22 | train] - Train Epoch: [27] [729600/1281167 (57%)]	Loss: 1.743122
[2022-03-29 11:16:44 | train] - Train Epoch: [27] [742400/1281167 (58%)]	Loss: 1.439881
[2022-03-29 11:17:06 | train] - Train Epoch: [27] [755200/1281167 (59%)]	Loss: 1.552541
[2022-03-29 11:17:28 | train] - Train Epoch: [27] [768000/1281167 (60%)]	Loss: 1.839674
[2022-03-29 11:17:49 | train] - Train Epoch: [27] [780800/1281167 (61%)]	Loss: 1.748729
[2022-03-29 11:18:11 | train] - Train Epoch: [27] [793600/1281167 (62%)]	Loss: 1.855880
[2022-03-29 11:18:33 | train] - Train Epoch: [27] [806400/1281167 (63%)]	Loss: 1.557684
[2022-03-29 11:18:54 | train] - Train Epoch: [27] [819200/1281167 (64%)]	Loss: 1.485888
[2022-03-29 11:19:17 | train] - Train Epoch: [27] [832000/1281167 (65%)]	Loss: 1.566062
[2022-03-29 11:19:39 | train] - Train Epoch: [27] [844800/1281167 (66%)]	Loss: 1.691660
[2022-03-29 11:20:01 | train] - Train Epoch: [27] [857600/1281167 (67%)]	Loss: 1.759012
[2022-03-29 11:20:22 | train] - Train Epoch: [27] [870400/1281167 (68%)]	Loss: 1.275355
[2022-03-29 11:20:44 | train] - Train Epoch: [27] [883200/1281167 (69%)]	Loss: 1.878043
[2022-03-29 11:21:06 | train] - Train Epoch: [27] [896000/1281167 (70%)]	Loss: 1.606085
[2022-03-29 11:21:28 | train] - Train Epoch: [27] [908800/1281167 (71%)]	Loss: 1.443844
[2022-03-29 11:21:50 | train] - Train Epoch: [27] [921600/1281167 (72%)]	Loss: 1.557721
[2022-03-29 11:22:12 | train] - Train Epoch: [27] [934400/1281167 (73%)]	Loss: 1.724469
[2022-03-29 11:22:33 | train] - Train Epoch: [27] [947200/1281167 (74%)]	Loss: 1.718391
[2022-03-29 11:22:55 | train] - Train Epoch: [27] [960000/1281167 (75%)]	Loss: 1.531671
[2022-03-29 11:23:17 | train] - Train Epoch: [27] [972800/1281167 (76%)]	Loss: 1.505673
[2022-03-29 11:23:38 | train] - Train Epoch: [27] [985600/1281167 (77%)]	Loss: 1.179482
[2022-03-29 11:24:00 | train] - Train Epoch: [27] [998400/1281167 (78%)]	Loss: 1.573464
[2022-03-29 11:24:22 | train] - Train Epoch: [27] [1011200/1281167 (79%)]	Loss: 1.600204
[2022-03-29 11:24:44 | train] - Train Epoch: [27] [1024000/1281167 (80%)]	Loss: 1.200948
[2022-03-29 11:25:05 | train] - Train Epoch: [27] [1036800/1281167 (81%)]	Loss: 1.544788
[2022-03-29 11:25:27 | train] - Train Epoch: [27] [1049600/1281167 (82%)]	Loss: 1.454166
[2022-03-29 11:25:49 | train] - Train Epoch: [27] [1062400/1281167 (83%)]	Loss: 1.331876
[2022-03-29 11:26:12 | train] - Train Epoch: [27] [1075200/1281167 (84%)]	Loss: 1.252470
[2022-03-29 11:26:34 | train] - Train Epoch: [27] [1088000/1281167 (85%)]	Loss: 1.555351
[2022-03-29 11:26:55 | train] - Train Epoch: [27] [1100800/1281167 (86%)]	Loss: 1.667184
[2022-03-29 11:27:17 | train] - Train Epoch: [27] [1113600/1281167 (87%)]	Loss: 1.495009
[2022-03-29 11:27:39 | train] - Train Epoch: [27] [1126400/1281167 (88%)]	Loss: 1.970256
[2022-03-29 11:28:01 | train] - Train Epoch: [27] [1139200/1281167 (89%)]	Loss: 1.441134
[2022-03-29 11:28:23 | train] - Train Epoch: [27] [1152000/1281167 (90%)]	Loss: 1.309847
[2022-03-29 11:28:45 | train] - Train Epoch: [27] [1164800/1281167 (91%)]	Loss: 1.540883
[2022-03-29 11:29:06 | train] - Train Epoch: [27] [1177600/1281167 (92%)]	Loss: 1.677338
[2022-03-29 11:29:27 | train] - Train Epoch: [27] [1190400/1281167 (93%)]	Loss: 1.429409
[2022-03-29 11:29:49 | train] - Train Epoch: [27] [1203200/1281167 (94%)]	Loss: 1.649717
[2022-03-29 11:30:10 | train] - Train Epoch: [27] [1216000/1281167 (95%)]	Loss: 1.499446
[2022-03-29 11:30:32 | train] - Train Epoch: [27] [1228800/1281167 (96%)]	Loss: 1.478991
[2022-03-29 11:30:55 | train] - Train Epoch: [27] [1241600/1281167 (97%)]	Loss: 1.830895
[2022-03-29 11:31:17 | train] - Train Epoch: [27] [1254400/1281167 (98%)]	Loss: 1.626691
[2022-03-29 11:31:38 | train] - Train Epoch: [27] [1267200/1281167 (99%)]	Loss: 1.996710
[2022-03-29 11:32:01 | train] - Train Epoch: [27] [1280000/1281167 (100%)]	Loss: 1.495105
[2022-03-29 11:32:03 | train] - Train Epoch: [27]	 Average Loss: 1.553496	 Total Acc : 63.6562	 Total Top5 Acc : 83.8751
[2022-03-29 11:32:05 | train] - -------27 epoch end-----------
========================================
-------27 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 11:33:44 | train] - 
Epoch [27] Test set: Average loss: 1.4570, Accuracy: 32677/50000 (65.3249%), Top-5 Accuracy: 86.5066%

[2022-03-29 11:33:44 | train] - save intermediate epoch [27] result


[2022-03-29 11:33:50 | train] - logging best performance 27 epoch
[2022-03-29 11:33:51 | train] - -------28 epoch start-----------
========================================
----- test end -------------------------


logging best performance 27 epoch
[2022-03-29 11:33:53 | train] - Train Epoch: [28] [0/1281167 (0%)]	Loss: 1.455244
[2022-03-29 11:34:17 | train] - Train Epoch: [28] [12800/1281167 (1%)]	Loss: 1.749354
[2022-03-29 11:34:38 | train] - Train Epoch: [28] [25600/1281167 (2%)]	Loss: 1.662297
[2022-03-29 11:35:00 | train] - Train Epoch: [28] [38400/1281167 (3%)]	Loss: 1.641741
[2022-03-29 11:35:22 | train] - Train Epoch: [28] [51200/1281167 (4%)]	Loss: 1.785457
[2022-03-29 11:35:43 | train] - Train Epoch: [28] [64000/1281167 (5%)]	Loss: 1.629462
[2022-03-29 11:36:05 | train] - Train Epoch: [28] [76800/1281167 (6%)]	Loss: 1.762156
[2022-03-29 11:36:26 | train] - Train Epoch: [28] [89600/1281167 (7%)]	Loss: 1.020529
[2022-03-29 11:36:47 | train] - Train Epoch: [28] [102400/1281167 (8%)]	Loss: 1.713636
[2022-03-29 11:37:09 | train] - Train Epoch: [28] [115200/1281167 (9%)]	Loss: 1.297443
[2022-03-29 11:37:30 | train] - Train Epoch: [28] [128000/1281167 (10%)]	Loss: 1.251747
[2022-03-29 11:37:52 | train] - Train Epoch: [28] [140800/1281167 (11%)]	Loss: 1.486075
[2022-03-29 11:38:14 | train] - Train Epoch: [28] [153600/1281167 (12%)]	Loss: 1.431830
[2022-03-29 11:38:36 | train] - Train Epoch: [28] [166400/1281167 (13%)]	Loss: 1.201582
[2022-03-29 11:38:58 | train] - Train Epoch: [28] [179200/1281167 (14%)]	Loss: 1.871588
[2022-03-29 11:39:20 | train] - Train Epoch: [28] [192000/1281167 (15%)]	Loss: 1.890685
[2022-03-29 11:39:41 | train] - Train Epoch: [28] [204800/1281167 (16%)]	Loss: 1.544253
[2022-03-29 11:40:03 | train] - Train Epoch: [28] [217600/1281167 (17%)]	Loss: 1.124440
[2022-03-29 11:40:25 | train] - Train Epoch: [28] [230400/1281167 (18%)]	Loss: 1.559487
[2022-03-29 11:40:47 | train] - Train Epoch: [28] [243200/1281167 (19%)]	Loss: 1.598911
[2022-03-29 11:41:09 | train] - Train Epoch: [28] [256000/1281167 (20%)]	Loss: 1.514985
[2022-03-29 11:41:30 | train] - Train Epoch: [28] [268800/1281167 (21%)]	Loss: 1.377677
[2022-03-29 11:41:51 | train] - Train Epoch: [28] [281600/1281167 (22%)]	Loss: 1.946700
[2022-03-29 11:42:13 | train] - Train Epoch: [28] [294400/1281167 (23%)]	Loss: 1.541018
[2022-03-29 11:42:34 | train] - Train Epoch: [28] [307200/1281167 (24%)]	Loss: 1.704591
[2022-03-29 11:42:56 | train] - Train Epoch: [28] [320000/1281167 (25%)]	Loss: 1.701282
[2022-03-29 11:43:18 | train] - Train Epoch: [28] [332800/1281167 (26%)]	Loss: 1.729848
[2022-03-29 11:43:40 | train] - Train Epoch: [28] [345600/1281167 (27%)]	Loss: 1.451769
[2022-03-29 11:44:01 | train] - Train Epoch: [28] [358400/1281167 (28%)]	Loss: 1.364466
[2022-03-29 11:44:22 | train] - Train Epoch: [28] [371200/1281167 (29%)]	Loss: 1.334117
[2022-03-29 11:44:44 | train] - Train Epoch: [28] [384000/1281167 (30%)]	Loss: 1.396761
[2022-03-29 11:45:05 | train] - Train Epoch: [28] [396800/1281167 (31%)]	Loss: 1.440645
[2022-03-29 11:45:28 | train] - Train Epoch: [28] [409600/1281167 (32%)]	Loss: 1.702214
[2022-03-29 11:45:50 | train] - Train Epoch: [28] [422400/1281167 (33%)]	Loss: 1.848432
[2022-03-29 11:46:11 | train] - Train Epoch: [28] [435200/1281167 (34%)]	Loss: 1.610558
[2022-03-29 11:46:33 | train] - Train Epoch: [28] [448000/1281167 (35%)]	Loss: 1.724171
[2022-03-29 11:46:55 | train] - Train Epoch: [28] [460800/1281167 (36%)]	Loss: 1.285056
[2022-03-29 11:47:17 | train] - Train Epoch: [28] [473600/1281167 (37%)]	Loss: 1.598631
[2022-03-29 11:47:39 | train] - Train Epoch: [28] [486400/1281167 (38%)]	Loss: 1.727822
[2022-03-29 11:48:01 | train] - Train Epoch: [28] [499200/1281167 (39%)]	Loss: 1.588581
[2022-03-29 11:48:23 | train] - Train Epoch: [28] [512000/1281167 (40%)]	Loss: 1.720583
[2022-03-29 11:48:45 | train] - Train Epoch: [28] [524800/1281167 (41%)]	Loss: 1.148084
[2022-03-29 11:49:06 | train] - Train Epoch: [28] [537600/1281167 (42%)]	Loss: 1.396330
[2022-03-29 11:49:28 | train] - Train Epoch: [28] [550400/1281167 (43%)]	Loss: 1.342534
[2022-03-29 11:49:49 | train] - Train Epoch: [28] [563200/1281167 (44%)]	Loss: 1.651400
[2022-03-29 11:50:11 | train] - Train Epoch: [28] [576000/1281167 (45%)]	Loss: 1.709513
[2022-03-29 11:50:33 | train] - Train Epoch: [28] [588800/1281167 (46%)]	Loss: 1.504589
[2022-03-29 11:50:55 | train] - Train Epoch: [28] [601600/1281167 (47%)]	Loss: 1.651774
[2022-03-29 11:51:17 | train] - Train Epoch: [28] [614400/1281167 (48%)]	Loss: 1.267457
[2022-03-29 11:51:38 | train] - Train Epoch: [28] [627200/1281167 (49%)]	Loss: 1.547719
[2022-03-29 11:52:00 | train] - Train Epoch: [28] [640000/1281167 (50%)]	Loss: 1.376361
[2022-03-29 11:52:22 | train] - Train Epoch: [28] [652800/1281167 (51%)]	Loss: 1.528463
[2022-03-29 11:52:43 | train] - Train Epoch: [28] [665600/1281167 (52%)]	Loss: 1.639070
[2022-03-29 11:53:06 | train] - Train Epoch: [28] [678400/1281167 (53%)]	Loss: 1.701969
[2022-03-29 11:53:28 | train] - Train Epoch: [28] [691200/1281167 (54%)]	Loss: 1.013321
[2022-03-29 11:53:49 | train] - Train Epoch: [28] [704000/1281167 (55%)]	Loss: 2.052489
[2022-03-29 11:54:11 | train] - Train Epoch: [28] [716800/1281167 (56%)]	Loss: 1.284337
[2022-03-29 11:54:33 | train] - Train Epoch: [28] [729600/1281167 (57%)]	Loss: 1.694445
[2022-03-29 11:54:54 | train] - Train Epoch: [28] [742400/1281167 (58%)]	Loss: 1.624141
[2022-03-29 11:55:16 | train] - Train Epoch: [28] [755200/1281167 (59%)]	Loss: 1.389149
[2022-03-29 11:55:37 | train] - Train Epoch: [28] [768000/1281167 (60%)]	Loss: 1.530633
[2022-03-29 11:55:59 | train] - Train Epoch: [28] [780800/1281167 (61%)]	Loss: 1.501408
[2022-03-29 11:56:20 | train] - Train Epoch: [28] [793600/1281167 (62%)]	Loss: 1.635944
[2022-03-29 11:56:42 | train] - Train Epoch: [28] [806400/1281167 (63%)]	Loss: 1.501593
[2022-03-29 11:57:04 | train] - Train Epoch: [28] [819200/1281167 (64%)]	Loss: 1.341068
[2022-03-29 11:57:26 | train] - Train Epoch: [28] [832000/1281167 (65%)]	Loss: 1.444038
[2022-03-29 11:57:48 | train] - Train Epoch: [28] [844800/1281167 (66%)]	Loss: 1.346353
[2022-03-29 11:58:10 | train] - Train Epoch: [28] [857600/1281167 (67%)]	Loss: 1.257380
[2022-03-29 11:58:32 | train] - Train Epoch: [28] [870400/1281167 (68%)]	Loss: 1.656877
[2022-03-29 11:58:53 | train] - Train Epoch: [28] [883200/1281167 (69%)]	Loss: 1.535426
[2022-03-29 11:59:16 | train] - Train Epoch: [28] [896000/1281167 (70%)]	Loss: 1.424379
[2022-03-29 11:59:37 | train] - Train Epoch: [28] [908800/1281167 (71%)]	Loss: 1.534124
[2022-03-29 11:59:58 | train] - Train Epoch: [28] [921600/1281167 (72%)]	Loss: 1.448071
[2022-03-29 12:00:19 | train] - Train Epoch: [28] [934400/1281167 (73%)]	Loss: 1.587113
[2022-03-29 12:00:41 | train] - Train Epoch: [28] [947200/1281167 (74%)]	Loss: 1.897712
[2022-03-29 12:01:02 | train] - Train Epoch: [28] [960000/1281167 (75%)]	Loss: 1.496931
[2022-03-29 12:01:24 | train] - Train Epoch: [28] [972800/1281167 (76%)]	Loss: 1.297320
[2022-03-29 12:01:46 | train] - Train Epoch: [28] [985600/1281167 (77%)]	Loss: 1.528835
[2022-03-29 12:02:08 | train] - Train Epoch: [28] [998400/1281167 (78%)]	Loss: 1.507070
[2022-03-29 12:02:29 | train] - Train Epoch: [28] [1011200/1281167 (79%)]	Loss: 1.946172
[2022-03-29 12:02:51 | train] - Train Epoch: [28] [1024000/1281167 (80%)]	Loss: 1.751872
[2022-03-29 12:03:13 | train] - Train Epoch: [28] [1036800/1281167 (81%)]	Loss: 1.371625
[2022-03-29 12:03:35 | train] - Train Epoch: [28] [1049600/1281167 (82%)]	Loss: 1.763378
[2022-03-29 12:03:56 | train] - Train Epoch: [28] [1062400/1281167 (83%)]	Loss: 1.591163
[2022-03-29 12:04:18 | train] - Train Epoch: [28] [1075200/1281167 (84%)]	Loss: 1.856012
[2022-03-29 12:04:40 | train] - Train Epoch: [28] [1088000/1281167 (85%)]	Loss: 1.475944
[2022-03-29 12:05:02 | train] - Train Epoch: [28] [1100800/1281167 (86%)]	Loss: 1.463435
[2022-03-29 12:05:23 | train] - Train Epoch: [28] [1113600/1281167 (87%)]	Loss: 1.797747
[2022-03-29 12:05:46 | train] - Train Epoch: [28] [1126400/1281167 (88%)]	Loss: 1.413206
[2022-03-29 12:06:08 | train] - Train Epoch: [28] [1139200/1281167 (89%)]	Loss: 1.820309
[2022-03-29 12:06:30 | train] - Train Epoch: [28] [1152000/1281167 (90%)]	Loss: 1.647543
[2022-03-29 12:06:51 | train] - Train Epoch: [28] [1164800/1281167 (91%)]	Loss: 1.444723
[2022-03-29 12:07:12 | train] - Train Epoch: [28] [1177600/1281167 (92%)]	Loss: 1.754249
[2022-03-29 12:07:34 | train] - Train Epoch: [28] [1190400/1281167 (93%)]	Loss: 1.646182
[2022-03-29 12:07:56 | train] - Train Epoch: [28] [1203200/1281167 (94%)]	Loss: 1.748894
[2022-03-29 12:08:18 | train] - Train Epoch: [28] [1216000/1281167 (95%)]	Loss: 1.456190
[2022-03-29 12:08:40 | train] - Train Epoch: [28] [1228800/1281167 (96%)]	Loss: 1.800959
[2022-03-29 12:09:02 | train] - Train Epoch: [28] [1241600/1281167 (97%)]	Loss: 1.353119
[2022-03-29 12:09:23 | train] - Train Epoch: [28] [1254400/1281167 (98%)]	Loss: 1.556130
[2022-03-29 12:09:45 | train] - Train Epoch: [28] [1267200/1281167 (99%)]	Loss: 1.737558
[2022-03-29 12:10:07 | train] - Train Epoch: [28] [1280000/1281167 (100%)]	Loss: 1.293525
[2022-03-29 12:10:09 | train] - Train Epoch: [28]	 Average Loss: 1.532706	 Total Acc : 64.0346	 Total Top5 Acc : 84.1661
[2022-03-29 12:10:12 | train] - -------28 epoch end-----------
========================================
-------28 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 12:11:52 | train] - 
Epoch [28] Test set: Average loss: 1.4557, Accuracy: 32719/50000 (65.4052%), Top-5 Accuracy: 86.5797%

[2022-03-29 12:11:52 | train] - save intermediate epoch [28] result


[2022-03-29 12:11:58 | train] - logging best performance 28 epoch
[2022-03-29 12:11:59 | train] - -------29 epoch start-----------
========================================
----- test end -------------------------


logging best performance 28 epoch
[2022-03-29 12:12:01 | train] - Train Epoch: [29] [0/1281167 (0%)]	Loss: 1.329966
[2022-03-29 12:12:23 | train] - Train Epoch: [29] [12800/1281167 (1%)]	Loss: 1.594758
[2022-03-29 12:12:45 | train] - Train Epoch: [29] [25600/1281167 (2%)]	Loss: 1.403386
[2022-03-29 12:13:08 | train] - Train Epoch: [29] [38400/1281167 (3%)]	Loss: 1.579934
[2022-03-29 12:13:30 | train] - Train Epoch: [29] [51200/1281167 (4%)]	Loss: 1.576902
[2022-03-29 12:13:51 | train] - Train Epoch: [29] [64000/1281167 (5%)]	Loss: 1.317202
[2022-03-29 12:14:13 | train] - Train Epoch: [29] [76800/1281167 (6%)]	Loss: 1.508148
[2022-03-29 12:14:35 | train] - Train Epoch: [29] [89600/1281167 (7%)]	Loss: 1.324480
[2022-03-29 12:14:56 | train] - Train Epoch: [29] [102400/1281167 (8%)]	Loss: 1.597715
[2022-03-29 12:15:18 | train] - Train Epoch: [29] [115200/1281167 (9%)]	Loss: 1.347534
[2022-03-29 12:15:40 | train] - Train Epoch: [29] [128000/1281167 (10%)]	Loss: 1.457298
[2022-03-29 12:16:02 | train] - Train Epoch: [29] [140800/1281167 (11%)]	Loss: 1.476901
[2022-03-29 12:16:24 | train] - Train Epoch: [29] [153600/1281167 (12%)]	Loss: 1.493646
[2022-03-29 12:16:46 | train] - Train Epoch: [29] [166400/1281167 (13%)]	Loss: 1.861963
[2022-03-29 12:17:08 | train] - Train Epoch: [29] [179200/1281167 (14%)]	Loss: 1.446507
[2022-03-29 12:17:30 | train] - Train Epoch: [29] [192000/1281167 (15%)]	Loss: 1.617259
[2022-03-29 12:17:52 | train] - Train Epoch: [29] [204800/1281167 (16%)]	Loss: 1.625002
[2022-03-29 12:18:14 | train] - Train Epoch: [29] [217600/1281167 (17%)]	Loss: 1.311415
[2022-03-29 12:18:35 | train] - Train Epoch: [29] [230400/1281167 (18%)]	Loss: 1.442737
[2022-03-29 12:18:56 | train] - Train Epoch: [29] [243200/1281167 (19%)]	Loss: 1.600953
[2022-03-29 12:19:18 | train] - Train Epoch: [29] [256000/1281167 (20%)]	Loss: 1.457417
[2022-03-29 12:19:40 | train] - Train Epoch: [29] [268800/1281167 (21%)]	Loss: 1.144814
[2022-03-29 12:20:02 | train] - Train Epoch: [29] [281600/1281167 (22%)]	Loss: 1.195259
[2022-03-29 12:20:23 | train] - Train Epoch: [29] [294400/1281167 (23%)]	Loss: 1.574399
[2022-03-29 12:20:45 | train] - Train Epoch: [29] [307200/1281167 (24%)]	Loss: 1.541271
[2022-03-29 12:21:06 | train] - Train Epoch: [29] [320000/1281167 (25%)]	Loss: 1.380709
[2022-03-29 12:21:29 | train] - Train Epoch: [29] [332800/1281167 (26%)]	Loss: 1.704128
[2022-03-29 12:21:50 | train] - Train Epoch: [29] [345600/1281167 (27%)]	Loss: 1.523498
[2022-03-29 12:22:12 | train] - Train Epoch: [29] [358400/1281167 (28%)]	Loss: 1.408229
[2022-03-29 12:22:33 | train] - Train Epoch: [29] [371200/1281167 (29%)]	Loss: 1.135675
[2022-03-29 12:22:55 | train] - Train Epoch: [29] [384000/1281167 (30%)]	Loss: 1.882790
[2022-03-29 12:23:17 | train] - Train Epoch: [29] [396800/1281167 (31%)]	Loss: 1.613747
[2022-03-29 12:23:39 | train] - Train Epoch: [29] [409600/1281167 (32%)]	Loss: 1.361327
[2022-03-29 12:24:00 | train] - Train Epoch: [29] [422400/1281167 (33%)]	Loss: 1.240145
[2022-03-29 12:24:23 | train] - Train Epoch: [29] [435200/1281167 (34%)]	Loss: 1.371085
[2022-03-29 12:24:44 | train] - Train Epoch: [29] [448000/1281167 (35%)]	Loss: 1.414227
[2022-03-29 12:25:06 | train] - Train Epoch: [29] [460800/1281167 (36%)]	Loss: 1.491721
[2022-03-29 12:25:28 | train] - Train Epoch: [29] [473600/1281167 (37%)]	Loss: 1.340775
[2022-03-29 12:25:50 | train] - Train Epoch: [29] [486400/1281167 (38%)]	Loss: 1.447521
[2022-03-29 12:26:12 | train] - Train Epoch: [29] [499200/1281167 (39%)]	Loss: 1.426518
[2022-03-29 12:26:34 | train] - Train Epoch: [29] [512000/1281167 (40%)]	Loss: 1.482548
[2022-03-29 12:26:56 | train] - Train Epoch: [29] [524800/1281167 (41%)]	Loss: 1.198462
[2022-03-29 12:27:17 | train] - Train Epoch: [29] [537600/1281167 (42%)]	Loss: 1.472817
[2022-03-29 12:27:40 | train] - Train Epoch: [29] [550400/1281167 (43%)]	Loss: 1.456579
[2022-03-29 12:28:01 | train] - Train Epoch: [29] [563200/1281167 (44%)]	Loss: 1.742784
[2022-03-29 12:28:24 | train] - Train Epoch: [29] [576000/1281167 (45%)]	Loss: 1.592788
[2022-03-29 12:28:46 | train] - Train Epoch: [29] [588800/1281167 (46%)]	Loss: 1.821371
[2022-03-29 12:29:08 | train] - Train Epoch: [29] [601600/1281167 (47%)]	Loss: 1.000380
[2022-03-29 12:29:29 | train] - Train Epoch: [29] [614400/1281167 (48%)]	Loss: 1.853828
[2022-03-29 12:29:51 | train] - Train Epoch: [29] [627200/1281167 (49%)]	Loss: 1.540239
[2022-03-29 12:30:13 | train] - Train Epoch: [29] [640000/1281167 (50%)]	Loss: 1.580204
[2022-03-29 12:30:35 | train] - Train Epoch: [29] [652800/1281167 (51%)]	Loss: 1.368643
[2022-03-29 12:30:56 | train] - Train Epoch: [29] [665600/1281167 (52%)]	Loss: 1.437609
[2022-03-29 12:31:18 | train] - Train Epoch: [29] [678400/1281167 (53%)]	Loss: 1.622354
[2022-03-29 12:31:40 | train] - Train Epoch: [29] [691200/1281167 (54%)]	Loss: 1.420756
[2022-03-29 12:32:02 | train] - Train Epoch: [29] [704000/1281167 (55%)]	Loss: 1.655726
[2022-03-29 12:32:24 | train] - Train Epoch: [29] [716800/1281167 (56%)]	Loss: 1.590038
[2022-03-29 12:32:45 | train] - Train Epoch: [29] [729600/1281167 (57%)]	Loss: 1.520787
[2022-03-29 12:33:07 | train] - Train Epoch: [29] [742400/1281167 (58%)]	Loss: 1.488796
[2022-03-29 12:33:29 | train] - Train Epoch: [29] [755200/1281167 (59%)]	Loss: 1.703461
[2022-03-29 12:33:51 | train] - Train Epoch: [29] [768000/1281167 (60%)]	Loss: 1.543769
[2022-03-29 12:34:13 | train] - Train Epoch: [29] [780800/1281167 (61%)]	Loss: 1.306708
[2022-03-29 12:34:34 | train] - Train Epoch: [29] [793600/1281167 (62%)]	Loss: 1.208822
[2022-03-29 12:34:56 | train] - Train Epoch: [29] [806400/1281167 (63%)]	Loss: 1.327177
[2022-03-29 12:35:18 | train] - Train Epoch: [29] [819200/1281167 (64%)]	Loss: 1.639788
[2022-03-29 12:35:39 | train] - Train Epoch: [29] [832000/1281167 (65%)]	Loss: 1.454642
[2022-03-29 12:36:01 | train] - Train Epoch: [29] [844800/1281167 (66%)]	Loss: 1.775011
[2022-03-29 12:36:23 | train] - Train Epoch: [29] [857600/1281167 (67%)]	Loss: 1.309779
[2022-03-29 12:36:45 | train] - Train Epoch: [29] [870400/1281167 (68%)]	Loss: 1.629536
[2022-03-29 12:37:06 | train] - Train Epoch: [29] [883200/1281167 (69%)]	Loss: 1.465045
[2022-03-29 12:37:28 | train] - Train Epoch: [29] [896000/1281167 (70%)]	Loss: 1.517925
[2022-03-29 12:37:50 | train] - Train Epoch: [29] [908800/1281167 (71%)]	Loss: 1.585826
[2022-03-29 12:38:11 | train] - Train Epoch: [29] [921600/1281167 (72%)]	Loss: 1.375978
[2022-03-29 12:38:33 | train] - Train Epoch: [29] [934400/1281167 (73%)]	Loss: 1.531595
[2022-03-29 12:38:55 | train] - Train Epoch: [29] [947200/1281167 (74%)]	Loss: 1.548757
[2022-03-29 12:39:17 | train] - Train Epoch: [29] [960000/1281167 (75%)]	Loss: 1.360199
[2022-03-29 12:39:39 | train] - Train Epoch: [29] [972800/1281167 (76%)]	Loss: 1.348010
[2022-03-29 12:40:01 | train] - Train Epoch: [29] [985600/1281167 (77%)]	Loss: 1.175325
[2022-03-29 12:40:23 | train] - Train Epoch: [29] [998400/1281167 (78%)]	Loss: 1.550622
[2022-03-29 12:40:45 | train] - Train Epoch: [29] [1011200/1281167 (79%)]	Loss: 1.396322
[2022-03-29 12:41:07 | train] - Train Epoch: [29] [1024000/1281167 (80%)]	Loss: 1.688704
[2022-03-29 12:41:29 | train] - Train Epoch: [29] [1036800/1281167 (81%)]	Loss: 1.021832
[2022-03-29 12:41:51 | train] - Train Epoch: [29] [1049600/1281167 (82%)]	Loss: 1.449798
[2022-03-29 12:42:12 | train] - Train Epoch: [29] [1062400/1281167 (83%)]	Loss: 1.624816
[2022-03-29 12:42:35 | train] - Train Epoch: [29] [1075200/1281167 (84%)]	Loss: 1.538262
[2022-03-29 12:42:56 | train] - Train Epoch: [29] [1088000/1281167 (85%)]	Loss: 1.667410
[2022-03-29 12:43:18 | train] - Train Epoch: [29] [1100800/1281167 (86%)]	Loss: 1.720948
[2022-03-29 12:43:40 | train] - Train Epoch: [29] [1113600/1281167 (87%)]	Loss: 1.357289
[2022-03-29 12:44:02 | train] - Train Epoch: [29] [1126400/1281167 (88%)]	Loss: 1.203551
[2022-03-29 12:44:24 | train] - Train Epoch: [29] [1139200/1281167 (89%)]	Loss: 1.803636
[2022-03-29 12:44:45 | train] - Train Epoch: [29] [1152000/1281167 (90%)]	Loss: 1.364038
[2022-03-29 12:45:07 | train] - Train Epoch: [29] [1164800/1281167 (91%)]	Loss: 1.282723
[2022-03-29 12:45:29 | train] - Train Epoch: [29] [1177600/1281167 (92%)]	Loss: 1.492713
[2022-03-29 12:45:50 | train] - Train Epoch: [29] [1190400/1281167 (93%)]	Loss: 1.467567
[2022-03-29 12:46:12 | train] - Train Epoch: [29] [1203200/1281167 (94%)]	Loss: 1.624383
[2022-03-29 12:46:34 | train] - Train Epoch: [29] [1216000/1281167 (95%)]	Loss: 1.483803
[2022-03-29 12:46:56 | train] - Train Epoch: [29] [1228800/1281167 (96%)]	Loss: 1.358038
[2022-03-29 12:47:17 | train] - Train Epoch: [29] [1241600/1281167 (97%)]	Loss: 1.416035
[2022-03-29 12:47:39 | train] - Train Epoch: [29] [1254400/1281167 (98%)]	Loss: 1.849613
[2022-03-29 12:48:02 | train] - Train Epoch: [29] [1267200/1281167 (99%)]	Loss: 1.724427
[2022-03-29 12:48:24 | train] - Train Epoch: [29] [1280000/1281167 (100%)]	Loss: 1.464216
[2022-03-29 12:48:26 | train] - Train Epoch: [29]	 Average Loss: 1.512575	 Total Acc : 64.4641	 Total Top5 Acc : 84.4332
[2022-03-29 12:48:28 | train] - -------29 epoch end-----------
========================================
-------29 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 12:50:11 | train] - 
Epoch [29] Test set: Average loss: 1.4172, Accuracy: 33024/50000 (66.0194%), Top-5 Accuracy: 86.9401%

[2022-03-29 12:50:11 | train] - save intermediate epoch [29] result


[2022-03-29 12:50:17 | train] - logging best performance 29 epoch
[2022-03-29 12:50:18 | train] - -------30 epoch start-----------
[2022-03-29 12:50:18 | train] - -------- logging 30 batch layer input tensor ------------------
========================================
----- test end -------------------------


logging best performance 29 epoch
batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
batch_grad_output shape : torch.Size([128, 64, 112, 112])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
[2022-03-29 12:50:44 | train] - -------- logging end 30 --------------------
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1000])
batch_grad_output tuples shape : [128]
[2022-03-29 12:50:46 | train] - Train Epoch: [30] [0/1281167 (0%)]	Loss: 1.745203
[2022-03-29 12:51:09 | train] - Train Epoch: [30] [12800/1281167 (1%)]	Loss: 1.605883
[2022-03-29 12:51:32 | train] - Train Epoch: [30] [25600/1281167 (2%)]	Loss: 1.420943
[2022-03-29 12:51:54 | train] - Train Epoch: [30] [38400/1281167 (3%)]	Loss: 1.513118
[2022-03-29 12:52:14 | train] - Train Epoch: [30] [51200/1281167 (4%)]	Loss: 1.683545
[2022-03-29 12:52:35 | train] - Train Epoch: [30] [64000/1281167 (5%)]	Loss: 1.750517
[2022-03-29 12:52:57 | train] - Train Epoch: [30] [76800/1281167 (6%)]	Loss: 1.506606
[2022-03-29 12:53:18 | train] - Train Epoch: [30] [89600/1281167 (7%)]	Loss: 1.363603
[2022-03-29 12:53:39 | train] - Train Epoch: [30] [102400/1281167 (8%)]	Loss: 1.464779
[2022-03-29 12:54:00 | train] - Train Epoch: [30] [115200/1281167 (9%)]	Loss: 1.835805
[2022-03-29 12:54:21 | train] - Train Epoch: [30] [128000/1281167 (10%)]	Loss: 1.287025
[2022-03-29 12:54:42 | train] - Train Epoch: [30] [140800/1281167 (11%)]	Loss: 1.497651
[2022-03-29 12:55:04 | train] - Train Epoch: [30] [153600/1281167 (12%)]	Loss: 1.194496
[2022-03-29 12:55:25 | train] - Train Epoch: [30] [166400/1281167 (13%)]	Loss: 1.709169
[2022-03-29 12:55:46 | train] - Train Epoch: [30] [179200/1281167 (14%)]	Loss: 1.628719
[2022-03-29 12:56:07 | train] - Train Epoch: [30] [192000/1281167 (15%)]	Loss: 1.453578
[2022-03-29 12:56:28 | train] - Train Epoch: [30] [204800/1281167 (16%)]	Loss: 1.372651
[2022-03-29 12:56:49 | train] - Train Epoch: [30] [217600/1281167 (17%)]	Loss: 1.731817
[2022-03-29 12:57:10 | train] - Train Epoch: [30] [230400/1281167 (18%)]	Loss: 1.576881
[2022-03-29 12:57:31 | train] - Train Epoch: [30] [243200/1281167 (19%)]	Loss: 1.189447
[2022-03-29 12:57:52 | train] - Train Epoch: [30] [256000/1281167 (20%)]	Loss: 1.656285
[2022-03-29 12:58:13 | train] - Train Epoch: [30] [268800/1281167 (21%)]	Loss: 1.324897
[2022-03-29 12:58:34 | train] - Train Epoch: [30] [281600/1281167 (22%)]	Loss: 1.392748
[2022-03-29 12:58:55 | train] - Train Epoch: [30] [294400/1281167 (23%)]	Loss: 1.164560
[2022-03-29 12:59:16 | train] - Train Epoch: [30] [307200/1281167 (24%)]	Loss: 1.625504
[2022-03-29 12:59:36 | train] - Train Epoch: [30] [320000/1281167 (25%)]	Loss: 1.343958
[2022-03-29 12:59:58 | train] - Train Epoch: [30] [332800/1281167 (26%)]	Loss: 1.649758
[2022-03-29 13:00:18 | train] - Train Epoch: [30] [345600/1281167 (27%)]	Loss: 1.305761
[2022-03-29 13:00:40 | train] - Train Epoch: [30] [358400/1281167 (28%)]	Loss: 1.653366
[2022-03-29 13:01:01 | train] - Train Epoch: [30] [371200/1281167 (29%)]	Loss: 1.410437
[2022-03-29 13:01:21 | train] - Train Epoch: [30] [384000/1281167 (30%)]	Loss: 1.366204
[2022-03-29 13:01:43 | train] - Train Epoch: [30] [396800/1281167 (31%)]	Loss: 1.571103
[2022-03-29 13:02:04 | train] - Train Epoch: [30] [409600/1281167 (32%)]	Loss: 1.448398
[2022-03-29 13:02:25 | train] - Train Epoch: [30] [422400/1281167 (33%)]	Loss: 1.352216
[2022-03-29 13:02:45 | train] - Train Epoch: [30] [435200/1281167 (34%)]	Loss: 1.213714
[2022-03-29 13:03:06 | train] - Train Epoch: [30] [448000/1281167 (35%)]	Loss: 1.707331
[2022-03-29 13:03:27 | train] - Train Epoch: [30] [460800/1281167 (36%)]	Loss: 1.763830
[2022-03-29 13:03:49 | train] - Train Epoch: [30] [473600/1281167 (37%)]	Loss: 1.557462
[2022-03-29 13:04:10 | train] - Train Epoch: [30] [486400/1281167 (38%)]	Loss: 1.332576
[2022-03-29 13:04:31 | train] - Train Epoch: [30] [499200/1281167 (39%)]	Loss: 1.345711
[2022-03-29 13:04:52 | train] - Train Epoch: [30] [512000/1281167 (40%)]	Loss: 1.361681
[2022-03-29 13:05:13 | train] - Train Epoch: [30] [524800/1281167 (41%)]	Loss: 1.379395
[2022-03-29 13:05:33 | train] - Train Epoch: [30] [537600/1281167 (42%)]	Loss: 1.338049
[2022-03-29 13:05:55 | train] - Train Epoch: [30] [550400/1281167 (43%)]	Loss: 1.776823
[2022-03-29 13:06:16 | train] - Train Epoch: [30] [563200/1281167 (44%)]	Loss: 1.397014
[2022-03-29 13:06:37 | train] - Train Epoch: [30] [576000/1281167 (45%)]	Loss: 1.568216
[2022-03-29 13:06:58 | train] - Train Epoch: [30] [588800/1281167 (46%)]	Loss: 1.541726
[2022-03-29 13:07:19 | train] - Train Epoch: [30] [601600/1281167 (47%)]	Loss: 1.746415
[2022-03-29 13:07:41 | train] - Train Epoch: [30] [614400/1281167 (48%)]	Loss: 1.238865
[2022-03-29 13:08:01 | train] - Train Epoch: [30] [627200/1281167 (49%)]	Loss: 1.416411
[2022-03-29 13:08:23 | train] - Train Epoch: [30] [640000/1281167 (50%)]	Loss: 1.176576
[2022-03-29 13:08:44 | train] - Train Epoch: [30] [652800/1281167 (51%)]	Loss: 1.575544
[2022-03-29 13:09:05 | train] - Train Epoch: [30] [665600/1281167 (52%)]	Loss: 1.295635
[2022-03-29 13:09:26 | train] - Train Epoch: [30] [678400/1281167 (53%)]	Loss: 1.216609
[2022-03-29 13:09:47 | train] - Train Epoch: [30] [691200/1281167 (54%)]	Loss: 1.606330
[2022-03-29 13:10:09 | train] - Train Epoch: [30] [704000/1281167 (55%)]	Loss: 1.360245
[2022-03-29 13:10:30 | train] - Train Epoch: [30] [716800/1281167 (56%)]	Loss: 1.255169
[2022-03-29 13:10:51 | train] - Train Epoch: [30] [729600/1281167 (57%)]	Loss: 1.499844
[2022-03-29 13:11:12 | train] - Train Epoch: [30] [742400/1281167 (58%)]	Loss: 1.473381
[2022-03-29 13:11:33 | train] - Train Epoch: [30] [755200/1281167 (59%)]	Loss: 1.347934
[2022-03-29 13:11:54 | train] - Train Epoch: [30] [768000/1281167 (60%)]	Loss: 1.619785
[2022-03-29 13:12:15 | train] - Train Epoch: [30] [780800/1281167 (61%)]	Loss: 1.665224
[2022-03-29 13:12:36 | train] - Train Epoch: [30] [793600/1281167 (62%)]	Loss: 1.258934
[2022-03-29 13:12:57 | train] - Train Epoch: [30] [806400/1281167 (63%)]	Loss: 1.465468
[2022-03-29 13:13:19 | train] - Train Epoch: [30] [819200/1281167 (64%)]	Loss: 1.849221
[2022-03-29 13:13:39 | train] - Train Epoch: [30] [832000/1281167 (65%)]	Loss: 1.318639
[2022-03-29 13:14:00 | train] - Train Epoch: [30] [844800/1281167 (66%)]	Loss: 1.224114
[2022-03-29 13:14:21 | train] - Train Epoch: [30] [857600/1281167 (67%)]	Loss: 1.564631
[2022-03-29 13:14:43 | train] - Train Epoch: [30] [870400/1281167 (68%)]	Loss: 1.339155
[2022-03-29 13:15:04 | train] - Train Epoch: [30] [883200/1281167 (69%)]	Loss: 1.572783
[2022-03-29 13:15:25 | train] - Train Epoch: [30] [896000/1281167 (70%)]	Loss: 1.622562
[2022-03-29 13:15:46 | train] - Train Epoch: [30] [908800/1281167 (71%)]	Loss: 1.778473
[2022-03-29 13:16:07 | train] - Train Epoch: [30] [921600/1281167 (72%)]	Loss: 1.438180
[2022-03-29 13:16:28 | train] - Train Epoch: [30] [934400/1281167 (73%)]	Loss: 1.483761
[2022-03-29 13:16:50 | train] - Train Epoch: [30] [947200/1281167 (74%)]	Loss: 1.378928
[2022-03-29 13:17:11 | train] - Train Epoch: [30] [960000/1281167 (75%)]	Loss: 1.224013
[2022-03-29 13:17:32 | train] - Train Epoch: [30] [972800/1281167 (76%)]	Loss: 1.382537
[2022-03-29 13:17:53 | train] - Train Epoch: [30] [985600/1281167 (77%)]	Loss: 1.430057
[2022-03-29 13:18:14 | train] - Train Epoch: [30] [998400/1281167 (78%)]	Loss: 1.572055
[2022-03-29 13:18:35 | train] - Train Epoch: [30] [1011200/1281167 (79%)]	Loss: 1.083440
[2022-03-29 13:18:57 | train] - Train Epoch: [30] [1024000/1281167 (80%)]	Loss: 1.420146
[2022-03-29 13:19:18 | train] - Train Epoch: [30] [1036800/1281167 (81%)]	Loss: 1.398965
[2022-03-29 13:19:39 | train] - Train Epoch: [30] [1049600/1281167 (82%)]	Loss: 1.211903
[2022-03-29 13:20:00 | train] - Train Epoch: [30] [1062400/1281167 (83%)]	Loss: 1.663600
[2022-03-29 13:20:22 | train] - Train Epoch: [30] [1075200/1281167 (84%)]	Loss: 1.749452
[2022-03-29 13:20:43 | train] - Train Epoch: [30] [1088000/1281167 (85%)]	Loss: 1.452219
[2022-03-29 13:21:05 | train] - Train Epoch: [30] [1100800/1281167 (86%)]	Loss: 1.249408
[2022-03-29 13:21:26 | train] - Train Epoch: [30] [1113600/1281167 (87%)]	Loss: 1.713871
[2022-03-29 13:21:47 | train] - Train Epoch: [30] [1126400/1281167 (88%)]	Loss: 1.302339
[2022-03-29 13:22:08 | train] - Train Epoch: [30] [1139200/1281167 (89%)]	Loss: 1.456044
[2022-03-29 13:22:30 | train] - Train Epoch: [30] [1152000/1281167 (90%)]	Loss: 1.647707
[2022-03-29 13:22:51 | train] - Train Epoch: [30] [1164800/1281167 (91%)]	Loss: 1.429300
[2022-03-29 13:23:11 | train] - Train Epoch: [30] [1177600/1281167 (92%)]	Loss: 1.549894
[2022-03-29 13:23:33 | train] - Train Epoch: [30] [1190400/1281167 (93%)]	Loss: 1.443800
[2022-03-29 13:23:53 | train] - Train Epoch: [30] [1203200/1281167 (94%)]	Loss: 1.683954
[2022-03-29 13:24:15 | train] - Train Epoch: [30] [1216000/1281167 (95%)]	Loss: 1.709646
[2022-03-29 13:24:36 | train] - Train Epoch: [30] [1228800/1281167 (96%)]	Loss: 1.565963
[2022-03-29 13:24:57 | train] - Train Epoch: [30] [1241600/1281167 (97%)]	Loss: 1.456672
[2022-03-29 13:25:18 | train] - Train Epoch: [30] [1254400/1281167 (98%)]	Loss: 1.551212
[2022-03-29 13:25:40 | train] - Train Epoch: [30] [1267200/1281167 (99%)]	Loss: 1.298115
[2022-03-29 13:26:01 | train] - Train Epoch: [30] [1280000/1281167 (100%)]	Loss: 1.562882
[2022-03-29 13:26:03 | train] - Train Epoch: [30]	 Average Loss: 1.495209	 Total Acc : 64.7758	 Total Top5 Acc : 84.7175
[2022-03-29 13:26:07 | train] - -------30 epoch end-----------
========================================
-------30 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 13:27:47 | train] - 
Epoch [30] Test set: Average loss: 1.4141, Accuracy: 33048/50000 (66.0734%), Top-5 Accuracy: 86.9054%

[2022-03-29 13:27:47 | train] - save intermediate epoch [30] result


[2022-03-29 13:27:53 | train] - logging best performance 30 epoch
[2022-03-29 13:27:54 | train] - -------31 epoch start-----------
========================================
----- test end -------------------------


logging best performance 30 epoch
[2022-03-29 13:27:57 | train] - Train Epoch: [31] [0/1281167 (0%)]	Loss: 1.840401
[2022-03-29 13:28:19 | train] - Train Epoch: [31] [12800/1281167 (1%)]	Loss: 1.548117
[2022-03-29 13:28:40 | train] - Train Epoch: [31] [25600/1281167 (2%)]	Loss: 1.480519
[2022-03-29 13:29:01 | train] - Train Epoch: [31] [38400/1281167 (3%)]	Loss: 1.670586
[2022-03-29 13:29:23 | train] - Train Epoch: [31] [51200/1281167 (4%)]	Loss: 1.093475
[2022-03-29 13:29:45 | train] - Train Epoch: [31] [64000/1281167 (5%)]	Loss: 1.666514
[2022-03-29 13:30:06 | train] - Train Epoch: [31] [76800/1281167 (6%)]	Loss: 1.315116
[2022-03-29 13:30:27 | train] - Train Epoch: [31] [89600/1281167 (7%)]	Loss: 1.459845
[2022-03-29 13:30:49 | train] - Train Epoch: [31] [102400/1281167 (8%)]	Loss: 1.187086
[2022-03-29 13:31:10 | train] - Train Epoch: [31] [115200/1281167 (9%)]	Loss: 1.525267
[2022-03-29 13:31:32 | train] - Train Epoch: [31] [128000/1281167 (10%)]	Loss: 1.281841
[2022-03-29 13:31:53 | train] - Train Epoch: [31] [140800/1281167 (11%)]	Loss: 1.682172
[2022-03-29 13:32:14 | train] - Train Epoch: [31] [153600/1281167 (12%)]	Loss: 1.477248
[2022-03-29 13:32:36 | train] - Train Epoch: [31] [166400/1281167 (13%)]	Loss: 1.149680
[2022-03-29 13:32:57 | train] - Train Epoch: [31] [179200/1281167 (14%)]	Loss: 1.588213
[2022-03-29 13:33:18 | train] - Train Epoch: [31] [192000/1281167 (15%)]	Loss: 1.423474
[2022-03-29 13:33:40 | train] - Train Epoch: [31] [204800/1281167 (16%)]	Loss: 1.275102
[2022-03-29 13:34:02 | train] - Train Epoch: [31] [217600/1281167 (17%)]	Loss: 1.578435
[2022-03-29 13:34:23 | train] - Train Epoch: [31] [230400/1281167 (18%)]	Loss: 1.486198
[2022-03-29 13:34:45 | train] - Train Epoch: [31] [243200/1281167 (19%)]	Loss: 1.272305
[2022-03-29 13:35:07 | train] - Train Epoch: [31] [256000/1281167 (20%)]	Loss: 1.522900
[2022-03-29 13:35:28 | train] - Train Epoch: [31] [268800/1281167 (21%)]	Loss: 1.766373
[2022-03-29 13:35:50 | train] - Train Epoch: [31] [281600/1281167 (22%)]	Loss: 1.481347
[2022-03-29 13:36:12 | train] - Train Epoch: [31] [294400/1281167 (23%)]	Loss: 1.508468
[2022-03-29 13:36:34 | train] - Train Epoch: [31] [307200/1281167 (24%)]	Loss: 1.664746
[2022-03-29 13:36:55 | train] - Train Epoch: [31] [320000/1281167 (25%)]	Loss: 1.756985
[2022-03-29 13:37:16 | train] - Train Epoch: [31] [332800/1281167 (26%)]	Loss: 1.457614
[2022-03-29 13:37:38 | train] - Train Epoch: [31] [345600/1281167 (27%)]	Loss: 1.402170
[2022-03-29 13:37:59 | train] - Train Epoch: [31] [358400/1281167 (28%)]	Loss: 1.691335
[2022-03-29 13:38:20 | train] - Train Epoch: [31] [371200/1281167 (29%)]	Loss: 1.146929
[2022-03-29 13:38:41 | train] - Train Epoch: [31] [384000/1281167 (30%)]	Loss: 1.654009
[2022-03-29 13:39:03 | train] - Train Epoch: [31] [396800/1281167 (31%)]	Loss: 1.500113
[2022-03-29 13:39:24 | train] - Train Epoch: [31] [409600/1281167 (32%)]	Loss: 1.494447
[2022-03-29 13:39:46 | train] - Train Epoch: [31] [422400/1281167 (33%)]	Loss: 1.582827
[2022-03-29 13:40:08 | train] - Train Epoch: [31] [435200/1281167 (34%)]	Loss: 1.727723
[2022-03-29 13:40:30 | train] - Train Epoch: [31] [448000/1281167 (35%)]	Loss: 1.215611
[2022-03-29 13:40:51 | train] - Train Epoch: [31] [460800/1281167 (36%)]	Loss: 1.448579
[2022-03-29 13:41:12 | train] - Train Epoch: [31] [473600/1281167 (37%)]	Loss: 1.367945
[2022-03-29 13:41:34 | train] - Train Epoch: [31] [486400/1281167 (38%)]	Loss: 1.642876
[2022-03-29 13:41:55 | train] - Train Epoch: [31] [499200/1281167 (39%)]	Loss: 1.132616
[2022-03-29 13:42:17 | train] - Train Epoch: [31] [512000/1281167 (40%)]	Loss: 1.822609
[2022-03-29 13:42:38 | train] - Train Epoch: [31] [524800/1281167 (41%)]	Loss: 1.550808
[2022-03-29 13:43:00 | train] - Train Epoch: [31] [537600/1281167 (42%)]	Loss: 1.351215
[2022-03-29 13:43:22 | train] - Train Epoch: [31] [550400/1281167 (43%)]	Loss: 1.325893
[2022-03-29 13:43:43 | train] - Train Epoch: [31] [563200/1281167 (44%)]	Loss: 1.420202
[2022-03-29 13:44:04 | train] - Train Epoch: [31] [576000/1281167 (45%)]	Loss: 1.404874
[2022-03-29 13:44:26 | train] - Train Epoch: [31] [588800/1281167 (46%)]	Loss: 1.449005
[2022-03-29 13:44:48 | train] - Train Epoch: [31] [601600/1281167 (47%)]	Loss: 1.404338
[2022-03-29 13:45:09 | train] - Train Epoch: [31] [614400/1281167 (48%)]	Loss: 1.294435
[2022-03-29 13:45:30 | train] - Train Epoch: [31] [627200/1281167 (49%)]	Loss: 1.353528
[2022-03-29 13:45:52 | train] - Train Epoch: [31] [640000/1281167 (50%)]	Loss: 1.896374
[2022-03-29 13:46:13 | train] - Train Epoch: [31] [652800/1281167 (51%)]	Loss: 1.500652
[2022-03-29 13:46:34 | train] - Train Epoch: [31] [665600/1281167 (52%)]	Loss: 1.396528
[2022-03-29 13:46:56 | train] - Train Epoch: [31] [678400/1281167 (53%)]	Loss: 1.551296
[2022-03-29 13:47:17 | train] - Train Epoch: [31] [691200/1281167 (54%)]	Loss: 1.577897
[2022-03-29 13:47:38 | train] - Train Epoch: [31] [704000/1281167 (55%)]	Loss: 1.481802
[2022-03-29 13:48:00 | train] - Train Epoch: [31] [716800/1281167 (56%)]	Loss: 1.248739
[2022-03-29 13:48:21 | train] - Train Epoch: [31] [729600/1281167 (57%)]	Loss: 1.700787
[2022-03-29 13:48:43 | train] - Train Epoch: [31] [742400/1281167 (58%)]	Loss: 1.548355
[2022-03-29 13:49:05 | train] - Train Epoch: [31] [755200/1281167 (59%)]	Loss: 1.409634
[2022-03-29 13:49:26 | train] - Train Epoch: [31] [768000/1281167 (60%)]	Loss: 1.636279
[2022-03-29 13:49:49 | train] - Train Epoch: [31] [780800/1281167 (61%)]	Loss: 1.448931
[2022-03-29 13:50:10 | train] - Train Epoch: [31] [793600/1281167 (62%)]	Loss: 1.620274
[2022-03-29 13:50:32 | train] - Train Epoch: [31] [806400/1281167 (63%)]	Loss: 1.387146
[2022-03-29 13:50:54 | train] - Train Epoch: [31] [819200/1281167 (64%)]	Loss: 1.666769
[2022-03-29 13:51:15 | train] - Train Epoch: [31] [832000/1281167 (65%)]	Loss: 1.251030
[2022-03-29 13:51:37 | train] - Train Epoch: [31] [844800/1281167 (66%)]	Loss: 1.555862
[2022-03-29 13:51:58 | train] - Train Epoch: [31] [857600/1281167 (67%)]	Loss: 1.325975
[2022-03-29 13:52:20 | train] - Train Epoch: [31] [870400/1281167 (68%)]	Loss: 1.700795
[2022-03-29 13:52:41 | train] - Train Epoch: [31] [883200/1281167 (69%)]	Loss: 1.693366
[2022-03-29 13:53:04 | train] - Train Epoch: [31] [896000/1281167 (70%)]	Loss: 1.529657
[2022-03-29 13:53:25 | train] - Train Epoch: [31] [908800/1281167 (71%)]	Loss: 1.297377
[2022-03-29 13:53:46 | train] - Train Epoch: [31] [921600/1281167 (72%)]	Loss: 1.770517
[2022-03-29 13:54:07 | train] - Train Epoch: [31] [934400/1281167 (73%)]	Loss: 1.394561
[2022-03-29 13:54:28 | train] - Train Epoch: [31] [947200/1281167 (74%)]	Loss: 1.601401
[2022-03-29 13:54:50 | train] - Train Epoch: [31] [960000/1281167 (75%)]	Loss: 1.225467
[2022-03-29 13:55:12 | train] - Train Epoch: [31] [972800/1281167 (76%)]	Loss: 1.240859
[2022-03-29 13:55:34 | train] - Train Epoch: [31] [985600/1281167 (77%)]	Loss: 1.449550
[2022-03-29 13:55:56 | train] - Train Epoch: [31] [998400/1281167 (78%)]	Loss: 1.346015
[2022-03-29 13:56:17 | train] - Train Epoch: [31] [1011200/1281167 (79%)]	Loss: 1.576348
[2022-03-29 13:56:38 | train] - Train Epoch: [31] [1024000/1281167 (80%)]	Loss: 1.534944
[2022-03-29 13:56:59 | train] - Train Epoch: [31] [1036800/1281167 (81%)]	Loss: 1.833529
[2022-03-29 13:57:21 | train] - Train Epoch: [31] [1049600/1281167 (82%)]	Loss: 1.471466
[2022-03-29 13:57:42 | train] - Train Epoch: [31] [1062400/1281167 (83%)]	Loss: 1.372823
[2022-03-29 13:58:04 | train] - Train Epoch: [31] [1075200/1281167 (84%)]	Loss: 1.312010
[2022-03-29 13:58:25 | train] - Train Epoch: [31] [1088000/1281167 (85%)]	Loss: 1.432219
[2022-03-29 13:58:47 | train] - Train Epoch: [31] [1100800/1281167 (86%)]	Loss: 1.374404
[2022-03-29 13:59:08 | train] - Train Epoch: [31] [1113600/1281167 (87%)]	Loss: 1.397250
[2022-03-29 13:59:30 | train] - Train Epoch: [31] [1126400/1281167 (88%)]	Loss: 1.254904
[2022-03-29 13:59:52 | train] - Train Epoch: [31] [1139200/1281167 (89%)]	Loss: 1.557781
[2022-03-29 14:00:13 | train] - Train Epoch: [31] [1152000/1281167 (90%)]	Loss: 1.380276
[2022-03-29 14:00:34 | train] - Train Epoch: [31] [1164800/1281167 (91%)]	Loss: 1.141214
[2022-03-29 14:00:56 | train] - Train Epoch: [31] [1177600/1281167 (92%)]	Loss: 1.428247
[2022-03-29 14:01:18 | train] - Train Epoch: [31] [1190400/1281167 (93%)]	Loss: 1.392907
[2022-03-29 14:01:40 | train] - Train Epoch: [31] [1203200/1281167 (94%)]	Loss: 1.556770
[2022-03-29 14:02:02 | train] - Train Epoch: [31] [1216000/1281167 (95%)]	Loss: 1.836539
[2022-03-29 14:02:24 | train] - Train Epoch: [31] [1228800/1281167 (96%)]	Loss: 1.271742
[2022-03-29 14:02:45 | train] - Train Epoch: [31] [1241600/1281167 (97%)]	Loss: 1.707970
[2022-03-29 14:03:06 | train] - Train Epoch: [31] [1254400/1281167 (98%)]	Loss: 1.720307
[2022-03-29 14:03:28 | train] - Train Epoch: [31] [1267200/1281167 (99%)]	Loss: 1.535408
[2022-03-29 14:03:50 | train] - Train Epoch: [31] [1280000/1281167 (100%)]	Loss: 1.620995
[2022-03-29 14:03:52 | train] - Train Epoch: [31]	 Average Loss: 1.478485	 Total Acc : 65.1750	 Total Top5 Acc : 84.9318
[2022-03-29 14:03:55 | train] - -------31 epoch end-----------
========================================
-------31 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 14:05:35 | train] - 
Epoch [31] Test set: Average loss: 1.4082, Accuracy: 33264/50000 (66.5014%), Top-5 Accuracy: 87.1459%

[2022-03-29 14:05:35 | train] - save intermediate epoch [31] result


[2022-03-29 14:05:42 | train] - logging best performance 31 epoch
[2022-03-29 14:05:44 | train] - -------32 epoch start-----------
========================================
----- test end -------------------------


logging best performance 31 epoch
[2022-03-29 14:05:46 | train] - Train Epoch: [32] [0/1281167 (0%)]	Loss: 1.490680
[2022-03-29 14:06:08 | train] - Train Epoch: [32] [12800/1281167 (1%)]	Loss: 1.397696
[2022-03-29 14:06:29 | train] - Train Epoch: [32] [25600/1281167 (2%)]	Loss: 1.184237
[2022-03-29 14:06:49 | train] - Train Epoch: [32] [38400/1281167 (3%)]	Loss: 1.527753
[2022-03-29 14:07:11 | train] - Train Epoch: [32] [51200/1281167 (4%)]	Loss: 1.374704
[2022-03-29 14:07:32 | train] - Train Epoch: [32] [64000/1281167 (5%)]	Loss: 1.237839
[2022-03-29 14:07:53 | train] - Train Epoch: [32] [76800/1281167 (6%)]	Loss: 1.273333
[2022-03-29 14:08:13 | train] - Train Epoch: [32] [89600/1281167 (7%)]	Loss: 1.572772
[2022-03-29 14:08:34 | train] - Train Epoch: [32] [102400/1281167 (8%)]	Loss: 1.298497
[2022-03-29 14:08:54 | train] - Train Epoch: [32] [115200/1281167 (9%)]	Loss: 1.146410
[2022-03-29 14:09:15 | train] - Train Epoch: [32] [128000/1281167 (10%)]	Loss: 1.576795
[2022-03-29 14:09:35 | train] - Train Epoch: [32] [140800/1281167 (11%)]	Loss: 1.367141
[2022-03-29 14:09:57 | train] - Train Epoch: [32] [153600/1281167 (12%)]	Loss: 1.365881
[2022-03-29 14:10:17 | train] - Train Epoch: [32] [166400/1281167 (13%)]	Loss: 1.144613
[2022-03-29 14:10:38 | train] - Train Epoch: [32] [179200/1281167 (14%)]	Loss: 1.377652
[2022-03-29 14:10:58 | train] - Train Epoch: [32] [192000/1281167 (15%)]	Loss: 1.416820
[2022-03-29 14:11:19 | train] - Train Epoch: [32] [204800/1281167 (16%)]	Loss: 1.294394
[2022-03-29 14:11:40 | train] - Train Epoch: [32] [217600/1281167 (17%)]	Loss: 1.473072
[2022-03-29 14:12:00 | train] - Train Epoch: [32] [230400/1281167 (18%)]	Loss: 1.399676
[2022-03-29 14:12:21 | train] - Train Epoch: [32] [243200/1281167 (19%)]	Loss: 1.213265
[2022-03-29 14:12:42 | train] - Train Epoch: [32] [256000/1281167 (20%)]	Loss: 1.195383
[2022-03-29 14:13:03 | train] - Train Epoch: [32] [268800/1281167 (21%)]	Loss: 1.324822
[2022-03-29 14:13:24 | train] - Train Epoch: [32] [281600/1281167 (22%)]	Loss: 1.524948
[2022-03-29 14:13:45 | train] - Train Epoch: [32] [294400/1281167 (23%)]	Loss: 1.407191
[2022-03-29 14:14:05 | train] - Train Epoch: [32] [307200/1281167 (24%)]	Loss: 1.654747
[2022-03-29 14:14:26 | train] - Train Epoch: [32] [320000/1281167 (25%)]	Loss: 1.448082
[2022-03-29 14:14:47 | train] - Train Epoch: [32] [332800/1281167 (26%)]	Loss: 1.376371
[2022-03-29 14:15:08 | train] - Train Epoch: [32] [345600/1281167 (27%)]	Loss: 1.477846
[2022-03-29 14:15:29 | train] - Train Epoch: [32] [358400/1281167 (28%)]	Loss: 1.270775
[2022-03-29 14:15:50 | train] - Train Epoch: [32] [371200/1281167 (29%)]	Loss: 1.336355
[2022-03-29 14:16:11 | train] - Train Epoch: [32] [384000/1281167 (30%)]	Loss: 1.217035
[2022-03-29 14:16:32 | train] - Train Epoch: [32] [396800/1281167 (31%)]	Loss: 1.446995
[2022-03-29 14:16:53 | train] - Train Epoch: [32] [409600/1281167 (32%)]	Loss: 1.499354
[2022-03-29 14:17:14 | train] - Train Epoch: [32] [422400/1281167 (33%)]	Loss: 1.401337
[2022-03-29 14:17:35 | train] - Train Epoch: [32] [435200/1281167 (34%)]	Loss: 1.182597
[2022-03-29 14:17:55 | train] - Train Epoch: [32] [448000/1281167 (35%)]	Loss: 1.365536
[2022-03-29 14:18:17 | train] - Train Epoch: [32] [460800/1281167 (36%)]	Loss: 1.314781
[2022-03-29 14:18:38 | train] - Train Epoch: [32] [473600/1281167 (37%)]	Loss: 1.368861
[2022-03-29 14:18:59 | train] - Train Epoch: [32] [486400/1281167 (38%)]	Loss: 1.439198
[2022-03-29 14:19:19 | train] - Train Epoch: [32] [499200/1281167 (39%)]	Loss: 1.478954
[2022-03-29 14:19:40 | train] - Train Epoch: [32] [512000/1281167 (40%)]	Loss: 1.574877
[2022-03-29 14:20:01 | train] - Train Epoch: [32] [524800/1281167 (41%)]	Loss: 1.552882
[2022-03-29 14:20:22 | train] - Train Epoch: [32] [537600/1281167 (42%)]	Loss: 1.305734
[2022-03-29 14:20:43 | train] - Train Epoch: [32] [550400/1281167 (43%)]	Loss: 1.280914
[2022-03-29 14:21:04 | train] - Train Epoch: [32] [563200/1281167 (44%)]	Loss: 1.359219
[2022-03-29 14:21:25 | train] - Train Epoch: [32] [576000/1281167 (45%)]	Loss: 1.864316
[2022-03-29 14:21:46 | train] - Train Epoch: [32] [588800/1281167 (46%)]	Loss: 1.136337
[2022-03-29 14:22:08 | train] - Train Epoch: [32] [601600/1281167 (47%)]	Loss: 1.584592
[2022-03-29 14:22:29 | train] - Train Epoch: [32] [614400/1281167 (48%)]	Loss: 1.488837
[2022-03-29 14:22:50 | train] - Train Epoch: [32] [627200/1281167 (49%)]	Loss: 1.383403
[2022-03-29 14:23:11 | train] - Train Epoch: [32] [640000/1281167 (50%)]	Loss: 1.366924
[2022-03-29 14:23:32 | train] - Train Epoch: [32] [652800/1281167 (51%)]	Loss: 1.707038
[2022-03-29 14:23:52 | train] - Train Epoch: [32] [665600/1281167 (52%)]	Loss: 1.338634
[2022-03-29 14:24:13 | train] - Train Epoch: [32] [678400/1281167 (53%)]	Loss: 1.526233
[2022-03-29 14:24:34 | train] - Train Epoch: [32] [691200/1281167 (54%)]	Loss: 1.510787
[2022-03-29 14:24:56 | train] - Train Epoch: [32] [704000/1281167 (55%)]	Loss: 1.508279
[2022-03-29 14:25:17 | train] - Train Epoch: [32] [716800/1281167 (56%)]	Loss: 1.391755
[2022-03-29 14:25:39 | train] - Train Epoch: [32] [729600/1281167 (57%)]	Loss: 1.702546
[2022-03-29 14:26:00 | train] - Train Epoch: [32] [742400/1281167 (58%)]	Loss: 1.552131
[2022-03-29 14:26:21 | train] - Train Epoch: [32] [755200/1281167 (59%)]	Loss: 1.702010
[2022-03-29 14:26:42 | train] - Train Epoch: [32] [768000/1281167 (60%)]	Loss: 1.456731
[2022-03-29 14:27:03 | train] - Train Epoch: [32] [780800/1281167 (61%)]	Loss: 1.356904
[2022-03-29 14:27:25 | train] - Train Epoch: [32] [793600/1281167 (62%)]	Loss: 1.718481
[2022-03-29 14:27:46 | train] - Train Epoch: [32] [806400/1281167 (63%)]	Loss: 1.480221
[2022-03-29 14:28:06 | train] - Train Epoch: [32] [819200/1281167 (64%)]	Loss: 1.740770
[2022-03-29 14:28:27 | train] - Train Epoch: [32] [832000/1281167 (65%)]	Loss: 1.564551
[2022-03-29 14:28:48 | train] - Train Epoch: [32] [844800/1281167 (66%)]	Loss: 1.428720
[2022-03-29 14:29:09 | train] - Train Epoch: [32] [857600/1281167 (67%)]	Loss: 1.543697
[2022-03-29 14:29:30 | train] - Train Epoch: [32] [870400/1281167 (68%)]	Loss: 1.367017
[2022-03-29 14:29:51 | train] - Train Epoch: [32] [883200/1281167 (69%)]	Loss: 1.622865
[2022-03-29 14:30:13 | train] - Train Epoch: [32] [896000/1281167 (70%)]	Loss: 2.014763
[2022-03-29 14:30:34 | train] - Train Epoch: [32] [908800/1281167 (71%)]	Loss: 1.078839
[2022-03-29 14:30:56 | train] - Train Epoch: [32] [921600/1281167 (72%)]	Loss: 1.569237
[2022-03-29 14:31:17 | train] - Train Epoch: [32] [934400/1281167 (73%)]	Loss: 1.219328
[2022-03-29 14:31:38 | train] - Train Epoch: [32] [947200/1281167 (74%)]	Loss: 1.379010
[2022-03-29 14:31:59 | train] - Train Epoch: [32] [960000/1281167 (75%)]	Loss: 1.461808
[2022-03-29 14:32:19 | train] - Train Epoch: [32] [972800/1281167 (76%)]	Loss: 1.210692
[2022-03-29 14:32:40 | train] - Train Epoch: [32] [985600/1281167 (77%)]	Loss: 1.554316
[2022-03-29 14:33:01 | train] - Train Epoch: [32] [998400/1281167 (78%)]	Loss: 1.556215
[2022-03-29 14:33:23 | train] - Train Epoch: [32] [1011200/1281167 (79%)]	Loss: 1.243364
[2022-03-29 14:33:43 | train] - Train Epoch: [32] [1024000/1281167 (80%)]	Loss: 1.325897
[2022-03-29 14:34:04 | train] - Train Epoch: [32] [1036800/1281167 (81%)]	Loss: 1.318668
[2022-03-29 14:34:26 | train] - Train Epoch: [32] [1049600/1281167 (82%)]	Loss: 1.441739
[2022-03-29 14:34:46 | train] - Train Epoch: [32] [1062400/1281167 (83%)]	Loss: 1.418730
[2022-03-29 14:35:07 | train] - Train Epoch: [32] [1075200/1281167 (84%)]	Loss: 1.397491
[2022-03-29 14:35:29 | train] - Train Epoch: [32] [1088000/1281167 (85%)]	Loss: 1.635622
[2022-03-29 14:35:50 | train] - Train Epoch: [32] [1100800/1281167 (86%)]	Loss: 1.144423
[2022-03-29 14:36:11 | train] - Train Epoch: [32] [1113600/1281167 (87%)]	Loss: 1.361311
[2022-03-29 14:36:32 | train] - Train Epoch: [32] [1126400/1281167 (88%)]	Loss: 1.282125
[2022-03-29 14:36:53 | train] - Train Epoch: [32] [1139200/1281167 (89%)]	Loss: 1.671153
[2022-03-29 14:37:15 | train] - Train Epoch: [32] [1152000/1281167 (90%)]	Loss: 1.561925
[2022-03-29 14:37:36 | train] - Train Epoch: [32] [1164800/1281167 (91%)]	Loss: 1.427711
[2022-03-29 14:37:57 | train] - Train Epoch: [32] [1177600/1281167 (92%)]	Loss: 1.795619
[2022-03-29 14:38:19 | train] - Train Epoch: [32] [1190400/1281167 (93%)]	Loss: 1.780257
[2022-03-29 14:38:40 | train] - Train Epoch: [32] [1203200/1281167 (94%)]	Loss: 1.685568
[2022-03-29 14:39:02 | train] - Train Epoch: [32] [1216000/1281167 (95%)]	Loss: 1.194991
[2022-03-29 14:39:24 | train] - Train Epoch: [32] [1228800/1281167 (96%)]	Loss: 1.431156
[2022-03-29 14:39:45 | train] - Train Epoch: [32] [1241600/1281167 (97%)]	Loss: 1.823127
[2022-03-29 14:40:07 | train] - Train Epoch: [32] [1254400/1281167 (98%)]	Loss: 1.677911
[2022-03-29 14:40:28 | train] - Train Epoch: [32] [1267200/1281167 (99%)]	Loss: 1.630076
[2022-03-29 14:40:49 | train] - Train Epoch: [32] [1280000/1281167 (100%)]	Loss: 1.613422
[2022-03-29 14:40:51 | train] - Train Epoch: [32]	 Average Loss: 1.460660	 Total Acc : 65.5184	 Total Top5 Acc : 85.1529
[2022-03-29 14:40:55 | train] - -------32 epoch end-----------
========================================
-------32 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 14:42:36 | train] - 
Epoch [32] Test set: Average loss: 1.4182, Accuracy: 33200/50000 (66.3747%), Top-5 Accuracy: 86.9605%

[2022-03-29 14:42:36 | train] - save intermediate epoch [32] result


[2022-03-29 14:42:44 | train] - -------33 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 14:42:46 | train] - Train Epoch: [33] [0/1281167 (0%)]	Loss: 1.553916
[2022-03-29 14:43:08 | train] - Train Epoch: [33] [12800/1281167 (1%)]	Loss: 1.608135
[2022-03-29 14:43:29 | train] - Train Epoch: [33] [25600/1281167 (2%)]	Loss: 1.345769
[2022-03-29 14:43:51 | train] - Train Epoch: [33] [38400/1281167 (3%)]	Loss: 1.527543
[2022-03-29 14:44:13 | train] - Train Epoch: [33] [51200/1281167 (4%)]	Loss: 1.611564
[2022-03-29 14:44:34 | train] - Train Epoch: [33] [64000/1281167 (5%)]	Loss: 1.043787
[2022-03-29 14:44:55 | train] - Train Epoch: [33] [76800/1281167 (6%)]	Loss: 1.349347
[2022-03-29 14:45:17 | train] - Train Epoch: [33] [89600/1281167 (7%)]	Loss: 1.422650
[2022-03-29 14:45:38 | train] - Train Epoch: [33] [102400/1281167 (8%)]	Loss: 1.542287
[2022-03-29 14:45:59 | train] - Train Epoch: [33] [115200/1281167 (9%)]	Loss: 1.423193
[2022-03-29 14:46:20 | train] - Train Epoch: [33] [128000/1281167 (10%)]	Loss: 1.408584
[2022-03-29 14:46:42 | train] - Train Epoch: [33] [140800/1281167 (11%)]	Loss: 1.559716
[2022-03-29 14:47:02 | train] - Train Epoch: [33] [153600/1281167 (12%)]	Loss: 1.643143
[2022-03-29 14:47:24 | train] - Train Epoch: [33] [166400/1281167 (13%)]	Loss: 1.339716
[2022-03-29 14:47:44 | train] - Train Epoch: [33] [179200/1281167 (14%)]	Loss: 1.341416
[2022-03-29 14:48:06 | train] - Train Epoch: [33] [192000/1281167 (15%)]	Loss: 1.519809
[2022-03-29 14:48:27 | train] - Train Epoch: [33] [204800/1281167 (16%)]	Loss: 1.161477
[2022-03-29 14:48:48 | train] - Train Epoch: [33] [217600/1281167 (17%)]	Loss: 1.184293
[2022-03-29 14:49:09 | train] - Train Epoch: [33] [230400/1281167 (18%)]	Loss: 1.642411
[2022-03-29 14:49:30 | train] - Train Epoch: [33] [243200/1281167 (19%)]	Loss: 1.523410
[2022-03-29 14:49:51 | train] - Train Epoch: [33] [256000/1281167 (20%)]	Loss: 1.556024
[2022-03-29 14:50:12 | train] - Train Epoch: [33] [268800/1281167 (21%)]	Loss: 1.227749
[2022-03-29 14:50:33 | train] - Train Epoch: [33] [281600/1281167 (22%)]	Loss: 1.438142
[2022-03-29 14:50:55 | train] - Train Epoch: [33] [294400/1281167 (23%)]	Loss: 1.299547
[2022-03-29 14:51:15 | train] - Train Epoch: [33] [307200/1281167 (24%)]	Loss: 1.723999
[2022-03-29 14:51:36 | train] - Train Epoch: [33] [320000/1281167 (25%)]	Loss: 1.675756
[2022-03-29 14:51:58 | train] - Train Epoch: [33] [332800/1281167 (26%)]	Loss: 1.194607
[2022-03-29 14:52:19 | train] - Train Epoch: [33] [345600/1281167 (27%)]	Loss: 1.595937
[2022-03-29 14:52:40 | train] - Train Epoch: [33] [358400/1281167 (28%)]	Loss: 1.254598
[2022-03-29 14:53:01 | train] - Train Epoch: [33] [371200/1281167 (29%)]	Loss: 1.660413
[2022-03-29 14:53:22 | train] - Train Epoch: [33] [384000/1281167 (30%)]	Loss: 1.453070
[2022-03-29 14:53:43 | train] - Train Epoch: [33] [396800/1281167 (31%)]	Loss: 1.654569
[2022-03-29 14:54:05 | train] - Train Epoch: [33] [409600/1281167 (32%)]	Loss: 1.343935
[2022-03-29 14:54:25 | train] - Train Epoch: [33] [422400/1281167 (33%)]	Loss: 1.103096
[2022-03-29 14:54:47 | train] - Train Epoch: [33] [435200/1281167 (34%)]	Loss: 1.348861
[2022-03-29 14:55:09 | train] - Train Epoch: [33] [448000/1281167 (35%)]	Loss: 1.957087
[2022-03-29 14:55:30 | train] - Train Epoch: [33] [460800/1281167 (36%)]	Loss: 1.413717
[2022-03-29 14:55:51 | train] - Train Epoch: [33] [473600/1281167 (37%)]	Loss: 1.596353
[2022-03-29 14:56:12 | train] - Train Epoch: [33] [486400/1281167 (38%)]	Loss: 1.695585
[2022-03-29 14:56:34 | train] - Train Epoch: [33] [499200/1281167 (39%)]	Loss: 1.592577
[2022-03-29 14:56:55 | train] - Train Epoch: [33] [512000/1281167 (40%)]	Loss: 1.567400
[2022-03-29 14:57:16 | train] - Train Epoch: [33] [524800/1281167 (41%)]	Loss: 1.403105
[2022-03-29 14:57:37 | train] - Train Epoch: [33] [537600/1281167 (42%)]	Loss: 1.516397
[2022-03-29 14:57:58 | train] - Train Epoch: [33] [550400/1281167 (43%)]	Loss: 1.402180
[2022-03-29 14:58:19 | train] - Train Epoch: [33] [563200/1281167 (44%)]	Loss: 1.600500
[2022-03-29 14:58:41 | train] - Train Epoch: [33] [576000/1281167 (45%)]	Loss: 1.235222
[2022-03-29 14:59:02 | train] - Train Epoch: [33] [588800/1281167 (46%)]	Loss: 1.366440
[2022-03-29 14:59:23 | train] - Train Epoch: [33] [601600/1281167 (47%)]	Loss: 1.208661
[2022-03-29 14:59:44 | train] - Train Epoch: [33] [614400/1281167 (48%)]	Loss: 1.404181
[2022-03-29 15:00:06 | train] - Train Epoch: [33] [627200/1281167 (49%)]	Loss: 1.623442
[2022-03-29 15:00:27 | train] - Train Epoch: [33] [640000/1281167 (50%)]	Loss: 1.445976
[2022-03-29 15:00:49 | train] - Train Epoch: [33] [652800/1281167 (51%)]	Loss: 1.350415
[2022-03-29 15:01:09 | train] - Train Epoch: [33] [665600/1281167 (52%)]	Loss: 1.754659
[2022-03-29 15:01:31 | train] - Train Epoch: [33] [678400/1281167 (53%)]	Loss: 1.376050
[2022-03-29 15:01:53 | train] - Train Epoch: [33] [691200/1281167 (54%)]	Loss: 1.296649
[2022-03-29 15:02:14 | train] - Train Epoch: [33] [704000/1281167 (55%)]	Loss: 1.711963
[2022-03-29 15:02:36 | train] - Train Epoch: [33] [716800/1281167 (56%)]	Loss: 1.739365
[2022-03-29 15:02:57 | train] - Train Epoch: [33] [729600/1281167 (57%)]	Loss: 1.332020
[2022-03-29 15:03:18 | train] - Train Epoch: [33] [742400/1281167 (58%)]	Loss: 1.415627
[2022-03-29 15:03:39 | train] - Train Epoch: [33] [755200/1281167 (59%)]	Loss: 1.693220
[2022-03-29 15:03:59 | train] - Train Epoch: [33] [768000/1281167 (60%)]	Loss: 1.449945
[2022-03-29 15:04:21 | train] - Train Epoch: [33] [780800/1281167 (61%)]	Loss: 1.403878
[2022-03-29 15:04:42 | train] - Train Epoch: [33] [793600/1281167 (62%)]	Loss: 1.172659
[2022-03-29 15:05:03 | train] - Train Epoch: [33] [806400/1281167 (63%)]	Loss: 1.679557
[2022-03-29 15:05:25 | train] - Train Epoch: [33] [819200/1281167 (64%)]	Loss: 1.408357
[2022-03-29 15:05:46 | train] - Train Epoch: [33] [832000/1281167 (65%)]	Loss: 1.482352
[2022-03-29 15:06:08 | train] - Train Epoch: [33] [844800/1281167 (66%)]	Loss: 1.484565
[2022-03-29 15:06:29 | train] - Train Epoch: [33] [857600/1281167 (67%)]	Loss: 1.623403
[2022-03-29 15:06:50 | train] - Train Epoch: [33] [870400/1281167 (68%)]	Loss: 1.420303
[2022-03-29 15:07:11 | train] - Train Epoch: [33] [883200/1281167 (69%)]	Loss: 1.443379
[2022-03-29 15:07:33 | train] - Train Epoch: [33] [896000/1281167 (70%)]	Loss: 1.548281
[2022-03-29 15:07:54 | train] - Train Epoch: [33] [908800/1281167 (71%)]	Loss: 1.812725
[2022-03-29 15:08:15 | train] - Train Epoch: [33] [921600/1281167 (72%)]	Loss: 1.127120
[2022-03-29 15:08:36 | train] - Train Epoch: [33] [934400/1281167 (73%)]	Loss: 1.696117
[2022-03-29 15:08:58 | train] - Train Epoch: [33] [947200/1281167 (74%)]	Loss: 1.212923
[2022-03-29 15:09:19 | train] - Train Epoch: [33] [960000/1281167 (75%)]	Loss: 1.360494
[2022-03-29 15:09:40 | train] - Train Epoch: [33] [972800/1281167 (76%)]	Loss: 2.151263
[2022-03-29 15:10:02 | train] - Train Epoch: [33] [985600/1281167 (77%)]	Loss: 1.493629
[2022-03-29 15:10:22 | train] - Train Epoch: [33] [998400/1281167 (78%)]	Loss: 1.308702
[2022-03-29 15:10:44 | train] - Train Epoch: [33] [1011200/1281167 (79%)]	Loss: 1.325625
[2022-03-29 15:11:05 | train] - Train Epoch: [33] [1024000/1281167 (80%)]	Loss: 1.323154
[2022-03-29 15:11:26 | train] - Train Epoch: [33] [1036800/1281167 (81%)]	Loss: 1.573628
[2022-03-29 15:11:48 | train] - Train Epoch: [33] [1049600/1281167 (82%)]	Loss: 1.072617
[2022-03-29 15:12:08 | train] - Train Epoch: [33] [1062400/1281167 (83%)]	Loss: 1.420195
[2022-03-29 15:12:29 | train] - Train Epoch: [33] [1075200/1281167 (84%)]	Loss: 1.849105
[2022-03-29 15:12:51 | train] - Train Epoch: [33] [1088000/1281167 (85%)]	Loss: 1.222299
[2022-03-29 15:13:12 | train] - Train Epoch: [33] [1100800/1281167 (86%)]	Loss: 1.963335
[2022-03-29 15:13:34 | train] - Train Epoch: [33] [1113600/1281167 (87%)]	Loss: 1.727294
[2022-03-29 15:13:55 | train] - Train Epoch: [33] [1126400/1281167 (88%)]	Loss: 1.513423
[2022-03-29 15:14:17 | train] - Train Epoch: [33] [1139200/1281167 (89%)]	Loss: 1.316438
[2022-03-29 15:14:39 | train] - Train Epoch: [33] [1152000/1281167 (90%)]	Loss: 1.425496
[2022-03-29 15:15:00 | train] - Train Epoch: [33] [1164800/1281167 (91%)]	Loss: 1.239585
[2022-03-29 15:15:21 | train] - Train Epoch: [33] [1177600/1281167 (92%)]	Loss: 1.413418
[2022-03-29 15:15:42 | train] - Train Epoch: [33] [1190400/1281167 (93%)]	Loss: 1.405736
[2022-03-29 15:16:04 | train] - Train Epoch: [33] [1203200/1281167 (94%)]	Loss: 1.569720
[2022-03-29 15:16:25 | train] - Train Epoch: [33] [1216000/1281167 (95%)]	Loss: 1.669018
[2022-03-29 15:16:47 | train] - Train Epoch: [33] [1228800/1281167 (96%)]	Loss: 1.274919
[2022-03-29 15:17:08 | train] - Train Epoch: [33] [1241600/1281167 (97%)]	Loss: 1.522256
[2022-03-29 15:17:29 | train] - Train Epoch: [33] [1254400/1281167 (98%)]	Loss: 1.429324
[2022-03-29 15:17:51 | train] - Train Epoch: [33] [1267200/1281167 (99%)]	Loss: 1.245885
[2022-03-29 15:18:13 | train] - Train Epoch: [33] [1280000/1281167 (100%)]	Loss: 1.394235
[2022-03-29 15:18:15 | train] - Train Epoch: [33]	 Average Loss: 1.443537	 Total Acc : 65.8984	 Total Top5 Acc : 85.3336
[2022-03-29 15:18:19 | train] - -------33 epoch end-----------
========================================
-------33 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 15:20:00 | train] - 
Epoch [33] Test set: Average loss: 1.4039, Accuracy: 33217/50000 (66.4122%), Top-5 Accuracy: 87.4065%

[2022-03-29 15:20:00 | train] - save intermediate epoch [33] result


[2022-03-29 15:20:09 | train] - -------34 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 15:20:11 | train] - Train Epoch: [34] [0/1281167 (0%)]	Loss: 1.330654
[2022-03-29 15:20:33 | train] - Train Epoch: [34] [12800/1281167 (1%)]	Loss: 1.711804
[2022-03-29 15:20:55 | train] - Train Epoch: [34] [25600/1281167 (2%)]	Loss: 1.785935
[2022-03-29 15:21:17 | train] - Train Epoch: [34] [38400/1281167 (3%)]	Loss: 1.259042
[2022-03-29 15:21:38 | train] - Train Epoch: [34] [51200/1281167 (4%)]	Loss: 1.155731
[2022-03-29 15:22:00 | train] - Train Epoch: [34] [64000/1281167 (5%)]	Loss: 1.831066
[2022-03-29 15:22:21 | train] - Train Epoch: [34] [76800/1281167 (6%)]	Loss: 1.309979
[2022-03-29 15:22:43 | train] - Train Epoch: [34] [89600/1281167 (7%)]	Loss: 1.281378
[2022-03-29 15:23:04 | train] - Train Epoch: [34] [102400/1281167 (8%)]	Loss: 1.310022
[2022-03-29 15:23:27 | train] - Train Epoch: [34] [115200/1281167 (9%)]	Loss: 1.358653
[2022-03-29 15:23:48 | train] - Train Epoch: [34] [128000/1281167 (10%)]	Loss: 1.530615
[2022-03-29 15:24:10 | train] - Train Epoch: [34] [140800/1281167 (11%)]	Loss: 1.532253
[2022-03-29 15:24:32 | train] - Train Epoch: [34] [153600/1281167 (12%)]	Loss: 1.475433
[2022-03-29 15:24:53 | train] - Train Epoch: [34] [166400/1281167 (13%)]	Loss: 1.370899
[2022-03-29 15:25:15 | train] - Train Epoch: [34] [179200/1281167 (14%)]	Loss: 1.200692
[2022-03-29 15:25:37 | train] - Train Epoch: [34] [192000/1281167 (15%)]	Loss: 1.618666
[2022-03-29 15:25:58 | train] - Train Epoch: [34] [204800/1281167 (16%)]	Loss: 1.171570
[2022-03-29 15:26:20 | train] - Train Epoch: [34] [217600/1281167 (17%)]	Loss: 1.516295
[2022-03-29 15:26:42 | train] - Train Epoch: [34] [230400/1281167 (18%)]	Loss: 1.095662
[2022-03-29 15:27:04 | train] - Train Epoch: [34] [243200/1281167 (19%)]	Loss: 1.303841
[2022-03-29 15:27:25 | train] - Train Epoch: [34] [256000/1281167 (20%)]	Loss: 1.244622
[2022-03-29 15:27:47 | train] - Train Epoch: [34] [268800/1281167 (21%)]	Loss: 1.478638
[2022-03-29 15:28:10 | train] - Train Epoch: [34] [281600/1281167 (22%)]	Loss: 1.449480
[2022-03-29 15:28:31 | train] - Train Epoch: [34] [294400/1281167 (23%)]	Loss: 1.392196
[2022-03-29 15:28:53 | train] - Train Epoch: [34] [307200/1281167 (24%)]	Loss: 1.661516
[2022-03-29 15:29:14 | train] - Train Epoch: [34] [320000/1281167 (25%)]	Loss: 1.542023
[2022-03-29 15:29:35 | train] - Train Epoch: [34] [332800/1281167 (26%)]	Loss: 1.496243
[2022-03-29 15:29:57 | train] - Train Epoch: [34] [345600/1281167 (27%)]	Loss: 1.414172
[2022-03-29 15:30:19 | train] - Train Epoch: [34] [358400/1281167 (28%)]	Loss: 1.514710
[2022-03-29 15:30:40 | train] - Train Epoch: [34] [371200/1281167 (29%)]	Loss: 1.602505
[2022-03-29 15:31:01 | train] - Train Epoch: [34] [384000/1281167 (30%)]	Loss: 1.413652
[2022-03-29 15:31:23 | train] - Train Epoch: [34] [396800/1281167 (31%)]	Loss: 1.476094
[2022-03-29 15:31:45 | train] - Train Epoch: [34] [409600/1281167 (32%)]	Loss: 0.942030
[2022-03-29 15:32:07 | train] - Train Epoch: [34] [422400/1281167 (33%)]	Loss: 1.744294
[2022-03-29 15:32:29 | train] - Train Epoch: [34] [435200/1281167 (34%)]	Loss: 1.474346
[2022-03-29 15:32:50 | train] - Train Epoch: [34] [448000/1281167 (35%)]	Loss: 1.450062
[2022-03-29 15:33:12 | train] - Train Epoch: [34] [460800/1281167 (36%)]	Loss: 1.695085
[2022-03-29 15:33:34 | train] - Train Epoch: [34] [473600/1281167 (37%)]	Loss: 1.423730
[2022-03-29 15:33:56 | train] - Train Epoch: [34] [486400/1281167 (38%)]	Loss: 1.801312
[2022-03-29 15:34:18 | train] - Train Epoch: [34] [499200/1281167 (39%)]	Loss: 1.384339
[2022-03-29 15:34:39 | train] - Train Epoch: [34] [512000/1281167 (40%)]	Loss: 1.524250
[2022-03-29 15:35:01 | train] - Train Epoch: [34] [524800/1281167 (41%)]	Loss: 1.121317
[2022-03-29 15:35:23 | train] - Train Epoch: [34] [537600/1281167 (42%)]	Loss: 1.514543
[2022-03-29 15:35:44 | train] - Train Epoch: [34] [550400/1281167 (43%)]	Loss: 1.253880
[2022-03-29 15:36:07 | train] - Train Epoch: [34] [563200/1281167 (44%)]	Loss: 1.826179
[2022-03-29 15:36:29 | train] - Train Epoch: [34] [576000/1281167 (45%)]	Loss: 1.217653
[2022-03-29 15:36:51 | train] - Train Epoch: [34] [588800/1281167 (46%)]	Loss: 1.251067
[2022-03-29 15:37:12 | train] - Train Epoch: [34] [601600/1281167 (47%)]	Loss: 1.656186
[2022-03-29 15:37:34 | train] - Train Epoch: [34] [614400/1281167 (48%)]	Loss: 1.523874
[2022-03-29 15:37:55 | train] - Train Epoch: [34] [627200/1281167 (49%)]	Loss: 1.234865
[2022-03-29 15:38:17 | train] - Train Epoch: [34] [640000/1281167 (50%)]	Loss: 1.347510
[2022-03-29 15:38:38 | train] - Train Epoch: [34] [652800/1281167 (51%)]	Loss: 1.682907
[2022-03-29 15:38:59 | train] - Train Epoch: [34] [665600/1281167 (52%)]	Loss: 1.487204
[2022-03-29 15:39:21 | train] - Train Epoch: [34] [678400/1281167 (53%)]	Loss: 1.295596
[2022-03-29 15:39:43 | train] - Train Epoch: [34] [691200/1281167 (54%)]	Loss: 1.174119
[2022-03-29 15:40:05 | train] - Train Epoch: [34] [704000/1281167 (55%)]	Loss: 1.389244
[2022-03-29 15:40:26 | train] - Train Epoch: [34] [716800/1281167 (56%)]	Loss: 1.577339
[2022-03-29 15:40:49 | train] - Train Epoch: [34] [729600/1281167 (57%)]	Loss: 1.574887
[2022-03-29 15:41:10 | train] - Train Epoch: [34] [742400/1281167 (58%)]	Loss: 1.584696
[2022-03-29 15:41:32 | train] - Train Epoch: [34] [755200/1281167 (59%)]	Loss: 1.531910
[2022-03-29 15:41:53 | train] - Train Epoch: [34] [768000/1281167 (60%)]	Loss: 1.604677
[2022-03-29 15:42:15 | train] - Train Epoch: [34] [780800/1281167 (61%)]	Loss: 1.508716
[2022-03-29 15:42:37 | train] - Train Epoch: [34] [793600/1281167 (62%)]	Loss: 1.369454
[2022-03-29 15:42:59 | train] - Train Epoch: [34] [806400/1281167 (63%)]	Loss: 1.230808
[2022-03-29 15:43:20 | train] - Train Epoch: [34] [819200/1281167 (64%)]	Loss: 1.612848
[2022-03-29 15:43:42 | train] - Train Epoch: [34] [832000/1281167 (65%)]	Loss: 1.453106
[2022-03-29 15:44:04 | train] - Train Epoch: [34] [844800/1281167 (66%)]	Loss: 1.204751
[2022-03-29 15:44:26 | train] - Train Epoch: [34] [857600/1281167 (67%)]	Loss: 1.184521
[2022-03-29 15:44:48 | train] - Train Epoch: [34] [870400/1281167 (68%)]	Loss: 1.500523
[2022-03-29 15:45:09 | train] - Train Epoch: [34] [883200/1281167 (69%)]	Loss: 1.737960
[2022-03-29 15:45:32 | train] - Train Epoch: [34] [896000/1281167 (70%)]	Loss: 1.243892
[2022-03-29 15:45:53 | train] - Train Epoch: [34] [908800/1281167 (71%)]	Loss: 1.441151
[2022-03-29 15:46:15 | train] - Train Epoch: [34] [921600/1281167 (72%)]	Loss: 1.797978
[2022-03-29 15:46:37 | train] - Train Epoch: [34] [934400/1281167 (73%)]	Loss: 1.385165
[2022-03-29 15:46:59 | train] - Train Epoch: [34] [947200/1281167 (74%)]	Loss: 1.375619
[2022-03-29 15:47:21 | train] - Train Epoch: [34] [960000/1281167 (75%)]	Loss: 1.363697
[2022-03-29 15:47:43 | train] - Train Epoch: [34] [972800/1281167 (76%)]	Loss: 1.367973
[2022-03-29 15:48:05 | train] - Train Epoch: [34] [985600/1281167 (77%)]	Loss: 1.285721
[2022-03-29 15:48:27 | train] - Train Epoch: [34] [998400/1281167 (78%)]	Loss: 1.660251
[2022-03-29 15:48:48 | train] - Train Epoch: [34] [1011200/1281167 (79%)]	Loss: 1.395786
[2022-03-29 15:49:10 | train] - Train Epoch: [34] [1024000/1281167 (80%)]	Loss: 1.321042
[2022-03-29 15:49:32 | train] - Train Epoch: [34] [1036800/1281167 (81%)]	Loss: 1.199839
[2022-03-29 15:49:53 | train] - Train Epoch: [34] [1049600/1281167 (82%)]	Loss: 1.492744
[2022-03-29 15:50:15 | train] - Train Epoch: [34] [1062400/1281167 (83%)]	Loss: 1.428242
[2022-03-29 15:50:37 | train] - Train Epoch: [34] [1075200/1281167 (84%)]	Loss: 1.450762
[2022-03-29 15:50:59 | train] - Train Epoch: [34] [1088000/1281167 (85%)]	Loss: 1.431347
[2022-03-29 15:51:20 | train] - Train Epoch: [34] [1100800/1281167 (86%)]	Loss: 1.526953
[2022-03-29 15:51:42 | train] - Train Epoch: [34] [1113600/1281167 (87%)]	Loss: 1.419415
[2022-03-29 15:52:04 | train] - Train Epoch: [34] [1126400/1281167 (88%)]	Loss: 1.310832
[2022-03-29 15:52:27 | train] - Train Epoch: [34] [1139200/1281167 (89%)]	Loss: 1.435739
[2022-03-29 15:52:48 | train] - Train Epoch: [34] [1152000/1281167 (90%)]	Loss: 1.159379
[2022-03-29 15:53:11 | train] - Train Epoch: [34] [1164800/1281167 (91%)]	Loss: 1.290587
[2022-03-29 15:53:33 | train] - Train Epoch: [34] [1177600/1281167 (92%)]	Loss: 1.322366
[2022-03-29 15:53:55 | train] - Train Epoch: [34] [1190400/1281167 (93%)]	Loss: 1.470783
[2022-03-29 15:54:16 | train] - Train Epoch: [34] [1203200/1281167 (94%)]	Loss: 1.704129
[2022-03-29 15:54:38 | train] - Train Epoch: [34] [1216000/1281167 (95%)]	Loss: 1.519536
[2022-03-29 15:55:00 | train] - Train Epoch: [34] [1228800/1281167 (96%)]	Loss: 1.716917
[2022-03-29 15:55:22 | train] - Train Epoch: [34] [1241600/1281167 (97%)]	Loss: 1.328460
[2022-03-29 15:55:43 | train] - Train Epoch: [34] [1254400/1281167 (98%)]	Loss: 1.289041
[2022-03-29 15:56:05 | train] - Train Epoch: [34] [1267200/1281167 (99%)]	Loss: 1.782847
[2022-03-29 15:56:26 | train] - Train Epoch: [34] [1280000/1281167 (100%)]	Loss: 1.413292
[2022-03-29 15:56:29 | train] - Train Epoch: [34]	 Average Loss: 1.427291	 Total Acc : 66.1919	 Total Top5 Acc : 85.5891
[2022-03-29 15:56:32 | train] - -------34 epoch end-----------
========================================
-------34 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 15:58:12 | train] - 
Epoch [34] Test set: Average loss: 1.4113, Accuracy: 33214/50000 (66.4015%), Top-5 Accuracy: 87.1112%

[2022-03-29 15:58:13 | train] - save intermediate epoch [34] result


[2022-03-29 15:58:21 | train] - -------35 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 15:58:24 | train] - Train Epoch: [35] [0/1281167 (0%)]	Loss: 1.116812
[2022-03-29 15:58:45 | train] - Train Epoch: [35] [12800/1281167 (1%)]	Loss: 1.311014
[2022-03-29 15:59:06 | train] - Train Epoch: [35] [25600/1281167 (2%)]	Loss: 1.545667
[2022-03-29 15:59:27 | train] - Train Epoch: [35] [38400/1281167 (3%)]	Loss: 1.244633
[2022-03-29 15:59:49 | train] - Train Epoch: [35] [51200/1281167 (4%)]	Loss: 1.374600
[2022-03-29 16:00:11 | train] - Train Epoch: [35] [64000/1281167 (5%)]	Loss: 1.250459
[2022-03-29 16:00:32 | train] - Train Epoch: [35] [76800/1281167 (6%)]	Loss: 1.231671
[2022-03-29 16:00:54 | train] - Train Epoch: [35] [89600/1281167 (7%)]	Loss: 1.221741
[2022-03-29 16:01:16 | train] - Train Epoch: [35] [102400/1281167 (8%)]	Loss: 1.132073
[2022-03-29 16:01:37 | train] - Train Epoch: [35] [115200/1281167 (9%)]	Loss: 1.393944
[2022-03-29 16:01:59 | train] - Train Epoch: [35] [128000/1281167 (10%)]	Loss: 1.589267
[2022-03-29 16:02:21 | train] - Train Epoch: [35] [140800/1281167 (11%)]	Loss: 1.701179
[2022-03-29 16:02:42 | train] - Train Epoch: [35] [153600/1281167 (12%)]	Loss: 1.368301
[2022-03-29 16:03:04 | train] - Train Epoch: [35] [166400/1281167 (13%)]	Loss: 1.486657
[2022-03-29 16:03:25 | train] - Train Epoch: [35] [179200/1281167 (14%)]	Loss: 1.685004
[2022-03-29 16:03:46 | train] - Train Epoch: [35] [192000/1281167 (15%)]	Loss: 1.431405
[2022-03-29 16:04:07 | train] - Train Epoch: [35] [204800/1281167 (16%)]	Loss: 1.190647
[2022-03-29 16:04:29 | train] - Train Epoch: [35] [217600/1281167 (17%)]	Loss: 1.464222
[2022-03-29 16:04:51 | train] - Train Epoch: [35] [230400/1281167 (18%)]	Loss: 1.552546
[2022-03-29 16:05:13 | train] - Train Epoch: [35] [243200/1281167 (19%)]	Loss: 1.306237
[2022-03-29 16:05:34 | train] - Train Epoch: [35] [256000/1281167 (20%)]	Loss: 1.342195
[2022-03-29 16:05:55 | train] - Train Epoch: [35] [268800/1281167 (21%)]	Loss: 1.541423
[2022-03-29 16:06:16 | train] - Train Epoch: [35] [281600/1281167 (22%)]	Loss: 1.570146
[2022-03-29 16:06:37 | train] - Train Epoch: [35] [294400/1281167 (23%)]	Loss: 1.370365
[2022-03-29 16:06:58 | train] - Train Epoch: [35] [307200/1281167 (24%)]	Loss: 1.459769
[2022-03-29 16:07:19 | train] - Train Epoch: [35] [320000/1281167 (25%)]	Loss: 1.165876
[2022-03-29 16:07:40 | train] - Train Epoch: [35] [332800/1281167 (26%)]	Loss: 1.163496
[2022-03-29 16:08:02 | train] - Train Epoch: [35] [345600/1281167 (27%)]	Loss: 1.126650
[2022-03-29 16:08:24 | train] - Train Epoch: [35] [358400/1281167 (28%)]	Loss: 1.282416
[2022-03-29 16:08:45 | train] - Train Epoch: [35] [371200/1281167 (29%)]	Loss: 1.288968
[2022-03-29 16:09:07 | train] - Train Epoch: [35] [384000/1281167 (30%)]	Loss: 1.684140
[2022-03-29 16:09:29 | train] - Train Epoch: [35] [396800/1281167 (31%)]	Loss: 1.136699
[2022-03-29 16:09:50 | train] - Train Epoch: [35] [409600/1281167 (32%)]	Loss: 1.268453
[2022-03-29 16:10:11 | train] - Train Epoch: [35] [422400/1281167 (33%)]	Loss: 1.087267
[2022-03-29 16:10:33 | train] - Train Epoch: [35] [435200/1281167 (34%)]	Loss: 1.471406
[2022-03-29 16:10:55 | train] - Train Epoch: [35] [448000/1281167 (35%)]	Loss: 1.400721
[2022-03-29 16:11:16 | train] - Train Epoch: [35] [460800/1281167 (36%)]	Loss: 1.281748
[2022-03-29 16:11:37 | train] - Train Epoch: [35] [473600/1281167 (37%)]	Loss: 1.417560
[2022-03-29 16:11:59 | train] - Train Epoch: [35] [486400/1281167 (38%)]	Loss: 1.260248
[2022-03-29 16:12:21 | train] - Train Epoch: [35] [499200/1281167 (39%)]	Loss: 1.476869
[2022-03-29 16:12:42 | train] - Train Epoch: [35] [512000/1281167 (40%)]	Loss: 1.508324
[2022-03-29 16:13:04 | train] - Train Epoch: [35] [524800/1281167 (41%)]	Loss: 1.423785
[2022-03-29 16:13:26 | train] - Train Epoch: [35] [537600/1281167 (42%)]	Loss: 1.335491
[2022-03-29 16:13:48 | train] - Train Epoch: [35] [550400/1281167 (43%)]	Loss: 1.448449
[2022-03-29 16:14:10 | train] - Train Epoch: [35] [563200/1281167 (44%)]	Loss: 1.453336
[2022-03-29 16:14:31 | train] - Train Epoch: [35] [576000/1281167 (45%)]	Loss: 1.395575
[2022-03-29 16:14:53 | train] - Train Epoch: [35] [588800/1281167 (46%)]	Loss: 1.450970
[2022-03-29 16:15:14 | train] - Train Epoch: [35] [601600/1281167 (47%)]	Loss: 1.371705
[2022-03-29 16:15:35 | train] - Train Epoch: [35] [614400/1281167 (48%)]	Loss: 1.512083
[2022-03-29 16:15:56 | train] - Train Epoch: [35] [627200/1281167 (49%)]	Loss: 1.476000
[2022-03-29 16:16:17 | train] - Train Epoch: [35] [640000/1281167 (50%)]	Loss: 1.265361
[2022-03-29 16:16:39 | train] - Train Epoch: [35] [652800/1281167 (51%)]	Loss: 1.265086
[2022-03-29 16:17:00 | train] - Train Epoch: [35] [665600/1281167 (52%)]	Loss: 1.489754
[2022-03-29 16:17:22 | train] - Train Epoch: [35] [678400/1281167 (53%)]	Loss: 1.447729
[2022-03-29 16:17:43 | train] - Train Epoch: [35] [691200/1281167 (54%)]	Loss: 1.340893
[2022-03-29 16:18:05 | train] - Train Epoch: [35] [704000/1281167 (55%)]	Loss: 1.289999
[2022-03-29 16:18:26 | train] - Train Epoch: [35] [716800/1281167 (56%)]	Loss: 1.344245
[2022-03-29 16:18:48 | train] - Train Epoch: [35] [729600/1281167 (57%)]	Loss: 1.491381
[2022-03-29 16:19:09 | train] - Train Epoch: [35] [742400/1281167 (58%)]	Loss: 1.569871
[2022-03-29 16:19:31 | train] - Train Epoch: [35] [755200/1281167 (59%)]	Loss: 1.299776
[2022-03-29 16:19:53 | train] - Train Epoch: [35] [768000/1281167 (60%)]	Loss: 1.257500
[2022-03-29 16:20:15 | train] - Train Epoch: [35] [780800/1281167 (61%)]	Loss: 1.160271
[2022-03-29 16:20:36 | train] - Train Epoch: [35] [793600/1281167 (62%)]	Loss: 1.745924
[2022-03-29 16:20:58 | train] - Train Epoch: [35] [806400/1281167 (63%)]	Loss: 1.056129
[2022-03-29 16:21:20 | train] - Train Epoch: [35] [819200/1281167 (64%)]	Loss: 1.543446
[2022-03-29 16:21:41 | train] - Train Epoch: [35] [832000/1281167 (65%)]	Loss: 1.501902
[2022-03-29 16:22:03 | train] - Train Epoch: [35] [844800/1281167 (66%)]	Loss: 1.132001
[2022-03-29 16:22:24 | train] - Train Epoch: [35] [857600/1281167 (67%)]	Loss: 1.256908
[2022-03-29 16:22:46 | train] - Train Epoch: [35] [870400/1281167 (68%)]	Loss: 1.407533
[2022-03-29 16:23:08 | train] - Train Epoch: [35] [883200/1281167 (69%)]	Loss: 1.255911
[2022-03-29 16:23:29 | train] - Train Epoch: [35] [896000/1281167 (70%)]	Loss: 1.432342
[2022-03-29 16:23:50 | train] - Train Epoch: [35] [908800/1281167 (71%)]	Loss: 1.241579
[2022-03-29 16:24:12 | train] - Train Epoch: [35] [921600/1281167 (72%)]	Loss: 1.103555
[2022-03-29 16:24:34 | train] - Train Epoch: [35] [934400/1281167 (73%)]	Loss: 1.124316
[2022-03-29 16:24:55 | train] - Train Epoch: [35] [947200/1281167 (74%)]	Loss: 1.567047
[2022-03-29 16:25:18 | train] - Train Epoch: [35] [960000/1281167 (75%)]	Loss: 1.341207
[2022-03-29 16:25:39 | train] - Train Epoch: [35] [972800/1281167 (76%)]	Loss: 1.210868
[2022-03-29 16:26:00 | train] - Train Epoch: [35] [985600/1281167 (77%)]	Loss: 1.512528
[2022-03-29 16:26:22 | train] - Train Epoch: [35] [998400/1281167 (78%)]	Loss: 1.130465
[2022-03-29 16:26:43 | train] - Train Epoch: [35] [1011200/1281167 (79%)]	Loss: 1.396054
[2022-03-29 16:27:05 | train] - Train Epoch: [35] [1024000/1281167 (80%)]	Loss: 1.481463
[2022-03-29 16:27:26 | train] - Train Epoch: [35] [1036800/1281167 (81%)]	Loss: 1.493382
[2022-03-29 16:27:47 | train] - Train Epoch: [35] [1049600/1281167 (82%)]	Loss: 1.541069
[2022-03-29 16:28:08 | train] - Train Epoch: [35] [1062400/1281167 (83%)]	Loss: 1.761135
[2022-03-29 16:28:30 | train] - Train Epoch: [35] [1075200/1281167 (84%)]	Loss: 1.192596
[2022-03-29 16:28:52 | train] - Train Epoch: [35] [1088000/1281167 (85%)]	Loss: 1.583013
[2022-03-29 16:29:14 | train] - Train Epoch: [35] [1100800/1281167 (86%)]	Loss: 1.561589
[2022-03-29 16:29:35 | train] - Train Epoch: [35] [1113600/1281167 (87%)]	Loss: 1.600254
[2022-03-29 16:29:57 | train] - Train Epoch: [35] [1126400/1281167 (88%)]	Loss: 1.164752
[2022-03-29 16:30:18 | train] - Train Epoch: [35] [1139200/1281167 (89%)]	Loss: 1.502565
[2022-03-29 16:30:40 | train] - Train Epoch: [35] [1152000/1281167 (90%)]	Loss: 1.591926
[2022-03-29 16:31:02 | train] - Train Epoch: [35] [1164800/1281167 (91%)]	Loss: 1.828288
[2022-03-29 16:31:23 | train] - Train Epoch: [35] [1177600/1281167 (92%)]	Loss: 1.576667
[2022-03-29 16:31:45 | train] - Train Epoch: [35] [1190400/1281167 (93%)]	Loss: 1.456878
[2022-03-29 16:32:06 | train] - Train Epoch: [35] [1203200/1281167 (94%)]	Loss: 1.083300
[2022-03-29 16:32:28 | train] - Train Epoch: [35] [1216000/1281167 (95%)]	Loss: 1.600695
[2022-03-29 16:32:50 | train] - Train Epoch: [35] [1228800/1281167 (96%)]	Loss: 1.497374
[2022-03-29 16:33:11 | train] - Train Epoch: [35] [1241600/1281167 (97%)]	Loss: 1.329025
[2022-03-29 16:33:34 | train] - Train Epoch: [35] [1254400/1281167 (98%)]	Loss: 1.175918
[2022-03-29 16:33:55 | train] - Train Epoch: [35] [1267200/1281167 (99%)]	Loss: 1.517602
[2022-03-29 16:34:16 | train] - Train Epoch: [35] [1280000/1281167 (100%)]	Loss: 1.245754
[2022-03-29 16:34:19 | train] - Train Epoch: [35]	 Average Loss: 1.412486	 Total Acc : 66.5671	 Total Top5 Acc : 85.7789
[2022-03-29 16:34:22 | train] - -------35 epoch end-----------
========================================
-------35 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 16:36:03 | train] - 
Epoch [35] Test set: Average loss: 1.3884, Accuracy: 33384/50000 (66.7363%), Top-5 Accuracy: 87.3677%

[2022-03-29 16:36:03 | train] - save intermediate epoch [35] result


[2022-03-29 16:36:10 | train] - logging best performance 35 epoch
[2022-03-29 16:36:12 | train] - -------36 epoch start-----------
========================================
----- test end -------------------------


logging best performance 35 epoch
[2022-03-29 16:36:14 | train] - Train Epoch: [36] [0/1281167 (0%)]	Loss: 1.238657
[2022-03-29 16:36:36 | train] - Train Epoch: [36] [12800/1281167 (1%)]	Loss: 1.394212
[2022-03-29 16:36:58 | train] - Train Epoch: [36] [25600/1281167 (2%)]	Loss: 1.172621
[2022-03-29 16:37:19 | train] - Train Epoch: [36] [38400/1281167 (3%)]	Loss: 1.480213
[2022-03-29 16:37:40 | train] - Train Epoch: [36] [51200/1281167 (4%)]	Loss: 1.322222
[2022-03-29 16:38:02 | train] - Train Epoch: [36] [64000/1281167 (5%)]	Loss: 1.379921
[2022-03-29 16:38:23 | train] - Train Epoch: [36] [76800/1281167 (6%)]	Loss: 1.361298
[2022-03-29 16:38:45 | train] - Train Epoch: [36] [89600/1281167 (7%)]	Loss: 1.468398
[2022-03-29 16:39:06 | train] - Train Epoch: [36] [102400/1281167 (8%)]	Loss: 1.421807
[2022-03-29 16:39:28 | train] - Train Epoch: [36] [115200/1281167 (9%)]	Loss: 1.259390
[2022-03-29 16:39:49 | train] - Train Epoch: [36] [128000/1281167 (10%)]	Loss: 1.343989
[2022-03-29 16:40:10 | train] - Train Epoch: [36] [140800/1281167 (11%)]	Loss: 1.142592
[2022-03-29 16:40:31 | train] - Train Epoch: [36] [153600/1281167 (12%)]	Loss: 1.292058
[2022-03-29 16:40:54 | train] - Train Epoch: [36] [166400/1281167 (13%)]	Loss: 1.511680
[2022-03-29 16:41:15 | train] - Train Epoch: [36] [179200/1281167 (14%)]	Loss: 1.257052
[2022-03-29 16:41:37 | train] - Train Epoch: [36] [192000/1281167 (15%)]	Loss: 1.432600
[2022-03-29 16:41:59 | train] - Train Epoch: [36] [204800/1281167 (16%)]	Loss: 1.460735
[2022-03-29 16:42:21 | train] - Train Epoch: [36] [217600/1281167 (17%)]	Loss: 1.367085
[2022-03-29 16:42:42 | train] - Train Epoch: [36] [230400/1281167 (18%)]	Loss: 1.622457
[2022-03-29 16:43:03 | train] - Train Epoch: [36] [243200/1281167 (19%)]	Loss: 1.387110
[2022-03-29 16:43:25 | train] - Train Epoch: [36] [256000/1281167 (20%)]	Loss: 1.508154
[2022-03-29 16:43:47 | train] - Train Epoch: [36] [268800/1281167 (21%)]	Loss: 1.372761
[2022-03-29 16:44:08 | train] - Train Epoch: [36] [281600/1281167 (22%)]	Loss: 1.407485
[2022-03-29 16:44:30 | train] - Train Epoch: [36] [294400/1281167 (23%)]	Loss: 1.380261
[2022-03-29 16:44:51 | train] - Train Epoch: [36] [307200/1281167 (24%)]	Loss: 1.620938
[2022-03-29 16:45:12 | train] - Train Epoch: [36] [320000/1281167 (25%)]	Loss: 1.432397
[2022-03-29 16:45:34 | train] - Train Epoch: [36] [332800/1281167 (26%)]	Loss: 1.266749
[2022-03-29 16:45:56 | train] - Train Epoch: [36] [345600/1281167 (27%)]	Loss: 1.441477
[2022-03-29 16:46:18 | train] - Train Epoch: [36] [358400/1281167 (28%)]	Loss: 1.429095
[2022-03-29 16:46:39 | train] - Train Epoch: [36] [371200/1281167 (29%)]	Loss: 1.307688
[2022-03-29 16:47:01 | train] - Train Epoch: [36] [384000/1281167 (30%)]	Loss: 1.174632
[2022-03-29 16:47:23 | train] - Train Epoch: [36] [396800/1281167 (31%)]	Loss: 1.129577
[2022-03-29 16:47:44 | train] - Train Epoch: [36] [409600/1281167 (32%)]	Loss: 1.531876
[2022-03-29 16:48:05 | train] - Train Epoch: [36] [422400/1281167 (33%)]	Loss: 1.491981
[2022-03-29 16:48:27 | train] - Train Epoch: [36] [435200/1281167 (34%)]	Loss: 1.259645
[2022-03-29 16:48:49 | train] - Train Epoch: [36] [448000/1281167 (35%)]	Loss: 1.161202
[2022-03-29 16:49:11 | train] - Train Epoch: [36] [460800/1281167 (36%)]	Loss: 1.694790
[2022-03-29 16:49:32 | train] - Train Epoch: [36] [473600/1281167 (37%)]	Loss: 1.093987
[2022-03-29 16:49:54 | train] - Train Epoch: [36] [486400/1281167 (38%)]	Loss: 1.427029
[2022-03-29 16:50:15 | train] - Train Epoch: [36] [499200/1281167 (39%)]	Loss: 1.359528
[2022-03-29 16:50:36 | train] - Train Epoch: [36] [512000/1281167 (40%)]	Loss: 1.723523
[2022-03-29 16:50:57 | train] - Train Epoch: [36] [524800/1281167 (41%)]	Loss: 1.219163
[2022-03-29 16:51:19 | train] - Train Epoch: [36] [537600/1281167 (42%)]	Loss: 1.357982
[2022-03-29 16:51:41 | train] - Train Epoch: [36] [550400/1281167 (43%)]	Loss: 1.604856
[2022-03-29 16:52:02 | train] - Train Epoch: [36] [563200/1281167 (44%)]	Loss: 1.261086
[2022-03-29 16:52:23 | train] - Train Epoch: [36] [576000/1281167 (45%)]	Loss: 1.186474
[2022-03-29 16:52:44 | train] - Train Epoch: [36] [588800/1281167 (46%)]	Loss: 1.861244
[2022-03-29 16:53:06 | train] - Train Epoch: [36] [601600/1281167 (47%)]	Loss: 1.119512
[2022-03-29 16:53:27 | train] - Train Epoch: [36] [614400/1281167 (48%)]	Loss: 1.216455
[2022-03-29 16:53:49 | train] - Train Epoch: [36] [627200/1281167 (49%)]	Loss: 1.254918
[2022-03-29 16:54:11 | train] - Train Epoch: [36] [640000/1281167 (50%)]	Loss: 1.304676
[2022-03-29 16:54:32 | train] - Train Epoch: [36] [652800/1281167 (51%)]	Loss: 1.750909
[2022-03-29 16:54:54 | train] - Train Epoch: [36] [665600/1281167 (52%)]	Loss: 1.371790
[2022-03-29 16:55:15 | train] - Train Epoch: [36] [678400/1281167 (53%)]	Loss: 1.206012
[2022-03-29 16:55:37 | train] - Train Epoch: [36] [691200/1281167 (54%)]	Loss: 1.298621
[2022-03-29 16:55:59 | train] - Train Epoch: [36] [704000/1281167 (55%)]	Loss: 1.353723
[2022-03-29 16:56:20 | train] - Train Epoch: [36] [716800/1281167 (56%)]	Loss: 1.476821
[2022-03-29 16:56:41 | train] - Train Epoch: [36] [729600/1281167 (57%)]	Loss: 1.585717
[2022-03-29 16:57:03 | train] - Train Epoch: [36] [742400/1281167 (58%)]	Loss: 1.776629
[2022-03-29 16:57:25 | train] - Train Epoch: [36] [755200/1281167 (59%)]	Loss: 1.501882
[2022-03-29 16:57:46 | train] - Train Epoch: [36] [768000/1281167 (60%)]	Loss: 1.497240
[2022-03-29 16:58:08 | train] - Train Epoch: [36] [780800/1281167 (61%)]	Loss: 1.443205
[2022-03-29 16:58:30 | train] - Train Epoch: [36] [793600/1281167 (62%)]	Loss: 1.358953
[2022-03-29 16:58:51 | train] - Train Epoch: [36] [806400/1281167 (63%)]	Loss: 1.428420
[2022-03-29 16:59:13 | train] - Train Epoch: [36] [819200/1281167 (64%)]	Loss: 1.125849
[2022-03-29 16:59:34 | train] - Train Epoch: [36] [832000/1281167 (65%)]	Loss: 1.191990
[2022-03-29 16:59:56 | train] - Train Epoch: [36] [844800/1281167 (66%)]	Loss: 1.556438
[2022-03-29 17:00:19 | train] - Train Epoch: [36] [857600/1281167 (67%)]	Loss: 1.468319
[2022-03-29 17:00:41 | train] - Train Epoch: [36] [870400/1281167 (68%)]	Loss: 1.561192
[2022-03-29 17:01:03 | train] - Train Epoch: [36] [883200/1281167 (69%)]	Loss: 1.342619
[2022-03-29 17:01:25 | train] - Train Epoch: [36] [896000/1281167 (70%)]	Loss: 0.956119
[2022-03-29 17:01:48 | train] - Train Epoch: [36] [908800/1281167 (71%)]	Loss: 1.194473
[2022-03-29 17:02:10 | train] - Train Epoch: [36] [921600/1281167 (72%)]	Loss: 1.182635
[2022-03-29 17:02:32 | train] - Train Epoch: [36] [934400/1281167 (73%)]	Loss: 1.592196
[2022-03-29 17:02:54 | train] - Train Epoch: [36] [947200/1281167 (74%)]	Loss: 1.421982
[2022-03-29 17:03:17 | train] - Train Epoch: [36] [960000/1281167 (75%)]	Loss: 1.444166
[2022-03-29 17:03:39 | train] - Train Epoch: [36] [972800/1281167 (76%)]	Loss: 1.018483
[2022-03-29 17:04:02 | train] - Train Epoch: [36] [985600/1281167 (77%)]	Loss: 1.370575
[2022-03-29 17:04:24 | train] - Train Epoch: [36] [998400/1281167 (78%)]	Loss: 1.327415
[2022-03-29 17:04:47 | train] - Train Epoch: [36] [1011200/1281167 (79%)]	Loss: 1.383633
[2022-03-29 17:05:09 | train] - Train Epoch: [36] [1024000/1281167 (80%)]	Loss: 1.304677
[2022-03-29 17:05:31 | train] - Train Epoch: [36] [1036800/1281167 (81%)]	Loss: 1.367930
[2022-03-29 17:05:54 | train] - Train Epoch: [36] [1049600/1281167 (82%)]	Loss: 1.529579
[2022-03-29 17:06:16 | train] - Train Epoch: [36] [1062400/1281167 (83%)]	Loss: 1.362301
[2022-03-29 17:06:39 | train] - Train Epoch: [36] [1075200/1281167 (84%)]	Loss: 1.726206
[2022-03-29 17:07:00 | train] - Train Epoch: [36] [1088000/1281167 (85%)]	Loss: 1.461507
[2022-03-29 17:07:23 | train] - Train Epoch: [36] [1100800/1281167 (86%)]	Loss: 1.292520
[2022-03-29 17:07:45 | train] - Train Epoch: [36] [1113600/1281167 (87%)]	Loss: 1.530039
[2022-03-29 17:08:07 | train] - Train Epoch: [36] [1126400/1281167 (88%)]	Loss: 1.203673
[2022-03-29 17:08:29 | train] - Train Epoch: [36] [1139200/1281167 (89%)]	Loss: 1.722982
[2022-03-29 17:08:51 | train] - Train Epoch: [36] [1152000/1281167 (90%)]	Loss: 1.436871
[2022-03-29 17:09:13 | train] - Train Epoch: [36] [1164800/1281167 (91%)]	Loss: 1.213928
[2022-03-29 17:09:35 | train] - Train Epoch: [36] [1177600/1281167 (92%)]	Loss: 1.423602
[2022-03-29 17:09:57 | train] - Train Epoch: [36] [1190400/1281167 (93%)]	Loss: 1.315756
[2022-03-29 17:10:19 | train] - Train Epoch: [36] [1203200/1281167 (94%)]	Loss: 1.756803
[2022-03-29 17:10:42 | train] - Train Epoch: [36] [1216000/1281167 (95%)]	Loss: 1.626777
[2022-03-29 17:11:03 | train] - Train Epoch: [36] [1228800/1281167 (96%)]	Loss: 1.376127
[2022-03-29 17:11:25 | train] - Train Epoch: [36] [1241600/1281167 (97%)]	Loss: 1.560978
[2022-03-29 17:11:47 | train] - Train Epoch: [36] [1254400/1281167 (98%)]	Loss: 1.263165
[2022-03-29 17:12:09 | train] - Train Epoch: [36] [1267200/1281167 (99%)]	Loss: 1.762267
[2022-03-29 17:12:31 | train] - Train Epoch: [36] [1280000/1281167 (100%)]	Loss: 1.860135
[2022-03-29 17:12:34 | train] - Train Epoch: [36]	 Average Loss: 1.396626	 Total Acc : 66.8397	 Total Top5 Acc : 85.9916
[2022-03-29 17:12:36 | train] - -------36 epoch end-----------
========================================
-------36 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 17:14:17 | train] - 
Epoch [36] Test set: Average loss: 1.3874, Accuracy: 33551/50000 (67.0712%), Top-5 Accuracy: 87.5539%

[2022-03-29 17:14:17 | train] - save intermediate epoch [36] result


[2022-03-29 17:14:25 | train] - logging best performance 36 epoch
[2022-03-29 17:14:27 | train] - -------37 epoch start-----------
========================================
----- test end -------------------------


logging best performance 36 epoch
[2022-03-29 17:14:29 | train] - Train Epoch: [37] [0/1281167 (0%)]	Loss: 1.349313
[2022-03-29 17:14:51 | train] - Train Epoch: [37] [12800/1281167 (1%)]	Loss: 1.453802
[2022-03-29 17:15:13 | train] - Train Epoch: [37] [25600/1281167 (2%)]	Loss: 1.301813
[2022-03-29 17:15:34 | train] - Train Epoch: [37] [38400/1281167 (3%)]	Loss: 1.240345
[2022-03-29 17:15:57 | train] - Train Epoch: [37] [51200/1281167 (4%)]	Loss: 1.506460
[2022-03-29 17:16:19 | train] - Train Epoch: [37] [64000/1281167 (5%)]	Loss: 1.583548
[2022-03-29 17:16:40 | train] - Train Epoch: [37] [76800/1281167 (6%)]	Loss: 1.705508
[2022-03-29 17:17:01 | train] - Train Epoch: [37] [89600/1281167 (7%)]	Loss: 1.553785
[2022-03-29 17:17:22 | train] - Train Epoch: [37] [102400/1281167 (8%)]	Loss: 1.375774
[2022-03-29 17:17:44 | train] - Train Epoch: [37] [115200/1281167 (9%)]	Loss: 1.474662
[2022-03-29 17:18:05 | train] - Train Epoch: [37] [128000/1281167 (10%)]	Loss: 1.386320
[2022-03-29 17:18:26 | train] - Train Epoch: [37] [140800/1281167 (11%)]	Loss: 1.392332
[2022-03-29 17:18:47 | train] - Train Epoch: [37] [153600/1281167 (12%)]	Loss: 1.204381
[2022-03-29 17:19:09 | train] - Train Epoch: [37] [166400/1281167 (13%)]	Loss: 1.546158
[2022-03-29 17:19:29 | train] - Train Epoch: [37] [179200/1281167 (14%)]	Loss: 1.221416
[2022-03-29 17:19:51 | train] - Train Epoch: [37] [192000/1281167 (15%)]	Loss: 1.558523
[2022-03-29 17:20:12 | train] - Train Epoch: [37] [204800/1281167 (16%)]	Loss: 1.296855
[2022-03-29 17:20:33 | train] - Train Epoch: [37] [217600/1281167 (17%)]	Loss: 1.455535
[2022-03-29 17:20:55 | train] - Train Epoch: [37] [230400/1281167 (18%)]	Loss: 1.554930
[2022-03-29 17:21:15 | train] - Train Epoch: [37] [243200/1281167 (19%)]	Loss: 1.226401
[2022-03-29 17:21:36 | train] - Train Epoch: [37] [256000/1281167 (20%)]	Loss: 1.282914
[2022-03-29 17:21:57 | train] - Train Epoch: [37] [268800/1281167 (21%)]	Loss: 1.694410
[2022-03-29 17:22:19 | train] - Train Epoch: [37] [281600/1281167 (22%)]	Loss: 1.221825
[2022-03-29 17:22:40 | train] - Train Epoch: [37] [294400/1281167 (23%)]	Loss: 1.353307
[2022-03-29 17:23:01 | train] - Train Epoch: [37] [307200/1281167 (24%)]	Loss: 1.164877
[2022-03-29 17:23:22 | train] - Train Epoch: [37] [320000/1281167 (25%)]	Loss: 1.336318
[2022-03-29 17:23:43 | train] - Train Epoch: [37] [332800/1281167 (26%)]	Loss: 1.472363
[2022-03-29 17:24:05 | train] - Train Epoch: [37] [345600/1281167 (27%)]	Loss: 1.455528
[2022-03-29 17:24:26 | train] - Train Epoch: [37] [358400/1281167 (28%)]	Loss: 1.826390
[2022-03-29 17:24:47 | train] - Train Epoch: [37] [371200/1281167 (29%)]	Loss: 1.316143
[2022-03-29 17:25:08 | train] - Train Epoch: [37] [384000/1281167 (30%)]	Loss: 1.241389
[2022-03-29 17:25:29 | train] - Train Epoch: [37] [396800/1281167 (31%)]	Loss: 1.277112
[2022-03-29 17:25:50 | train] - Train Epoch: [37] [409600/1281167 (32%)]	Loss: 1.354233
[2022-03-29 17:26:10 | train] - Train Epoch: [37] [422400/1281167 (33%)]	Loss: 1.321505
[2022-03-29 17:26:32 | train] - Train Epoch: [37] [435200/1281167 (34%)]	Loss: 1.354129
[2022-03-29 17:26:53 | train] - Train Epoch: [37] [448000/1281167 (35%)]	Loss: 1.245163
[2022-03-29 17:27:15 | train] - Train Epoch: [37] [460800/1281167 (36%)]	Loss: 1.283567
[2022-03-29 17:27:36 | train] - Train Epoch: [37] [473600/1281167 (37%)]	Loss: 1.610785
[2022-03-29 17:27:57 | train] - Train Epoch: [37] [486400/1281167 (38%)]	Loss: 1.704034
[2022-03-29 17:28:19 | train] - Train Epoch: [37] [499200/1281167 (39%)]	Loss: 1.628497
[2022-03-29 17:28:40 | train] - Train Epoch: [37] [512000/1281167 (40%)]	Loss: 1.542193
[2022-03-29 17:29:02 | train] - Train Epoch: [37] [524800/1281167 (41%)]	Loss: 1.807026
[2022-03-29 17:29:23 | train] - Train Epoch: [37] [537600/1281167 (42%)]	Loss: 1.789820
[2022-03-29 17:29:44 | train] - Train Epoch: [37] [550400/1281167 (43%)]	Loss: 1.562602
[2022-03-29 17:30:06 | train] - Train Epoch: [37] [563200/1281167 (44%)]	Loss: 1.485204
[2022-03-29 17:30:27 | train] - Train Epoch: [37] [576000/1281167 (45%)]	Loss: 1.372246
[2022-03-29 17:30:49 | train] - Train Epoch: [37] [588800/1281167 (46%)]	Loss: 1.296468
[2022-03-29 17:31:10 | train] - Train Epoch: [37] [601600/1281167 (47%)]	Loss: 1.718463
[2022-03-29 17:31:32 | train] - Train Epoch: [37] [614400/1281167 (48%)]	Loss: 1.483588
[2022-03-29 17:31:53 | train] - Train Epoch: [37] [627200/1281167 (49%)]	Loss: 1.030143
[2022-03-29 17:32:14 | train] - Train Epoch: [37] [640000/1281167 (50%)]	Loss: 1.438530
[2022-03-29 17:32:36 | train] - Train Epoch: [37] [652800/1281167 (51%)]	Loss: 1.070858
[2022-03-29 17:32:57 | train] - Train Epoch: [37] [665600/1281167 (52%)]	Loss: 1.568410
[2022-03-29 17:33:18 | train] - Train Epoch: [37] [678400/1281167 (53%)]	Loss: 1.049059
[2022-03-29 17:33:39 | train] - Train Epoch: [37] [691200/1281167 (54%)]	Loss: 1.302142
[2022-03-29 17:34:00 | train] - Train Epoch: [37] [704000/1281167 (55%)]	Loss: 1.232429
[2022-03-29 17:34:21 | train] - Train Epoch: [37] [716800/1281167 (56%)]	Loss: 1.166420
[2022-03-29 17:34:43 | train] - Train Epoch: [37] [729600/1281167 (57%)]	Loss: 1.041775
[2022-03-29 17:35:04 | train] - Train Epoch: [37] [742400/1281167 (58%)]	Loss: 1.113814
[2022-03-29 17:35:26 | train] - Train Epoch: [37] [755200/1281167 (59%)]	Loss: 1.010482
[2022-03-29 17:35:47 | train] - Train Epoch: [37] [768000/1281167 (60%)]	Loss: 1.464631
[2022-03-29 17:36:09 | train] - Train Epoch: [37] [780800/1281167 (61%)]	Loss: 1.453115
[2022-03-29 17:36:29 | train] - Train Epoch: [37] [793600/1281167 (62%)]	Loss: 1.526415
[2022-03-29 17:36:51 | train] - Train Epoch: [37] [806400/1281167 (63%)]	Loss: 1.685447
[2022-03-29 17:37:13 | train] - Train Epoch: [37] [819200/1281167 (64%)]	Loss: 1.301643
[2022-03-29 17:37:35 | train] - Train Epoch: [37] [832000/1281167 (65%)]	Loss: 1.608249
[2022-03-29 17:37:56 | train] - Train Epoch: [37] [844800/1281167 (66%)]	Loss: 1.169061
[2022-03-29 17:38:17 | train] - Train Epoch: [37] [857600/1281167 (67%)]	Loss: 1.520046
[2022-03-29 17:38:38 | train] - Train Epoch: [37] [870400/1281167 (68%)]	Loss: 1.415880
[2022-03-29 17:38:59 | train] - Train Epoch: [37] [883200/1281167 (69%)]	Loss: 1.267634
[2022-03-29 17:39:20 | train] - Train Epoch: [37] [896000/1281167 (70%)]	Loss: 1.310359
[2022-03-29 17:39:42 | train] - Train Epoch: [37] [908800/1281167 (71%)]	Loss: 1.229143
[2022-03-29 17:40:04 | train] - Train Epoch: [37] [921600/1281167 (72%)]	Loss: 1.206322
[2022-03-29 17:40:26 | train] - Train Epoch: [37] [934400/1281167 (73%)]	Loss: 1.459273
[2022-03-29 17:40:48 | train] - Train Epoch: [37] [947200/1281167 (74%)]	Loss: 1.629668
[2022-03-29 17:41:09 | train] - Train Epoch: [37] [960000/1281167 (75%)]	Loss: 1.069410
[2022-03-29 17:41:30 | train] - Train Epoch: [37] [972800/1281167 (76%)]	Loss: 1.404182
[2022-03-29 17:41:52 | train] - Train Epoch: [37] [985600/1281167 (77%)]	Loss: 1.371211
[2022-03-29 17:42:14 | train] - Train Epoch: [37] [998400/1281167 (78%)]	Loss: 1.002711
[2022-03-29 17:42:35 | train] - Train Epoch: [37] [1011200/1281167 (79%)]	Loss: 1.429621
[2022-03-29 17:42:57 | train] - Train Epoch: [37] [1024000/1281167 (80%)]	Loss: 1.566428
[2022-03-29 17:43:18 | train] - Train Epoch: [37] [1036800/1281167 (81%)]	Loss: 1.484298
[2022-03-29 17:43:39 | train] - Train Epoch: [37] [1049600/1281167 (82%)]	Loss: 1.237277
[2022-03-29 17:44:01 | train] - Train Epoch: [37] [1062400/1281167 (83%)]	Loss: 1.414564
[2022-03-29 17:44:22 | train] - Train Epoch: [37] [1075200/1281167 (84%)]	Loss: 1.411034
[2022-03-29 17:44:44 | train] - Train Epoch: [37] [1088000/1281167 (85%)]	Loss: 1.149256
[2022-03-29 17:45:05 | train] - Train Epoch: [37] [1100800/1281167 (86%)]	Loss: 1.509244
[2022-03-29 17:45:26 | train] - Train Epoch: [37] [1113600/1281167 (87%)]	Loss: 1.518497
[2022-03-29 17:45:47 | train] - Train Epoch: [37] [1126400/1281167 (88%)]	Loss: 1.214678
[2022-03-29 17:46:09 | train] - Train Epoch: [37] [1139200/1281167 (89%)]	Loss: 1.803952
[2022-03-29 17:46:30 | train] - Train Epoch: [37] [1152000/1281167 (90%)]	Loss: 1.222101
[2022-03-29 17:46:51 | train] - Train Epoch: [37] [1164800/1281167 (91%)]	Loss: 1.709833
[2022-03-29 17:47:14 | train] - Train Epoch: [37] [1177600/1281167 (92%)]	Loss: 1.112624
[2022-03-29 17:47:35 | train] - Train Epoch: [37] [1190400/1281167 (93%)]	Loss: 1.494546
[2022-03-29 17:47:57 | train] - Train Epoch: [37] [1203200/1281167 (94%)]	Loss: 1.319061
[2022-03-29 17:48:19 | train] - Train Epoch: [37] [1216000/1281167 (95%)]	Loss: 1.412338
[2022-03-29 17:48:41 | train] - Train Epoch: [37] [1228800/1281167 (96%)]	Loss: 1.341634
[2022-03-29 17:49:02 | train] - Train Epoch: [37] [1241600/1281167 (97%)]	Loss: 1.582483
[2022-03-29 17:49:24 | train] - Train Epoch: [37] [1254400/1281167 (98%)]	Loss: 1.576739
[2022-03-29 17:49:45 | train] - Train Epoch: [37] [1267200/1281167 (99%)]	Loss: 1.550130
[2022-03-29 17:50:06 | train] - Train Epoch: [37] [1280000/1281167 (100%)]	Loss: 1.443741
[2022-03-29 17:50:08 | train] - Train Epoch: [37]	 Average Loss: 1.381650	 Total Acc : 67.1339	 Total Top5 Acc : 86.2078
[2022-03-29 17:50:11 | train] - -------37 epoch end-----------
========================================
-------37 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 17:51:52 | train] - 
Epoch [37] Test set: Average loss: 1.3917, Accuracy: 33564/50000 (67.0912%), Top-5 Accuracy: 87.4329%

[2022-03-29 17:51:52 | train] - save intermediate epoch [37] result


[2022-03-29 17:52:01 | train] - logging best performance 37 epoch
[2022-03-29 17:52:02 | train] - -------38 epoch start-----------
========================================
----- test end -------------------------


logging best performance 37 epoch
[2022-03-29 17:52:05 | train] - Train Epoch: [38] [0/1281167 (0%)]	Loss: 1.381707
[2022-03-29 17:52:27 | train] - Train Epoch: [38] [12800/1281167 (1%)]	Loss: 1.359746
[2022-03-29 17:52:48 | train] - Train Epoch: [38] [25600/1281167 (2%)]	Loss: 1.401487
[2022-03-29 17:53:10 | train] - Train Epoch: [38] [38400/1281167 (3%)]	Loss: 0.970446
[2022-03-29 17:53:31 | train] - Train Epoch: [38] [51200/1281167 (4%)]	Loss: 1.363530
[2022-03-29 17:53:52 | train] - Train Epoch: [38] [64000/1281167 (5%)]	Loss: 1.346143
[2022-03-29 17:54:13 | train] - Train Epoch: [38] [76800/1281167 (6%)]	Loss: 1.233002
[2022-03-29 17:54:34 | train] - Train Epoch: [38] [89600/1281167 (7%)]	Loss: 1.226550
[2022-03-29 17:54:56 | train] - Train Epoch: [38] [102400/1281167 (8%)]	Loss: 1.143459
[2022-03-29 17:55:18 | train] - Train Epoch: [38] [115200/1281167 (9%)]	Loss: 1.134078
[2022-03-29 17:55:39 | train] - Train Epoch: [38] [128000/1281167 (10%)]	Loss: 1.227628
[2022-03-29 17:56:01 | train] - Train Epoch: [38] [140800/1281167 (11%)]	Loss: 1.298458
[2022-03-29 17:56:22 | train] - Train Epoch: [38] [153600/1281167 (12%)]	Loss: 1.640473
[2022-03-29 17:56:43 | train] - Train Epoch: [38] [166400/1281167 (13%)]	Loss: 1.306638
[2022-03-29 17:57:03 | train] - Train Epoch: [38] [179200/1281167 (14%)]	Loss: 1.483354
[2022-03-29 17:57:25 | train] - Train Epoch: [38] [192000/1281167 (15%)]	Loss: 1.465732
[2022-03-29 17:57:45 | train] - Train Epoch: [38] [204800/1281167 (16%)]	Loss: 1.506022
[2022-03-29 17:58:08 | train] - Train Epoch: [38] [217600/1281167 (17%)]	Loss: 1.407041
[2022-03-29 17:58:29 | train] - Train Epoch: [38] [230400/1281167 (18%)]	Loss: 1.207819
[2022-03-29 17:58:50 | train] - Train Epoch: [38] [243200/1281167 (19%)]	Loss: 1.225930
[2022-03-29 17:59:12 | train] - Train Epoch: [38] [256000/1281167 (20%)]	Loss: 1.365133
[2022-03-29 17:59:33 | train] - Train Epoch: [38] [268800/1281167 (21%)]	Loss: 1.644589
[2022-03-29 17:59:54 | train] - Train Epoch: [38] [281600/1281167 (22%)]	Loss: 1.370414
[2022-03-29 18:00:16 | train] - Train Epoch: [38] [294400/1281167 (23%)]	Loss: 1.588763
[2022-03-29 18:00:37 | train] - Train Epoch: [38] [307200/1281167 (24%)]	Loss: 1.283967
[2022-03-29 18:00:58 | train] - Train Epoch: [38] [320000/1281167 (25%)]	Loss: 1.362227
[2022-03-29 18:01:20 | train] - Train Epoch: [38] [332800/1281167 (26%)]	Loss: 1.493630
[2022-03-29 18:01:40 | train] - Train Epoch: [38] [345600/1281167 (27%)]	Loss: 1.639070
[2022-03-29 18:02:02 | train] - Train Epoch: [38] [358400/1281167 (28%)]	Loss: 1.545140
[2022-03-29 18:02:23 | train] - Train Epoch: [38] [371200/1281167 (29%)]	Loss: 1.196338
[2022-03-29 18:02:45 | train] - Train Epoch: [38] [384000/1281167 (30%)]	Loss: 1.499593
[2022-03-29 18:03:07 | train] - Train Epoch: [38] [396800/1281167 (31%)]	Loss: 1.126715
[2022-03-29 18:03:28 | train] - Train Epoch: [38] [409600/1281167 (32%)]	Loss: 1.444681
[2022-03-29 18:03:50 | train] - Train Epoch: [38] [422400/1281167 (33%)]	Loss: 1.352098
[2022-03-29 18:04:12 | train] - Train Epoch: [38] [435200/1281167 (34%)]	Loss: 1.559866
[2022-03-29 18:04:33 | train] - Train Epoch: [38] [448000/1281167 (35%)]	Loss: 1.335649
[2022-03-29 18:04:54 | train] - Train Epoch: [38] [460800/1281167 (36%)]	Loss: 1.617430
[2022-03-29 18:05:16 | train] - Train Epoch: [38] [473600/1281167 (37%)]	Loss: 1.244595
[2022-03-29 18:05:37 | train] - Train Epoch: [38] [486400/1281167 (38%)]	Loss: 1.164726
[2022-03-29 18:05:57 | train] - Train Epoch: [38] [499200/1281167 (39%)]	Loss: 1.469862
[2022-03-29 18:06:18 | train] - Train Epoch: [38] [512000/1281167 (40%)]	Loss: 1.193548
[2022-03-29 18:06:40 | train] - Train Epoch: [38] [524800/1281167 (41%)]	Loss: 1.156943
[2022-03-29 18:07:01 | train] - Train Epoch: [38] [537600/1281167 (42%)]	Loss: 1.344239
[2022-03-29 18:07:23 | train] - Train Epoch: [38] [550400/1281167 (43%)]	Loss: 1.380646
[2022-03-29 18:07:43 | train] - Train Epoch: [38] [563200/1281167 (44%)]	Loss: 1.649523
[2022-03-29 18:08:05 | train] - Train Epoch: [38] [576000/1281167 (45%)]	Loss: 1.541800
[2022-03-29 18:08:27 | train] - Train Epoch: [38] [588800/1281167 (46%)]	Loss: 1.122691
[2022-03-29 18:08:48 | train] - Train Epoch: [38] [601600/1281167 (47%)]	Loss: 1.700751
[2022-03-29 18:09:09 | train] - Train Epoch: [38] [614400/1281167 (48%)]	Loss: 1.456302
[2022-03-29 18:09:31 | train] - Train Epoch: [38] [627200/1281167 (49%)]	Loss: 1.131948
[2022-03-29 18:09:53 | train] - Train Epoch: [38] [640000/1281167 (50%)]	Loss: 1.606123
[2022-03-29 18:10:14 | train] - Train Epoch: [38] [652800/1281167 (51%)]	Loss: 1.317442
[2022-03-29 18:10:35 | train] - Train Epoch: [38] [665600/1281167 (52%)]	Loss: 1.418710
[2022-03-29 18:10:57 | train] - Train Epoch: [38] [678400/1281167 (53%)]	Loss: 1.501305
[2022-03-29 18:11:17 | train] - Train Epoch: [38] [691200/1281167 (54%)]	Loss: 1.164821
[2022-03-29 18:11:38 | train] - Train Epoch: [38] [704000/1281167 (55%)]	Loss: 1.083815
[2022-03-29 18:12:00 | train] - Train Epoch: [38] [716800/1281167 (56%)]	Loss: 1.650200
[2022-03-29 18:12:22 | train] - Train Epoch: [38] [729600/1281167 (57%)]	Loss: 1.064741
[2022-03-29 18:12:43 | train] - Train Epoch: [38] [742400/1281167 (58%)]	Loss: 1.572663
[2022-03-29 18:13:05 | train] - Train Epoch: [38] [755200/1281167 (59%)]	Loss: 1.416920
[2022-03-29 18:13:25 | train] - Train Epoch: [38] [768000/1281167 (60%)]	Loss: 1.329780
[2022-03-29 18:13:46 | train] - Train Epoch: [38] [780800/1281167 (61%)]	Loss: 1.082622
[2022-03-29 18:14:08 | train] - Train Epoch: [38] [793600/1281167 (62%)]	Loss: 1.426735
[2022-03-29 18:14:30 | train] - Train Epoch: [38] [806400/1281167 (63%)]	Loss: 1.430805
[2022-03-29 18:14:50 | train] - Train Epoch: [38] [819200/1281167 (64%)]	Loss: 1.483530
[2022-03-29 18:15:10 | train] - Train Epoch: [38] [832000/1281167 (65%)]	Loss: 1.550075
[2022-03-29 18:15:31 | train] - Train Epoch: [38] [844800/1281167 (66%)]	Loss: 1.380933
[2022-03-29 18:15:54 | train] - Train Epoch: [38] [857600/1281167 (67%)]	Loss: 1.455860
[2022-03-29 18:16:15 | train] - Train Epoch: [38] [870400/1281167 (68%)]	Loss: 1.512184
[2022-03-29 18:16:36 | train] - Train Epoch: [38] [883200/1281167 (69%)]	Loss: 1.550157
[2022-03-29 18:16:56 | train] - Train Epoch: [38] [896000/1281167 (70%)]	Loss: 1.344214
[2022-03-29 18:17:17 | train] - Train Epoch: [38] [908800/1281167 (71%)]	Loss: 1.559606
[2022-03-29 18:17:37 | train] - Train Epoch: [38] [921600/1281167 (72%)]	Loss: 1.356711
[2022-03-29 18:17:59 | train] - Train Epoch: [38] [934400/1281167 (73%)]	Loss: 1.582378
[2022-03-29 18:18:19 | train] - Train Epoch: [38] [947200/1281167 (74%)]	Loss: 1.449883
[2022-03-29 18:18:41 | train] - Train Epoch: [38] [960000/1281167 (75%)]	Loss: 1.220703
[2022-03-29 18:19:02 | train] - Train Epoch: [38] [972800/1281167 (76%)]	Loss: 1.260234
[2022-03-29 18:19:25 | train] - Train Epoch: [38] [985600/1281167 (77%)]	Loss: 1.678290
[2022-03-29 18:19:47 | train] - Train Epoch: [38] [998400/1281167 (78%)]	Loss: 1.345363
[2022-03-29 18:20:10 | train] - Train Epoch: [38] [1011200/1281167 (79%)]	Loss: 1.155876
[2022-03-29 18:20:33 | train] - Train Epoch: [38] [1024000/1281167 (80%)]	Loss: 1.564955
[2022-03-29 18:20:55 | train] - Train Epoch: [38] [1036800/1281167 (81%)]	Loss: 1.589947
[2022-03-29 18:21:16 | train] - Train Epoch: [38] [1049600/1281167 (82%)]	Loss: 1.373741
[2022-03-29 18:21:38 | train] - Train Epoch: [38] [1062400/1281167 (83%)]	Loss: 1.008068
[2022-03-29 18:21:59 | train] - Train Epoch: [38] [1075200/1281167 (84%)]	Loss: 1.122839
[2022-03-29 18:22:22 | train] - Train Epoch: [38] [1088000/1281167 (85%)]	Loss: 1.324295
[2022-03-29 18:22:44 | train] - Train Epoch: [38] [1100800/1281167 (86%)]	Loss: 1.221385
[2022-03-29 18:23:06 | train] - Train Epoch: [38] [1113600/1281167 (87%)]	Loss: 1.751583
[2022-03-29 18:23:29 | train] - Train Epoch: [38] [1126400/1281167 (88%)]	Loss: 1.374110
[2022-03-29 18:23:51 | train] - Train Epoch: [38] [1139200/1281167 (89%)]	Loss: 1.194909
[2022-03-29 18:24:12 | train] - Train Epoch: [38] [1152000/1281167 (90%)]	Loss: 0.955521
[2022-03-29 18:24:34 | train] - Train Epoch: [38] [1164800/1281167 (91%)]	Loss: 1.376322
[2022-03-29 18:24:56 | train] - Train Epoch: [38] [1177600/1281167 (92%)]	Loss: 1.349125
[2022-03-29 18:25:17 | train] - Train Epoch: [38] [1190400/1281167 (93%)]	Loss: 1.570408
[2022-03-29 18:25:38 | train] - Train Epoch: [38] [1203200/1281167 (94%)]	Loss: 1.473226
[2022-03-29 18:26:01 | train] - Train Epoch: [38] [1216000/1281167 (95%)]	Loss: 1.449929
[2022-03-29 18:26:22 | train] - Train Epoch: [38] [1228800/1281167 (96%)]	Loss: 1.261957
[2022-03-29 18:26:43 | train] - Train Epoch: [38] [1241600/1281167 (97%)]	Loss: 1.564558
[2022-03-29 18:27:04 | train] - Train Epoch: [38] [1254400/1281167 (98%)]	Loss: 1.656369
[2022-03-29 18:27:26 | train] - Train Epoch: [38] [1267200/1281167 (99%)]	Loss: 1.600052
[2022-03-29 18:27:47 | train] - Train Epoch: [38] [1280000/1281167 (100%)]	Loss: 1.484825
[2022-03-29 18:27:49 | train] - Train Epoch: [38]	 Average Loss: 1.368571	 Total Acc : 67.4201	 Total Top5 Acc : 86.3545
[2022-03-29 18:27:52 | train] - -------38 epoch end-----------
========================================
-------38 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 18:29:35 | train] - 
Epoch [38] Test set: Average loss: 1.3989, Accuracy: 33513/50000 (66.9917%), Top-5 Accuracy: 87.4992%

[2022-03-29 18:29:35 | train] - save intermediate epoch [38] result


[2022-03-29 18:29:45 | train] - -------39 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 18:29:48 | train] - Train Epoch: [39] [0/1281167 (0%)]	Loss: 1.465034
[2022-03-29 18:30:11 | train] - Train Epoch: [39] [12800/1281167 (1%)]	Loss: 1.579831
[2022-03-29 18:30:33 | train] - Train Epoch: [39] [25600/1281167 (2%)]	Loss: 1.270358
[2022-03-29 18:30:57 | train] - Train Epoch: [39] [38400/1281167 (3%)]	Loss: 1.261770
[2022-03-29 18:31:19 | train] - Train Epoch: [39] [51200/1281167 (4%)]	Loss: 1.240735
[2022-03-29 18:31:41 | train] - Train Epoch: [39] [64000/1281167 (5%)]	Loss: 1.588920
[2022-03-29 18:32:04 | train] - Train Epoch: [39] [76800/1281167 (6%)]	Loss: 1.328708
[2022-03-29 18:32:28 | train] - Train Epoch: [39] [89600/1281167 (7%)]	Loss: 1.533259
[2022-03-29 18:32:50 | train] - Train Epoch: [39] [102400/1281167 (8%)]	Loss: 1.081134
[2022-03-29 18:33:13 | train] - Train Epoch: [39] [115200/1281167 (9%)]	Loss: 1.278197
[2022-03-29 18:33:36 | train] - Train Epoch: [39] [128000/1281167 (10%)]	Loss: 1.512213
[2022-03-29 18:33:59 | train] - Train Epoch: [39] [140800/1281167 (11%)]	Loss: 1.394921
[2022-03-29 18:34:20 | train] - Train Epoch: [39] [153600/1281167 (12%)]	Loss: 1.783728
[2022-03-29 18:34:41 | train] - Train Epoch: [39] [166400/1281167 (13%)]	Loss: 1.537202
[2022-03-29 18:35:03 | train] - Train Epoch: [39] [179200/1281167 (14%)]	Loss: 1.464571
[2022-03-29 18:35:25 | train] - Train Epoch: [39] [192000/1281167 (15%)]	Loss: 1.384936
[2022-03-29 18:35:47 | train] - Train Epoch: [39] [204800/1281167 (16%)]	Loss: 1.412388
[2022-03-29 18:36:09 | train] - Train Epoch: [39] [217600/1281167 (17%)]	Loss: 1.420347
[2022-03-29 18:36:30 | train] - Train Epoch: [39] [230400/1281167 (18%)]	Loss: 1.527784
[2022-03-29 18:36:50 | train] - Train Epoch: [39] [243200/1281167 (19%)]	Loss: 1.310479
[2022-03-29 18:37:12 | train] - Train Epoch: [39] [256000/1281167 (20%)]	Loss: 1.395929
[2022-03-29 18:37:33 | train] - Train Epoch: [39] [268800/1281167 (21%)]	Loss: 1.340372
[2022-03-29 18:37:55 | train] - Train Epoch: [39] [281600/1281167 (22%)]	Loss: 1.334723
[2022-03-29 18:38:17 | train] - Train Epoch: [39] [294400/1281167 (23%)]	Loss: 1.283109
[2022-03-29 18:38:38 | train] - Train Epoch: [39] [307200/1281167 (24%)]	Loss: 1.581414
[2022-03-29 18:38:59 | train] - Train Epoch: [39] [320000/1281167 (25%)]	Loss: 1.440999
[2022-03-29 18:39:22 | train] - Train Epoch: [39] [332800/1281167 (26%)]	Loss: 1.407936
[2022-03-29 18:39:44 | train] - Train Epoch: [39] [345600/1281167 (27%)]	Loss: 1.286864
[2022-03-29 18:40:05 | train] - Train Epoch: [39] [358400/1281167 (28%)]	Loss: 1.284820
[2022-03-29 18:40:27 | train] - Train Epoch: [39] [371200/1281167 (29%)]	Loss: 1.216690
[2022-03-29 18:40:47 | train] - Train Epoch: [39] [384000/1281167 (30%)]	Loss: 1.441588
[2022-03-29 18:41:08 | train] - Train Epoch: [39] [396800/1281167 (31%)]	Loss: 1.392292
[2022-03-29 18:41:30 | train] - Train Epoch: [39] [409600/1281167 (32%)]	Loss: 1.391151
[2022-03-29 18:41:52 | train] - Train Epoch: [39] [422400/1281167 (33%)]	Loss: 1.224137
[2022-03-29 18:42:15 | train] - Train Epoch: [39] [435200/1281167 (34%)]	Loss: 1.387278
[2022-03-29 18:42:38 | train] - Train Epoch: [39] [448000/1281167 (35%)]	Loss: 1.580664
[2022-03-29 18:43:00 | train] - Train Epoch: [39] [460800/1281167 (36%)]	Loss: 1.213980
[2022-03-29 18:43:23 | train] - Train Epoch: [39] [473600/1281167 (37%)]	Loss: 1.192056
[2022-03-29 18:43:46 | train] - Train Epoch: [39] [486400/1281167 (38%)]	Loss: 1.217679
[2022-03-29 18:44:06 | train] - Train Epoch: [39] [499200/1281167 (39%)]	Loss: 0.983857
[2022-03-29 18:44:27 | train] - Train Epoch: [39] [512000/1281167 (40%)]	Loss: 1.445865
[2022-03-29 18:44:49 | train] - Train Epoch: [39] [524800/1281167 (41%)]	Loss: 1.508294
[2022-03-29 18:45:12 | train] - Train Epoch: [39] [537600/1281167 (42%)]	Loss: 1.384069
[2022-03-29 18:45:34 | train] - Train Epoch: [39] [550400/1281167 (43%)]	Loss: 1.515639
[2022-03-29 18:45:56 | train] - Train Epoch: [39] [563200/1281167 (44%)]	Loss: 1.464173
[2022-03-29 18:46:19 | train] - Train Epoch: [39] [576000/1281167 (45%)]	Loss: 1.413644
[2022-03-29 18:46:39 | train] - Train Epoch: [39] [588800/1281167 (46%)]	Loss: 1.053659
[2022-03-29 18:47:00 | train] - Train Epoch: [39] [601600/1281167 (47%)]	Loss: 1.684773
[2022-03-29 18:47:22 | train] - Train Epoch: [39] [614400/1281167 (48%)]	Loss: 1.272336
[2022-03-29 18:47:43 | train] - Train Epoch: [39] [627200/1281167 (49%)]	Loss: 1.487121
[2022-03-29 18:48:05 | train] - Train Epoch: [39] [640000/1281167 (50%)]	Loss: 1.446216
[2022-03-29 18:48:27 | train] - Train Epoch: [39] [652800/1281167 (51%)]	Loss: 1.284086
[2022-03-29 18:48:51 | train] - Train Epoch: [39] [665600/1281167 (52%)]	Loss: 1.271210
[2022-03-29 18:49:13 | train] - Train Epoch: [39] [678400/1281167 (53%)]	Loss: 1.635671
[2022-03-29 18:49:34 | train] - Train Epoch: [39] [691200/1281167 (54%)]	Loss: 1.354149
[2022-03-29 18:49:55 | train] - Train Epoch: [39] [704000/1281167 (55%)]	Loss: 1.268013
[2022-03-29 18:50:17 | train] - Train Epoch: [39] [716800/1281167 (56%)]	Loss: 1.095227
[2022-03-29 18:50:39 | train] - Train Epoch: [39] [729600/1281167 (57%)]	Loss: 1.402838
[2022-03-29 18:51:01 | train] - Train Epoch: [39] [742400/1281167 (58%)]	Loss: 1.577164
[2022-03-29 18:51:23 | train] - Train Epoch: [39] [755200/1281167 (59%)]	Loss: 1.373613
[2022-03-29 18:51:45 | train] - Train Epoch: [39] [768000/1281167 (60%)]	Loss: 1.203536
[2022-03-29 18:52:07 | train] - Train Epoch: [39] [780800/1281167 (61%)]	Loss: 1.214182
[2022-03-29 18:52:29 | train] - Train Epoch: [39] [793600/1281167 (62%)]	Loss: 1.374734
[2022-03-29 18:52:50 | train] - Train Epoch: [39] [806400/1281167 (63%)]	Loss: 1.568670
[2022-03-29 18:53:10 | train] - Train Epoch: [39] [819200/1281167 (64%)]	Loss: 1.510323
[2022-03-29 18:53:32 | train] - Train Epoch: [39] [832000/1281167 (65%)]	Loss: 1.174436
[2022-03-29 18:53:54 | train] - Train Epoch: [39] [844800/1281167 (66%)]	Loss: 1.031858
[2022-03-29 18:54:16 | train] - Train Epoch: [39] [857600/1281167 (67%)]	Loss: 1.622226
[2022-03-29 18:54:37 | train] - Train Epoch: [39] [870400/1281167 (68%)]	Loss: 1.296248
[2022-03-29 18:54:58 | train] - Train Epoch: [39] [883200/1281167 (69%)]	Loss: 1.417556
[2022-03-29 18:55:19 | train] - Train Epoch: [39] [896000/1281167 (70%)]	Loss: 1.514256
[2022-03-29 18:55:40 | train] - Train Epoch: [39] [908800/1281167 (71%)]	Loss: 1.213458
[2022-03-29 18:56:02 | train] - Train Epoch: [39] [921600/1281167 (72%)]	Loss: 1.178526
[2022-03-29 18:56:24 | train] - Train Epoch: [39] [934400/1281167 (73%)]	Loss: 1.173619
[2022-03-29 18:56:46 | train] - Train Epoch: [39] [947200/1281167 (74%)]	Loss: 1.313475
[2022-03-29 18:57:09 | train] - Train Epoch: [39] [960000/1281167 (75%)]	Loss: 1.461038
[2022-03-29 18:57:31 | train] - Train Epoch: [39] [972800/1281167 (76%)]	Loss: 1.316327
[2022-03-29 18:57:53 | train] - Train Epoch: [39] [985600/1281167 (77%)]	Loss: 1.386454
[2022-03-29 18:58:14 | train] - Train Epoch: [39] [998400/1281167 (78%)]	Loss: 1.249733
[2022-03-29 18:58:35 | train] - Train Epoch: [39] [1011200/1281167 (79%)]	Loss: 1.486757
[2022-03-29 18:58:56 | train] - Train Epoch: [39] [1024000/1281167 (80%)]	Loss: 1.292808
[2022-03-29 18:59:17 | train] - Train Epoch: [39] [1036800/1281167 (81%)]	Loss: 1.781834
[2022-03-29 18:59:39 | train] - Train Epoch: [39] [1049600/1281167 (82%)]	Loss: 1.249815
[2022-03-29 19:00:00 | train] - Train Epoch: [39] [1062400/1281167 (83%)]	Loss: 1.494167
[2022-03-29 19:00:21 | train] - Train Epoch: [39] [1075200/1281167 (84%)]	Loss: 1.104432
[2022-03-29 19:00:42 | train] - Train Epoch: [39] [1088000/1281167 (85%)]	Loss: 1.463539
[2022-03-29 19:01:05 | train] - Train Epoch: [39] [1100800/1281167 (86%)]	Loss: 1.190508
[2022-03-29 19:01:27 | train] - Train Epoch: [39] [1113600/1281167 (87%)]	Loss: 1.320450
[2022-03-29 19:01:48 | train] - Train Epoch: [39] [1126400/1281167 (88%)]	Loss: 1.680550
[2022-03-29 19:02:10 | train] - Train Epoch: [39] [1139200/1281167 (89%)]	Loss: 1.283614
[2022-03-29 19:02:32 | train] - Train Epoch: [39] [1152000/1281167 (90%)]	Loss: 1.292054
[2022-03-29 19:02:53 | train] - Train Epoch: [39] [1164800/1281167 (91%)]	Loss: 1.598958
[2022-03-29 19:03:14 | train] - Train Epoch: [39] [1177600/1281167 (92%)]	Loss: 1.267313
[2022-03-29 19:03:35 | train] - Train Epoch: [39] [1190400/1281167 (93%)]	Loss: 1.393810
[2022-03-29 19:03:56 | train] - Train Epoch: [39] [1203200/1281167 (94%)]	Loss: 1.207312
[2022-03-29 19:04:18 | train] - Train Epoch: [39] [1216000/1281167 (95%)]	Loss: 1.148946
[2022-03-29 19:04:41 | train] - Train Epoch: [39] [1228800/1281167 (96%)]	Loss: 1.476756
[2022-03-29 19:05:02 | train] - Train Epoch: [39] [1241600/1281167 (97%)]	Loss: 1.265068
[2022-03-29 19:05:23 | train] - Train Epoch: [39] [1254400/1281167 (98%)]	Loss: 1.321767
[2022-03-29 19:05:45 | train] - Train Epoch: [39] [1267200/1281167 (99%)]	Loss: 1.806149
[2022-03-29 19:06:07 | train] - Train Epoch: [39] [1280000/1281167 (100%)]	Loss: 1.746315
[2022-03-29 19:06:09 | train] - Train Epoch: [39]	 Average Loss: 1.355864	 Total Acc : 67.6987	 Total Top5 Acc : 86.5101
[2022-03-29 19:06:12 | train] - -------39 epoch end-----------
========================================
-------39 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 19:07:54 | train] - 
Epoch [39] Test set: Average loss: 1.4021, Accuracy: 33491/50000 (66.9609%), Top-5 Accuracy: 87.4736%

[2022-03-29 19:07:54 | train] - save intermediate epoch [39] result


[2022-03-29 19:08:04 | train] - -------40 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 19:08:06 | train] - Train Epoch: [40] [0/1281167 (0%)]	Loss: 1.419026
[2022-03-29 19:08:29 | train] - Train Epoch: [40] [12800/1281167 (1%)]	Loss: 1.374114
[2022-03-29 19:08:51 | train] - Train Epoch: [40] [25600/1281167 (2%)]	Loss: 1.363691
[2022-03-29 19:09:13 | train] - Train Epoch: [40] [38400/1281167 (3%)]	Loss: 1.281673
[2022-03-29 19:09:36 | train] - Train Epoch: [40] [51200/1281167 (4%)]	Loss: 1.248537
[2022-03-29 19:09:59 | train] - Train Epoch: [40] [64000/1281167 (5%)]	Loss: 1.280114
[2022-03-29 19:10:21 | train] - Train Epoch: [40] [76800/1281167 (6%)]	Loss: 1.609187
[2022-03-29 19:10:43 | train] - Train Epoch: [40] [89600/1281167 (7%)]	Loss: 1.239707
[2022-03-29 19:11:05 | train] - Train Epoch: [40] [102400/1281167 (8%)]	Loss: 1.328898
[2022-03-29 19:11:28 | train] - Train Epoch: [40] [115200/1281167 (9%)]	Loss: 1.408820
[2022-03-29 19:11:50 | train] - Train Epoch: [40] [128000/1281167 (10%)]	Loss: 1.329489
[2022-03-29 19:12:12 | train] - Train Epoch: [40] [140800/1281167 (11%)]	Loss: 1.237683
[2022-03-29 19:12:35 | train] - Train Epoch: [40] [153600/1281167 (12%)]	Loss: 1.253903
[2022-03-29 19:12:56 | train] - Train Epoch: [40] [166400/1281167 (13%)]	Loss: 1.282429
[2022-03-29 19:13:18 | train] - Train Epoch: [40] [179200/1281167 (14%)]	Loss: 1.184256
[2022-03-29 19:13:39 | train] - Train Epoch: [40] [192000/1281167 (15%)]	Loss: 1.373579
[2022-03-29 19:14:02 | train] - Train Epoch: [40] [204800/1281167 (16%)]	Loss: 1.460952
[2022-03-29 19:14:24 | train] - Train Epoch: [40] [217600/1281167 (17%)]	Loss: 1.446093
[2022-03-29 19:14:46 | train] - Train Epoch: [40] [230400/1281167 (18%)]	Loss: 1.368131
[2022-03-29 19:15:08 | train] - Train Epoch: [40] [243200/1281167 (19%)]	Loss: 1.020379
[2022-03-29 19:15:30 | train] - Train Epoch: [40] [256000/1281167 (20%)]	Loss: 1.271303
[2022-03-29 19:15:51 | train] - Train Epoch: [40] [268800/1281167 (21%)]	Loss: 1.584510
[2022-03-29 19:16:13 | train] - Train Epoch: [40] [281600/1281167 (22%)]	Loss: 1.245446
[2022-03-29 19:16:35 | train] - Train Epoch: [40] [294400/1281167 (23%)]	Loss: 1.024355
[2022-03-29 19:16:57 | train] - Train Epoch: [40] [307200/1281167 (24%)]	Loss: 1.108759
[2022-03-29 19:17:19 | train] - Train Epoch: [40] [320000/1281167 (25%)]	Loss: 1.532872
[2022-03-29 19:17:40 | train] - Train Epoch: [40] [332800/1281167 (26%)]	Loss: 1.494099
[2022-03-29 19:18:02 | train] - Train Epoch: [40] [345600/1281167 (27%)]	Loss: 1.238040
[2022-03-29 19:18:25 | train] - Train Epoch: [40] [358400/1281167 (28%)]	Loss: 1.314576
[2022-03-29 19:18:47 | train] - Train Epoch: [40] [371200/1281167 (29%)]	Loss: 1.102697
[2022-03-29 19:19:09 | train] - Train Epoch: [40] [384000/1281167 (30%)]	Loss: 1.156521
[2022-03-29 19:19:31 | train] - Train Epoch: [40] [396800/1281167 (31%)]	Loss: 1.455122
[2022-03-29 19:19:53 | train] - Train Epoch: [40] [409600/1281167 (32%)]	Loss: 1.226495
[2022-03-29 19:20:16 | train] - Train Epoch: [40] [422400/1281167 (33%)]	Loss: 1.461457
[2022-03-29 19:20:39 | train] - Train Epoch: [40] [435200/1281167 (34%)]	Loss: 1.664339
[2022-03-29 19:21:01 | train] - Train Epoch: [40] [448000/1281167 (35%)]	Loss: 1.446359
[2022-03-29 19:21:23 | train] - Train Epoch: [40] [460800/1281167 (36%)]	Loss: 1.348783
[2022-03-29 19:21:45 | train] - Train Epoch: [40] [473600/1281167 (37%)]	Loss: 1.211360
[2022-03-29 19:22:07 | train] - Train Epoch: [40] [486400/1281167 (38%)]	Loss: 1.426917
[2022-03-29 19:22:29 | train] - Train Epoch: [40] [499200/1281167 (39%)]	Loss: 1.131495
[2022-03-29 19:22:52 | train] - Train Epoch: [40] [512000/1281167 (40%)]	Loss: 1.473657
[2022-03-29 19:23:13 | train] - Train Epoch: [40] [524800/1281167 (41%)]	Loss: 1.348294
[2022-03-29 19:23:35 | train] - Train Epoch: [40] [537600/1281167 (42%)]	Loss: 1.301653
[2022-03-29 19:23:58 | train] - Train Epoch: [40] [550400/1281167 (43%)]	Loss: 1.869790
[2022-03-29 19:24:20 | train] - Train Epoch: [40] [563200/1281167 (44%)]	Loss: 1.369165
[2022-03-29 19:24:42 | train] - Train Epoch: [40] [576000/1281167 (45%)]	Loss: 1.340267
[2022-03-29 19:25:04 | train] - Train Epoch: [40] [588800/1281167 (46%)]	Loss: 0.997428
[2022-03-29 19:25:26 | train] - Train Epoch: [40] [601600/1281167 (47%)]	Loss: 1.180083
[2022-03-29 19:25:49 | train] - Train Epoch: [40] [614400/1281167 (48%)]	Loss: 1.102816
[2022-03-29 19:26:11 | train] - Train Epoch: [40] [627200/1281167 (49%)]	Loss: 1.415824
[2022-03-29 19:26:33 | train] - Train Epoch: [40] [640000/1281167 (50%)]	Loss: 1.346799
[2022-03-29 19:26:55 | train] - Train Epoch: [40] [652800/1281167 (51%)]	Loss: 0.962453
[2022-03-29 19:27:17 | train] - Train Epoch: [40] [665600/1281167 (52%)]	Loss: 1.151259
[2022-03-29 19:27:39 | train] - Train Epoch: [40] [678400/1281167 (53%)]	Loss: 1.335180
[2022-03-29 19:28:01 | train] - Train Epoch: [40] [691200/1281167 (54%)]	Loss: 1.416884
[2022-03-29 19:28:24 | train] - Train Epoch: [40] [704000/1281167 (55%)]	Loss: 1.371032
[2022-03-29 19:28:46 | train] - Train Epoch: [40] [716800/1281167 (56%)]	Loss: 1.443040
[2022-03-29 19:29:08 | train] - Train Epoch: [40] [729600/1281167 (57%)]	Loss: 1.596004
[2022-03-29 19:29:30 | train] - Train Epoch: [40] [742400/1281167 (58%)]	Loss: 1.586076
[2022-03-29 19:29:53 | train] - Train Epoch: [40] [755200/1281167 (59%)]	Loss: 1.382264
[2022-03-29 19:30:16 | train] - Train Epoch: [40] [768000/1281167 (60%)]	Loss: 1.384097
[2022-03-29 19:30:38 | train] - Train Epoch: [40] [780800/1281167 (61%)]	Loss: 1.578855
[2022-03-29 19:31:00 | train] - Train Epoch: [40] [793600/1281167 (62%)]	Loss: 1.540034
[2022-03-29 19:31:21 | train] - Train Epoch: [40] [806400/1281167 (63%)]	Loss: 1.514578
[2022-03-29 19:31:43 | train] - Train Epoch: [40] [819200/1281167 (64%)]	Loss: 1.136999
[2022-03-29 19:32:06 | train] - Train Epoch: [40] [832000/1281167 (65%)]	Loss: 1.846318
[2022-03-29 19:32:29 | train] - Train Epoch: [40] [844800/1281167 (66%)]	Loss: 1.255723
[2022-03-29 19:32:50 | train] - Train Epoch: [40] [857600/1281167 (67%)]	Loss: 1.369106
[2022-03-29 19:33:13 | train] - Train Epoch: [40] [870400/1281167 (68%)]	Loss: 1.353335
[2022-03-29 19:33:35 | train] - Train Epoch: [40] [883200/1281167 (69%)]	Loss: 1.316143
[2022-03-29 19:33:57 | train] - Train Epoch: [40] [896000/1281167 (70%)]	Loss: 1.350788
[2022-03-29 19:34:19 | train] - Train Epoch: [40] [908800/1281167 (71%)]	Loss: 1.847684
[2022-03-29 19:34:41 | train] - Train Epoch: [40] [921600/1281167 (72%)]	Loss: 1.341652
[2022-03-29 19:35:04 | train] - Train Epoch: [40] [934400/1281167 (73%)]	Loss: 1.695761
[2022-03-29 19:35:25 | train] - Train Epoch: [40] [947200/1281167 (74%)]	Loss: 1.148346
[2022-03-29 19:35:48 | train] - Train Epoch: [40] [960000/1281167 (75%)]	Loss: 1.499072
[2022-03-29 19:36:10 | train] - Train Epoch: [40] [972800/1281167 (76%)]	Loss: 1.091493
[2022-03-29 19:36:33 | train] - Train Epoch: [40] [985600/1281167 (77%)]	Loss: 1.140642
[2022-03-29 19:36:54 | train] - Train Epoch: [40] [998400/1281167 (78%)]	Loss: 1.640667
[2022-03-29 19:37:18 | train] - Train Epoch: [40] [1011200/1281167 (79%)]	Loss: 1.178713
[2022-03-29 19:37:40 | train] - Train Epoch: [40] [1024000/1281167 (80%)]	Loss: 1.616374
[2022-03-29 19:38:02 | train] - Train Epoch: [40] [1036800/1281167 (81%)]	Loss: 1.408130
[2022-03-29 19:38:24 | train] - Train Epoch: [40] [1049600/1281167 (82%)]	Loss: 1.198783
[2022-03-29 19:38:46 | train] - Train Epoch: [40] [1062400/1281167 (83%)]	Loss: 1.311348
[2022-03-29 19:39:08 | train] - Train Epoch: [40] [1075200/1281167 (84%)]	Loss: 1.481042
[2022-03-29 19:39:31 | train] - Train Epoch: [40] [1088000/1281167 (85%)]	Loss: 1.297693
[2022-03-29 19:39:53 | train] - Train Epoch: [40] [1100800/1281167 (86%)]	Loss: 1.262494
[2022-03-29 19:40:15 | train] - Train Epoch: [40] [1113600/1281167 (87%)]	Loss: 1.528711
[2022-03-29 19:40:37 | train] - Train Epoch: [40] [1126400/1281167 (88%)]	Loss: 1.288140
[2022-03-29 19:40:59 | train] - Train Epoch: [40] [1139200/1281167 (89%)]	Loss: 1.380563
[2022-03-29 19:41:21 | train] - Train Epoch: [40] [1152000/1281167 (90%)]	Loss: 1.690201
[2022-03-29 19:41:44 | train] - Train Epoch: [40] [1164800/1281167 (91%)]	Loss: 1.590211
[2022-03-29 19:42:06 | train] - Train Epoch: [40] [1177600/1281167 (92%)]	Loss: 1.284804
[2022-03-29 19:42:28 | train] - Train Epoch: [40] [1190400/1281167 (93%)]	Loss: 1.648919
[2022-03-29 19:42:50 | train] - Train Epoch: [40] [1203200/1281167 (94%)]	Loss: 1.589888
[2022-03-29 19:43:12 | train] - Train Epoch: [40] [1216000/1281167 (95%)]	Loss: 1.357584
[2022-03-29 19:43:35 | train] - Train Epoch: [40] [1228800/1281167 (96%)]	Loss: 1.449887
[2022-03-29 19:43:56 | train] - Train Epoch: [40] [1241600/1281167 (97%)]	Loss: 1.464241
[2022-03-29 19:44:18 | train] - Train Epoch: [40] [1254400/1281167 (98%)]	Loss: 1.181332
[2022-03-29 19:44:40 | train] - Train Epoch: [40] [1267200/1281167 (99%)]	Loss: 1.451363
[2022-03-29 19:45:02 | train] - Train Epoch: [40] [1280000/1281167 (100%)]	Loss: 1.221862
[2022-03-29 19:45:05 | train] - Train Epoch: [40]	 Average Loss: 1.341148	 Total Acc : 68.0624	 Total Top5 Acc : 86.7217
[2022-03-29 19:45:07 | train] - -------40 epoch end-----------
========================================
-------40 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 19:46:50 | train] - 
Epoch [40] Test set: Average loss: 1.3777, Accuracy: 33629/50000 (67.2235%), Top-5 Accuracy: 87.5244%

[2022-03-29 19:46:50 | train] - save intermediate epoch [40] result


[2022-03-29 19:46:59 | train] - logging best performance 40 epoch
[2022-03-29 19:47:00 | train] - -------41 epoch start-----------
========================================
----- test end -------------------------


logging best performance 40 epoch
[2022-03-29 19:47:03 | train] - Train Epoch: [41] [0/1281167 (0%)]	Loss: 1.378410
[2022-03-29 19:47:26 | train] - Train Epoch: [41] [12800/1281167 (1%)]	Loss: 1.346224
[2022-03-29 19:47:47 | train] - Train Epoch: [41] [25600/1281167 (2%)]	Loss: 1.259334
[2022-03-29 19:48:08 | train] - Train Epoch: [41] [38400/1281167 (3%)]	Loss: 1.496437
[2022-03-29 19:48:30 | train] - Train Epoch: [41] [51200/1281167 (4%)]	Loss: 1.451779
[2022-03-29 19:48:52 | train] - Train Epoch: [41] [64000/1281167 (5%)]	Loss: 1.406253
[2022-03-29 19:49:15 | train] - Train Epoch: [41] [76800/1281167 (6%)]	Loss: 1.310750
[2022-03-29 19:49:38 | train] - Train Epoch: [41] [89600/1281167 (7%)]	Loss: 1.402578
[2022-03-29 19:50:00 | train] - Train Epoch: [41] [102400/1281167 (8%)]	Loss: 1.148258
[2022-03-29 19:50:20 | train] - Train Epoch: [41] [115200/1281167 (9%)]	Loss: 1.282367
[2022-03-29 19:50:43 | train] - Train Epoch: [41] [128000/1281167 (10%)]	Loss: 1.241053
[2022-03-29 19:51:05 | train] - Train Epoch: [41] [140800/1281167 (11%)]	Loss: 1.298420
[2022-03-29 19:51:27 | train] - Train Epoch: [41] [153600/1281167 (12%)]	Loss: 1.256571
[2022-03-29 19:51:48 | train] - Train Epoch: [41] [166400/1281167 (13%)]	Loss: 1.495546
[2022-03-29 19:52:10 | train] - Train Epoch: [41] [179200/1281167 (14%)]	Loss: 1.085468
[2022-03-29 19:52:33 | train] - Train Epoch: [41] [192000/1281167 (15%)]	Loss: 1.402354
[2022-03-29 19:52:54 | train] - Train Epoch: [41] [204800/1281167 (16%)]	Loss: 1.301404
[2022-03-29 19:53:16 | train] - Train Epoch: [41] [217600/1281167 (17%)]	Loss: 1.155344
[2022-03-29 19:53:38 | train] - Train Epoch: [41] [230400/1281167 (18%)]	Loss: 1.411444
[2022-03-29 19:54:00 | train] - Train Epoch: [41] [243200/1281167 (19%)]	Loss: 1.193318
[2022-03-29 19:54:21 | train] - Train Epoch: [41] [256000/1281167 (20%)]	Loss: 1.320118
[2022-03-29 19:54:42 | train] - Train Epoch: [41] [268800/1281167 (21%)]	Loss: 1.130089
[2022-03-29 19:55:04 | train] - Train Epoch: [41] [281600/1281167 (22%)]	Loss: 1.742300
[2022-03-29 19:55:25 | train] - Train Epoch: [41] [294400/1281167 (23%)]	Loss: 1.485912
[2022-03-29 19:55:46 | train] - Train Epoch: [41] [307200/1281167 (24%)]	Loss: 1.469399
[2022-03-29 19:56:08 | train] - Train Epoch: [41] [320000/1281167 (25%)]	Loss: 1.319467
[2022-03-29 19:56:30 | train] - Train Epoch: [41] [332800/1281167 (26%)]	Loss: 1.341411
[2022-03-29 19:56:53 | train] - Train Epoch: [41] [345600/1281167 (27%)]	Loss: 1.272509
[2022-03-29 19:57:15 | train] - Train Epoch: [41] [358400/1281167 (28%)]	Loss: 1.173369
[2022-03-29 19:57:36 | train] - Train Epoch: [41] [371200/1281167 (29%)]	Loss: 1.694022
[2022-03-29 19:57:57 | train] - Train Epoch: [41] [384000/1281167 (30%)]	Loss: 1.108612
[2022-03-29 19:58:20 | train] - Train Epoch: [41] [396800/1281167 (31%)]	Loss: 1.046999
[2022-03-29 19:58:41 | train] - Train Epoch: [41] [409600/1281167 (32%)]	Loss: 1.170299
[2022-03-29 19:59:03 | train] - Train Epoch: [41] [422400/1281167 (33%)]	Loss: 1.067110
[2022-03-29 19:59:23 | train] - Train Epoch: [41] [435200/1281167 (34%)]	Loss: 1.170838
[2022-03-29 19:59:45 | train] - Train Epoch: [41] [448000/1281167 (35%)]	Loss: 1.288495
[2022-03-29 20:00:07 | train] - Train Epoch: [41] [460800/1281167 (36%)]	Loss: 1.145706
[2022-03-29 20:00:29 | train] - Train Epoch: [41] [473600/1281167 (37%)]	Loss: 1.353077
[2022-03-29 20:00:50 | train] - Train Epoch: [41] [486400/1281167 (38%)]	Loss: 1.297971
[2022-03-29 20:01:12 | train] - Train Epoch: [41] [499200/1281167 (39%)]	Loss: 1.331655
[2022-03-29 20:01:34 | train] - Train Epoch: [41] [512000/1281167 (40%)]	Loss: 1.260809
[2022-03-29 20:01:54 | train] - Train Epoch: [41] [524800/1281167 (41%)]	Loss: 1.532229
[2022-03-29 20:02:16 | train] - Train Epoch: [41] [537600/1281167 (42%)]	Loss: 1.367730
[2022-03-29 20:02:37 | train] - Train Epoch: [41] [550400/1281167 (43%)]	Loss: 1.646737
[2022-03-29 20:02:58 | train] - Train Epoch: [41] [563200/1281167 (44%)]	Loss: 1.375991
[2022-03-29 20:03:20 | train] - Train Epoch: [41] [576000/1281167 (45%)]	Loss: 1.358191
[2022-03-29 20:03:42 | train] - Train Epoch: [41] [588800/1281167 (46%)]	Loss: 1.029682
[2022-03-29 20:04:04 | train] - Train Epoch: [41] [601600/1281167 (47%)]	Loss: 1.348110
[2022-03-29 20:04:26 | train] - Train Epoch: [41] [614400/1281167 (48%)]	Loss: 1.150385
[2022-03-29 20:04:47 | train] - Train Epoch: [41] [627200/1281167 (49%)]	Loss: 1.339607
[2022-03-29 20:05:09 | train] - Train Epoch: [41] [640000/1281167 (50%)]	Loss: 1.151940
[2022-03-29 20:05:30 | train] - Train Epoch: [41] [652800/1281167 (51%)]	Loss: 1.410119
[2022-03-29 20:05:52 | train] - Train Epoch: [41] [665600/1281167 (52%)]	Loss: 1.309686
[2022-03-29 20:06:14 | train] - Train Epoch: [41] [678400/1281167 (53%)]	Loss: 1.120372
[2022-03-29 20:06:35 | train] - Train Epoch: [41] [691200/1281167 (54%)]	Loss: 1.520611
[2022-03-29 20:06:57 | train] - Train Epoch: [41] [704000/1281167 (55%)]	Loss: 1.163619
[2022-03-29 20:07:19 | train] - Train Epoch: [41] [716800/1281167 (56%)]	Loss: 1.142241
[2022-03-29 20:07:42 | train] - Train Epoch: [41] [729600/1281167 (57%)]	Loss: 1.102760
[2022-03-29 20:08:05 | train] - Train Epoch: [41] [742400/1281167 (58%)]	Loss: 1.213415
[2022-03-29 20:08:28 | train] - Train Epoch: [41] [755200/1281167 (59%)]	Loss: 1.106241
[2022-03-29 20:08:51 | train] - Train Epoch: [41] [768000/1281167 (60%)]	Loss: 1.083203
[2022-03-29 20:09:14 | train] - Train Epoch: [41] [780800/1281167 (61%)]	Loss: 1.356120
[2022-03-29 20:09:37 | train] - Train Epoch: [41] [793600/1281167 (62%)]	Loss: 1.457479
[2022-03-29 20:09:59 | train] - Train Epoch: [41] [806400/1281167 (63%)]	Loss: 1.371501
[2022-03-29 20:10:21 | train] - Train Epoch: [41] [819200/1281167 (64%)]	Loss: 1.397202
[2022-03-29 20:10:44 | train] - Train Epoch: [41] [832000/1281167 (65%)]	Loss: 1.397198
[2022-03-29 20:11:07 | train] - Train Epoch: [41] [844800/1281167 (66%)]	Loss: 1.396498
[2022-03-29 20:11:29 | train] - Train Epoch: [41] [857600/1281167 (67%)]	Loss: 1.389912
[2022-03-29 20:11:51 | train] - Train Epoch: [41] [870400/1281167 (68%)]	Loss: 1.366460
[2022-03-29 20:12:13 | train] - Train Epoch: [41] [883200/1281167 (69%)]	Loss: 1.243426
[2022-03-29 20:12:35 | train] - Train Epoch: [41] [896000/1281167 (70%)]	Loss: 1.273989
[2022-03-29 20:12:57 | train] - Train Epoch: [41] [908800/1281167 (71%)]	Loss: 1.269285
[2022-03-29 20:13:19 | train] - Train Epoch: [41] [921600/1281167 (72%)]	Loss: 1.436107
[2022-03-29 20:13:42 | train] - Train Epoch: [41] [934400/1281167 (73%)]	Loss: 1.330480
[2022-03-29 20:14:04 | train] - Train Epoch: [41] [947200/1281167 (74%)]	Loss: 1.111289
[2022-03-29 20:14:26 | train] - Train Epoch: [41] [960000/1281167 (75%)]	Loss: 1.436144
[2022-03-29 20:14:48 | train] - Train Epoch: [41] [972800/1281167 (76%)]	Loss: 1.490263
[2022-03-29 20:15:11 | train] - Train Epoch: [41] [985600/1281167 (77%)]	Loss: 1.314538
[2022-03-29 20:15:34 | train] - Train Epoch: [41] [998400/1281167 (78%)]	Loss: 1.653579
[2022-03-29 20:15:56 | train] - Train Epoch: [41] [1011200/1281167 (79%)]	Loss: 1.608906
[2022-03-29 20:16:19 | train] - Train Epoch: [41] [1024000/1281167 (80%)]	Loss: 1.583568
[2022-03-29 20:16:42 | train] - Train Epoch: [41] [1036800/1281167 (81%)]	Loss: 1.498225
[2022-03-29 20:17:05 | train] - Train Epoch: [41] [1049600/1281167 (82%)]	Loss: 1.104570
[2022-03-29 20:17:28 | train] - Train Epoch: [41] [1062400/1281167 (83%)]	Loss: 1.517875
[2022-03-29 20:17:51 | train] - Train Epoch: [41] [1075200/1281167 (84%)]	Loss: 1.650677
[2022-03-29 20:18:14 | train] - Train Epoch: [41] [1088000/1281167 (85%)]	Loss: 1.391084
[2022-03-29 20:18:37 | train] - Train Epoch: [41] [1100800/1281167 (86%)]	Loss: 1.315722
[2022-03-29 20:19:00 | train] - Train Epoch: [41] [1113600/1281167 (87%)]	Loss: 1.365964
[2022-03-29 20:19:23 | train] - Train Epoch: [41] [1126400/1281167 (88%)]	Loss: 1.562991
[2022-03-29 20:19:45 | train] - Train Epoch: [41] [1139200/1281167 (89%)]	Loss: 1.236463
[2022-03-29 20:20:08 | train] - Train Epoch: [41] [1152000/1281167 (90%)]	Loss: 1.046819
[2022-03-29 20:20:31 | train] - Train Epoch: [41] [1164800/1281167 (91%)]	Loss: 1.351219
[2022-03-29 20:20:54 | train] - Train Epoch: [41] [1177600/1281167 (92%)]	Loss: 1.686455
[2022-03-29 20:21:17 | train] - Train Epoch: [41] [1190400/1281167 (93%)]	Loss: 0.961446
[2022-03-29 20:21:40 | train] - Train Epoch: [41] [1203200/1281167 (94%)]	Loss: 1.376463
[2022-03-29 20:22:03 | train] - Train Epoch: [41] [1216000/1281167 (95%)]	Loss: 1.116658
[2022-03-29 20:22:26 | train] - Train Epoch: [41] [1228800/1281167 (96%)]	Loss: 1.689032
[2022-03-29 20:22:49 | train] - Train Epoch: [41] [1241600/1281167 (97%)]	Loss: 1.235853
[2022-03-29 20:23:12 | train] - Train Epoch: [41] [1254400/1281167 (98%)]	Loss: 1.548955
[2022-03-29 20:23:34 | train] - Train Epoch: [41] [1267200/1281167 (99%)]	Loss: 1.225420
[2022-03-29 20:23:56 | train] - Train Epoch: [41] [1280000/1281167 (100%)]	Loss: 1.449113
[2022-03-29 20:23:58 | train] - Train Epoch: [41]	 Average Loss: 1.328831	 Total Acc : 68.2496	 Total Top5 Acc : 86.8954
[2022-03-29 20:24:01 | train] - -------41 epoch end-----------
========================================
-------41 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 20:25:44 | train] - 
Epoch [41] Test set: Average loss: 1.3709, Accuracy: 33780/50000 (67.5348%), Top-5 Accuracy: 87.6630%

[2022-03-29 20:25:44 | train] - save intermediate epoch [41] result


[2022-03-29 20:25:54 | train] - logging best performance 41 epoch
[2022-03-29 20:25:56 | train] - -------42 epoch start-----------
========================================
----- test end -------------------------


logging best performance 41 epoch
[2022-03-29 20:25:58 | train] - Train Epoch: [42] [0/1281167 (0%)]	Loss: 1.123596
[2022-03-29 20:26:21 | train] - Train Epoch: [42] [12800/1281167 (1%)]	Loss: 0.959626
[2022-03-29 20:26:44 | train] - Train Epoch: [42] [25600/1281167 (2%)]	Loss: 1.540936
[2022-03-29 20:27:07 | train] - Train Epoch: [42] [38400/1281167 (3%)]	Loss: 1.090458
[2022-03-29 20:27:29 | train] - Train Epoch: [42] [51200/1281167 (4%)]	Loss: 1.230123
[2022-03-29 20:27:50 | train] - Train Epoch: [42] [64000/1281167 (5%)]	Loss: 1.268853
[2022-03-29 20:28:12 | train] - Train Epoch: [42] [76800/1281167 (6%)]	Loss: 1.388462
[2022-03-29 20:28:33 | train] - Train Epoch: [42] [89600/1281167 (7%)]	Loss: 1.424515
[2022-03-29 20:28:54 | train] - Train Epoch: [42] [102400/1281167 (8%)]	Loss: 1.470627
[2022-03-29 20:29:16 | train] - Train Epoch: [42] [115200/1281167 (9%)]	Loss: 1.394428
[2022-03-29 20:29:38 | train] - Train Epoch: [42] [128000/1281167 (10%)]	Loss: 1.647049
[2022-03-29 20:29:59 | train] - Train Epoch: [42] [140800/1281167 (11%)]	Loss: 1.330378
[2022-03-29 20:30:21 | train] - Train Epoch: [42] [153600/1281167 (12%)]	Loss: 1.057208
[2022-03-29 20:30:43 | train] - Train Epoch: [42] [166400/1281167 (13%)]	Loss: 1.236176
[2022-03-29 20:31:04 | train] - Train Epoch: [42] [179200/1281167 (14%)]	Loss: 1.238070
[2022-03-29 20:31:25 | train] - Train Epoch: [42] [192000/1281167 (15%)]	Loss: 1.098913
[2022-03-29 20:31:46 | train] - Train Epoch: [42] [204800/1281167 (16%)]	Loss: 1.515772
[2022-03-29 20:32:08 | train] - Train Epoch: [42] [217600/1281167 (17%)]	Loss: 1.481942
[2022-03-29 20:32:30 | train] - Train Epoch: [42] [230400/1281167 (18%)]	Loss: 1.363489
[2022-03-29 20:32:53 | train] - Train Epoch: [42] [243200/1281167 (19%)]	Loss: 1.439916
[2022-03-29 20:33:14 | train] - Train Epoch: [42] [256000/1281167 (20%)]	Loss: 1.159498
[2022-03-29 20:33:36 | train] - Train Epoch: [42] [268800/1281167 (21%)]	Loss: 1.276194
[2022-03-29 20:33:58 | train] - Train Epoch: [42] [281600/1281167 (22%)]	Loss: 1.135137
[2022-03-29 20:34:19 | train] - Train Epoch: [42] [294400/1281167 (23%)]	Loss: 1.598406
[2022-03-29 20:34:41 | train] - Train Epoch: [42] [307200/1281167 (24%)]	Loss: 1.321103
[2022-03-29 20:35:02 | train] - Train Epoch: [42] [320000/1281167 (25%)]	Loss: 1.303712
[2022-03-29 20:35:23 | train] - Train Epoch: [42] [332800/1281167 (26%)]	Loss: 1.346556
[2022-03-29 20:35:45 | train] - Train Epoch: [42] [345600/1281167 (27%)]	Loss: 1.164483
[2022-03-29 20:36:06 | train] - Train Epoch: [42] [358400/1281167 (28%)]	Loss: 1.212042
[2022-03-29 20:36:28 | train] - Train Epoch: [42] [371200/1281167 (29%)]	Loss: 1.205968
[2022-03-29 20:36:49 | train] - Train Epoch: [42] [384000/1281167 (30%)]	Loss: 1.417053
[2022-03-29 20:37:11 | train] - Train Epoch: [42] [396800/1281167 (31%)]	Loss: 1.233112
[2022-03-29 20:37:32 | train] - Train Epoch: [42] [409600/1281167 (32%)]	Loss: 1.175818
[2022-03-29 20:37:54 | train] - Train Epoch: [42] [422400/1281167 (33%)]	Loss: 1.303741
[2022-03-29 20:38:15 | train] - Train Epoch: [42] [435200/1281167 (34%)]	Loss: 1.240715
[2022-03-29 20:38:38 | train] - Train Epoch: [42] [448000/1281167 (35%)]	Loss: 1.217201
[2022-03-29 20:38:59 | train] - Train Epoch: [42] [460800/1281167 (36%)]	Loss: 1.453581
[2022-03-29 20:39:20 | train] - Train Epoch: [42] [473600/1281167 (37%)]	Loss: 1.820429
[2022-03-29 20:39:43 | train] - Train Epoch: [42] [486400/1281167 (38%)]	Loss: 1.598938
[2022-03-29 20:40:04 | train] - Train Epoch: [42] [499200/1281167 (39%)]	Loss: 1.399379
[2022-03-29 20:40:25 | train] - Train Epoch: [42] [512000/1281167 (40%)]	Loss: 1.469623
[2022-03-29 20:40:48 | train] - Train Epoch: [42] [524800/1281167 (41%)]	Loss: 1.114229
[2022-03-29 20:41:09 | train] - Train Epoch: [42] [537600/1281167 (42%)]	Loss: 1.628021
[2022-03-29 20:41:31 | train] - Train Epoch: [42] [550400/1281167 (43%)]	Loss: 1.510731
[2022-03-29 20:41:53 | train] - Train Epoch: [42] [563200/1281167 (44%)]	Loss: 1.351950
[2022-03-29 20:42:15 | train] - Train Epoch: [42] [576000/1281167 (45%)]	Loss: 1.028651
[2022-03-29 20:42:36 | train] - Train Epoch: [42] [588800/1281167 (46%)]	Loss: 1.438497
[2022-03-29 20:42:58 | train] - Train Epoch: [42] [601600/1281167 (47%)]	Loss: 1.067508
[2022-03-29 20:43:19 | train] - Train Epoch: [42] [614400/1281167 (48%)]	Loss: 1.135621
[2022-03-29 20:43:40 | train] - Train Epoch: [42] [627200/1281167 (49%)]	Loss: 1.401799
[2022-03-29 20:44:01 | train] - Train Epoch: [42] [640000/1281167 (50%)]	Loss: 1.279616
[2022-03-29 20:44:22 | train] - Train Epoch: [42] [652800/1281167 (51%)]	Loss: 0.984151
[2022-03-29 20:44:43 | train] - Train Epoch: [42] [665600/1281167 (52%)]	Loss: 1.388398
[2022-03-29 20:45:05 | train] - Train Epoch: [42] [678400/1281167 (53%)]	Loss: 1.245296
[2022-03-29 20:45:26 | train] - Train Epoch: [42] [691200/1281167 (54%)]	Loss: 0.951884
[2022-03-29 20:45:47 | train] - Train Epoch: [42] [704000/1281167 (55%)]	Loss: 1.097121
[2022-03-29 20:46:09 | train] - Train Epoch: [42] [716800/1281167 (56%)]	Loss: 1.280933
[2022-03-29 20:46:30 | train] - Train Epoch: [42] [729600/1281167 (57%)]	Loss: 1.476255
[2022-03-29 20:46:51 | train] - Train Epoch: [42] [742400/1281167 (58%)]	Loss: 1.183567
[2022-03-29 20:47:13 | train] - Train Epoch: [42] [755200/1281167 (59%)]	Loss: 1.242982
[2022-03-29 20:47:35 | train] - Train Epoch: [42] [768000/1281167 (60%)]	Loss: 1.426877
[2022-03-29 20:47:57 | train] - Train Epoch: [42] [780800/1281167 (61%)]	Loss: 1.341426
[2022-03-29 20:48:19 | train] - Train Epoch: [42] [793600/1281167 (62%)]	Loss: 1.652576
[2022-03-29 20:48:40 | train] - Train Epoch: [42] [806400/1281167 (63%)]	Loss: 1.444274
[2022-03-29 20:49:03 | train] - Train Epoch: [42] [819200/1281167 (64%)]	Loss: 1.321777
[2022-03-29 20:49:26 | train] - Train Epoch: [42] [832000/1281167 (65%)]	Loss: 1.542410
[2022-03-29 20:49:47 | train] - Train Epoch: [42] [844800/1281167 (66%)]	Loss: 1.286009
[2022-03-29 20:50:09 | train] - Train Epoch: [42] [857600/1281167 (67%)]	Loss: 1.426759
[2022-03-29 20:50:30 | train] - Train Epoch: [42] [870400/1281167 (68%)]	Loss: 1.066518
[2022-03-29 20:50:53 | train] - Train Epoch: [42] [883200/1281167 (69%)]	Loss: 1.545852
[2022-03-29 20:51:15 | train] - Train Epoch: [42] [896000/1281167 (70%)]	Loss: 1.030423
[2022-03-29 20:51:36 | train] - Train Epoch: [42] [908800/1281167 (71%)]	Loss: 1.115017
[2022-03-29 20:51:59 | train] - Train Epoch: [42] [921600/1281167 (72%)]	Loss: 1.336706
[2022-03-29 20:52:20 | train] - Train Epoch: [42] [934400/1281167 (73%)]	Loss: 1.188749
[2022-03-29 20:52:41 | train] - Train Epoch: [42] [947200/1281167 (74%)]	Loss: 1.214494
[2022-03-29 20:53:02 | train] - Train Epoch: [42] [960000/1281167 (75%)]	Loss: 1.511762
[2022-03-29 20:53:24 | train] - Train Epoch: [42] [972800/1281167 (76%)]	Loss: 1.423148
[2022-03-29 20:53:45 | train] - Train Epoch: [42] [985600/1281167 (77%)]	Loss: 1.478768
[2022-03-29 20:54:06 | train] - Train Epoch: [42] [998400/1281167 (78%)]	Loss: 1.485703
[2022-03-29 20:54:27 | train] - Train Epoch: [42] [1011200/1281167 (79%)]	Loss: 1.636458
[2022-03-29 20:54:49 | train] - Train Epoch: [42] [1024000/1281167 (80%)]	Loss: 1.433687
[2022-03-29 20:55:10 | train] - Train Epoch: [42] [1036800/1281167 (81%)]	Loss: 1.322991
[2022-03-29 20:55:32 | train] - Train Epoch: [42] [1049600/1281167 (82%)]	Loss: 1.175310
[2022-03-29 20:55:53 | train] - Train Epoch: [42] [1062400/1281167 (83%)]	Loss: 1.225950
[2022-03-29 20:56:14 | train] - Train Epoch: [42] [1075200/1281167 (84%)]	Loss: 1.309380
[2022-03-29 20:56:36 | train] - Train Epoch: [42] [1088000/1281167 (85%)]	Loss: 1.214581
[2022-03-29 20:56:59 | train] - Train Epoch: [42] [1100800/1281167 (86%)]	Loss: 1.369372
[2022-03-29 20:57:21 | train] - Train Epoch: [42] [1113600/1281167 (87%)]	Loss: 1.554154
[2022-03-29 20:57:42 | train] - Train Epoch: [42] [1126400/1281167 (88%)]	Loss: 1.327894
[2022-03-29 20:58:04 | train] - Train Epoch: [42] [1139200/1281167 (89%)]	Loss: 1.307423
[2022-03-29 20:58:27 | train] - Train Epoch: [42] [1152000/1281167 (90%)]	Loss: 1.304174
[2022-03-29 20:58:48 | train] - Train Epoch: [42] [1164800/1281167 (91%)]	Loss: 1.167274
[2022-03-29 20:59:10 | train] - Train Epoch: [42] [1177600/1281167 (92%)]	Loss: 1.275438
[2022-03-29 20:59:31 | train] - Train Epoch: [42] [1190400/1281167 (93%)]	Loss: 1.301179
[2022-03-29 20:59:52 | train] - Train Epoch: [42] [1203200/1281167 (94%)]	Loss: 1.427771
[2022-03-29 21:00:14 | train] - Train Epoch: [42] [1216000/1281167 (95%)]	Loss: 1.071452
[2022-03-29 21:00:35 | train] - Train Epoch: [42] [1228800/1281167 (96%)]	Loss: 1.120286
[2022-03-29 21:00:57 | train] - Train Epoch: [42] [1241600/1281167 (97%)]	Loss: 1.229494
[2022-03-29 21:01:18 | train] - Train Epoch: [42] [1254400/1281167 (98%)]	Loss: 1.210232
[2022-03-29 21:01:40 | train] - Train Epoch: [42] [1267200/1281167 (99%)]	Loss: 1.189160
[2022-03-29 21:02:02 | train] - Train Epoch: [42] [1280000/1281167 (100%)]	Loss: 1.062845
[2022-03-29 21:02:05 | train] - Train Epoch: [42]	 Average Loss: 1.314559	 Total Acc : 68.5597	 Total Top5 Acc : 87.0683
[2022-03-29 21:02:07 | train] - -------42 epoch end-----------
========================================
-------42 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 21:03:51 | train] - 
Epoch [42] Test set: Average loss: 1.3625, Accuracy: 33801/50000 (67.5695%), Top-5 Accuracy: 87.8501%

[2022-03-29 21:03:51 | train] - save intermediate epoch [42] result


[2022-03-29 21:04:01 | train] - logging best performance 42 epoch
[2022-03-29 21:04:02 | train] - -------43 epoch start-----------
========================================
----- test end -------------------------


logging best performance 42 epoch
[2022-03-29 21:04:04 | train] - Train Epoch: [43] [0/1281167 (0%)]	Loss: 1.295510
[2022-03-29 21:04:29 | train] - Train Epoch: [43] [12800/1281167 (1%)]	Loss: 1.314314
[2022-03-29 21:04:51 | train] - Train Epoch: [43] [25600/1281167 (2%)]	Loss: 1.089412
[2022-03-29 21:05:13 | train] - Train Epoch: [43] [38400/1281167 (3%)]	Loss: 1.353711
[2022-03-29 21:05:36 | train] - Train Epoch: [43] [51200/1281167 (4%)]	Loss: 1.054602
[2022-03-29 21:05:59 | train] - Train Epoch: [43] [64000/1281167 (5%)]	Loss: 1.261855
[2022-03-29 21:06:21 | train] - Train Epoch: [43] [76800/1281167 (6%)]	Loss: 1.386409
[2022-03-29 21:06:44 | train] - Train Epoch: [43] [89600/1281167 (7%)]	Loss: 1.071536
[2022-03-29 21:07:06 | train] - Train Epoch: [43] [102400/1281167 (8%)]	Loss: 1.226307
[2022-03-29 21:07:29 | train] - Train Epoch: [43] [115200/1281167 (9%)]	Loss: 0.800594
[2022-03-29 21:07:51 | train] - Train Epoch: [43] [128000/1281167 (10%)]	Loss: 1.139540
[2022-03-29 21:08:14 | train] - Train Epoch: [43] [140800/1281167 (11%)]	Loss: 1.249064
[2022-03-29 21:08:37 | train] - Train Epoch: [43] [153600/1281167 (12%)]	Loss: 1.303495
[2022-03-29 21:08:59 | train] - Train Epoch: [43] [166400/1281167 (13%)]	Loss: 1.298005
[2022-03-29 21:09:22 | train] - Train Epoch: [43] [179200/1281167 (14%)]	Loss: 1.281727
[2022-03-29 21:09:44 | train] - Train Epoch: [43] [192000/1281167 (15%)]	Loss: 1.235250
[2022-03-29 21:10:06 | train] - Train Epoch: [43] [204800/1281167 (16%)]	Loss: 1.551046
[2022-03-29 21:10:28 | train] - Train Epoch: [43] [217600/1281167 (17%)]	Loss: 1.545768
[2022-03-29 21:10:50 | train] - Train Epoch: [43] [230400/1281167 (18%)]	Loss: 1.213822
[2022-03-29 21:11:11 | train] - Train Epoch: [43] [243200/1281167 (19%)]	Loss: 1.344350
[2022-03-29 21:11:32 | train] - Train Epoch: [43] [256000/1281167 (20%)]	Loss: 1.511256
[2022-03-29 21:11:54 | train] - Train Epoch: [43] [268800/1281167 (21%)]	Loss: 1.297403
[2022-03-29 21:12:14 | train] - Train Epoch: [43] [281600/1281167 (22%)]	Loss: 1.144755
[2022-03-29 21:12:36 | train] - Train Epoch: [43] [294400/1281167 (23%)]	Loss: 1.129917
[2022-03-29 21:12:57 | train] - Train Epoch: [43] [307200/1281167 (24%)]	Loss: 1.263940
[2022-03-29 21:13:18 | train] - Train Epoch: [43] [320000/1281167 (25%)]	Loss: 1.095722
[2022-03-29 21:13:40 | train] - Train Epoch: [43] [332800/1281167 (26%)]	Loss: 1.445540
[2022-03-29 21:14:01 | train] - Train Epoch: [43] [345600/1281167 (27%)]	Loss: 1.229955
[2022-03-29 21:14:22 | train] - Train Epoch: [43] [358400/1281167 (28%)]	Loss: 1.273966
[2022-03-29 21:14:44 | train] - Train Epoch: [43] [371200/1281167 (29%)]	Loss: 1.200132
[2022-03-29 21:15:05 | train] - Train Epoch: [43] [384000/1281167 (30%)]	Loss: 1.269006
[2022-03-29 21:15:26 | train] - Train Epoch: [43] [396800/1281167 (31%)]	Loss: 1.383989
[2022-03-29 21:15:49 | train] - Train Epoch: [43] [409600/1281167 (32%)]	Loss: 1.038968
[2022-03-29 21:16:10 | train] - Train Epoch: [43] [422400/1281167 (33%)]	Loss: 1.349399
[2022-03-29 21:16:32 | train] - Train Epoch: [43] [435200/1281167 (34%)]	Loss: 1.319937
[2022-03-29 21:16:54 | train] - Train Epoch: [43] [448000/1281167 (35%)]	Loss: 1.206163
[2022-03-29 21:17:14 | train] - Train Epoch: [43] [460800/1281167 (36%)]	Loss: 1.590286
[2022-03-29 21:17:34 | train] - Train Epoch: [43] [473600/1281167 (37%)]	Loss: 1.066681
[2022-03-29 21:17:55 | train] - Train Epoch: [43] [486400/1281167 (38%)]	Loss: 1.428016
[2022-03-29 21:18:16 | train] - Train Epoch: [43] [499200/1281167 (39%)]	Loss: 1.375780
[2022-03-29 21:18:36 | train] - Train Epoch: [43] [512000/1281167 (40%)]	Loss: 1.062266
[2022-03-29 21:18:57 | train] - Train Epoch: [43] [524800/1281167 (41%)]	Loss: 1.237679
[2022-03-29 21:19:18 | train] - Train Epoch: [43] [537600/1281167 (42%)]	Loss: 1.420764
[2022-03-29 21:19:39 | train] - Train Epoch: [43] [550400/1281167 (43%)]	Loss: 1.001949
[2022-03-29 21:20:00 | train] - Train Epoch: [43] [563200/1281167 (44%)]	Loss: 1.228360
[2022-03-29 21:20:21 | train] - Train Epoch: [43] [576000/1281167 (45%)]	Loss: 1.168016
[2022-03-29 21:20:41 | train] - Train Epoch: [43] [588800/1281167 (46%)]	Loss: 1.276765
[2022-03-29 21:21:03 | train] - Train Epoch: [43] [601600/1281167 (47%)]	Loss: 1.037423
[2022-03-29 21:21:23 | train] - Train Epoch: [43] [614400/1281167 (48%)]	Loss: 1.447939
[2022-03-29 21:21:44 | train] - Train Epoch: [43] [627200/1281167 (49%)]	Loss: 1.294851
[2022-03-29 21:22:05 | train] - Train Epoch: [43] [640000/1281167 (50%)]	Loss: 1.455634
[2022-03-29 21:22:26 | train] - Train Epoch: [43] [652800/1281167 (51%)]	Loss: 1.183454
[2022-03-29 21:22:46 | train] - Train Epoch: [43] [665600/1281167 (52%)]	Loss: 1.197253
[2022-03-29 21:23:08 | train] - Train Epoch: [43] [678400/1281167 (53%)]	Loss: 1.690040
[2022-03-29 21:23:29 | train] - Train Epoch: [43] [691200/1281167 (54%)]	Loss: 1.409422
[2022-03-29 21:23:51 | train] - Train Epoch: [43] [704000/1281167 (55%)]	Loss: 1.271917
[2022-03-29 21:24:11 | train] - Train Epoch: [43] [716800/1281167 (56%)]	Loss: 0.992470
[2022-03-29 21:24:32 | train] - Train Epoch: [43] [729600/1281167 (57%)]	Loss: 1.245049
[2022-03-29 21:24:54 | train] - Train Epoch: [43] [742400/1281167 (58%)]	Loss: 1.385847
[2022-03-29 21:25:15 | train] - Train Epoch: [43] [755200/1281167 (59%)]	Loss: 1.450277
[2022-03-29 21:25:36 | train] - Train Epoch: [43] [768000/1281167 (60%)]	Loss: 1.309076
[2022-03-29 21:25:57 | train] - Train Epoch: [43] [780800/1281167 (61%)]	Loss: 1.263439
[2022-03-29 21:26:19 | train] - Train Epoch: [43] [793600/1281167 (62%)]	Loss: 1.130076
[2022-03-29 21:26:39 | train] - Train Epoch: [43] [806400/1281167 (63%)]	Loss: 1.386015
[2022-03-29 21:27:00 | train] - Train Epoch: [43] [819200/1281167 (64%)]	Loss: 1.150905
[2022-03-29 21:27:21 | train] - Train Epoch: [43] [832000/1281167 (65%)]	Loss: 1.239109
[2022-03-29 21:27:42 | train] - Train Epoch: [43] [844800/1281167 (66%)]	Loss: 1.262251
[2022-03-29 21:28:03 | train] - Train Epoch: [43] [857600/1281167 (67%)]	Loss: 1.141880
[2022-03-29 21:28:25 | train] - Train Epoch: [43] [870400/1281167 (68%)]	Loss: 1.440608
[2022-03-29 21:28:46 | train] - Train Epoch: [43] [883200/1281167 (69%)]	Loss: 1.505934
[2022-03-29 21:29:08 | train] - Train Epoch: [43] [896000/1281167 (70%)]	Loss: 1.343010
[2022-03-29 21:29:30 | train] - Train Epoch: [43] [908800/1281167 (71%)]	Loss: 1.552735
[2022-03-29 21:29:52 | train] - Train Epoch: [43] [921600/1281167 (72%)]	Loss: 1.382659
[2022-03-29 21:30:15 | train] - Train Epoch: [43] [934400/1281167 (73%)]	Loss: 1.432534
[2022-03-29 21:30:35 | train] - Train Epoch: [43] [947200/1281167 (74%)]	Loss: 1.357473
[2022-03-29 21:30:58 | train] - Train Epoch: [43] [960000/1281167 (75%)]	Loss: 1.609744
[2022-03-29 21:31:18 | train] - Train Epoch: [43] [972800/1281167 (76%)]	Loss: 1.270025
[2022-03-29 21:31:40 | train] - Train Epoch: [43] [985600/1281167 (77%)]	Loss: 1.144701
[2022-03-29 21:32:01 | train] - Train Epoch: [43] [998400/1281167 (78%)]	Loss: 1.345757
[2022-03-29 21:32:23 | train] - Train Epoch: [43] [1011200/1281167 (79%)]	Loss: 1.280214
[2022-03-29 21:32:45 | train] - Train Epoch: [43] [1024000/1281167 (80%)]	Loss: 1.132531
[2022-03-29 21:33:06 | train] - Train Epoch: [43] [1036800/1281167 (81%)]	Loss: 1.189403
[2022-03-29 21:33:28 | train] - Train Epoch: [43] [1049600/1281167 (82%)]	Loss: 1.614776
[2022-03-29 21:33:51 | train] - Train Epoch: [43] [1062400/1281167 (83%)]	Loss: 1.118855
[2022-03-29 21:34:14 | train] - Train Epoch: [43] [1075200/1281167 (84%)]	Loss: 1.149347
[2022-03-29 21:34:36 | train] - Train Epoch: [43] [1088000/1281167 (85%)]	Loss: 1.682576
[2022-03-29 21:34:57 | train] - Train Epoch: [43] [1100800/1281167 (86%)]	Loss: 1.361097
[2022-03-29 21:35:17 | train] - Train Epoch: [43] [1113600/1281167 (87%)]	Loss: 1.247764
[2022-03-29 21:35:39 | train] - Train Epoch: [43] [1126400/1281167 (88%)]	Loss: 1.512113
[2022-03-29 21:35:59 | train] - Train Epoch: [43] [1139200/1281167 (89%)]	Loss: 1.540510
[2022-03-29 21:36:20 | train] - Train Epoch: [43] [1152000/1281167 (90%)]	Loss: 1.346591
[2022-03-29 21:36:40 | train] - Train Epoch: [43] [1164800/1281167 (91%)]	Loss: 1.384110
[2022-03-29 21:37:01 | train] - Train Epoch: [43] [1177600/1281167 (92%)]	Loss: 1.458272
[2022-03-29 21:37:22 | train] - Train Epoch: [43] [1190400/1281167 (93%)]	Loss: 1.324045
[2022-03-29 21:37:43 | train] - Train Epoch: [43] [1203200/1281167 (94%)]	Loss: 1.052051
[2022-03-29 21:38:04 | train] - Train Epoch: [43] [1216000/1281167 (95%)]	Loss: 1.293261
[2022-03-29 21:38:26 | train] - Train Epoch: [43] [1228800/1281167 (96%)]	Loss: 1.602894
[2022-03-29 21:38:48 | train] - Train Epoch: [43] [1241600/1281167 (97%)]	Loss: 1.348217
[2022-03-29 21:39:09 | train] - Train Epoch: [43] [1254400/1281167 (98%)]	Loss: 1.412256
[2022-03-29 21:39:29 | train] - Train Epoch: [43] [1267200/1281167 (99%)]	Loss: 1.449864
[2022-03-29 21:39:50 | train] - Train Epoch: [43] [1280000/1281167 (100%)]	Loss: 1.110497
[2022-03-29 21:39:53 | train] - Train Epoch: [43]	 Average Loss: 1.303241	 Total Acc : 68.7849	 Total Top5 Acc : 87.2141
[2022-03-29 21:39:55 | train] - -------43 epoch end-----------
========================================
-------43 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 21:41:40 | train] - 
Epoch [43] Test set: Average loss: 1.3741, Accuracy: 33768/50000 (67.5084%), Top-5 Accuracy: 87.8321%

[2022-03-29 21:41:40 | train] - save intermediate epoch [43] result


[2022-03-29 21:41:52 | train] - -------44 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 21:41:54 | train] - Train Epoch: [44] [0/1281167 (0%)]	Loss: 1.205321
[2022-03-29 21:42:16 | train] - Train Epoch: [44] [12800/1281167 (1%)]	Loss: 1.114105
[2022-03-29 21:42:37 | train] - Train Epoch: [44] [25600/1281167 (2%)]	Loss: 1.215164
[2022-03-29 21:43:00 | train] - Train Epoch: [44] [38400/1281167 (3%)]	Loss: 1.166888
[2022-03-29 21:43:23 | train] - Train Epoch: [44] [51200/1281167 (4%)]	Loss: 1.198848
[2022-03-29 21:43:45 | train] - Train Epoch: [44] [64000/1281167 (5%)]	Loss: 1.170736
[2022-03-29 21:44:08 | train] - Train Epoch: [44] [76800/1281167 (6%)]	Loss: 1.286826
[2022-03-29 21:44:30 | train] - Train Epoch: [44] [89600/1281167 (7%)]	Loss: 1.332651
[2022-03-29 21:44:52 | train] - Train Epoch: [44] [102400/1281167 (8%)]	Loss: 0.946778
[2022-03-29 21:45:14 | train] - Train Epoch: [44] [115200/1281167 (9%)]	Loss: 1.586193
[2022-03-29 21:45:36 | train] - Train Epoch: [44] [128000/1281167 (10%)]	Loss: 1.280463
[2022-03-29 21:45:58 | train] - Train Epoch: [44] [140800/1281167 (11%)]	Loss: 1.045526
[2022-03-29 21:46:20 | train] - Train Epoch: [44] [153600/1281167 (12%)]	Loss: 1.273070
[2022-03-29 21:46:42 | train] - Train Epoch: [44] [166400/1281167 (13%)]	Loss: 1.157631
[2022-03-29 21:47:04 | train] - Train Epoch: [44] [179200/1281167 (14%)]	Loss: 1.094361
[2022-03-29 21:47:25 | train] - Train Epoch: [44] [192000/1281167 (15%)]	Loss: 1.254120
[2022-03-29 21:47:47 | train] - Train Epoch: [44] [204800/1281167 (16%)]	Loss: 1.235443
[2022-03-29 21:48:08 | train] - Train Epoch: [44] [217600/1281167 (17%)]	Loss: 1.311971
[2022-03-29 21:48:30 | train] - Train Epoch: [44] [230400/1281167 (18%)]	Loss: 1.159773
[2022-03-29 21:48:51 | train] - Train Epoch: [44] [243200/1281167 (19%)]	Loss: 1.262095
[2022-03-29 21:49:12 | train] - Train Epoch: [44] [256000/1281167 (20%)]	Loss: 1.222626
[2022-03-29 21:49:33 | train] - Train Epoch: [44] [268800/1281167 (21%)]	Loss: 0.932018
[2022-03-29 21:49:54 | train] - Train Epoch: [44] [281600/1281167 (22%)]	Loss: 1.801658
[2022-03-29 21:50:15 | train] - Train Epoch: [44] [294400/1281167 (23%)]	Loss: 1.352033
[2022-03-29 21:50:36 | train] - Train Epoch: [44] [307200/1281167 (24%)]	Loss: 1.561216
[2022-03-29 21:50:57 | train] - Train Epoch: [44] [320000/1281167 (25%)]	Loss: 1.417780
[2022-03-29 21:51:18 | train] - Train Epoch: [44] [332800/1281167 (26%)]	Loss: 1.858518
[2022-03-29 21:51:40 | train] - Train Epoch: [44] [345600/1281167 (27%)]	Loss: 1.098706
[2022-03-29 21:52:02 | train] - Train Epoch: [44] [358400/1281167 (28%)]	Loss: 1.414888
[2022-03-29 21:52:24 | train] - Train Epoch: [44] [371200/1281167 (29%)]	Loss: 1.323856
[2022-03-29 21:52:45 | train] - Train Epoch: [44] [384000/1281167 (30%)]	Loss: 1.073953
[2022-03-29 21:53:07 | train] - Train Epoch: [44] [396800/1281167 (31%)]	Loss: 1.214637
[2022-03-29 21:53:28 | train] - Train Epoch: [44] [409600/1281167 (32%)]	Loss: 1.556045
[2022-03-29 21:53:50 | train] - Train Epoch: [44] [422400/1281167 (33%)]	Loss: 1.097794
[2022-03-29 21:54:11 | train] - Train Epoch: [44] [435200/1281167 (34%)]	Loss: 0.934308
[2022-03-29 21:54:33 | train] - Train Epoch: [44] [448000/1281167 (35%)]	Loss: 1.276358
[2022-03-29 21:54:55 | train] - Train Epoch: [44] [460800/1281167 (36%)]	Loss: 1.293105
[2022-03-29 21:55:16 | train] - Train Epoch: [44] [473600/1281167 (37%)]	Loss: 1.053937
[2022-03-29 21:55:38 | train] - Train Epoch: [44] [486400/1281167 (38%)]	Loss: 1.525596
[2022-03-29 21:55:59 | train] - Train Epoch: [44] [499200/1281167 (39%)]	Loss: 1.372064
[2022-03-29 21:56:20 | train] - Train Epoch: [44] [512000/1281167 (40%)]	Loss: 1.162676
[2022-03-29 21:56:42 | train] - Train Epoch: [44] [524800/1281167 (41%)]	Loss: 1.130945
[2022-03-29 21:57:04 | train] - Train Epoch: [44] [537600/1281167 (42%)]	Loss: 1.470390
[2022-03-29 21:57:25 | train] - Train Epoch: [44] [550400/1281167 (43%)]	Loss: 1.315227
[2022-03-29 21:57:47 | train] - Train Epoch: [44] [563200/1281167 (44%)]	Loss: 1.793407
[2022-03-29 21:58:08 | train] - Train Epoch: [44] [576000/1281167 (45%)]	Loss: 1.417036
[2022-03-29 21:58:29 | train] - Train Epoch: [44] [588800/1281167 (46%)]	Loss: 1.205521
[2022-03-29 21:58:51 | train] - Train Epoch: [44] [601600/1281167 (47%)]	Loss: 1.372258
[2022-03-29 21:59:12 | train] - Train Epoch: [44] [614400/1281167 (48%)]	Loss: 1.397458
[2022-03-29 21:59:34 | train] - Train Epoch: [44] [627200/1281167 (49%)]	Loss: 1.273237
[2022-03-29 21:59:55 | train] - Train Epoch: [44] [640000/1281167 (50%)]	Loss: 1.295599
[2022-03-29 22:00:16 | train] - Train Epoch: [44] [652800/1281167 (51%)]	Loss: 1.546382
[2022-03-29 22:00:37 | train] - Train Epoch: [44] [665600/1281167 (52%)]	Loss: 1.294820
[2022-03-29 22:00:59 | train] - Train Epoch: [44] [678400/1281167 (53%)]	Loss: 1.312445
[2022-03-29 22:01:21 | train] - Train Epoch: [44] [691200/1281167 (54%)]	Loss: 1.394367
[2022-03-29 22:01:42 | train] - Train Epoch: [44] [704000/1281167 (55%)]	Loss: 1.151013
[2022-03-29 22:02:03 | train] - Train Epoch: [44] [716800/1281167 (56%)]	Loss: 1.298492
[2022-03-29 22:02:23 | train] - Train Epoch: [44] [729600/1281167 (57%)]	Loss: 1.134908
[2022-03-29 22:02:44 | train] - Train Epoch: [44] [742400/1281167 (58%)]	Loss: 1.566666
[2022-03-29 22:03:06 | train] - Train Epoch: [44] [755200/1281167 (59%)]	Loss: 1.665476
[2022-03-29 22:03:27 | train] - Train Epoch: [44] [768000/1281167 (60%)]	Loss: 1.179225
[2022-03-29 22:03:49 | train] - Train Epoch: [44] [780800/1281167 (61%)]	Loss: 1.339949
[2022-03-29 22:04:11 | train] - Train Epoch: [44] [793600/1281167 (62%)]	Loss: 1.564595
[2022-03-29 22:04:33 | train] - Train Epoch: [44] [806400/1281167 (63%)]	Loss: 1.587647
[2022-03-29 22:04:55 | train] - Train Epoch: [44] [819200/1281167 (64%)]	Loss: 1.326266
[2022-03-29 22:05:16 | train] - Train Epoch: [44] [832000/1281167 (65%)]	Loss: 1.101490
[2022-03-29 22:05:38 | train] - Train Epoch: [44] [844800/1281167 (66%)]	Loss: 1.477661
[2022-03-29 22:06:00 | train] - Train Epoch: [44] [857600/1281167 (67%)]	Loss: 1.312468
[2022-03-29 22:06:22 | train] - Train Epoch: [44] [870400/1281167 (68%)]	Loss: 1.154880
[2022-03-29 22:06:43 | train] - Train Epoch: [44] [883200/1281167 (69%)]	Loss: 1.215417
[2022-03-29 22:07:05 | train] - Train Epoch: [44] [896000/1281167 (70%)]	Loss: 1.349874
[2022-03-29 22:07:27 | train] - Train Epoch: [44] [908800/1281167 (71%)]	Loss: 1.349643
[2022-03-29 22:07:49 | train] - Train Epoch: [44] [921600/1281167 (72%)]	Loss: 1.280617
[2022-03-29 22:08:11 | train] - Train Epoch: [44] [934400/1281167 (73%)]	Loss: 1.123048
[2022-03-29 22:08:33 | train] - Train Epoch: [44] [947200/1281167 (74%)]	Loss: 0.980845
[2022-03-29 22:08:55 | train] - Train Epoch: [44] [960000/1281167 (75%)]	Loss: 1.178575
[2022-03-29 22:09:16 | train] - Train Epoch: [44] [972800/1281167 (76%)]	Loss: 1.292455
[2022-03-29 22:09:38 | train] - Train Epoch: [44] [985600/1281167 (77%)]	Loss: 1.485152
[2022-03-29 22:09:59 | train] - Train Epoch: [44] [998400/1281167 (78%)]	Loss: 1.204073
[2022-03-29 22:10:20 | train] - Train Epoch: [44] [1011200/1281167 (79%)]	Loss: 1.297302
[2022-03-29 22:10:42 | train] - Train Epoch: [44] [1024000/1281167 (80%)]	Loss: 1.234385
[2022-03-29 22:11:02 | train] - Train Epoch: [44] [1036800/1281167 (81%)]	Loss: 0.975377
[2022-03-29 22:11:23 | train] - Train Epoch: [44] [1049600/1281167 (82%)]	Loss: 1.561521
[2022-03-29 22:11:46 | train] - Train Epoch: [44] [1062400/1281167 (83%)]	Loss: 1.272712
[2022-03-29 22:12:08 | train] - Train Epoch: [44] [1075200/1281167 (84%)]	Loss: 1.487460
[2022-03-29 22:12:30 | train] - Train Epoch: [44] [1088000/1281167 (85%)]	Loss: 1.267772
[2022-03-29 22:12:51 | train] - Train Epoch: [44] [1100800/1281167 (86%)]	Loss: 1.386100
[2022-03-29 22:13:12 | train] - Train Epoch: [44] [1113600/1281167 (87%)]	Loss: 1.411820
[2022-03-29 22:13:33 | train] - Train Epoch: [44] [1126400/1281167 (88%)]	Loss: 1.424668
[2022-03-29 22:13:54 | train] - Train Epoch: [44] [1139200/1281167 (89%)]	Loss: 1.427404
[2022-03-29 22:14:15 | train] - Train Epoch: [44] [1152000/1281167 (90%)]	Loss: 1.306615
[2022-03-29 22:14:36 | train] - Train Epoch: [44] [1164800/1281167 (91%)]	Loss: 1.543077
[2022-03-29 22:14:58 | train] - Train Epoch: [44] [1177600/1281167 (92%)]	Loss: 1.017162
[2022-03-29 22:15:19 | train] - Train Epoch: [44] [1190400/1281167 (93%)]	Loss: 1.334100
[2022-03-29 22:15:40 | train] - Train Epoch: [44] [1203200/1281167 (94%)]	Loss: 1.066991
[2022-03-29 22:16:03 | train] - Train Epoch: [44] [1216000/1281167 (95%)]	Loss: 1.308029
[2022-03-29 22:16:23 | train] - Train Epoch: [44] [1228800/1281167 (96%)]	Loss: 1.174495
[2022-03-29 22:16:43 | train] - Train Epoch: [44] [1241600/1281167 (97%)]	Loss: 1.562844
[2022-03-29 22:17:05 | train] - Train Epoch: [44] [1254400/1281167 (98%)]	Loss: 1.404651
[2022-03-29 22:17:26 | train] - Train Epoch: [44] [1267200/1281167 (99%)]	Loss: 1.292342
[2022-03-29 22:17:48 | train] - Train Epoch: [44] [1280000/1281167 (100%)]	Loss: 1.170889
[2022-03-29 22:17:51 | train] - Train Epoch: [44]	 Average Loss: 1.292534	 Total Acc : 69.0388	 Total Top5 Acc : 87.3881
[2022-03-29 22:17:53 | train] - -------44 epoch end-----------
========================================
-------44 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 22:19:35 | train] - 
Epoch [44] Test set: Average loss: 1.3713, Accuracy: 33866/50000 (67.7006%), Top-5 Accuracy: 87.8700%

[2022-03-29 22:19:35 | train] - save intermediate epoch [44] result


[2022-03-29 22:19:46 | train] - logging best performance 44 epoch
[2022-03-29 22:19:48 | train] - -------45 epoch start-----------
========================================
----- test end -------------------------


logging best performance 44 epoch
[2022-03-29 22:19:50 | train] - Train Epoch: [45] [0/1281167 (0%)]	Loss: 0.984805
[2022-03-29 22:20:13 | train] - Train Epoch: [45] [12800/1281167 (1%)]	Loss: 1.392807
[2022-03-29 22:20:36 | train] - Train Epoch: [45] [25600/1281167 (2%)]	Loss: 1.332803
[2022-03-29 22:20:58 | train] - Train Epoch: [45] [38400/1281167 (3%)]	Loss: 1.295572
[2022-03-29 22:21:21 | train] - Train Epoch: [45] [51200/1281167 (4%)]	Loss: 1.367655
[2022-03-29 22:21:44 | train] - Train Epoch: [45] [64000/1281167 (5%)]	Loss: 0.933297
[2022-03-29 22:22:06 | train] - Train Epoch: [45] [76800/1281167 (6%)]	Loss: 1.092676
[2022-03-29 22:22:29 | train] - Train Epoch: [45] [89600/1281167 (7%)]	Loss: 1.139425
[2022-03-29 22:22:52 | train] - Train Epoch: [45] [102400/1281167 (8%)]	Loss: 1.149536
[2022-03-29 22:23:15 | train] - Train Epoch: [45] [115200/1281167 (9%)]	Loss: 1.354159
[2022-03-29 22:23:37 | train] - Train Epoch: [45] [128000/1281167 (10%)]	Loss: 0.939236
[2022-03-29 22:24:00 | train] - Train Epoch: [45] [140800/1281167 (11%)]	Loss: 1.225026
[2022-03-29 22:24:21 | train] - Train Epoch: [45] [153600/1281167 (12%)]	Loss: 1.181944
[2022-03-29 22:24:44 | train] - Train Epoch: [45] [166400/1281167 (13%)]	Loss: 1.513712
[2022-03-29 22:25:08 | train] - Train Epoch: [45] [179200/1281167 (14%)]	Loss: 1.123191
[2022-03-29 22:25:29 | train] - Train Epoch: [45] [192000/1281167 (15%)]	Loss: 1.339511
[2022-03-29 22:25:52 | train] - Train Epoch: [45] [204800/1281167 (16%)]	Loss: 1.242230
[2022-03-29 22:26:13 | train] - Train Epoch: [45] [217600/1281167 (17%)]	Loss: 1.404614
[2022-03-29 22:26:34 | train] - Train Epoch: [45] [230400/1281167 (18%)]	Loss: 1.151389
[2022-03-29 22:26:55 | train] - Train Epoch: [45] [243200/1281167 (19%)]	Loss: 1.730800
[2022-03-29 22:27:18 | train] - Train Epoch: [45] [256000/1281167 (20%)]	Loss: 1.015509
[2022-03-29 22:27:40 | train] - Train Epoch: [45] [268800/1281167 (21%)]	Loss: 1.284801
[2022-03-29 22:28:03 | train] - Train Epoch: [45] [281600/1281167 (22%)]	Loss: 1.321255
[2022-03-29 22:28:25 | train] - Train Epoch: [45] [294400/1281167 (23%)]	Loss: 1.233744
[2022-03-29 22:28:46 | train] - Train Epoch: [45] [307200/1281167 (24%)]	Loss: 1.143936
[2022-03-29 22:29:08 | train] - Train Epoch: [45] [320000/1281167 (25%)]	Loss: 1.508775
[2022-03-29 22:29:29 | train] - Train Epoch: [45] [332800/1281167 (26%)]	Loss: 1.057775
[2022-03-29 22:29:50 | train] - Train Epoch: [45] [345600/1281167 (27%)]	Loss: 1.072922
[2022-03-29 22:30:11 | train] - Train Epoch: [45] [358400/1281167 (28%)]	Loss: 1.239388
[2022-03-29 22:30:32 | train] - Train Epoch: [45] [371200/1281167 (29%)]	Loss: 1.223350
[2022-03-29 22:30:53 | train] - Train Epoch: [45] [384000/1281167 (30%)]	Loss: 1.131207
[2022-03-29 22:31:14 | train] - Train Epoch: [45] [396800/1281167 (31%)]	Loss: 1.130177
[2022-03-29 22:31:35 | train] - Train Epoch: [45] [409600/1281167 (32%)]	Loss: 1.300608
[2022-03-29 22:31:56 | train] - Train Epoch: [45] [422400/1281167 (33%)]	Loss: 1.155235
[2022-03-29 22:32:17 | train] - Train Epoch: [45] [435200/1281167 (34%)]	Loss: 1.226603
[2022-03-29 22:32:37 | train] - Train Epoch: [45] [448000/1281167 (35%)]	Loss: 1.347794
[2022-03-29 22:32:57 | train] - Train Epoch: [45] [460800/1281167 (36%)]	Loss: 1.228828
[2022-03-29 22:33:18 | train] - Train Epoch: [45] [473600/1281167 (37%)]	Loss: 1.435538
[2022-03-29 22:33:39 | train] - Train Epoch: [45] [486400/1281167 (38%)]	Loss: 0.903011
[2022-03-29 22:34:00 | train] - Train Epoch: [45] [499200/1281167 (39%)]	Loss: 1.380730
[2022-03-29 22:34:20 | train] - Train Epoch: [45] [512000/1281167 (40%)]	Loss: 1.202737
[2022-03-29 22:34:41 | train] - Train Epoch: [45] [524800/1281167 (41%)]	Loss: 1.299382
[2022-03-29 22:35:02 | train] - Train Epoch: [45] [537600/1281167 (42%)]	Loss: 0.944294
[2022-03-29 22:35:23 | train] - Train Epoch: [45] [550400/1281167 (43%)]	Loss: 1.286041
[2022-03-29 22:35:44 | train] - Train Epoch: [45] [563200/1281167 (44%)]	Loss: 1.276361
[2022-03-29 22:36:05 | train] - Train Epoch: [45] [576000/1281167 (45%)]	Loss: 1.166318
[2022-03-29 22:36:24 | train] - Train Epoch: [45] [588800/1281167 (46%)]	Loss: 1.229437
[2022-03-29 22:36:44 | train] - Train Epoch: [45] [601600/1281167 (47%)]	Loss: 1.326130
[2022-03-29 22:37:07 | train] - Train Epoch: [45] [614400/1281167 (48%)]	Loss: 1.367858
[2022-03-29 22:37:26 | train] - Train Epoch: [45] [627200/1281167 (49%)]	Loss: 1.257877
[2022-03-29 22:37:48 | train] - Train Epoch: [45] [640000/1281167 (50%)]	Loss: 1.192457
[2022-03-29 22:38:08 | train] - Train Epoch: [45] [652800/1281167 (51%)]	Loss: 1.556558
[2022-03-29 22:38:29 | train] - Train Epoch: [45] [665600/1281167 (52%)]	Loss: 1.122711
[2022-03-29 22:38:50 | train] - Train Epoch: [45] [678400/1281167 (53%)]	Loss: 1.335589
[2022-03-29 22:39:11 | train] - Train Epoch: [45] [691200/1281167 (54%)]	Loss: 1.539557
[2022-03-29 22:39:33 | train] - Train Epoch: [45] [704000/1281167 (55%)]	Loss: 1.225445
[2022-03-29 22:39:54 | train] - Train Epoch: [45] [716800/1281167 (56%)]	Loss: 1.298040
[2022-03-29 22:40:15 | train] - Train Epoch: [45] [729600/1281167 (57%)]	Loss: 1.559855
[2022-03-29 22:40:36 | train] - Train Epoch: [45] [742400/1281167 (58%)]	Loss: 1.247311
[2022-03-29 22:40:58 | train] - Train Epoch: [45] [755200/1281167 (59%)]	Loss: 1.522512
[2022-03-29 22:41:19 | train] - Train Epoch: [45] [768000/1281167 (60%)]	Loss: 0.960274
[2022-03-29 22:41:40 | train] - Train Epoch: [45] [780800/1281167 (61%)]	Loss: 1.169950
[2022-03-29 22:42:01 | train] - Train Epoch: [45] [793600/1281167 (62%)]	Loss: 1.267428
[2022-03-29 22:42:22 | train] - Train Epoch: [45] [806400/1281167 (63%)]	Loss: 1.533229
[2022-03-29 22:42:43 | train] - Train Epoch: [45] [819200/1281167 (64%)]	Loss: 1.503830
[2022-03-29 22:43:04 | train] - Train Epoch: [45] [832000/1281167 (65%)]	Loss: 1.218699
[2022-03-29 22:43:25 | train] - Train Epoch: [45] [844800/1281167 (66%)]	Loss: 1.490878
[2022-03-29 22:43:46 | train] - Train Epoch: [45] [857600/1281167 (67%)]	Loss: 1.309781
[2022-03-29 22:44:06 | train] - Train Epoch: [45] [870400/1281167 (68%)]	Loss: 1.239093
[2022-03-29 22:44:27 | train] - Train Epoch: [45] [883200/1281167 (69%)]	Loss: 1.493187
[2022-03-29 22:44:49 | train] - Train Epoch: [45] [896000/1281167 (70%)]	Loss: 1.292425
[2022-03-29 22:45:10 | train] - Train Epoch: [45] [908800/1281167 (71%)]	Loss: 1.166540
[2022-03-29 22:45:31 | train] - Train Epoch: [45] [921600/1281167 (72%)]	Loss: 1.183181
[2022-03-29 22:45:52 | train] - Train Epoch: [45] [934400/1281167 (73%)]	Loss: 1.138239
[2022-03-29 22:46:13 | train] - Train Epoch: [45] [947200/1281167 (74%)]	Loss: 1.325367
[2022-03-29 22:46:35 | train] - Train Epoch: [45] [960000/1281167 (75%)]	Loss: 1.462509
[2022-03-29 22:46:55 | train] - Train Epoch: [45] [972800/1281167 (76%)]	Loss: 1.290843
[2022-03-29 22:47:15 | train] - Train Epoch: [45] [985600/1281167 (77%)]	Loss: 1.266002
[2022-03-29 22:47:35 | train] - Train Epoch: [45] [998400/1281167 (78%)]	Loss: 1.051724
[2022-03-29 22:47:57 | train] - Train Epoch: [45] [1011200/1281167 (79%)]	Loss: 1.401023
[2022-03-29 22:48:18 | train] - Train Epoch: [45] [1024000/1281167 (80%)]	Loss: 1.332358
[2022-03-29 22:48:38 | train] - Train Epoch: [45] [1036800/1281167 (81%)]	Loss: 1.177863
[2022-03-29 22:49:00 | train] - Train Epoch: [45] [1049600/1281167 (82%)]	Loss: 1.100961
[2022-03-29 22:49:21 | train] - Train Epoch: [45] [1062400/1281167 (83%)]	Loss: 1.314072
[2022-03-29 22:49:42 | train] - Train Epoch: [45] [1075200/1281167 (84%)]	Loss: 1.045453
[2022-03-29 22:50:04 | train] - Train Epoch: [45] [1088000/1281167 (85%)]	Loss: 1.065900
[2022-03-29 22:50:24 | train] - Train Epoch: [45] [1100800/1281167 (86%)]	Loss: 1.312863
[2022-03-29 22:50:44 | train] - Train Epoch: [45] [1113600/1281167 (87%)]	Loss: 1.356563
[2022-03-29 22:51:06 | train] - Train Epoch: [45] [1126400/1281167 (88%)]	Loss: 1.311144
[2022-03-29 22:51:27 | train] - Train Epoch: [45] [1139200/1281167 (89%)]	Loss: 1.387296
[2022-03-29 22:51:47 | train] - Train Epoch: [45] [1152000/1281167 (90%)]	Loss: 1.425103
[2022-03-29 22:52:08 | train] - Train Epoch: [45] [1164800/1281167 (91%)]	Loss: 1.603588
[2022-03-29 22:52:29 | train] - Train Epoch: [45] [1177600/1281167 (92%)]	Loss: 1.423730
[2022-03-29 22:52:50 | train] - Train Epoch: [45] [1190400/1281167 (93%)]	Loss: 1.231372
[2022-03-29 22:53:10 | train] - Train Epoch: [45] [1203200/1281167 (94%)]	Loss: 1.169190
[2022-03-29 22:53:30 | train] - Train Epoch: [45] [1216000/1281167 (95%)]	Loss: 1.326932
[2022-03-29 22:53:51 | train] - Train Epoch: [45] [1228800/1281167 (96%)]	Loss: 1.212384
[2022-03-29 22:54:12 | train] - Train Epoch: [45] [1241600/1281167 (97%)]	Loss: 1.474832
[2022-03-29 22:54:34 | train] - Train Epoch: [45] [1254400/1281167 (98%)]	Loss: 1.095118
[2022-03-29 22:54:54 | train] - Train Epoch: [45] [1267200/1281167 (99%)]	Loss: 1.349319
[2022-03-29 22:55:16 | train] - Train Epoch: [45] [1280000/1281167 (100%)]	Loss: 1.338197
[2022-03-29 22:55:19 | train] - Train Epoch: [45]	 Average Loss: 1.281232	 Total Acc : 69.2443	 Total Top5 Acc : 87.5030
[2022-03-29 22:55:21 | train] - -------45 epoch end-----------
========================================
-------45 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 22:57:04 | train] - 
Epoch [45] Test set: Average loss: 1.3741, Accuracy: 33791/50000 (67.5591%), Top-5 Accuracy: 87.7598%

[2022-03-29 22:57:04 | train] - save intermediate epoch [45] result


[2022-03-29 22:57:17 | train] - -------46 epoch start-----------
========================================
----- test end -------------------------


[2022-03-29 22:57:19 | train] - Train Epoch: [46] [0/1281167 (0%)]	Loss: 1.214098
[2022-03-29 22:57:43 | train] - Train Epoch: [46] [12800/1281167 (1%)]	Loss: 0.916637
[2022-03-29 22:58:06 | train] - Train Epoch: [46] [25600/1281167 (2%)]	Loss: 1.454770
[2022-03-29 22:58:29 | train] - Train Epoch: [46] [38400/1281167 (3%)]	Loss: 1.067260
[2022-03-29 22:58:52 | train] - Train Epoch: [46] [51200/1281167 (4%)]	Loss: 1.100747
[2022-03-29 22:59:13 | train] - Train Epoch: [46] [64000/1281167 (5%)]	Loss: 1.078550
[2022-03-29 22:59:36 | train] - Train Epoch: [46] [76800/1281167 (6%)]	Loss: 1.187759
[2022-03-29 22:59:59 | train] - Train Epoch: [46] [89600/1281167 (7%)]	Loss: 1.330584
[2022-03-29 23:00:22 | train] - Train Epoch: [46] [102400/1281167 (8%)]	Loss: 1.071533
[2022-03-29 23:00:45 | train] - Train Epoch: [46] [115200/1281167 (9%)]	Loss: 1.187788
[2022-03-29 23:01:07 | train] - Train Epoch: [46] [128000/1281167 (10%)]	Loss: 1.216660
[2022-03-29 23:01:29 | train] - Train Epoch: [46] [140800/1281167 (11%)]	Loss: 1.233339
[2022-03-29 23:01:52 | train] - Train Epoch: [46] [153600/1281167 (12%)]	Loss: 1.279505
[2022-03-29 23:02:16 | train] - Train Epoch: [46] [166400/1281167 (13%)]	Loss: 1.185318
[2022-03-29 23:02:38 | train] - Train Epoch: [46] [179200/1281167 (14%)]	Loss: 1.006732
[2022-03-29 23:02:59 | train] - Train Epoch: [46] [192000/1281167 (15%)]	Loss: 1.660790
[2022-03-29 23:03:21 | train] - Train Epoch: [46] [204800/1281167 (16%)]	Loss: 1.065175
[2022-03-29 23:03:42 | train] - Train Epoch: [46] [217600/1281167 (17%)]	Loss: 1.329935
[2022-03-29 23:04:04 | train] - Train Epoch: [46] [230400/1281167 (18%)]	Loss: 1.141195
[2022-03-29 23:04:26 | train] - Train Epoch: [46] [243200/1281167 (19%)]	Loss: 1.396062
[2022-03-29 23:04:48 | train] - Train Epoch: [46] [256000/1281167 (20%)]	Loss: 1.085551
[2022-03-29 23:05:11 | train] - Train Epoch: [46] [268800/1281167 (21%)]	Loss: 1.541391
[2022-03-29 23:05:33 | train] - Train Epoch: [46] [281600/1281167 (22%)]	Loss: 1.141522
[2022-03-29 23:05:55 | train] - Train Epoch: [46] [294400/1281167 (23%)]	Loss: 1.101302
[2022-03-29 23:06:16 | train] - Train Epoch: [46] [307200/1281167 (24%)]	Loss: 1.275729
[2022-03-29 23:06:38 | train] - Train Epoch: [46] [320000/1281167 (25%)]	Loss: 1.239424
[2022-03-29 23:07:00 | train] - Train Epoch: [46] [332800/1281167 (26%)]	Loss: 1.384420
[2022-03-29 23:07:21 | train] - Train Epoch: [46] [345600/1281167 (27%)]	Loss: 1.003839
[2022-03-29 23:07:43 | train] - Train Epoch: [46] [358400/1281167 (28%)]	Loss: 1.578191
[2022-03-29 23:08:05 | train] - Train Epoch: [46] [371200/1281167 (29%)]	Loss: 1.241314
[2022-03-29 23:08:27 | train] - Train Epoch: [46] [384000/1281167 (30%)]	Loss: 1.377028
[2022-03-29 23:08:49 | train] - Train Epoch: [46] [396800/1281167 (31%)]	Loss: 1.011213
[2022-03-29 23:09:10 | train] - Train Epoch: [46] [409600/1281167 (32%)]	Loss: 1.291199
[2022-03-29 23:09:31 | train] - Train Epoch: [46] [422400/1281167 (33%)]	Loss: 1.365337
[2022-03-29 23:09:53 | train] - Train Epoch: [46] [435200/1281167 (34%)]	Loss: 1.220834
[2022-03-29 23:10:14 | train] - Train Epoch: [46] [448000/1281167 (35%)]	Loss: 1.183080
[2022-03-29 23:10:34 | train] - Train Epoch: [46] [460800/1281167 (36%)]	Loss: 1.394165
[2022-03-29 23:10:55 | train] - Train Epoch: [46] [473600/1281167 (37%)]	Loss: 1.324108
[2022-03-29 23:11:17 | train] - Train Epoch: [46] [486400/1281167 (38%)]	Loss: 1.335952
[2022-03-29 23:11:39 | train] - Train Epoch: [46] [499200/1281167 (39%)]	Loss: 1.562044
[2022-03-29 23:12:00 | train] - Train Epoch: [46] [512000/1281167 (40%)]	Loss: 1.466707
[2022-03-29 23:12:21 | train] - Train Epoch: [46] [524800/1281167 (41%)]	Loss: 1.086719
[2022-03-29 23:12:42 | train] - Train Epoch: [46] [537600/1281167 (42%)]	Loss: 1.215026
[2022-03-29 23:13:03 | train] - Train Epoch: [46] [550400/1281167 (43%)]	Loss: 1.322464
[2022-03-29 23:13:25 | train] - Train Epoch: [46] [563200/1281167 (44%)]	Loss: 1.368042
[2022-03-29 23:13:46 | train] - Train Epoch: [46] [576000/1281167 (45%)]	Loss: 1.202497
[2022-03-29 23:14:08 | train] - Train Epoch: [46] [588800/1281167 (46%)]	Loss: 1.171398
[2022-03-29 23:14:29 | train] - Train Epoch: [46] [601600/1281167 (47%)]	Loss: 1.603921
[2022-03-29 23:14:51 | train] - Train Epoch: [46] [614400/1281167 (48%)]	Loss: 1.325345
[2022-03-29 23:15:12 | train] - Train Epoch: [46] [627200/1281167 (49%)]	Loss: 1.555962
[2022-03-29 23:15:34 | train] - Train Epoch: [46] [640000/1281167 (50%)]	Loss: 1.418242
[2022-03-29 23:15:55 | train] - Train Epoch: [46] [652800/1281167 (51%)]	Loss: 1.052907
[2022-03-29 23:16:18 | train] - Train Epoch: [46] [665600/1281167 (52%)]	Loss: 1.113442
[2022-03-29 23:16:40 | train] - Train Epoch: [46] [678400/1281167 (53%)]	Loss: 1.270898
[2022-03-29 23:17:01 | train] - Train Epoch: [46] [691200/1281167 (54%)]	Loss: 1.109667
[2022-03-29 23:17:23 | train] - Train Epoch: [46] [704000/1281167 (55%)]	Loss: 1.184234
[2022-03-29 23:17:45 | train] - Train Epoch: [46] [716800/1281167 (56%)]	Loss: 1.086687
[2022-03-29 23:18:06 | train] - Train Epoch: [46] [729600/1281167 (57%)]	Loss: 1.570198
[2022-03-29 23:18:28 | train] - Train Epoch: [46] [742400/1281167 (58%)]	Loss: 1.251346
[2022-03-29 23:18:50 | train] - Train Epoch: [46] [755200/1281167 (59%)]	Loss: 1.404683
[2022-03-29 23:19:13 | train] - Train Epoch: [46] [768000/1281167 (60%)]	Loss: 1.124236
[2022-03-29 23:19:34 | train] - Train Epoch: [46] [780800/1281167 (61%)]	Loss: 1.351669
[2022-03-29 23:19:56 | train] - Train Epoch: [46] [793600/1281167 (62%)]	Loss: 1.612235
[2022-03-29 23:20:18 | train] - Train Epoch: [46] [806400/1281167 (63%)]	Loss: 1.201524
[2022-03-29 23:20:39 | train] - Train Epoch: [46] [819200/1281167 (64%)]	Loss: 1.246900
[2022-03-29 23:21:01 | train] - Train Epoch: [46] [832000/1281167 (65%)]	Loss: 1.218200
[2022-03-29 23:21:23 | train] - Train Epoch: [46] [844800/1281167 (66%)]	Loss: 1.169827
[2022-03-29 23:21:44 | train] - Train Epoch: [46] [857600/1281167 (67%)]	Loss: 1.255574
[2022-03-29 23:22:06 | train] - Train Epoch: [46] [870400/1281167 (68%)]	Loss: 1.303037
[2022-03-29 23:22:27 | train] - Train Epoch: [46] [883200/1281167 (69%)]	Loss: 1.264362
[2022-03-29 23:22:50 | train] - Train Epoch: [46] [896000/1281167 (70%)]	Loss: 1.490018
[2022-03-29 23:23:12 | train] - Train Epoch: [46] [908800/1281167 (71%)]	Loss: 1.489545
[2022-03-29 23:23:35 | train] - Train Epoch: [46] [921600/1281167 (72%)]	Loss: 1.160431
[2022-03-29 23:23:57 | train] - Train Epoch: [46] [934400/1281167 (73%)]	Loss: 1.352153
[2022-03-29 23:24:20 | train] - Train Epoch: [46] [947200/1281167 (74%)]	Loss: 1.292082
[2022-03-29 23:24:42 | train] - Train Epoch: [46] [960000/1281167 (75%)]	Loss: 1.379821
[2022-03-29 23:25:04 | train] - Train Epoch: [46] [972800/1281167 (76%)]	Loss: 1.191361
[2022-03-29 23:25:26 | train] - Train Epoch: [46] [985600/1281167 (77%)]	Loss: 1.322716
[2022-03-29 23:25:48 | train] - Train Epoch: [46] [998400/1281167 (78%)]	Loss: 1.291431
[2022-03-29 23:26:11 | train] - Train Epoch: [46] [1011200/1281167 (79%)]	Loss: 1.243800
[2022-03-29 23:26:32 | train] - Train Epoch: [46] [1024000/1281167 (80%)]	Loss: 1.025327
[2022-03-29 23:26:54 | train] - Train Epoch: [46] [1036800/1281167 (81%)]	Loss: 1.078705
[2022-03-29 23:27:15 | train] - Train Epoch: [46] [1049600/1281167 (82%)]	Loss: 1.342754
[2022-03-29 23:27:37 | train] - Train Epoch: [46] [1062400/1281167 (83%)]	Loss: 1.190071
[2022-03-29 23:27:58 | train] - Train Epoch: [46] [1075200/1281167 (84%)]	Loss: 1.040921
[2022-03-29 23:28:21 | train] - Train Epoch: [46] [1088000/1281167 (85%)]	Loss: 1.310915
[2022-03-29 23:28:43 | train] - Train Epoch: [46] [1100800/1281167 (86%)]	Loss: 1.177768
[2022-03-29 23:29:05 | train] - Train Epoch: [46] [1113600/1281167 (87%)]	Loss: 1.330176
[2022-03-29 23:29:28 | train] - Train Epoch: [46] [1126400/1281167 (88%)]	Loss: 1.243770
[2022-03-29 23:29:50 | train] - Train Epoch: [46] [1139200/1281167 (89%)]	Loss: 1.243330
[2022-03-29 23:30:13 | train] - Train Epoch: [46] [1152000/1281167 (90%)]	Loss: 1.355114
[2022-03-29 23:30:34 | train] - Train Epoch: [46] [1164800/1281167 (91%)]	Loss: 1.471879
[2022-03-29 23:30:57 | train] - Train Epoch: [46] [1177600/1281167 (92%)]	Loss: 1.351710
[2022-03-29 23:31:19 | train] - Train Epoch: [46] [1190400/1281167 (93%)]	Loss: 1.177480
[2022-03-29 23:31:41 | train] - Train Epoch: [46] [1203200/1281167 (94%)]	Loss: 1.477377
[2022-03-29 23:32:03 | train] - Train Epoch: [46] [1216000/1281167 (95%)]	Loss: 1.315477
[2022-03-29 23:32:26 | train] - Train Epoch: [46] [1228800/1281167 (96%)]	Loss: 1.022460
[2022-03-29 23:32:48 | train] - Train Epoch: [46] [1241600/1281167 (97%)]	Loss: 1.136060
[2022-03-29 23:33:10 | train] - Train Epoch: [46] [1254400/1281167 (98%)]	Loss: 1.133273
[2022-03-29 23:33:32 | train] - Train Epoch: [46] [1267200/1281167 (99%)]	Loss: 1.082901
[2022-03-29 23:33:53 | train] - Train Epoch: [46] [1280000/1281167 (100%)]	Loss: 1.322015
[2022-03-29 23:33:56 | train] - Train Epoch: [46]	 Average Loss: 1.269693	 Total Acc : 69.5118	 Total Top5 Acc : 87.6167
[2022-03-29 23:33:58 | train] - -------46 epoch end-----------
========================================
-------46 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-29 23:35:42 | train] - 
Epoch [46] Test set: Average loss: 1.3757, Accuracy: 33898/50000 (67.7598%), Top-5 Accuracy: 87.9715%

[2022-03-29 23:35:42 | train] - save intermediate epoch [46] result


[2022-03-29 23:35:53 | train] - logging best performance 46 epoch
[2022-03-29 23:35:54 | train] - -------47 epoch start-----------
========================================
----- test end -------------------------


logging best performance 46 epoch
[2022-03-29 23:35:57 | train] - Train Epoch: [47] [0/1281167 (0%)]	Loss: 1.382303
[2022-03-29 23:36:20 | train] - Train Epoch: [47] [12800/1281167 (1%)]	Loss: 1.332116
[2022-03-29 23:36:43 | train] - Train Epoch: [47] [25600/1281167 (2%)]	Loss: 1.044229
[2022-03-29 23:37:07 | train] - Train Epoch: [47] [38400/1281167 (3%)]	Loss: 1.055770
[2022-03-29 23:37:30 | train] - Train Epoch: [47] [51200/1281167 (4%)]	Loss: 1.119784
[2022-03-29 23:37:54 | train] - Train Epoch: [47] [64000/1281167 (5%)]	Loss: 1.314049
[2022-03-29 23:38:17 | train] - Train Epoch: [47] [76800/1281167 (6%)]	Loss: 1.282926
[2022-03-29 23:38:40 | train] - Train Epoch: [47] [89600/1281167 (7%)]	Loss: 1.246198
[2022-03-29 23:39:03 | train] - Train Epoch: [47] [102400/1281167 (8%)]	Loss: 1.290268
[2022-03-29 23:39:27 | train] - Train Epoch: [47] [115200/1281167 (9%)]	Loss: 1.263269
[2022-03-29 23:39:50 | train] - Train Epoch: [47] [128000/1281167 (10%)]	Loss: 1.659875
[2022-03-29 23:40:14 | train] - Train Epoch: [47] [140800/1281167 (11%)]	Loss: 1.108941
[2022-03-29 23:40:36 | train] - Train Epoch: [47] [153600/1281167 (12%)]	Loss: 1.038509
[2022-03-29 23:40:59 | train] - Train Epoch: [47] [166400/1281167 (13%)]	Loss: 1.114098
[2022-03-29 23:41:22 | train] - Train Epoch: [47] [179200/1281167 (14%)]	Loss: 1.073059
[2022-03-29 23:41:46 | train] - Train Epoch: [47] [192000/1281167 (15%)]	Loss: 1.331155
[2022-03-29 23:42:08 | train] - Train Epoch: [47] [204800/1281167 (16%)]	Loss: 1.166465
[2022-03-29 23:42:31 | train] - Train Epoch: [47] [217600/1281167 (17%)]	Loss: 1.299291
[2022-03-29 23:42:54 | train] - Train Epoch: [47] [230400/1281167 (18%)]	Loss: 1.283578
[2022-03-29 23:43:17 | train] - Train Epoch: [47] [243200/1281167 (19%)]	Loss: 1.398172
[2022-03-29 23:43:39 | train] - Train Epoch: [47] [256000/1281167 (20%)]	Loss: 0.828350
[2022-03-29 23:44:02 | train] - Train Epoch: [47] [268800/1281167 (21%)]	Loss: 1.113822
[2022-03-29 23:44:25 | train] - Train Epoch: [47] [281600/1281167 (22%)]	Loss: 1.028187
[2022-03-29 23:44:48 | train] - Train Epoch: [47] [294400/1281167 (23%)]	Loss: 1.218271
[2022-03-29 23:45:09 | train] - Train Epoch: [47] [307200/1281167 (24%)]	Loss: 1.337174
[2022-03-29 23:45:32 | train] - Train Epoch: [47] [320000/1281167 (25%)]	Loss: 0.965149
[2022-03-29 23:45:54 | train] - Train Epoch: [47] [332800/1281167 (26%)]	Loss: 1.139545
[2022-03-29 23:46:16 | train] - Train Epoch: [47] [345600/1281167 (27%)]	Loss: 1.459619
[2022-03-29 23:46:39 | train] - Train Epoch: [47] [358400/1281167 (28%)]	Loss: 1.099767
[2022-03-29 23:47:03 | train] - Train Epoch: [47] [371200/1281167 (29%)]	Loss: 1.386981
[2022-03-29 23:47:26 | train] - Train Epoch: [47] [384000/1281167 (30%)]	Loss: 1.101396
[2022-03-29 23:47:47 | train] - Train Epoch: [47] [396800/1281167 (31%)]	Loss: 1.570534
[2022-03-29 23:48:09 | train] - Train Epoch: [47] [409600/1281167 (32%)]	Loss: 1.139601
[2022-03-29 23:48:31 | train] - Train Epoch: [47] [422400/1281167 (33%)]	Loss: 1.020606
[2022-03-29 23:48:54 | train] - Train Epoch: [47] [435200/1281167 (34%)]	Loss: 1.306811
[2022-03-29 23:49:16 | train] - Train Epoch: [47] [448000/1281167 (35%)]	Loss: 1.268644
[2022-03-29 23:49:39 | train] - Train Epoch: [47] [460800/1281167 (36%)]	Loss: 0.959338
[2022-03-29 23:50:02 | train] - Train Epoch: [47] [473600/1281167 (37%)]	Loss: 1.135876
[2022-03-29 23:50:25 | train] - Train Epoch: [47] [486400/1281167 (38%)]	Loss: 1.180802
[2022-03-29 23:50:47 | train] - Train Epoch: [47] [499200/1281167 (39%)]	Loss: 1.258985
[2022-03-29 23:51:09 | train] - Train Epoch: [47] [512000/1281167 (40%)]	Loss: 1.234759
[2022-03-29 23:51:30 | train] - Train Epoch: [47] [524800/1281167 (41%)]	Loss: 1.007772
[2022-03-29 23:51:52 | train] - Train Epoch: [47] [537600/1281167 (42%)]	Loss: 1.054740
[2022-03-29 23:52:14 | train] - Train Epoch: [47] [550400/1281167 (43%)]	Loss: 1.234150
[2022-03-29 23:52:36 | train] - Train Epoch: [47] [563200/1281167 (44%)]	Loss: 0.928101
[2022-03-29 23:52:57 | train] - Train Epoch: [47] [576000/1281167 (45%)]	Loss: 1.274895
[2022-03-29 23:53:19 | train] - Train Epoch: [47] [588800/1281167 (46%)]	Loss: 1.216492
[2022-03-29 23:53:41 | train] - Train Epoch: [47] [601600/1281167 (47%)]	Loss: 1.171514
[2022-03-29 23:54:03 | train] - Train Epoch: [47] [614400/1281167 (48%)]	Loss: 1.007419
[2022-03-29 23:54:26 | train] - Train Epoch: [47] [627200/1281167 (49%)]	Loss: 1.247816
[2022-03-29 23:54:48 | train] - Train Epoch: [47] [640000/1281167 (50%)]	Loss: 1.424793
[2022-03-29 23:55:10 | train] - Train Epoch: [47] [652800/1281167 (51%)]	Loss: 1.451240
[2022-03-29 23:55:31 | train] - Train Epoch: [47] [665600/1281167 (52%)]	Loss: 1.372847
[2022-03-29 23:55:53 | train] - Train Epoch: [47] [678400/1281167 (53%)]	Loss: 1.086794
[2022-03-29 23:56:14 | train] - Train Epoch: [47] [691200/1281167 (54%)]	Loss: 1.240027
[2022-03-29 23:56:36 | train] - Train Epoch: [47] [704000/1281167 (55%)]	Loss: 1.150869
[2022-03-29 23:56:58 | train] - Train Epoch: [47] [716800/1281167 (56%)]	Loss: 1.741321
[2022-03-29 23:57:20 | train] - Train Epoch: [47] [729600/1281167 (57%)]	Loss: 1.480865
[2022-03-29 23:57:43 | train] - Train Epoch: [47] [742400/1281167 (58%)]	Loss: 1.291533
[2022-03-29 23:58:04 | train] - Train Epoch: [47] [755200/1281167 (59%)]	Loss: 0.846240
[2022-03-29 23:58:26 | train] - Train Epoch: [47] [768000/1281167 (60%)]	Loss: 1.498169
[2022-03-29 23:58:47 | train] - Train Epoch: [47] [780800/1281167 (61%)]	Loss: 1.244453
[2022-03-29 23:59:09 | train] - Train Epoch: [47] [793600/1281167 (62%)]	Loss: 1.192923
[2022-03-29 23:59:31 | train] - Train Epoch: [47] [806400/1281167 (63%)]	Loss: 1.361349
[2022-03-29 23:59:52 | train] - Train Epoch: [47] [819200/1281167 (64%)]	Loss: 1.274238
[2022-03-30 00:00:14 | train] - Train Epoch: [47] [832000/1281167 (65%)]	Loss: 1.217969
[2022-03-30 00:00:35 | train] - Train Epoch: [47] [844800/1281167 (66%)]	Loss: 1.440151
[2022-03-30 00:00:58 | train] - Train Epoch: [47] [857600/1281167 (67%)]	Loss: 1.358150
[2022-03-30 00:01:20 | train] - Train Epoch: [47] [870400/1281167 (68%)]	Loss: 1.281223
[2022-03-30 00:01:41 | train] - Train Epoch: [47] [883200/1281167 (69%)]	Loss: 1.181445
[2022-03-30 00:02:04 | train] - Train Epoch: [47] [896000/1281167 (70%)]	Loss: 1.144123
[2022-03-30 00:02:26 | train] - Train Epoch: [47] [908800/1281167 (71%)]	Loss: 1.095395
[2022-03-30 00:02:48 | train] - Train Epoch: [47] [921600/1281167 (72%)]	Loss: 1.237098
[2022-03-30 00:03:10 | train] - Train Epoch: [47] [934400/1281167 (73%)]	Loss: 1.174881
[2022-03-30 00:03:31 | train] - Train Epoch: [47] [947200/1281167 (74%)]	Loss: 1.233274
[2022-03-30 00:03:53 | train] - Train Epoch: [47] [960000/1281167 (75%)]	Loss: 1.125499
[2022-03-30 00:04:14 | train] - Train Epoch: [47] [972800/1281167 (76%)]	Loss: 1.031227
[2022-03-30 00:04:36 | train] - Train Epoch: [47] [985600/1281167 (77%)]	Loss: 1.326821
[2022-03-30 00:04:58 | train] - Train Epoch: [47] [998400/1281167 (78%)]	Loss: 1.264254
[2022-03-30 00:05:20 | train] - Train Epoch: [47] [1011200/1281167 (79%)]	Loss: 1.297354
[2022-03-30 00:05:42 | train] - Train Epoch: [47] [1024000/1281167 (80%)]	Loss: 1.175207
[2022-03-30 00:06:05 | train] - Train Epoch: [47] [1036800/1281167 (81%)]	Loss: 1.295146
[2022-03-30 00:06:27 | train] - Train Epoch: [47] [1049600/1281167 (82%)]	Loss: 1.610280
[2022-03-30 00:06:49 | train] - Train Epoch: [47] [1062400/1281167 (83%)]	Loss: 1.319191
[2022-03-30 00:07:11 | train] - Train Epoch: [47] [1075200/1281167 (84%)]	Loss: 1.317248
[2022-03-30 00:07:32 | train] - Train Epoch: [47] [1088000/1281167 (85%)]	Loss: 1.000697
[2022-03-30 00:07:54 | train] - Train Epoch: [47] [1100800/1281167 (86%)]	Loss: 1.458143
[2022-03-30 00:08:15 | train] - Train Epoch: [47] [1113600/1281167 (87%)]	Loss: 1.317341
[2022-03-30 00:08:37 | train] - Train Epoch: [47] [1126400/1281167 (88%)]	Loss: 1.014803
[2022-03-30 00:08:59 | train] - Train Epoch: [47] [1139200/1281167 (89%)]	Loss: 1.289616
[2022-03-30 00:09:21 | train] - Train Epoch: [47] [1152000/1281167 (90%)]	Loss: 1.124599
[2022-03-30 00:09:43 | train] - Train Epoch: [47] [1164800/1281167 (91%)]	Loss: 1.267923
[2022-03-30 00:10:06 | train] - Train Epoch: [47] [1177600/1281167 (92%)]	Loss: 0.899958
[2022-03-30 00:10:28 | train] - Train Epoch: [47] [1190400/1281167 (93%)]	Loss: 0.987554
[2022-03-30 00:10:50 | train] - Train Epoch: [47] [1203200/1281167 (94%)]	Loss: 1.271806
[2022-03-30 00:11:13 | train] - Train Epoch: [47] [1216000/1281167 (95%)]	Loss: 1.381482
[2022-03-30 00:11:36 | train] - Train Epoch: [47] [1228800/1281167 (96%)]	Loss: 1.219692
[2022-03-30 00:11:59 | train] - Train Epoch: [47] [1241600/1281167 (97%)]	Loss: 1.371054
[2022-03-30 00:12:22 | train] - Train Epoch: [47] [1254400/1281167 (98%)]	Loss: 1.308080
[2022-03-30 00:12:44 | train] - Train Epoch: [47] [1267200/1281167 (99%)]	Loss: 1.591747
[2022-03-30 00:13:07 | train] - Train Epoch: [47] [1280000/1281167 (100%)]	Loss: 1.211031
[2022-03-30 00:13:10 | train] - Train Epoch: [47]	 Average Loss: 1.257128	 Total Acc : 69.7767	 Total Top5 Acc : 87.8097
[2022-03-30 00:13:12 | train] - -------47 epoch end-----------
========================================
-------47 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 00:14:57 | train] - 
Epoch [47] Test set: Average loss: 1.3717, Accuracy: 34075/50000 (68.1182%), Top-5 Accuracy: 87.9008%

[2022-03-30 00:14:57 | train] - save intermediate epoch [47] result


[2022-03-30 00:15:10 | train] - logging best performance 47 epoch
[2022-03-30 00:15:11 | train] - -------48 epoch start-----------
========================================
----- test end -------------------------


logging best performance 47 epoch
[2022-03-30 00:15:13 | train] - Train Epoch: [48] [0/1281167 (0%)]	Loss: 1.562510
[2022-03-30 00:15:36 | train] - Train Epoch: [48] [12800/1281167 (1%)]	Loss: 1.152069
[2022-03-30 00:15:59 | train] - Train Epoch: [48] [25600/1281167 (2%)]	Loss: 1.374693
[2022-03-30 00:16:22 | train] - Train Epoch: [48] [38400/1281167 (3%)]	Loss: 1.220235
[2022-03-30 00:16:45 | train] - Train Epoch: [48] [51200/1281167 (4%)]	Loss: 1.059412
[2022-03-30 00:17:07 | train] - Train Epoch: [48] [64000/1281167 (5%)]	Loss: 1.265067
[2022-03-30 00:17:28 | train] - Train Epoch: [48] [76800/1281167 (6%)]	Loss: 1.111693
[2022-03-30 00:17:50 | train] - Train Epoch: [48] [89600/1281167 (7%)]	Loss: 1.139923
[2022-03-30 00:18:12 | train] - Train Epoch: [48] [102400/1281167 (8%)]	Loss: 1.113957
[2022-03-30 00:18:35 | train] - Train Epoch: [48] [115200/1281167 (9%)]	Loss: 1.488043
[2022-03-30 00:18:58 | train] - Train Epoch: [48] [128000/1281167 (10%)]	Loss: 1.409368
[2022-03-30 00:19:19 | train] - Train Epoch: [48] [140800/1281167 (11%)]	Loss: 1.075100
[2022-03-30 00:19:43 | train] - Train Epoch: [48] [153600/1281167 (12%)]	Loss: 1.195886
[2022-03-30 00:20:05 | train] - Train Epoch: [48] [166400/1281167 (13%)]	Loss: 1.264274
[2022-03-30 00:20:26 | train] - Train Epoch: [48] [179200/1281167 (14%)]	Loss: 1.172309
[2022-03-30 00:20:47 | train] - Train Epoch: [48] [192000/1281167 (15%)]	Loss: 1.204410
[2022-03-30 00:21:08 | train] - Train Epoch: [48] [204800/1281167 (16%)]	Loss: 1.225385
[2022-03-30 00:21:30 | train] - Train Epoch: [48] [217600/1281167 (17%)]	Loss: 1.163853
[2022-03-30 00:21:53 | train] - Train Epoch: [48] [230400/1281167 (18%)]	Loss: 1.050634
[2022-03-30 00:22:14 | train] - Train Epoch: [48] [243200/1281167 (19%)]	Loss: 1.180758
[2022-03-30 00:22:36 | train] - Train Epoch: [48] [256000/1281167 (20%)]	Loss: 0.997950
[2022-03-30 00:22:57 | train] - Train Epoch: [48] [268800/1281167 (21%)]	Loss: 1.442448
[2022-03-30 00:23:18 | train] - Train Epoch: [48] [281600/1281167 (22%)]	Loss: 1.239347
[2022-03-30 00:23:40 | train] - Train Epoch: [48] [294400/1281167 (23%)]	Loss: 1.003399
[2022-03-30 00:24:01 | train] - Train Epoch: [48] [307200/1281167 (24%)]	Loss: 1.181035
[2022-03-30 00:24:23 | train] - Train Epoch: [48] [320000/1281167 (25%)]	Loss: 1.326599
[2022-03-30 00:24:45 | train] - Train Epoch: [48] [332800/1281167 (26%)]	Loss: 1.250011
[2022-03-30 00:25:06 | train] - Train Epoch: [48] [345600/1281167 (27%)]	Loss: 1.459104
[2022-03-30 00:25:29 | train] - Train Epoch: [48] [358400/1281167 (28%)]	Loss: 1.276462
[2022-03-30 00:25:53 | train] - Train Epoch: [48] [371200/1281167 (29%)]	Loss: 1.381522
[2022-03-30 00:26:15 | train] - Train Epoch: [48] [384000/1281167 (30%)]	Loss: 1.429645
[2022-03-30 00:26:37 | train] - Train Epoch: [48] [396800/1281167 (31%)]	Loss: 1.299299
[2022-03-30 00:27:00 | train] - Train Epoch: [48] [409600/1281167 (32%)]	Loss: 1.306662
[2022-03-30 00:27:21 | train] - Train Epoch: [48] [422400/1281167 (33%)]	Loss: 1.199082
[2022-03-30 00:27:44 | train] - Train Epoch: [48] [435200/1281167 (34%)]	Loss: 1.257607
[2022-03-30 00:28:04 | train] - Train Epoch: [48] [448000/1281167 (35%)]	Loss: 1.058705
[2022-03-30 00:28:25 | train] - Train Epoch: [48] [460800/1281167 (36%)]	Loss: 1.095468
[2022-03-30 00:28:47 | train] - Train Epoch: [48] [473600/1281167 (37%)]	Loss: 1.406361
[2022-03-30 00:29:08 | train] - Train Epoch: [48] [486400/1281167 (38%)]	Loss: 1.456490
[2022-03-30 00:29:30 | train] - Train Epoch: [48] [499200/1281167 (39%)]	Loss: 1.028911
[2022-03-30 00:29:51 | train] - Train Epoch: [48] [512000/1281167 (40%)]	Loss: 1.450702
[2022-03-30 00:30:12 | train] - Train Epoch: [48] [524800/1281167 (41%)]	Loss: 1.248803
[2022-03-30 00:30:33 | train] - Train Epoch: [48] [537600/1281167 (42%)]	Loss: 1.253199
[2022-03-30 00:30:55 | train] - Train Epoch: [48] [550400/1281167 (43%)]	Loss: 1.408375
[2022-03-30 00:31:17 | train] - Train Epoch: [48] [563200/1281167 (44%)]	Loss: 1.361284
[2022-03-30 00:31:38 | train] - Train Epoch: [48] [576000/1281167 (45%)]	Loss: 1.174312
[2022-03-30 00:32:00 | train] - Train Epoch: [48] [588800/1281167 (46%)]	Loss: 1.184451
[2022-03-30 00:32:21 | train] - Train Epoch: [48] [601600/1281167 (47%)]	Loss: 1.041115
[2022-03-30 00:32:43 | train] - Train Epoch: [48] [614400/1281167 (48%)]	Loss: 0.877934
[2022-03-30 00:33:03 | train] - Train Epoch: [48] [627200/1281167 (49%)]	Loss: 1.274785
[2022-03-30 00:33:25 | train] - Train Epoch: [48] [640000/1281167 (50%)]	Loss: 1.364310
[2022-03-30 00:33:47 | train] - Train Epoch: [48] [652800/1281167 (51%)]	Loss: 1.501984
[2022-03-30 00:34:09 | train] - Train Epoch: [48] [665600/1281167 (52%)]	Loss: 1.333079
[2022-03-30 00:34:31 | train] - Train Epoch: [48] [678400/1281167 (53%)]	Loss: 1.416522
[2022-03-30 00:34:52 | train] - Train Epoch: [48] [691200/1281167 (54%)]	Loss: 1.365899
[2022-03-30 00:35:14 | train] - Train Epoch: [48] [704000/1281167 (55%)]	Loss: 1.179121
[2022-03-30 00:35:36 | train] - Train Epoch: [48] [716800/1281167 (56%)]	Loss: 1.327869
[2022-03-30 00:35:57 | train] - Train Epoch: [48] [729600/1281167 (57%)]	Loss: 1.491267
[2022-03-30 00:36:19 | train] - Train Epoch: [48] [742400/1281167 (58%)]	Loss: 1.393970
[2022-03-30 00:36:40 | train] - Train Epoch: [48] [755200/1281167 (59%)]	Loss: 1.212205
[2022-03-30 00:37:03 | train] - Train Epoch: [48] [768000/1281167 (60%)]	Loss: 1.257563
[2022-03-30 00:37:25 | train] - Train Epoch: [48] [780800/1281167 (61%)]	Loss: 1.139018
[2022-03-30 00:37:47 | train] - Train Epoch: [48] [793600/1281167 (62%)]	Loss: 1.409849
[2022-03-30 00:38:09 | train] - Train Epoch: [48] [806400/1281167 (63%)]	Loss: 1.253258
[2022-03-30 00:38:30 | train] - Train Epoch: [48] [819200/1281167 (64%)]	Loss: 1.362905
[2022-03-30 00:38:52 | train] - Train Epoch: [48] [832000/1281167 (65%)]	Loss: 1.036076
[2022-03-30 00:39:13 | train] - Train Epoch: [48] [844800/1281167 (66%)]	Loss: 1.387599
[2022-03-30 00:39:34 | train] - Train Epoch: [48] [857600/1281167 (67%)]	Loss: 0.972584
[2022-03-30 00:39:56 | train] - Train Epoch: [48] [870400/1281167 (68%)]	Loss: 1.173069
[2022-03-30 00:40:18 | train] - Train Epoch: [48] [883200/1281167 (69%)]	Loss: 1.233731
[2022-03-30 00:40:40 | train] - Train Epoch: [48] [896000/1281167 (70%)]	Loss: 1.292194
[2022-03-30 00:41:02 | train] - Train Epoch: [48] [908800/1281167 (71%)]	Loss: 1.042963
[2022-03-30 00:41:23 | train] - Train Epoch: [48] [921600/1281167 (72%)]	Loss: 1.566817
[2022-03-30 00:41:44 | train] - Train Epoch: [48] [934400/1281167 (73%)]	Loss: 1.222313
[2022-03-30 00:42:05 | train] - Train Epoch: [48] [947200/1281167 (74%)]	Loss: 1.250058
[2022-03-30 00:42:26 | train] - Train Epoch: [48] [960000/1281167 (75%)]	Loss: 1.269807
[2022-03-30 00:42:48 | train] - Train Epoch: [48] [972800/1281167 (76%)]	Loss: 1.510654
[2022-03-30 00:43:09 | train] - Train Epoch: [48] [985600/1281167 (77%)]	Loss: 1.206329
[2022-03-30 00:43:31 | train] - Train Epoch: [48] [998400/1281167 (78%)]	Loss: 1.416863
[2022-03-30 00:43:53 | train] - Train Epoch: [48] [1011200/1281167 (79%)]	Loss: 1.232185
[2022-03-30 00:44:15 | train] - Train Epoch: [48] [1024000/1281167 (80%)]	Loss: 1.003312
[2022-03-30 00:44:37 | train] - Train Epoch: [48] [1036800/1281167 (81%)]	Loss: 1.209675
[2022-03-30 00:45:00 | train] - Train Epoch: [48] [1049600/1281167 (82%)]	Loss: 1.440863
[2022-03-30 00:45:21 | train] - Train Epoch: [48] [1062400/1281167 (83%)]	Loss: 0.923810
[2022-03-30 00:45:43 | train] - Train Epoch: [48] [1075200/1281167 (84%)]	Loss: 1.265326
[2022-03-30 00:46:05 | train] - Train Epoch: [48] [1088000/1281167 (85%)]	Loss: 1.165679
[2022-03-30 00:46:27 | train] - Train Epoch: [48] [1100800/1281167 (86%)]	Loss: 1.182706
[2022-03-30 00:46:50 | train] - Train Epoch: [48] [1113600/1281167 (87%)]	Loss: 1.499808
[2022-03-30 00:47:12 | train] - Train Epoch: [48] [1126400/1281167 (88%)]	Loss: 1.624259
[2022-03-30 00:47:35 | train] - Train Epoch: [48] [1139200/1281167 (89%)]	Loss: 1.082098
[2022-03-30 00:47:56 | train] - Train Epoch: [48] [1152000/1281167 (90%)]	Loss: 1.193248
[2022-03-30 00:48:16 | train] - Train Epoch: [48] [1164800/1281167 (91%)]	Loss: 1.372397
[2022-03-30 00:48:39 | train] - Train Epoch: [48] [1177600/1281167 (92%)]	Loss: 1.381285
[2022-03-30 00:49:00 | train] - Train Epoch: [48] [1190400/1281167 (93%)]	Loss: 1.201538
[2022-03-30 00:49:22 | train] - Train Epoch: [48] [1203200/1281167 (94%)]	Loss: 0.871446
[2022-03-30 00:49:43 | train] - Train Epoch: [48] [1216000/1281167 (95%)]	Loss: 1.411625
[2022-03-30 00:50:05 | train] - Train Epoch: [48] [1228800/1281167 (96%)]	Loss: 1.387851
[2022-03-30 00:50:26 | train] - Train Epoch: [48] [1241600/1281167 (97%)]	Loss: 1.047809
[2022-03-30 00:50:48 | train] - Train Epoch: [48] [1254400/1281167 (98%)]	Loss: 1.469503
[2022-03-30 00:51:09 | train] - Train Epoch: [48] [1267200/1281167 (99%)]	Loss: 1.369521
[2022-03-30 00:51:30 | train] - Train Epoch: [48] [1280000/1281167 (100%)]	Loss: 1.022269
[2022-03-30 00:51:32 | train] - Train Epoch: [48]	 Average Loss: 1.250218	 Total Acc : 69.9703	 Total Top5 Acc : 87.8937
[2022-03-30 00:51:35 | train] - -------48 epoch end-----------
========================================
-------48 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 00:53:18 | train] - 
Epoch [48] Test set: Average loss: 1.3668, Accuracy: 34128/50000 (68.2289%), Top-5 Accuracy: 88.0507%

[2022-03-30 00:53:18 | train] - save intermediate epoch [48] result


[2022-03-30 00:53:30 | train] - logging best performance 48 epoch
[2022-03-30 00:53:31 | train] - -------49 epoch start-----------
========================================
----- test end -------------------------


logging best performance 48 epoch
[2022-03-30 00:53:34 | train] - Train Epoch: [49] [0/1281167 (0%)]	Loss: 1.155219
[2022-03-30 00:53:58 | train] - Train Epoch: [49] [12800/1281167 (1%)]	Loss: 1.198049
[2022-03-30 00:54:22 | train] - Train Epoch: [49] [25600/1281167 (2%)]	Loss: 1.313309
[2022-03-30 00:54:45 | train] - Train Epoch: [49] [38400/1281167 (3%)]	Loss: 1.102093
[2022-03-30 00:55:08 | train] - Train Epoch: [49] [51200/1281167 (4%)]	Loss: 0.900235
[2022-03-30 00:55:32 | train] - Train Epoch: [49] [64000/1281167 (5%)]	Loss: 1.122085
[2022-03-30 00:55:54 | train] - Train Epoch: [49] [76800/1281167 (6%)]	Loss: 0.875942
[2022-03-30 00:56:17 | train] - Train Epoch: [49] [89600/1281167 (7%)]	Loss: 1.274569
[2022-03-30 00:56:41 | train] - Train Epoch: [49] [102400/1281167 (8%)]	Loss: 1.618284
[2022-03-30 00:57:04 | train] - Train Epoch: [49] [115200/1281167 (9%)]	Loss: 1.115951
[2022-03-30 00:57:27 | train] - Train Epoch: [49] [128000/1281167 (10%)]	Loss: 1.214654
[2022-03-30 00:57:50 | train] - Train Epoch: [49] [140800/1281167 (11%)]	Loss: 1.119262
[2022-03-30 00:58:12 | train] - Train Epoch: [49] [153600/1281167 (12%)]	Loss: 1.048245
[2022-03-30 00:58:35 | train] - Train Epoch: [49] [166400/1281167 (13%)]	Loss: 1.368720
[2022-03-30 00:58:58 | train] - Train Epoch: [49] [179200/1281167 (14%)]	Loss: 1.410675
[2022-03-30 00:59:20 | train] - Train Epoch: [49] [192000/1281167 (15%)]	Loss: 1.145842
[2022-03-30 00:59:42 | train] - Train Epoch: [49] [204800/1281167 (16%)]	Loss: 1.238942
[2022-03-30 01:00:03 | train] - Train Epoch: [49] [217600/1281167 (17%)]	Loss: 0.839222
[2022-03-30 01:00:24 | train] - Train Epoch: [49] [230400/1281167 (18%)]	Loss: 0.981492
[2022-03-30 01:00:45 | train] - Train Epoch: [49] [243200/1281167 (19%)]	Loss: 1.332195
[2022-03-30 01:01:06 | train] - Train Epoch: [49] [256000/1281167 (20%)]	Loss: 1.211509
[2022-03-30 01:01:28 | train] - Train Epoch: [49] [268800/1281167 (21%)]	Loss: 1.155837
[2022-03-30 01:01:50 | train] - Train Epoch: [49] [281600/1281167 (22%)]	Loss: 1.388351
[2022-03-30 01:02:12 | train] - Train Epoch: [49] [294400/1281167 (23%)]	Loss: 0.946078
[2022-03-30 01:02:32 | train] - Train Epoch: [49] [307200/1281167 (24%)]	Loss: 1.220396
[2022-03-30 01:02:54 | train] - Train Epoch: [49] [320000/1281167 (25%)]	Loss: 1.005405
[2022-03-30 01:03:15 | train] - Train Epoch: [49] [332800/1281167 (26%)]	Loss: 1.217742
[2022-03-30 01:03:36 | train] - Train Epoch: [49] [345600/1281167 (27%)]	Loss: 0.950100
[2022-03-30 01:03:57 | train] - Train Epoch: [49] [358400/1281167 (28%)]	Loss: 1.034208
[2022-03-30 01:04:18 | train] - Train Epoch: [49] [371200/1281167 (29%)]	Loss: 1.189571
[2022-03-30 01:04:40 | train] - Train Epoch: [49] [384000/1281167 (30%)]	Loss: 1.212973
[2022-03-30 01:05:01 | train] - Train Epoch: [49] [396800/1281167 (31%)]	Loss: 1.387628
[2022-03-30 01:05:23 | train] - Train Epoch: [49] [409600/1281167 (32%)]	Loss: 1.336664
[2022-03-30 01:05:43 | train] - Train Epoch: [49] [422400/1281167 (33%)]	Loss: 1.047784
[2022-03-30 01:06:04 | train] - Train Epoch: [49] [435200/1281167 (34%)]	Loss: 0.934615
[2022-03-30 01:06:25 | train] - Train Epoch: [49] [448000/1281167 (35%)]	Loss: 1.083716
[2022-03-30 01:06:46 | train] - Train Epoch: [49] [460800/1281167 (36%)]	Loss: 1.134094
[2022-03-30 01:07:08 | train] - Train Epoch: [49] [473600/1281167 (37%)]	Loss: 1.038744
[2022-03-30 01:07:29 | train] - Train Epoch: [49] [486400/1281167 (38%)]	Loss: 1.092608
[2022-03-30 01:07:51 | train] - Train Epoch: [49] [499200/1281167 (39%)]	Loss: 1.223856
[2022-03-30 01:08:11 | train] - Train Epoch: [49] [512000/1281167 (40%)]	Loss: 1.079989
[2022-03-30 01:08:31 | train] - Train Epoch: [49] [524800/1281167 (41%)]	Loss: 1.172560
[2022-03-30 01:08:52 | train] - Train Epoch: [49] [537600/1281167 (42%)]	Loss: 1.159052
[2022-03-30 01:09:13 | train] - Train Epoch: [49] [550400/1281167 (43%)]	Loss: 1.431136
[2022-03-30 01:09:33 | train] - Train Epoch: [49] [563200/1281167 (44%)]	Loss: 1.015835
[2022-03-30 01:09:54 | train] - Train Epoch: [49] [576000/1281167 (45%)]	Loss: 1.444978
[2022-03-30 01:10:15 | train] - Train Epoch: [49] [588800/1281167 (46%)]	Loss: 1.314075
[2022-03-30 01:10:35 | train] - Train Epoch: [49] [601600/1281167 (47%)]	Loss: 1.197164
[2022-03-30 01:10:57 | train] - Train Epoch: [49] [614400/1281167 (48%)]	Loss: 1.255648
[2022-03-30 01:11:18 | train] - Train Epoch: [49] [627200/1281167 (49%)]	Loss: 1.158126
[2022-03-30 01:11:39 | train] - Train Epoch: [49] [640000/1281167 (50%)]	Loss: 1.295725
[2022-03-30 01:12:00 | train] - Train Epoch: [49] [652800/1281167 (51%)]	Loss: 1.108986
[2022-03-30 01:12:20 | train] - Train Epoch: [49] [665600/1281167 (52%)]	Loss: 1.002074
[2022-03-30 01:12:42 | train] - Train Epoch: [49] [678400/1281167 (53%)]	Loss: 1.208447
[2022-03-30 01:13:03 | train] - Train Epoch: [49] [691200/1281167 (54%)]	Loss: 1.434253
[2022-03-30 01:13:25 | train] - Train Epoch: [49] [704000/1281167 (55%)]	Loss: 1.372740
[2022-03-30 01:13:46 | train] - Train Epoch: [49] [716800/1281167 (56%)]	Loss: 1.239449
[2022-03-30 01:14:09 | train] - Train Epoch: [49] [729600/1281167 (57%)]	Loss: 1.244226
[2022-03-30 01:14:30 | train] - Train Epoch: [49] [742400/1281167 (58%)]	Loss: 1.543816
[2022-03-30 01:14:51 | train] - Train Epoch: [49] [755200/1281167 (59%)]	Loss: 1.278277
[2022-03-30 01:15:12 | train] - Train Epoch: [49] [768000/1281167 (60%)]	Loss: 1.153254
[2022-03-30 01:15:33 | train] - Train Epoch: [49] [780800/1281167 (61%)]	Loss: 1.515510
[2022-03-30 01:15:55 | train] - Train Epoch: [49] [793600/1281167 (62%)]	Loss: 1.386963
[2022-03-30 01:16:16 | train] - Train Epoch: [49] [806400/1281167 (63%)]	Loss: 0.972285
[2022-03-30 01:16:37 | train] - Train Epoch: [49] [819200/1281167 (64%)]	Loss: 1.258188
[2022-03-30 01:16:59 | train] - Train Epoch: [49] [832000/1281167 (65%)]	Loss: 0.991989
[2022-03-30 01:17:20 | train] - Train Epoch: [49] [844800/1281167 (66%)]	Loss: 1.169799
[2022-03-30 01:17:41 | train] - Train Epoch: [49] [857600/1281167 (67%)]	Loss: 1.159175
[2022-03-30 01:18:03 | train] - Train Epoch: [49] [870400/1281167 (68%)]	Loss: 1.467847
[2022-03-30 01:18:24 | train] - Train Epoch: [49] [883200/1281167 (69%)]	Loss: 1.269800
[2022-03-30 01:18:46 | train] - Train Epoch: [49] [896000/1281167 (70%)]	Loss: 1.166434
[2022-03-30 01:19:07 | train] - Train Epoch: [49] [908800/1281167 (71%)]	Loss: 0.911516
[2022-03-30 01:19:28 | train] - Train Epoch: [49] [921600/1281167 (72%)]	Loss: 1.439147
[2022-03-30 01:19:50 | train] - Train Epoch: [49] [934400/1281167 (73%)]	Loss: 1.381276
[2022-03-30 01:20:11 | train] - Train Epoch: [49] [947200/1281167 (74%)]	Loss: 1.117919
[2022-03-30 01:20:32 | train] - Train Epoch: [49] [960000/1281167 (75%)]	Loss: 1.191568
[2022-03-30 01:20:53 | train] - Train Epoch: [49] [972800/1281167 (76%)]	Loss: 1.179330
[2022-03-30 01:21:14 | train] - Train Epoch: [49] [985600/1281167 (77%)]	Loss: 1.042628
[2022-03-30 01:21:35 | train] - Train Epoch: [49] [998400/1281167 (78%)]	Loss: 1.243013
[2022-03-30 01:21:56 | train] - Train Epoch: [49] [1011200/1281167 (79%)]	Loss: 1.049680
[2022-03-30 01:22:17 | train] - Train Epoch: [49] [1024000/1281167 (80%)]	Loss: 1.093588
[2022-03-30 01:22:36 | train] - Train Epoch: [49] [1036800/1281167 (81%)]	Loss: 1.132304
[2022-03-30 01:22:58 | train] - Train Epoch: [49] [1049600/1281167 (82%)]	Loss: 1.403549
[2022-03-30 01:23:19 | train] - Train Epoch: [49] [1062400/1281167 (83%)]	Loss: 1.101687
[2022-03-30 01:23:40 | train] - Train Epoch: [49] [1075200/1281167 (84%)]	Loss: 1.243739
[2022-03-30 01:24:02 | train] - Train Epoch: [49] [1088000/1281167 (85%)]	Loss: 1.246411
[2022-03-30 01:24:23 | train] - Train Epoch: [49] [1100800/1281167 (86%)]	Loss: 1.502965
[2022-03-30 01:24:43 | train] - Train Epoch: [49] [1113600/1281167 (87%)]	Loss: 1.406370
[2022-03-30 01:25:04 | train] - Train Epoch: [49] [1126400/1281167 (88%)]	Loss: 1.235809
[2022-03-30 01:25:25 | train] - Train Epoch: [49] [1139200/1281167 (89%)]	Loss: 1.521057
[2022-03-30 01:25:46 | train] - Train Epoch: [49] [1152000/1281167 (90%)]	Loss: 0.930016
[2022-03-30 01:26:06 | train] - Train Epoch: [49] [1164800/1281167 (91%)]	Loss: 1.299808
[2022-03-30 01:26:27 | train] - Train Epoch: [49] [1177600/1281167 (92%)]	Loss: 1.195645
[2022-03-30 01:26:48 | train] - Train Epoch: [49] [1190400/1281167 (93%)]	Loss: 1.214598
[2022-03-30 01:27:08 | train] - Train Epoch: [49] [1203200/1281167 (94%)]	Loss: 1.434891
[2022-03-30 01:27:29 | train] - Train Epoch: [49] [1216000/1281167 (95%)]	Loss: 1.364557
[2022-03-30 01:27:51 | train] - Train Epoch: [49] [1228800/1281167 (96%)]	Loss: 1.216996
[2022-03-30 01:28:13 | train] - Train Epoch: [49] [1241600/1281167 (97%)]	Loss: 0.943462
[2022-03-30 01:28:33 | train] - Train Epoch: [49] [1254400/1281167 (98%)]	Loss: 1.175180
[2022-03-30 01:28:53 | train] - Train Epoch: [49] [1267200/1281167 (99%)]	Loss: 1.190158
[2022-03-30 01:29:15 | train] - Train Epoch: [49] [1280000/1281167 (100%)]	Loss: 1.119027
[2022-03-30 01:29:17 | train] - Train Epoch: [49]	 Average Loss: 1.236345	 Total Acc : 70.2075	 Total Top5 Acc : 88.0825
[2022-03-30 01:29:20 | train] - -------49 epoch end-----------
========================================
-------49 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 01:31:06 | train] - 
Epoch [49] Test set: Average loss: 1.3576, Accuracy: 34083/50000 (68.1306%), Top-5 Accuracy: 88.1614%

[2022-03-30 01:31:06 | train] - save intermediate epoch [49] result


[2022-03-30 01:31:18 | train] - -------50 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 01:31:21 | train] - Train Epoch: [50] [0/1281167 (0%)]	Loss: 1.274435
[2022-03-30 01:31:45 | train] - Train Epoch: [50] [12800/1281167 (1%)]	Loss: 1.461600
[2022-03-30 01:32:08 | train] - Train Epoch: [50] [25600/1281167 (2%)]	Loss: 1.217502
[2022-03-30 01:32:30 | train] - Train Epoch: [50] [38400/1281167 (3%)]	Loss: 0.912149
[2022-03-30 01:32:51 | train] - Train Epoch: [50] [51200/1281167 (4%)]	Loss: 1.529002
[2022-03-30 01:33:13 | train] - Train Epoch: [50] [64000/1281167 (5%)]	Loss: 1.211485
[2022-03-30 01:33:34 | train] - Train Epoch: [50] [76800/1281167 (6%)]	Loss: 1.231827
[2022-03-30 01:33:56 | train] - Train Epoch: [50] [89600/1281167 (7%)]	Loss: 1.485522
[2022-03-30 01:34:18 | train] - Train Epoch: [50] [102400/1281167 (8%)]	Loss: 1.303752
[2022-03-30 01:34:39 | train] - Train Epoch: [50] [115200/1281167 (9%)]	Loss: 1.166416
[2022-03-30 01:35:01 | train] - Train Epoch: [50] [128000/1281167 (10%)]	Loss: 1.083209
[2022-03-30 01:35:22 | train] - Train Epoch: [50] [140800/1281167 (11%)]	Loss: 1.162964
[2022-03-30 01:35:44 | train] - Train Epoch: [50] [153600/1281167 (12%)]	Loss: 1.086529
[2022-03-30 01:36:06 | train] - Train Epoch: [50] [166400/1281167 (13%)]	Loss: 1.042208
[2022-03-30 01:36:27 | train] - Train Epoch: [50] [179200/1281167 (14%)]	Loss: 1.035387
[2022-03-30 01:36:48 | train] - Train Epoch: [50] [192000/1281167 (15%)]	Loss: 1.217254
[2022-03-30 01:37:10 | train] - Train Epoch: [50] [204800/1281167 (16%)]	Loss: 1.091254
[2022-03-30 01:37:31 | train] - Train Epoch: [50] [217600/1281167 (17%)]	Loss: 1.127291
[2022-03-30 01:37:52 | train] - Train Epoch: [50] [230400/1281167 (18%)]	Loss: 1.183426
[2022-03-30 01:38:15 | train] - Train Epoch: [50] [243200/1281167 (19%)]	Loss: 1.092971
[2022-03-30 01:38:36 | train] - Train Epoch: [50] [256000/1281167 (20%)]	Loss: 1.442818
[2022-03-30 01:38:58 | train] - Train Epoch: [50] [268800/1281167 (21%)]	Loss: 1.078374
[2022-03-30 01:39:20 | train] - Train Epoch: [50] [281600/1281167 (22%)]	Loss: 1.125552
[2022-03-30 01:39:41 | train] - Train Epoch: [50] [294400/1281167 (23%)]	Loss: 1.503701
[2022-03-30 01:40:03 | train] - Train Epoch: [50] [307200/1281167 (24%)]	Loss: 1.431842
[2022-03-30 01:40:24 | train] - Train Epoch: [50] [320000/1281167 (25%)]	Loss: 1.479469
[2022-03-30 01:40:46 | train] - Train Epoch: [50] [332800/1281167 (26%)]	Loss: 1.328477
[2022-03-30 01:41:08 | train] - Train Epoch: [50] [345600/1281167 (27%)]	Loss: 1.297650
[2022-03-30 01:41:29 | train] - Train Epoch: [50] [358400/1281167 (28%)]	Loss: 1.307347
[2022-03-30 01:41:50 | train] - Train Epoch: [50] [371200/1281167 (29%)]	Loss: 1.329751
[2022-03-30 01:42:12 | train] - Train Epoch: [50] [384000/1281167 (30%)]	Loss: 0.890811
[2022-03-30 01:42:34 | train] - Train Epoch: [50] [396800/1281167 (31%)]	Loss: 0.996899
[2022-03-30 01:42:56 | train] - Train Epoch: [50] [409600/1281167 (32%)]	Loss: 1.102141
[2022-03-30 01:43:19 | train] - Train Epoch: [50] [422400/1281167 (33%)]	Loss: 1.318880
[2022-03-30 01:43:40 | train] - Train Epoch: [50] [435200/1281167 (34%)]	Loss: 1.196596
[2022-03-30 01:44:02 | train] - Train Epoch: [50] [448000/1281167 (35%)]	Loss: 1.150836
[2022-03-30 01:44:23 | train] - Train Epoch: [50] [460800/1281167 (36%)]	Loss: 1.232005
[2022-03-30 01:44:45 | train] - Train Epoch: [50] [473600/1281167 (37%)]	Loss: 1.382213
[2022-03-30 01:45:07 | train] - Train Epoch: [50] [486400/1281167 (38%)]	Loss: 1.188412
[2022-03-30 01:45:28 | train] - Train Epoch: [50] [499200/1281167 (39%)]	Loss: 1.113827
[2022-03-30 01:45:49 | train] - Train Epoch: [50] [512000/1281167 (40%)]	Loss: 1.118843
[2022-03-30 01:46:11 | train] - Train Epoch: [50] [524800/1281167 (41%)]	Loss: 1.294345
[2022-03-30 01:46:33 | train] - Train Epoch: [50] [537600/1281167 (42%)]	Loss: 1.033087
[2022-03-30 01:46:54 | train] - Train Epoch: [50] [550400/1281167 (43%)]	Loss: 1.205212
[2022-03-30 01:47:16 | train] - Train Epoch: [50] [563200/1281167 (44%)]	Loss: 1.206519
[2022-03-30 01:47:37 | train] - Train Epoch: [50] [576000/1281167 (45%)]	Loss: 1.214086
[2022-03-30 01:47:59 | train] - Train Epoch: [50] [588800/1281167 (46%)]	Loss: 0.978390
[2022-03-30 01:48:20 | train] - Train Epoch: [50] [601600/1281167 (47%)]	Loss: 1.209943
[2022-03-30 01:48:42 | train] - Train Epoch: [50] [614400/1281167 (48%)]	Loss: 1.176322
[2022-03-30 01:49:04 | train] - Train Epoch: [50] [627200/1281167 (49%)]	Loss: 1.008274
[2022-03-30 01:49:25 | train] - Train Epoch: [50] [640000/1281167 (50%)]	Loss: 1.169755
[2022-03-30 01:49:46 | train] - Train Epoch: [50] [652800/1281167 (51%)]	Loss: 1.400411
[2022-03-30 01:50:07 | train] - Train Epoch: [50] [665600/1281167 (52%)]	Loss: 1.289828
[2022-03-30 01:50:29 | train] - Train Epoch: [50] [678400/1281167 (53%)]	Loss: 1.307125
[2022-03-30 01:50:51 | train] - Train Epoch: [50] [691200/1281167 (54%)]	Loss: 1.032758
[2022-03-30 01:51:13 | train] - Train Epoch: [50] [704000/1281167 (55%)]	Loss: 1.068172
[2022-03-30 01:51:36 | train] - Train Epoch: [50] [716800/1281167 (56%)]	Loss: 1.241320
[2022-03-30 01:51:57 | train] - Train Epoch: [50] [729600/1281167 (57%)]	Loss: 1.185831
[2022-03-30 01:52:19 | train] - Train Epoch: [50] [742400/1281167 (58%)]	Loss: 1.493833
[2022-03-30 01:52:42 | train] - Train Epoch: [50] [755200/1281167 (59%)]	Loss: 1.134213
[2022-03-30 01:53:05 | train] - Train Epoch: [50] [768000/1281167 (60%)]	Loss: 1.158006
[2022-03-30 01:53:28 | train] - Train Epoch: [50] [780800/1281167 (61%)]	Loss: 1.469539
[2022-03-30 01:53:50 | train] - Train Epoch: [50] [793600/1281167 (62%)]	Loss: 1.136219
[2022-03-30 01:54:13 | train] - Train Epoch: [50] [806400/1281167 (63%)]	Loss: 1.084505
[2022-03-30 01:54:36 | train] - Train Epoch: [50] [819200/1281167 (64%)]	Loss: 1.192524
[2022-03-30 01:54:59 | train] - Train Epoch: [50] [832000/1281167 (65%)]	Loss: 1.619563
[2022-03-30 01:55:21 | train] - Train Epoch: [50] [844800/1281167 (66%)]	Loss: 1.143613
[2022-03-30 01:55:44 | train] - Train Epoch: [50] [857600/1281167 (67%)]	Loss: 1.497055
[2022-03-30 01:56:05 | train] - Train Epoch: [50] [870400/1281167 (68%)]	Loss: 1.270640
[2022-03-30 01:56:27 | train] - Train Epoch: [50] [883200/1281167 (69%)]	Loss: 1.105848
[2022-03-30 01:56:50 | train] - Train Epoch: [50] [896000/1281167 (70%)]	Loss: 0.959375
[2022-03-30 01:57:11 | train] - Train Epoch: [50] [908800/1281167 (71%)]	Loss: 1.241582
[2022-03-30 01:57:33 | train] - Train Epoch: [50] [921600/1281167 (72%)]	Loss: 1.574396
[2022-03-30 01:57:54 | train] - Train Epoch: [50] [934400/1281167 (73%)]	Loss: 1.105259
[2022-03-30 01:58:17 | train] - Train Epoch: [50] [947200/1281167 (74%)]	Loss: 1.064904
[2022-03-30 01:58:39 | train] - Train Epoch: [50] [960000/1281167 (75%)]	Loss: 1.403531
[2022-03-30 01:59:02 | train] - Train Epoch: [50] [972800/1281167 (76%)]	Loss: 1.165995
[2022-03-30 01:59:24 | train] - Train Epoch: [50] [985600/1281167 (77%)]	Loss: 1.410334
[2022-03-30 01:59:46 | train] - Train Epoch: [50] [998400/1281167 (78%)]	Loss: 1.608736
[2022-03-30 02:00:07 | train] - Train Epoch: [50] [1011200/1281167 (79%)]	Loss: 1.312380
[2022-03-30 02:00:29 | train] - Train Epoch: [50] [1024000/1281167 (80%)]	Loss: 1.429567
[2022-03-30 02:00:51 | train] - Train Epoch: [50] [1036800/1281167 (81%)]	Loss: 1.023471
[2022-03-30 02:01:11 | train] - Train Epoch: [50] [1049600/1281167 (82%)]	Loss: 1.319986
[2022-03-30 02:01:33 | train] - Train Epoch: [50] [1062400/1281167 (83%)]	Loss: 1.237323
[2022-03-30 02:01:57 | train] - Train Epoch: [50] [1075200/1281167 (84%)]	Loss: 1.376768
[2022-03-30 02:02:19 | train] - Train Epoch: [50] [1088000/1281167 (85%)]	Loss: 1.463172
[2022-03-30 02:02:40 | train] - Train Epoch: [50] [1100800/1281167 (86%)]	Loss: 1.445570
[2022-03-30 02:03:02 | train] - Train Epoch: [50] [1113600/1281167 (87%)]	Loss: 0.949249
[2022-03-30 02:03:24 | train] - Train Epoch: [50] [1126400/1281167 (88%)]	Loss: 1.174345
[2022-03-30 02:03:46 | train] - Train Epoch: [50] [1139200/1281167 (89%)]	Loss: 1.119531
[2022-03-30 02:04:06 | train] - Train Epoch: [50] [1152000/1281167 (90%)]	Loss: 1.156718
[2022-03-30 02:04:28 | train] - Train Epoch: [50] [1164800/1281167 (91%)]	Loss: 1.019476
[2022-03-30 02:04:50 | train] - Train Epoch: [50] [1177600/1281167 (92%)]	Loss: 1.387758
[2022-03-30 02:05:12 | train] - Train Epoch: [50] [1190400/1281167 (93%)]	Loss: 1.059221
[2022-03-30 02:05:34 | train] - Train Epoch: [50] [1203200/1281167 (94%)]	Loss: 1.143847
[2022-03-30 02:05:56 | train] - Train Epoch: [50] [1216000/1281167 (95%)]	Loss: 1.159793
[2022-03-30 02:06:17 | train] - Train Epoch: [50] [1228800/1281167 (96%)]	Loss: 1.310351
[2022-03-30 02:06:39 | train] - Train Epoch: [50] [1241600/1281167 (97%)]	Loss: 1.047328
[2022-03-30 02:07:00 | train] - Train Epoch: [50] [1254400/1281167 (98%)]	Loss: 1.271472
[2022-03-30 02:07:21 | train] - Train Epoch: [50] [1267200/1281167 (99%)]	Loss: 1.409102
[2022-03-30 02:07:43 | train] - Train Epoch: [50] [1280000/1281167 (100%)]	Loss: 1.456713
[2022-03-30 02:07:46 | train] - Train Epoch: [50]	 Average Loss: 1.227815	 Total Acc : 70.3792	 Total Top5 Acc : 88.1555
[2022-03-30 02:07:48 | train] - -------50 epoch end-----------
========================================
-------50 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 02:09:32 | train] - 
Epoch [50] Test set: Average loss: 1.4037, Accuracy: 33837/50000 (67.6451%), Top-5 Accuracy: 87.7094%

[2022-03-30 02:09:32 | train] - save intermediate epoch [50] result


[2022-03-30 02:09:46 | train] - -------51 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 02:09:49 | train] - Train Epoch: [51] [0/1281167 (0%)]	Loss: 1.132042
[2022-03-30 02:10:11 | train] - Train Epoch: [51] [12800/1281167 (1%)]	Loss: 1.363386
[2022-03-30 02:10:34 | train] - Train Epoch: [51] [25600/1281167 (2%)]	Loss: 1.331659
[2022-03-30 02:10:58 | train] - Train Epoch: [51] [38400/1281167 (3%)]	Loss: 1.166337
[2022-03-30 02:11:21 | train] - Train Epoch: [51] [51200/1281167 (4%)]	Loss: 1.296374
[2022-03-30 02:11:44 | train] - Train Epoch: [51] [64000/1281167 (5%)]	Loss: 1.009983
[2022-03-30 02:12:07 | train] - Train Epoch: [51] [76800/1281167 (6%)]	Loss: 1.125043
[2022-03-30 02:12:30 | train] - Train Epoch: [51] [89600/1281167 (7%)]	Loss: 1.072858
[2022-03-30 02:12:53 | train] - Train Epoch: [51] [102400/1281167 (8%)]	Loss: 1.183212
[2022-03-30 02:13:16 | train] - Train Epoch: [51] [115200/1281167 (9%)]	Loss: 1.108891
[2022-03-30 02:13:39 | train] - Train Epoch: [51] [128000/1281167 (10%)]	Loss: 1.541070
[2022-03-30 02:14:01 | train] - Train Epoch: [51] [140800/1281167 (11%)]	Loss: 1.096712
[2022-03-30 02:14:23 | train] - Train Epoch: [51] [153600/1281167 (12%)]	Loss: 1.311495
[2022-03-30 02:14:45 | train] - Train Epoch: [51] [166400/1281167 (13%)]	Loss: 1.183525
[2022-03-30 02:15:07 | train] - Train Epoch: [51] [179200/1281167 (14%)]	Loss: 1.336703
[2022-03-30 02:15:29 | train] - Train Epoch: [51] [192000/1281167 (15%)]	Loss: 1.188558
[2022-03-30 02:15:50 | train] - Train Epoch: [51] [204800/1281167 (16%)]	Loss: 1.056928
[2022-03-30 02:16:12 | train] - Train Epoch: [51] [217600/1281167 (17%)]	Loss: 1.077178
[2022-03-30 02:16:33 | train] - Train Epoch: [51] [230400/1281167 (18%)]	Loss: 1.054174
[2022-03-30 02:16:55 | train] - Train Epoch: [51] [243200/1281167 (19%)]	Loss: 1.013193
[2022-03-30 02:17:17 | train] - Train Epoch: [51] [256000/1281167 (20%)]	Loss: 1.170993
[2022-03-30 02:17:37 | train] - Train Epoch: [51] [268800/1281167 (21%)]	Loss: 1.247679
[2022-03-30 02:17:58 | train] - Train Epoch: [51] [281600/1281167 (22%)]	Loss: 1.208290
[2022-03-30 02:18:19 | train] - Train Epoch: [51] [294400/1281167 (23%)]	Loss: 0.990929
[2022-03-30 02:18:39 | train] - Train Epoch: [51] [307200/1281167 (24%)]	Loss: 1.277752
[2022-03-30 02:19:01 | train] - Train Epoch: [51] [320000/1281167 (25%)]	Loss: 0.823142
[2022-03-30 02:19:22 | train] - Train Epoch: [51] [332800/1281167 (26%)]	Loss: 1.252925
[2022-03-30 02:19:43 | train] - Train Epoch: [51] [345600/1281167 (27%)]	Loss: 1.090995
[2022-03-30 02:20:04 | train] - Train Epoch: [51] [358400/1281167 (28%)]	Loss: 1.083472
[2022-03-30 02:20:25 | train] - Train Epoch: [51] [371200/1281167 (29%)]	Loss: 1.416348
[2022-03-30 02:20:46 | train] - Train Epoch: [51] [384000/1281167 (30%)]	Loss: 1.160840
[2022-03-30 02:21:07 | train] - Train Epoch: [51] [396800/1281167 (31%)]	Loss: 1.019457
[2022-03-30 02:21:28 | train] - Train Epoch: [51] [409600/1281167 (32%)]	Loss: 1.053566
[2022-03-30 02:21:50 | train] - Train Epoch: [51] [422400/1281167 (33%)]	Loss: 1.226677
[2022-03-30 02:22:11 | train] - Train Epoch: [51] [435200/1281167 (34%)]	Loss: 1.315397
[2022-03-30 02:22:31 | train] - Train Epoch: [51] [448000/1281167 (35%)]	Loss: 1.257314
[2022-03-30 02:22:52 | train] - Train Epoch: [51] [460800/1281167 (36%)]	Loss: 1.165335
[2022-03-30 02:23:14 | train] - Train Epoch: [51] [473600/1281167 (37%)]	Loss: 1.360435
[2022-03-30 02:23:35 | train] - Train Epoch: [51] [486400/1281167 (38%)]	Loss: 1.185493
[2022-03-30 02:23:57 | train] - Train Epoch: [51] [499200/1281167 (39%)]	Loss: 1.508341
[2022-03-30 02:24:18 | train] - Train Epoch: [51] [512000/1281167 (40%)]	Loss: 0.873869
[2022-03-30 02:24:38 | train] - Train Epoch: [51] [524800/1281167 (41%)]	Loss: 1.253154
[2022-03-30 02:24:58 | train] - Train Epoch: [51] [537600/1281167 (42%)]	Loss: 1.263703
[2022-03-30 02:25:21 | train] - Train Epoch: [51] [550400/1281167 (43%)]	Loss: 1.041969
[2022-03-30 02:25:43 | train] - Train Epoch: [51] [563200/1281167 (44%)]	Loss: 1.188304
[2022-03-30 02:26:05 | train] - Train Epoch: [51] [576000/1281167 (45%)]	Loss: 0.828074
[2022-03-30 02:26:26 | train] - Train Epoch: [51] [588800/1281167 (46%)]	Loss: 1.623056
[2022-03-30 02:26:48 | train] - Train Epoch: [51] [601600/1281167 (47%)]	Loss: 1.091592
[2022-03-30 02:27:09 | train] - Train Epoch: [51] [614400/1281167 (48%)]	Loss: 1.201638
[2022-03-30 02:27:31 | train] - Train Epoch: [51] [627200/1281167 (49%)]	Loss: 1.115409
[2022-03-30 02:27:51 | train] - Train Epoch: [51] [640000/1281167 (50%)]	Loss: 1.017158
[2022-03-30 02:28:14 | train] - Train Epoch: [51] [652800/1281167 (51%)]	Loss: 1.434149
[2022-03-30 02:28:36 | train] - Train Epoch: [51] [665600/1281167 (52%)]	Loss: 1.234627
[2022-03-30 02:28:57 | train] - Train Epoch: [51] [678400/1281167 (53%)]	Loss: 1.197077
[2022-03-30 02:29:18 | train] - Train Epoch: [51] [691200/1281167 (54%)]	Loss: 1.053774
[2022-03-30 02:29:38 | train] - Train Epoch: [51] [704000/1281167 (55%)]	Loss: 1.302023
[2022-03-30 02:30:00 | train] - Train Epoch: [51] [716800/1281167 (56%)]	Loss: 1.028167
[2022-03-30 02:30:22 | train] - Train Epoch: [51] [729600/1281167 (57%)]	Loss: 1.189607
[2022-03-30 02:30:43 | train] - Train Epoch: [51] [742400/1281167 (58%)]	Loss: 1.237448
[2022-03-30 02:31:05 | train] - Train Epoch: [51] [755200/1281167 (59%)]	Loss: 1.246549
[2022-03-30 02:31:26 | train] - Train Epoch: [51] [768000/1281167 (60%)]	Loss: 1.152361
[2022-03-30 02:31:47 | train] - Train Epoch: [51] [780800/1281167 (61%)]	Loss: 1.344838
[2022-03-30 02:32:07 | train] - Train Epoch: [51] [793600/1281167 (62%)]	Loss: 1.295687
[2022-03-30 02:32:30 | train] - Train Epoch: [51] [806400/1281167 (63%)]	Loss: 1.483183
[2022-03-30 02:32:52 | train] - Train Epoch: [51] [819200/1281167 (64%)]	Loss: 1.280184
[2022-03-30 02:33:13 | train] - Train Epoch: [51] [832000/1281167 (65%)]	Loss: 1.204719
[2022-03-30 02:33:33 | train] - Train Epoch: [51] [844800/1281167 (66%)]	Loss: 1.350009
[2022-03-30 02:33:54 | train] - Train Epoch: [51] [857600/1281167 (67%)]	Loss: 1.108112
[2022-03-30 02:34:15 | train] - Train Epoch: [51] [870400/1281167 (68%)]	Loss: 1.133098
[2022-03-30 02:34:36 | train] - Train Epoch: [51] [883200/1281167 (69%)]	Loss: 1.110707
[2022-03-30 02:34:58 | train] - Train Epoch: [51] [896000/1281167 (70%)]	Loss: 1.397852
[2022-03-30 02:35:19 | train] - Train Epoch: [51] [908800/1281167 (71%)]	Loss: 1.038932
[2022-03-30 02:35:40 | train] - Train Epoch: [51] [921600/1281167 (72%)]	Loss: 1.115515
[2022-03-30 02:36:01 | train] - Train Epoch: [51] [934400/1281167 (73%)]	Loss: 1.337562
[2022-03-30 02:36:22 | train] - Train Epoch: [51] [947200/1281167 (74%)]	Loss: 1.340032
[2022-03-30 02:36:43 | train] - Train Epoch: [51] [960000/1281167 (75%)]	Loss: 1.278126
[2022-03-30 02:37:06 | train] - Train Epoch: [51] [972800/1281167 (76%)]	Loss: 1.114752
[2022-03-30 02:37:26 | train] - Train Epoch: [51] [985600/1281167 (77%)]	Loss: 1.067965
[2022-03-30 02:37:48 | train] - Train Epoch: [51] [998400/1281167 (78%)]	Loss: 1.197241
[2022-03-30 02:38:10 | train] - Train Epoch: [51] [1011200/1281167 (79%)]	Loss: 1.306383
[2022-03-30 02:38:31 | train] - Train Epoch: [51] [1024000/1281167 (80%)]	Loss: 1.593506
[2022-03-30 02:38:51 | train] - Train Epoch: [51] [1036800/1281167 (81%)]	Loss: 0.906743
[2022-03-30 02:39:11 | train] - Train Epoch: [51] [1049600/1281167 (82%)]	Loss: 1.145360
[2022-03-30 02:39:33 | train] - Train Epoch: [51] [1062400/1281167 (83%)]	Loss: 1.085454
[2022-03-30 02:39:55 | train] - Train Epoch: [51] [1075200/1281167 (84%)]	Loss: 1.045031
[2022-03-30 02:40:15 | train] - Train Epoch: [51] [1088000/1281167 (85%)]	Loss: 1.385059
[2022-03-30 02:40:34 | train] - Train Epoch: [51] [1100800/1281167 (86%)]	Loss: 1.190221
[2022-03-30 02:40:55 | train] - Train Epoch: [51] [1113600/1281167 (87%)]	Loss: 1.012905
[2022-03-30 02:41:16 | train] - Train Epoch: [51] [1126400/1281167 (88%)]	Loss: 1.353192
[2022-03-30 02:41:37 | train] - Train Epoch: [51] [1139200/1281167 (89%)]	Loss: 1.264055
[2022-03-30 02:41:58 | train] - Train Epoch: [51] [1152000/1281167 (90%)]	Loss: 1.213667
[2022-03-30 02:42:20 | train] - Train Epoch: [51] [1164800/1281167 (91%)]	Loss: 1.255206
[2022-03-30 02:42:41 | train] - Train Epoch: [51] [1177600/1281167 (92%)]	Loss: 1.214706
[2022-03-30 02:43:02 | train] - Train Epoch: [51] [1190400/1281167 (93%)]	Loss: 1.007700
[2022-03-30 02:43:23 | train] - Train Epoch: [51] [1203200/1281167 (94%)]	Loss: 1.153665
[2022-03-30 02:43:44 | train] - Train Epoch: [51] [1216000/1281167 (95%)]	Loss: 1.131106
[2022-03-30 02:44:04 | train] - Train Epoch: [51] [1228800/1281167 (96%)]	Loss: 1.126210
[2022-03-30 02:44:25 | train] - Train Epoch: [51] [1241600/1281167 (97%)]	Loss: 1.286612
[2022-03-30 02:44:46 | train] - Train Epoch: [51] [1254400/1281167 (98%)]	Loss: 1.158092
[2022-03-30 02:45:08 | train] - Train Epoch: [51] [1267200/1281167 (99%)]	Loss: 1.198560
[2022-03-30 02:45:29 | train] - Train Epoch: [51] [1280000/1281167 (100%)]	Loss: 1.127900
[2022-03-30 02:45:32 | train] - Train Epoch: [51]	 Average Loss: 1.216985	 Total Acc : 70.6089	 Total Top5 Acc : 88.3081
[2022-03-30 02:45:34 | train] - -------51 epoch end-----------
========================================
-------51 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 02:47:18 | train] - 
Epoch [51] Test set: Average loss: 1.3925, Accuracy: 33947/50000 (67.8636%), Top-5 Accuracy: 87.6806%

[2022-03-30 02:47:18 | train] - save intermediate epoch [51] result


[2022-03-30 02:47:33 | train] - -------52 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 02:47:35 | train] - Train Epoch: [52] [0/1281167 (0%)]	Loss: 1.311457
[2022-03-30 02:47:58 | train] - Train Epoch: [52] [12800/1281167 (1%)]	Loss: 1.238362
[2022-03-30 02:48:20 | train] - Train Epoch: [52] [25600/1281167 (2%)]	Loss: 1.346862
[2022-03-30 02:48:42 | train] - Train Epoch: [52] [38400/1281167 (3%)]	Loss: 1.363885
[2022-03-30 02:49:04 | train] - Train Epoch: [52] [51200/1281167 (4%)]	Loss: 0.990379
[2022-03-30 02:49:25 | train] - Train Epoch: [52] [64000/1281167 (5%)]	Loss: 1.118387
[2022-03-30 02:49:47 | train] - Train Epoch: [52] [76800/1281167 (6%)]	Loss: 1.176982
[2022-03-30 02:50:09 | train] - Train Epoch: [52] [89600/1281167 (7%)]	Loss: 1.180505
[2022-03-30 02:50:31 | train] - Train Epoch: [52] [102400/1281167 (8%)]	Loss: 1.106436
[2022-03-30 02:50:53 | train] - Train Epoch: [52] [115200/1281167 (9%)]	Loss: 1.023329
[2022-03-30 02:51:15 | train] - Train Epoch: [52] [128000/1281167 (10%)]	Loss: 1.150766
[2022-03-30 02:51:36 | train] - Train Epoch: [52] [140800/1281167 (11%)]	Loss: 1.015633
[2022-03-30 02:51:58 | train] - Train Epoch: [52] [153600/1281167 (12%)]	Loss: 0.798372
[2022-03-30 02:52:20 | train] - Train Epoch: [52] [166400/1281167 (13%)]	Loss: 1.179703
[2022-03-30 02:52:42 | train] - Train Epoch: [52] [179200/1281167 (14%)]	Loss: 1.121047
[2022-03-30 02:53:04 | train] - Train Epoch: [52] [192000/1281167 (15%)]	Loss: 0.749899
[2022-03-30 02:53:25 | train] - Train Epoch: [52] [204800/1281167 (16%)]	Loss: 1.177759
[2022-03-30 02:53:48 | train] - Train Epoch: [52] [217600/1281167 (17%)]	Loss: 1.414045
[2022-03-30 02:54:10 | train] - Train Epoch: [52] [230400/1281167 (18%)]	Loss: 1.435882
[2022-03-30 02:54:32 | train] - Train Epoch: [52] [243200/1281167 (19%)]	Loss: 0.854072
[2022-03-30 02:54:54 | train] - Train Epoch: [52] [256000/1281167 (20%)]	Loss: 1.073754
[2022-03-30 02:55:16 | train] - Train Epoch: [52] [268800/1281167 (21%)]	Loss: 1.006577
[2022-03-30 02:55:38 | train] - Train Epoch: [52] [281600/1281167 (22%)]	Loss: 1.133384
[2022-03-30 02:56:00 | train] - Train Epoch: [52] [294400/1281167 (23%)]	Loss: 1.356167
[2022-03-30 02:56:21 | train] - Train Epoch: [52] [307200/1281167 (24%)]	Loss: 1.181671
[2022-03-30 02:56:43 | train] - Train Epoch: [52] [320000/1281167 (25%)]	Loss: 1.265018
[2022-03-30 02:57:05 | train] - Train Epoch: [52] [332800/1281167 (26%)]	Loss: 1.213330
[2022-03-30 02:57:27 | train] - Train Epoch: [52] [345600/1281167 (27%)]	Loss: 1.143311
[2022-03-30 02:57:48 | train] - Train Epoch: [52] [358400/1281167 (28%)]	Loss: 0.915233
[2022-03-30 02:58:10 | train] - Train Epoch: [52] [371200/1281167 (29%)]	Loss: 0.996560
[2022-03-30 02:58:32 | train] - Train Epoch: [52] [384000/1281167 (30%)]	Loss: 1.141789
[2022-03-30 02:58:54 | train] - Train Epoch: [52] [396800/1281167 (31%)]	Loss: 1.059451
[2022-03-30 02:59:16 | train] - Train Epoch: [52] [409600/1281167 (32%)]	Loss: 1.188409
[2022-03-30 02:59:38 | train] - Train Epoch: [52] [422400/1281167 (33%)]	Loss: 1.262993
[2022-03-30 03:00:01 | train] - Train Epoch: [52] [435200/1281167 (34%)]	Loss: 1.229444
[2022-03-30 03:00:22 | train] - Train Epoch: [52] [448000/1281167 (35%)]	Loss: 1.275314
[2022-03-30 03:00:44 | train] - Train Epoch: [52] [460800/1281167 (36%)]	Loss: 1.093414
[2022-03-30 03:01:05 | train] - Train Epoch: [52] [473600/1281167 (37%)]	Loss: 1.113708
[2022-03-30 03:01:28 | train] - Train Epoch: [52] [486400/1281167 (38%)]	Loss: 1.086039
[2022-03-30 03:01:49 | train] - Train Epoch: [52] [499200/1281167 (39%)]	Loss: 0.939968
[2022-03-30 03:02:11 | train] - Train Epoch: [52] [512000/1281167 (40%)]	Loss: 1.061491
[2022-03-30 03:02:33 | train] - Train Epoch: [52] [524800/1281167 (41%)]	Loss: 1.472860
[2022-03-30 03:02:55 | train] - Train Epoch: [52] [537600/1281167 (42%)]	Loss: 1.131320
[2022-03-30 03:03:17 | train] - Train Epoch: [52] [550400/1281167 (43%)]	Loss: 1.000888
[2022-03-30 03:03:39 | train] - Train Epoch: [52] [563200/1281167 (44%)]	Loss: 1.551041
[2022-03-30 03:04:00 | train] - Train Epoch: [52] [576000/1281167 (45%)]	Loss: 1.315294
[2022-03-30 03:04:22 | train] - Train Epoch: [52] [588800/1281167 (46%)]	Loss: 0.995949
[2022-03-30 03:04:44 | train] - Train Epoch: [52] [601600/1281167 (47%)]	Loss: 1.261788
[2022-03-30 03:05:06 | train] - Train Epoch: [52] [614400/1281167 (48%)]	Loss: 1.069600
[2022-03-30 03:05:28 | train] - Train Epoch: [52] [627200/1281167 (49%)]	Loss: 1.292302
[2022-03-30 03:05:50 | train] - Train Epoch: [52] [640000/1281167 (50%)]	Loss: 1.000956
[2022-03-30 03:06:12 | train] - Train Epoch: [52] [652800/1281167 (51%)]	Loss: 1.298908
[2022-03-30 03:06:34 | train] - Train Epoch: [52] [665600/1281167 (52%)]	Loss: 1.167999
[2022-03-30 03:06:56 | train] - Train Epoch: [52] [678400/1281167 (53%)]	Loss: 1.193242
[2022-03-30 03:07:18 | train] - Train Epoch: [52] [691200/1281167 (54%)]	Loss: 1.298679
[2022-03-30 03:07:40 | train] - Train Epoch: [52] [704000/1281167 (55%)]	Loss: 1.010560
[2022-03-30 03:08:02 | train] - Train Epoch: [52] [716800/1281167 (56%)]	Loss: 1.100068
[2022-03-30 03:08:23 | train] - Train Epoch: [52] [729600/1281167 (57%)]	Loss: 1.287830
[2022-03-30 03:08:45 | train] - Train Epoch: [52] [742400/1281167 (58%)]	Loss: 1.249516
[2022-03-30 03:09:07 | train] - Train Epoch: [52] [755200/1281167 (59%)]	Loss: 1.208861
[2022-03-30 03:09:29 | train] - Train Epoch: [52] [768000/1281167 (60%)]	Loss: 1.422484
[2022-03-30 03:09:50 | train] - Train Epoch: [52] [780800/1281167 (61%)]	Loss: 1.308631
[2022-03-30 03:10:12 | train] - Train Epoch: [52] [793600/1281167 (62%)]	Loss: 1.151366
[2022-03-30 03:10:33 | train] - Train Epoch: [52] [806400/1281167 (63%)]	Loss: 1.080263
[2022-03-30 03:10:56 | train] - Train Epoch: [52] [819200/1281167 (64%)]	Loss: 1.394120
[2022-03-30 03:11:18 | train] - Train Epoch: [52] [832000/1281167 (65%)]	Loss: 1.349113
[2022-03-30 03:11:40 | train] - Train Epoch: [52] [844800/1281167 (66%)]	Loss: 1.131195
[2022-03-30 03:12:02 | train] - Train Epoch: [52] [857600/1281167 (67%)]	Loss: 1.343883
[2022-03-30 03:12:24 | train] - Train Epoch: [52] [870400/1281167 (68%)]	Loss: 1.243437
[2022-03-30 03:12:46 | train] - Train Epoch: [52] [883200/1281167 (69%)]	Loss: 1.090832
[2022-03-30 03:13:08 | train] - Train Epoch: [52] [896000/1281167 (70%)]	Loss: 1.269533
[2022-03-30 03:13:30 | train] - Train Epoch: [52] [908800/1281167 (71%)]	Loss: 1.112799
[2022-03-30 03:13:52 | train] - Train Epoch: [52] [921600/1281167 (72%)]	Loss: 1.332923
[2022-03-30 03:14:13 | train] - Train Epoch: [52] [934400/1281167 (73%)]	Loss: 1.139235
[2022-03-30 03:14:36 | train] - Train Epoch: [52] [947200/1281167 (74%)]	Loss: 1.331523
[2022-03-30 03:14:58 | train] - Train Epoch: [52] [960000/1281167 (75%)]	Loss: 1.326516
[2022-03-30 03:15:20 | train] - Train Epoch: [52] [972800/1281167 (76%)]	Loss: 1.338496
[2022-03-30 03:15:42 | train] - Train Epoch: [52] [985600/1281167 (77%)]	Loss: 1.362905
[2022-03-30 03:16:04 | train] - Train Epoch: [52] [998400/1281167 (78%)]	Loss: 1.080299
[2022-03-30 03:16:26 | train] - Train Epoch: [52] [1011200/1281167 (79%)]	Loss: 1.309291
[2022-03-30 03:16:47 | train] - Train Epoch: [52] [1024000/1281167 (80%)]	Loss: 1.110871
[2022-03-30 03:17:09 | train] - Train Epoch: [52] [1036800/1281167 (81%)]	Loss: 1.096865
[2022-03-30 03:17:31 | train] - Train Epoch: [52] [1049600/1281167 (82%)]	Loss: 1.032958
[2022-03-30 03:17:53 | train] - Train Epoch: [52] [1062400/1281167 (83%)]	Loss: 1.489016
[2022-03-30 03:18:15 | train] - Train Epoch: [52] [1075200/1281167 (84%)]	Loss: 1.112784
[2022-03-30 03:18:37 | train] - Train Epoch: [52] [1088000/1281167 (85%)]	Loss: 1.078195
[2022-03-30 03:18:58 | train] - Train Epoch: [52] [1100800/1281167 (86%)]	Loss: 1.397866
[2022-03-30 03:19:20 | train] - Train Epoch: [52] [1113600/1281167 (87%)]	Loss: 1.121461
[2022-03-30 03:19:43 | train] - Train Epoch: [52] [1126400/1281167 (88%)]	Loss: 1.122038
[2022-03-30 03:20:05 | train] - Train Epoch: [52] [1139200/1281167 (89%)]	Loss: 1.268518
[2022-03-30 03:20:27 | train] - Train Epoch: [52] [1152000/1281167 (90%)]	Loss: 1.185281
[2022-03-30 03:20:49 | train] - Train Epoch: [52] [1164800/1281167 (91%)]	Loss: 1.202389
[2022-03-30 03:21:10 | train] - Train Epoch: [52] [1177600/1281167 (92%)]	Loss: 1.303106
[2022-03-30 03:21:32 | train] - Train Epoch: [52] [1190400/1281167 (93%)]	Loss: 1.326168
[2022-03-30 03:21:53 | train] - Train Epoch: [52] [1203200/1281167 (94%)]	Loss: 1.681640
[2022-03-30 03:22:16 | train] - Train Epoch: [52] [1216000/1281167 (95%)]	Loss: 1.004750
[2022-03-30 03:22:38 | train] - Train Epoch: [52] [1228800/1281167 (96%)]	Loss: 1.075995
[2022-03-30 03:23:00 | train] - Train Epoch: [52] [1241600/1281167 (97%)]	Loss: 1.010542
[2022-03-30 03:23:22 | train] - Train Epoch: [52] [1254400/1281167 (98%)]	Loss: 1.436498
[2022-03-30 03:23:45 | train] - Train Epoch: [52] [1267200/1281167 (99%)]	Loss: 1.176525
[2022-03-30 03:24:07 | train] - Train Epoch: [52] [1280000/1281167 (100%)]	Loss: 1.112707
[2022-03-30 03:24:09 | train] - Train Epoch: [52]	 Average Loss: 1.208125	 Total Acc : 70.7758	 Total Top5 Acc : 88.4170
[2022-03-30 03:24:12 | train] - -------52 epoch end-----------
========================================
-------52 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 03:25:53 | train] - 
Epoch [52] Test set: Average loss: 1.3841, Accuracy: 33966/50000 (67.9076%), Top-5 Accuracy: 87.9368%

[2022-03-30 03:25:53 | train] - save intermediate epoch [52] result


[2022-03-30 03:26:08 | train] - -------53 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 03:26:10 | train] - Train Epoch: [53] [0/1281167 (0%)]	Loss: 1.049252
[2022-03-30 03:26:34 | train] - Train Epoch: [53] [12800/1281167 (1%)]	Loss: 0.893694
[2022-03-30 03:26:57 | train] - Train Epoch: [53] [25600/1281167 (2%)]	Loss: 0.884771
[2022-03-30 03:27:19 | train] - Train Epoch: [53] [38400/1281167 (3%)]	Loss: 1.296518
[2022-03-30 03:27:42 | train] - Train Epoch: [53] [51200/1281167 (4%)]	Loss: 1.368837
[2022-03-30 03:28:05 | train] - Train Epoch: [53] [64000/1281167 (5%)]	Loss: 1.363305
[2022-03-30 03:28:27 | train] - Train Epoch: [53] [76800/1281167 (6%)]	Loss: 1.220209
[2022-03-30 03:28:50 | train] - Train Epoch: [53] [89600/1281167 (7%)]	Loss: 1.349183
[2022-03-30 03:29:12 | train] - Train Epoch: [53] [102400/1281167 (8%)]	Loss: 0.904828
[2022-03-30 03:29:35 | train] - Train Epoch: [53] [115200/1281167 (9%)]	Loss: 1.101916
[2022-03-30 03:29:56 | train] - Train Epoch: [53] [128000/1281167 (10%)]	Loss: 1.145261
[2022-03-30 03:30:18 | train] - Train Epoch: [53] [140800/1281167 (11%)]	Loss: 1.348419
[2022-03-30 03:30:41 | train] - Train Epoch: [53] [153600/1281167 (12%)]	Loss: 1.381120
[2022-03-30 03:31:02 | train] - Train Epoch: [53] [166400/1281167 (13%)]	Loss: 1.096989
[2022-03-30 03:31:23 | train] - Train Epoch: [53] [179200/1281167 (14%)]	Loss: 1.145380
[2022-03-30 03:31:44 | train] - Train Epoch: [53] [192000/1281167 (15%)]	Loss: 1.187415
[2022-03-30 03:32:06 | train] - Train Epoch: [53] [204800/1281167 (16%)]	Loss: 0.929660
[2022-03-30 03:32:29 | train] - Train Epoch: [53] [217600/1281167 (17%)]	Loss: 1.514230
[2022-03-30 03:32:50 | train] - Train Epoch: [53] [230400/1281167 (18%)]	Loss: 1.247613
[2022-03-30 03:33:12 | train] - Train Epoch: [53] [243200/1281167 (19%)]	Loss: 1.413430
[2022-03-30 03:33:33 | train] - Train Epoch: [53] [256000/1281167 (20%)]	Loss: 1.220310
[2022-03-30 03:33:54 | train] - Train Epoch: [53] [268800/1281167 (21%)]	Loss: 1.254938
[2022-03-30 03:34:16 | train] - Train Epoch: [53] [281600/1281167 (22%)]	Loss: 1.205792
[2022-03-30 03:34:37 | train] - Train Epoch: [53] [294400/1281167 (23%)]	Loss: 0.999329
[2022-03-30 03:34:58 | train] - Train Epoch: [53] [307200/1281167 (24%)]	Loss: 1.103072
[2022-03-30 03:35:20 | train] - Train Epoch: [53] [320000/1281167 (25%)]	Loss: 0.902900
[2022-03-30 03:35:40 | train] - Train Epoch: [53] [332800/1281167 (26%)]	Loss: 1.316824
[2022-03-30 03:36:01 | train] - Train Epoch: [53] [345600/1281167 (27%)]	Loss: 1.091365
[2022-03-30 03:36:22 | train] - Train Epoch: [53] [358400/1281167 (28%)]	Loss: 1.017325
[2022-03-30 03:36:43 | train] - Train Epoch: [53] [371200/1281167 (29%)]	Loss: 1.382336
[2022-03-30 03:37:05 | train] - Train Epoch: [53] [384000/1281167 (30%)]	Loss: 1.238251
[2022-03-30 03:37:27 | train] - Train Epoch: [53] [396800/1281167 (31%)]	Loss: 1.538582
[2022-03-30 03:37:50 | train] - Train Epoch: [53] [409600/1281167 (32%)]	Loss: 1.082396
[2022-03-30 03:38:12 | train] - Train Epoch: [53] [422400/1281167 (33%)]	Loss: 1.248757
[2022-03-30 03:38:33 | train] - Train Epoch: [53] [435200/1281167 (34%)]	Loss: 1.090647
[2022-03-30 03:38:54 | train] - Train Epoch: [53] [448000/1281167 (35%)]	Loss: 0.778212
[2022-03-30 03:39:14 | train] - Train Epoch: [53] [460800/1281167 (36%)]	Loss: 1.491647
[2022-03-30 03:39:35 | train] - Train Epoch: [53] [473600/1281167 (37%)]	Loss: 0.914099
[2022-03-30 03:39:56 | train] - Train Epoch: [53] [486400/1281167 (38%)]	Loss: 1.138757
[2022-03-30 03:40:17 | train] - Train Epoch: [53] [499200/1281167 (39%)]	Loss: 1.107354
[2022-03-30 03:40:38 | train] - Train Epoch: [53] [512000/1281167 (40%)]	Loss: 1.184475
[2022-03-30 03:41:00 | train] - Train Epoch: [53] [524800/1281167 (41%)]	Loss: 1.158085
[2022-03-30 03:41:21 | train] - Train Epoch: [53] [537600/1281167 (42%)]	Loss: 1.090904
[2022-03-30 03:41:42 | train] - Train Epoch: [53] [550400/1281167 (43%)]	Loss: 0.961810
[2022-03-30 03:42:02 | train] - Train Epoch: [53] [563200/1281167 (44%)]	Loss: 1.262448
[2022-03-30 03:42:23 | train] - Train Epoch: [53] [576000/1281167 (45%)]	Loss: 1.199812
[2022-03-30 03:42:44 | train] - Train Epoch: [53] [588800/1281167 (46%)]	Loss: 1.186062
[2022-03-30 03:43:05 | train] - Train Epoch: [53] [601600/1281167 (47%)]	Loss: 1.089568
[2022-03-30 03:43:26 | train] - Train Epoch: [53] [614400/1281167 (48%)]	Loss: 1.341344
[2022-03-30 03:43:48 | train] - Train Epoch: [53] [627200/1281167 (49%)]	Loss: 1.450241
[2022-03-30 03:44:10 | train] - Train Epoch: [53] [640000/1281167 (50%)]	Loss: 1.013595
[2022-03-30 03:44:33 | train] - Train Epoch: [53] [652800/1281167 (51%)]	Loss: 0.990260
[2022-03-30 03:44:56 | train] - Train Epoch: [53] [665600/1281167 (52%)]	Loss: 1.075226
[2022-03-30 03:45:17 | train] - Train Epoch: [53] [678400/1281167 (53%)]	Loss: 1.116162
[2022-03-30 03:45:39 | train] - Train Epoch: [53] [691200/1281167 (54%)]	Loss: 1.201828
[2022-03-30 03:46:00 | train] - Train Epoch: [53] [704000/1281167 (55%)]	Loss: 1.097568
[2022-03-30 03:46:21 | train] - Train Epoch: [53] [716800/1281167 (56%)]	Loss: 1.399289
[2022-03-30 03:46:42 | train] - Train Epoch: [53] [729600/1281167 (57%)]	Loss: 1.349919
[2022-03-30 03:47:04 | train] - Train Epoch: [53] [742400/1281167 (58%)]	Loss: 0.998801
[2022-03-30 03:47:27 | train] - Train Epoch: [53] [755200/1281167 (59%)]	Loss: 1.187596
[2022-03-30 03:47:49 | train] - Train Epoch: [53] [768000/1281167 (60%)]	Loss: 1.632319
[2022-03-30 03:48:09 | train] - Train Epoch: [53] [780800/1281167 (61%)]	Loss: 1.280689
[2022-03-30 03:48:31 | train] - Train Epoch: [53] [793600/1281167 (62%)]	Loss: 1.168201
[2022-03-30 03:48:51 | train] - Train Epoch: [53] [806400/1281167 (63%)]	Loss: 1.270053
[2022-03-30 03:49:12 | train] - Train Epoch: [53] [819200/1281167 (64%)]	Loss: 1.366773
[2022-03-30 03:49:33 | train] - Train Epoch: [53] [832000/1281167 (65%)]	Loss: 1.156938
[2022-03-30 03:49:55 | train] - Train Epoch: [53] [844800/1281167 (66%)]	Loss: 0.995060
[2022-03-30 03:50:16 | train] - Train Epoch: [53] [857600/1281167 (67%)]	Loss: 1.250435
[2022-03-30 03:50:36 | train] - Train Epoch: [53] [870400/1281167 (68%)]	Loss: 1.296695
[2022-03-30 03:50:57 | train] - Train Epoch: [53] [883200/1281167 (69%)]	Loss: 1.555232
[2022-03-30 03:51:19 | train] - Train Epoch: [53] [896000/1281167 (70%)]	Loss: 1.092049
[2022-03-30 03:51:40 | train] - Train Epoch: [53] [908800/1281167 (71%)]	Loss: 1.003904
[2022-03-30 03:52:02 | train] - Train Epoch: [53] [921600/1281167 (72%)]	Loss: 1.021211
[2022-03-30 03:52:24 | train] - Train Epoch: [53] [934400/1281167 (73%)]	Loss: 1.073343
[2022-03-30 03:52:47 | train] - Train Epoch: [53] [947200/1281167 (74%)]	Loss: 0.971692
[2022-03-30 03:53:10 | train] - Train Epoch: [53] [960000/1281167 (75%)]	Loss: 1.259191
[2022-03-30 03:53:32 | train] - Train Epoch: [53] [972800/1281167 (76%)]	Loss: 1.138860
[2022-03-30 03:53:52 | train] - Train Epoch: [53] [985600/1281167 (77%)]	Loss: 0.827630
[2022-03-30 03:54:14 | train] - Train Epoch: [53] [998400/1281167 (78%)]	Loss: 1.274914
[2022-03-30 03:54:36 | train] - Train Epoch: [53] [1011200/1281167 (79%)]	Loss: 0.960809
[2022-03-30 03:54:57 | train] - Train Epoch: [53] [1024000/1281167 (80%)]	Loss: 1.196583
[2022-03-30 03:55:17 | train] - Train Epoch: [53] [1036800/1281167 (81%)]	Loss: 1.432063
[2022-03-30 03:55:38 | train] - Train Epoch: [53] [1049600/1281167 (82%)]	Loss: 1.525753
[2022-03-30 03:56:00 | train] - Train Epoch: [53] [1062400/1281167 (83%)]	Loss: 1.121689
[2022-03-30 03:56:21 | train] - Train Epoch: [53] [1075200/1281167 (84%)]	Loss: 1.158746
[2022-03-30 03:56:43 | train] - Train Epoch: [53] [1088000/1281167 (85%)]	Loss: 1.253120
[2022-03-30 03:57:04 | train] - Train Epoch: [53] [1100800/1281167 (86%)]	Loss: 1.266355
[2022-03-30 03:57:24 | train] - Train Epoch: [53] [1113600/1281167 (87%)]	Loss: 1.080195
[2022-03-30 03:57:46 | train] - Train Epoch: [53] [1126400/1281167 (88%)]	Loss: 1.232340
[2022-03-30 03:58:07 | train] - Train Epoch: [53] [1139200/1281167 (89%)]	Loss: 1.040397
[2022-03-30 03:58:28 | train] - Train Epoch: [53] [1152000/1281167 (90%)]	Loss: 1.337996
[2022-03-30 03:58:49 | train] - Train Epoch: [53] [1164800/1281167 (91%)]	Loss: 1.303699
[2022-03-30 03:59:10 | train] - Train Epoch: [53] [1177600/1281167 (92%)]	Loss: 1.796985
[2022-03-30 03:59:31 | train] - Train Epoch: [53] [1190400/1281167 (93%)]	Loss: 1.493486
[2022-03-30 03:59:53 | train] - Train Epoch: [53] [1203200/1281167 (94%)]	Loss: 1.233020
[2022-03-30 04:00:14 | train] - Train Epoch: [53] [1216000/1281167 (95%)]	Loss: 1.398129
[2022-03-30 04:00:36 | train] - Train Epoch: [53] [1228800/1281167 (96%)]	Loss: 1.322039
[2022-03-30 04:00:57 | train] - Train Epoch: [53] [1241600/1281167 (97%)]	Loss: 0.897480
[2022-03-30 04:01:18 | train] - Train Epoch: [53] [1254400/1281167 (98%)]	Loss: 1.123817
[2022-03-30 04:01:39 | train] - Train Epoch: [53] [1267200/1281167 (99%)]	Loss: 2.045673
[2022-03-30 04:01:59 | train] - Train Epoch: [53] [1280000/1281167 (100%)]	Loss: 1.132731
[2022-03-30 04:02:02 | train] - Train Epoch: [53]	 Average Loss: 1.198981	 Total Acc : 71.0050	 Total Top5 Acc : 88.5588
[2022-03-30 04:02:04 | train] - -------53 epoch end-----------
========================================
-------53 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 04:03:48 | train] - 
Epoch [53] Test set: Average loss: 1.3688, Accuracy: 34164/50000 (68.2960%), Top-5 Accuracy: 88.0495%

[2022-03-30 04:03:48 | train] - save intermediate epoch [53] result


[2022-03-30 04:04:02 | train] - logging best performance 53 epoch
[2022-03-30 04:04:04 | train] - -------54 epoch start-----------
========================================
----- test end -------------------------


logging best performance 53 epoch
[2022-03-30 04:04:06 | train] - Train Epoch: [54] [0/1281167 (0%)]	Loss: 0.981664
[2022-03-30 04:04:29 | train] - Train Epoch: [54] [12800/1281167 (1%)]	Loss: 0.870135
[2022-03-30 04:04:52 | train] - Train Epoch: [54] [25600/1281167 (2%)]	Loss: 1.237114
[2022-03-30 04:05:15 | train] - Train Epoch: [54] [38400/1281167 (3%)]	Loss: 1.309354
[2022-03-30 04:05:38 | train] - Train Epoch: [54] [51200/1281167 (4%)]	Loss: 1.049171
[2022-03-30 04:06:01 | train] - Train Epoch: [54] [64000/1281167 (5%)]	Loss: 1.046683
[2022-03-30 04:06:24 | train] - Train Epoch: [54] [76800/1281167 (6%)]	Loss: 1.251275
[2022-03-30 04:06:47 | train] - Train Epoch: [54] [89600/1281167 (7%)]	Loss: 1.173642
[2022-03-30 04:07:10 | train] - Train Epoch: [54] [102400/1281167 (8%)]	Loss: 1.376029
[2022-03-30 04:07:32 | train] - Train Epoch: [54] [115200/1281167 (9%)]	Loss: 1.156503
[2022-03-30 04:07:55 | train] - Train Epoch: [54] [128000/1281167 (10%)]	Loss: 1.223083
[2022-03-30 04:08:17 | train] - Train Epoch: [54] [140800/1281167 (11%)]	Loss: 1.258180
[2022-03-30 04:08:38 | train] - Train Epoch: [54] [153600/1281167 (12%)]	Loss: 0.992338
[2022-03-30 04:08:59 | train] - Train Epoch: [54] [166400/1281167 (13%)]	Loss: 1.219507
[2022-03-30 04:09:21 | train] - Train Epoch: [54] [179200/1281167 (14%)]	Loss: 1.142725
[2022-03-30 04:09:42 | train] - Train Epoch: [54] [192000/1281167 (15%)]	Loss: 1.230674
[2022-03-30 04:10:04 | train] - Train Epoch: [54] [204800/1281167 (16%)]	Loss: 0.952053
[2022-03-30 04:10:25 | train] - Train Epoch: [54] [217600/1281167 (17%)]	Loss: 0.937870
[2022-03-30 04:10:46 | train] - Train Epoch: [54] [230400/1281167 (18%)]	Loss: 1.245519
[2022-03-30 04:11:07 | train] - Train Epoch: [54] [243200/1281167 (19%)]	Loss: 1.347521
[2022-03-30 04:11:30 | train] - Train Epoch: [54] [256000/1281167 (20%)]	Loss: 1.008254
[2022-03-30 04:11:50 | train] - Train Epoch: [54] [268800/1281167 (21%)]	Loss: 1.104557
[2022-03-30 04:12:10 | train] - Train Epoch: [54] [281600/1281167 (22%)]	Loss: 1.202819
[2022-03-30 04:12:32 | train] - Train Epoch: [54] [294400/1281167 (23%)]	Loss: 1.154637
[2022-03-30 04:12:53 | train] - Train Epoch: [54] [307200/1281167 (24%)]	Loss: 1.103881
[2022-03-30 04:13:14 | train] - Train Epoch: [54] [320000/1281167 (25%)]	Loss: 1.214664
[2022-03-30 04:13:35 | train] - Train Epoch: [54] [332800/1281167 (26%)]	Loss: 1.415815
[2022-03-30 04:13:55 | train] - Train Epoch: [54] [345600/1281167 (27%)]	Loss: 1.151612
[2022-03-30 04:14:17 | train] - Train Epoch: [54] [358400/1281167 (28%)]	Loss: 0.826693
[2022-03-30 04:14:39 | train] - Train Epoch: [54] [371200/1281167 (29%)]	Loss: 1.297529
[2022-03-30 04:15:02 | train] - Train Epoch: [54] [384000/1281167 (30%)]	Loss: 1.125052
[2022-03-30 04:15:23 | train] - Train Epoch: [54] [396800/1281167 (31%)]	Loss: 1.067789
[2022-03-30 04:15:44 | train] - Train Epoch: [54] [409600/1281167 (32%)]	Loss: 1.142515
[2022-03-30 04:16:05 | train] - Train Epoch: [54] [422400/1281167 (33%)]	Loss: 1.256114
[2022-03-30 04:16:26 | train] - Train Epoch: [54] [435200/1281167 (34%)]	Loss: 1.369241
[2022-03-30 04:16:47 | train] - Train Epoch: [54] [448000/1281167 (35%)]	Loss: 0.975653
[2022-03-30 04:17:07 | train] - Train Epoch: [54] [460800/1281167 (36%)]	Loss: 1.412516
[2022-03-30 04:17:29 | train] - Train Epoch: [54] [473600/1281167 (37%)]	Loss: 1.245944
[2022-03-30 04:17:49 | train] - Train Epoch: [54] [486400/1281167 (38%)]	Loss: 1.516301
[2022-03-30 04:18:10 | train] - Train Epoch: [54] [499200/1281167 (39%)]	Loss: 1.315712
[2022-03-30 04:18:31 | train] - Train Epoch: [54] [512000/1281167 (40%)]	Loss: 1.066664
[2022-03-30 04:18:53 | train] - Train Epoch: [54] [524800/1281167 (41%)]	Loss: 1.260914
[2022-03-30 04:19:13 | train] - Train Epoch: [54] [537600/1281167 (42%)]	Loss: 1.066050
[2022-03-30 04:19:34 | train] - Train Epoch: [54] [550400/1281167 (43%)]	Loss: 0.998033
[2022-03-30 04:19:55 | train] - Train Epoch: [54] [563200/1281167 (44%)]	Loss: 0.978886
[2022-03-30 04:20:16 | train] - Train Epoch: [54] [576000/1281167 (45%)]	Loss: 1.084127
[2022-03-30 04:20:37 | train] - Train Epoch: [54] [588800/1281167 (46%)]	Loss: 1.167085
[2022-03-30 04:20:57 | train] - Train Epoch: [54] [601600/1281167 (47%)]	Loss: 1.027937
[2022-03-30 04:21:18 | train] - Train Epoch: [54] [614400/1281167 (48%)]	Loss: 1.444388
[2022-03-30 04:21:38 | train] - Train Epoch: [54] [627200/1281167 (49%)]	Loss: 1.157036
[2022-03-30 04:21:59 | train] - Train Epoch: [54] [640000/1281167 (50%)]	Loss: 1.191133
[2022-03-30 04:22:20 | train] - Train Epoch: [54] [652800/1281167 (51%)]	Loss: 1.305591
[2022-03-30 04:22:42 | train] - Train Epoch: [54] [665600/1281167 (52%)]	Loss: 1.146137
[2022-03-30 04:23:02 | train] - Train Epoch: [54] [678400/1281167 (53%)]	Loss: 1.191133
[2022-03-30 04:23:24 | train] - Train Epoch: [54] [691200/1281167 (54%)]	Loss: 1.283289
[2022-03-30 04:23:45 | train] - Train Epoch: [54] [704000/1281167 (55%)]	Loss: 1.061292
[2022-03-30 04:24:04 | train] - Train Epoch: [54] [716800/1281167 (56%)]	Loss: 1.301680
[2022-03-30 04:24:26 | train] - Train Epoch: [54] [729600/1281167 (57%)]	Loss: 1.229043
[2022-03-30 04:24:48 | train] - Train Epoch: [54] [742400/1281167 (58%)]	Loss: 0.975091
[2022-03-30 04:25:09 | train] - Train Epoch: [54] [755200/1281167 (59%)]	Loss: 1.030808
[2022-03-30 04:25:31 | train] - Train Epoch: [54] [768000/1281167 (60%)]	Loss: 1.045853
[2022-03-30 04:25:51 | train] - Train Epoch: [54] [780800/1281167 (61%)]	Loss: 1.371106
[2022-03-30 04:26:13 | train] - Train Epoch: [54] [793600/1281167 (62%)]	Loss: 1.396940
[2022-03-30 04:26:34 | train] - Train Epoch: [54] [806400/1281167 (63%)]	Loss: 1.398752
[2022-03-30 04:26:54 | train] - Train Epoch: [54] [819200/1281167 (64%)]	Loss: 1.095429
[2022-03-30 04:27:15 | train] - Train Epoch: [54] [832000/1281167 (65%)]	Loss: 1.067787
[2022-03-30 04:27:36 | train] - Train Epoch: [54] [844800/1281167 (66%)]	Loss: 0.977387
[2022-03-30 04:27:58 | train] - Train Epoch: [54] [857600/1281167 (67%)]	Loss: 1.323345
[2022-03-30 04:28:21 | train] - Train Epoch: [54] [870400/1281167 (68%)]	Loss: 1.327582
[2022-03-30 04:28:43 | train] - Train Epoch: [54] [883200/1281167 (69%)]	Loss: 1.593472
[2022-03-30 04:29:04 | train] - Train Epoch: [54] [896000/1281167 (70%)]	Loss: 1.017297
[2022-03-30 04:29:25 | train] - Train Epoch: [54] [908800/1281167 (71%)]	Loss: 1.237365
[2022-03-30 04:29:47 | train] - Train Epoch: [54] [921600/1281167 (72%)]	Loss: 0.969510
[2022-03-30 04:30:08 | train] - Train Epoch: [54] [934400/1281167 (73%)]	Loss: 1.008547
[2022-03-30 04:30:28 | train] - Train Epoch: [54] [947200/1281167 (74%)]	Loss: 1.340432
[2022-03-30 04:30:49 | train] - Train Epoch: [54] [960000/1281167 (75%)]	Loss: 1.188939
[2022-03-30 04:31:08 | train] - Train Epoch: [54] [972800/1281167 (76%)]	Loss: 1.288053
[2022-03-30 04:31:29 | train] - Train Epoch: [54] [985600/1281167 (77%)]	Loss: 1.002367
[2022-03-30 04:31:52 | train] - Train Epoch: [54] [998400/1281167 (78%)]	Loss: 0.864752
[2022-03-30 04:32:13 | train] - Train Epoch: [54] [1011200/1281167 (79%)]	Loss: 1.154427
[2022-03-30 04:32:36 | train] - Train Epoch: [54] [1024000/1281167 (80%)]	Loss: 1.258895
[2022-03-30 04:32:59 | train] - Train Epoch: [54] [1036800/1281167 (81%)]	Loss: 1.470686
[2022-03-30 04:33:21 | train] - Train Epoch: [54] [1049600/1281167 (82%)]	Loss: 1.098034
[2022-03-30 04:33:44 | train] - Train Epoch: [54] [1062400/1281167 (83%)]	Loss: 1.185907
[2022-03-30 04:34:07 | train] - Train Epoch: [54] [1075200/1281167 (84%)]	Loss: 1.235509
[2022-03-30 04:34:28 | train] - Train Epoch: [54] [1088000/1281167 (85%)]	Loss: 1.419246
[2022-03-30 04:34:49 | train] - Train Epoch: [54] [1100800/1281167 (86%)]	Loss: 1.104990
[2022-03-30 04:35:11 | train] - Train Epoch: [54] [1113600/1281167 (87%)]	Loss: 1.153563
[2022-03-30 04:35:30 | train] - Train Epoch: [54] [1126400/1281167 (88%)]	Loss: 1.257051
[2022-03-30 04:35:51 | train] - Train Epoch: [54] [1139200/1281167 (89%)]	Loss: 1.319495
[2022-03-30 04:36:11 | train] - Train Epoch: [54] [1152000/1281167 (90%)]	Loss: 1.245082
[2022-03-30 04:36:31 | train] - Train Epoch: [54] [1164800/1281167 (91%)]	Loss: 1.306146
[2022-03-30 04:36:51 | train] - Train Epoch: [54] [1177600/1281167 (92%)]	Loss: 1.164552
[2022-03-30 04:37:12 | train] - Train Epoch: [54] [1190400/1281167 (93%)]	Loss: 1.168595
[2022-03-30 04:37:34 | train] - Train Epoch: [54] [1203200/1281167 (94%)]	Loss: 1.440362
[2022-03-30 04:37:55 | train] - Train Epoch: [54] [1216000/1281167 (95%)]	Loss: 1.021827
[2022-03-30 04:38:15 | train] - Train Epoch: [54] [1228800/1281167 (96%)]	Loss: 1.079175
[2022-03-30 04:38:37 | train] - Train Epoch: [54] [1241600/1281167 (97%)]	Loss: 1.246239
[2022-03-30 04:38:57 | train] - Train Epoch: [54] [1254400/1281167 (98%)]	Loss: 1.215543
[2022-03-30 04:39:18 | train] - Train Epoch: [54] [1267200/1281167 (99%)]	Loss: 1.013730
[2022-03-30 04:39:40 | train] - Train Epoch: [54] [1280000/1281167 (100%)]	Loss: 1.233213
[2022-03-30 04:39:42 | train] - Train Epoch: [54]	 Average Loss: 1.188992	 Total Acc : 71.2178	 Total Top5 Acc : 88.6773
[2022-03-30 04:39:45 | train] - -------54 epoch end-----------
========================================
-------54 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 04:41:28 | train] - 
Epoch [54] Test set: Average loss: 1.3664, Accuracy: 34157/50000 (68.2821%), Top-5 Accuracy: 88.0982%

[2022-03-30 04:41:28 | train] - save intermediate epoch [54] result


[2022-03-30 04:41:44 | train] - -------55 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 04:41:46 | train] - Train Epoch: [55] [0/1281167 (0%)]	Loss: 1.255700
[2022-03-30 04:42:10 | train] - Train Epoch: [55] [12800/1281167 (1%)]	Loss: 1.127814
[2022-03-30 04:42:32 | train] - Train Epoch: [55] [25600/1281167 (2%)]	Loss: 1.173914
[2022-03-30 04:42:54 | train] - Train Epoch: [55] [38400/1281167 (3%)]	Loss: 1.555731
[2022-03-30 04:43:16 | train] - Train Epoch: [55] [51200/1281167 (4%)]	Loss: 1.140427
[2022-03-30 04:43:38 | train] - Train Epoch: [55] [64000/1281167 (5%)]	Loss: 1.185343
[2022-03-30 04:44:00 | train] - Train Epoch: [55] [76800/1281167 (6%)]	Loss: 1.104066
[2022-03-30 04:44:21 | train] - Train Epoch: [55] [89600/1281167 (7%)]	Loss: 1.105921
[2022-03-30 04:44:43 | train] - Train Epoch: [55] [102400/1281167 (8%)]	Loss: 1.096823
[2022-03-30 04:45:05 | train] - Train Epoch: [55] [115200/1281167 (9%)]	Loss: 1.202223
[2022-03-30 04:45:28 | train] - Train Epoch: [55] [128000/1281167 (10%)]	Loss: 0.957945
[2022-03-30 04:45:50 | train] - Train Epoch: [55] [140800/1281167 (11%)]	Loss: 1.006231
[2022-03-30 04:46:12 | train] - Train Epoch: [55] [153600/1281167 (12%)]	Loss: 1.701177
[2022-03-30 04:46:34 | train] - Train Epoch: [55] [166400/1281167 (13%)]	Loss: 1.119254
[2022-03-30 04:46:56 | train] - Train Epoch: [55] [179200/1281167 (14%)]	Loss: 1.136477
[2022-03-30 04:47:18 | train] - Train Epoch: [55] [192000/1281167 (15%)]	Loss: 1.146150
[2022-03-30 04:47:41 | train] - Train Epoch: [55] [204800/1281167 (16%)]	Loss: 0.936238
[2022-03-30 04:48:03 | train] - Train Epoch: [55] [217600/1281167 (17%)]	Loss: 1.274054
[2022-03-30 04:48:26 | train] - Train Epoch: [55] [230400/1281167 (18%)]	Loss: 1.082613
[2022-03-30 04:48:47 | train] - Train Epoch: [55] [243200/1281167 (19%)]	Loss: 1.007277
[2022-03-30 04:49:10 | train] - Train Epoch: [55] [256000/1281167 (20%)]	Loss: 1.436941
[2022-03-30 04:49:32 | train] - Train Epoch: [55] [268800/1281167 (21%)]	Loss: 1.158998
[2022-03-30 04:49:54 | train] - Train Epoch: [55] [281600/1281167 (22%)]	Loss: 1.137231
[2022-03-30 04:50:17 | train] - Train Epoch: [55] [294400/1281167 (23%)]	Loss: 1.188669
[2022-03-30 04:50:39 | train] - Train Epoch: [55] [307200/1281167 (24%)]	Loss: 1.141847
[2022-03-30 04:50:58 | train] - Train Epoch: [55] [320000/1281167 (25%)]	Loss: 1.297872
[2022-03-30 04:51:20 | train] - Train Epoch: [55] [332800/1281167 (26%)]	Loss: 1.090719
[2022-03-30 04:51:40 | train] - Train Epoch: [55] [345600/1281167 (27%)]	Loss: 0.913093
[2022-03-30 04:52:01 | train] - Train Epoch: [55] [358400/1281167 (28%)]	Loss: 1.050386
[2022-03-30 04:52:23 | train] - Train Epoch: [55] [371200/1281167 (29%)]	Loss: 1.330314
[2022-03-30 04:52:45 | train] - Train Epoch: [55] [384000/1281167 (30%)]	Loss: 1.183995
[2022-03-30 04:53:06 | train] - Train Epoch: [55] [396800/1281167 (31%)]	Loss: 0.806842
[2022-03-30 04:53:28 | train] - Train Epoch: [55] [409600/1281167 (32%)]	Loss: 1.116744
[2022-03-30 04:53:50 | train] - Train Epoch: [55] [422400/1281167 (33%)]	Loss: 0.968633
[2022-03-30 04:54:10 | train] - Train Epoch: [55] [435200/1281167 (34%)]	Loss: 1.291041
[2022-03-30 04:54:32 | train] - Train Epoch: [55] [448000/1281167 (35%)]	Loss: 1.600946
[2022-03-30 04:54:53 | train] - Train Epoch: [55] [460800/1281167 (36%)]	Loss: 1.044468
[2022-03-30 04:55:15 | train] - Train Epoch: [55] [473600/1281167 (37%)]	Loss: 1.278713
[2022-03-30 04:55:37 | train] - Train Epoch: [55] [486400/1281167 (38%)]	Loss: 1.087091
[2022-03-30 04:55:58 | train] - Train Epoch: [55] [499200/1281167 (39%)]	Loss: 0.986996
[2022-03-30 04:56:20 | train] - Train Epoch: [55] [512000/1281167 (40%)]	Loss: 1.350674
[2022-03-30 04:56:42 | train] - Train Epoch: [55] [524800/1281167 (41%)]	Loss: 1.279556
[2022-03-30 04:57:02 | train] - Train Epoch: [55] [537600/1281167 (42%)]	Loss: 1.379831
[2022-03-30 04:57:24 | train] - Train Epoch: [55] [550400/1281167 (43%)]	Loss: 1.349641
[2022-03-30 04:57:46 | train] - Train Epoch: [55] [563200/1281167 (44%)]	Loss: 1.068400
[2022-03-30 04:58:09 | train] - Train Epoch: [55] [576000/1281167 (45%)]	Loss: 1.264907
[2022-03-30 04:58:30 | train] - Train Epoch: [55] [588800/1281167 (46%)]	Loss: 1.225412
[2022-03-30 04:58:51 | train] - Train Epoch: [55] [601600/1281167 (47%)]	Loss: 1.227209
[2022-03-30 04:59:13 | train] - Train Epoch: [55] [614400/1281167 (48%)]	Loss: 1.302783
[2022-03-30 04:59:34 | train] - Train Epoch: [55] [627200/1281167 (49%)]	Loss: 1.092085
[2022-03-30 04:59:56 | train] - Train Epoch: [55] [640000/1281167 (50%)]	Loss: 1.283456
[2022-03-30 05:00:17 | train] - Train Epoch: [55] [652800/1281167 (51%)]	Loss: 1.450179
[2022-03-30 05:00:38 | train] - Train Epoch: [55] [665600/1281167 (52%)]	Loss: 1.101267
[2022-03-30 05:01:00 | train] - Train Epoch: [55] [678400/1281167 (53%)]	Loss: 1.321079
[2022-03-30 05:01:22 | train] - Train Epoch: [55] [691200/1281167 (54%)]	Loss: 1.112004
[2022-03-30 05:01:44 | train] - Train Epoch: [55] [704000/1281167 (55%)]	Loss: 0.936688
[2022-03-30 05:02:07 | train] - Train Epoch: [55] [716800/1281167 (56%)]	Loss: 1.214914
[2022-03-30 05:02:29 | train] - Train Epoch: [55] [729600/1281167 (57%)]	Loss: 0.964553
[2022-03-30 05:02:50 | train] - Train Epoch: [55] [742400/1281167 (58%)]	Loss: 1.243744
[2022-03-30 05:03:12 | train] - Train Epoch: [55] [755200/1281167 (59%)]	Loss: 1.265013
[2022-03-30 05:03:33 | train] - Train Epoch: [55] [768000/1281167 (60%)]	Loss: 1.045043
[2022-03-30 05:03:55 | train] - Train Epoch: [55] [780800/1281167 (61%)]	Loss: 1.359236
[2022-03-30 05:04:16 | train] - Train Epoch: [55] [793600/1281167 (62%)]	Loss: 1.201610
[2022-03-30 05:04:37 | train] - Train Epoch: [55] [806400/1281167 (63%)]	Loss: 1.054300
[2022-03-30 05:04:59 | train] - Train Epoch: [55] [819200/1281167 (64%)]	Loss: 1.603937
[2022-03-30 05:05:20 | train] - Train Epoch: [55] [832000/1281167 (65%)]	Loss: 1.031183
[2022-03-30 05:05:42 | train] - Train Epoch: [55] [844800/1281167 (66%)]	Loss: 1.283971
[2022-03-30 05:06:05 | train] - Train Epoch: [55] [857600/1281167 (67%)]	Loss: 1.180461
[2022-03-30 05:06:26 | train] - Train Epoch: [55] [870400/1281167 (68%)]	Loss: 1.264006
[2022-03-30 05:06:48 | train] - Train Epoch: [55] [883200/1281167 (69%)]	Loss: 1.073755
[2022-03-30 05:07:09 | train] - Train Epoch: [55] [896000/1281167 (70%)]	Loss: 1.353839
[2022-03-30 05:07:31 | train] - Train Epoch: [55] [908800/1281167 (71%)]	Loss: 1.146605
[2022-03-30 05:07:52 | train] - Train Epoch: [55] [921600/1281167 (72%)]	Loss: 1.480975
[2022-03-30 05:08:14 | train] - Train Epoch: [55] [934400/1281167 (73%)]	Loss: 1.049970
[2022-03-30 05:08:36 | train] - Train Epoch: [55] [947200/1281167 (74%)]	Loss: 1.328848
[2022-03-30 05:08:58 | train] - Train Epoch: [55] [960000/1281167 (75%)]	Loss: 1.141440
[2022-03-30 05:09:18 | train] - Train Epoch: [55] [972800/1281167 (76%)]	Loss: 1.098197
[2022-03-30 05:09:39 | train] - Train Epoch: [55] [985600/1281167 (77%)]	Loss: 1.359661
[2022-03-30 05:10:01 | train] - Train Epoch: [55] [998400/1281167 (78%)]	Loss: 1.247483
[2022-03-30 05:10:22 | train] - Train Epoch: [55] [1011200/1281167 (79%)]	Loss: 1.197680
[2022-03-30 05:10:44 | train] - Train Epoch: [55] [1024000/1281167 (80%)]	Loss: 0.956014
[2022-03-30 05:11:05 | train] - Train Epoch: [55] [1036800/1281167 (81%)]	Loss: 1.227236
[2022-03-30 05:11:28 | train] - Train Epoch: [55] [1049600/1281167 (82%)]	Loss: 0.780152
[2022-03-30 05:11:50 | train] - Train Epoch: [55] [1062400/1281167 (83%)]	Loss: 1.322315
[2022-03-30 05:12:12 | train] - Train Epoch: [55] [1075200/1281167 (84%)]	Loss: 0.888938
[2022-03-30 05:12:33 | train] - Train Epoch: [55] [1088000/1281167 (85%)]	Loss: 1.521215
[2022-03-30 05:12:55 | train] - Train Epoch: [55] [1100800/1281167 (86%)]	Loss: 1.275048
[2022-03-30 05:13:16 | train] - Train Epoch: [55] [1113600/1281167 (87%)]	Loss: 1.412751
[2022-03-30 05:13:38 | train] - Train Epoch: [55] [1126400/1281167 (88%)]	Loss: 1.242497
[2022-03-30 05:14:00 | train] - Train Epoch: [55] [1139200/1281167 (89%)]	Loss: 1.573871
[2022-03-30 05:14:21 | train] - Train Epoch: [55] [1152000/1281167 (90%)]	Loss: 1.061946
[2022-03-30 05:14:42 | train] - Train Epoch: [55] [1164800/1281167 (91%)]	Loss: 1.428501
[2022-03-30 05:15:04 | train] - Train Epoch: [55] [1177600/1281167 (92%)]	Loss: 1.165714
[2022-03-30 05:15:26 | train] - Train Epoch: [55] [1190400/1281167 (93%)]	Loss: 1.092015
[2022-03-30 05:15:47 | train] - Train Epoch: [55] [1203200/1281167 (94%)]	Loss: 1.343404
[2022-03-30 05:16:08 | train] - Train Epoch: [55] [1216000/1281167 (95%)]	Loss: 1.293746
[2022-03-30 05:16:29 | train] - Train Epoch: [55] [1228800/1281167 (96%)]	Loss: 1.221631
[2022-03-30 05:16:51 | train] - Train Epoch: [55] [1241600/1281167 (97%)]	Loss: 1.445981
[2022-03-30 05:17:13 | train] - Train Epoch: [55] [1254400/1281167 (98%)]	Loss: 1.160956
[2022-03-30 05:17:34 | train] - Train Epoch: [55] [1267200/1281167 (99%)]	Loss: 1.141742
[2022-03-30 05:17:55 | train] - Train Epoch: [55] [1280000/1281167 (100%)]	Loss: 1.207900
[2022-03-30 05:17:57 | train] - Train Epoch: [55]	 Average Loss: 1.179252	 Total Acc : 71.4497	 Total Top5 Acc : 88.7690
[2022-03-30 05:18:00 | train] - -------55 epoch end-----------
========================================
-------55 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 05:19:44 | train] - 
Epoch [55] Test set: Average loss: 1.3649, Accuracy: 34272/50000 (68.5250%), Top-5 Accuracy: 88.0870%

[2022-03-30 05:19:44 | train] - save intermediate epoch [55] result


[2022-03-30 05:19:59 | train] - logging best performance 55 epoch
[2022-03-30 05:20:00 | train] - -------56 epoch start-----------
========================================
----- test end -------------------------


logging best performance 55 epoch
[2022-03-30 05:20:03 | train] - Train Epoch: [56] [0/1281167 (0%)]	Loss: 0.839458
[2022-03-30 05:20:24 | train] - Train Epoch: [56] [12800/1281167 (1%)]	Loss: 1.254447
[2022-03-30 05:20:47 | train] - Train Epoch: [56] [25600/1281167 (2%)]	Loss: 0.953103
[2022-03-30 05:21:08 | train] - Train Epoch: [56] [38400/1281167 (3%)]	Loss: 1.125215
[2022-03-30 05:21:29 | train] - Train Epoch: [56] [51200/1281167 (4%)]	Loss: 1.334039
[2022-03-30 05:21:51 | train] - Train Epoch: [56] [64000/1281167 (5%)]	Loss: 1.042668
[2022-03-30 05:22:12 | train] - Train Epoch: [56] [76800/1281167 (6%)]	Loss: 1.391947
[2022-03-30 05:22:35 | train] - Train Epoch: [56] [89600/1281167 (7%)]	Loss: 1.193318
[2022-03-30 05:22:57 | train] - Train Epoch: [56] [102400/1281167 (8%)]	Loss: 1.056466
[2022-03-30 05:23:19 | train] - Train Epoch: [56] [115200/1281167 (9%)]	Loss: 1.198686
[2022-03-30 05:23:41 | train] - Train Epoch: [56] [128000/1281167 (10%)]	Loss: 0.909822
[2022-03-30 05:24:02 | train] - Train Epoch: [56] [140800/1281167 (11%)]	Loss: 1.239089
[2022-03-30 05:24:24 | train] - Train Epoch: [56] [153600/1281167 (12%)]	Loss: 1.434888
[2022-03-30 05:24:47 | train] - Train Epoch: [56] [166400/1281167 (13%)]	Loss: 0.867068
[2022-03-30 05:25:08 | train] - Train Epoch: [56] [179200/1281167 (14%)]	Loss: 1.451017
[2022-03-30 05:25:30 | train] - Train Epoch: [56] [192000/1281167 (15%)]	Loss: 1.447311
[2022-03-30 05:25:52 | train] - Train Epoch: [56] [204800/1281167 (16%)]	Loss: 1.199435
[2022-03-30 05:26:14 | train] - Train Epoch: [56] [217600/1281167 (17%)]	Loss: 0.869593
[2022-03-30 05:26:35 | train] - Train Epoch: [56] [230400/1281167 (18%)]	Loss: 0.987107
[2022-03-30 05:26:57 | train] - Train Epoch: [56] [243200/1281167 (19%)]	Loss: 1.444244
[2022-03-30 05:27:17 | train] - Train Epoch: [56] [256000/1281167 (20%)]	Loss: 0.942790
[2022-03-30 05:27:39 | train] - Train Epoch: [56] [268800/1281167 (21%)]	Loss: 1.118924
[2022-03-30 05:27:59 | train] - Train Epoch: [56] [281600/1281167 (22%)]	Loss: 1.127464
[2022-03-30 05:28:20 | train] - Train Epoch: [56] [294400/1281167 (23%)]	Loss: 0.977789
[2022-03-30 05:28:41 | train] - Train Epoch: [56] [307200/1281167 (24%)]	Loss: 1.199876
[2022-03-30 05:29:03 | train] - Train Epoch: [56] [320000/1281167 (25%)]	Loss: 1.370775
[2022-03-30 05:29:24 | train] - Train Epoch: [56] [332800/1281167 (26%)]	Loss: 1.043729
[2022-03-30 05:29:46 | train] - Train Epoch: [56] [345600/1281167 (27%)]	Loss: 1.391215
[2022-03-30 05:30:07 | train] - Train Epoch: [56] [358400/1281167 (28%)]	Loss: 1.003748
[2022-03-30 05:30:27 | train] - Train Epoch: [56] [371200/1281167 (29%)]	Loss: 1.080649
[2022-03-30 05:30:49 | train] - Train Epoch: [56] [384000/1281167 (30%)]	Loss: 1.146897
[2022-03-30 05:31:10 | train] - Train Epoch: [56] [396800/1281167 (31%)]	Loss: 1.062509
[2022-03-30 05:31:31 | train] - Train Epoch: [56] [409600/1281167 (32%)]	Loss: 1.211014
[2022-03-30 05:31:53 | train] - Train Epoch: [56] [422400/1281167 (33%)]	Loss: 1.342202
[2022-03-30 05:32:15 | train] - Train Epoch: [56] [435200/1281167 (34%)]	Loss: 1.095150
[2022-03-30 05:32:36 | train] - Train Epoch: [56] [448000/1281167 (35%)]	Loss: 1.298295
[2022-03-30 05:32:57 | train] - Train Epoch: [56] [460800/1281167 (36%)]	Loss: 0.988659
[2022-03-30 05:33:19 | train] - Train Epoch: [56] [473600/1281167 (37%)]	Loss: 0.870455
[2022-03-30 05:33:40 | train] - Train Epoch: [56] [486400/1281167 (38%)]	Loss: 1.117407
[2022-03-30 05:34:02 | train] - Train Epoch: [56] [499200/1281167 (39%)]	Loss: 0.992289
[2022-03-30 05:34:22 | train] - Train Epoch: [56] [512000/1281167 (40%)]	Loss: 1.051913
[2022-03-30 05:34:43 | train] - Train Epoch: [56] [524800/1281167 (41%)]	Loss: 1.109919
[2022-03-30 05:35:05 | train] - Train Epoch: [56] [537600/1281167 (42%)]	Loss: 1.120076
[2022-03-30 05:35:26 | train] - Train Epoch: [56] [550400/1281167 (43%)]	Loss: 1.156863
[2022-03-30 05:35:47 | train] - Train Epoch: [56] [563200/1281167 (44%)]	Loss: 0.976379
[2022-03-30 05:36:08 | train] - Train Epoch: [56] [576000/1281167 (45%)]	Loss: 1.149286
[2022-03-30 05:36:28 | train] - Train Epoch: [56] [588800/1281167 (46%)]	Loss: 1.201977
[2022-03-30 05:36:49 | train] - Train Epoch: [56] [601600/1281167 (47%)]	Loss: 1.469272
[2022-03-30 05:37:10 | train] - Train Epoch: [56] [614400/1281167 (48%)]	Loss: 1.030137
[2022-03-30 05:37:32 | train] - Train Epoch: [56] [627200/1281167 (49%)]	Loss: 0.962507
[2022-03-30 05:37:53 | train] - Train Epoch: [56] [640000/1281167 (50%)]	Loss: 1.472829
[2022-03-30 05:38:14 | train] - Train Epoch: [56] [652800/1281167 (51%)]	Loss: 1.330989
[2022-03-30 05:38:36 | train] - Train Epoch: [56] [665600/1281167 (52%)]	Loss: 1.237405
[2022-03-30 05:38:57 | train] - Train Epoch: [56] [678400/1281167 (53%)]	Loss: 1.672715
[2022-03-30 05:39:18 | train] - Train Epoch: [56] [691200/1281167 (54%)]	Loss: 1.052196
[2022-03-30 05:39:39 | train] - Train Epoch: [56] [704000/1281167 (55%)]	Loss: 0.876878
[2022-03-30 05:40:00 | train] - Train Epoch: [56] [716800/1281167 (56%)]	Loss: 1.375080
[2022-03-30 05:40:20 | train] - Train Epoch: [56] [729600/1281167 (57%)]	Loss: 1.313163
[2022-03-30 05:40:42 | train] - Train Epoch: [56] [742400/1281167 (58%)]	Loss: 1.156263
[2022-03-30 05:41:03 | train] - Train Epoch: [56] [755200/1281167 (59%)]	Loss: 1.177704
[2022-03-30 05:41:24 | train] - Train Epoch: [56] [768000/1281167 (60%)]	Loss: 1.266146
[2022-03-30 05:41:45 | train] - Train Epoch: [56] [780800/1281167 (61%)]	Loss: 1.228862
[2022-03-30 05:42:06 | train] - Train Epoch: [56] [793600/1281167 (62%)]	Loss: 1.063298
[2022-03-30 05:42:27 | train] - Train Epoch: [56] [806400/1281167 (63%)]	Loss: 1.425851
[2022-03-30 05:42:49 | train] - Train Epoch: [56] [819200/1281167 (64%)]	Loss: 1.182043
[2022-03-30 05:43:10 | train] - Train Epoch: [56] [832000/1281167 (65%)]	Loss: 1.090154
[2022-03-30 05:43:31 | train] - Train Epoch: [56] [844800/1281167 (66%)]	Loss: 0.961523
[2022-03-30 05:43:51 | train] - Train Epoch: [56] [857600/1281167 (67%)]	Loss: 1.000369
[2022-03-30 05:44:13 | train] - Train Epoch: [56] [870400/1281167 (68%)]	Loss: 0.854951
[2022-03-30 05:44:35 | train] - Train Epoch: [56] [883200/1281167 (69%)]	Loss: 1.021418
[2022-03-30 05:44:57 | train] - Train Epoch: [56] [896000/1281167 (70%)]	Loss: 0.980860
[2022-03-30 05:45:19 | train] - Train Epoch: [56] [908800/1281167 (71%)]	Loss: 1.496351
[2022-03-30 05:45:40 | train] - Train Epoch: [56] [921600/1281167 (72%)]	Loss: 1.012373
[2022-03-30 05:46:02 | train] - Train Epoch: [56] [934400/1281167 (73%)]	Loss: 1.133149
[2022-03-30 05:46:24 | train] - Train Epoch: [56] [947200/1281167 (74%)]	Loss: 0.858963
[2022-03-30 05:46:45 | train] - Train Epoch: [56] [960000/1281167 (75%)]	Loss: 1.182745
[2022-03-30 05:47:07 | train] - Train Epoch: [56] [972800/1281167 (76%)]	Loss: 1.142088
[2022-03-30 05:47:28 | train] - Train Epoch: [56] [985600/1281167 (77%)]	Loss: 1.143428
[2022-03-30 05:47:49 | train] - Train Epoch: [56] [998400/1281167 (78%)]	Loss: 0.979485
[2022-03-30 05:48:10 | train] - Train Epoch: [56] [1011200/1281167 (79%)]	Loss: 1.201106
[2022-03-30 05:48:31 | train] - Train Epoch: [56] [1024000/1281167 (80%)]	Loss: 0.942143
[2022-03-30 05:48:52 | train] - Train Epoch: [56] [1036800/1281167 (81%)]	Loss: 1.134194
[2022-03-30 05:49:13 | train] - Train Epoch: [56] [1049600/1281167 (82%)]	Loss: 1.076789
[2022-03-30 05:49:33 | train] - Train Epoch: [56] [1062400/1281167 (83%)]	Loss: 1.500780
[2022-03-30 05:49:54 | train] - Train Epoch: [56] [1075200/1281167 (84%)]	Loss: 1.123857
[2022-03-30 05:50:15 | train] - Train Epoch: [56] [1088000/1281167 (85%)]	Loss: 1.382270
[2022-03-30 05:50:36 | train] - Train Epoch: [56] [1100800/1281167 (86%)]	Loss: 1.353967
[2022-03-30 05:50:57 | train] - Train Epoch: [56] [1113600/1281167 (87%)]	Loss: 1.054547
[2022-03-30 05:51:18 | train] - Train Epoch: [56] [1126400/1281167 (88%)]	Loss: 1.248579
[2022-03-30 05:51:40 | train] - Train Epoch: [56] [1139200/1281167 (89%)]	Loss: 1.324172
[2022-03-30 05:52:02 | train] - Train Epoch: [56] [1152000/1281167 (90%)]	Loss: 1.316193
[2022-03-30 05:52:24 | train] - Train Epoch: [56] [1164800/1281167 (91%)]	Loss: 1.456885
[2022-03-30 05:52:45 | train] - Train Epoch: [56] [1177600/1281167 (92%)]	Loss: 1.255081
[2022-03-30 05:53:07 | train] - Train Epoch: [56] [1190400/1281167 (93%)]	Loss: 1.294659
[2022-03-30 05:53:27 | train] - Train Epoch: [56] [1203200/1281167 (94%)]	Loss: 1.144046
[2022-03-30 05:53:49 | train] - Train Epoch: [56] [1216000/1281167 (95%)]	Loss: 1.139959
[2022-03-30 05:54:11 | train] - Train Epoch: [56] [1228800/1281167 (96%)]	Loss: 0.940414
[2022-03-30 05:54:32 | train] - Train Epoch: [56] [1241600/1281167 (97%)]	Loss: 1.155105
[2022-03-30 05:54:53 | train] - Train Epoch: [56] [1254400/1281167 (98%)]	Loss: 1.104775
[2022-03-30 05:55:15 | train] - Train Epoch: [56] [1267200/1281167 (99%)]	Loss: 1.235836
[2022-03-30 05:55:36 | train] - Train Epoch: [56] [1280000/1281167 (100%)]	Loss: 1.076034
[2022-03-30 05:55:38 | train] - Train Epoch: [56]	 Average Loss: 1.169362	 Total Acc : 71.6280	 Total Top5 Acc : 88.8943
[2022-03-30 05:55:41 | train] - -------56 epoch end-----------
========================================
-------56 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 05:57:24 | train] - 
Epoch [56] Test set: Average loss: 1.3724, Accuracy: 33891/50000 (67.7566%), Top-5 Accuracy: 88.0962%

[2022-03-30 05:57:24 | train] - save intermediate epoch [56] result


[2022-03-30 05:57:40 | train] - -------57 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 05:57:43 | train] - Train Epoch: [57] [0/1281167 (0%)]	Loss: 1.062879
[2022-03-30 05:58:06 | train] - Train Epoch: [57] [12800/1281167 (1%)]	Loss: 0.946135
[2022-03-30 05:58:28 | train] - Train Epoch: [57] [25600/1281167 (2%)]	Loss: 1.199017
[2022-03-30 05:58:51 | train] - Train Epoch: [57] [38400/1281167 (3%)]	Loss: 1.148475
[2022-03-30 05:59:14 | train] - Train Epoch: [57] [51200/1281167 (4%)]	Loss: 0.995246
[2022-03-30 05:59:37 | train] - Train Epoch: [57] [64000/1281167 (5%)]	Loss: 1.234142
[2022-03-30 05:59:59 | train] - Train Epoch: [57] [76800/1281167 (6%)]	Loss: 1.211545
[2022-03-30 06:00:22 | train] - Train Epoch: [57] [89600/1281167 (7%)]	Loss: 1.520179
[2022-03-30 06:00:45 | train] - Train Epoch: [57] [102400/1281167 (8%)]	Loss: 1.458198
[2022-03-30 06:01:08 | train] - Train Epoch: [57] [115200/1281167 (9%)]	Loss: 1.209824
[2022-03-30 06:01:31 | train] - Train Epoch: [57] [128000/1281167 (10%)]	Loss: 1.215226
[2022-03-30 06:01:53 | train] - Train Epoch: [57] [140800/1281167 (11%)]	Loss: 1.107119
[2022-03-30 06:02:15 | train] - Train Epoch: [57] [153600/1281167 (12%)]	Loss: 0.855132
[2022-03-30 06:02:36 | train] - Train Epoch: [57] [166400/1281167 (13%)]	Loss: 0.986330
[2022-03-30 06:02:58 | train] - Train Epoch: [57] [179200/1281167 (14%)]	Loss: 1.061686
[2022-03-30 06:03:21 | train] - Train Epoch: [57] [192000/1281167 (15%)]	Loss: 0.978091
[2022-03-30 06:03:42 | train] - Train Epoch: [57] [204800/1281167 (16%)]	Loss: 0.996066
[2022-03-30 06:04:04 | train] - Train Epoch: [57] [217600/1281167 (17%)]	Loss: 1.150288
[2022-03-30 06:04:25 | train] - Train Epoch: [57] [230400/1281167 (18%)]	Loss: 0.897412
[2022-03-30 06:04:46 | train] - Train Epoch: [57] [243200/1281167 (19%)]	Loss: 1.174842
[2022-03-30 06:05:07 | train] - Train Epoch: [57] [256000/1281167 (20%)]	Loss: 1.225199
[2022-03-30 06:05:29 | train] - Train Epoch: [57] [268800/1281167 (21%)]	Loss: 1.033965
[2022-03-30 06:05:50 | train] - Train Epoch: [57] [281600/1281167 (22%)]	Loss: 1.279462
[2022-03-30 06:06:12 | train] - Train Epoch: [57] [294400/1281167 (23%)]	Loss: 1.003513
[2022-03-30 06:06:32 | train] - Train Epoch: [57] [307200/1281167 (24%)]	Loss: 1.089800
[2022-03-30 06:06:53 | train] - Train Epoch: [57] [320000/1281167 (25%)]	Loss: 1.287954
[2022-03-30 06:07:14 | train] - Train Epoch: [57] [332800/1281167 (26%)]	Loss: 1.210586
[2022-03-30 06:07:35 | train] - Train Epoch: [57] [345600/1281167 (27%)]	Loss: 1.727742
[2022-03-30 06:07:57 | train] - Train Epoch: [57] [358400/1281167 (28%)]	Loss: 1.297755
[2022-03-30 06:08:19 | train] - Train Epoch: [57] [371200/1281167 (29%)]	Loss: 1.157699
[2022-03-30 06:08:41 | train] - Train Epoch: [57] [384000/1281167 (30%)]	Loss: 1.226306
[2022-03-30 06:09:04 | train] - Train Epoch: [57] [396800/1281167 (31%)]	Loss: 1.413167
[2022-03-30 06:09:25 | train] - Train Epoch: [57] [409600/1281167 (32%)]	Loss: 1.202563
[2022-03-30 06:09:46 | train] - Train Epoch: [57] [422400/1281167 (33%)]	Loss: 1.355488
[2022-03-30 06:10:08 | train] - Train Epoch: [57] [435200/1281167 (34%)]	Loss: 1.473884
[2022-03-30 06:10:30 | train] - Train Epoch: [57] [448000/1281167 (35%)]	Loss: 1.531787
[2022-03-30 06:10:51 | train] - Train Epoch: [57] [460800/1281167 (36%)]	Loss: 0.831847
[2022-03-30 06:11:12 | train] - Train Epoch: [57] [473600/1281167 (37%)]	Loss: 1.140139
[2022-03-30 06:11:33 | train] - Train Epoch: [57] [486400/1281167 (38%)]	Loss: 1.342866
[2022-03-30 06:11:54 | train] - Train Epoch: [57] [499200/1281167 (39%)]	Loss: 1.409086
[2022-03-30 06:12:15 | train] - Train Epoch: [57] [512000/1281167 (40%)]	Loss: 1.444672
[2022-03-30 06:12:36 | train] - Train Epoch: [57] [524800/1281167 (41%)]	Loss: 1.448408
[2022-03-30 06:12:57 | train] - Train Epoch: [57] [537600/1281167 (42%)]	Loss: 1.333135
[2022-03-30 06:13:17 | train] - Train Epoch: [57] [550400/1281167 (43%)]	Loss: 1.312071
[2022-03-30 06:13:39 | train] - Train Epoch: [57] [563200/1281167 (44%)]	Loss: 1.013779
[2022-03-30 06:13:59 | train] - Train Epoch: [57] [576000/1281167 (45%)]	Loss: 1.216425
[2022-03-30 06:14:20 | train] - Train Epoch: [57] [588800/1281167 (46%)]	Loss: 1.240880
[2022-03-30 06:14:41 | train] - Train Epoch: [57] [601600/1281167 (47%)]	Loss: 1.143293
[2022-03-30 06:15:01 | train] - Train Epoch: [57] [614400/1281167 (48%)]	Loss: 1.295390
[2022-03-30 06:15:23 | train] - Train Epoch: [57] [627200/1281167 (49%)]	Loss: 1.123077
[2022-03-30 06:15:44 | train] - Train Epoch: [57] [640000/1281167 (50%)]	Loss: 1.094339
[2022-03-30 06:16:07 | train] - Train Epoch: [57] [652800/1281167 (51%)]	Loss: 1.262935
[2022-03-30 06:16:27 | train] - Train Epoch: [57] [665600/1281167 (52%)]	Loss: 0.970963
[2022-03-30 06:16:49 | train] - Train Epoch: [57] [678400/1281167 (53%)]	Loss: 0.866535
[2022-03-30 06:17:11 | train] - Train Epoch: [57] [691200/1281167 (54%)]	Loss: 0.927142
[2022-03-30 06:17:31 | train] - Train Epoch: [57] [704000/1281167 (55%)]	Loss: 0.947971
[2022-03-30 06:17:52 | train] - Train Epoch: [57] [716800/1281167 (56%)]	Loss: 1.012135
[2022-03-30 06:18:14 | train] - Train Epoch: [57] [729600/1281167 (57%)]	Loss: 0.904655
[2022-03-30 06:18:36 | train] - Train Epoch: [57] [742400/1281167 (58%)]	Loss: 1.181617
[2022-03-30 06:18:58 | train] - Train Epoch: [57] [755200/1281167 (59%)]	Loss: 1.022545
[2022-03-30 06:19:19 | train] - Train Epoch: [57] [768000/1281167 (60%)]	Loss: 1.037297
[2022-03-30 06:19:40 | train] - Train Epoch: [57] [780800/1281167 (61%)]	Loss: 1.308254
[2022-03-30 06:20:01 | train] - Train Epoch: [57] [793600/1281167 (62%)]	Loss: 1.125263
[2022-03-30 06:20:21 | train] - Train Epoch: [57] [806400/1281167 (63%)]	Loss: 1.166369
[2022-03-30 06:20:42 | train] - Train Epoch: [57] [819200/1281167 (64%)]	Loss: 1.151094
[2022-03-30 06:21:03 | train] - Train Epoch: [57] [832000/1281167 (65%)]	Loss: 1.264458
[2022-03-30 06:21:24 | train] - Train Epoch: [57] [844800/1281167 (66%)]	Loss: 1.414286
[2022-03-30 06:21:46 | train] - Train Epoch: [57] [857600/1281167 (67%)]	Loss: 1.402056
[2022-03-30 06:22:07 | train] - Train Epoch: [57] [870400/1281167 (68%)]	Loss: 1.185180
[2022-03-30 06:22:29 | train] - Train Epoch: [57] [883200/1281167 (69%)]	Loss: 0.958892
[2022-03-30 06:22:51 | train] - Train Epoch: [57] [896000/1281167 (70%)]	Loss: 1.222942
[2022-03-30 06:23:13 | train] - Train Epoch: [57] [908800/1281167 (71%)]	Loss: 1.353189
[2022-03-30 06:23:34 | train] - Train Epoch: [57] [921600/1281167 (72%)]	Loss: 1.160638
[2022-03-30 06:23:55 | train] - Train Epoch: [57] [934400/1281167 (73%)]	Loss: 0.963020
[2022-03-30 06:24:16 | train] - Train Epoch: [57] [947200/1281167 (74%)]	Loss: 0.982664
[2022-03-30 06:24:36 | train] - Train Epoch: [57] [960000/1281167 (75%)]	Loss: 1.245644
[2022-03-30 06:24:57 | train] - Train Epoch: [57] [972800/1281167 (76%)]	Loss: 1.318520
[2022-03-30 06:25:17 | train] - Train Epoch: [57] [985600/1281167 (77%)]	Loss: 1.590841
[2022-03-30 06:25:39 | train] - Train Epoch: [57] [998400/1281167 (78%)]	Loss: 1.381114
[2022-03-30 06:26:00 | train] - Train Epoch: [57] [1011200/1281167 (79%)]	Loss: 1.286268
[2022-03-30 06:26:21 | train] - Train Epoch: [57] [1024000/1281167 (80%)]	Loss: 1.063342
[2022-03-30 06:26:40 | train] - Train Epoch: [57] [1036800/1281167 (81%)]	Loss: 1.150729
[2022-03-30 06:27:01 | train] - Train Epoch: [57] [1049600/1281167 (82%)]	Loss: 0.925295
[2022-03-30 06:27:22 | train] - Train Epoch: [57] [1062400/1281167 (83%)]	Loss: 1.315950
[2022-03-30 06:27:43 | train] - Train Epoch: [57] [1075200/1281167 (84%)]	Loss: 1.141059
[2022-03-30 06:28:06 | train] - Train Epoch: [57] [1088000/1281167 (85%)]	Loss: 0.825462
[2022-03-30 06:28:27 | train] - Train Epoch: [57] [1100800/1281167 (86%)]	Loss: 1.202415
[2022-03-30 06:28:48 | train] - Train Epoch: [57] [1113600/1281167 (87%)]	Loss: 1.194865
[2022-03-30 06:29:09 | train] - Train Epoch: [57] [1126400/1281167 (88%)]	Loss: 1.356270
[2022-03-30 06:29:30 | train] - Train Epoch: [57] [1139200/1281167 (89%)]	Loss: 1.203163
[2022-03-30 06:29:52 | train] - Train Epoch: [57] [1152000/1281167 (90%)]	Loss: 1.344195
[2022-03-30 06:30:14 | train] - Train Epoch: [57] [1164800/1281167 (91%)]	Loss: 1.084214
[2022-03-30 06:30:34 | train] - Train Epoch: [57] [1177600/1281167 (92%)]	Loss: 1.206439
[2022-03-30 06:30:54 | train] - Train Epoch: [57] [1190400/1281167 (93%)]	Loss: 1.185565
[2022-03-30 06:31:14 | train] - Train Epoch: [57] [1203200/1281167 (94%)]	Loss: 1.325731
[2022-03-30 06:31:35 | train] - Train Epoch: [57] [1216000/1281167 (95%)]	Loss: 0.976191
[2022-03-30 06:31:56 | train] - Train Epoch: [57] [1228800/1281167 (96%)]	Loss: 1.221108
[2022-03-30 06:32:18 | train] - Train Epoch: [57] [1241600/1281167 (97%)]	Loss: 1.281426
[2022-03-30 06:32:39 | train] - Train Epoch: [57] [1254400/1281167 (98%)]	Loss: 1.158661
[2022-03-30 06:33:00 | train] - Train Epoch: [57] [1267200/1281167 (99%)]	Loss: 1.018764
[2022-03-30 06:33:22 | train] - Train Epoch: [57] [1280000/1281167 (100%)]	Loss: 1.129330
[2022-03-30 06:33:24 | train] - Train Epoch: [57]	 Average Loss: 1.162771	 Total Acc : 71.7890	 Total Top5 Acc : 88.9775
[2022-03-30 06:33:27 | train] - -------57 epoch end-----------
========================================
-------57 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 06:35:09 | train] - 
Epoch [57] Test set: Average loss: 1.3693, Accuracy: 34147/50000 (68.2657%), Top-5 Accuracy: 88.0591%

[2022-03-30 06:35:09 | train] - save intermediate epoch [57] result


[2022-03-30 06:35:26 | train] - -------58 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 06:35:28 | train] - Train Epoch: [58] [0/1281167 (0%)]	Loss: 0.923469
[2022-03-30 06:35:52 | train] - Train Epoch: [58] [12800/1281167 (1%)]	Loss: 1.044707
[2022-03-30 06:36:14 | train] - Train Epoch: [58] [25600/1281167 (2%)]	Loss: 1.107415
[2022-03-30 06:36:37 | train] - Train Epoch: [58] [38400/1281167 (3%)]	Loss: 1.062579
[2022-03-30 06:37:00 | train] - Train Epoch: [58] [51200/1281167 (4%)]	Loss: 0.997394
[2022-03-30 06:37:22 | train] - Train Epoch: [58] [64000/1281167 (5%)]	Loss: 1.433714
[2022-03-30 06:37:45 | train] - Train Epoch: [58] [76800/1281167 (6%)]	Loss: 1.003374
[2022-03-30 06:38:07 | train] - Train Epoch: [58] [89600/1281167 (7%)]	Loss: 0.889553
[2022-03-30 06:38:31 | train] - Train Epoch: [58] [102400/1281167 (8%)]	Loss: 1.067527
[2022-03-30 06:38:53 | train] - Train Epoch: [58] [115200/1281167 (9%)]	Loss: 1.205607
[2022-03-30 06:39:16 | train] - Train Epoch: [58] [128000/1281167 (10%)]	Loss: 1.015248
[2022-03-30 06:39:38 | train] - Train Epoch: [58] [140800/1281167 (11%)]	Loss: 1.013104
[2022-03-30 06:40:00 | train] - Train Epoch: [58] [153600/1281167 (12%)]	Loss: 1.683658
[2022-03-30 06:40:23 | train] - Train Epoch: [58] [166400/1281167 (13%)]	Loss: 0.968347
[2022-03-30 06:40:46 | train] - Train Epoch: [58] [179200/1281167 (14%)]	Loss: 1.181406
[2022-03-30 06:41:09 | train] - Train Epoch: [58] [192000/1281167 (15%)]	Loss: 1.146770
[2022-03-30 06:41:32 | train] - Train Epoch: [58] [204800/1281167 (16%)]	Loss: 1.414840
[2022-03-30 06:41:54 | train] - Train Epoch: [58] [217600/1281167 (17%)]	Loss: 0.873066
[2022-03-30 06:42:17 | train] - Train Epoch: [58] [230400/1281167 (18%)]	Loss: 1.056700
[2022-03-30 06:42:39 | train] - Train Epoch: [58] [243200/1281167 (19%)]	Loss: 1.088358
[2022-03-30 06:43:03 | train] - Train Epoch: [58] [256000/1281167 (20%)]	Loss: 0.877505
[2022-03-30 06:43:24 | train] - Train Epoch: [58] [268800/1281167 (21%)]	Loss: 1.499388
[2022-03-30 06:43:47 | train] - Train Epoch: [58] [281600/1281167 (22%)]	Loss: 1.025353
[2022-03-30 06:44:09 | train] - Train Epoch: [58] [294400/1281167 (23%)]	Loss: 1.210810
[2022-03-30 06:44:32 | train] - Train Epoch: [58] [307200/1281167 (24%)]	Loss: 0.991599
[2022-03-30 06:44:53 | train] - Train Epoch: [58] [320000/1281167 (25%)]	Loss: 1.364258
[2022-03-30 06:45:15 | train] - Train Epoch: [58] [332800/1281167 (26%)]	Loss: 1.242850
[2022-03-30 06:45:37 | train] - Train Epoch: [58] [345600/1281167 (27%)]	Loss: 1.415566
[2022-03-30 06:45:58 | train] - Train Epoch: [58] [358400/1281167 (28%)]	Loss: 1.179474
[2022-03-30 06:46:19 | train] - Train Epoch: [58] [371200/1281167 (29%)]	Loss: 1.093363
[2022-03-30 06:46:40 | train] - Train Epoch: [58] [384000/1281167 (30%)]	Loss: 1.357899
[2022-03-30 06:47:01 | train] - Train Epoch: [58] [396800/1281167 (31%)]	Loss: 1.045065
[2022-03-30 06:47:22 | train] - Train Epoch: [58] [409600/1281167 (32%)]	Loss: 1.252894
[2022-03-30 06:47:44 | train] - Train Epoch: [58] [422400/1281167 (33%)]	Loss: 1.264339
[2022-03-30 06:48:04 | train] - Train Epoch: [58] [435200/1281167 (34%)]	Loss: 1.150845
[2022-03-30 06:48:25 | train] - Train Epoch: [58] [448000/1281167 (35%)]	Loss: 1.322018
[2022-03-30 06:48:47 | train] - Train Epoch: [58] [460800/1281167 (36%)]	Loss: 0.982897
[2022-03-30 06:49:09 | train] - Train Epoch: [58] [473600/1281167 (37%)]	Loss: 1.141746
[2022-03-30 06:49:30 | train] - Train Epoch: [58] [486400/1281167 (38%)]	Loss: 1.088913
[2022-03-30 06:49:51 | train] - Train Epoch: [58] [499200/1281167 (39%)]	Loss: 1.000301
[2022-03-30 06:50:13 | train] - Train Epoch: [58] [512000/1281167 (40%)]	Loss: 0.920279
[2022-03-30 06:50:34 | train] - Train Epoch: [58] [524800/1281167 (41%)]	Loss: 1.092015
[2022-03-30 06:50:55 | train] - Train Epoch: [58] [537600/1281167 (42%)]	Loss: 1.142454
[2022-03-30 06:51:15 | train] - Train Epoch: [58] [550400/1281167 (43%)]	Loss: 1.102308
[2022-03-30 06:51:37 | train] - Train Epoch: [58] [563200/1281167 (44%)]	Loss: 0.999235
[2022-03-30 06:51:58 | train] - Train Epoch: [58] [576000/1281167 (45%)]	Loss: 1.037465
[2022-03-30 06:52:19 | train] - Train Epoch: [58] [588800/1281167 (46%)]	Loss: 1.232156
[2022-03-30 06:52:40 | train] - Train Epoch: [58] [601600/1281167 (47%)]	Loss: 1.481080
[2022-03-30 06:53:01 | train] - Train Epoch: [58] [614400/1281167 (48%)]	Loss: 0.800856
[2022-03-30 06:53:22 | train] - Train Epoch: [58] [627200/1281167 (49%)]	Loss: 1.180944
[2022-03-30 06:53:43 | train] - Train Epoch: [58] [640000/1281167 (50%)]	Loss: 1.169936
[2022-03-30 06:54:03 | train] - Train Epoch: [58] [652800/1281167 (51%)]	Loss: 1.294836
[2022-03-30 06:54:26 | train] - Train Epoch: [58] [665600/1281167 (52%)]	Loss: 1.020242
[2022-03-30 06:54:46 | train] - Train Epoch: [58] [678400/1281167 (53%)]	Loss: 1.206614
[2022-03-30 06:55:07 | train] - Train Epoch: [58] [691200/1281167 (54%)]	Loss: 1.460400
[2022-03-30 06:55:28 | train] - Train Epoch: [58] [704000/1281167 (55%)]	Loss: 1.039565
[2022-03-30 06:55:49 | train] - Train Epoch: [58] [716800/1281167 (56%)]	Loss: 0.893132
[2022-03-30 06:56:09 | train] - Train Epoch: [58] [729600/1281167 (57%)]	Loss: 0.951534
[2022-03-30 06:56:30 | train] - Train Epoch: [58] [742400/1281167 (58%)]	Loss: 1.129808
[2022-03-30 06:56:51 | train] - Train Epoch: [58] [755200/1281167 (59%)]	Loss: 1.277679
[2022-03-30 06:57:13 | train] - Train Epoch: [58] [768000/1281167 (60%)]	Loss: 1.019520
[2022-03-30 06:57:35 | train] - Train Epoch: [58] [780800/1281167 (61%)]	Loss: 1.143227
[2022-03-30 06:57:57 | train] - Train Epoch: [58] [793600/1281167 (62%)]	Loss: 1.426517
[2022-03-30 06:58:18 | train] - Train Epoch: [58] [806400/1281167 (63%)]	Loss: 1.046661
[2022-03-30 06:58:40 | train] - Train Epoch: [58] [819200/1281167 (64%)]	Loss: 1.146066
[2022-03-30 06:59:02 | train] - Train Epoch: [58] [832000/1281167 (65%)]	Loss: 1.239144
[2022-03-30 06:59:23 | train] - Train Epoch: [58] [844800/1281167 (66%)]	Loss: 1.308569
[2022-03-30 06:59:45 | train] - Train Epoch: [58] [857600/1281167 (67%)]	Loss: 1.047789
[2022-03-30 07:00:07 | train] - Train Epoch: [58] [870400/1281167 (68%)]	Loss: 1.150248
[2022-03-30 07:00:28 | train] - Train Epoch: [58] [883200/1281167 (69%)]	Loss: 1.273144
[2022-03-30 07:00:50 | train] - Train Epoch: [58] [896000/1281167 (70%)]	Loss: 0.953046
[2022-03-30 07:01:11 | train] - Train Epoch: [58] [908800/1281167 (71%)]	Loss: 1.248549
[2022-03-30 07:01:31 | train] - Train Epoch: [58] [921600/1281167 (72%)]	Loss: 1.227774
[2022-03-30 07:01:53 | train] - Train Epoch: [58] [934400/1281167 (73%)]	Loss: 1.091773
[2022-03-30 07:02:14 | train] - Train Epoch: [58] [947200/1281167 (74%)]	Loss: 1.184010
[2022-03-30 07:02:34 | train] - Train Epoch: [58] [960000/1281167 (75%)]	Loss: 1.367208
[2022-03-30 07:02:55 | train] - Train Epoch: [58] [972800/1281167 (76%)]	Loss: 0.859564
[2022-03-30 07:03:15 | train] - Train Epoch: [58] [985600/1281167 (77%)]	Loss: 0.971653
[2022-03-30 07:03:36 | train] - Train Epoch: [58] [998400/1281167 (78%)]	Loss: 1.371545
[2022-03-30 07:03:58 | train] - Train Epoch: [58] [1011200/1281167 (79%)]	Loss: 1.062811
[2022-03-30 07:04:19 | train] - Train Epoch: [58] [1024000/1281167 (80%)]	Loss: 1.128885
[2022-03-30 07:04:40 | train] - Train Epoch: [58] [1036800/1281167 (81%)]	Loss: 1.187562
[2022-03-30 07:05:01 | train] - Train Epoch: [58] [1049600/1281167 (82%)]	Loss: 1.226786
[2022-03-30 07:05:22 | train] - Train Epoch: [58] [1062400/1281167 (83%)]	Loss: 1.275232
[2022-03-30 07:05:43 | train] - Train Epoch: [58] [1075200/1281167 (84%)]	Loss: 0.982097
[2022-03-30 07:06:05 | train] - Train Epoch: [58] [1088000/1281167 (85%)]	Loss: 1.133886
[2022-03-30 07:06:26 | train] - Train Epoch: [58] [1100800/1281167 (86%)]	Loss: 1.124159
[2022-03-30 07:06:48 | train] - Train Epoch: [58] [1113600/1281167 (87%)]	Loss: 1.136775
[2022-03-30 07:07:09 | train] - Train Epoch: [58] [1126400/1281167 (88%)]	Loss: 1.384209
[2022-03-30 07:07:31 | train] - Train Epoch: [58] [1139200/1281167 (89%)]	Loss: 1.074850
[2022-03-30 07:07:51 | train] - Train Epoch: [58] [1152000/1281167 (90%)]	Loss: 1.397856
[2022-03-30 07:08:13 | train] - Train Epoch: [58] [1164800/1281167 (91%)]	Loss: 0.887492
[2022-03-30 07:08:33 | train] - Train Epoch: [58] [1177600/1281167 (92%)]	Loss: 1.130614
[2022-03-30 07:08:54 | train] - Train Epoch: [58] [1190400/1281167 (93%)]	Loss: 0.799353
[2022-03-30 07:09:14 | train] - Train Epoch: [58] [1203200/1281167 (94%)]	Loss: 0.988262
[2022-03-30 07:09:34 | train] - Train Epoch: [58] [1216000/1281167 (95%)]	Loss: 1.056122
[2022-03-30 07:09:56 | train] - Train Epoch: [58] [1228800/1281167 (96%)]	Loss: 1.347808
[2022-03-30 07:10:17 | train] - Train Epoch: [58] [1241600/1281167 (97%)]	Loss: 1.369237
[2022-03-30 07:10:39 | train] - Train Epoch: [58] [1254400/1281167 (98%)]	Loss: 0.972674
[2022-03-30 07:10:59 | train] - Train Epoch: [58] [1267200/1281167 (99%)]	Loss: 1.222374
[2022-03-30 07:11:19 | train] - Train Epoch: [58] [1280000/1281167 (100%)]	Loss: 1.012005
[2022-03-30 07:11:21 | train] - Train Epoch: [58]	 Average Loss: 1.153860	 Total Acc : 71.9656	 Total Top5 Acc : 89.0850
[2022-03-30 07:11:24 | train] - -------58 epoch end-----------
========================================
-------58 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 07:13:07 | train] - 
Epoch [58] Test set: Average loss: 1.3761, Accuracy: 34170/50000 (68.3248%), Top-5 Accuracy: 88.2413%

[2022-03-30 07:13:07 | train] - save intermediate epoch [58] result


[2022-03-30 07:13:23 | train] - -------59 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 07:13:25 | train] - Train Epoch: [59] [0/1281167 (0%)]	Loss: 1.469677
[2022-03-30 07:13:48 | train] - Train Epoch: [59] [12800/1281167 (1%)]	Loss: 0.891262
[2022-03-30 07:14:12 | train] - Train Epoch: [59] [25600/1281167 (2%)]	Loss: 1.141543
[2022-03-30 07:14:34 | train] - Train Epoch: [59] [38400/1281167 (3%)]	Loss: 1.140396
[2022-03-30 07:14:59 | train] - Train Epoch: [59] [51200/1281167 (4%)]	Loss: 1.260568
[2022-03-30 07:15:22 | train] - Train Epoch: [59] [64000/1281167 (5%)]	Loss: 1.190333
[2022-03-30 07:15:46 | train] - Train Epoch: [59] [76800/1281167 (6%)]	Loss: 1.363360
[2022-03-30 07:16:09 | train] - Train Epoch: [59] [89600/1281167 (7%)]	Loss: 1.099125
[2022-03-30 07:16:31 | train] - Train Epoch: [59] [102400/1281167 (8%)]	Loss: 0.970277
[2022-03-30 07:16:53 | train] - Train Epoch: [59] [115200/1281167 (9%)]	Loss: 1.151538
[2022-03-30 07:17:14 | train] - Train Epoch: [59] [128000/1281167 (10%)]	Loss: 1.250353
[2022-03-30 07:17:36 | train] - Train Epoch: [59] [140800/1281167 (11%)]	Loss: 0.913220
[2022-03-30 07:17:57 | train] - Train Epoch: [59] [153600/1281167 (12%)]	Loss: 1.141748
[2022-03-30 07:18:19 | train] - Train Epoch: [59] [166400/1281167 (13%)]	Loss: 0.906237
[2022-03-30 07:18:40 | train] - Train Epoch: [59] [179200/1281167 (14%)]	Loss: 1.032059
[2022-03-30 07:19:02 | train] - Train Epoch: [59] [192000/1281167 (15%)]	Loss: 1.201879
[2022-03-30 07:19:23 | train] - Train Epoch: [59] [204800/1281167 (16%)]	Loss: 1.074414
[2022-03-30 07:19:45 | train] - Train Epoch: [59] [217600/1281167 (17%)]	Loss: 1.163985
[2022-03-30 07:20:06 | train] - Train Epoch: [59] [230400/1281167 (18%)]	Loss: 1.336380
[2022-03-30 07:20:28 | train] - Train Epoch: [59] [243200/1281167 (19%)]	Loss: 0.872072
[2022-03-30 07:20:49 | train] - Train Epoch: [59] [256000/1281167 (20%)]	Loss: 1.269226
[2022-03-30 07:21:11 | train] - Train Epoch: [59] [268800/1281167 (21%)]	Loss: 0.850092
[2022-03-30 07:21:32 | train] - Train Epoch: [59] [281600/1281167 (22%)]	Loss: 1.226990
[2022-03-30 07:21:53 | train] - Train Epoch: [59] [294400/1281167 (23%)]	Loss: 1.065373
[2022-03-30 07:22:14 | train] - Train Epoch: [59] [307200/1281167 (24%)]	Loss: 1.343602
[2022-03-30 07:22:35 | train] - Train Epoch: [59] [320000/1281167 (25%)]	Loss: 1.521205
[2022-03-30 07:22:56 | train] - Train Epoch: [59] [332800/1281167 (26%)]	Loss: 1.164255
[2022-03-30 07:23:17 | train] - Train Epoch: [59] [345600/1281167 (27%)]	Loss: 0.927370
[2022-03-30 07:23:39 | train] - Train Epoch: [59] [358400/1281167 (28%)]	Loss: 1.188233
[2022-03-30 07:23:59 | train] - Train Epoch: [59] [371200/1281167 (29%)]	Loss: 1.080722
[2022-03-30 07:24:21 | train] - Train Epoch: [59] [384000/1281167 (30%)]	Loss: 1.013931
[2022-03-30 07:24:41 | train] - Train Epoch: [59] [396800/1281167 (31%)]	Loss: 1.146694
[2022-03-30 07:25:02 | train] - Train Epoch: [59] [409600/1281167 (32%)]	Loss: 0.888701
[2022-03-30 07:25:23 | train] - Train Epoch: [59] [422400/1281167 (33%)]	Loss: 0.749639
[2022-03-30 07:25:44 | train] - Train Epoch: [59] [435200/1281167 (34%)]	Loss: 1.173412
[2022-03-30 07:26:05 | train] - Train Epoch: [59] [448000/1281167 (35%)]	Loss: 1.173250
[2022-03-30 07:26:26 | train] - Train Epoch: [59] [460800/1281167 (36%)]	Loss: 1.460213
[2022-03-30 07:26:48 | train] - Train Epoch: [59] [473600/1281167 (37%)]	Loss: 1.078980
[2022-03-30 07:27:09 | train] - Train Epoch: [59] [486400/1281167 (38%)]	Loss: 1.173785
[2022-03-30 07:27:32 | train] - Train Epoch: [59] [499200/1281167 (39%)]	Loss: 0.882075
[2022-03-30 07:27:54 | train] - Train Epoch: [59] [512000/1281167 (40%)]	Loss: 1.089022
[2022-03-30 07:28:16 | train] - Train Epoch: [59] [524800/1281167 (41%)]	Loss: 0.826575
[2022-03-30 07:28:38 | train] - Train Epoch: [59] [537600/1281167 (42%)]	Loss: 1.023585
[2022-03-30 07:28:59 | train] - Train Epoch: [59] [550400/1281167 (43%)]	Loss: 0.858841
[2022-03-30 07:29:21 | train] - Train Epoch: [59] [563200/1281167 (44%)]	Loss: 1.093931
[2022-03-30 07:29:43 | train] - Train Epoch: [59] [576000/1281167 (45%)]	Loss: 1.025390
[2022-03-30 07:30:04 | train] - Train Epoch: [59] [588800/1281167 (46%)]	Loss: 1.219202
[2022-03-30 07:30:26 | train] - Train Epoch: [59] [601600/1281167 (47%)]	Loss: 1.307420
[2022-03-30 07:30:47 | train] - Train Epoch: [59] [614400/1281167 (48%)]	Loss: 1.155206
[2022-03-30 07:31:08 | train] - Train Epoch: [59] [627200/1281167 (49%)]	Loss: 1.240224
[2022-03-30 07:31:31 | train] - Train Epoch: [59] [640000/1281167 (50%)]	Loss: 1.394771
[2022-03-30 07:31:52 | train] - Train Epoch: [59] [652800/1281167 (51%)]	Loss: 1.265404
[2022-03-30 07:32:13 | train] - Train Epoch: [59] [665600/1281167 (52%)]	Loss: 1.255948
[2022-03-30 07:32:35 | train] - Train Epoch: [59] [678400/1281167 (53%)]	Loss: 1.026219
[2022-03-30 07:32:56 | train] - Train Epoch: [59] [691200/1281167 (54%)]	Loss: 1.145598
[2022-03-30 07:33:18 | train] - Train Epoch: [59] [704000/1281167 (55%)]	Loss: 1.002710
[2022-03-30 07:33:40 | train] - Train Epoch: [59] [716800/1281167 (56%)]	Loss: 1.343150
[2022-03-30 07:34:01 | train] - Train Epoch: [59] [729600/1281167 (57%)]	Loss: 1.017802
[2022-03-30 07:34:22 | train] - Train Epoch: [59] [742400/1281167 (58%)]	Loss: 1.115252
[2022-03-30 07:34:43 | train] - Train Epoch: [59] [755200/1281167 (59%)]	Loss: 1.481231
[2022-03-30 07:35:04 | train] - Train Epoch: [59] [768000/1281167 (60%)]	Loss: 1.136030
[2022-03-30 07:35:26 | train] - Train Epoch: [59] [780800/1281167 (61%)]	Loss: 1.336133
[2022-03-30 07:35:47 | train] - Train Epoch: [59] [793600/1281167 (62%)]	Loss: 1.300743
[2022-03-30 07:36:08 | train] - Train Epoch: [59] [806400/1281167 (63%)]	Loss: 1.534934
[2022-03-30 07:36:30 | train] - Train Epoch: [59] [819200/1281167 (64%)]	Loss: 1.210616
[2022-03-30 07:36:52 | train] - Train Epoch: [59] [832000/1281167 (65%)]	Loss: 1.408078
[2022-03-30 07:37:13 | train] - Train Epoch: [59] [844800/1281167 (66%)]	Loss: 0.784481
[2022-03-30 07:37:35 | train] - Train Epoch: [59] [857600/1281167 (67%)]	Loss: 1.141363
[2022-03-30 07:37:56 | train] - Train Epoch: [59] [870400/1281167 (68%)]	Loss: 1.103959
[2022-03-30 07:38:17 | train] - Train Epoch: [59] [883200/1281167 (69%)]	Loss: 0.805397
[2022-03-30 07:38:39 | train] - Train Epoch: [59] [896000/1281167 (70%)]	Loss: 1.265277
[2022-03-30 07:39:00 | train] - Train Epoch: [59] [908800/1281167 (71%)]	Loss: 1.173229
[2022-03-30 07:39:21 | train] - Train Epoch: [59] [921600/1281167 (72%)]	Loss: 1.168248
[2022-03-30 07:39:43 | train] - Train Epoch: [59] [934400/1281167 (73%)]	Loss: 1.090165
[2022-03-30 07:40:05 | train] - Train Epoch: [59] [947200/1281167 (74%)]	Loss: 1.069758
[2022-03-30 07:40:26 | train] - Train Epoch: [59] [960000/1281167 (75%)]	Loss: 1.103254
[2022-03-30 07:40:47 | train] - Train Epoch: [59] [972800/1281167 (76%)]	Loss: 1.161617
[2022-03-30 07:41:08 | train] - Train Epoch: [59] [985600/1281167 (77%)]	Loss: 1.396978
[2022-03-30 07:41:30 | train] - Train Epoch: [59] [998400/1281167 (78%)]	Loss: 1.251334
[2022-03-30 07:41:51 | train] - Train Epoch: [59] [1011200/1281167 (79%)]	Loss: 1.231445
[2022-03-30 07:42:12 | train] - Train Epoch: [59] [1024000/1281167 (80%)]	Loss: 0.909461
[2022-03-30 07:42:34 | train] - Train Epoch: [59] [1036800/1281167 (81%)]	Loss: 0.798241
[2022-03-30 07:42:55 | train] - Train Epoch: [59] [1049600/1281167 (82%)]	Loss: 1.110024
[2022-03-30 07:43:17 | train] - Train Epoch: [59] [1062400/1281167 (83%)]	Loss: 0.615102
[2022-03-30 07:43:39 | train] - Train Epoch: [59] [1075200/1281167 (84%)]	Loss: 0.817250
[2022-03-30 07:44:01 | train] - Train Epoch: [59] [1088000/1281167 (85%)]	Loss: 1.082960
[2022-03-30 07:44:23 | train] - Train Epoch: [59] [1100800/1281167 (86%)]	Loss: 1.431088
[2022-03-30 07:44:44 | train] - Train Epoch: [59] [1113600/1281167 (87%)]	Loss: 1.337829
[2022-03-30 07:45:05 | train] - Train Epoch: [59] [1126400/1281167 (88%)]	Loss: 0.963218
[2022-03-30 07:45:26 | train] - Train Epoch: [59] [1139200/1281167 (89%)]	Loss: 0.891741
[2022-03-30 07:45:48 | train] - Train Epoch: [59] [1152000/1281167 (90%)]	Loss: 1.468001
[2022-03-30 07:46:09 | train] - Train Epoch: [59] [1164800/1281167 (91%)]	Loss: 1.395356
[2022-03-30 07:46:30 | train] - Train Epoch: [59] [1177600/1281167 (92%)]	Loss: 1.157096
[2022-03-30 07:46:52 | train] - Train Epoch: [59] [1190400/1281167 (93%)]	Loss: 1.446313
[2022-03-30 07:47:13 | train] - Train Epoch: [59] [1203200/1281167 (94%)]	Loss: 0.781327
[2022-03-30 07:47:34 | train] - Train Epoch: [59] [1216000/1281167 (95%)]	Loss: 1.389537
[2022-03-30 07:47:55 | train] - Train Epoch: [59] [1228800/1281167 (96%)]	Loss: 1.229126
[2022-03-30 07:48:17 | train] - Train Epoch: [59] [1241600/1281167 (97%)]	Loss: 1.035697
[2022-03-30 07:48:38 | train] - Train Epoch: [59] [1254400/1281167 (98%)]	Loss: 1.060182
[2022-03-30 07:48:59 | train] - Train Epoch: [59] [1267200/1281167 (99%)]	Loss: 1.288701
[2022-03-30 07:49:21 | train] - Train Epoch: [59] [1280000/1281167 (100%)]	Loss: 1.209953
[2022-03-30 07:49:24 | train] - Train Epoch: [59]	 Average Loss: 1.146575	 Total Acc : 72.1252	 Total Top5 Acc : 89.1374
[2022-03-30 07:49:27 | train] - -------59 epoch end-----------
========================================
-------59 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 07:51:09 | train] - 
Epoch [59] Test set: Average loss: 1.3907, Accuracy: 34014/50000 (68.0023%), Top-5 Accuracy: 87.9368%

[2022-03-30 07:51:09 | train] - save intermediate epoch [59] result


[2022-03-30 07:51:25 | train] - -------60 epoch start-----------
[2022-03-30 07:51:25 | train] - -------- logging 60 batch layer input tensor ------------------
========================================
----- test end -------------------------


Traceback (most recent call last):
  File "main.py", line 382, in <module>
    main()
  File "main.py", line 279, in main
    result_fwd_hook_list, result_bwd_hook_list = batchnorm_hook_result(net, check_data, check_label, optimizer, option)
  File "main.py", line 138, in batchnorm_hook_result
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 352, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 39.41 GiB total capacity; 36.52 GiB already allocated; 355.50 MiB free; 37.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[2022-03-30 17:44:53 | train] - -------start batchnorm param logging -----------

[2022-03-30 17:44:54 | train] - -------end batchnorm param logging -----------

[2022-03-30 17:44:54 | train] - -------69 epoch start-----------
/data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
load log path /data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/
load pretrained model : epoch 69
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
[2022-03-30 17:44:56 | train] - Train Epoch: [69] [0/1281167 (0%)]	Loss: 0.910718
[2022-03-30 17:45:15 | train] - Train Epoch: [69] [12800/1281167 (1%)]	Loss: 0.818265
[2022-03-30 17:45:36 | train] - Train Epoch: [69] [25600/1281167 (2%)]	Loss: 0.744146
[2022-03-30 17:45:56 | train] - Train Epoch: [69] [38400/1281167 (3%)]	Loss: 0.819717
[2022-03-30 17:46:17 | train] - Train Epoch: [69] [51200/1281167 (4%)]	Loss: 0.670431
[2022-03-30 17:46:38 | train] - Train Epoch: [69] [64000/1281167 (5%)]	Loss: 0.758536
[2022-03-30 17:47:00 | train] - Train Epoch: [69] [76800/1281167 (6%)]	Loss: 0.957443
[2022-03-30 17:47:20 | train] - Train Epoch: [69] [89600/1281167 (7%)]	Loss: 0.875234
[2022-03-30 17:47:40 | train] - Train Epoch: [69] [102400/1281167 (8%)]	Loss: 1.003394
[2022-03-30 17:47:59 | train] - Train Epoch: [69] [115200/1281167 (9%)]	Loss: 0.722044
[2022-03-30 17:48:20 | train] - Train Epoch: [69] [128000/1281167 (10%)]	Loss: 0.623373
[2022-03-30 17:48:40 | train] - Train Epoch: [69] [140800/1281167 (11%)]	Loss: 1.022555
[2022-03-30 17:49:02 | train] - Train Epoch: [69] [153600/1281167 (12%)]	Loss: 0.970457
[2022-03-30 17:49:21 | train] - Train Epoch: [69] [166400/1281167 (13%)]	Loss: 0.814876
[2022-03-30 17:49:41 | train] - Train Epoch: [69] [179200/1281167 (14%)]	Loss: 0.972580
[2022-03-30 17:50:01 | train] - Train Epoch: [69] [192000/1281167 (15%)]	Loss: 1.077217
[2022-03-30 17:50:22 | train] - Train Epoch: [69] [204800/1281167 (16%)]	Loss: 0.905944
[2022-03-30 17:50:43 | train] - Train Epoch: [69] [217600/1281167 (17%)]	Loss: 1.036936
[2022-03-30 17:51:03 | train] - Train Epoch: [69] [230400/1281167 (18%)]	Loss: 0.948069
[2022-03-30 17:51:23 | train] - Train Epoch: [69] [243200/1281167 (19%)]	Loss: 0.979732
[2022-03-30 17:51:43 | train] - Train Epoch: [69] [256000/1281167 (20%)]	Loss: 1.043328
[2022-03-30 17:52:03 | train] - Train Epoch: [69] [268800/1281167 (21%)]	Loss: 1.113805
[2022-03-30 17:52:22 | train] - Train Epoch: [69] [281600/1281167 (22%)]	Loss: 0.875699
[2022-03-30 17:52:42 | train] - Train Epoch: [69] [294400/1281167 (23%)]	Loss: 0.681300
[2022-03-30 17:53:02 | train] - Train Epoch: [69] [307200/1281167 (24%)]	Loss: 0.658687
[2022-03-30 17:53:21 | train] - Train Epoch: [69] [320000/1281167 (25%)]	Loss: 1.014622
[2022-03-30 17:53:41 | train] - Train Epoch: [69] [332800/1281167 (26%)]	Loss: 0.863405
[2022-03-30 17:54:01 | train] - Train Epoch: [69] [345600/1281167 (27%)]	Loss: 0.969249
[2022-03-30 17:54:21 | train] - Train Epoch: [69] [358400/1281167 (28%)]	Loss: 0.917250
[2022-03-30 17:54:41 | train] - Train Epoch: [69] [371200/1281167 (29%)]	Loss: 0.674850
[2022-03-30 17:55:01 | train] - Train Epoch: [69] [384000/1281167 (30%)]	Loss: 0.758551
[2022-03-30 17:55:21 | train] - Train Epoch: [69] [396800/1281167 (31%)]	Loss: 0.585410
[2022-03-30 17:55:40 | train] - Train Epoch: [69] [409600/1281167 (32%)]	Loss: 0.980895
[2022-03-30 17:55:59 | train] - Train Epoch: [69] [422400/1281167 (33%)]	Loss: 0.824548
[2022-03-30 17:56:19 | train] - Train Epoch: [69] [435200/1281167 (34%)]	Loss: 0.872254
[2022-03-30 17:56:38 | train] - Train Epoch: [69] [448000/1281167 (35%)]	Loss: 0.737778
[2022-03-30 17:56:58 | train] - Train Epoch: [69] [460800/1281167 (36%)]	Loss: 0.889242
[2022-03-30 17:57:18 | train] - Train Epoch: [69] [473600/1281167 (37%)]	Loss: 0.809861
[2022-03-30 17:57:38 | train] - Train Epoch: [69] [486400/1281167 (38%)]	Loss: 1.055398
[2022-03-30 17:57:57 | train] - Train Epoch: [69] [499200/1281167 (39%)]	Loss: 0.670987
[2022-03-30 17:58:17 | train] - Train Epoch: [69] [512000/1281167 (40%)]	Loss: 0.666886
[2022-03-30 17:58:37 | train] - Train Epoch: [69] [524800/1281167 (41%)]	Loss: 0.943349
[2022-03-30 17:58:57 | train] - Train Epoch: [69] [537600/1281167 (42%)]	Loss: 0.779396
[2022-03-30 17:59:17 | train] - Train Epoch: [69] [550400/1281167 (43%)]	Loss: 0.858892
[2022-03-30 17:59:37 | train] - Train Epoch: [69] [563200/1281167 (44%)]	Loss: 0.812067
[2022-03-30 17:59:57 | train] - Train Epoch: [69] [576000/1281167 (45%)]	Loss: 0.841930
[2022-03-30 18:00:18 | train] - Train Epoch: [69] [588800/1281167 (46%)]	Loss: 0.976719
[2022-03-30 18:00:38 | train] - Train Epoch: [69] [601600/1281167 (47%)]	Loss: 0.919774
[2022-03-30 18:00:58 | train] - Train Epoch: [69] [614400/1281167 (48%)]	Loss: 0.708666
[2022-03-30 18:01:18 | train] - Train Epoch: [69] [627200/1281167 (49%)]	Loss: 0.824978
[2022-03-30 18:01:37 | train] - Train Epoch: [69] [640000/1281167 (50%)]	Loss: 1.042862
[2022-03-30 18:01:58 | train] - Train Epoch: [69] [652800/1281167 (51%)]	Loss: 0.762837
[2022-03-30 18:02:18 | train] - Train Epoch: [69] [665600/1281167 (52%)]	Loss: 1.205348
[2022-03-30 18:02:38 | train] - Train Epoch: [69] [678400/1281167 (53%)]	Loss: 0.695841
[2022-03-30 18:02:59 | train] - Train Epoch: [69] [691200/1281167 (54%)]	Loss: 0.741537
[2022-03-30 18:03:19 | train] - Train Epoch: [69] [704000/1281167 (55%)]	Loss: 0.916516
[2022-03-30 18:03:38 | train] - Train Epoch: [69] [716800/1281167 (56%)]	Loss: 0.657991
[2022-03-30 18:03:58 | train] - Train Epoch: [69] [729600/1281167 (57%)]	Loss: 0.651043
[2022-03-30 18:04:18 | train] - Train Epoch: [69] [742400/1281167 (58%)]	Loss: 0.812155
[2022-03-30 18:04:38 | train] - Train Epoch: [69] [755200/1281167 (59%)]	Loss: 1.000713
[2022-03-30 18:04:57 | train] - Train Epoch: [69] [768000/1281167 (60%)]	Loss: 1.067793
[2022-03-30 18:05:17 | train] - Train Epoch: [69] [780800/1281167 (61%)]	Loss: 0.813815
[2022-03-30 18:05:37 | train] - Train Epoch: [69] [793600/1281167 (62%)]	Loss: 0.986978
[2022-03-30 18:05:57 | train] - Train Epoch: [69] [806400/1281167 (63%)]	Loss: 0.791377
[2022-03-30 18:06:17 | train] - Train Epoch: [69] [819200/1281167 (64%)]	Loss: 0.958835
[2022-03-30 18:06:36 | train] - Train Epoch: [69] [832000/1281167 (65%)]	Loss: 0.959396
[2022-03-30 18:06:55 | train] - Train Epoch: [69] [844800/1281167 (66%)]	Loss: 0.779613
[2022-03-30 18:07:15 | train] - Train Epoch: [69] [857600/1281167 (67%)]	Loss: 0.780237
[2022-03-30 18:07:35 | train] - Train Epoch: [69] [870400/1281167 (68%)]	Loss: 0.831195
[2022-03-30 18:07:55 | train] - Train Epoch: [69] [883200/1281167 (69%)]	Loss: 0.865442
[2022-03-30 18:08:14 | train] - Train Epoch: [69] [896000/1281167 (70%)]	Loss: 0.865650
[2022-03-30 18:08:34 | train] - Train Epoch: [69] [908800/1281167 (71%)]	Loss: 0.808941
[2022-03-30 18:08:53 | train] - Train Epoch: [69] [921600/1281167 (72%)]	Loss: 1.292275
[2022-03-30 18:09:13 | train] - Train Epoch: [69] [934400/1281167 (73%)]	Loss: 0.678568
[2022-03-30 18:09:33 | train] - Train Epoch: [69] [947200/1281167 (74%)]	Loss: 0.802604
[2022-03-30 18:09:52 | train] - Train Epoch: [69] [960000/1281167 (75%)]	Loss: 0.851595
[2022-03-30 18:10:12 | train] - Train Epoch: [69] [972800/1281167 (76%)]	Loss: 0.849056
[2022-03-30 18:10:32 | train] - Train Epoch: [69] [985600/1281167 (77%)]	Loss: 0.899145
[2022-03-30 18:10:51 | train] - Train Epoch: [69] [998400/1281167 (78%)]	Loss: 0.853118
[2022-03-30 18:11:11 | train] - Train Epoch: [69] [1011200/1281167 (79%)]	Loss: 0.864304
[2022-03-30 18:11:31 | train] - Train Epoch: [69] [1024000/1281167 (80%)]	Loss: 0.791501
[2022-03-30 18:11:51 | train] - Train Epoch: [69] [1036800/1281167 (81%)]	Loss: 0.821798
[2022-03-30 18:12:11 | train] - Train Epoch: [69] [1049600/1281167 (82%)]	Loss: 0.760211
[2022-03-30 18:12:31 | train] - Train Epoch: [69] [1062400/1281167 (83%)]	Loss: 0.788088
[2022-03-30 18:12:51 | train] - Train Epoch: [69] [1075200/1281167 (84%)]	Loss: 1.177096
[2022-03-30 18:13:10 | train] - Train Epoch: [69] [1088000/1281167 (85%)]	Loss: 0.647385
[2022-03-30 18:13:30 | train] - Train Epoch: [69] [1100800/1281167 (86%)]	Loss: 0.903250
[2022-03-30 18:13:50 | train] - Train Epoch: [69] [1113600/1281167 (87%)]	Loss: 0.660889
[2022-03-30 18:14:10 | train] - Train Epoch: [69] [1126400/1281167 (88%)]	Loss: 0.835535
[2022-03-30 18:14:29 | train] - Train Epoch: [69] [1139200/1281167 (89%)]	Loss: 1.070775
[2022-03-30 18:14:49 | train] - Train Epoch: [69] [1152000/1281167 (90%)]	Loss: 0.855228
[2022-03-30 18:15:09 | train] - Train Epoch: [69] [1164800/1281167 (91%)]	Loss: 0.951657
[2022-03-30 18:15:29 | train] - Train Epoch: [69] [1177600/1281167 (92%)]	Loss: 1.452585
[2022-03-30 18:15:48 | train] - Train Epoch: [69] [1190400/1281167 (93%)]	Loss: 0.889119
[2022-03-30 18:16:08 | train] - Train Epoch: [69] [1203200/1281167 (94%)]	Loss: 0.837809
[2022-03-30 18:16:28 | train] - Train Epoch: [69] [1216000/1281167 (95%)]	Loss: 0.735565
[2022-03-30 18:16:47 | train] - Train Epoch: [69] [1228800/1281167 (96%)]	Loss: 0.756614
[2022-03-30 18:17:07 | train] - Train Epoch: [69] [1241600/1281167 (97%)]	Loss: 1.125492
[2022-03-30 18:17:27 | train] - Train Epoch: [69] [1254400/1281167 (98%)]	Loss: 0.672274
[2022-03-30 18:17:46 | train] - Train Epoch: [69] [1267200/1281167 (99%)]	Loss: 1.026449
[2022-03-30 18:18:06 | train] - Train Epoch: [69] [1280000/1281167 (100%)]	Loss: 0.856321
[2022-03-30 18:18:08 | train] - Train Epoch: [69]	 Average Loss: 0.891249	 Total Acc : 78.3899	 Total Top5 Acc : 91.9587
[2022-03-30 18:18:08 | train] - -------69 epoch end-----------
========================================
-------69 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 18:19:39 | train] - 
Epoch [69] Test set: Average loss: 1.3204, Accuracy: 35113/50000 (70.2042%), Top-5 Accuracy: 89.1668%

[2022-03-30 18:19:39 | train] - save intermediate epoch [69] result


[2022-03-30 18:19:40 | train] - logging best performance 69 epoch
[2022-03-30 18:19:41 | train] - -------70 epoch start-----------
========================================
----- test end -------------------------


logging best performance 69 epoch
[2022-03-30 18:19:43 | train] - Train Epoch: [70] [0/1281167 (0%)]	Loss: 0.796103
[2022-03-30 18:20:03 | train] - Train Epoch: [70] [12800/1281167 (1%)]	Loss: 0.801844
[2022-03-30 18:20:23 | train] - Train Epoch: [70] [25600/1281167 (2%)]	Loss: 0.848105
[2022-03-30 18:20:42 | train] - Train Epoch: [70] [38400/1281167 (3%)]	Loss: 0.542302
[2022-03-30 18:21:02 | train] - Train Epoch: [70] [51200/1281167 (4%)]	Loss: 0.723035
[2022-03-30 18:21:22 | train] - Train Epoch: [70] [64000/1281167 (5%)]	Loss: 0.815701
[2022-03-30 18:21:42 | train] - Train Epoch: [70] [76800/1281167 (6%)]	Loss: 0.822322
[2022-03-30 18:22:01 | train] - Train Epoch: [70] [89600/1281167 (7%)]	Loss: 0.794798
[2022-03-30 18:22:21 | train] - Train Epoch: [70] [102400/1281167 (8%)]	Loss: 0.834823
[2022-03-30 18:22:42 | train] - Train Epoch: [70] [115200/1281167 (9%)]	Loss: 0.651687
[2022-03-30 18:23:01 | train] - Train Epoch: [70] [128000/1281167 (10%)]	Loss: 0.964642
[2022-03-30 18:23:21 | train] - Train Epoch: [70] [140800/1281167 (11%)]	Loss: 0.768313
[2022-03-30 18:23:41 | train] - Train Epoch: [70] [153600/1281167 (12%)]	Loss: 0.738861
[2022-03-30 18:24:01 | train] - Train Epoch: [70] [166400/1281167 (13%)]	Loss: 1.159922
[2022-03-30 18:24:21 | train] - Train Epoch: [70] [179200/1281167 (14%)]	Loss: 0.844044
[2022-03-30 18:24:41 | train] - Train Epoch: [70] [192000/1281167 (15%)]	Loss: 0.977715
[2022-03-30 18:25:01 | train] - Train Epoch: [70] [204800/1281167 (16%)]	Loss: 0.784695
[2022-03-30 18:25:21 | train] - Train Epoch: [70] [217600/1281167 (17%)]	Loss: 0.870898
[2022-03-30 18:25:41 | train] - Train Epoch: [70] [230400/1281167 (18%)]	Loss: 0.768238
[2022-03-30 18:26:00 | train] - Train Epoch: [70] [243200/1281167 (19%)]	Loss: 0.796896
[2022-03-30 18:26:21 | train] - Train Epoch: [70] [256000/1281167 (20%)]	Loss: 0.674992
[2022-03-30 18:26:40 | train] - Train Epoch: [70] [268800/1281167 (21%)]	Loss: 0.821157
[2022-03-30 18:27:00 | train] - Train Epoch: [70] [281600/1281167 (22%)]	Loss: 1.072484
[2022-03-30 18:27:20 | train] - Train Epoch: [70] [294400/1281167 (23%)]	Loss: 1.018167
[2022-03-30 18:27:40 | train] - Train Epoch: [70] [307200/1281167 (24%)]	Loss: 0.868561
[2022-03-30 18:28:00 | train] - Train Epoch: [70] [320000/1281167 (25%)]	Loss: 1.153565
[2022-03-30 18:28:20 | train] - Train Epoch: [70] [332800/1281167 (26%)]	Loss: 0.840134
[2022-03-30 18:28:40 | train] - Train Epoch: [70] [345600/1281167 (27%)]	Loss: 0.983113
[2022-03-30 18:29:00 | train] - Train Epoch: [70] [358400/1281167 (28%)]	Loss: 0.719122
[2022-03-30 18:29:19 | train] - Train Epoch: [70] [371200/1281167 (29%)]	Loss: 0.976144
[2022-03-30 18:29:39 | train] - Train Epoch: [70] [384000/1281167 (30%)]	Loss: 1.038392
[2022-03-30 18:29:59 | train] - Train Epoch: [70] [396800/1281167 (31%)]	Loss: 0.820141
[2022-03-30 18:30:19 | train] - Train Epoch: [70] [409600/1281167 (32%)]	Loss: 0.642016
[2022-03-30 18:30:39 | train] - Train Epoch: [70] [422400/1281167 (33%)]	Loss: 0.804262
[2022-03-30 18:30:58 | train] - Train Epoch: [70] [435200/1281167 (34%)]	Loss: 0.941613
[2022-03-30 18:31:19 | train] - Train Epoch: [70] [448000/1281167 (35%)]	Loss: 0.959650
[2022-03-30 18:31:39 | train] - Train Epoch: [70] [460800/1281167 (36%)]	Loss: 0.841894
[2022-03-30 18:31:59 | train] - Train Epoch: [70] [473600/1281167 (37%)]	Loss: 0.875751
[2022-03-30 18:32:19 | train] - Train Epoch: [70] [486400/1281167 (38%)]	Loss: 0.937303
[2022-03-30 18:32:38 | train] - Train Epoch: [70] [499200/1281167 (39%)]	Loss: 0.939525
[2022-03-30 18:32:59 | train] - Train Epoch: [70] [512000/1281167 (40%)]	Loss: 0.743133
[2022-03-30 18:33:19 | train] - Train Epoch: [70] [524800/1281167 (41%)]	Loss: 0.665086
[2022-03-30 18:33:39 | train] - Train Epoch: [70] [537600/1281167 (42%)]	Loss: 1.031292
[2022-03-30 18:33:58 | train] - Train Epoch: [70] [550400/1281167 (43%)]	Loss: 0.956419
[2022-03-30 18:34:18 | train] - Train Epoch: [70] [563200/1281167 (44%)]	Loss: 0.831642
[2022-03-30 18:34:38 | train] - Train Epoch: [70] [576000/1281167 (45%)]	Loss: 0.932277
[2022-03-30 18:34:58 | train] - Train Epoch: [70] [588800/1281167 (46%)]	Loss: 0.846460
[2022-03-30 18:35:18 | train] - Train Epoch: [70] [601600/1281167 (47%)]	Loss: 0.875893
[2022-03-30 18:35:38 | train] - Train Epoch: [70] [614400/1281167 (48%)]	Loss: 0.888655
[2022-03-30 18:35:58 | train] - Train Epoch: [70] [627200/1281167 (49%)]	Loss: 1.147507
[2022-03-30 18:36:18 | train] - Train Epoch: [70] [640000/1281167 (50%)]	Loss: 0.755767
[2022-03-30 18:36:38 | train] - Train Epoch: [70] [652800/1281167 (51%)]	Loss: 0.773573
[2022-03-30 18:36:57 | train] - Train Epoch: [70] [665600/1281167 (52%)]	Loss: 0.951173
[2022-03-30 18:37:17 | train] - Train Epoch: [70] [678400/1281167 (53%)]	Loss: 0.861926
[2022-03-30 18:37:38 | train] - Train Epoch: [70] [691200/1281167 (54%)]	Loss: 1.268149
[2022-03-30 18:37:58 | train] - Train Epoch: [70] [704000/1281167 (55%)]	Loss: 0.892743
[2022-03-30 18:38:17 | train] - Train Epoch: [70] [716800/1281167 (56%)]	Loss: 0.797895
[2022-03-30 18:38:37 | train] - Train Epoch: [70] [729600/1281167 (57%)]	Loss: 0.631530
[2022-03-30 18:38:57 | train] - Train Epoch: [70] [742400/1281167 (58%)]	Loss: 0.996146
[2022-03-30 18:39:17 | train] - Train Epoch: [70] [755200/1281167 (59%)]	Loss: 0.660842
[2022-03-30 18:39:37 | train] - Train Epoch: [70] [768000/1281167 (60%)]	Loss: 0.770499
[2022-03-30 18:39:57 | train] - Train Epoch: [70] [780800/1281167 (61%)]	Loss: 0.788999
[2022-03-30 18:40:18 | train] - Train Epoch: [70] [793600/1281167 (62%)]	Loss: 1.024973
[2022-03-30 18:40:38 | train] - Train Epoch: [70] [806400/1281167 (63%)]	Loss: 0.870889
[2022-03-30 18:40:58 | train] - Train Epoch: [70] [819200/1281167 (64%)]	Loss: 0.673006
[2022-03-30 18:41:18 | train] - Train Epoch: [70] [832000/1281167 (65%)]	Loss: 0.650598
[2022-03-30 18:41:38 | train] - Train Epoch: [70] [844800/1281167 (66%)]	Loss: 0.927910
[2022-03-30 18:41:57 | train] - Train Epoch: [70] [857600/1281167 (67%)]	Loss: 0.893245
[2022-03-30 18:42:17 | train] - Train Epoch: [70] [870400/1281167 (68%)]	Loss: 1.075857
[2022-03-30 18:42:37 | train] - Train Epoch: [70] [883200/1281167 (69%)]	Loss: 0.670734
[2022-03-30 18:42:57 | train] - Train Epoch: [70] [896000/1281167 (70%)]	Loss: 1.182734
[2022-03-30 18:43:17 | train] - Train Epoch: [70] [908800/1281167 (71%)]	Loss: 0.694711
[2022-03-30 18:43:36 | train] - Train Epoch: [70] [921600/1281167 (72%)]	Loss: 0.762471
[2022-03-30 18:43:56 | train] - Train Epoch: [70] [934400/1281167 (73%)]	Loss: 1.025825
[2022-03-30 18:44:16 | train] - Train Epoch: [70] [947200/1281167 (74%)]	Loss: 0.800753
[2022-03-30 18:44:36 | train] - Train Epoch: [70] [960000/1281167 (75%)]	Loss: 1.063732
[2022-03-30 18:44:56 | train] - Train Epoch: [70] [972800/1281167 (76%)]	Loss: 0.965884
[2022-03-30 18:45:16 | train] - Train Epoch: [70] [985600/1281167 (77%)]	Loss: 0.984211
[2022-03-30 18:45:36 | train] - Train Epoch: [70] [998400/1281167 (78%)]	Loss: 0.792105
[2022-03-30 18:45:56 | train] - Train Epoch: [70] [1011200/1281167 (79%)]	Loss: 0.857579
[2022-03-30 18:46:16 | train] - Train Epoch: [70] [1024000/1281167 (80%)]	Loss: 0.993568
[2022-03-30 18:46:36 | train] - Train Epoch: [70] [1036800/1281167 (81%)]	Loss: 1.025961
[2022-03-30 18:46:56 | train] - Train Epoch: [70] [1049600/1281167 (82%)]	Loss: 1.049465
[2022-03-30 18:47:15 | train] - Train Epoch: [70] [1062400/1281167 (83%)]	Loss: 1.005447
[2022-03-30 18:47:36 | train] - Train Epoch: [70] [1075200/1281167 (84%)]	Loss: 0.971918
[2022-03-30 18:47:56 | train] - Train Epoch: [70] [1088000/1281167 (85%)]	Loss: 0.607893
[2022-03-30 18:48:17 | train] - Train Epoch: [70] [1100800/1281167 (86%)]	Loss: 1.073370
[2022-03-30 18:48:37 | train] - Train Epoch: [70] [1113600/1281167 (87%)]	Loss: 1.016411
[2022-03-30 18:48:56 | train] - Train Epoch: [70] [1126400/1281167 (88%)]	Loss: 0.898606
[2022-03-30 18:49:16 | train] - Train Epoch: [70] [1139200/1281167 (89%)]	Loss: 0.845492
[2022-03-30 18:49:36 | train] - Train Epoch: [70] [1152000/1281167 (90%)]	Loss: 0.843926
[2022-03-30 18:49:56 | train] - Train Epoch: [70] [1164800/1281167 (91%)]	Loss: 0.740027
[2022-03-30 18:50:16 | train] - Train Epoch: [70] [1177600/1281167 (92%)]	Loss: 0.802393
[2022-03-30 18:50:35 | train] - Train Epoch: [70] [1190400/1281167 (93%)]	Loss: 0.874499
[2022-03-30 18:50:55 | train] - Train Epoch: [70] [1203200/1281167 (94%)]	Loss: 0.890525
[2022-03-30 18:51:15 | train] - Train Epoch: [70] [1216000/1281167 (95%)]	Loss: 0.836027
[2022-03-30 18:51:35 | train] - Train Epoch: [70] [1228800/1281167 (96%)]	Loss: 0.824885
[2022-03-30 18:51:55 | train] - Train Epoch: [70] [1241600/1281167 (97%)]	Loss: 0.762913
[2022-03-30 18:52:14 | train] - Train Epoch: [70] [1254400/1281167 (98%)]	Loss: 0.851498
[2022-03-30 18:52:34 | train] - Train Epoch: [70] [1267200/1281167 (99%)]	Loss: 0.918927
[2022-03-30 18:52:54 | train] - Train Epoch: [70] [1280000/1281167 (100%)]	Loss: 0.819131
[2022-03-30 18:52:56 | train] - Train Epoch: [70]	 Average Loss: 0.886300	 Total Acc : 78.5363	 Total Top5 Acc : 91.9940
[2022-03-30 18:52:56 | train] - -------70 epoch end-----------
========================================
-------70 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 18:54:25 | train] - 
Epoch [70] Test set: Average loss: 1.3277, Accuracy: 35072/50000 (70.1163%), Top-5 Accuracy: 89.0969%

[2022-03-30 18:54:25 | train] - save intermediate epoch [70] result


[2022-03-30 18:54:27 | train] - -------71 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 18:54:29 | train] - Train Epoch: [71] [0/1281167 (0%)]	Loss: 1.061566
[2022-03-30 18:54:49 | train] - Train Epoch: [71] [12800/1281167 (1%)]	Loss: 0.978165
[2022-03-30 18:55:09 | train] - Train Epoch: [71] [25600/1281167 (2%)]	Loss: 0.897561
[2022-03-30 18:55:29 | train] - Train Epoch: [71] [38400/1281167 (3%)]	Loss: 0.709364
[2022-03-30 18:55:49 | train] - Train Epoch: [71] [51200/1281167 (4%)]	Loss: 0.593449
[2022-03-30 18:56:08 | train] - Train Epoch: [71] [64000/1281167 (5%)]	Loss: 0.684190
[2022-03-30 18:56:28 | train] - Train Epoch: [71] [76800/1281167 (6%)]	Loss: 0.906638
[2022-03-30 18:56:48 | train] - Train Epoch: [71] [89600/1281167 (7%)]	Loss: 1.133912
[2022-03-30 18:57:08 | train] - Train Epoch: [71] [102400/1281167 (8%)]	Loss: 0.923316
[2022-03-30 18:57:28 | train] - Train Epoch: [71] [115200/1281167 (9%)]	Loss: 1.084215
[2022-03-30 18:57:47 | train] - Train Epoch: [71] [128000/1281167 (10%)]	Loss: 0.754750
[2022-03-30 18:58:07 | train] - Train Epoch: [71] [140800/1281167 (11%)]	Loss: 0.797376
[2022-03-30 18:58:27 | train] - Train Epoch: [71] [153600/1281167 (12%)]	Loss: 0.970529
[2022-03-30 18:58:47 | train] - Train Epoch: [71] [166400/1281167 (13%)]	Loss: 0.915241
[2022-03-30 18:59:06 | train] - Train Epoch: [71] [179200/1281167 (14%)]	Loss: 0.752508
[2022-03-30 18:59:26 | train] - Train Epoch: [71] [192000/1281167 (15%)]	Loss: 0.727006
[2022-03-30 18:59:46 | train] - Train Epoch: [71] [204800/1281167 (16%)]	Loss: 0.627993
[2022-03-30 19:00:05 | train] - Train Epoch: [71] [217600/1281167 (17%)]	Loss: 0.732415
[2022-03-30 19:00:25 | train] - Train Epoch: [71] [230400/1281167 (18%)]	Loss: 0.899212
[2022-03-30 19:00:45 | train] - Train Epoch: [71] [243200/1281167 (19%)]	Loss: 0.970859
[2022-03-30 19:01:05 | train] - Train Epoch: [71] [256000/1281167 (20%)]	Loss: 0.713089
[2022-03-30 19:01:24 | train] - Train Epoch: [71] [268800/1281167 (21%)]	Loss: 0.799641
[2022-03-30 19:01:44 | train] - Train Epoch: [71] [281600/1281167 (22%)]	Loss: 0.729080
[2022-03-30 19:02:04 | train] - Train Epoch: [71] [294400/1281167 (23%)]	Loss: 0.699793
[2022-03-30 19:02:24 | train] - Train Epoch: [71] [307200/1281167 (24%)]	Loss: 0.922764
[2022-03-30 19:02:43 | train] - Train Epoch: [71] [320000/1281167 (25%)]	Loss: 0.892409
[2022-03-30 19:03:04 | train] - Train Epoch: [71] [332800/1281167 (26%)]	Loss: 0.995975
[2022-03-30 19:03:24 | train] - Train Epoch: [71] [345600/1281167 (27%)]	Loss: 0.829561
[2022-03-30 19:03:44 | train] - Train Epoch: [71] [358400/1281167 (28%)]	Loss: 1.079177
[2022-03-30 19:04:04 | train] - Train Epoch: [71] [371200/1281167 (29%)]	Loss: 1.076930
[2022-03-30 19:04:24 | train] - Train Epoch: [71] [384000/1281167 (30%)]	Loss: 0.762076
[2022-03-30 19:04:45 | train] - Train Epoch: [71] [396800/1281167 (31%)]	Loss: 0.783064
[2022-03-30 19:05:04 | train] - Train Epoch: [71] [409600/1281167 (32%)]	Loss: 0.902781
[2022-03-30 19:05:25 | train] - Train Epoch: [71] [422400/1281167 (33%)]	Loss: 0.882273
[2022-03-30 19:05:45 | train] - Train Epoch: [71] [435200/1281167 (34%)]	Loss: 0.755090
[2022-03-30 19:06:05 | train] - Train Epoch: [71] [448000/1281167 (35%)]	Loss: 1.022494
[2022-03-30 19:06:24 | train] - Train Epoch: [71] [460800/1281167 (36%)]	Loss: 0.922656
[2022-03-30 19:06:44 | train] - Train Epoch: [71] [473600/1281167 (37%)]	Loss: 0.803047
[2022-03-30 19:07:04 | train] - Train Epoch: [71] [486400/1281167 (38%)]	Loss: 0.720632
[2022-03-30 19:07:23 | train] - Train Epoch: [71] [499200/1281167 (39%)]	Loss: 0.692230
[2022-03-30 19:07:42 | train] - Train Epoch: [71] [512000/1281167 (40%)]	Loss: 0.965042
[2022-03-30 19:08:02 | train] - Train Epoch: [71] [524800/1281167 (41%)]	Loss: 0.794133
[2022-03-30 19:08:22 | train] - Train Epoch: [71] [537600/1281167 (42%)]	Loss: 0.650798
[2022-03-30 19:08:41 | train] - Train Epoch: [71] [550400/1281167 (43%)]	Loss: 0.861581
[2022-03-30 19:09:02 | train] - Train Epoch: [71] [563200/1281167 (44%)]	Loss: 1.039819
[2022-03-30 19:09:21 | train] - Train Epoch: [71] [576000/1281167 (45%)]	Loss: 0.816952
[2022-03-30 19:09:41 | train] - Train Epoch: [71] [588800/1281167 (46%)]	Loss: 0.575826
[2022-03-30 19:10:01 | train] - Train Epoch: [71] [601600/1281167 (47%)]	Loss: 0.965425
[2022-03-30 19:10:22 | train] - Train Epoch: [71] [614400/1281167 (48%)]	Loss: 1.056494
[2022-03-30 19:10:41 | train] - Train Epoch: [71] [627200/1281167 (49%)]	Loss: 0.808282
[2022-03-30 19:11:01 | train] - Train Epoch: [71] [640000/1281167 (50%)]	Loss: 0.726592
[2022-03-30 19:11:21 | train] - Train Epoch: [71] [652800/1281167 (51%)]	Loss: 0.692617
[2022-03-30 19:11:41 | train] - Train Epoch: [71] [665600/1281167 (52%)]	Loss: 0.699760
[2022-03-30 19:12:01 | train] - Train Epoch: [71] [678400/1281167 (53%)]	Loss: 1.006710
[2022-03-30 19:12:20 | train] - Train Epoch: [71] [691200/1281167 (54%)]	Loss: 0.751937
[2022-03-30 19:12:40 | train] - Train Epoch: [71] [704000/1281167 (55%)]	Loss: 1.103911
[2022-03-30 19:12:59 | train] - Train Epoch: [71] [716800/1281167 (56%)]	Loss: 1.111018
[2022-03-30 19:13:19 | train] - Train Epoch: [71] [729600/1281167 (57%)]	Loss: 0.779765
[2022-03-30 19:13:38 | train] - Train Epoch: [71] [742400/1281167 (58%)]	Loss: 0.899971
[2022-03-30 19:13:59 | train] - Train Epoch: [71] [755200/1281167 (59%)]	Loss: 0.866517
[2022-03-30 19:14:18 | train] - Train Epoch: [71] [768000/1281167 (60%)]	Loss: 0.880979
[2022-03-30 19:14:38 | train] - Train Epoch: [71] [780800/1281167 (61%)]	Loss: 0.874093
[2022-03-30 19:14:58 | train] - Train Epoch: [71] [793600/1281167 (62%)]	Loss: 0.845451
[2022-03-30 19:15:18 | train] - Train Epoch: [71] [806400/1281167 (63%)]	Loss: 0.725801
[2022-03-30 19:15:38 | train] - Train Epoch: [71] [819200/1281167 (64%)]	Loss: 0.860016
[2022-03-30 19:15:59 | train] - Train Epoch: [71] [832000/1281167 (65%)]	Loss: 0.939810
[2022-03-30 19:16:18 | train] - Train Epoch: [71] [844800/1281167 (66%)]	Loss: 0.682836
[2022-03-30 19:16:38 | train] - Train Epoch: [71] [857600/1281167 (67%)]	Loss: 0.867165
[2022-03-30 19:16:57 | train] - Train Epoch: [71] [870400/1281167 (68%)]	Loss: 1.011553
[2022-03-30 19:17:17 | train] - Train Epoch: [71] [883200/1281167 (69%)]	Loss: 0.847062
[2022-03-30 19:17:37 | train] - Train Epoch: [71] [896000/1281167 (70%)]	Loss: 0.926581
[2022-03-30 19:17:57 | train] - Train Epoch: [71] [908800/1281167 (71%)]	Loss: 0.825452
[2022-03-30 19:18:17 | train] - Train Epoch: [71] [921600/1281167 (72%)]	Loss: 0.957695
[2022-03-30 19:18:37 | train] - Train Epoch: [71] [934400/1281167 (73%)]	Loss: 0.813402
[2022-03-30 19:18:57 | train] - Train Epoch: [71] [947200/1281167 (74%)]	Loss: 1.063353
[2022-03-30 19:19:16 | train] - Train Epoch: [71] [960000/1281167 (75%)]	Loss: 0.830568
[2022-03-30 19:19:36 | train] - Train Epoch: [71] [972800/1281167 (76%)]	Loss: 0.873718
[2022-03-30 19:19:57 | train] - Train Epoch: [71] [985600/1281167 (77%)]	Loss: 0.882613
[2022-03-30 19:20:17 | train] - Train Epoch: [71] [998400/1281167 (78%)]	Loss: 0.803392
[2022-03-30 19:20:37 | train] - Train Epoch: [71] [1011200/1281167 (79%)]	Loss: 0.633941
[2022-03-30 19:20:57 | train] - Train Epoch: [71] [1024000/1281167 (80%)]	Loss: 0.754700
[2022-03-30 19:21:16 | train] - Train Epoch: [71] [1036800/1281167 (81%)]	Loss: 1.010552
[2022-03-30 19:21:36 | train] - Train Epoch: [71] [1049600/1281167 (82%)]	Loss: 0.974248
[2022-03-30 19:21:56 | train] - Train Epoch: [71] [1062400/1281167 (83%)]	Loss: 0.811623
[2022-03-30 19:22:16 | train] - Train Epoch: [71] [1075200/1281167 (84%)]	Loss: 0.746746
[2022-03-30 19:22:36 | train] - Train Epoch: [71] [1088000/1281167 (85%)]	Loss: 0.735629
[2022-03-30 19:22:56 | train] - Train Epoch: [71] [1100800/1281167 (86%)]	Loss: 0.843657
[2022-03-30 19:23:17 | train] - Train Epoch: [71] [1113600/1281167 (87%)]	Loss: 0.826988
[2022-03-30 19:23:37 | train] - Train Epoch: [71] [1126400/1281167 (88%)]	Loss: 0.832047
[2022-03-30 19:23:56 | train] - Train Epoch: [71] [1139200/1281167 (89%)]	Loss: 0.889476
[2022-03-30 19:24:17 | train] - Train Epoch: [71] [1152000/1281167 (90%)]	Loss: 0.849536
[2022-03-30 19:24:36 | train] - Train Epoch: [71] [1164800/1281167 (91%)]	Loss: 1.092613
[2022-03-30 19:24:57 | train] - Train Epoch: [71] [1177600/1281167 (92%)]	Loss: 1.134032
[2022-03-30 19:25:17 | train] - Train Epoch: [71] [1190400/1281167 (93%)]	Loss: 0.836993
[2022-03-30 19:25:37 | train] - Train Epoch: [71] [1203200/1281167 (94%)]	Loss: 1.177301
[2022-03-30 19:25:57 | train] - Train Epoch: [71] [1216000/1281167 (95%)]	Loss: 1.052738
[2022-03-30 19:26:16 | train] - Train Epoch: [71] [1228800/1281167 (96%)]	Loss: 1.129781
[2022-03-30 19:26:35 | train] - Train Epoch: [71] [1241600/1281167 (97%)]	Loss: 0.528439
[2022-03-30 19:26:55 | train] - Train Epoch: [71] [1254400/1281167 (98%)]	Loss: 1.075341
[2022-03-30 19:27:15 | train] - Train Epoch: [71] [1267200/1281167 (99%)]	Loss: 0.959771
[2022-03-30 19:27:34 | train] - Train Epoch: [71] [1280000/1281167 (100%)]	Loss: 0.749814
[2022-03-30 19:27:36 | train] - Train Epoch: [71]	 Average Loss: 0.878556	 Total Acc : 78.6982	 Total Top5 Acc : 92.0781
[2022-03-30 19:27:36 | train] - -------71 epoch end-----------
========================================
-------71 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 19:29:07 | train] - 
Epoch [71] Test set: Average loss: 1.3376, Accuracy: 35007/50000 (69.9864%), Top-5 Accuracy: 89.0701%

[2022-03-30 19:29:07 | train] - save intermediate epoch [71] result


[2022-03-30 19:29:09 | train] - -------72 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 19:29:11 | train] - Train Epoch: [72] [0/1281167 (0%)]	Loss: 0.882248
[2022-03-30 19:29:30 | train] - Train Epoch: [72] [12800/1281167 (1%)]	Loss: 0.693606
[2022-03-30 19:29:49 | train] - Train Epoch: [72] [25600/1281167 (2%)]	Loss: 0.938994
[2022-03-30 19:30:09 | train] - Train Epoch: [72] [38400/1281167 (3%)]	Loss: 0.832802
[2022-03-30 19:30:29 | train] - Train Epoch: [72] [51200/1281167 (4%)]	Loss: 0.803607
[2022-03-30 19:30:48 | train] - Train Epoch: [72] [64000/1281167 (5%)]	Loss: 1.041015
[2022-03-30 19:31:08 | train] - Train Epoch: [72] [76800/1281167 (6%)]	Loss: 0.711405
[2022-03-30 19:31:28 | train] - Train Epoch: [72] [89600/1281167 (7%)]	Loss: 0.740342
[2022-03-30 19:31:48 | train] - Train Epoch: [72] [102400/1281167 (8%)]	Loss: 0.894109
[2022-03-30 19:32:08 | train] - Train Epoch: [72] [115200/1281167 (9%)]	Loss: 0.780744
[2022-03-30 19:32:27 | train] - Train Epoch: [72] [128000/1281167 (10%)]	Loss: 1.104229
[2022-03-30 19:32:47 | train] - Train Epoch: [72] [140800/1281167 (11%)]	Loss: 0.915531
[2022-03-30 19:33:06 | train] - Train Epoch: [72] [153600/1281167 (12%)]	Loss: 0.954727
[2022-03-30 19:33:26 | train] - Train Epoch: [72] [166400/1281167 (13%)]	Loss: 0.859930
[2022-03-30 19:33:45 | train] - Train Epoch: [72] [179200/1281167 (14%)]	Loss: 1.026330
[2022-03-30 19:34:05 | train] - Train Epoch: [72] [192000/1281167 (15%)]	Loss: 0.818770
[2022-03-30 19:34:25 | train] - Train Epoch: [72] [204800/1281167 (16%)]	Loss: 0.981791
[2022-03-30 19:34:45 | train] - Train Epoch: [72] [217600/1281167 (17%)]	Loss: 1.120229
[2022-03-30 19:35:05 | train] - Train Epoch: [72] [230400/1281167 (18%)]	Loss: 0.704014
[2022-03-30 19:35:24 | train] - Train Epoch: [72] [243200/1281167 (19%)]	Loss: 0.784412
[2022-03-30 19:35:44 | train] - Train Epoch: [72] [256000/1281167 (20%)]	Loss: 0.748185
[2022-03-30 19:36:04 | train] - Train Epoch: [72] [268800/1281167 (21%)]	Loss: 1.001833
[2022-03-30 19:36:24 | train] - Train Epoch: [72] [281600/1281167 (22%)]	Loss: 1.273458
[2022-03-30 19:36:44 | train] - Train Epoch: [72] [294400/1281167 (23%)]	Loss: 0.607113
[2022-03-30 19:37:04 | train] - Train Epoch: [72] [307200/1281167 (24%)]	Loss: 0.811869
[2022-03-30 19:37:23 | train] - Train Epoch: [72] [320000/1281167 (25%)]	Loss: 0.721806
[2022-03-30 19:37:44 | train] - Train Epoch: [72] [332800/1281167 (26%)]	Loss: 0.901532
[2022-03-30 19:38:03 | train] - Train Epoch: [72] [345600/1281167 (27%)]	Loss: 1.027642
[2022-03-30 19:38:23 | train] - Train Epoch: [72] [358400/1281167 (28%)]	Loss: 0.881835
[2022-03-30 19:38:43 | train] - Train Epoch: [72] [371200/1281167 (29%)]	Loss: 0.883035
[2022-03-30 19:39:03 | train] - Train Epoch: [72] [384000/1281167 (30%)]	Loss: 1.105424
[2022-03-30 19:39:23 | train] - Train Epoch: [72] [396800/1281167 (31%)]	Loss: 0.556035
[2022-03-30 19:39:43 | train] - Train Epoch: [72] [409600/1281167 (32%)]	Loss: 0.823358
[2022-03-30 19:40:03 | train] - Train Epoch: [72] [422400/1281167 (33%)]	Loss: 0.966022
[2022-03-30 19:40:22 | train] - Train Epoch: [72] [435200/1281167 (34%)]	Loss: 0.963919
[2022-03-30 19:40:42 | train] - Train Epoch: [72] [448000/1281167 (35%)]	Loss: 0.971762
[2022-03-30 19:41:02 | train] - Train Epoch: [72] [460800/1281167 (36%)]	Loss: 0.823435
[2022-03-30 19:41:22 | train] - Train Epoch: [72] [473600/1281167 (37%)]	Loss: 0.557498
[2022-03-30 19:41:42 | train] - Train Epoch: [72] [486400/1281167 (38%)]	Loss: 0.708686
[2022-03-30 19:42:01 | train] - Train Epoch: [72] [499200/1281167 (39%)]	Loss: 0.992977
[2022-03-30 19:42:21 | train] - Train Epoch: [72] [512000/1281167 (40%)]	Loss: 1.408135
[2022-03-30 19:42:42 | train] - Train Epoch: [72] [524800/1281167 (41%)]	Loss: 0.804318
[2022-03-30 19:43:01 | train] - Train Epoch: [72] [537600/1281167 (42%)]	Loss: 0.863402
[2022-03-30 19:43:21 | train] - Train Epoch: [72] [550400/1281167 (43%)]	Loss: 0.704598
[2022-03-30 19:43:41 | train] - Train Epoch: [72] [563200/1281167 (44%)]	Loss: 0.777967
[2022-03-30 19:44:01 | train] - Train Epoch: [72] [576000/1281167 (45%)]	Loss: 0.895121
[2022-03-30 19:44:21 | train] - Train Epoch: [72] [588800/1281167 (46%)]	Loss: 0.966767
[2022-03-30 19:44:40 | train] - Train Epoch: [72] [601600/1281167 (47%)]	Loss: 0.870773
[2022-03-30 19:45:00 | train] - Train Epoch: [72] [614400/1281167 (48%)]	Loss: 0.775686
[2022-03-30 19:45:19 | train] - Train Epoch: [72] [627200/1281167 (49%)]	Loss: 0.984291
[2022-03-30 19:45:39 | train] - Train Epoch: [72] [640000/1281167 (50%)]	Loss: 1.261317
[2022-03-30 19:45:58 | train] - Train Epoch: [72] [652800/1281167 (51%)]	Loss: 0.829156
[2022-03-30 19:46:18 | train] - Train Epoch: [72] [665600/1281167 (52%)]	Loss: 0.777982
[2022-03-30 19:46:38 | train] - Train Epoch: [72] [678400/1281167 (53%)]	Loss: 0.852014
[2022-03-30 19:46:57 | train] - Train Epoch: [72] [691200/1281167 (54%)]	Loss: 0.586263
[2022-03-30 19:47:17 | train] - Train Epoch: [72] [704000/1281167 (55%)]	Loss: 0.583762
[2022-03-30 19:47:38 | train] - Train Epoch: [72] [716800/1281167 (56%)]	Loss: 1.062213
[2022-03-30 19:47:58 | train] - Train Epoch: [72] [729600/1281167 (57%)]	Loss: 1.181455
[2022-03-30 19:48:18 | train] - Train Epoch: [72] [742400/1281167 (58%)]	Loss: 0.858556
[2022-03-30 19:48:38 | train] - Train Epoch: [72] [755200/1281167 (59%)]	Loss: 0.925760
[2022-03-30 19:48:58 | train] - Train Epoch: [72] [768000/1281167 (60%)]	Loss: 0.575759
[2022-03-30 19:49:17 | train] - Train Epoch: [72] [780800/1281167 (61%)]	Loss: 1.085582
[2022-03-30 19:49:37 | train] - Train Epoch: [72] [793600/1281167 (62%)]	Loss: 0.818302
[2022-03-30 19:49:56 | train] - Train Epoch: [72] [806400/1281167 (63%)]	Loss: 1.114730
[2022-03-30 19:50:16 | train] - Train Epoch: [72] [819200/1281167 (64%)]	Loss: 0.895613
[2022-03-30 19:50:36 | train] - Train Epoch: [72] [832000/1281167 (65%)]	Loss: 0.791145
[2022-03-30 19:50:55 | train] - Train Epoch: [72] [844800/1281167 (66%)]	Loss: 0.853009
[2022-03-30 19:51:15 | train] - Train Epoch: [72] [857600/1281167 (67%)]	Loss: 0.708726
[2022-03-30 19:51:34 | train] - Train Epoch: [72] [870400/1281167 (68%)]	Loss: 0.901152
[2022-03-30 19:51:54 | train] - Train Epoch: [72] [883200/1281167 (69%)]	Loss: 0.937758
[2022-03-30 19:52:13 | train] - Train Epoch: [72] [896000/1281167 (70%)]	Loss: 0.904399
[2022-03-30 19:52:34 | train] - Train Epoch: [72] [908800/1281167 (71%)]	Loss: 0.819945
[2022-03-30 19:52:54 | train] - Train Epoch: [72] [921600/1281167 (72%)]	Loss: 0.961210
[2022-03-30 19:53:14 | train] - Train Epoch: [72] [934400/1281167 (73%)]	Loss: 0.911336
[2022-03-30 19:53:34 | train] - Train Epoch: [72] [947200/1281167 (74%)]	Loss: 0.980007
[2022-03-30 19:53:54 | train] - Train Epoch: [72] [960000/1281167 (75%)]	Loss: 1.080954
[2022-03-30 19:54:14 | train] - Train Epoch: [72] [972800/1281167 (76%)]	Loss: 0.937704
[2022-03-30 19:54:34 | train] - Train Epoch: [72] [985600/1281167 (77%)]	Loss: 0.818888
[2022-03-30 19:54:54 | train] - Train Epoch: [72] [998400/1281167 (78%)]	Loss: 0.966754
[2022-03-30 19:55:14 | train] - Train Epoch: [72] [1011200/1281167 (79%)]	Loss: 0.783874
[2022-03-30 19:55:33 | train] - Train Epoch: [72] [1024000/1281167 (80%)]	Loss: 0.820213
[2022-03-30 19:55:52 | train] - Train Epoch: [72] [1036800/1281167 (81%)]	Loss: 0.620272
[2022-03-30 19:56:12 | train] - Train Epoch: [72] [1049600/1281167 (82%)]	Loss: 0.830816
[2022-03-30 19:56:32 | train] - Train Epoch: [72] [1062400/1281167 (83%)]	Loss: 0.926771
[2022-03-30 19:56:51 | train] - Train Epoch: [72] [1075200/1281167 (84%)]	Loss: 0.901200
[2022-03-30 19:57:11 | train] - Train Epoch: [72] [1088000/1281167 (85%)]	Loss: 0.993849
[2022-03-30 19:57:30 | train] - Train Epoch: [72] [1100800/1281167 (86%)]	Loss: 0.822092
[2022-03-30 19:57:51 | train] - Train Epoch: [72] [1113600/1281167 (87%)]	Loss: 0.623507
[2022-03-30 19:58:10 | train] - Train Epoch: [72] [1126400/1281167 (88%)]	Loss: 0.968590
[2022-03-30 19:58:30 | train] - Train Epoch: [72] [1139200/1281167 (89%)]	Loss: 0.618935
[2022-03-30 19:58:51 | train] - Train Epoch: [72] [1152000/1281167 (90%)]	Loss: 0.848605
[2022-03-30 19:59:10 | train] - Train Epoch: [72] [1164800/1281167 (91%)]	Loss: 0.992046
[2022-03-30 19:59:30 | train] - Train Epoch: [72] [1177600/1281167 (92%)]	Loss: 0.793385
[2022-03-30 19:59:49 | train] - Train Epoch: [72] [1190400/1281167 (93%)]	Loss: 1.073674
[2022-03-30 20:00:09 | train] - Train Epoch: [72] [1203200/1281167 (94%)]	Loss: 0.584914
[2022-03-30 20:00:28 | train] - Train Epoch: [72] [1216000/1281167 (95%)]	Loss: 0.936762
[2022-03-30 20:00:49 | train] - Train Epoch: [72] [1228800/1281167 (96%)]	Loss: 0.803492
[2022-03-30 20:01:08 | train] - Train Epoch: [72] [1241600/1281167 (97%)]	Loss: 0.824980
[2022-03-30 20:01:28 | train] - Train Epoch: [72] [1254400/1281167 (98%)]	Loss: 1.072092
[2022-03-30 20:01:48 | train] - Train Epoch: [72] [1267200/1281167 (99%)]	Loss: 0.817259
[2022-03-30 20:02:08 | train] - Train Epoch: [72] [1280000/1281167 (100%)]	Loss: 0.799146
[2022-03-30 20:02:10 | train] - Train Epoch: [72]	 Average Loss: 0.873295	 Total Acc : 78.7807	 Total Top5 Acc : 92.1387
[2022-03-30 20:02:10 | train] - -------72 epoch end-----------
========================================
-------72 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 20:03:39 | train] - 
Epoch [72] Test set: Average loss: 1.3309, Accuracy: 35065/50000 (70.0999%), Top-5 Accuracy: 89.0897%

[2022-03-30 20:03:39 | train] - save intermediate epoch [72] result


[2022-03-30 20:03:42 | train] - -------73 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 20:03:43 | train] - Train Epoch: [73] [0/1281167 (0%)]	Loss: 0.689654
[2022-03-30 20:04:02 | train] - Train Epoch: [73] [12800/1281167 (1%)]	Loss: 0.955891
[2022-03-30 20:04:22 | train] - Train Epoch: [73] [25600/1281167 (2%)]	Loss: 0.917747
[2022-03-30 20:04:43 | train] - Train Epoch: [73] [38400/1281167 (3%)]	Loss: 0.785950
[2022-03-30 20:05:04 | train] - Train Epoch: [73] [51200/1281167 (4%)]	Loss: 0.870180
[2022-03-30 20:05:24 | train] - Train Epoch: [73] [64000/1281167 (5%)]	Loss: 0.980748
[2022-03-30 20:05:45 | train] - Train Epoch: [73] [76800/1281167 (6%)]	Loss: 0.796532
[2022-03-30 20:06:06 | train] - Train Epoch: [73] [89600/1281167 (7%)]	Loss: 0.830717
[2022-03-30 20:06:27 | train] - Train Epoch: [73] [102400/1281167 (8%)]	Loss: 0.907567
[2022-03-30 20:06:46 | train] - Train Epoch: [73] [115200/1281167 (9%)]	Loss: 0.942637
[2022-03-30 20:07:05 | train] - Train Epoch: [73] [128000/1281167 (10%)]	Loss: 1.048734
[2022-03-30 20:07:25 | train] - Train Epoch: [73] [140800/1281167 (11%)]	Loss: 0.904675
[2022-03-30 20:07:46 | train] - Train Epoch: [73] [153600/1281167 (12%)]	Loss: 0.949099
[2022-03-30 20:08:06 | train] - Train Epoch: [73] [166400/1281167 (13%)]	Loss: 0.873651
[2022-03-30 20:08:26 | train] - Train Epoch: [73] [179200/1281167 (14%)]	Loss: 0.776573
[2022-03-30 20:08:45 | train] - Train Epoch: [73] [192000/1281167 (15%)]	Loss: 0.749579
[2022-03-30 20:09:05 | train] - Train Epoch: [73] [204800/1281167 (16%)]	Loss: 0.693373
[2022-03-30 20:09:26 | train] - Train Epoch: [73] [217600/1281167 (17%)]	Loss: 0.719484
[2022-03-30 20:09:47 | train] - Train Epoch: [73] [230400/1281167 (18%)]	Loss: 1.013268
[2022-03-30 20:10:08 | train] - Train Epoch: [73] [243200/1281167 (19%)]	Loss: 0.830842
[2022-03-30 20:10:28 | train] - Train Epoch: [73] [256000/1281167 (20%)]	Loss: 1.011731
[2022-03-30 20:10:49 | train] - Train Epoch: [73] [268800/1281167 (21%)]	Loss: 0.942504
[2022-03-30 20:11:08 | train] - Train Epoch: [73] [281600/1281167 (22%)]	Loss: 0.919210
[2022-03-30 20:11:28 | train] - Train Epoch: [73] [294400/1281167 (23%)]	Loss: 0.916888
[2022-03-30 20:11:47 | train] - Train Epoch: [73] [307200/1281167 (24%)]	Loss: 0.900793
[2022-03-30 20:12:07 | train] - Train Epoch: [73] [320000/1281167 (25%)]	Loss: 0.786311
[2022-03-30 20:12:27 | train] - Train Epoch: [73] [332800/1281167 (26%)]	Loss: 0.966428
[2022-03-30 20:12:47 | train] - Train Epoch: [73] [345600/1281167 (27%)]	Loss: 1.022428
[2022-03-30 20:13:07 | train] - Train Epoch: [73] [358400/1281167 (28%)]	Loss: 0.793395
[2022-03-30 20:13:27 | train] - Train Epoch: [73] [371200/1281167 (29%)]	Loss: 0.922838
[2022-03-30 20:13:47 | train] - Train Epoch: [73] [384000/1281167 (30%)]	Loss: 0.823352
[2022-03-30 20:14:07 | train] - Train Epoch: [73] [396800/1281167 (31%)]	Loss: 0.800155
[2022-03-30 20:14:26 | train] - Train Epoch: [73] [409600/1281167 (32%)]	Loss: 0.798783
[2022-03-30 20:14:46 | train] - Train Epoch: [73] [422400/1281167 (33%)]	Loss: 0.882353
[2022-03-30 20:15:05 | train] - Train Epoch: [73] [435200/1281167 (34%)]	Loss: 0.912743
[2022-03-30 20:15:25 | train] - Train Epoch: [73] [448000/1281167 (35%)]	Loss: 0.628658
[2022-03-30 20:15:44 | train] - Train Epoch: [73] [460800/1281167 (36%)]	Loss: 0.919691
[2022-03-30 20:16:04 | train] - Train Epoch: [73] [473600/1281167 (37%)]	Loss: 1.006109
[2022-03-30 20:16:24 | train] - Train Epoch: [73] [486400/1281167 (38%)]	Loss: 1.000503
[2022-03-30 20:16:43 | train] - Train Epoch: [73] [499200/1281167 (39%)]	Loss: 0.875069
[2022-03-30 20:17:03 | train] - Train Epoch: [73] [512000/1281167 (40%)]	Loss: 1.107245
[2022-03-30 20:17:23 | train] - Train Epoch: [73] [524800/1281167 (41%)]	Loss: 0.753090
[2022-03-30 20:17:43 | train] - Train Epoch: [73] [537600/1281167 (42%)]	Loss: 0.838896
[2022-03-30 20:18:03 | train] - Train Epoch: [73] [550400/1281167 (43%)]	Loss: 0.919063
[2022-03-30 20:18:23 | train] - Train Epoch: [73] [563200/1281167 (44%)]	Loss: 0.784570
[2022-03-30 20:18:43 | train] - Train Epoch: [73] [576000/1281167 (45%)]	Loss: 0.834707
[2022-03-30 20:19:03 | train] - Train Epoch: [73] [588800/1281167 (46%)]	Loss: 0.805507
[2022-03-30 20:19:23 | train] - Train Epoch: [73] [601600/1281167 (47%)]	Loss: 0.662645
[2022-03-30 20:19:43 | train] - Train Epoch: [73] [614400/1281167 (48%)]	Loss: 0.655035
[2022-03-30 20:20:02 | train] - Train Epoch: [73] [627200/1281167 (49%)]	Loss: 0.904634
[2022-03-30 20:20:22 | train] - Train Epoch: [73] [640000/1281167 (50%)]	Loss: 0.986491
[2022-03-30 20:20:42 | train] - Train Epoch: [73] [652800/1281167 (51%)]	Loss: 0.821777
[2022-03-30 20:21:02 | train] - Train Epoch: [73] [665600/1281167 (52%)]	Loss: 1.096964
[2022-03-30 20:21:21 | train] - Train Epoch: [73] [678400/1281167 (53%)]	Loss: 0.953320
[2022-03-30 20:21:41 | train] - Train Epoch: [73] [691200/1281167 (54%)]	Loss: 0.775248
[2022-03-30 20:22:00 | train] - Train Epoch: [73] [704000/1281167 (55%)]	Loss: 1.092812
[2022-03-30 20:22:20 | train] - Train Epoch: [73] [716800/1281167 (56%)]	Loss: 0.571248
[2022-03-30 20:22:40 | train] - Train Epoch: [73] [729600/1281167 (57%)]	Loss: 0.803419
[2022-03-30 20:22:59 | train] - Train Epoch: [73] [742400/1281167 (58%)]	Loss: 0.959917
[2022-03-30 20:23:19 | train] - Train Epoch: [73] [755200/1281167 (59%)]	Loss: 0.920029
[2022-03-30 20:23:39 | train] - Train Epoch: [73] [768000/1281167 (60%)]	Loss: 0.740797
[2022-03-30 20:23:59 | train] - Train Epoch: [73] [780800/1281167 (61%)]	Loss: 0.692237
[2022-03-30 20:24:19 | train] - Train Epoch: [73] [793600/1281167 (62%)]	Loss: 1.010147
[2022-03-30 20:24:38 | train] - Train Epoch: [73] [806400/1281167 (63%)]	Loss: 0.631472
[2022-03-30 20:24:59 | train] - Train Epoch: [73] [819200/1281167 (64%)]	Loss: 0.643004
[2022-03-30 20:25:19 | train] - Train Epoch: [73] [832000/1281167 (65%)]	Loss: 0.812604
[2022-03-30 20:25:38 | train] - Train Epoch: [73] [844800/1281167 (66%)]	Loss: 0.793963
[2022-03-30 20:25:58 | train] - Train Epoch: [73] [857600/1281167 (67%)]	Loss: 0.861950
[2022-03-30 20:26:18 | train] - Train Epoch: [73] [870400/1281167 (68%)]	Loss: 0.949459
[2022-03-30 20:26:38 | train] - Train Epoch: [73] [883200/1281167 (69%)]	Loss: 0.588389
[2022-03-30 20:26:58 | train] - Train Epoch: [73] [896000/1281167 (70%)]	Loss: 0.735679
[2022-03-30 20:27:18 | train] - Train Epoch: [73] [908800/1281167 (71%)]	Loss: 0.686159
[2022-03-30 20:27:38 | train] - Train Epoch: [73] [921600/1281167 (72%)]	Loss: 0.901876
[2022-03-30 20:27:58 | train] - Train Epoch: [73] [934400/1281167 (73%)]	Loss: 0.688301
[2022-03-30 20:28:17 | train] - Train Epoch: [73] [947200/1281167 (74%)]	Loss: 0.628904
[2022-03-30 20:28:37 | train] - Train Epoch: [73] [960000/1281167 (75%)]	Loss: 0.937785
[2022-03-30 20:28:56 | train] - Train Epoch: [73] [972800/1281167 (76%)]	Loss: 0.962937
[2022-03-30 20:29:16 | train] - Train Epoch: [73] [985600/1281167 (77%)]	Loss: 0.825965
[2022-03-30 20:29:36 | train] - Train Epoch: [73] [998400/1281167 (78%)]	Loss: 0.841487
[2022-03-30 20:29:55 | train] - Train Epoch: [73] [1011200/1281167 (79%)]	Loss: 0.737320
[2022-03-30 20:30:15 | train] - Train Epoch: [73] [1024000/1281167 (80%)]	Loss: 0.611957
[2022-03-30 20:30:34 | train] - Train Epoch: [73] [1036800/1281167 (81%)]	Loss: 0.955793
[2022-03-30 20:30:54 | train] - Train Epoch: [73] [1049600/1281167 (82%)]	Loss: 0.888041
[2022-03-30 20:31:13 | train] - Train Epoch: [73] [1062400/1281167 (83%)]	Loss: 0.895343
[2022-03-30 20:31:33 | train] - Train Epoch: [73] [1075200/1281167 (84%)]	Loss: 0.788393
[2022-03-30 20:31:54 | train] - Train Epoch: [73] [1088000/1281167 (85%)]	Loss: 0.767831
[2022-03-30 20:32:13 | train] - Train Epoch: [73] [1100800/1281167 (86%)]	Loss: 0.841365
[2022-03-30 20:32:33 | train] - Train Epoch: [73] [1113600/1281167 (87%)]	Loss: 0.857889
[2022-03-30 20:32:53 | train] - Train Epoch: [73] [1126400/1281167 (88%)]	Loss: 0.748699
[2022-03-30 20:33:13 | train] - Train Epoch: [73] [1139200/1281167 (89%)]	Loss: 0.997316
[2022-03-30 20:33:33 | train] - Train Epoch: [73] [1152000/1281167 (90%)]	Loss: 1.014446
[2022-03-30 20:33:53 | train] - Train Epoch: [73] [1164800/1281167 (91%)]	Loss: 0.793340
[2022-03-30 20:34:12 | train] - Train Epoch: [73] [1177600/1281167 (92%)]	Loss: 0.852352
[2022-03-30 20:34:33 | train] - Train Epoch: [73] [1190400/1281167 (93%)]	Loss: 0.801100
[2022-03-30 20:34:53 | train] - Train Epoch: [73] [1203200/1281167 (94%)]	Loss: 0.939511
[2022-03-30 20:35:13 | train] - Train Epoch: [73] [1216000/1281167 (95%)]	Loss: 0.891312
[2022-03-30 20:35:32 | train] - Train Epoch: [73] [1228800/1281167 (96%)]	Loss: 0.887313
[2022-03-30 20:35:52 | train] - Train Epoch: [73] [1241600/1281167 (97%)]	Loss: 0.933892
[2022-03-30 20:36:12 | train] - Train Epoch: [73] [1254400/1281167 (98%)]	Loss: 0.937787
[2022-03-30 20:36:31 | train] - Train Epoch: [73] [1267200/1281167 (99%)]	Loss: 0.717385
[2022-03-30 20:36:51 | train] - Train Epoch: [73] [1280000/1281167 (100%)]	Loss: 0.843408
[2022-03-30 20:36:53 | train] - Train Epoch: [73]	 Average Loss: 0.868422	 Total Acc : 78.8985	 Total Top5 Acc : 92.1959
[2022-03-30 20:36:53 | train] - -------73 epoch end-----------
========================================
-------73 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 20:38:24 | train] - 
Epoch [73] Test set: Average loss: 1.3507, Accuracy: 35033/50000 (70.0384%), Top-5 Accuracy: 89.0677%

[2022-03-30 20:38:24 | train] - save intermediate epoch [73] result


[2022-03-30 20:38:26 | train] - -------74 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 20:38:28 | train] - Train Epoch: [74] [0/1281167 (0%)]	Loss: 0.719888
[2022-03-30 20:38:48 | train] - Train Epoch: [74] [12800/1281167 (1%)]	Loss: 0.782025
[2022-03-30 20:39:08 | train] - Train Epoch: [74] [25600/1281167 (2%)]	Loss: 0.810125
[2022-03-30 20:39:27 | train] - Train Epoch: [74] [38400/1281167 (3%)]	Loss: 1.105336
[2022-03-30 20:39:47 | train] - Train Epoch: [74] [51200/1281167 (4%)]	Loss: 0.813299
[2022-03-30 20:40:06 | train] - Train Epoch: [74] [64000/1281167 (5%)]	Loss: 0.585806
[2022-03-30 20:40:26 | train] - Train Epoch: [74] [76800/1281167 (6%)]	Loss: 0.991863
[2022-03-30 20:40:46 | train] - Train Epoch: [74] [89600/1281167 (7%)]	Loss: 0.883274
[2022-03-30 20:41:06 | train] - Train Epoch: [74] [102400/1281167 (8%)]	Loss: 1.026868
[2022-03-30 20:41:26 | train] - Train Epoch: [74] [115200/1281167 (9%)]	Loss: 0.912714
[2022-03-30 20:41:45 | train] - Train Epoch: [74] [128000/1281167 (10%)]	Loss: 0.693650
[2022-03-30 20:42:05 | train] - Train Epoch: [74] [140800/1281167 (11%)]	Loss: 0.952636
[2022-03-30 20:42:24 | train] - Train Epoch: [74] [153600/1281167 (12%)]	Loss: 0.914015
[2022-03-30 20:42:44 | train] - Train Epoch: [74] [166400/1281167 (13%)]	Loss: 0.709251
[2022-03-30 20:43:04 | train] - Train Epoch: [74] [179200/1281167 (14%)]	Loss: 0.721045
[2022-03-30 20:43:24 | train] - Train Epoch: [74] [192000/1281167 (15%)]	Loss: 0.962814
[2022-03-30 20:43:44 | train] - Train Epoch: [74] [204800/1281167 (16%)]	Loss: 0.848106
[2022-03-30 20:44:03 | train] - Train Epoch: [74] [217600/1281167 (17%)]	Loss: 0.747732
[2022-03-30 20:44:23 | train] - Train Epoch: [74] [230400/1281167 (18%)]	Loss: 0.774765
[2022-03-30 20:44:42 | train] - Train Epoch: [74] [243200/1281167 (19%)]	Loss: 0.744064
[2022-03-30 20:45:02 | train] - Train Epoch: [74] [256000/1281167 (20%)]	Loss: 1.051285
[2022-03-30 20:45:22 | train] - Train Epoch: [74] [268800/1281167 (21%)]	Loss: 0.870518
[2022-03-30 20:45:42 | train] - Train Epoch: [74] [281600/1281167 (22%)]	Loss: 1.106069
[2022-03-30 20:46:02 | train] - Train Epoch: [74] [294400/1281167 (23%)]	Loss: 0.782734
[2022-03-30 20:46:22 | train] - Train Epoch: [74] [307200/1281167 (24%)]	Loss: 0.891413
[2022-03-30 20:46:41 | train] - Train Epoch: [74] [320000/1281167 (25%)]	Loss: 0.637162
[2022-03-30 20:47:01 | train] - Train Epoch: [74] [332800/1281167 (26%)]	Loss: 0.906418
[2022-03-30 20:47:21 | train] - Train Epoch: [74] [345600/1281167 (27%)]	Loss: 0.685657
[2022-03-30 20:47:41 | train] - Train Epoch: [74] [358400/1281167 (28%)]	Loss: 0.951699
[2022-03-30 20:48:01 | train] - Train Epoch: [74] [371200/1281167 (29%)]	Loss: 1.076945
[2022-03-30 20:48:21 | train] - Train Epoch: [74] [384000/1281167 (30%)]	Loss: 0.945413
[2022-03-30 20:48:41 | train] - Train Epoch: [74] [396800/1281167 (31%)]	Loss: 0.714365
[2022-03-30 20:49:00 | train] - Train Epoch: [74] [409600/1281167 (32%)]	Loss: 0.730296
[2022-03-30 20:49:20 | train] - Train Epoch: [74] [422400/1281167 (33%)]	Loss: 0.938512
[2022-03-30 20:49:40 | train] - Train Epoch: [74] [435200/1281167 (34%)]	Loss: 0.778181
[2022-03-30 20:50:00 | train] - Train Epoch: [74] [448000/1281167 (35%)]	Loss: 1.214274
[2022-03-30 20:50:20 | train] - Train Epoch: [74] [460800/1281167 (36%)]	Loss: 0.829066
[2022-03-30 20:50:40 | train] - Train Epoch: [74] [473600/1281167 (37%)]	Loss: 0.667417
[2022-03-30 20:50:59 | train] - Train Epoch: [74] [486400/1281167 (38%)]	Loss: 0.912408
[2022-03-30 20:51:18 | train] - Train Epoch: [74] [499200/1281167 (39%)]	Loss: 0.925801
[2022-03-30 20:51:38 | train] - Train Epoch: [74] [512000/1281167 (40%)]	Loss: 0.888811
[2022-03-30 20:51:57 | train] - Train Epoch: [74] [524800/1281167 (41%)]	Loss: 1.005624
[2022-03-30 20:52:17 | train] - Train Epoch: [74] [537600/1281167 (42%)]	Loss: 0.639272
[2022-03-30 20:52:36 | train] - Train Epoch: [74] [550400/1281167 (43%)]	Loss: 0.769958
[2022-03-30 20:52:56 | train] - Train Epoch: [74] [563200/1281167 (44%)]	Loss: 0.789248
[2022-03-30 20:53:16 | train] - Train Epoch: [74] [576000/1281167 (45%)]	Loss: 0.832008
[2022-03-30 20:53:35 | train] - Train Epoch: [74] [588800/1281167 (46%)]	Loss: 0.640375
[2022-03-30 20:53:55 | train] - Train Epoch: [74] [601600/1281167 (47%)]	Loss: 0.997773
[2022-03-30 20:54:15 | train] - Train Epoch: [74] [614400/1281167 (48%)]	Loss: 0.721466
[2022-03-30 20:54:35 | train] - Train Epoch: [74] [627200/1281167 (49%)]	Loss: 0.652680
[2022-03-30 20:54:55 | train] - Train Epoch: [74] [640000/1281167 (50%)]	Loss: 0.975243
[2022-03-30 20:55:14 | train] - Train Epoch: [74] [652800/1281167 (51%)]	Loss: 0.930421
[2022-03-30 20:55:33 | train] - Train Epoch: [74] [665600/1281167 (52%)]	Loss: 0.766132
[2022-03-30 20:55:53 | train] - Train Epoch: [74] [678400/1281167 (53%)]	Loss: 0.774244
[2022-03-30 20:56:13 | train] - Train Epoch: [74] [691200/1281167 (54%)]	Loss: 0.711257
[2022-03-30 20:56:32 | train] - Train Epoch: [74] [704000/1281167 (55%)]	Loss: 1.082394
[2022-03-30 20:56:51 | train] - Train Epoch: [74] [716800/1281167 (56%)]	Loss: 0.618369
[2022-03-30 20:57:11 | train] - Train Epoch: [74] [729600/1281167 (57%)]	Loss: 0.699139
[2022-03-30 20:57:31 | train] - Train Epoch: [74] [742400/1281167 (58%)]	Loss: 0.888460
[2022-03-30 20:57:51 | train] - Train Epoch: [74] [755200/1281167 (59%)]	Loss: 0.943673
[2022-03-30 20:58:11 | train] - Train Epoch: [74] [768000/1281167 (60%)]	Loss: 0.862892
[2022-03-30 20:58:31 | train] - Train Epoch: [74] [780800/1281167 (61%)]	Loss: 1.076597
[2022-03-30 20:58:50 | train] - Train Epoch: [74] [793600/1281167 (62%)]	Loss: 0.905050
[2022-03-30 20:59:10 | train] - Train Epoch: [74] [806400/1281167 (63%)]	Loss: 1.055823
[2022-03-30 20:59:31 | train] - Train Epoch: [74] [819200/1281167 (64%)]	Loss: 0.931777
[2022-03-30 20:59:51 | train] - Train Epoch: [74] [832000/1281167 (65%)]	Loss: 0.798779
[2022-03-30 21:00:11 | train] - Train Epoch: [74] [844800/1281167 (66%)]	Loss: 0.945523
[2022-03-30 21:00:30 | train] - Train Epoch: [74] [857600/1281167 (67%)]	Loss: 0.812731
[2022-03-30 21:00:50 | train] - Train Epoch: [74] [870400/1281167 (68%)]	Loss: 0.888782
[2022-03-30 21:01:09 | train] - Train Epoch: [74] [883200/1281167 (69%)]	Loss: 0.596394
[2022-03-30 21:01:29 | train] - Train Epoch: [74] [896000/1281167 (70%)]	Loss: 0.906507
[2022-03-30 21:01:48 | train] - Train Epoch: [74] [908800/1281167 (71%)]	Loss: 0.847164
[2022-03-30 21:02:08 | train] - Train Epoch: [74] [921600/1281167 (72%)]	Loss: 0.632477
[2022-03-30 21:02:28 | train] - Train Epoch: [74] [934400/1281167 (73%)]	Loss: 1.098760
[2022-03-30 21:02:47 | train] - Train Epoch: [74] [947200/1281167 (74%)]	Loss: 0.985405
[2022-03-30 21:03:07 | train] - Train Epoch: [74] [960000/1281167 (75%)]	Loss: 0.685834
[2022-03-30 21:03:26 | train] - Train Epoch: [74] [972800/1281167 (76%)]	Loss: 0.766279
[2022-03-30 21:03:45 | train] - Train Epoch: [74] [985600/1281167 (77%)]	Loss: 0.764574
[2022-03-30 21:04:05 | train] - Train Epoch: [74] [998400/1281167 (78%)]	Loss: 0.722373
[2022-03-30 21:04:24 | train] - Train Epoch: [74] [1011200/1281167 (79%)]	Loss: 0.960003
[2022-03-30 21:04:44 | train] - Train Epoch: [74] [1024000/1281167 (80%)]	Loss: 0.895562
[2022-03-30 21:05:03 | train] - Train Epoch: [74] [1036800/1281167 (81%)]	Loss: 0.769995
[2022-03-30 21:05:23 | train] - Train Epoch: [74] [1049600/1281167 (82%)]	Loss: 0.673449
[2022-03-30 21:05:43 | train] - Train Epoch: [74] [1062400/1281167 (83%)]	Loss: 0.998723
[2022-03-30 21:06:03 | train] - Train Epoch: [74] [1075200/1281167 (84%)]	Loss: 0.998801
[2022-03-30 21:06:22 | train] - Train Epoch: [74] [1088000/1281167 (85%)]	Loss: 0.763362
[2022-03-30 21:06:42 | train] - Train Epoch: [74] [1100800/1281167 (86%)]	Loss: 0.736622
[2022-03-30 21:07:02 | train] - Train Epoch: [74] [1113600/1281167 (87%)]	Loss: 0.719816
[2022-03-30 21:07:22 | train] - Train Epoch: [74] [1126400/1281167 (88%)]	Loss: 0.815943
[2022-03-30 21:07:42 | train] - Train Epoch: [74] [1139200/1281167 (89%)]	Loss: 0.960882
[2022-03-30 21:08:01 | train] - Train Epoch: [74] [1152000/1281167 (90%)]	Loss: 0.828688
[2022-03-30 21:08:21 | train] - Train Epoch: [74] [1164800/1281167 (91%)]	Loss: 0.479227
[2022-03-30 21:08:40 | train] - Train Epoch: [74] [1177600/1281167 (92%)]	Loss: 0.899066
[2022-03-30 21:09:00 | train] - Train Epoch: [74] [1190400/1281167 (93%)]	Loss: 0.835946
[2022-03-30 21:09:19 | train] - Train Epoch: [74] [1203200/1281167 (94%)]	Loss: 0.809707
[2022-03-30 21:09:40 | train] - Train Epoch: [74] [1216000/1281167 (95%)]	Loss: 0.985937
[2022-03-30 21:09:59 | train] - Train Epoch: [74] [1228800/1281167 (96%)]	Loss: 1.068900
[2022-03-30 21:10:19 | train] - Train Epoch: [74] [1241600/1281167 (97%)]	Loss: 0.809914
[2022-03-30 21:10:39 | train] - Train Epoch: [74] [1254400/1281167 (98%)]	Loss: 0.969774
[2022-03-30 21:10:59 | train] - Train Epoch: [74] [1267200/1281167 (99%)]	Loss: 0.730909
[2022-03-30 21:11:19 | train] - Train Epoch: [74] [1280000/1281167 (100%)]	Loss: 1.061610
[2022-03-30 21:11:21 | train] - Train Epoch: [74]	 Average Loss: 0.865299	 Total Acc : 78.9730	 Total Top5 Acc : 92.2458
[2022-03-30 21:11:21 | train] - -------74 epoch end-----------
========================================
-------74 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 21:12:52 | train] - 
Epoch [74] Test set: Average loss: 1.3499, Accuracy: 35029/50000 (70.0304%), Top-5 Accuracy: 89.0597%

[2022-03-30 21:12:52 | train] - save intermediate epoch [74] result


[2022-03-30 21:12:55 | train] - -------75 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 21:12:56 | train] - Train Epoch: [75] [0/1281167 (0%)]	Loss: 0.822988
[2022-03-30 21:13:16 | train] - Train Epoch: [75] [12800/1281167 (1%)]	Loss: 0.859224
[2022-03-30 21:13:37 | train] - Train Epoch: [75] [25600/1281167 (2%)]	Loss: 1.029233
[2022-03-30 21:13:59 | train] - Train Epoch: [75] [38400/1281167 (3%)]	Loss: 0.875031
[2022-03-30 21:14:20 | train] - Train Epoch: [75] [51200/1281167 (4%)]	Loss: 1.275420
[2022-03-30 21:14:41 | train] - Train Epoch: [75] [64000/1281167 (5%)]	Loss: 0.754587
[2022-03-30 21:15:01 | train] - Train Epoch: [75] [76800/1281167 (6%)]	Loss: 0.792259
[2022-03-30 21:15:22 | train] - Train Epoch: [75] [89600/1281167 (7%)]	Loss: 1.065313
[2022-03-30 21:15:43 | train] - Train Epoch: [75] [102400/1281167 (8%)]	Loss: 0.926012
[2022-03-30 21:16:03 | train] - Train Epoch: [75] [115200/1281167 (9%)]	Loss: 1.159053
[2022-03-30 21:16:22 | train] - Train Epoch: [75] [128000/1281167 (10%)]	Loss: 0.718585
[2022-03-30 21:16:42 | train] - Train Epoch: [75] [140800/1281167 (11%)]	Loss: 0.816231
[2022-03-30 21:17:02 | train] - Train Epoch: [75] [153600/1281167 (12%)]	Loss: 1.251619
[2022-03-30 21:17:23 | train] - Train Epoch: [75] [166400/1281167 (13%)]	Loss: 1.013545
[2022-03-30 21:17:44 | train] - Train Epoch: [75] [179200/1281167 (14%)]	Loss: 0.716887
[2022-03-30 21:18:04 | train] - Train Epoch: [75] [192000/1281167 (15%)]	Loss: 0.781881
[2022-03-30 21:18:25 | train] - Train Epoch: [75] [204800/1281167 (16%)]	Loss: 0.733724
[2022-03-30 21:18:45 | train] - Train Epoch: [75] [217600/1281167 (17%)]	Loss: 0.935350
[2022-03-30 21:19:04 | train] - Train Epoch: [75] [230400/1281167 (18%)]	Loss: 0.706417
[2022-03-30 21:19:24 | train] - Train Epoch: [75] [243200/1281167 (19%)]	Loss: 0.790385
[2022-03-30 21:19:44 | train] - Train Epoch: [75] [256000/1281167 (20%)]	Loss: 1.108525
[2022-03-30 21:20:04 | train] - Train Epoch: [75] [268800/1281167 (21%)]	Loss: 0.735359
[2022-03-30 21:20:23 | train] - Train Epoch: [75] [281600/1281167 (22%)]	Loss: 0.700933
[2022-03-30 21:20:43 | train] - Train Epoch: [75] [294400/1281167 (23%)]	Loss: 0.826928
[2022-03-30 21:21:02 | train] - Train Epoch: [75] [307200/1281167 (24%)]	Loss: 0.952654
[2022-03-30 21:21:22 | train] - Train Epoch: [75] [320000/1281167 (25%)]	Loss: 0.653417
[2022-03-30 21:21:42 | train] - Train Epoch: [75] [332800/1281167 (26%)]	Loss: 1.372908
[2022-03-30 21:22:01 | train] - Train Epoch: [75] [345600/1281167 (27%)]	Loss: 0.589995
[2022-03-30 21:22:21 | train] - Train Epoch: [75] [358400/1281167 (28%)]	Loss: 0.969719
[2022-03-30 21:22:41 | train] - Train Epoch: [75] [371200/1281167 (29%)]	Loss: 0.857353
[2022-03-30 21:23:01 | train] - Train Epoch: [75] [384000/1281167 (30%)]	Loss: 1.105039
[2022-03-30 21:23:20 | train] - Train Epoch: [75] [396800/1281167 (31%)]	Loss: 1.123788
[2022-03-30 21:23:40 | train] - Train Epoch: [75] [409600/1281167 (32%)]	Loss: 0.884707
[2022-03-30 21:23:59 | train] - Train Epoch: [75] [422400/1281167 (33%)]	Loss: 0.958244
[2022-03-30 21:24:20 | train] - Train Epoch: [75] [435200/1281167 (34%)]	Loss: 0.732603
[2022-03-30 21:24:39 | train] - Train Epoch: [75] [448000/1281167 (35%)]	Loss: 0.730638
[2022-03-30 21:24:59 | train] - Train Epoch: [75] [460800/1281167 (36%)]	Loss: 0.920586
[2022-03-30 21:25:18 | train] - Train Epoch: [75] [473600/1281167 (37%)]	Loss: 0.655848
[2022-03-30 21:25:38 | train] - Train Epoch: [75] [486400/1281167 (38%)]	Loss: 0.996844
[2022-03-30 21:25:58 | train] - Train Epoch: [75] [499200/1281167 (39%)]	Loss: 0.917242
[2022-03-30 21:26:19 | train] - Train Epoch: [75] [512000/1281167 (40%)]	Loss: 1.232681
[2022-03-30 21:26:38 | train] - Train Epoch: [75] [524800/1281167 (41%)]	Loss: 0.417551
[2022-03-30 21:26:58 | train] - Train Epoch: [75] [537600/1281167 (42%)]	Loss: 0.608542
[2022-03-30 21:27:18 | train] - Train Epoch: [75] [550400/1281167 (43%)]	Loss: 0.894797
[2022-03-30 21:27:38 | train] - Train Epoch: [75] [563200/1281167 (44%)]	Loss: 0.616422
[2022-03-30 21:27:57 | train] - Train Epoch: [75] [576000/1281167 (45%)]	Loss: 0.840168
[2022-03-30 21:28:17 | train] - Train Epoch: [75] [588800/1281167 (46%)]	Loss: 0.849713
[2022-03-30 21:28:37 | train] - Train Epoch: [75] [601600/1281167 (47%)]	Loss: 0.785468
[2022-03-30 21:28:56 | train] - Train Epoch: [75] [614400/1281167 (48%)]	Loss: 0.873116
[2022-03-30 21:29:17 | train] - Train Epoch: [75] [627200/1281167 (49%)]	Loss: 0.709748
[2022-03-30 21:29:37 | train] - Train Epoch: [75] [640000/1281167 (50%)]	Loss: 0.840580
[2022-03-30 21:29:57 | train] - Train Epoch: [75] [652800/1281167 (51%)]	Loss: 0.820440
[2022-03-30 21:30:16 | train] - Train Epoch: [75] [665600/1281167 (52%)]	Loss: 0.723732
[2022-03-30 21:30:36 | train] - Train Epoch: [75] [678400/1281167 (53%)]	Loss: 1.150639
[2022-03-30 21:30:56 | train] - Train Epoch: [75] [691200/1281167 (54%)]	Loss: 0.869845
[2022-03-30 21:31:16 | train] - Train Epoch: [75] [704000/1281167 (55%)]	Loss: 0.718723
[2022-03-30 21:31:36 | train] - Train Epoch: [75] [716800/1281167 (56%)]	Loss: 0.949482
[2022-03-30 21:31:56 | train] - Train Epoch: [75] [729600/1281167 (57%)]	Loss: 0.911598
[2022-03-30 21:32:17 | train] - Train Epoch: [75] [742400/1281167 (58%)]	Loss: 1.063416
[2022-03-30 21:32:37 | train] - Train Epoch: [75] [755200/1281167 (59%)]	Loss: 0.951590
[2022-03-30 21:32:57 | train] - Train Epoch: [75] [768000/1281167 (60%)]	Loss: 0.853580
[2022-03-30 21:33:17 | train] - Train Epoch: [75] [780800/1281167 (61%)]	Loss: 0.800978
[2022-03-30 21:33:37 | train] - Train Epoch: [75] [793600/1281167 (62%)]	Loss: 1.148416
[2022-03-30 21:33:58 | train] - Train Epoch: [75] [806400/1281167 (63%)]	Loss: 0.831268
[2022-03-30 21:34:18 | train] - Train Epoch: [75] [819200/1281167 (64%)]	Loss: 0.720789
[2022-03-30 21:34:38 | train] - Train Epoch: [75] [832000/1281167 (65%)]	Loss: 0.734621
[2022-03-30 21:34:58 | train] - Train Epoch: [75] [844800/1281167 (66%)]	Loss: 0.927785
[2022-03-30 21:35:18 | train] - Train Epoch: [75] [857600/1281167 (67%)]	Loss: 0.821738
[2022-03-30 21:35:38 | train] - Train Epoch: [75] [870400/1281167 (68%)]	Loss: 0.732782
[2022-03-30 21:35:57 | train] - Train Epoch: [75] [883200/1281167 (69%)]	Loss: 0.742303
[2022-03-30 21:36:17 | train] - Train Epoch: [75] [896000/1281167 (70%)]	Loss: 0.742684
[2022-03-30 21:36:37 | train] - Train Epoch: [75] [908800/1281167 (71%)]	Loss: 0.924108
[2022-03-30 21:36:57 | train] - Train Epoch: [75] [921600/1281167 (72%)]	Loss: 0.982061
[2022-03-30 21:37:17 | train] - Train Epoch: [75] [934400/1281167 (73%)]	Loss: 0.716696
[2022-03-30 21:37:38 | train] - Train Epoch: [75] [947200/1281167 (74%)]	Loss: 0.740642
[2022-03-30 21:37:58 | train] - Train Epoch: [75] [960000/1281167 (75%)]	Loss: 0.915252
[2022-03-30 21:38:18 | train] - Train Epoch: [75] [972800/1281167 (76%)]	Loss: 0.716401
[2022-03-30 21:38:38 | train] - Train Epoch: [75] [985600/1281167 (77%)]	Loss: 0.742482
[2022-03-30 21:38:58 | train] - Train Epoch: [75] [998400/1281167 (78%)]	Loss: 0.797742
[2022-03-30 21:39:18 | train] - Train Epoch: [75] [1011200/1281167 (79%)]	Loss: 0.717235
[2022-03-30 21:39:38 | train] - Train Epoch: [75] [1024000/1281167 (80%)]	Loss: 0.776242
[2022-03-30 21:39:57 | train] - Train Epoch: [75] [1036800/1281167 (81%)]	Loss: 0.836581
[2022-03-30 21:40:17 | train] - Train Epoch: [75] [1049600/1281167 (82%)]	Loss: 0.990214
[2022-03-30 21:40:37 | train] - Train Epoch: [75] [1062400/1281167 (83%)]	Loss: 0.650667
[2022-03-30 21:40:57 | train] - Train Epoch: [75] [1075200/1281167 (84%)]	Loss: 0.868990
[2022-03-30 21:41:17 | train] - Train Epoch: [75] [1088000/1281167 (85%)]	Loss: 1.050869
[2022-03-30 21:41:36 | train] - Train Epoch: [75] [1100800/1281167 (86%)]	Loss: 0.733051
[2022-03-30 21:41:56 | train] - Train Epoch: [75] [1113600/1281167 (87%)]	Loss: 0.797174
[2022-03-30 21:42:16 | train] - Train Epoch: [75] [1126400/1281167 (88%)]	Loss: 1.116937
[2022-03-30 21:42:36 | train] - Train Epoch: [75] [1139200/1281167 (89%)]	Loss: 0.775913
[2022-03-30 21:42:56 | train] - Train Epoch: [75] [1152000/1281167 (90%)]	Loss: 0.634027
[2022-03-30 21:43:16 | train] - Train Epoch: [75] [1164800/1281167 (91%)]	Loss: 0.977820
[2022-03-30 21:43:36 | train] - Train Epoch: [75] [1177600/1281167 (92%)]	Loss: 1.014171
[2022-03-30 21:43:56 | train] - Train Epoch: [75] [1190400/1281167 (93%)]	Loss: 0.618046
[2022-03-30 21:44:16 | train] - Train Epoch: [75] [1203200/1281167 (94%)]	Loss: 0.965124
[2022-03-30 21:44:35 | train] - Train Epoch: [75] [1216000/1281167 (95%)]	Loss: 0.908357
[2022-03-30 21:44:55 | train] - Train Epoch: [75] [1228800/1281167 (96%)]	Loss: 1.040034
[2022-03-30 21:45:16 | train] - Train Epoch: [75] [1241600/1281167 (97%)]	Loss: 0.974820
[2022-03-30 21:45:35 | train] - Train Epoch: [75] [1254400/1281167 (98%)]	Loss: 0.740408
[2022-03-30 21:45:55 | train] - Train Epoch: [75] [1267200/1281167 (99%)]	Loss: 0.818386
[2022-03-30 21:46:14 | train] - Train Epoch: [75] [1280000/1281167 (100%)]	Loss: 0.838354
[2022-03-30 21:46:16 | train] - Train Epoch: [75]	 Average Loss: 0.858489	 Total Acc : 79.1335	 Total Top5 Acc : 92.3041
[2022-03-30 21:46:16 | train] - -------75 epoch end-----------
========================================
-------75 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 21:47:47 | train] - 
Epoch [75] Test set: Average loss: 1.3440, Accuracy: 35042/50000 (70.0551%), Top-5 Accuracy: 89.1069%

[2022-03-30 21:47:47 | train] - save intermediate epoch [75] result


[2022-03-30 21:47:50 | train] - -------76 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 21:47:51 | train] - Train Epoch: [76] [0/1281167 (0%)]	Loss: 1.021619
[2022-03-30 21:48:12 | train] - Train Epoch: [76] [12800/1281167 (1%)]	Loss: 0.812163
[2022-03-30 21:48:32 | train] - Train Epoch: [76] [25600/1281167 (2%)]	Loss: 0.695047
[2022-03-30 21:48:52 | train] - Train Epoch: [76] [38400/1281167 (3%)]	Loss: 0.986092
[2022-03-30 21:49:12 | train] - Train Epoch: [76] [51200/1281167 (4%)]	Loss: 0.811090
[2022-03-30 21:49:32 | train] - Train Epoch: [76] [64000/1281167 (5%)]	Loss: 0.858444
[2022-03-30 21:49:52 | train] - Train Epoch: [76] [76800/1281167 (6%)]	Loss: 0.802166
[2022-03-30 21:50:11 | train] - Train Epoch: [76] [89600/1281167 (7%)]	Loss: 0.622140
[2022-03-30 21:50:31 | train] - Train Epoch: [76] [102400/1281167 (8%)]	Loss: 0.969361
[2022-03-30 21:50:51 | train] - Train Epoch: [76] [115200/1281167 (9%)]	Loss: 0.492839
[2022-03-30 21:51:11 | train] - Train Epoch: [76] [128000/1281167 (10%)]	Loss: 0.780563
[2022-03-30 21:51:30 | train] - Train Epoch: [76] [140800/1281167 (11%)]	Loss: 0.782420
[2022-03-30 21:51:50 | train] - Train Epoch: [76] [153600/1281167 (12%)]	Loss: 0.729702
[2022-03-30 21:52:10 | train] - Train Epoch: [76] [166400/1281167 (13%)]	Loss: 1.030581
[2022-03-30 21:52:30 | train] - Train Epoch: [76] [179200/1281167 (14%)]	Loss: 0.606618
[2022-03-30 21:52:50 | train] - Train Epoch: [76] [192000/1281167 (15%)]	Loss: 0.947095
[2022-03-30 21:53:10 | train] - Train Epoch: [76] [204800/1281167 (16%)]	Loss: 0.842898
[2022-03-30 21:53:30 | train] - Train Epoch: [76] [217600/1281167 (17%)]	Loss: 0.981794
[2022-03-30 21:53:50 | train] - Train Epoch: [76] [230400/1281167 (18%)]	Loss: 0.761630
[2022-03-30 21:54:10 | train] - Train Epoch: [76] [243200/1281167 (19%)]	Loss: 0.665348
[2022-03-30 21:54:30 | train] - Train Epoch: [76] [256000/1281167 (20%)]	Loss: 0.750024
[2022-03-30 21:54:50 | train] - Train Epoch: [76] [268800/1281167 (21%)]	Loss: 0.971412
[2022-03-30 21:55:10 | train] - Train Epoch: [76] [281600/1281167 (22%)]	Loss: 1.060102
[2022-03-30 21:55:30 | train] - Train Epoch: [76] [294400/1281167 (23%)]	Loss: 0.631521
[2022-03-30 21:55:50 | train] - Train Epoch: [76] [307200/1281167 (24%)]	Loss: 0.980910
[2022-03-30 21:56:11 | train] - Train Epoch: [76] [320000/1281167 (25%)]	Loss: 0.930076
[2022-03-30 21:56:30 | train] - Train Epoch: [76] [332800/1281167 (26%)]	Loss: 0.953150
[2022-03-30 21:56:49 | train] - Train Epoch: [76] [345600/1281167 (27%)]	Loss: 0.938752
[2022-03-30 21:57:09 | train] - Train Epoch: [76] [358400/1281167 (28%)]	Loss: 0.775708
[2022-03-30 21:57:29 | train] - Train Epoch: [76] [371200/1281167 (29%)]	Loss: 1.182826
[2022-03-30 21:57:49 | train] - Train Epoch: [76] [384000/1281167 (30%)]	Loss: 0.608660
[2022-03-30 21:58:08 | train] - Train Epoch: [76] [396800/1281167 (31%)]	Loss: 0.657556
[2022-03-30 21:58:28 | train] - Train Epoch: [76] [409600/1281167 (32%)]	Loss: 0.590819
[2022-03-30 21:58:49 | train] - Train Epoch: [76] [422400/1281167 (33%)]	Loss: 0.751813
[2022-03-30 21:59:08 | train] - Train Epoch: [76] [435200/1281167 (34%)]	Loss: 1.017701
[2022-03-30 21:59:29 | train] - Train Epoch: [76] [448000/1281167 (35%)]	Loss: 1.042321
[2022-03-30 21:59:49 | train] - Train Epoch: [76] [460800/1281167 (36%)]	Loss: 0.994738
[2022-03-30 22:00:09 | train] - Train Epoch: [76] [473600/1281167 (37%)]	Loss: 0.845830
[2022-03-30 22:00:28 | train] - Train Epoch: [76] [486400/1281167 (38%)]	Loss: 0.756606
[2022-03-30 22:00:48 | train] - Train Epoch: [76] [499200/1281167 (39%)]	Loss: 0.911562
[2022-03-30 22:01:08 | train] - Train Epoch: [76] [512000/1281167 (40%)]	Loss: 1.328212
[2022-03-30 22:01:28 | train] - Train Epoch: [76] [524800/1281167 (41%)]	Loss: 0.658135
[2022-03-30 22:01:48 | train] - Train Epoch: [76] [537600/1281167 (42%)]	Loss: 0.867401
[2022-03-30 22:02:07 | train] - Train Epoch: [76] [550400/1281167 (43%)]	Loss: 0.935094
[2022-03-30 22:02:27 | train] - Train Epoch: [76] [563200/1281167 (44%)]	Loss: 0.942098
[2022-03-30 22:02:46 | train] - Train Epoch: [76] [576000/1281167 (45%)]	Loss: 0.892328
[2022-03-30 22:03:05 | train] - Train Epoch: [76] [588800/1281167 (46%)]	Loss: 0.647106
[2022-03-30 22:03:25 | train] - Train Epoch: [76] [601600/1281167 (47%)]	Loss: 0.839729
[2022-03-30 22:03:45 | train] - Train Epoch: [76] [614400/1281167 (48%)]	Loss: 0.949632
[2022-03-30 22:04:04 | train] - Train Epoch: [76] [627200/1281167 (49%)]	Loss: 1.068220
[2022-03-30 22:04:24 | train] - Train Epoch: [76] [640000/1281167 (50%)]	Loss: 0.875121
[2022-03-30 22:04:45 | train] - Train Epoch: [76] [652800/1281167 (51%)]	Loss: 1.196384
[2022-03-30 22:05:04 | train] - Train Epoch: [76] [665600/1281167 (52%)]	Loss: 0.774963
[2022-03-30 22:05:24 | train] - Train Epoch: [76] [678400/1281167 (53%)]	Loss: 0.751552
[2022-03-30 22:05:44 | train] - Train Epoch: [76] [691200/1281167 (54%)]	Loss: 0.921416
[2022-03-30 22:06:03 | train] - Train Epoch: [76] [704000/1281167 (55%)]	Loss: 0.570937
[2022-03-30 22:06:23 | train] - Train Epoch: [76] [716800/1281167 (56%)]	Loss: 0.623786
[2022-03-30 22:06:43 | train] - Train Epoch: [76] [729600/1281167 (57%)]	Loss: 0.842312
[2022-03-30 22:07:03 | train] - Train Epoch: [76] [742400/1281167 (58%)]	Loss: 0.756548
[2022-03-30 22:07:23 | train] - Train Epoch: [76] [755200/1281167 (59%)]	Loss: 0.900620
[2022-03-30 22:07:43 | train] - Train Epoch: [76] [768000/1281167 (60%)]	Loss: 0.839363
[2022-03-30 22:08:03 | train] - Train Epoch: [76] [780800/1281167 (61%)]	Loss: 0.933324
[2022-03-30 22:08:24 | train] - Train Epoch: [76] [793600/1281167 (62%)]	Loss: 0.669667
[2022-03-30 22:08:43 | train] - Train Epoch: [76] [806400/1281167 (63%)]	Loss: 0.639818
[2022-03-30 22:09:02 | train] - Train Epoch: [76] [819200/1281167 (64%)]	Loss: 0.976098
[2022-03-30 22:09:22 | train] - Train Epoch: [76] [832000/1281167 (65%)]	Loss: 0.886044
[2022-03-30 22:09:42 | train] - Train Epoch: [76] [844800/1281167 (66%)]	Loss: 0.980880
[2022-03-30 22:10:01 | train] - Train Epoch: [76] [857600/1281167 (67%)]	Loss: 0.679347
[2022-03-30 22:10:21 | train] - Train Epoch: [76] [870400/1281167 (68%)]	Loss: 0.564799
[2022-03-30 22:10:41 | train] - Train Epoch: [76] [883200/1281167 (69%)]	Loss: 0.895722
[2022-03-30 22:11:01 | train] - Train Epoch: [76] [896000/1281167 (70%)]	Loss: 0.796626
[2022-03-30 22:11:20 | train] - Train Epoch: [76] [908800/1281167 (71%)]	Loss: 1.004228
[2022-03-30 22:11:41 | train] - Train Epoch: [76] [921600/1281167 (72%)]	Loss: 1.040960
[2022-03-30 22:12:01 | train] - Train Epoch: [76] [934400/1281167 (73%)]	Loss: 0.654971
[2022-03-30 22:12:20 | train] - Train Epoch: [76] [947200/1281167 (74%)]	Loss: 0.982472
[2022-03-30 22:12:40 | train] - Train Epoch: [76] [960000/1281167 (75%)]	Loss: 0.784220
[2022-03-30 22:13:01 | train] - Train Epoch: [76] [972800/1281167 (76%)]	Loss: 0.914293
[2022-03-30 22:13:21 | train] - Train Epoch: [76] [985600/1281167 (77%)]	Loss: 0.680775
[2022-03-30 22:13:41 | train] - Train Epoch: [76] [998400/1281167 (78%)]	Loss: 0.674959
[2022-03-30 22:14:00 | train] - Train Epoch: [76] [1011200/1281167 (79%)]	Loss: 0.912076
[2022-03-30 22:14:20 | train] - Train Epoch: [76] [1024000/1281167 (80%)]	Loss: 0.665674
[2022-03-30 22:14:40 | train] - Train Epoch: [76] [1036800/1281167 (81%)]	Loss: 0.884160
[2022-03-30 22:14:59 | train] - Train Epoch: [76] [1049600/1281167 (82%)]	Loss: 0.854323
[2022-03-30 22:15:19 | train] - Train Epoch: [76] [1062400/1281167 (83%)]	Loss: 0.875573
[2022-03-30 22:15:39 | train] - Train Epoch: [76] [1075200/1281167 (84%)]	Loss: 0.888271
[2022-03-30 22:15:58 | train] - Train Epoch: [76] [1088000/1281167 (85%)]	Loss: 1.076742
[2022-03-30 22:16:18 | train] - Train Epoch: [76] [1100800/1281167 (86%)]	Loss: 1.095983
[2022-03-30 22:16:37 | train] - Train Epoch: [76] [1113600/1281167 (87%)]	Loss: 0.892785
[2022-03-30 22:16:58 | train] - Train Epoch: [76] [1126400/1281167 (88%)]	Loss: 0.632868
[2022-03-30 22:17:18 | train] - Train Epoch: [76] [1139200/1281167 (89%)]	Loss: 0.812971
[2022-03-30 22:17:38 | train] - Train Epoch: [76] [1152000/1281167 (90%)]	Loss: 0.901645
[2022-03-30 22:17:58 | train] - Train Epoch: [76] [1164800/1281167 (91%)]	Loss: 0.765725
[2022-03-30 22:18:18 | train] - Train Epoch: [76] [1177600/1281167 (92%)]	Loss: 0.781120
[2022-03-30 22:18:37 | train] - Train Epoch: [76] [1190400/1281167 (93%)]	Loss: 0.820319
[2022-03-30 22:18:56 | train] - Train Epoch: [76] [1203200/1281167 (94%)]	Loss: 0.724051
[2022-03-30 22:19:16 | train] - Train Epoch: [76] [1216000/1281167 (95%)]	Loss: 0.674160
[2022-03-30 22:19:36 | train] - Train Epoch: [76] [1228800/1281167 (96%)]	Loss: 0.975435
[2022-03-30 22:19:56 | train] - Train Epoch: [76] [1241600/1281167 (97%)]	Loss: 1.044210
[2022-03-30 22:20:16 | train] - Train Epoch: [76] [1254400/1281167 (98%)]	Loss: 0.847989
[2022-03-30 22:20:36 | train] - Train Epoch: [76] [1267200/1281167 (99%)]	Loss: 0.943977
[2022-03-30 22:20:56 | train] - Train Epoch: [76] [1280000/1281167 (100%)]	Loss: 0.913622
[2022-03-30 22:20:58 | train] - Train Epoch: [76]	 Average Loss: 0.854307	 Total Acc : 79.2307	 Total Top5 Acc : 92.3634
[2022-03-30 22:20:58 | train] - -------76 epoch end-----------
========================================
-------76 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 22:22:30 | train] - 
Epoch [76] Test set: Average loss: 1.3567, Accuracy: 34944/50000 (69.8605%), Top-5 Accuracy: 88.9258%

[2022-03-30 22:22:30 | train] - save intermediate epoch [76] result


[2022-03-30 22:22:33 | train] - -------77 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 22:22:35 | train] - Train Epoch: [77] [0/1281167 (0%)]	Loss: 0.859466
[2022-03-30 22:22:56 | train] - Train Epoch: [77] [12800/1281167 (1%)]	Loss: 1.012612
[2022-03-30 22:23:16 | train] - Train Epoch: [77] [25600/1281167 (2%)]	Loss: 0.864105
[2022-03-30 22:23:37 | train] - Train Epoch: [77] [38400/1281167 (3%)]	Loss: 0.888471
[2022-03-30 22:23:57 | train] - Train Epoch: [77] [51200/1281167 (4%)]	Loss: 0.828538
[2022-03-30 22:24:16 | train] - Train Epoch: [77] [64000/1281167 (5%)]	Loss: 0.951169
[2022-03-30 22:24:37 | train] - Train Epoch: [77] [76800/1281167 (6%)]	Loss: 0.741015
[2022-03-30 22:24:58 | train] - Train Epoch: [77] [89600/1281167 (7%)]	Loss: 0.739851
[2022-03-30 22:25:18 | train] - Train Epoch: [77] [102400/1281167 (8%)]	Loss: 0.733260
[2022-03-30 22:25:38 | train] - Train Epoch: [77] [115200/1281167 (9%)]	Loss: 0.903891
[2022-03-30 22:25:57 | train] - Train Epoch: [77] [128000/1281167 (10%)]	Loss: 0.800060
[2022-03-30 22:26:17 | train] - Train Epoch: [77] [140800/1281167 (11%)]	Loss: 0.983244
[2022-03-30 22:26:37 | train] - Train Epoch: [77] [153600/1281167 (12%)]	Loss: 0.772580
[2022-03-30 22:26:56 | train] - Train Epoch: [77] [166400/1281167 (13%)]	Loss: 0.892365
[2022-03-30 22:27:16 | train] - Train Epoch: [77] [179200/1281167 (14%)]	Loss: 0.727790
[2022-03-30 22:27:36 | train] - Train Epoch: [77] [192000/1281167 (15%)]	Loss: 0.842679
[2022-03-30 22:27:56 | train] - Train Epoch: [77] [204800/1281167 (16%)]	Loss: 0.994154
[2022-03-30 22:28:15 | train] - Train Epoch: [77] [217600/1281167 (17%)]	Loss: 1.017239
[2022-03-30 22:28:34 | train] - Train Epoch: [77] [230400/1281167 (18%)]	Loss: 0.821141
[2022-03-30 22:28:54 | train] - Train Epoch: [77] [243200/1281167 (19%)]	Loss: 0.683201
[2022-03-30 22:29:14 | train] - Train Epoch: [77] [256000/1281167 (20%)]	Loss: 0.774228
[2022-03-30 22:29:33 | train] - Train Epoch: [77] [268800/1281167 (21%)]	Loss: 0.698443
[2022-03-30 22:29:53 | train] - Train Epoch: [77] [281600/1281167 (22%)]	Loss: 0.970829
[2022-03-30 22:30:13 | train] - Train Epoch: [77] [294400/1281167 (23%)]	Loss: 0.945813
[2022-03-30 22:30:32 | train] - Train Epoch: [77] [307200/1281167 (24%)]	Loss: 0.913289
[2022-03-30 22:30:52 | train] - Train Epoch: [77] [320000/1281167 (25%)]	Loss: 0.451046
[2022-03-30 22:31:12 | train] - Train Epoch: [77] [332800/1281167 (26%)]	Loss: 0.953196
[2022-03-30 22:31:32 | train] - Train Epoch: [77] [345600/1281167 (27%)]	Loss: 0.923660
[2022-03-30 22:31:52 | train] - Train Epoch: [77] [358400/1281167 (28%)]	Loss: 0.881716
[2022-03-30 22:32:12 | train] - Train Epoch: [77] [371200/1281167 (29%)]	Loss: 0.974880
[2022-03-30 22:32:31 | train] - Train Epoch: [77] [384000/1281167 (30%)]	Loss: 0.807603
[2022-03-30 22:32:51 | train] - Train Epoch: [77] [396800/1281167 (31%)]	Loss: 0.868274
[2022-03-30 22:33:11 | train] - Train Epoch: [77] [409600/1281167 (32%)]	Loss: 1.026811
[2022-03-30 22:33:30 | train] - Train Epoch: [77] [422400/1281167 (33%)]	Loss: 0.823662
[2022-03-30 22:33:50 | train] - Train Epoch: [77] [435200/1281167 (34%)]	Loss: 0.813485
[2022-03-30 22:34:09 | train] - Train Epoch: [77] [448000/1281167 (35%)]	Loss: 0.826205
[2022-03-30 22:34:29 | train] - Train Epoch: [77] [460800/1281167 (36%)]	Loss: 1.047134
[2022-03-30 22:34:48 | train] - Train Epoch: [77] [473600/1281167 (37%)]	Loss: 0.801686
[2022-03-30 22:35:09 | train] - Train Epoch: [77] [486400/1281167 (38%)]	Loss: 0.846371
[2022-03-30 22:35:28 | train] - Train Epoch: [77] [499200/1281167 (39%)]	Loss: 0.850651
[2022-03-30 22:35:48 | train] - Train Epoch: [77] [512000/1281167 (40%)]	Loss: 0.782392
[2022-03-30 22:36:08 | train] - Train Epoch: [77] [524800/1281167 (41%)]	Loss: 0.770168
[2022-03-30 22:36:27 | train] - Train Epoch: [77] [537600/1281167 (42%)]	Loss: 0.883759
[2022-03-30 22:36:47 | train] - Train Epoch: [77] [550400/1281167 (43%)]	Loss: 0.817737
[2022-03-30 22:37:06 | train] - Train Epoch: [77] [563200/1281167 (44%)]	Loss: 0.903591
[2022-03-30 22:37:26 | train] - Train Epoch: [77] [576000/1281167 (45%)]	Loss: 0.887683
[2022-03-30 22:37:45 | train] - Train Epoch: [77] [588800/1281167 (46%)]	Loss: 0.896944
[2022-03-30 22:38:05 | train] - Train Epoch: [77] [601600/1281167 (47%)]	Loss: 0.722449
[2022-03-30 22:38:25 | train] - Train Epoch: [77] [614400/1281167 (48%)]	Loss: 1.106848
[2022-03-30 22:38:45 | train] - Train Epoch: [77] [627200/1281167 (49%)]	Loss: 0.893206
[2022-03-30 22:39:04 | train] - Train Epoch: [77] [640000/1281167 (50%)]	Loss: 0.878598
[2022-03-30 22:39:24 | train] - Train Epoch: [77] [652800/1281167 (51%)]	Loss: 1.034335
[2022-03-30 22:39:44 | train] - Train Epoch: [77] [665600/1281167 (52%)]	Loss: 0.794305
[2022-03-30 22:40:04 | train] - Train Epoch: [77] [678400/1281167 (53%)]	Loss: 0.864097
[2022-03-30 22:40:24 | train] - Train Epoch: [77] [691200/1281167 (54%)]	Loss: 0.580480
[2022-03-30 22:40:43 | train] - Train Epoch: [77] [704000/1281167 (55%)]	Loss: 1.115482
[2022-03-30 22:41:03 | train] - Train Epoch: [77] [716800/1281167 (56%)]	Loss: 0.805699
[2022-03-30 22:41:22 | train] - Train Epoch: [77] [729600/1281167 (57%)]	Loss: 0.794623
[2022-03-30 22:41:43 | train] - Train Epoch: [77] [742400/1281167 (58%)]	Loss: 0.667774
[2022-03-30 22:42:03 | train] - Train Epoch: [77] [755200/1281167 (59%)]	Loss: 0.666621
[2022-03-30 22:42:23 | train] - Train Epoch: [77] [768000/1281167 (60%)]	Loss: 0.629878
[2022-03-30 22:42:43 | train] - Train Epoch: [77] [780800/1281167 (61%)]	Loss: 0.709028
[2022-03-30 22:43:03 | train] - Train Epoch: [77] [793600/1281167 (62%)]	Loss: 0.759405
[2022-03-30 22:43:23 | train] - Train Epoch: [77] [806400/1281167 (63%)]	Loss: 0.747590
[2022-03-30 22:43:43 | train] - Train Epoch: [77] [819200/1281167 (64%)]	Loss: 0.690864
[2022-03-30 22:44:03 | train] - Train Epoch: [77] [832000/1281167 (65%)]	Loss: 1.109497
[2022-03-30 22:44:23 | train] - Train Epoch: [77] [844800/1281167 (66%)]	Loss: 0.734726
[2022-03-30 22:44:44 | train] - Train Epoch: [77] [857600/1281167 (67%)]	Loss: 0.919293
[2022-03-30 22:45:03 | train] - Train Epoch: [77] [870400/1281167 (68%)]	Loss: 1.013479
[2022-03-30 22:45:23 | train] - Train Epoch: [77] [883200/1281167 (69%)]	Loss: 0.707042
[2022-03-30 22:45:43 | train] - Train Epoch: [77] [896000/1281167 (70%)]	Loss: 0.686597
[2022-03-30 22:46:03 | train] - Train Epoch: [77] [908800/1281167 (71%)]	Loss: 1.048781
[2022-03-30 22:46:22 | train] - Train Epoch: [77] [921600/1281167 (72%)]	Loss: 1.076120
[2022-03-30 22:46:43 | train] - Train Epoch: [77] [934400/1281167 (73%)]	Loss: 0.675944
[2022-03-30 22:47:02 | train] - Train Epoch: [77] [947200/1281167 (74%)]	Loss: 1.073433
[2022-03-30 22:47:22 | train] - Train Epoch: [77] [960000/1281167 (75%)]	Loss: 1.006228
[2022-03-30 22:47:41 | train] - Train Epoch: [77] [972800/1281167 (76%)]	Loss: 0.822184
[2022-03-30 22:48:01 | train] - Train Epoch: [77] [985600/1281167 (77%)]	Loss: 0.572615
[2022-03-30 22:48:21 | train] - Train Epoch: [77] [998400/1281167 (78%)]	Loss: 0.682479
[2022-03-30 22:48:41 | train] - Train Epoch: [77] [1011200/1281167 (79%)]	Loss: 1.043118
[2022-03-30 22:49:01 | train] - Train Epoch: [77] [1024000/1281167 (80%)]	Loss: 0.799794
[2022-03-30 22:49:21 | train] - Train Epoch: [77] [1036800/1281167 (81%)]	Loss: 1.007713
[2022-03-30 22:49:40 | train] - Train Epoch: [77] [1049600/1281167 (82%)]	Loss: 1.087745
[2022-03-30 22:50:00 | train] - Train Epoch: [77] [1062400/1281167 (83%)]	Loss: 0.891832
[2022-03-30 22:50:20 | train] - Train Epoch: [77] [1075200/1281167 (84%)]	Loss: 1.047571
[2022-03-30 22:50:40 | train] - Train Epoch: [77] [1088000/1281167 (85%)]	Loss: 1.009285
[2022-03-30 22:51:00 | train] - Train Epoch: [77] [1100800/1281167 (86%)]	Loss: 1.070324
[2022-03-30 22:51:19 | train] - Train Epoch: [77] [1113600/1281167 (87%)]	Loss: 0.813246
[2022-03-30 22:51:39 | train] - Train Epoch: [77] [1126400/1281167 (88%)]	Loss: 0.705850
[2022-03-30 22:51:59 | train] - Train Epoch: [77] [1139200/1281167 (89%)]	Loss: 0.828407
[2022-03-30 22:52:19 | train] - Train Epoch: [77] [1152000/1281167 (90%)]	Loss: 0.736826
[2022-03-30 22:52:38 | train] - Train Epoch: [77] [1164800/1281167 (91%)]	Loss: 0.897575
[2022-03-30 22:52:57 | train] - Train Epoch: [77] [1177600/1281167 (92%)]	Loss: 0.910526
[2022-03-30 22:53:17 | train] - Train Epoch: [77] [1190400/1281167 (93%)]	Loss: 1.032569
[2022-03-30 22:53:37 | train] - Train Epoch: [77] [1203200/1281167 (94%)]	Loss: 1.016815
[2022-03-30 22:53:57 | train] - Train Epoch: [77] [1216000/1281167 (95%)]	Loss: 0.832933
[2022-03-30 22:54:16 | train] - Train Epoch: [77] [1228800/1281167 (96%)]	Loss: 0.878166
[2022-03-30 22:54:37 | train] - Train Epoch: [77] [1241600/1281167 (97%)]	Loss: 0.795231
[2022-03-30 22:54:57 | train] - Train Epoch: [77] [1254400/1281167 (98%)]	Loss: 0.741608
[2022-03-30 22:55:16 | train] - Train Epoch: [77] [1267200/1281167 (99%)]	Loss: 0.885557
[2022-03-30 22:55:36 | train] - Train Epoch: [77] [1280000/1281167 (100%)]	Loss: 0.928056
[2022-03-30 22:55:38 | train] - Train Epoch: [77]	 Average Loss: 0.851134	 Total Acc : 79.3158	 Total Top5 Acc : 92.3838
[2022-03-30 22:55:38 | train] - -------77 epoch end-----------
========================================
-------77 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 22:57:11 | train] - 
Epoch [77] Test set: Average loss: 1.3504, Accuracy: 34971/50000 (69.9169%), Top-5 Accuracy: 88.9298%

[2022-03-30 22:57:11 | train] - save intermediate epoch [77] result


[2022-03-30 22:57:15 | train] - -------78 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 22:57:17 | train] - Train Epoch: [78] [0/1281167 (0%)]	Loss: 0.782185
[2022-03-30 22:57:36 | train] - Train Epoch: [78] [12800/1281167 (1%)]	Loss: 1.047543
[2022-03-30 22:57:56 | train] - Train Epoch: [78] [25600/1281167 (2%)]	Loss: 0.767421
[2022-03-30 22:58:16 | train] - Train Epoch: [78] [38400/1281167 (3%)]	Loss: 0.912601
[2022-03-30 22:58:36 | train] - Train Epoch: [78] [51200/1281167 (4%)]	Loss: 0.780853
[2022-03-30 22:58:55 | train] - Train Epoch: [78] [64000/1281167 (5%)]	Loss: 0.877537
[2022-03-30 22:59:15 | train] - Train Epoch: [78] [76800/1281167 (6%)]	Loss: 0.763993
[2022-03-30 22:59:35 | train] - Train Epoch: [78] [89600/1281167 (7%)]	Loss: 0.901191
[2022-03-30 22:59:54 | train] - Train Epoch: [78] [102400/1281167 (8%)]	Loss: 0.832008
[2022-03-30 23:00:14 | train] - Train Epoch: [78] [115200/1281167 (9%)]	Loss: 0.883950
[2022-03-30 23:00:34 | train] - Train Epoch: [78] [128000/1281167 (10%)]	Loss: 0.634114
[2022-03-30 23:00:54 | train] - Train Epoch: [78] [140800/1281167 (11%)]	Loss: 0.724246
[2022-03-30 23:01:15 | train] - Train Epoch: [78] [153600/1281167 (12%)]	Loss: 1.231279
[2022-03-30 23:01:35 | train] - Train Epoch: [78] [166400/1281167 (13%)]	Loss: 0.938141
[2022-03-30 23:01:55 | train] - Train Epoch: [78] [179200/1281167 (14%)]	Loss: 0.932542
[2022-03-30 23:02:15 | train] - Train Epoch: [78] [192000/1281167 (15%)]	Loss: 1.198268
[2022-03-30 23:02:35 | train] - Train Epoch: [78] [204800/1281167 (16%)]	Loss: 1.203033
[2022-03-30 23:02:55 | train] - Train Epoch: [78] [217600/1281167 (17%)]	Loss: 1.124388
[2022-03-30 23:03:14 | train] - Train Epoch: [78] [230400/1281167 (18%)]	Loss: 1.087782
[2022-03-30 23:03:34 | train] - Train Epoch: [78] [243200/1281167 (19%)]	Loss: 0.788741
[2022-03-30 23:03:53 | train] - Train Epoch: [78] [256000/1281167 (20%)]	Loss: 0.890405
[2022-03-30 23:04:13 | train] - Train Epoch: [78] [268800/1281167 (21%)]	Loss: 0.615244
[2022-03-30 23:04:33 | train] - Train Epoch: [78] [281600/1281167 (22%)]	Loss: 0.993635
[2022-03-30 23:04:52 | train] - Train Epoch: [78] [294400/1281167 (23%)]	Loss: 0.726968
[2022-03-30 23:05:12 | train] - Train Epoch: [78] [307200/1281167 (24%)]	Loss: 0.674090
[2022-03-30 23:05:32 | train] - Train Epoch: [78] [320000/1281167 (25%)]	Loss: 1.037522
[2022-03-30 23:05:52 | train] - Train Epoch: [78] [332800/1281167 (26%)]	Loss: 0.876524
[2022-03-30 23:06:11 | train] - Train Epoch: [78] [345600/1281167 (27%)]	Loss: 0.880880
[2022-03-30 23:06:31 | train] - Train Epoch: [78] [358400/1281167 (28%)]	Loss: 0.739526
[2022-03-30 23:06:51 | train] - Train Epoch: [78] [371200/1281167 (29%)]	Loss: 0.782492
[2022-03-30 23:07:11 | train] - Train Epoch: [78] [384000/1281167 (30%)]	Loss: 1.048517
[2022-03-30 23:07:31 | train] - Train Epoch: [78] [396800/1281167 (31%)]	Loss: 1.025332
[2022-03-30 23:07:51 | train] - Train Epoch: [78] [409600/1281167 (32%)]	Loss: 0.831664
[2022-03-30 23:08:11 | train] - Train Epoch: [78] [422400/1281167 (33%)]	Loss: 0.918636
[2022-03-30 23:08:31 | train] - Train Epoch: [78] [435200/1281167 (34%)]	Loss: 0.971112
[2022-03-30 23:08:50 | train] - Train Epoch: [78] [448000/1281167 (35%)]	Loss: 0.898976
[2022-03-30 23:09:10 | train] - Train Epoch: [78] [460800/1281167 (36%)]	Loss: 0.753093
[2022-03-30 23:09:29 | train] - Train Epoch: [78] [473600/1281167 (37%)]	Loss: 0.744549
[2022-03-30 23:09:49 | train] - Train Epoch: [78] [486400/1281167 (38%)]	Loss: 0.853783
[2022-03-30 23:10:09 | train] - Train Epoch: [78] [499200/1281167 (39%)]	Loss: 0.829021
[2022-03-30 23:10:29 | train] - Train Epoch: [78] [512000/1281167 (40%)]	Loss: 0.680563
[2022-03-30 23:10:48 | train] - Train Epoch: [78] [524800/1281167 (41%)]	Loss: 1.182352
[2022-03-30 23:11:08 | train] - Train Epoch: [78] [537600/1281167 (42%)]	Loss: 0.815777
[2022-03-30 23:11:28 | train] - Train Epoch: [78] [550400/1281167 (43%)]	Loss: 0.777681
[2022-03-30 23:11:48 | train] - Train Epoch: [78] [563200/1281167 (44%)]	Loss: 1.042703
[2022-03-30 23:12:08 | train] - Train Epoch: [78] [576000/1281167 (45%)]	Loss: 0.970841
[2022-03-30 23:12:28 | train] - Train Epoch: [78] [588800/1281167 (46%)]	Loss: 1.042203
[2022-03-30 23:12:49 | train] - Train Epoch: [78] [601600/1281167 (47%)]	Loss: 0.781876
[2022-03-30 23:13:08 | train] - Train Epoch: [78] [614400/1281167 (48%)]	Loss: 0.663884
[2022-03-30 23:13:28 | train] - Train Epoch: [78] [627200/1281167 (49%)]	Loss: 0.982454
[2022-03-30 23:13:48 | train] - Train Epoch: [78] [640000/1281167 (50%)]	Loss: 1.074404
[2022-03-30 23:14:07 | train] - Train Epoch: [78] [652800/1281167 (51%)]	Loss: 0.742506
[2022-03-30 23:14:28 | train] - Train Epoch: [78] [665600/1281167 (52%)]	Loss: 0.663757
[2022-03-30 23:14:47 | train] - Train Epoch: [78] [678400/1281167 (53%)]	Loss: 1.128169
[2022-03-30 23:15:07 | train] - Train Epoch: [78] [691200/1281167 (54%)]	Loss: 0.890556
[2022-03-30 23:15:27 | train] - Train Epoch: [78] [704000/1281167 (55%)]	Loss: 0.852609
[2022-03-30 23:15:46 | train] - Train Epoch: [78] [716800/1281167 (56%)]	Loss: 0.685487
[2022-03-30 23:16:06 | train] - Train Epoch: [78] [729600/1281167 (57%)]	Loss: 1.084140
[2022-03-30 23:16:26 | train] - Train Epoch: [78] [742400/1281167 (58%)]	Loss: 0.821567
[2022-03-30 23:16:46 | train] - Train Epoch: [78] [755200/1281167 (59%)]	Loss: 0.623034
[2022-03-30 23:17:05 | train] - Train Epoch: [78] [768000/1281167 (60%)]	Loss: 0.912364
[2022-03-30 23:17:25 | train] - Train Epoch: [78] [780800/1281167 (61%)]	Loss: 0.604617
[2022-03-30 23:17:44 | train] - Train Epoch: [78] [793600/1281167 (62%)]	Loss: 0.851258
[2022-03-30 23:18:03 | train] - Train Epoch: [78] [806400/1281167 (63%)]	Loss: 0.751492
[2022-03-30 23:18:23 | train] - Train Epoch: [78] [819200/1281167 (64%)]	Loss: 0.951596
[2022-03-30 23:18:43 | train] - Train Epoch: [78] [832000/1281167 (65%)]	Loss: 0.869557
[2022-03-30 23:19:03 | train] - Train Epoch: [78] [844800/1281167 (66%)]	Loss: 0.675549
[2022-03-30 23:19:23 | train] - Train Epoch: [78] [857600/1281167 (67%)]	Loss: 0.906457
[2022-03-30 23:19:43 | train] - Train Epoch: [78] [870400/1281167 (68%)]	Loss: 0.810553
[2022-03-30 23:20:02 | train] - Train Epoch: [78] [883200/1281167 (69%)]	Loss: 1.149917
[2022-03-30 23:20:22 | train] - Train Epoch: [78] [896000/1281167 (70%)]	Loss: 0.873448
[2022-03-30 23:20:42 | train] - Train Epoch: [78] [908800/1281167 (71%)]	Loss: 0.627929
[2022-03-30 23:21:02 | train] - Train Epoch: [78] [921600/1281167 (72%)]	Loss: 0.851468
[2022-03-30 23:21:22 | train] - Train Epoch: [78] [934400/1281167 (73%)]	Loss: 0.697350
[2022-03-30 23:21:41 | train] - Train Epoch: [78] [947200/1281167 (74%)]	Loss: 0.927350
[2022-03-30 23:22:01 | train] - Train Epoch: [78] [960000/1281167 (75%)]	Loss: 0.777257
[2022-03-30 23:22:21 | train] - Train Epoch: [78] [972800/1281167 (76%)]	Loss: 0.694613
[2022-03-30 23:22:40 | train] - Train Epoch: [78] [985600/1281167 (77%)]	Loss: 0.755542
[2022-03-30 23:22:59 | train] - Train Epoch: [78] [998400/1281167 (78%)]	Loss: 0.716558
[2022-03-30 23:23:19 | train] - Train Epoch: [78] [1011200/1281167 (79%)]	Loss: 0.794851
[2022-03-30 23:23:39 | train] - Train Epoch: [78] [1024000/1281167 (80%)]	Loss: 0.939545
[2022-03-30 23:23:59 | train] - Train Epoch: [78] [1036800/1281167 (81%)]	Loss: 0.816721
[2022-03-30 23:24:19 | train] - Train Epoch: [78] [1049600/1281167 (82%)]	Loss: 0.905499
[2022-03-30 23:24:39 | train] - Train Epoch: [78] [1062400/1281167 (83%)]	Loss: 0.992481
[2022-03-30 23:24:59 | train] - Train Epoch: [78] [1075200/1281167 (84%)]	Loss: 0.700937
[2022-03-30 23:25:19 | train] - Train Epoch: [78] [1088000/1281167 (85%)]	Loss: 0.938920
[2022-03-30 23:25:38 | train] - Train Epoch: [78] [1100800/1281167 (86%)]	Loss: 0.901925
[2022-03-30 23:25:58 | train] - Train Epoch: [78] [1113600/1281167 (87%)]	Loss: 0.853938
[2022-03-30 23:26:17 | train] - Train Epoch: [78] [1126400/1281167 (88%)]	Loss: 0.861184
[2022-03-30 23:26:37 | train] - Train Epoch: [78] [1139200/1281167 (89%)]	Loss: 0.862198
[2022-03-30 23:26:56 | train] - Train Epoch: [78] [1152000/1281167 (90%)]	Loss: 0.592228
[2022-03-30 23:27:17 | train] - Train Epoch: [78] [1164800/1281167 (91%)]	Loss: 0.829794
[2022-03-30 23:27:36 | train] - Train Epoch: [78] [1177600/1281167 (92%)]	Loss: 1.057874
[2022-03-30 23:27:55 | train] - Train Epoch: [78] [1190400/1281167 (93%)]	Loss: 0.904985
[2022-03-30 23:28:15 | train] - Train Epoch: [78] [1203200/1281167 (94%)]	Loss: 0.901615
[2022-03-30 23:28:35 | train] - Train Epoch: [78] [1216000/1281167 (95%)]	Loss: 0.972537
[2022-03-30 23:28:56 | train] - Train Epoch: [78] [1228800/1281167 (96%)]	Loss: 1.082055
[2022-03-30 23:29:16 | train] - Train Epoch: [78] [1241600/1281167 (97%)]	Loss: 0.822321
[2022-03-30 23:29:36 | train] - Train Epoch: [78] [1254400/1281167 (98%)]	Loss: 0.709895
[2022-03-30 23:29:55 | train] - Train Epoch: [78] [1267200/1281167 (99%)]	Loss: 0.839724
[2022-03-30 23:30:16 | train] - Train Epoch: [78] [1280000/1281167 (100%)]	Loss: 0.719472
[2022-03-30 23:30:18 | train] - Train Epoch: [78]	 Average Loss: 0.894261	 Total Acc : 78.1568	 Total Top5 Acc : 91.9315
[2022-03-30 23:30:18 | train] - -------78 epoch end-----------
========================================
-------78 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-30 23:31:49 | train] - 
Epoch [78] Test set: Average loss: 1.3535, Accuracy: 35008/50000 (69.9872%), Top-5 Accuracy: 88.9410%

[2022-03-30 23:31:49 | train] - save intermediate epoch [78] result


[2022-03-30 23:31:54 | train] - -------79 epoch start-----------
========================================
----- test end -------------------------


[2022-03-30 23:31:55 | train] - Train Epoch: [79] [0/1281167 (0%)]	Loss: 0.815314
[2022-03-30 23:32:15 | train] - Train Epoch: [79] [12800/1281167 (1%)]	Loss: 0.544616
[2022-03-30 23:32:35 | train] - Train Epoch: [79] [25600/1281167 (2%)]	Loss: 0.875546
[2022-03-30 23:32:55 | train] - Train Epoch: [79] [38400/1281167 (3%)]	Loss: 0.987136
[2022-03-30 23:33:16 | train] - Train Epoch: [79] [51200/1281167 (4%)]	Loss: 0.937394
[2022-03-30 23:33:36 | train] - Train Epoch: [79] [64000/1281167 (5%)]	Loss: 0.957205
[2022-03-30 23:33:57 | train] - Train Epoch: [79] [76800/1281167 (6%)]	Loss: 0.828941
[2022-03-30 23:34:17 | train] - Train Epoch: [79] [89600/1281167 (7%)]	Loss: 0.813239
[2022-03-30 23:34:37 | train] - Train Epoch: [79] [102400/1281167 (8%)]	Loss: 0.551912
[2022-03-30 23:34:56 | train] - Train Epoch: [79] [115200/1281167 (9%)]	Loss: 0.805530
[2022-03-30 23:35:15 | train] - Train Epoch: [79] [128000/1281167 (10%)]	Loss: 0.908628
[2022-03-30 23:35:35 | train] - Train Epoch: [79] [140800/1281167 (11%)]	Loss: 0.984877
[2022-03-30 23:35:55 | train] - Train Epoch: [79] [153600/1281167 (12%)]	Loss: 0.786328
[2022-03-30 23:36:14 | train] - Train Epoch: [79] [166400/1281167 (13%)]	Loss: 0.994788
[2022-03-30 23:36:34 | train] - Train Epoch: [79] [179200/1281167 (14%)]	Loss: 1.080963
[2022-03-30 23:36:53 | train] - Train Epoch: [79] [192000/1281167 (15%)]	Loss: 1.139877
[2022-03-30 23:37:12 | train] - Train Epoch: [79] [204800/1281167 (16%)]	Loss: 0.615576
[2022-03-30 23:37:32 | train] - Train Epoch: [79] [217600/1281167 (17%)]	Loss: 0.714640
[2022-03-30 23:37:52 | train] - Train Epoch: [79] [230400/1281167 (18%)]	Loss: 0.940815
[2022-03-30 23:38:11 | train] - Train Epoch: [79] [243200/1281167 (19%)]	Loss: 1.226855
[2022-03-30 23:38:31 | train] - Train Epoch: [79] [256000/1281167 (20%)]	Loss: 0.828067
[2022-03-30 23:38:51 | train] - Train Epoch: [79] [268800/1281167 (21%)]	Loss: 0.825467
[2022-03-30 23:39:11 | train] - Train Epoch: [79] [281600/1281167 (22%)]	Loss: 0.703799
[2022-03-30 23:39:30 | train] - Train Epoch: [79] [294400/1281167 (23%)]	Loss: 0.818937
[2022-03-30 23:39:50 | train] - Train Epoch: [79] [307200/1281167 (24%)]	Loss: 0.743729
[2022-03-30 23:40:10 | train] - Train Epoch: [79] [320000/1281167 (25%)]	Loss: 1.040154
[2022-03-30 23:40:31 | train] - Train Epoch: [79] [332800/1281167 (26%)]	Loss: 1.010584
[2022-03-30 23:40:50 | train] - Train Epoch: [79] [345600/1281167 (27%)]	Loss: 0.874890
[2022-03-30 23:41:10 | train] - Train Epoch: [79] [358400/1281167 (28%)]	Loss: 0.771272
[2022-03-30 23:41:30 | train] - Train Epoch: [79] [371200/1281167 (29%)]	Loss: 0.857840
[2022-03-30 23:41:50 | train] - Train Epoch: [79] [384000/1281167 (30%)]	Loss: 1.033588
[2022-03-30 23:42:10 | train] - Train Epoch: [79] [396800/1281167 (31%)]	Loss: 1.048584
[2022-03-30 23:42:29 | train] - Train Epoch: [79] [409600/1281167 (32%)]	Loss: 1.025795
[2022-03-30 23:42:49 | train] - Train Epoch: [79] [422400/1281167 (33%)]	Loss: 0.823246
[2022-03-30 23:43:09 | train] - Train Epoch: [79] [435200/1281167 (34%)]	Loss: 0.930687
[2022-03-30 23:43:29 | train] - Train Epoch: [79] [448000/1281167 (35%)]	Loss: 0.973819
[2022-03-30 23:43:48 | train] - Train Epoch: [79] [460800/1281167 (36%)]	Loss: 0.839173
[2022-03-30 23:44:08 | train] - Train Epoch: [79] [473600/1281167 (37%)]	Loss: 0.617512
[2022-03-30 23:44:27 | train] - Train Epoch: [79] [486400/1281167 (38%)]	Loss: 1.248078
[2022-03-30 23:44:47 | train] - Train Epoch: [79] [499200/1281167 (39%)]	Loss: 0.950766
[2022-03-30 23:45:07 | train] - Train Epoch: [79] [512000/1281167 (40%)]	Loss: 0.707988
[2022-03-30 23:45:27 | train] - Train Epoch: [79] [524800/1281167 (41%)]	Loss: 0.782506
[2022-03-30 23:45:47 | train] - Train Epoch: [79] [537600/1281167 (42%)]	Loss: 1.068991
[2022-03-30 23:46:07 | train] - Train Epoch: [79] [550400/1281167 (43%)]	Loss: 1.158153
[2022-03-30 23:46:27 | train] - Train Epoch: [79] [563200/1281167 (44%)]	Loss: 0.902694
[2022-03-30 23:46:47 | train] - Train Epoch: [79] [576000/1281167 (45%)]	Loss: 0.794713
[2022-03-30 23:47:07 | train] - Train Epoch: [79] [588800/1281167 (46%)]	Loss: 0.987366
[2022-03-30 23:47:27 | train] - Train Epoch: [79] [601600/1281167 (47%)]	Loss: 0.907514
[2022-03-30 23:47:47 | train] - Train Epoch: [79] [614400/1281167 (48%)]	Loss: 0.793689
[2022-03-30 23:48:06 | train] - Train Epoch: [79] [627200/1281167 (49%)]	Loss: 0.711150
[2022-03-30 23:48:26 | train] - Train Epoch: [79] [640000/1281167 (50%)]	Loss: 1.046283
[2022-03-30 23:48:45 | train] - Train Epoch: [79] [652800/1281167 (51%)]	Loss: 0.738448
[2022-03-30 23:49:04 | train] - Train Epoch: [79] [665600/1281167 (52%)]	Loss: 0.658319
[2022-03-30 23:49:24 | train] - Train Epoch: [79] [678400/1281167 (53%)]	Loss: 1.020874
[2022-03-30 23:49:44 | train] - Train Epoch: [79] [691200/1281167 (54%)]	Loss: 0.788196
[2022-03-30 23:50:03 | train] - Train Epoch: [79] [704000/1281167 (55%)]	Loss: 1.036152
[2022-03-30 23:50:23 | train] - Train Epoch: [79] [716800/1281167 (56%)]	Loss: 1.095609
[2022-03-30 23:50:42 | train] - Train Epoch: [79] [729600/1281167 (57%)]	Loss: 0.572113
[2022-03-30 23:51:01 | train] - Train Epoch: [79] [742400/1281167 (58%)]	Loss: 1.105413
[2022-03-30 23:51:21 | train] - Train Epoch: [79] [755200/1281167 (59%)]	Loss: 1.078532
[2022-03-30 23:51:40 | train] - Train Epoch: [79] [768000/1281167 (60%)]	Loss: 0.862415
[2022-03-30 23:52:00 | train] - Train Epoch: [79] [780800/1281167 (61%)]	Loss: 0.948780
[2022-03-30 23:52:20 | train] - Train Epoch: [79] [793600/1281167 (62%)]	Loss: 0.881130
[2022-03-30 23:52:39 | train] - Train Epoch: [79] [806400/1281167 (63%)]	Loss: 0.677851
[2022-03-30 23:53:00 | train] - Train Epoch: [79] [819200/1281167 (64%)]	Loss: 0.961729
[2022-03-30 23:53:19 | train] - Train Epoch: [79] [832000/1281167 (65%)]	Loss: 0.942569
[2022-03-30 23:53:40 | train] - Train Epoch: [79] [844800/1281167 (66%)]	Loss: 0.777799
[2022-03-30 23:54:00 | train] - Train Epoch: [79] [857600/1281167 (67%)]	Loss: 1.022042
[2022-03-30 23:54:20 | train] - Train Epoch: [79] [870400/1281167 (68%)]	Loss: 1.110728
[2022-03-30 23:54:40 | train] - Train Epoch: [79] [883200/1281167 (69%)]	Loss: 1.136919
[2022-03-30 23:55:00 | train] - Train Epoch: [79] [896000/1281167 (70%)]	Loss: 1.032207
[2022-03-30 23:55:20 | train] - Train Epoch: [79] [908800/1281167 (71%)]	Loss: 0.952465
[2022-03-30 23:55:40 | train] - Train Epoch: [79] [921600/1281167 (72%)]	Loss: 0.835020
[2022-03-30 23:56:00 | train] - Train Epoch: [79] [934400/1281167 (73%)]	Loss: 0.800068
[2022-03-30 23:56:20 | train] - Train Epoch: [79] [947200/1281167 (74%)]	Loss: 0.714269
[2022-03-30 23:56:40 | train] - Train Epoch: [79] [960000/1281167 (75%)]	Loss: 0.846281
[2022-03-30 23:57:00 | train] - Train Epoch: [79] [972800/1281167 (76%)]	Loss: 0.858985
[2022-03-30 23:57:20 | train] - Train Epoch: [79] [985600/1281167 (77%)]	Loss: 0.922710
[2022-03-30 23:57:39 | train] - Train Epoch: [79] [998400/1281167 (78%)]	Loss: 1.012693
[2022-03-30 23:58:00 | train] - Train Epoch: [79] [1011200/1281167 (79%)]	Loss: 0.833058
[2022-03-30 23:58:20 | train] - Train Epoch: [79] [1024000/1281167 (80%)]	Loss: 0.913828
[2022-03-30 23:58:39 | train] - Train Epoch: [79] [1036800/1281167 (81%)]	Loss: 0.815024
[2022-03-30 23:58:59 | train] - Train Epoch: [79] [1049600/1281167 (82%)]	Loss: 0.824448
[2022-03-30 23:59:19 | train] - Train Epoch: [79] [1062400/1281167 (83%)]	Loss: 0.642147
[2022-03-30 23:59:38 | train] - Train Epoch: [79] [1075200/1281167 (84%)]	Loss: 1.062801
[2022-03-30 23:59:58 | train] - Train Epoch: [79] [1088000/1281167 (85%)]	Loss: 0.836881
[2022-03-31 00:00:18 | train] - Train Epoch: [79] [1100800/1281167 (86%)]	Loss: 0.871232
[2022-03-31 00:00:38 | train] - Train Epoch: [79] [1113600/1281167 (87%)]	Loss: 0.827141
[2022-03-31 00:00:58 | train] - Train Epoch: [79] [1126400/1281167 (88%)]	Loss: 0.871207
[2022-03-31 00:01:17 | train] - Train Epoch: [79] [1139200/1281167 (89%)]	Loss: 0.774778
[2022-03-31 00:01:37 | train] - Train Epoch: [79] [1152000/1281167 (90%)]	Loss: 1.014917
[2022-03-31 00:01:57 | train] - Train Epoch: [79] [1164800/1281167 (91%)]	Loss: 1.035817
[2022-03-31 00:02:17 | train] - Train Epoch: [79] [1177600/1281167 (92%)]	Loss: 0.947374
[2022-03-31 00:02:36 | train] - Train Epoch: [79] [1190400/1281167 (93%)]	Loss: 0.836002
[2022-03-31 00:02:56 | train] - Train Epoch: [79] [1203200/1281167 (94%)]	Loss: 0.729880
[2022-03-31 00:03:15 | train] - Train Epoch: [79] [1216000/1281167 (95%)]	Loss: 1.154011
[2022-03-31 00:03:35 | train] - Train Epoch: [79] [1228800/1281167 (96%)]	Loss: 0.792560
[2022-03-31 00:03:55 | train] - Train Epoch: [79] [1241600/1281167 (97%)]	Loss: 0.939872
[2022-03-31 00:04:14 | train] - Train Epoch: [79] [1254400/1281167 (98%)]	Loss: 0.850879
[2022-03-31 00:04:34 | train] - Train Epoch: [79] [1267200/1281167 (99%)]	Loss: 1.076063
[2022-03-31 00:04:54 | train] - Train Epoch: [79] [1280000/1281167 (100%)]	Loss: 1.280085
[2022-03-31 00:04:56 | train] - Train Epoch: [79]	 Average Loss: 0.896291	 Total Acc : 78.0911	 Total Top5 Acc : 91.8847
[2022-03-31 00:04:56 | train] - -------79 epoch end-----------
========================================
-------79 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 00:06:27 | train] - 
Epoch [79] Test set: Average loss: 1.3669, Accuracy: 34906/50000 (69.7870%), Top-5 Accuracy: 88.8327%

[2022-03-31 00:06:27 | train] - save intermediate epoch [79] result


[2022-03-31 00:06:32 | train] - -------80 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 00:06:34 | train] - Train Epoch: [80] [0/1281167 (0%)]	Loss: 0.848766
[2022-03-31 00:06:54 | train] - Train Epoch: [80] [12800/1281167 (1%)]	Loss: 0.810630
[2022-03-31 00:07:14 | train] - Train Epoch: [80] [25600/1281167 (2%)]	Loss: 0.572683
[2022-03-31 00:07:34 | train] - Train Epoch: [80] [38400/1281167 (3%)]	Loss: 1.020523
[2022-03-31 00:07:54 | train] - Train Epoch: [80] [51200/1281167 (4%)]	Loss: 0.823476
[2022-03-31 00:08:14 | train] - Train Epoch: [80] [64000/1281167 (5%)]	Loss: 0.836837
[2022-03-31 00:08:33 | train] - Train Epoch: [80] [76800/1281167 (6%)]	Loss: 0.871940
[2022-03-31 00:08:53 | train] - Train Epoch: [80] [89600/1281167 (7%)]	Loss: 0.912475
[2022-03-31 00:09:12 | train] - Train Epoch: [80] [102400/1281167 (8%)]	Loss: 0.584486
[2022-03-31 00:09:33 | train] - Train Epoch: [80] [115200/1281167 (9%)]	Loss: 0.941732
[2022-03-31 00:09:53 | train] - Train Epoch: [80] [128000/1281167 (10%)]	Loss: 0.800224
[2022-03-31 00:10:12 | train] - Train Epoch: [80] [140800/1281167 (11%)]	Loss: 1.011518
[2022-03-31 00:10:31 | train] - Train Epoch: [80] [153600/1281167 (12%)]	Loss: 1.359736
[2022-03-31 00:10:51 | train] - Train Epoch: [80] [166400/1281167 (13%)]	Loss: 0.918126
[2022-03-31 00:11:11 | train] - Train Epoch: [80] [179200/1281167 (14%)]	Loss: 1.016721
[2022-03-31 00:11:31 | train] - Train Epoch: [80] [192000/1281167 (15%)]	Loss: 0.931901
[2022-03-31 00:11:50 | train] - Train Epoch: [80] [204800/1281167 (16%)]	Loss: 0.894322
[2022-03-31 00:12:11 | train] - Train Epoch: [80] [217600/1281167 (17%)]	Loss: 0.928945
[2022-03-31 00:12:30 | train] - Train Epoch: [80] [230400/1281167 (18%)]	Loss: 0.997413
[2022-03-31 00:12:50 | train] - Train Epoch: [80] [243200/1281167 (19%)]	Loss: 0.811574
[2022-03-31 00:13:10 | train] - Train Epoch: [80] [256000/1281167 (20%)]	Loss: 0.869778
[2022-03-31 00:13:30 | train] - Train Epoch: [80] [268800/1281167 (21%)]	Loss: 0.756044
[2022-03-31 00:13:49 | train] - Train Epoch: [80] [281600/1281167 (22%)]	Loss: 0.854039
[2022-03-31 00:14:10 | train] - Train Epoch: [80] [294400/1281167 (23%)]	Loss: 1.039812
[2022-03-31 00:14:29 | train] - Train Epoch: [80] [307200/1281167 (24%)]	Loss: 1.003458
[2022-03-31 00:14:49 | train] - Train Epoch: [80] [320000/1281167 (25%)]	Loss: 0.872835
[2022-03-31 00:15:09 | train] - Train Epoch: [80] [332800/1281167 (26%)]	Loss: 1.237668
[2022-03-31 00:15:28 | train] - Train Epoch: [80] [345600/1281167 (27%)]	Loss: 1.060204
[2022-03-31 00:15:48 | train] - Train Epoch: [80] [358400/1281167 (28%)]	Loss: 0.877260
[2022-03-31 00:16:07 | train] - Train Epoch: [80] [371200/1281167 (29%)]	Loss: 0.760799
[2022-03-31 00:16:27 | train] - Train Epoch: [80] [384000/1281167 (30%)]	Loss: 0.911647
[2022-03-31 00:16:46 | train] - Train Epoch: [80] [396800/1281167 (31%)]	Loss: 0.794151
[2022-03-31 00:17:06 | train] - Train Epoch: [80] [409600/1281167 (32%)]	Loss: 0.963880
[2022-03-31 00:17:26 | train] - Train Epoch: [80] [422400/1281167 (33%)]	Loss: 0.944014
[2022-03-31 00:17:46 | train] - Train Epoch: [80] [435200/1281167 (34%)]	Loss: 0.894135
[2022-03-31 00:18:06 | train] - Train Epoch: [80] [448000/1281167 (35%)]	Loss: 0.864992
[2022-03-31 00:18:25 | train] - Train Epoch: [80] [460800/1281167 (36%)]	Loss: 0.501796
[2022-03-31 00:18:45 | train] - Train Epoch: [80] [473600/1281167 (37%)]	Loss: 0.882194
[2022-03-31 00:19:05 | train] - Train Epoch: [80] [486400/1281167 (38%)]	Loss: 0.958820
[2022-03-31 00:19:25 | train] - Train Epoch: [80] [499200/1281167 (39%)]	Loss: 1.005272
[2022-03-31 00:19:45 | train] - Train Epoch: [80] [512000/1281167 (40%)]	Loss: 0.943488
[2022-03-31 00:20:04 | train] - Train Epoch: [80] [524800/1281167 (41%)]	Loss: 0.777076
[2022-03-31 00:20:24 | train] - Train Epoch: [80] [537600/1281167 (42%)]	Loss: 0.880333
[2022-03-31 00:20:43 | train] - Train Epoch: [80] [550400/1281167 (43%)]	Loss: 0.801047
[2022-03-31 00:21:03 | train] - Train Epoch: [80] [563200/1281167 (44%)]	Loss: 0.775935
[2022-03-31 00:21:23 | train] - Train Epoch: [80] [576000/1281167 (45%)]	Loss: 0.822356
[2022-03-31 00:21:43 | train] - Train Epoch: [80] [588800/1281167 (46%)]	Loss: 0.979885
[2022-03-31 00:22:03 | train] - Train Epoch: [80] [601600/1281167 (47%)]	Loss: 1.017947
[2022-03-31 00:22:22 | train] - Train Epoch: [80] [614400/1281167 (48%)]	Loss: 0.787444
[2022-03-31 00:22:42 | train] - Train Epoch: [80] [627200/1281167 (49%)]	Loss: 0.997286
[2022-03-31 00:23:02 | train] - Train Epoch: [80] [640000/1281167 (50%)]	Loss: 0.969696
[2022-03-31 00:23:21 | train] - Train Epoch: [80] [652800/1281167 (51%)]	Loss: 0.889128
[2022-03-31 00:23:41 | train] - Train Epoch: [80] [665600/1281167 (52%)]	Loss: 0.857428
[2022-03-31 00:24:01 | train] - Train Epoch: [80] [678400/1281167 (53%)]	Loss: 0.916204
[2022-03-31 00:24:21 | train] - Train Epoch: [80] [691200/1281167 (54%)]	Loss: 0.885100
[2022-03-31 00:24:40 | train] - Train Epoch: [80] [704000/1281167 (55%)]	Loss: 0.829461
[2022-03-31 00:25:00 | train] - Train Epoch: [80] [716800/1281167 (56%)]	Loss: 0.829201
[2022-03-31 00:25:20 | train] - Train Epoch: [80] [729600/1281167 (57%)]	Loss: 0.691594
[2022-03-31 00:25:39 | train] - Train Epoch: [80] [742400/1281167 (58%)]	Loss: 0.969887
[2022-03-31 00:25:59 | train] - Train Epoch: [80] [755200/1281167 (59%)]	Loss: 0.950270
[2022-03-31 00:26:19 | train] - Train Epoch: [80] [768000/1281167 (60%)]	Loss: 0.725032
[2022-03-31 00:26:38 | train] - Train Epoch: [80] [780800/1281167 (61%)]	Loss: 0.921975
[2022-03-31 00:26:58 | train] - Train Epoch: [80] [793600/1281167 (62%)]	Loss: 0.972733
[2022-03-31 00:27:17 | train] - Train Epoch: [80] [806400/1281167 (63%)]	Loss: 0.809151
[2022-03-31 00:27:37 | train] - Train Epoch: [80] [819200/1281167 (64%)]	Loss: 1.020576
[2022-03-31 00:27:56 | train] - Train Epoch: [80] [832000/1281167 (65%)]	Loss: 1.106237
[2022-03-31 00:28:16 | train] - Train Epoch: [80] [844800/1281167 (66%)]	Loss: 0.884598
[2022-03-31 00:28:36 | train] - Train Epoch: [80] [857600/1281167 (67%)]	Loss: 0.729687
[2022-03-31 00:28:56 | train] - Train Epoch: [80] [870400/1281167 (68%)]	Loss: 0.950083
[2022-03-31 00:29:16 | train] - Train Epoch: [80] [883200/1281167 (69%)]	Loss: 1.043375
[2022-03-31 00:29:35 | train] - Train Epoch: [80] [896000/1281167 (70%)]	Loss: 0.909737
[2022-03-31 00:29:54 | train] - Train Epoch: [80] [908800/1281167 (71%)]	Loss: 1.183747
[2022-03-31 00:30:14 | train] - Train Epoch: [80] [921600/1281167 (72%)]	Loss: 0.916490
[2022-03-31 00:30:34 | train] - Train Epoch: [80] [934400/1281167 (73%)]	Loss: 0.715022
[2022-03-31 00:30:53 | train] - Train Epoch: [80] [947200/1281167 (74%)]	Loss: 0.811062
[2022-03-31 00:31:13 | train] - Train Epoch: [80] [960000/1281167 (75%)]	Loss: 1.096321
[2022-03-31 00:31:32 | train] - Train Epoch: [80] [972800/1281167 (76%)]	Loss: 1.116943
[2022-03-31 00:31:52 | train] - Train Epoch: [80] [985600/1281167 (77%)]	Loss: 0.976593
[2022-03-31 00:32:12 | train] - Train Epoch: [80] [998400/1281167 (78%)]	Loss: 0.805971
[2022-03-31 00:32:31 | train] - Train Epoch: [80] [1011200/1281167 (79%)]	Loss: 1.014264
[2022-03-31 00:32:51 | train] - Train Epoch: [80] [1024000/1281167 (80%)]	Loss: 1.165363
[2022-03-31 00:33:11 | train] - Train Epoch: [80] [1036800/1281167 (81%)]	Loss: 1.093132
[2022-03-31 00:33:32 | train] - Train Epoch: [80] [1049600/1281167 (82%)]	Loss: 1.050315
[2022-03-31 00:33:52 | train] - Train Epoch: [80] [1062400/1281167 (83%)]	Loss: 0.848698
[2022-03-31 00:34:12 | train] - Train Epoch: [80] [1075200/1281167 (84%)]	Loss: 0.607751
[2022-03-31 00:34:31 | train] - Train Epoch: [80] [1088000/1281167 (85%)]	Loss: 0.843140
[2022-03-31 00:34:51 | train] - Train Epoch: [80] [1100800/1281167 (86%)]	Loss: 0.854099
[2022-03-31 00:35:11 | train] - Train Epoch: [80] [1113600/1281167 (87%)]	Loss: 1.087677
[2022-03-31 00:35:30 | train] - Train Epoch: [80] [1126400/1281167 (88%)]	Loss: 0.858166
[2022-03-31 00:35:50 | train] - Train Epoch: [80] [1139200/1281167 (89%)]	Loss: 0.761635
[2022-03-31 00:36:09 | train] - Train Epoch: [80] [1152000/1281167 (90%)]	Loss: 0.745697
[2022-03-31 00:36:28 | train] - Train Epoch: [80] [1164800/1281167 (91%)]	Loss: 0.930883
[2022-03-31 00:36:48 | train] - Train Epoch: [80] [1177600/1281167 (92%)]	Loss: 0.925378
[2022-03-31 00:37:07 | train] - Train Epoch: [80] [1190400/1281167 (93%)]	Loss: 0.886616
[2022-03-31 00:37:27 | train] - Train Epoch: [80] [1203200/1281167 (94%)]	Loss: 0.727598
[2022-03-31 00:37:46 | train] - Train Epoch: [80] [1216000/1281167 (95%)]	Loss: 1.097313
[2022-03-31 00:38:07 | train] - Train Epoch: [80] [1228800/1281167 (96%)]	Loss: 1.088642
[2022-03-31 00:38:27 | train] - Train Epoch: [80] [1241600/1281167 (97%)]	Loss: 0.937450
[2022-03-31 00:38:46 | train] - Train Epoch: [80] [1254400/1281167 (98%)]	Loss: 1.010145
[2022-03-31 00:39:06 | train] - Train Epoch: [80] [1267200/1281167 (99%)]	Loss: 1.055972
[2022-03-31 00:39:26 | train] - Train Epoch: [80] [1280000/1281167 (100%)]	Loss: 0.795739
[2022-03-31 00:39:28 | train] - Train Epoch: [80]	 Average Loss: 0.891929	 Total Acc : 78.2250	 Total Top5 Acc : 91.9564
[2022-03-31 00:39:28 | train] - -------80 epoch end-----------
========================================
-------80 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 00:40:58 | train] - 
Epoch [80] Test set: Average loss: 1.3626, Accuracy: 34998/50000 (69.9684%), Top-5 Accuracy: 88.9982%

[2022-03-31 00:40:58 | train] - save intermediate epoch [80] result


[2022-03-31 00:41:03 | train] - -------81 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 00:41:05 | train] - Train Epoch: [81] [0/1281167 (0%)]	Loss: 0.980849
[2022-03-31 00:41:25 | train] - Train Epoch: [81] [12800/1281167 (1%)]	Loss: 0.748705
[2022-03-31 00:41:44 | train] - Train Epoch: [81] [25600/1281167 (2%)]	Loss: 0.973367
[2022-03-31 00:42:04 | train] - Train Epoch: [81] [38400/1281167 (3%)]	Loss: 0.928419
[2022-03-31 00:42:23 | train] - Train Epoch: [81] [51200/1281167 (4%)]	Loss: 0.808039
[2022-03-31 00:42:43 | train] - Train Epoch: [81] [64000/1281167 (5%)]	Loss: 1.043834
[2022-03-31 00:43:02 | train] - Train Epoch: [81] [76800/1281167 (6%)]	Loss: 1.017505
[2022-03-31 00:43:21 | train] - Train Epoch: [81] [89600/1281167 (7%)]	Loss: 0.701709
[2022-03-31 00:43:41 | train] - Train Epoch: [81] [102400/1281167 (8%)]	Loss: 0.702977
[2022-03-31 00:44:00 | train] - Train Epoch: [81] [115200/1281167 (9%)]	Loss: 0.532175
[2022-03-31 00:44:21 | train] - Train Epoch: [81] [128000/1281167 (10%)]	Loss: 1.025879
[2022-03-31 00:44:41 | train] - Train Epoch: [81] [140800/1281167 (11%)]	Loss: 1.080657
[2022-03-31 00:45:01 | train] - Train Epoch: [81] [153600/1281167 (12%)]	Loss: 0.952783
[2022-03-31 00:45:21 | train] - Train Epoch: [81] [166400/1281167 (13%)]	Loss: 1.133337
[2022-03-31 00:45:40 | train] - Train Epoch: [81] [179200/1281167 (14%)]	Loss: 1.040194
[2022-03-31 00:45:59 | train] - Train Epoch: [81] [192000/1281167 (15%)]	Loss: 0.956113
[2022-03-31 00:46:20 | train] - Train Epoch: [81] [204800/1281167 (16%)]	Loss: 0.912562
[2022-03-31 00:46:39 | train] - Train Epoch: [81] [217600/1281167 (17%)]	Loss: 1.157965
[2022-03-31 00:46:59 | train] - Train Epoch: [81] [230400/1281167 (18%)]	Loss: 1.141976
[2022-03-31 00:47:19 | train] - Train Epoch: [81] [243200/1281167 (19%)]	Loss: 1.054174
[2022-03-31 00:47:38 | train] - Train Epoch: [81] [256000/1281167 (20%)]	Loss: 0.917056
[2022-03-31 00:47:58 | train] - Train Epoch: [81] [268800/1281167 (21%)]	Loss: 0.812703
[2022-03-31 00:48:17 | train] - Train Epoch: [81] [281600/1281167 (22%)]	Loss: 1.080942
[2022-03-31 00:48:37 | train] - Train Epoch: [81] [294400/1281167 (23%)]	Loss: 1.054323
[2022-03-31 00:48:57 | train] - Train Epoch: [81] [307200/1281167 (24%)]	Loss: 0.756256
[2022-03-31 00:49:17 | train] - Train Epoch: [81] [320000/1281167 (25%)]	Loss: 0.869202
[2022-03-31 00:49:36 | train] - Train Epoch: [81] [332800/1281167 (26%)]	Loss: 0.950654
[2022-03-31 00:49:56 | train] - Train Epoch: [81] [345600/1281167 (27%)]	Loss: 0.697782
[2022-03-31 00:50:16 | train] - Train Epoch: [81] [358400/1281167 (28%)]	Loss: 0.935929
[2022-03-31 00:50:34 | train] - Train Epoch: [81] [371200/1281167 (29%)]	Loss: 0.811634
[2022-03-31 00:50:54 | train] - Train Epoch: [81] [384000/1281167 (30%)]	Loss: 0.833419
[2022-03-31 00:51:13 | train] - Train Epoch: [81] [396800/1281167 (31%)]	Loss: 0.848608
[2022-03-31 00:51:33 | train] - Train Epoch: [81] [409600/1281167 (32%)]	Loss: 0.716757
[2022-03-31 00:51:53 | train] - Train Epoch: [81] [422400/1281167 (33%)]	Loss: 0.943015
[2022-03-31 00:52:12 | train] - Train Epoch: [81] [435200/1281167 (34%)]	Loss: 0.867487
[2022-03-31 00:52:32 | train] - Train Epoch: [81] [448000/1281167 (35%)]	Loss: 0.651526
[2022-03-31 00:52:51 | train] - Train Epoch: [81] [460800/1281167 (36%)]	Loss: 1.151036
[2022-03-31 00:53:11 | train] - Train Epoch: [81] [473600/1281167 (37%)]	Loss: 0.958416
[2022-03-31 00:53:30 | train] - Train Epoch: [81] [486400/1281167 (38%)]	Loss: 1.028372
[2022-03-31 00:53:50 | train] - Train Epoch: [81] [499200/1281167 (39%)]	Loss: 0.750773
[2022-03-31 00:54:09 | train] - Train Epoch: [81] [512000/1281167 (40%)]	Loss: 0.929464
[2022-03-31 00:54:28 | train] - Train Epoch: [81] [524800/1281167 (41%)]	Loss: 1.014200
[2022-03-31 00:54:48 | train] - Train Epoch: [81] [537600/1281167 (42%)]	Loss: 0.920128
[2022-03-31 00:55:08 | train] - Train Epoch: [81] [550400/1281167 (43%)]	Loss: 1.010558
[2022-03-31 00:55:28 | train] - Train Epoch: [81] [563200/1281167 (44%)]	Loss: 0.882975
[2022-03-31 00:55:47 | train] - Train Epoch: [81] [576000/1281167 (45%)]	Loss: 0.708736
[2022-03-31 00:56:07 | train] - Train Epoch: [81] [588800/1281167 (46%)]	Loss: 0.791858
[2022-03-31 00:56:26 | train] - Train Epoch: [81] [601600/1281167 (47%)]	Loss: 1.066184
[2022-03-31 00:56:45 | train] - Train Epoch: [81] [614400/1281167 (48%)]	Loss: 0.931542
[2022-03-31 00:57:04 | train] - Train Epoch: [81] [627200/1281167 (49%)]	Loss: 0.928113
[2022-03-31 00:57:23 | train] - Train Epoch: [81] [640000/1281167 (50%)]	Loss: 0.927039
[2022-03-31 00:57:43 | train] - Train Epoch: [81] [652800/1281167 (51%)]	Loss: 0.835139
[2022-03-31 00:58:03 | train] - Train Epoch: [81] [665600/1281167 (52%)]	Loss: 0.674230
[2022-03-31 00:58:22 | train] - Train Epoch: [81] [678400/1281167 (53%)]	Loss: 0.904513
[2022-03-31 00:58:42 | train] - Train Epoch: [81] [691200/1281167 (54%)]	Loss: 0.830070
[2022-03-31 00:59:02 | train] - Train Epoch: [81] [704000/1281167 (55%)]	Loss: 0.847364
[2022-03-31 00:59:21 | train] - Train Epoch: [81] [716800/1281167 (56%)]	Loss: 0.968250
[2022-03-31 00:59:42 | train] - Train Epoch: [81] [729600/1281167 (57%)]	Loss: 0.742848
[2022-03-31 01:00:01 | train] - Train Epoch: [81] [742400/1281167 (58%)]	Loss: 0.646144
[2022-03-31 01:00:22 | train] - Train Epoch: [81] [755200/1281167 (59%)]	Loss: 0.718407
[2022-03-31 01:00:41 | train] - Train Epoch: [81] [768000/1281167 (60%)]	Loss: 0.919623
[2022-03-31 01:01:01 | train] - Train Epoch: [81] [780800/1281167 (61%)]	Loss: 0.911211
[2022-03-31 01:01:20 | train] - Train Epoch: [81] [793600/1281167 (62%)]	Loss: 0.672260
[2022-03-31 01:01:39 | train] - Train Epoch: [81] [806400/1281167 (63%)]	Loss: 1.280146
[2022-03-31 01:01:59 | train] - Train Epoch: [81] [819200/1281167 (64%)]	Loss: 0.887802
[2022-03-31 01:02:19 | train] - Train Epoch: [81] [832000/1281167 (65%)]	Loss: 0.988725
[2022-03-31 01:02:38 | train] - Train Epoch: [81] [844800/1281167 (66%)]	Loss: 0.757503
[2022-03-31 01:02:58 | train] - Train Epoch: [81] [857600/1281167 (67%)]	Loss: 0.796012
[2022-03-31 01:03:18 | train] - Train Epoch: [81] [870400/1281167 (68%)]	Loss: 0.794895
[2022-03-31 01:03:38 | train] - Train Epoch: [81] [883200/1281167 (69%)]	Loss: 0.922727
[2022-03-31 01:03:58 | train] - Train Epoch: [81] [896000/1281167 (70%)]	Loss: 0.784728
[2022-03-31 01:04:17 | train] - Train Epoch: [81] [908800/1281167 (71%)]	Loss: 0.804913
[2022-03-31 01:04:37 | train] - Train Epoch: [81] [921600/1281167 (72%)]	Loss: 0.928339
[2022-03-31 01:04:57 | train] - Train Epoch: [81] [934400/1281167 (73%)]	Loss: 1.016158
[2022-03-31 01:05:16 | train] - Train Epoch: [81] [947200/1281167 (74%)]	Loss: 0.990225
[2022-03-31 01:05:35 | train] - Train Epoch: [81] [960000/1281167 (75%)]	Loss: 0.970310
[2022-03-31 01:05:55 | train] - Train Epoch: [81] [972800/1281167 (76%)]	Loss: 1.026984
[2022-03-31 01:06:15 | train] - Train Epoch: [81] [985600/1281167 (77%)]	Loss: 0.816503
[2022-03-31 01:06:35 | train] - Train Epoch: [81] [998400/1281167 (78%)]	Loss: 0.926304
[2022-03-31 01:06:55 | train] - Train Epoch: [81] [1011200/1281167 (79%)]	Loss: 0.761244
[2022-03-31 01:07:14 | train] - Train Epoch: [81] [1024000/1281167 (80%)]	Loss: 0.829960
[2022-03-31 01:07:34 | train] - Train Epoch: [81] [1036800/1281167 (81%)]	Loss: 1.105875
[2022-03-31 01:07:53 | train] - Train Epoch: [81] [1049600/1281167 (82%)]	Loss: 0.882363
[2022-03-31 01:08:14 | train] - Train Epoch: [81] [1062400/1281167 (83%)]	Loss: 0.800402
[2022-03-31 01:08:34 | train] - Train Epoch: [81] [1075200/1281167 (84%)]	Loss: 0.754306
[2022-03-31 01:08:53 | train] - Train Epoch: [81] [1088000/1281167 (85%)]	Loss: 1.019457
[2022-03-31 01:09:13 | train] - Train Epoch: [81] [1100800/1281167 (86%)]	Loss: 0.925090
[2022-03-31 01:09:33 | train] - Train Epoch: [81] [1113600/1281167 (87%)]	Loss: 1.040399
[2022-03-31 01:09:52 | train] - Train Epoch: [81] [1126400/1281167 (88%)]	Loss: 0.835862
[2022-03-31 01:10:13 | train] - Train Epoch: [81] [1139200/1281167 (89%)]	Loss: 0.810671
[2022-03-31 01:10:32 | train] - Train Epoch: [81] [1152000/1281167 (90%)]	Loss: 0.883679
[2022-03-31 01:10:51 | train] - Train Epoch: [81] [1164800/1281167 (91%)]	Loss: 0.711347
[2022-03-31 01:11:11 | train] - Train Epoch: [81] [1177600/1281167 (92%)]	Loss: 0.876428
[2022-03-31 01:11:31 | train] - Train Epoch: [81] [1190400/1281167 (93%)]	Loss: 0.819322
[2022-03-31 01:11:50 | train] - Train Epoch: [81] [1203200/1281167 (94%)]	Loss: 0.952655
[2022-03-31 01:12:11 | train] - Train Epoch: [81] [1216000/1281167 (95%)]	Loss: 0.969303
[2022-03-31 01:12:30 | train] - Train Epoch: [81] [1228800/1281167 (96%)]	Loss: 0.811242
[2022-03-31 01:12:50 | train] - Train Epoch: [81] [1241600/1281167 (97%)]	Loss: 0.789599
[2022-03-31 01:13:10 | train] - Train Epoch: [81] [1254400/1281167 (98%)]	Loss: 0.840613
[2022-03-31 01:13:29 | train] - Train Epoch: [81] [1267200/1281167 (99%)]	Loss: 0.835003
[2022-03-31 01:13:49 | train] - Train Epoch: [81] [1280000/1281167 (100%)]	Loss: 0.966124
[2022-03-31 01:13:51 | train] - Train Epoch: [81]	 Average Loss: 0.889265	 Total Acc : 78.2960	 Total Top5 Acc : 91.9735
[2022-03-31 01:13:51 | train] - -------81 epoch end-----------
========================================
-------81 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 01:15:22 | train] - 
Epoch [81] Test set: Average loss: 1.3626, Accuracy: 35058/50000 (70.0871%), Top-5 Accuracy: 88.9306%

[2022-03-31 01:15:22 | train] - save intermediate epoch [81] result


[2022-03-31 01:15:27 | train] - -------82 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 01:15:29 | train] - Train Epoch: [82] [0/1281167 (0%)]	Loss: 0.741850
[2022-03-31 01:15:48 | train] - Train Epoch: [82] [12800/1281167 (1%)]	Loss: 0.835602
[2022-03-31 01:16:08 | train] - Train Epoch: [82] [25600/1281167 (2%)]	Loss: 0.822408
[2022-03-31 01:16:27 | train] - Train Epoch: [82] [38400/1281167 (3%)]	Loss: 1.027954
[2022-03-31 01:16:46 | train] - Train Epoch: [82] [51200/1281167 (4%)]	Loss: 0.957455
[2022-03-31 01:17:06 | train] - Train Epoch: [82] [64000/1281167 (5%)]	Loss: 0.669496
[2022-03-31 01:17:25 | train] - Train Epoch: [82] [76800/1281167 (6%)]	Loss: 0.769813
[2022-03-31 01:17:44 | train] - Train Epoch: [82] [89600/1281167 (7%)]	Loss: 1.046087
[2022-03-31 01:18:04 | train] - Train Epoch: [82] [102400/1281167 (8%)]	Loss: 1.093622
[2022-03-31 01:18:23 | train] - Train Epoch: [82] [115200/1281167 (9%)]	Loss: 0.943476
[2022-03-31 01:18:43 | train] - Train Epoch: [82] [128000/1281167 (10%)]	Loss: 0.821258
[2022-03-31 01:19:03 | train] - Train Epoch: [82] [140800/1281167 (11%)]	Loss: 0.800684
[2022-03-31 01:19:23 | train] - Train Epoch: [82] [153600/1281167 (12%)]	Loss: 1.252059
[2022-03-31 01:19:42 | train] - Train Epoch: [82] [166400/1281167 (13%)]	Loss: 0.599065
[2022-03-31 01:20:01 | train] - Train Epoch: [82] [179200/1281167 (14%)]	Loss: 1.203717
[2022-03-31 01:20:21 | train] - Train Epoch: [82] [192000/1281167 (15%)]	Loss: 0.951926
[2022-03-31 01:20:41 | train] - Train Epoch: [82] [204800/1281167 (16%)]	Loss: 0.664250
[2022-03-31 01:21:01 | train] - Train Epoch: [82] [217600/1281167 (17%)]	Loss: 0.732828
[2022-03-31 01:21:21 | train] - Train Epoch: [82] [230400/1281167 (18%)]	Loss: 0.777006
[2022-03-31 01:21:40 | train] - Train Epoch: [82] [243200/1281167 (19%)]	Loss: 0.788284
[2022-03-31 01:22:00 | train] - Train Epoch: [82] [256000/1281167 (20%)]	Loss: 0.815467
[2022-03-31 01:22:20 | train] - Train Epoch: [82] [268800/1281167 (21%)]	Loss: 0.848023
[2022-03-31 01:22:39 | train] - Train Epoch: [82] [281600/1281167 (22%)]	Loss: 0.936268
[2022-03-31 01:22:59 | train] - Train Epoch: [82] [294400/1281167 (23%)]	Loss: 0.753935
[2022-03-31 01:23:18 | train] - Train Epoch: [82] [307200/1281167 (24%)]	Loss: 0.895409
[2022-03-31 01:23:37 | train] - Train Epoch: [82] [320000/1281167 (25%)]	Loss: 0.559155
[2022-03-31 01:23:57 | train] - Train Epoch: [82] [332800/1281167 (26%)]	Loss: 0.954092
[2022-03-31 01:24:17 | train] - Train Epoch: [82] [345600/1281167 (27%)]	Loss: 0.827723
[2022-03-31 01:24:37 | train] - Train Epoch: [82] [358400/1281167 (28%)]	Loss: 0.625492
[2022-03-31 01:24:56 | train] - Train Epoch: [82] [371200/1281167 (29%)]	Loss: 0.831861
[2022-03-31 01:25:16 | train] - Train Epoch: [82] [384000/1281167 (30%)]	Loss: 0.813955
[2022-03-31 01:25:35 | train] - Train Epoch: [82] [396800/1281167 (31%)]	Loss: 1.035479
[2022-03-31 01:25:54 | train] - Train Epoch: [82] [409600/1281167 (32%)]	Loss: 0.970544
[2022-03-31 01:26:14 | train] - Train Epoch: [82] [422400/1281167 (33%)]	Loss: 0.772460
[2022-03-31 01:26:34 | train] - Train Epoch: [82] [435200/1281167 (34%)]	Loss: 0.901185
[2022-03-31 01:26:54 | train] - Train Epoch: [82] [448000/1281167 (35%)]	Loss: 0.944043
[2022-03-31 01:27:13 | train] - Train Epoch: [82] [460800/1281167 (36%)]	Loss: 1.041766
[2022-03-31 01:27:33 | train] - Train Epoch: [82] [473600/1281167 (37%)]	Loss: 0.931479
[2022-03-31 01:27:52 | train] - Train Epoch: [82] [486400/1281167 (38%)]	Loss: 0.707069
[2022-03-31 01:28:11 | train] - Train Epoch: [82] [499200/1281167 (39%)]	Loss: 0.695186
[2022-03-31 01:28:31 | train] - Train Epoch: [82] [512000/1281167 (40%)]	Loss: 1.056879
[2022-03-31 01:28:50 | train] - Train Epoch: [82] [524800/1281167 (41%)]	Loss: 0.821121
[2022-03-31 01:29:10 | train] - Train Epoch: [82] [537600/1281167 (42%)]	Loss: 0.683849
[2022-03-31 01:29:30 | train] - Train Epoch: [82] [550400/1281167 (43%)]	Loss: 0.965933
[2022-03-31 01:29:50 | train] - Train Epoch: [82] [563200/1281167 (44%)]	Loss: 0.788503
[2022-03-31 01:30:09 | train] - Train Epoch: [82] [576000/1281167 (45%)]	Loss: 1.069123
[2022-03-31 01:30:29 | train] - Train Epoch: [82] [588800/1281167 (46%)]	Loss: 0.986624
[2022-03-31 01:30:49 | train] - Train Epoch: [82] [601600/1281167 (47%)]	Loss: 0.976694
[2022-03-31 01:31:09 | train] - Train Epoch: [82] [614400/1281167 (48%)]	Loss: 1.064973
[2022-03-31 01:31:28 | train] - Train Epoch: [82] [627200/1281167 (49%)]	Loss: 0.590471
[2022-03-31 01:31:48 | train] - Train Epoch: [82] [640000/1281167 (50%)]	Loss: 0.943840
[2022-03-31 01:32:09 | train] - Train Epoch: [82] [652800/1281167 (51%)]	Loss: 0.918908
[2022-03-31 01:32:28 | train] - Train Epoch: [82] [665600/1281167 (52%)]	Loss: 0.737436
[2022-03-31 01:32:48 | train] - Train Epoch: [82] [678400/1281167 (53%)]	Loss: 1.157798
[2022-03-31 01:33:08 | train] - Train Epoch: [82] [691200/1281167 (54%)]	Loss: 0.967681
[2022-03-31 01:33:28 | train] - Train Epoch: [82] [704000/1281167 (55%)]	Loss: 1.034845
[2022-03-31 01:33:48 | train] - Train Epoch: [82] [716800/1281167 (56%)]	Loss: 0.927008
[2022-03-31 01:34:07 | train] - Train Epoch: [82] [729600/1281167 (57%)]	Loss: 0.635821
[2022-03-31 01:34:27 | train] - Train Epoch: [82] [742400/1281167 (58%)]	Loss: 0.876592
[2022-03-31 01:34:47 | train] - Train Epoch: [82] [755200/1281167 (59%)]	Loss: 1.091797
[2022-03-31 01:35:07 | train] - Train Epoch: [82] [768000/1281167 (60%)]	Loss: 0.817111
[2022-03-31 01:35:27 | train] - Train Epoch: [82] [780800/1281167 (61%)]	Loss: 0.858174
[2022-03-31 01:35:46 | train] - Train Epoch: [82] [793600/1281167 (62%)]	Loss: 0.924059
[2022-03-31 01:36:06 | train] - Train Epoch: [82] [806400/1281167 (63%)]	Loss: 0.986550
[2022-03-31 01:36:25 | train] - Train Epoch: [82] [819200/1281167 (64%)]	Loss: 0.636221
[2022-03-31 01:36:45 | train] - Train Epoch: [82] [832000/1281167 (65%)]	Loss: 0.883260
[2022-03-31 01:37:04 | train] - Train Epoch: [82] [844800/1281167 (66%)]	Loss: 0.852167
[2022-03-31 01:37:24 | train] - Train Epoch: [82] [857600/1281167 (67%)]	Loss: 0.836082
[2022-03-31 01:37:44 | train] - Train Epoch: [82] [870400/1281167 (68%)]	Loss: 0.802862
[2022-03-31 01:38:04 | train] - Train Epoch: [82] [883200/1281167 (69%)]	Loss: 0.818038
[2022-03-31 01:38:22 | train] - Train Epoch: [82] [896000/1281167 (70%)]	Loss: 0.708158
[2022-03-31 01:38:42 | train] - Train Epoch: [82] [908800/1281167 (71%)]	Loss: 0.892946
[2022-03-31 01:39:01 | train] - Train Epoch: [82] [921600/1281167 (72%)]	Loss: 0.850077
[2022-03-31 01:39:22 | train] - Train Epoch: [82] [934400/1281167 (73%)]	Loss: 0.869547
[2022-03-31 01:39:42 | train] - Train Epoch: [82] [947200/1281167 (74%)]	Loss: 0.707441
[2022-03-31 01:40:01 | train] - Train Epoch: [82] [960000/1281167 (75%)]	Loss: 0.855419
[2022-03-31 01:40:21 | train] - Train Epoch: [82] [972800/1281167 (76%)]	Loss: 0.707449
[2022-03-31 01:40:40 | train] - Train Epoch: [82] [985600/1281167 (77%)]	Loss: 0.855601
[2022-03-31 01:41:00 | train] - Train Epoch: [82] [998400/1281167 (78%)]	Loss: 1.006614
[2022-03-31 01:41:20 | train] - Train Epoch: [82] [1011200/1281167 (79%)]	Loss: 0.781738
[2022-03-31 01:41:40 | train] - Train Epoch: [82] [1024000/1281167 (80%)]	Loss: 0.899162
[2022-03-31 01:41:59 | train] - Train Epoch: [82] [1036800/1281167 (81%)]	Loss: 0.713982
[2022-03-31 01:42:19 | train] - Train Epoch: [82] [1049600/1281167 (82%)]	Loss: 0.817671
[2022-03-31 01:42:38 | train] - Train Epoch: [82] [1062400/1281167 (83%)]	Loss: 0.556444
[2022-03-31 01:42:58 | train] - Train Epoch: [82] [1075200/1281167 (84%)]	Loss: 0.668627
[2022-03-31 01:43:17 | train] - Train Epoch: [82] [1088000/1281167 (85%)]	Loss: 0.948000
[2022-03-31 01:43:36 | train] - Train Epoch: [82] [1100800/1281167 (86%)]	Loss: 0.813476
[2022-03-31 01:43:57 | train] - Train Epoch: [82] [1113600/1281167 (87%)]	Loss: 0.837519
[2022-03-31 01:44:16 | train] - Train Epoch: [82] [1126400/1281167 (88%)]	Loss: 0.678818
[2022-03-31 01:44:36 | train] - Train Epoch: [82] [1139200/1281167 (89%)]	Loss: 0.928051
[2022-03-31 01:44:55 | train] - Train Epoch: [82] [1152000/1281167 (90%)]	Loss: 0.920309
[2022-03-31 01:45:15 | train] - Train Epoch: [82] [1164800/1281167 (91%)]	Loss: 0.859001
[2022-03-31 01:45:34 | train] - Train Epoch: [82] [1177600/1281167 (92%)]	Loss: 1.125004
[2022-03-31 01:45:54 | train] - Train Epoch: [82] [1190400/1281167 (93%)]	Loss: 0.874239
[2022-03-31 01:46:13 | train] - Train Epoch: [82] [1203200/1281167 (94%)]	Loss: 1.045642
[2022-03-31 01:46:33 | train] - Train Epoch: [82] [1216000/1281167 (95%)]	Loss: 0.865541
[2022-03-31 01:46:53 | train] - Train Epoch: [82] [1228800/1281167 (96%)]	Loss: 1.258045
[2022-03-31 01:47:12 | train] - Train Epoch: [82] [1241600/1281167 (97%)]	Loss: 0.831658
[2022-03-31 01:47:32 | train] - Train Epoch: [82] [1254400/1281167 (98%)]	Loss: 1.048222
[2022-03-31 01:47:51 | train] - Train Epoch: [82] [1267200/1281167 (99%)]	Loss: 0.824154
[2022-03-31 01:48:11 | train] - Train Epoch: [82] [1280000/1281167 (100%)]	Loss: 0.784264
[2022-03-31 01:48:13 | train] - Train Epoch: [82]	 Average Loss: 0.884379	 Total Acc : 78.3879	 Total Top5 Acc : 92.0428
[2022-03-31 01:48:13 | train] - -------82 epoch end-----------
========================================
-------82 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 01:49:43 | train] - 
Epoch [82] Test set: Average loss: 1.3613, Accuracy: 34951/50000 (69.8733%), Top-5 Accuracy: 89.0129%

[2022-03-31 01:49:43 | train] - save intermediate epoch [82] result


[2022-03-31 01:49:48 | train] - -------83 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 01:49:50 | train] - Train Epoch: [83] [0/1281167 (0%)]	Loss: 1.042656
[2022-03-31 01:50:11 | train] - Train Epoch: [83] [12800/1281167 (1%)]	Loss: 0.898782
[2022-03-31 01:50:31 | train] - Train Epoch: [83] [25600/1281167 (2%)]	Loss: 0.937604
[2022-03-31 01:50:52 | train] - Train Epoch: [83] [38400/1281167 (3%)]	Loss: 0.945223
[2022-03-31 01:51:13 | train] - Train Epoch: [83] [51200/1281167 (4%)]	Loss: 0.677008
[2022-03-31 01:51:34 | train] - Train Epoch: [83] [64000/1281167 (5%)]	Loss: 1.037309
[2022-03-31 01:51:55 | train] - Train Epoch: [83] [76800/1281167 (6%)]	Loss: 0.729398
[2022-03-31 01:52:16 | train] - Train Epoch: [83] [89600/1281167 (7%)]	Loss: 0.734169
[2022-03-31 01:52:37 | train] - Train Epoch: [83] [102400/1281167 (8%)]	Loss: 0.747712
[2022-03-31 01:52:58 | train] - Train Epoch: [83] [115200/1281167 (9%)]	Loss: 0.839750
[2022-03-31 01:53:16 | train] - Train Epoch: [83] [128000/1281167 (10%)]	Loss: 0.789574
[2022-03-31 01:53:36 | train] - Train Epoch: [83] [140800/1281167 (11%)]	Loss: 0.942852
[2022-03-31 01:53:56 | train] - Train Epoch: [83] [153600/1281167 (12%)]	Loss: 0.953787
[2022-03-31 01:54:16 | train] - Train Epoch: [83] [166400/1281167 (13%)]	Loss: 0.798149
[2022-03-31 01:54:36 | train] - Train Epoch: [83] [179200/1281167 (14%)]	Loss: 0.879935
[2022-03-31 01:54:57 | train] - Train Epoch: [83] [192000/1281167 (15%)]	Loss: 0.773916
[2022-03-31 01:55:18 | train] - Train Epoch: [83] [204800/1281167 (16%)]	Loss: 1.018098
[2022-03-31 01:55:40 | train] - Train Epoch: [83] [217600/1281167 (17%)]	Loss: 0.915616
[2022-03-31 01:56:02 | train] - Train Epoch: [83] [230400/1281167 (18%)]	Loss: 0.734838
[2022-03-31 01:56:23 | train] - Train Epoch: [83] [243200/1281167 (19%)]	Loss: 0.925810
[2022-03-31 01:56:44 | train] - Train Epoch: [83] [256000/1281167 (20%)]	Loss: 0.922397
[2022-03-31 01:57:05 | train] - Train Epoch: [83] [268800/1281167 (21%)]	Loss: 0.791035
[2022-03-31 01:57:24 | train] - Train Epoch: [83] [281600/1281167 (22%)]	Loss: 0.812472
[2022-03-31 01:57:43 | train] - Train Epoch: [83] [294400/1281167 (23%)]	Loss: 1.136888
[2022-03-31 01:58:04 | train] - Train Epoch: [83] [307200/1281167 (24%)]	Loss: 1.104663
[2022-03-31 01:58:23 | train] - Train Epoch: [83] [320000/1281167 (25%)]	Loss: 0.800885
[2022-03-31 01:58:43 | train] - Train Epoch: [83] [332800/1281167 (26%)]	Loss: 0.906650
[2022-03-31 01:59:04 | train] - Train Epoch: [83] [345600/1281167 (27%)]	Loss: 0.900559
[2022-03-31 01:59:24 | train] - Train Epoch: [83] [358400/1281167 (28%)]	Loss: 1.189922
[2022-03-31 01:59:43 | train] - Train Epoch: [83] [371200/1281167 (29%)]	Loss: 1.046343
[2022-03-31 02:00:03 | train] - Train Epoch: [83] [384000/1281167 (30%)]	Loss: 0.614751
[2022-03-31 02:00:23 | train] - Train Epoch: [83] [396800/1281167 (31%)]	Loss: 0.967772
[2022-03-31 02:00:44 | train] - Train Epoch: [83] [409600/1281167 (32%)]	Loss: 0.694509
[2022-03-31 02:01:03 | train] - Train Epoch: [83] [422400/1281167 (33%)]	Loss: 0.880045
[2022-03-31 02:01:24 | train] - Train Epoch: [83] [435200/1281167 (34%)]	Loss: 1.079025
[2022-03-31 02:01:43 | train] - Train Epoch: [83] [448000/1281167 (35%)]	Loss: 0.705554
[2022-03-31 02:02:03 | train] - Train Epoch: [83] [460800/1281167 (36%)]	Loss: 0.701102
[2022-03-31 02:02:23 | train] - Train Epoch: [83] [473600/1281167 (37%)]	Loss: 0.959418
[2022-03-31 02:02:43 | train] - Train Epoch: [83] [486400/1281167 (38%)]	Loss: 0.723145
[2022-03-31 02:03:03 | train] - Train Epoch: [83] [499200/1281167 (39%)]	Loss: 0.744125
[2022-03-31 02:03:23 | train] - Train Epoch: [83] [512000/1281167 (40%)]	Loss: 1.050144
[2022-03-31 02:03:44 | train] - Train Epoch: [83] [524800/1281167 (41%)]	Loss: 0.908452
[2022-03-31 02:04:03 | train] - Train Epoch: [83] [537600/1281167 (42%)]	Loss: 0.869497
[2022-03-31 02:04:23 | train] - Train Epoch: [83] [550400/1281167 (43%)]	Loss: 0.919590
[2022-03-31 02:04:41 | train] - Train Epoch: [83] [563200/1281167 (44%)]	Loss: 0.856861
[2022-03-31 02:05:01 | train] - Train Epoch: [83] [576000/1281167 (45%)]	Loss: 1.185684
[2022-03-31 02:05:21 | train] - Train Epoch: [83] [588800/1281167 (46%)]	Loss: 0.753470
[2022-03-31 02:05:40 | train] - Train Epoch: [83] [601600/1281167 (47%)]	Loss: 1.019246
[2022-03-31 02:06:00 | train] - Train Epoch: [83] [614400/1281167 (48%)]	Loss: 1.117406
[2022-03-31 02:06:19 | train] - Train Epoch: [83] [627200/1281167 (49%)]	Loss: 0.903264
[2022-03-31 02:06:38 | train] - Train Epoch: [83] [640000/1281167 (50%)]	Loss: 0.694443
[2022-03-31 02:06:59 | train] - Train Epoch: [83] [652800/1281167 (51%)]	Loss: 0.957934
[2022-03-31 02:07:18 | train] - Train Epoch: [83] [665600/1281167 (52%)]	Loss: 0.780265
[2022-03-31 02:07:38 | train] - Train Epoch: [83] [678400/1281167 (53%)]	Loss: 0.865232
[2022-03-31 02:07:58 | train] - Train Epoch: [83] [691200/1281167 (54%)]	Loss: 0.809042
[2022-03-31 02:08:17 | train] - Train Epoch: [83] [704000/1281167 (55%)]	Loss: 0.947570
[2022-03-31 02:08:37 | train] - Train Epoch: [83] [716800/1281167 (56%)]	Loss: 0.962535
[2022-03-31 02:08:57 | train] - Train Epoch: [83] [729600/1281167 (57%)]	Loss: 1.215580
[2022-03-31 02:09:17 | train] - Train Epoch: [83] [742400/1281167 (58%)]	Loss: 1.195977
[2022-03-31 02:09:37 | train] - Train Epoch: [83] [755200/1281167 (59%)]	Loss: 0.875436
[2022-03-31 02:09:57 | train] - Train Epoch: [83] [768000/1281167 (60%)]	Loss: 1.029225
[2022-03-31 02:10:17 | train] - Train Epoch: [83] [780800/1281167 (61%)]	Loss: 1.201564
[2022-03-31 02:10:37 | train] - Train Epoch: [83] [793600/1281167 (62%)]	Loss: 0.777788
[2022-03-31 02:10:57 | train] - Train Epoch: [83] [806400/1281167 (63%)]	Loss: 0.669000
[2022-03-31 02:11:17 | train] - Train Epoch: [83] [819200/1281167 (64%)]	Loss: 0.883571
[2022-03-31 02:11:37 | train] - Train Epoch: [83] [832000/1281167 (65%)]	Loss: 1.101027
[2022-03-31 02:11:56 | train] - Train Epoch: [83] [844800/1281167 (66%)]	Loss: 0.874883
[2022-03-31 02:12:16 | train] - Train Epoch: [83] [857600/1281167 (67%)]	Loss: 0.783685
[2022-03-31 02:12:36 | train] - Train Epoch: [83] [870400/1281167 (68%)]	Loss: 0.667167
[2022-03-31 02:12:56 | train] - Train Epoch: [83] [883200/1281167 (69%)]	Loss: 0.741417
[2022-03-31 02:13:16 | train] - Train Epoch: [83] [896000/1281167 (70%)]	Loss: 0.899571
[2022-03-31 02:13:35 | train] - Train Epoch: [83] [908800/1281167 (71%)]	Loss: 0.754771
[2022-03-31 02:13:54 | train] - Train Epoch: [83] [921600/1281167 (72%)]	Loss: 0.905394
[2022-03-31 02:14:13 | train] - Train Epoch: [83] [934400/1281167 (73%)]	Loss: 0.919874
[2022-03-31 02:14:33 | train] - Train Epoch: [83] [947200/1281167 (74%)]	Loss: 0.961884
[2022-03-31 02:14:53 | train] - Train Epoch: [83] [960000/1281167 (75%)]	Loss: 0.669614
[2022-03-31 02:15:12 | train] - Train Epoch: [83] [972800/1281167 (76%)]	Loss: 0.766796
[2022-03-31 02:15:32 | train] - Train Epoch: [83] [985600/1281167 (77%)]	Loss: 0.687001
[2022-03-31 02:15:52 | train] - Train Epoch: [83] [998400/1281167 (78%)]	Loss: 0.833775
[2022-03-31 02:16:12 | train] - Train Epoch: [83] [1011200/1281167 (79%)]	Loss: 0.792444
[2022-03-31 02:16:33 | train] - Train Epoch: [83] [1024000/1281167 (80%)]	Loss: 0.705171
[2022-03-31 02:16:52 | train] - Train Epoch: [83] [1036800/1281167 (81%)]	Loss: 0.732738
[2022-03-31 02:17:12 | train] - Train Epoch: [83] [1049600/1281167 (82%)]	Loss: 0.842707
[2022-03-31 02:17:32 | train] - Train Epoch: [83] [1062400/1281167 (83%)]	Loss: 0.661414
[2022-03-31 02:17:51 | train] - Train Epoch: [83] [1075200/1281167 (84%)]	Loss: 0.917124
[2022-03-31 02:18:10 | train] - Train Epoch: [83] [1088000/1281167 (85%)]	Loss: 0.727643
[2022-03-31 02:18:31 | train] - Train Epoch: [83] [1100800/1281167 (86%)]	Loss: 0.757636
[2022-03-31 02:18:51 | train] - Train Epoch: [83] [1113600/1281167 (87%)]	Loss: 0.912819
[2022-03-31 02:19:11 | train] - Train Epoch: [83] [1126400/1281167 (88%)]	Loss: 1.192350
[2022-03-31 02:19:30 | train] - Train Epoch: [83] [1139200/1281167 (89%)]	Loss: 0.820057
[2022-03-31 02:19:50 | train] - Train Epoch: [83] [1152000/1281167 (90%)]	Loss: 0.940916
[2022-03-31 02:20:10 | train] - Train Epoch: [83] [1164800/1281167 (91%)]	Loss: 1.017750
[2022-03-31 02:20:30 | train] - Train Epoch: [83] [1177600/1281167 (92%)]	Loss: 0.735838
[2022-03-31 02:20:50 | train] - Train Epoch: [83] [1190400/1281167 (93%)]	Loss: 0.832058
[2022-03-31 02:21:11 | train] - Train Epoch: [83] [1203200/1281167 (94%)]	Loss: 0.780767
[2022-03-31 02:21:30 | train] - Train Epoch: [83] [1216000/1281167 (95%)]	Loss: 0.720410
[2022-03-31 02:21:50 | train] - Train Epoch: [83] [1228800/1281167 (96%)]	Loss: 0.834315
[2022-03-31 02:22:10 | train] - Train Epoch: [83] [1241600/1281167 (97%)]	Loss: 0.834873
[2022-03-31 02:22:30 | train] - Train Epoch: [83] [1254400/1281167 (98%)]	Loss: 0.906135
[2022-03-31 02:22:49 | train] - Train Epoch: [83] [1267200/1281167 (99%)]	Loss: 0.815239
[2022-03-31 02:23:09 | train] - Train Epoch: [83] [1280000/1281167 (100%)]	Loss: 0.950017
[2022-03-31 02:23:10 | train] - Train Epoch: [83]	 Average Loss: 0.880186	 Total Acc : 78.5102	 Total Top5 Acc : 92.0620
[2022-03-31 02:23:10 | train] - -------83 epoch end-----------
========================================
-------83 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 02:24:42 | train] - 
Epoch [83] Test set: Average loss: 1.3616, Accuracy: 34962/50000 (69.9013%), Top-5 Accuracy: 88.9402%

[2022-03-31 02:24:42 | train] - save intermediate epoch [83] result


[2022-03-31 02:24:47 | train] - -------84 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 02:24:49 | train] - Train Epoch: [84] [0/1281167 (0%)]	Loss: 0.871994
[2022-03-31 02:25:09 | train] - Train Epoch: [84] [12800/1281167 (1%)]	Loss: 0.904894
[2022-03-31 02:25:30 | train] - Train Epoch: [84] [25600/1281167 (2%)]	Loss: 0.813729
[2022-03-31 02:25:52 | train] - Train Epoch: [84] [38400/1281167 (3%)]	Loss: 0.918306
[2022-03-31 02:26:12 | train] - Train Epoch: [84] [51200/1281167 (4%)]	Loss: 1.105960
[2022-03-31 02:26:32 | train] - Train Epoch: [84] [64000/1281167 (5%)]	Loss: 0.958426
[2022-03-31 02:26:52 | train] - Train Epoch: [84] [76800/1281167 (6%)]	Loss: 0.762798
[2022-03-31 02:27:13 | train] - Train Epoch: [84] [89600/1281167 (7%)]	Loss: 0.871369
[2022-03-31 02:27:33 | train] - Train Epoch: [84] [102400/1281167 (8%)]	Loss: 0.936046
[2022-03-31 02:27:54 | train] - Train Epoch: [84] [115200/1281167 (9%)]	Loss: 0.918194
[2022-03-31 02:28:14 | train] - Train Epoch: [84] [128000/1281167 (10%)]	Loss: 0.795275
[2022-03-31 02:28:34 | train] - Train Epoch: [84] [140800/1281167 (11%)]	Loss: 0.833729
[2022-03-31 02:28:52 | train] - Train Epoch: [84] [153600/1281167 (12%)]	Loss: 0.948080
[2022-03-31 02:29:13 | train] - Train Epoch: [84] [166400/1281167 (13%)]	Loss: 0.570688
[2022-03-31 02:29:34 | train] - Train Epoch: [84] [179200/1281167 (14%)]	Loss: 1.066086
[2022-03-31 02:29:55 | train] - Train Epoch: [84] [192000/1281167 (15%)]	Loss: 0.873605
[2022-03-31 02:30:15 | train] - Train Epoch: [84] [204800/1281167 (16%)]	Loss: 0.917462
[2022-03-31 02:30:35 | train] - Train Epoch: [84] [217600/1281167 (17%)]	Loss: 0.883543
[2022-03-31 02:30:55 | train] - Train Epoch: [84] [230400/1281167 (18%)]	Loss: 0.854891
[2022-03-31 02:31:14 | train] - Train Epoch: [84] [243200/1281167 (19%)]	Loss: 0.952644
[2022-03-31 02:31:34 | train] - Train Epoch: [84] [256000/1281167 (20%)]	Loss: 0.888337
[2022-03-31 02:31:54 | train] - Train Epoch: [84] [268800/1281167 (21%)]	Loss: 1.168265
[2022-03-31 02:32:13 | train] - Train Epoch: [84] [281600/1281167 (22%)]	Loss: 0.974648
[2022-03-31 02:32:32 | train] - Train Epoch: [84] [294400/1281167 (23%)]	Loss: 1.070981
[2022-03-31 02:32:51 | train] - Train Epoch: [84] [307200/1281167 (24%)]	Loss: 1.183933
[2022-03-31 02:33:11 | train] - Train Epoch: [84] [320000/1281167 (25%)]	Loss: 1.038224
[2022-03-31 02:33:30 | train] - Train Epoch: [84] [332800/1281167 (26%)]	Loss: 0.800091
[2022-03-31 02:33:50 | train] - Train Epoch: [84] [345600/1281167 (27%)]	Loss: 0.718206
[2022-03-31 02:34:09 | train] - Train Epoch: [84] [358400/1281167 (28%)]	Loss: 0.781924
[2022-03-31 02:34:29 | train] - Train Epoch: [84] [371200/1281167 (29%)]	Loss: 0.915240
[2022-03-31 02:34:49 | train] - Train Epoch: [84] [384000/1281167 (30%)]	Loss: 0.756920
[2022-03-31 02:35:08 | train] - Train Epoch: [84] [396800/1281167 (31%)]	Loss: 0.828454
[2022-03-31 02:35:27 | train] - Train Epoch: [84] [409600/1281167 (32%)]	Loss: 0.719168
[2022-03-31 02:35:46 | train] - Train Epoch: [84] [422400/1281167 (33%)]	Loss: 0.727608
[2022-03-31 02:36:06 | train] - Train Epoch: [84] [435200/1281167 (34%)]	Loss: 1.014011
[2022-03-31 02:36:25 | train] - Train Epoch: [84] [448000/1281167 (35%)]	Loss: 0.747245
[2022-03-31 02:36:45 | train] - Train Epoch: [84] [460800/1281167 (36%)]	Loss: 0.949674
[2022-03-31 02:37:05 | train] - Train Epoch: [84] [473600/1281167 (37%)]	Loss: 0.999586
[2022-03-31 02:37:26 | train] - Train Epoch: [84] [486400/1281167 (38%)]	Loss: 0.927859
[2022-03-31 02:37:46 | train] - Train Epoch: [84] [499200/1281167 (39%)]	Loss: 0.853571
[2022-03-31 02:38:05 | train] - Train Epoch: [84] [512000/1281167 (40%)]	Loss: 1.030682
[2022-03-31 02:38:25 | train] - Train Epoch: [84] [524800/1281167 (41%)]	Loss: 0.853689
[2022-03-31 02:38:45 | train] - Train Epoch: [84] [537600/1281167 (42%)]	Loss: 0.826222
[2022-03-31 02:39:05 | train] - Train Epoch: [84] [550400/1281167 (43%)]	Loss: 0.682360
[2022-03-31 02:39:25 | train] - Train Epoch: [84] [563200/1281167 (44%)]	Loss: 0.808709
[2022-03-31 02:39:44 | train] - Train Epoch: [84] [576000/1281167 (45%)]	Loss: 0.758449
[2022-03-31 02:40:03 | train] - Train Epoch: [84] [588800/1281167 (46%)]	Loss: 0.864588
[2022-03-31 02:40:23 | train] - Train Epoch: [84] [601600/1281167 (47%)]	Loss: 0.884873
[2022-03-31 02:40:42 | train] - Train Epoch: [84] [614400/1281167 (48%)]	Loss: 1.098119
[2022-03-31 02:41:01 | train] - Train Epoch: [84] [627200/1281167 (49%)]	Loss: 0.900720
[2022-03-31 02:41:21 | train] - Train Epoch: [84] [640000/1281167 (50%)]	Loss: 0.915268
[2022-03-31 02:41:41 | train] - Train Epoch: [84] [652800/1281167 (51%)]	Loss: 1.017760
[2022-03-31 02:42:01 | train] - Train Epoch: [84] [665600/1281167 (52%)]	Loss: 0.854166
[2022-03-31 02:42:21 | train] - Train Epoch: [84] [678400/1281167 (53%)]	Loss: 0.886937
[2022-03-31 02:42:40 | train] - Train Epoch: [84] [691200/1281167 (54%)]	Loss: 0.820201
[2022-03-31 02:42:59 | train] - Train Epoch: [84] [704000/1281167 (55%)]	Loss: 1.026275
[2022-03-31 02:43:19 | train] - Train Epoch: [84] [716800/1281167 (56%)]	Loss: 0.852646
[2022-03-31 02:43:39 | train] - Train Epoch: [84] [729600/1281167 (57%)]	Loss: 1.093295
[2022-03-31 02:43:58 | train] - Train Epoch: [84] [742400/1281167 (58%)]	Loss: 0.780320
[2022-03-31 02:44:18 | train] - Train Epoch: [84] [755200/1281167 (59%)]	Loss: 0.765496
[2022-03-31 02:44:37 | train] - Train Epoch: [84] [768000/1281167 (60%)]	Loss: 0.633314
[2022-03-31 02:44:56 | train] - Train Epoch: [84] [780800/1281167 (61%)]	Loss: 0.806662
[2022-03-31 02:45:16 | train] - Train Epoch: [84] [793600/1281167 (62%)]	Loss: 1.107693
[2022-03-31 02:45:35 | train] - Train Epoch: [84] [806400/1281167 (63%)]	Loss: 0.974677
[2022-03-31 02:45:55 | train] - Train Epoch: [84] [819200/1281167 (64%)]	Loss: 1.035526
[2022-03-31 02:46:15 | train] - Train Epoch: [84] [832000/1281167 (65%)]	Loss: 0.949096
[2022-03-31 02:46:34 | train] - Train Epoch: [84] [844800/1281167 (66%)]	Loss: 0.740889
[2022-03-31 02:46:54 | train] - Train Epoch: [84] [857600/1281167 (67%)]	Loss: 0.741264
[2022-03-31 02:47:15 | train] - Train Epoch: [84] [870400/1281167 (68%)]	Loss: 1.164202
[2022-03-31 02:47:35 | train] - Train Epoch: [84] [883200/1281167 (69%)]	Loss: 0.904547
[2022-03-31 02:47:54 | train] - Train Epoch: [84] [896000/1281167 (70%)]	Loss: 1.055849
[2022-03-31 02:48:14 | train] - Train Epoch: [84] [908800/1281167 (71%)]	Loss: 0.930900
[2022-03-31 02:48:33 | train] - Train Epoch: [84] [921600/1281167 (72%)]	Loss: 0.947286
[2022-03-31 02:48:53 | train] - Train Epoch: [84] [934400/1281167 (73%)]	Loss: 0.731863
[2022-03-31 02:49:12 | train] - Train Epoch: [84] [947200/1281167 (74%)]	Loss: 1.043747
[2022-03-31 02:49:32 | train] - Train Epoch: [84] [960000/1281167 (75%)]	Loss: 0.701176
[2022-03-31 02:49:51 | train] - Train Epoch: [84] [972800/1281167 (76%)]	Loss: 0.749141
[2022-03-31 02:50:11 | train] - Train Epoch: [84] [985600/1281167 (77%)]	Loss: 0.986480
[2022-03-31 02:50:31 | train] - Train Epoch: [84] [998400/1281167 (78%)]	Loss: 0.794794
[2022-03-31 02:50:51 | train] - Train Epoch: [84] [1011200/1281167 (79%)]	Loss: 0.763265
[2022-03-31 02:51:12 | train] - Train Epoch: [84] [1024000/1281167 (80%)]	Loss: 1.018734
[2022-03-31 02:51:31 | train] - Train Epoch: [84] [1036800/1281167 (81%)]	Loss: 0.913262
[2022-03-31 02:51:51 | train] - Train Epoch: [84] [1049600/1281167 (82%)]	Loss: 1.079002
[2022-03-31 02:52:11 | train] - Train Epoch: [84] [1062400/1281167 (83%)]	Loss: 0.654743
[2022-03-31 02:52:31 | train] - Train Epoch: [84] [1075200/1281167 (84%)]	Loss: 0.751322
[2022-03-31 02:52:51 | train] - Train Epoch: [84] [1088000/1281167 (85%)]	Loss: 0.832435
[2022-03-31 02:53:11 | train] - Train Epoch: [84] [1100800/1281167 (86%)]	Loss: 0.682964
[2022-03-31 02:53:31 | train] - Train Epoch: [84] [1113600/1281167 (87%)]	Loss: 0.782894
[2022-03-31 02:53:50 | train] - Train Epoch: [84] [1126400/1281167 (88%)]	Loss: 0.741252
[2022-03-31 02:54:10 | train] - Train Epoch: [84] [1139200/1281167 (89%)]	Loss: 0.870003
[2022-03-31 02:54:30 | train] - Train Epoch: [84] [1152000/1281167 (90%)]	Loss: 0.962708
[2022-03-31 02:54:50 | train] - Train Epoch: [84] [1164800/1281167 (91%)]	Loss: 0.816453
[2022-03-31 02:55:10 | train] - Train Epoch: [84] [1177600/1281167 (92%)]	Loss: 0.876323
[2022-03-31 02:55:29 | train] - Train Epoch: [84] [1190400/1281167 (93%)]	Loss: 0.790599
[2022-03-31 02:55:48 | train] - Train Epoch: [84] [1203200/1281167 (94%)]	Loss: 0.707911
[2022-03-31 02:56:07 | train] - Train Epoch: [84] [1216000/1281167 (95%)]	Loss: 1.089384
[2022-03-31 02:56:26 | train] - Train Epoch: [84] [1228800/1281167 (96%)]	Loss: 0.943239
[2022-03-31 02:56:46 | train] - Train Epoch: [84] [1241600/1281167 (97%)]	Loss: 0.730785
[2022-03-31 02:57:06 | train] - Train Epoch: [84] [1254400/1281167 (98%)]	Loss: 0.665775
[2022-03-31 02:57:26 | train] - Train Epoch: [84] [1267200/1281167 (99%)]	Loss: 0.913998
[2022-03-31 02:57:45 | train] - Train Epoch: [84] [1280000/1281167 (100%)]	Loss: 0.884265
[2022-03-31 02:57:47 | train] - Train Epoch: [84]	 Average Loss: 0.877018	 Total Acc : 78.5522	 Total Top5 Acc : 92.1039
[2022-03-31 02:57:47 | train] - -------84 epoch end-----------
========================================
-------84 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 02:59:17 | train] - 
Epoch [84] Test set: Average loss: 1.3593, Accuracy: 34957/50000 (69.8901%), Top-5 Accuracy: 88.8959%

[2022-03-31 02:59:17 | train] - save intermediate epoch [84] result


[2022-03-31 02:59:22 | train] - -------85 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 02:59:24 | train] - Train Epoch: [85] [0/1281167 (0%)]	Loss: 1.025826
[2022-03-31 02:59:45 | train] - Train Epoch: [85] [12800/1281167 (1%)]	Loss: 0.673795
[2022-03-31 03:00:05 | train] - Train Epoch: [85] [25600/1281167 (2%)]	Loss: 1.051316
[2022-03-31 03:00:24 | train] - Train Epoch: [85] [38400/1281167 (3%)]	Loss: 1.053366
[2022-03-31 03:00:43 | train] - Train Epoch: [85] [51200/1281167 (4%)]	Loss: 0.902949
[2022-03-31 03:01:02 | train] - Train Epoch: [85] [64000/1281167 (5%)]	Loss: 0.914759
[2022-03-31 03:01:21 | train] - Train Epoch: [85] [76800/1281167 (6%)]	Loss: 1.192515
[2022-03-31 03:01:42 | train] - Train Epoch: [85] [89600/1281167 (7%)]	Loss: 1.017021
[2022-03-31 03:02:01 | train] - Train Epoch: [85] [102400/1281167 (8%)]	Loss: 0.849265
[2022-03-31 03:02:21 | train] - Train Epoch: [85] [115200/1281167 (9%)]	Loss: 0.679921
[2022-03-31 03:02:40 | train] - Train Epoch: [85] [128000/1281167 (10%)]	Loss: 0.749866
[2022-03-31 03:03:00 | train] - Train Epoch: [85] [140800/1281167 (11%)]	Loss: 0.924577
[2022-03-31 03:03:20 | train] - Train Epoch: [85] [153600/1281167 (12%)]	Loss: 1.002207
[2022-03-31 03:03:39 | train] - Train Epoch: [85] [166400/1281167 (13%)]	Loss: 1.126742
[2022-03-31 03:03:59 | train] - Train Epoch: [85] [179200/1281167 (14%)]	Loss: 0.805634
[2022-03-31 03:04:19 | train] - Train Epoch: [85] [192000/1281167 (15%)]	Loss: 1.095233
[2022-03-31 03:04:39 | train] - Train Epoch: [85] [204800/1281167 (16%)]	Loss: 1.132313
[2022-03-31 03:04:58 | train] - Train Epoch: [85] [217600/1281167 (17%)]	Loss: 0.711718
[2022-03-31 03:05:17 | train] - Train Epoch: [85] [230400/1281167 (18%)]	Loss: 0.976280
[2022-03-31 03:05:37 | train] - Train Epoch: [85] [243200/1281167 (19%)]	Loss: 0.766021
[2022-03-31 03:05:56 | train] - Train Epoch: [85] [256000/1281167 (20%)]	Loss: 0.909068
[2022-03-31 03:06:17 | train] - Train Epoch: [85] [268800/1281167 (21%)]	Loss: 1.067302
[2022-03-31 03:06:37 | train] - Train Epoch: [85] [281600/1281167 (22%)]	Loss: 0.920903
[2022-03-31 03:06:57 | train] - Train Epoch: [85] [294400/1281167 (23%)]	Loss: 0.761339
[2022-03-31 03:07:16 | train] - Train Epoch: [85] [307200/1281167 (24%)]	Loss: 1.132627
[2022-03-31 03:07:36 | train] - Train Epoch: [85] [320000/1281167 (25%)]	Loss: 0.954326
[2022-03-31 03:07:55 | train] - Train Epoch: [85] [332800/1281167 (26%)]	Loss: 0.819821
[2022-03-31 03:08:14 | train] - Train Epoch: [85] [345600/1281167 (27%)]	Loss: 0.670067
[2022-03-31 03:08:34 | train] - Train Epoch: [85] [358400/1281167 (28%)]	Loss: 1.072792
[2022-03-31 03:08:54 | train] - Train Epoch: [85] [371200/1281167 (29%)]	Loss: 0.851260
[2022-03-31 03:09:13 | train] - Train Epoch: [85] [384000/1281167 (30%)]	Loss: 0.716579
[2022-03-31 03:09:33 | train] - Train Epoch: [85] [396800/1281167 (31%)]	Loss: 0.772745
[2022-03-31 03:09:52 | train] - Train Epoch: [85] [409600/1281167 (32%)]	Loss: 0.834223
[2022-03-31 03:10:12 | train] - Train Epoch: [85] [422400/1281167 (33%)]	Loss: 0.914660
[2022-03-31 03:10:33 | train] - Train Epoch: [85] [435200/1281167 (34%)]	Loss: 0.836771
[2022-03-31 03:10:52 | train] - Train Epoch: [85] [448000/1281167 (35%)]	Loss: 0.713561
[2022-03-31 03:11:11 | train] - Train Epoch: [85] [460800/1281167 (36%)]	Loss: 1.031515
[2022-03-31 03:11:31 | train] - Train Epoch: [85] [473600/1281167 (37%)]	Loss: 1.030348
[2022-03-31 03:11:51 | train] - Train Epoch: [85] [486400/1281167 (38%)]	Loss: 0.946420
[2022-03-31 03:12:10 | train] - Train Epoch: [85] [499200/1281167 (39%)]	Loss: 0.873339
[2022-03-31 03:12:29 | train] - Train Epoch: [85] [512000/1281167 (40%)]	Loss: 0.909307
[2022-03-31 03:12:49 | train] - Train Epoch: [85] [524800/1281167 (41%)]	Loss: 0.879126
[2022-03-31 03:13:09 | train] - Train Epoch: [85] [537600/1281167 (42%)]	Loss: 0.878353
[2022-03-31 03:13:29 | train] - Train Epoch: [85] [550400/1281167 (43%)]	Loss: 0.760034
[2022-03-31 03:13:48 | train] - Train Epoch: [85] [563200/1281167 (44%)]	Loss: 0.913031
[2022-03-31 03:14:08 | train] - Train Epoch: [85] [576000/1281167 (45%)]	Loss: 0.578786
[2022-03-31 03:14:28 | train] - Train Epoch: [85] [588800/1281167 (46%)]	Loss: 1.045233
[2022-03-31 03:14:48 | train] - Train Epoch: [85] [601600/1281167 (47%)]	Loss: 0.961767
[2022-03-31 03:15:08 | train] - Train Epoch: [85] [614400/1281167 (48%)]	Loss: 0.663318
[2022-03-31 03:15:27 | train] - Train Epoch: [85] [627200/1281167 (49%)]	Loss: 0.814414
[2022-03-31 03:15:47 | train] - Train Epoch: [85] [640000/1281167 (50%)]	Loss: 0.781152
[2022-03-31 03:16:07 | train] - Train Epoch: [85] [652800/1281167 (51%)]	Loss: 0.893476
[2022-03-31 03:16:26 | train] - Train Epoch: [85] [665600/1281167 (52%)]	Loss: 0.676302
[2022-03-31 03:16:46 | train] - Train Epoch: [85] [678400/1281167 (53%)]	Loss: 0.904471
[2022-03-31 03:17:06 | train] - Train Epoch: [85] [691200/1281167 (54%)]	Loss: 0.774442
[2022-03-31 03:17:26 | train] - Train Epoch: [85] [704000/1281167 (55%)]	Loss: 0.737107
[2022-03-31 03:17:46 | train] - Train Epoch: [85] [716800/1281167 (56%)]	Loss: 1.024289
[2022-03-31 03:18:06 | train] - Train Epoch: [85] [729600/1281167 (57%)]	Loss: 0.686418
[2022-03-31 03:18:25 | train] - Train Epoch: [85] [742400/1281167 (58%)]	Loss: 0.782691
[2022-03-31 03:18:45 | train] - Train Epoch: [85] [755200/1281167 (59%)]	Loss: 0.836535
[2022-03-31 03:19:04 | train] - Train Epoch: [85] [768000/1281167 (60%)]	Loss: 1.013031
[2022-03-31 03:19:23 | train] - Train Epoch: [85] [780800/1281167 (61%)]	Loss: 0.867659
[2022-03-31 03:19:43 | train] - Train Epoch: [85] [793600/1281167 (62%)]	Loss: 0.851964
[2022-03-31 03:20:02 | train] - Train Epoch: [85] [806400/1281167 (63%)]	Loss: 0.925664
[2022-03-31 03:20:21 | train] - Train Epoch: [85] [819200/1281167 (64%)]	Loss: 0.996500
[2022-03-31 03:20:41 | train] - Train Epoch: [85] [832000/1281167 (65%)]	Loss: 1.243392
[2022-03-31 03:21:01 | train] - Train Epoch: [85] [844800/1281167 (66%)]	Loss: 0.728661
[2022-03-31 03:21:20 | train] - Train Epoch: [85] [857600/1281167 (67%)]	Loss: 1.112962
[2022-03-31 03:21:40 | train] - Train Epoch: [85] [870400/1281167 (68%)]	Loss: 0.995694
[2022-03-31 03:22:00 | train] - Train Epoch: [85] [883200/1281167 (69%)]	Loss: 1.015009
[2022-03-31 03:22:20 | train] - Train Epoch: [85] [896000/1281167 (70%)]	Loss: 0.941555
[2022-03-31 03:22:40 | train] - Train Epoch: [85] [908800/1281167 (71%)]	Loss: 0.827739
[2022-03-31 03:23:00 | train] - Train Epoch: [85] [921600/1281167 (72%)]	Loss: 1.021272
[2022-03-31 03:23:20 | train] - Train Epoch: [85] [934400/1281167 (73%)]	Loss: 0.985555
[2022-03-31 03:23:40 | train] - Train Epoch: [85] [947200/1281167 (74%)]	Loss: 0.619784
[2022-03-31 03:24:00 | train] - Train Epoch: [85] [960000/1281167 (75%)]	Loss: 1.237433
[2022-03-31 03:24:20 | train] - Train Epoch: [85] [972800/1281167 (76%)]	Loss: 0.923645
[2022-03-31 03:24:39 | train] - Train Epoch: [85] [985600/1281167 (77%)]	Loss: 0.873575
[2022-03-31 03:25:00 | train] - Train Epoch: [85] [998400/1281167 (78%)]	Loss: 0.872017
[2022-03-31 03:25:20 | train] - Train Epoch: [85] [1011200/1281167 (79%)]	Loss: 0.962086
[2022-03-31 03:25:39 | train] - Train Epoch: [85] [1024000/1281167 (80%)]	Loss: 0.953425
[2022-03-31 03:25:58 | train] - Train Epoch: [85] [1036800/1281167 (81%)]	Loss: 0.859734
[2022-03-31 03:26:18 | train] - Train Epoch: [85] [1049600/1281167 (82%)]	Loss: 0.898663
[2022-03-31 03:26:38 | train] - Train Epoch: [85] [1062400/1281167 (83%)]	Loss: 0.691980
[2022-03-31 03:26:57 | train] - Train Epoch: [85] [1075200/1281167 (84%)]	Loss: 0.849248
[2022-03-31 03:27:17 | train] - Train Epoch: [85] [1088000/1281167 (85%)]	Loss: 0.853008
[2022-03-31 03:27:36 | train] - Train Epoch: [85] [1100800/1281167 (86%)]	Loss: 0.606234
[2022-03-31 03:27:56 | train] - Train Epoch: [85] [1113600/1281167 (87%)]	Loss: 0.825659
[2022-03-31 03:28:16 | train] - Train Epoch: [85] [1126400/1281167 (88%)]	Loss: 0.660457
[2022-03-31 03:28:35 | train] - Train Epoch: [85] [1139200/1281167 (89%)]	Loss: 0.845553
[2022-03-31 03:28:55 | train] - Train Epoch: [85] [1152000/1281167 (90%)]	Loss: 0.945255
[2022-03-31 03:29:15 | train] - Train Epoch: [85] [1164800/1281167 (91%)]	Loss: 1.137746
[2022-03-31 03:29:34 | train] - Train Epoch: [85] [1177600/1281167 (92%)]	Loss: 0.885976
[2022-03-31 03:29:54 | train] - Train Epoch: [85] [1190400/1281167 (93%)]	Loss: 0.853840
[2022-03-31 03:30:14 | train] - Train Epoch: [85] [1203200/1281167 (94%)]	Loss: 1.084439
[2022-03-31 03:30:34 | train] - Train Epoch: [85] [1216000/1281167 (95%)]	Loss: 0.525706
[2022-03-31 03:30:54 | train] - Train Epoch: [85] [1228800/1281167 (96%)]	Loss: 0.698167
[2022-03-31 03:31:14 | train] - Train Epoch: [85] [1241600/1281167 (97%)]	Loss: 0.957547
[2022-03-31 03:31:34 | train] - Train Epoch: [85] [1254400/1281167 (98%)]	Loss: 0.803459
[2022-03-31 03:31:54 | train] - Train Epoch: [85] [1267200/1281167 (99%)]	Loss: 0.597225
[2022-03-31 03:32:14 | train] - Train Epoch: [85] [1280000/1281167 (100%)]	Loss: 0.757901
[2022-03-31 03:32:16 | train] - Train Epoch: [85]	 Average Loss: 0.873188	 Total Acc : 78.6827	 Total Top5 Acc : 92.1058
[2022-03-31 03:32:16 | train] - -------85 epoch end-----------
========================================
-------85 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 03:33:45 | train] - 
Epoch [85] Test set: Average loss: 1.3586, Accuracy: 35037/50000 (70.0464%), Top-5 Accuracy: 88.8591%

[2022-03-31 03:33:45 | train] - save intermediate epoch [85] result


[2022-03-31 03:33:51 | train] - -------86 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 03:33:53 | train] - Train Epoch: [86] [0/1281167 (0%)]	Loss: 1.069717
[2022-03-31 03:34:12 | train] - Train Epoch: [86] [12800/1281167 (1%)]	Loss: 1.077638
[2022-03-31 03:34:31 | train] - Train Epoch: [86] [25600/1281167 (2%)]	Loss: 1.073680
[2022-03-31 03:34:50 | train] - Train Epoch: [86] [38400/1281167 (3%)]	Loss: 0.843091
[2022-03-31 03:35:09 | train] - Train Epoch: [86] [51200/1281167 (4%)]	Loss: 0.836308
[2022-03-31 03:35:28 | train] - Train Epoch: [86] [64000/1281167 (5%)]	Loss: 1.076167
[2022-03-31 03:35:48 | train] - Train Epoch: [86] [76800/1281167 (6%)]	Loss: 0.737212
[2022-03-31 03:36:08 | train] - Train Epoch: [86] [89600/1281167 (7%)]	Loss: 1.137161
[2022-03-31 03:36:27 | train] - Train Epoch: [86] [102400/1281167 (8%)]	Loss: 1.125127
[2022-03-31 03:36:46 | train] - Train Epoch: [86] [115200/1281167 (9%)]	Loss: 0.923000
[2022-03-31 03:37:06 | train] - Train Epoch: [86] [128000/1281167 (10%)]	Loss: 0.729474
[2022-03-31 03:37:26 | train] - Train Epoch: [86] [140800/1281167 (11%)]	Loss: 0.935429
[2022-03-31 03:37:45 | train] - Train Epoch: [86] [153600/1281167 (12%)]	Loss: 0.521919
[2022-03-31 03:38:05 | train] - Train Epoch: [86] [166400/1281167 (13%)]	Loss: 0.752043
[2022-03-31 03:38:24 | train] - Train Epoch: [86] [179200/1281167 (14%)]	Loss: 0.899900
[2022-03-31 03:38:43 | train] - Train Epoch: [86] [192000/1281167 (15%)]	Loss: 0.827481
[2022-03-31 03:39:03 | train] - Train Epoch: [86] [204800/1281167 (16%)]	Loss: 1.055524
[2022-03-31 03:39:22 | train] - Train Epoch: [86] [217600/1281167 (17%)]	Loss: 0.918468
[2022-03-31 03:39:42 | train] - Train Epoch: [86] [230400/1281167 (18%)]	Loss: 0.794960
[2022-03-31 03:40:02 | train] - Train Epoch: [86] [243200/1281167 (19%)]	Loss: 1.024051
[2022-03-31 03:40:22 | train] - Train Epoch: [86] [256000/1281167 (20%)]	Loss: 1.181038
[2022-03-31 03:40:41 | train] - Train Epoch: [86] [268800/1281167 (21%)]	Loss: 0.967495
[2022-03-31 03:41:00 | train] - Train Epoch: [86] [281600/1281167 (22%)]	Loss: 0.832196
[2022-03-31 03:41:20 | train] - Train Epoch: [86] [294400/1281167 (23%)]	Loss: 0.706275
[2022-03-31 03:41:39 | train] - Train Epoch: [86] [307200/1281167 (24%)]	Loss: 0.893497
[2022-03-31 03:41:58 | train] - Train Epoch: [86] [320000/1281167 (25%)]	Loss: 1.081523
[2022-03-31 03:42:18 | train] - Train Epoch: [86] [332800/1281167 (26%)]	Loss: 0.833857
[2022-03-31 03:42:39 | train] - Train Epoch: [86] [345600/1281167 (27%)]	Loss: 0.772375
[2022-03-31 03:42:58 | train] - Train Epoch: [86] [358400/1281167 (28%)]	Loss: 0.946301
[2022-03-31 03:43:18 | train] - Train Epoch: [86] [371200/1281167 (29%)]	Loss: 0.911572
[2022-03-31 03:43:37 | train] - Train Epoch: [86] [384000/1281167 (30%)]	Loss: 0.690219
[2022-03-31 03:43:56 | train] - Train Epoch: [86] [396800/1281167 (31%)]	Loss: 0.806383
[2022-03-31 03:44:16 | train] - Train Epoch: [86] [409600/1281167 (32%)]	Loss: 0.896086
[2022-03-31 03:44:36 | train] - Train Epoch: [86] [422400/1281167 (33%)]	Loss: 1.011517
[2022-03-31 03:44:57 | train] - Train Epoch: [86] [435200/1281167 (34%)]	Loss: 0.796786
[2022-03-31 03:45:16 | train] - Train Epoch: [86] [448000/1281167 (35%)]	Loss: 0.977691
[2022-03-31 03:45:36 | train] - Train Epoch: [86] [460800/1281167 (36%)]	Loss: 0.961134
[2022-03-31 03:45:56 | train] - Train Epoch: [86] [473600/1281167 (37%)]	Loss: 0.662177
[2022-03-31 03:46:16 | train] - Train Epoch: [86] [486400/1281167 (38%)]	Loss: 0.740813
[2022-03-31 03:46:36 | train] - Train Epoch: [86] [499200/1281167 (39%)]	Loss: 0.747748
[2022-03-31 03:46:55 | train] - Train Epoch: [86] [512000/1281167 (40%)]	Loss: 0.663538
[2022-03-31 03:47:15 | train] - Train Epoch: [86] [524800/1281167 (41%)]	Loss: 0.816014
[2022-03-31 03:47:35 | train] - Train Epoch: [86] [537600/1281167 (42%)]	Loss: 0.932477
[2022-03-31 03:47:55 | train] - Train Epoch: [86] [550400/1281167 (43%)]	Loss: 0.802733
[2022-03-31 03:48:15 | train] - Train Epoch: [86] [563200/1281167 (44%)]	Loss: 0.838162
[2022-03-31 03:48:35 | train] - Train Epoch: [86] [576000/1281167 (45%)]	Loss: 0.909461
[2022-03-31 03:48:54 | train] - Train Epoch: [86] [588800/1281167 (46%)]	Loss: 1.028728
[2022-03-31 03:49:14 | train] - Train Epoch: [86] [601600/1281167 (47%)]	Loss: 0.708499
[2022-03-31 03:49:34 | train] - Train Epoch: [86] [614400/1281167 (48%)]	Loss: 0.798833
[2022-03-31 03:49:53 | train] - Train Epoch: [86] [627200/1281167 (49%)]	Loss: 0.782240
[2022-03-31 03:50:13 | train] - Train Epoch: [86] [640000/1281167 (50%)]	Loss: 0.907665
[2022-03-31 03:50:32 | train] - Train Epoch: [86] [652800/1281167 (51%)]	Loss: 0.983404
[2022-03-31 03:50:52 | train] - Train Epoch: [86] [665600/1281167 (52%)]	Loss: 0.883944
[2022-03-31 03:51:12 | train] - Train Epoch: [86] [678400/1281167 (53%)]	Loss: 0.718836
[2022-03-31 03:51:31 | train] - Train Epoch: [86] [691200/1281167 (54%)]	Loss: 0.674953
[2022-03-31 03:51:52 | train] - Train Epoch: [86] [704000/1281167 (55%)]	Loss: 0.702298
[2022-03-31 03:52:11 | train] - Train Epoch: [86] [716800/1281167 (56%)]	Loss: 0.872812
[2022-03-31 03:52:30 | train] - Train Epoch: [86] [729600/1281167 (57%)]	Loss: 0.875894
[2022-03-31 03:52:50 | train] - Train Epoch: [86] [742400/1281167 (58%)]	Loss: 0.853834
[2022-03-31 03:53:10 | train] - Train Epoch: [86] [755200/1281167 (59%)]	Loss: 0.975766
[2022-03-31 03:53:30 | train] - Train Epoch: [86] [768000/1281167 (60%)]	Loss: 1.186534
[2022-03-31 03:53:49 | train] - Train Epoch: [86] [780800/1281167 (61%)]	Loss: 1.065023
[2022-03-31 03:54:09 | train] - Train Epoch: [86] [793600/1281167 (62%)]	Loss: 0.846429
[2022-03-31 03:54:29 | train] - Train Epoch: [86] [806400/1281167 (63%)]	Loss: 0.854744
[2022-03-31 03:54:48 | train] - Train Epoch: [86] [819200/1281167 (64%)]	Loss: 0.855727
[2022-03-31 03:55:08 | train] - Train Epoch: [86] [832000/1281167 (65%)]	Loss: 0.876700
[2022-03-31 03:55:28 | train] - Train Epoch: [86] [844800/1281167 (66%)]	Loss: 0.836364
[2022-03-31 03:55:49 | train] - Train Epoch: [86] [857600/1281167 (67%)]	Loss: 1.267581
[2022-03-31 03:56:08 | train] - Train Epoch: [86] [870400/1281167 (68%)]	Loss: 0.808136
[2022-03-31 03:56:28 | train] - Train Epoch: [86] [883200/1281167 (69%)]	Loss: 1.082987
[2022-03-31 03:56:47 | train] - Train Epoch: [86] [896000/1281167 (70%)]	Loss: 0.875875
[2022-03-31 03:57:08 | train] - Train Epoch: [86] [908800/1281167 (71%)]	Loss: 0.684697
[2022-03-31 03:57:27 | train] - Train Epoch: [86] [921600/1281167 (72%)]	Loss: 0.806779
[2022-03-31 03:57:47 | train] - Train Epoch: [86] [934400/1281167 (73%)]	Loss: 0.932763
[2022-03-31 03:58:06 | train] - Train Epoch: [86] [947200/1281167 (74%)]	Loss: 1.038348
[2022-03-31 03:58:25 | train] - Train Epoch: [86] [960000/1281167 (75%)]	Loss: 0.897142
[2022-03-31 03:58:45 | train] - Train Epoch: [86] [972800/1281167 (76%)]	Loss: 0.748201
[2022-03-31 03:59:04 | train] - Train Epoch: [86] [985600/1281167 (77%)]	Loss: 0.496930
[2022-03-31 03:59:24 | train] - Train Epoch: [86] [998400/1281167 (78%)]	Loss: 0.958527
[2022-03-31 03:59:44 | train] - Train Epoch: [86] [1011200/1281167 (79%)]	Loss: 0.951988
[2022-03-31 04:00:03 | train] - Train Epoch: [86] [1024000/1281167 (80%)]	Loss: 0.639006
[2022-03-31 04:00:23 | train] - Train Epoch: [86] [1036800/1281167 (81%)]	Loss: 0.832102
[2022-03-31 04:00:42 | train] - Train Epoch: [86] [1049600/1281167 (82%)]	Loss: 0.827720
[2022-03-31 04:01:01 | train] - Train Epoch: [86] [1062400/1281167 (83%)]	Loss: 0.695689
[2022-03-31 04:01:21 | train] - Train Epoch: [86] [1075200/1281167 (84%)]	Loss: 0.602946
[2022-03-31 04:01:41 | train] - Train Epoch: [86] [1088000/1281167 (85%)]	Loss: 0.902931
[2022-03-31 04:02:01 | train] - Train Epoch: [86] [1100800/1281167 (86%)]	Loss: 0.917835
[2022-03-31 04:02:20 | train] - Train Epoch: [86] [1113600/1281167 (87%)]	Loss: 0.903751
[2022-03-31 04:02:40 | train] - Train Epoch: [86] [1126400/1281167 (88%)]	Loss: 1.069141
[2022-03-31 04:03:00 | train] - Train Epoch: [86] [1139200/1281167 (89%)]	Loss: 0.714122
[2022-03-31 04:03:19 | train] - Train Epoch: [86] [1152000/1281167 (90%)]	Loss: 0.771295
[2022-03-31 04:03:39 | train] - Train Epoch: [86] [1164800/1281167 (91%)]	Loss: 0.809117
[2022-03-31 04:03:59 | train] - Train Epoch: [86] [1177600/1281167 (92%)]	Loss: 0.999293
[2022-03-31 04:04:18 | train] - Train Epoch: [86] [1190400/1281167 (93%)]	Loss: 0.718698
[2022-03-31 04:04:38 | train] - Train Epoch: [86] [1203200/1281167 (94%)]	Loss: 0.856276
[2022-03-31 04:04:57 | train] - Train Epoch: [86] [1216000/1281167 (95%)]	Loss: 0.868635
[2022-03-31 04:05:17 | train] - Train Epoch: [86] [1228800/1281167 (96%)]	Loss: 0.765832
[2022-03-31 04:05:36 | train] - Train Epoch: [86] [1241600/1281167 (97%)]	Loss: 1.115900
[2022-03-31 04:05:56 | train] - Train Epoch: [86] [1254400/1281167 (98%)]	Loss: 0.866184
[2022-03-31 04:06:16 | train] - Train Epoch: [86] [1267200/1281167 (99%)]	Loss: 1.058360
[2022-03-31 04:06:36 | train] - Train Epoch: [86] [1280000/1281167 (100%)]	Loss: 0.821470
[2022-03-31 04:06:38 | train] - Train Epoch: [86]	 Average Loss: 0.869846	 Total Acc : 78.7840	 Total Top5 Acc : 92.1665
[2022-03-31 04:06:38 | train] - -------86 epoch end-----------
========================================
-------86 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 04:08:06 | train] - 
Epoch [86] Test set: Average loss: 1.3737, Accuracy: 34964/50000 (69.9017%), Top-5 Accuracy: 88.9102%

[2022-03-31 04:08:06 | train] - save intermediate epoch [86] result


[2022-03-31 04:08:13 | train] - -------87 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 04:08:14 | train] - Train Epoch: [87] [0/1281167 (0%)]	Loss: 0.960198
[2022-03-31 04:08:34 | train] - Train Epoch: [87] [12800/1281167 (1%)]	Loss: 0.963001
[2022-03-31 04:08:53 | train] - Train Epoch: [87] [25600/1281167 (2%)]	Loss: 0.959986
[2022-03-31 04:09:13 | train] - Train Epoch: [87] [38400/1281167 (3%)]	Loss: 0.936498
[2022-03-31 04:09:34 | train] - Train Epoch: [87] [51200/1281167 (4%)]	Loss: 0.906269
[2022-03-31 04:09:54 | train] - Train Epoch: [87] [64000/1281167 (5%)]	Loss: 0.925452
[2022-03-31 04:10:14 | train] - Train Epoch: [87] [76800/1281167 (6%)]	Loss: 1.146974
[2022-03-31 04:10:33 | train] - Train Epoch: [87] [89600/1281167 (7%)]	Loss: 0.483606
[2022-03-31 04:10:52 | train] - Train Epoch: [87] [102400/1281167 (8%)]	Loss: 1.000897
[2022-03-31 04:11:12 | train] - Train Epoch: [87] [115200/1281167 (9%)]	Loss: 0.627556
[2022-03-31 04:11:32 | train] - Train Epoch: [87] [128000/1281167 (10%)]	Loss: 0.640180
[2022-03-31 04:11:52 | train] - Train Epoch: [87] [140800/1281167 (11%)]	Loss: 1.013555
[2022-03-31 04:12:11 | train] - Train Epoch: [87] [153600/1281167 (12%)]	Loss: 0.823416
[2022-03-31 04:12:30 | train] - Train Epoch: [87] [166400/1281167 (13%)]	Loss: 0.672178
[2022-03-31 04:12:50 | train] - Train Epoch: [87] [179200/1281167 (14%)]	Loss: 1.097986
[2022-03-31 04:13:09 | train] - Train Epoch: [87] [192000/1281167 (15%)]	Loss: 1.178270
[2022-03-31 04:13:29 | train] - Train Epoch: [87] [204800/1281167 (16%)]	Loss: 0.875073
[2022-03-31 04:13:49 | train] - Train Epoch: [87] [217600/1281167 (17%)]	Loss: 0.554605
[2022-03-31 04:14:09 | train] - Train Epoch: [87] [230400/1281167 (18%)]	Loss: 0.878923
[2022-03-31 04:14:28 | train] - Train Epoch: [87] [243200/1281167 (19%)]	Loss: 0.855018
[2022-03-31 04:14:48 | train] - Train Epoch: [87] [256000/1281167 (20%)]	Loss: 0.794636
[2022-03-31 04:15:07 | train] - Train Epoch: [87] [268800/1281167 (21%)]	Loss: 0.702123
[2022-03-31 04:15:27 | train] - Train Epoch: [87] [281600/1281167 (22%)]	Loss: 1.146951
[2022-03-31 04:15:46 | train] - Train Epoch: [87] [294400/1281167 (23%)]	Loss: 0.867553
[2022-03-31 04:16:06 | train] - Train Epoch: [87] [307200/1281167 (24%)]	Loss: 1.029901
[2022-03-31 04:16:26 | train] - Train Epoch: [87] [320000/1281167 (25%)]	Loss: 0.900238
[2022-03-31 04:16:46 | train] - Train Epoch: [87] [332800/1281167 (26%)]	Loss: 1.069134
[2022-03-31 04:17:05 | train] - Train Epoch: [87] [345600/1281167 (27%)]	Loss: 0.855031
[2022-03-31 04:17:25 | train] - Train Epoch: [87] [358400/1281167 (28%)]	Loss: 0.753902
[2022-03-31 04:17:44 | train] - Train Epoch: [87] [371200/1281167 (29%)]	Loss: 0.849090
[2022-03-31 04:18:04 | train] - Train Epoch: [87] [384000/1281167 (30%)]	Loss: 0.853886
[2022-03-31 04:18:23 | train] - Train Epoch: [87] [396800/1281167 (31%)]	Loss: 0.807432
[2022-03-31 04:18:43 | train] - Train Epoch: [87] [409600/1281167 (32%)]	Loss: 0.943622
[2022-03-31 04:19:03 | train] - Train Epoch: [87] [422400/1281167 (33%)]	Loss: 0.886493
[2022-03-31 04:19:21 | train] - Train Epoch: [87] [435200/1281167 (34%)]	Loss: 0.970614
[2022-03-31 04:19:41 | train] - Train Epoch: [87] [448000/1281167 (35%)]	Loss: 1.148777
[2022-03-31 04:20:00 | train] - Train Epoch: [87] [460800/1281167 (36%)]	Loss: 0.694297
[2022-03-31 04:20:20 | train] - Train Epoch: [87] [473600/1281167 (37%)]	Loss: 0.990490
[2022-03-31 04:20:40 | train] - Train Epoch: [87] [486400/1281167 (38%)]	Loss: 1.028515
[2022-03-31 04:21:00 | train] - Train Epoch: [87] [499200/1281167 (39%)]	Loss: 0.909886
[2022-03-31 04:21:19 | train] - Train Epoch: [87] [512000/1281167 (40%)]	Loss: 0.942579
[2022-03-31 04:21:39 | train] - Train Epoch: [87] [524800/1281167 (41%)]	Loss: 0.642255
[2022-03-31 04:21:58 | train] - Train Epoch: [87] [537600/1281167 (42%)]	Loss: 0.820720
[2022-03-31 04:22:17 | train] - Train Epoch: [87] [550400/1281167 (43%)]	Loss: 0.685341
[2022-03-31 04:22:37 | train] - Train Epoch: [87] [563200/1281167 (44%)]	Loss: 0.994564
[2022-03-31 04:22:56 | train] - Train Epoch: [87] [576000/1281167 (45%)]	Loss: 1.039537
[2022-03-31 04:23:16 | train] - Train Epoch: [87] [588800/1281167 (46%)]	Loss: 0.795037
[2022-03-31 04:23:35 | train] - Train Epoch: [87] [601600/1281167 (47%)]	Loss: 0.806708
[2022-03-31 04:23:55 | train] - Train Epoch: [87] [614400/1281167 (48%)]	Loss: 0.704408
[2022-03-31 04:24:14 | train] - Train Epoch: [87] [627200/1281167 (49%)]	Loss: 0.921661
[2022-03-31 04:24:34 | train] - Train Epoch: [87] [640000/1281167 (50%)]	Loss: 0.840393
[2022-03-31 04:24:54 | train] - Train Epoch: [87] [652800/1281167 (51%)]	Loss: 0.849398
[2022-03-31 04:25:13 | train] - Train Epoch: [87] [665600/1281167 (52%)]	Loss: 0.934181
[2022-03-31 04:25:33 | train] - Train Epoch: [87] [678400/1281167 (53%)]	Loss: 0.993461
[2022-03-31 04:25:52 | train] - Train Epoch: [87] [691200/1281167 (54%)]	Loss: 0.607909
[2022-03-31 04:26:11 | train] - Train Epoch: [87] [704000/1281167 (55%)]	Loss: 1.179722
[2022-03-31 04:26:30 | train] - Train Epoch: [87] [716800/1281167 (56%)]	Loss: 0.685703
[2022-03-31 04:26:50 | train] - Train Epoch: [87] [729600/1281167 (57%)]	Loss: 1.043171
[2022-03-31 04:27:09 | train] - Train Epoch: [87] [742400/1281167 (58%)]	Loss: 0.845527
[2022-03-31 04:27:29 | train] - Train Epoch: [87] [755200/1281167 (59%)]	Loss: 0.834996
[2022-03-31 04:27:49 | train] - Train Epoch: [87] [768000/1281167 (60%)]	Loss: 0.751910
[2022-03-31 04:28:08 | train] - Train Epoch: [87] [780800/1281167 (61%)]	Loss: 0.842059
[2022-03-31 04:28:27 | train] - Train Epoch: [87] [793600/1281167 (62%)]	Loss: 0.865829
[2022-03-31 04:28:47 | train] - Train Epoch: [87] [806400/1281167 (63%)]	Loss: 0.762065
[2022-03-31 04:29:06 | train] - Train Epoch: [87] [819200/1281167 (64%)]	Loss: 0.670980
[2022-03-31 04:29:26 | train] - Train Epoch: [87] [832000/1281167 (65%)]	Loss: 0.715985
[2022-03-31 04:29:45 | train] - Train Epoch: [87] [844800/1281167 (66%)]	Loss: 0.767798
[2022-03-31 04:30:04 | train] - Train Epoch: [87] [857600/1281167 (67%)]	Loss: 0.781539
[2022-03-31 04:30:24 | train] - Train Epoch: [87] [870400/1281167 (68%)]	Loss: 0.930629
[2022-03-31 04:30:44 | train] - Train Epoch: [87] [883200/1281167 (69%)]	Loss: 0.838194
[2022-03-31 04:31:03 | train] - Train Epoch: [87] [896000/1281167 (70%)]	Loss: 0.677737
[2022-03-31 04:31:23 | train] - Train Epoch: [87] [908800/1281167 (71%)]	Loss: 0.897968
[2022-03-31 04:31:42 | train] - Train Epoch: [87] [921600/1281167 (72%)]	Loss: 0.841781
[2022-03-31 04:32:01 | train] - Train Epoch: [87] [934400/1281167 (73%)]	Loss: 1.078231
[2022-03-31 04:32:20 | train] - Train Epoch: [87] [947200/1281167 (74%)]	Loss: 1.278719
[2022-03-31 04:32:40 | train] - Train Epoch: [87] [960000/1281167 (75%)]	Loss: 0.791224
[2022-03-31 04:32:59 | train] - Train Epoch: [87] [972800/1281167 (76%)]	Loss: 0.667049
[2022-03-31 04:33:18 | train] - Train Epoch: [87] [985600/1281167 (77%)]	Loss: 0.751616
[2022-03-31 04:33:38 | train] - Train Epoch: [87] [998400/1281167 (78%)]	Loss: 0.759540
[2022-03-31 04:33:58 | train] - Train Epoch: [87] [1011200/1281167 (79%)]	Loss: 1.142528
[2022-03-31 04:34:18 | train] - Train Epoch: [87] [1024000/1281167 (80%)]	Loss: 1.007394
[2022-03-31 04:34:38 | train] - Train Epoch: [87] [1036800/1281167 (81%)]	Loss: 0.732480
[2022-03-31 04:34:57 | train] - Train Epoch: [87] [1049600/1281167 (82%)]	Loss: 0.975963
[2022-03-31 04:35:17 | train] - Train Epoch: [87] [1062400/1281167 (83%)]	Loss: 0.875060
[2022-03-31 04:35:37 | train] - Train Epoch: [87] [1075200/1281167 (84%)]	Loss: 1.029045
[2022-03-31 04:35:56 | train] - Train Epoch: [87] [1088000/1281167 (85%)]	Loss: 0.858114
[2022-03-31 04:36:16 | train] - Train Epoch: [87] [1100800/1281167 (86%)]	Loss: 0.776560
[2022-03-31 04:36:36 | train] - Train Epoch: [87] [1113600/1281167 (87%)]	Loss: 0.978083
[2022-03-31 04:36:56 | train] - Train Epoch: [87] [1126400/1281167 (88%)]	Loss: 0.801882
[2022-03-31 04:37:15 | train] - Train Epoch: [87] [1139200/1281167 (89%)]	Loss: 0.880301
[2022-03-31 04:37:35 | train] - Train Epoch: [87] [1152000/1281167 (90%)]	Loss: 1.047058
[2022-03-31 04:37:54 | train] - Train Epoch: [87] [1164800/1281167 (91%)]	Loss: 0.878453
[2022-03-31 04:38:14 | train] - Train Epoch: [87] [1177600/1281167 (92%)]	Loss: 1.014575
[2022-03-31 04:38:33 | train] - Train Epoch: [87] [1190400/1281167 (93%)]	Loss: 0.882576
[2022-03-31 04:38:52 | train] - Train Epoch: [87] [1203200/1281167 (94%)]	Loss: 1.016846
[2022-03-31 04:39:11 | train] - Train Epoch: [87] [1216000/1281167 (95%)]	Loss: 0.827687
[2022-03-31 04:39:30 | train] - Train Epoch: [87] [1228800/1281167 (96%)]	Loss: 0.911964
[2022-03-31 04:39:50 | train] - Train Epoch: [87] [1241600/1281167 (97%)]	Loss: 0.879840
[2022-03-31 04:40:09 | train] - Train Epoch: [87] [1254400/1281167 (98%)]	Loss: 1.048661
[2022-03-31 04:40:29 | train] - Train Epoch: [87] [1267200/1281167 (99%)]	Loss: 1.173894
[2022-03-31 04:40:49 | train] - Train Epoch: [87] [1280000/1281167 (100%)]	Loss: 0.688710
[2022-03-31 04:40:51 | train] - Train Epoch: [87]	 Average Loss: 0.864956	 Total Acc : 78.8634	 Total Top5 Acc : 92.1957
[2022-03-31 04:40:51 | train] - -------87 epoch end-----------
========================================
-------87 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 04:42:21 | train] - 
Epoch [87] Test set: Average loss: 1.3688, Accuracy: 34961/50000 (69.8993%), Top-5 Accuracy: 88.9694%

[2022-03-31 04:42:21 | train] - save intermediate epoch [87] result


[2022-03-31 04:42:28 | train] - -------88 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 04:42:30 | train] - Train Epoch: [88] [0/1281167 (0%)]	Loss: 0.605932
[2022-03-31 04:42:49 | train] - Train Epoch: [88] [12800/1281167 (1%)]	Loss: 1.030996
[2022-03-31 04:43:09 | train] - Train Epoch: [88] [25600/1281167 (2%)]	Loss: 0.733368
[2022-03-31 04:43:29 | train] - Train Epoch: [88] [38400/1281167 (3%)]	Loss: 0.945507
[2022-03-31 04:43:48 | train] - Train Epoch: [88] [51200/1281167 (4%)]	Loss: 1.041185
[2022-03-31 04:44:08 | train] - Train Epoch: [88] [64000/1281167 (5%)]	Loss: 0.764276
[2022-03-31 04:44:28 | train] - Train Epoch: [88] [76800/1281167 (6%)]	Loss: 0.882490
[2022-03-31 04:44:47 | train] - Train Epoch: [88] [89600/1281167 (7%)]	Loss: 0.747708
[2022-03-31 04:45:07 | train] - Train Epoch: [88] [102400/1281167 (8%)]	Loss: 0.958270
[2022-03-31 04:45:26 | train] - Train Epoch: [88] [115200/1281167 (9%)]	Loss: 0.683675
[2022-03-31 04:45:47 | train] - Train Epoch: [88] [128000/1281167 (10%)]	Loss: 0.810525
[2022-03-31 04:46:06 | train] - Train Epoch: [88] [140800/1281167 (11%)]	Loss: 0.832247
[2022-03-31 04:46:26 | train] - Train Epoch: [88] [153600/1281167 (12%)]	Loss: 0.952808
[2022-03-31 04:46:46 | train] - Train Epoch: [88] [166400/1281167 (13%)]	Loss: 1.049991
[2022-03-31 04:47:05 | train] - Train Epoch: [88] [179200/1281167 (14%)]	Loss: 0.765202
[2022-03-31 04:47:25 | train] - Train Epoch: [88] [192000/1281167 (15%)]	Loss: 0.873801
[2022-03-31 04:47:45 | train] - Train Epoch: [88] [204800/1281167 (16%)]	Loss: 0.878034
[2022-03-31 04:48:04 | train] - Train Epoch: [88] [217600/1281167 (17%)]	Loss: 0.716269
[2022-03-31 04:48:24 | train] - Train Epoch: [88] [230400/1281167 (18%)]	Loss: 0.765856
[2022-03-31 04:48:44 | train] - Train Epoch: [88] [243200/1281167 (19%)]	Loss: 0.912401
[2022-03-31 04:49:04 | train] - Train Epoch: [88] [256000/1281167 (20%)]	Loss: 0.886728
[2022-03-31 04:49:23 | train] - Train Epoch: [88] [268800/1281167 (21%)]	Loss: 0.576147
[2022-03-31 04:49:43 | train] - Train Epoch: [88] [281600/1281167 (22%)]	Loss: 0.659639
[2022-03-31 04:50:02 | train] - Train Epoch: [88] [294400/1281167 (23%)]	Loss: 0.937295
[2022-03-31 04:50:22 | train] - Train Epoch: [88] [307200/1281167 (24%)]	Loss: 0.970209
[2022-03-31 04:50:40 | train] - Train Epoch: [88] [320000/1281167 (25%)]	Loss: 0.773678
[2022-03-31 04:51:01 | train] - Train Epoch: [88] [332800/1281167 (26%)]	Loss: 0.953340
[2022-03-31 04:51:21 | train] - Train Epoch: [88] [345600/1281167 (27%)]	Loss: 1.044012
[2022-03-31 04:51:41 | train] - Train Epoch: [88] [358400/1281167 (28%)]	Loss: 0.872894
[2022-03-31 04:52:00 | train] - Train Epoch: [88] [371200/1281167 (29%)]	Loss: 0.641708
[2022-03-31 04:52:20 | train] - Train Epoch: [88] [384000/1281167 (30%)]	Loss: 0.934394
[2022-03-31 04:52:39 | train] - Train Epoch: [88] [396800/1281167 (31%)]	Loss: 1.004596
[2022-03-31 04:52:59 | train] - Train Epoch: [88] [409600/1281167 (32%)]	Loss: 0.619216
[2022-03-31 04:53:18 | train] - Train Epoch: [88] [422400/1281167 (33%)]	Loss: 0.595629
[2022-03-31 04:53:37 | train] - Train Epoch: [88] [435200/1281167 (34%)]	Loss: 0.806743
[2022-03-31 04:53:57 | train] - Train Epoch: [88] [448000/1281167 (35%)]	Loss: 0.882207
[2022-03-31 04:54:17 | train] - Train Epoch: [88] [460800/1281167 (36%)]	Loss: 0.868663
[2022-03-31 04:54:36 | train] - Train Epoch: [88] [473600/1281167 (37%)]	Loss: 0.735687
[2022-03-31 04:54:56 | train] - Train Epoch: [88] [486400/1281167 (38%)]	Loss: 0.741086
[2022-03-31 04:55:15 | train] - Train Epoch: [88] [499200/1281167 (39%)]	Loss: 0.791124
[2022-03-31 04:55:35 | train] - Train Epoch: [88] [512000/1281167 (40%)]	Loss: 0.955843
[2022-03-31 04:55:55 | train] - Train Epoch: [88] [524800/1281167 (41%)]	Loss: 0.607675
[2022-03-31 04:56:14 | train] - Train Epoch: [88] [537600/1281167 (42%)]	Loss: 0.768591
[2022-03-31 04:56:34 | train] - Train Epoch: [88] [550400/1281167 (43%)]	Loss: 0.855771
[2022-03-31 04:56:54 | train] - Train Epoch: [88] [563200/1281167 (44%)]	Loss: 0.879397
[2022-03-31 04:57:14 | train] - Train Epoch: [88] [576000/1281167 (45%)]	Loss: 0.935904
[2022-03-31 04:57:34 | train] - Train Epoch: [88] [588800/1281167 (46%)]	Loss: 1.147373
[2022-03-31 04:57:53 | train] - Train Epoch: [88] [601600/1281167 (47%)]	Loss: 0.501142
[2022-03-31 04:58:13 | train] - Train Epoch: [88] [614400/1281167 (48%)]	Loss: 0.902617
[2022-03-31 04:58:33 | train] - Train Epoch: [88] [627200/1281167 (49%)]	Loss: 0.809289
[2022-03-31 04:58:54 | train] - Train Epoch: [88] [640000/1281167 (50%)]	Loss: 0.799945
[2022-03-31 04:59:14 | train] - Train Epoch: [88] [652800/1281167 (51%)]	Loss: 0.737822
[2022-03-31 04:59:34 | train] - Train Epoch: [88] [665600/1281167 (52%)]	Loss: 0.884388
[2022-03-31 04:59:53 | train] - Train Epoch: [88] [678400/1281167 (53%)]	Loss: 0.938116
[2022-03-31 05:00:13 | train] - Train Epoch: [88] [691200/1281167 (54%)]	Loss: 0.750436
[2022-03-31 05:00:33 | train] - Train Epoch: [88] [704000/1281167 (55%)]	Loss: 0.924150
[2022-03-31 05:00:53 | train] - Train Epoch: [88] [716800/1281167 (56%)]	Loss: 0.805485
[2022-03-31 05:01:12 | train] - Train Epoch: [88] [729600/1281167 (57%)]	Loss: 0.898291
[2022-03-31 05:01:31 | train] - Train Epoch: [88] [742400/1281167 (58%)]	Loss: 0.993602
[2022-03-31 05:01:52 | train] - Train Epoch: [88] [755200/1281167 (59%)]	Loss: 0.974734
[2022-03-31 05:02:11 | train] - Train Epoch: [88] [768000/1281167 (60%)]	Loss: 0.785115
[2022-03-31 05:02:31 | train] - Train Epoch: [88] [780800/1281167 (61%)]	Loss: 0.618391
[2022-03-31 05:02:51 | train] - Train Epoch: [88] [793600/1281167 (62%)]	Loss: 0.535897
[2022-03-31 05:03:11 | train] - Train Epoch: [88] [806400/1281167 (63%)]	Loss: 0.679300
[2022-03-31 05:03:31 | train] - Train Epoch: [88] [819200/1281167 (64%)]	Loss: 1.018853
[2022-03-31 05:03:50 | train] - Train Epoch: [88] [832000/1281167 (65%)]	Loss: 0.912832
[2022-03-31 05:04:09 | train] - Train Epoch: [88] [844800/1281167 (66%)]	Loss: 1.015748
[2022-03-31 05:04:29 | train] - Train Epoch: [88] [857600/1281167 (67%)]	Loss: 0.760892
[2022-03-31 05:04:49 | train] - Train Epoch: [88] [870400/1281167 (68%)]	Loss: 0.850021
[2022-03-31 05:05:09 | train] - Train Epoch: [88] [883200/1281167 (69%)]	Loss: 0.796515
[2022-03-31 05:05:28 | train] - Train Epoch: [88] [896000/1281167 (70%)]	Loss: 0.843174
[2022-03-31 05:05:48 | train] - Train Epoch: [88] [908800/1281167 (71%)]	Loss: 0.753251
[2022-03-31 05:06:08 | train] - Train Epoch: [88] [921600/1281167 (72%)]	Loss: 0.766124
[2022-03-31 05:06:28 | train] - Train Epoch: [88] [934400/1281167 (73%)]	Loss: 0.855375
[2022-03-31 05:06:47 | train] - Train Epoch: [88] [947200/1281167 (74%)]	Loss: 0.835338
[2022-03-31 05:07:07 | train] - Train Epoch: [88] [960000/1281167 (75%)]	Loss: 0.669652
[2022-03-31 05:07:26 | train] - Train Epoch: [88] [972800/1281167 (76%)]	Loss: 0.832055
[2022-03-31 05:07:46 | train] - Train Epoch: [88] [985600/1281167 (77%)]	Loss: 0.584919
[2022-03-31 05:08:05 | train] - Train Epoch: [88] [998400/1281167 (78%)]	Loss: 0.918859
[2022-03-31 05:08:25 | train] - Train Epoch: [88] [1011200/1281167 (79%)]	Loss: 0.852488
[2022-03-31 05:08:45 | train] - Train Epoch: [88] [1024000/1281167 (80%)]	Loss: 0.987629
[2022-03-31 05:09:05 | train] - Train Epoch: [88] [1036800/1281167 (81%)]	Loss: 0.449380
[2022-03-31 05:09:24 | train] - Train Epoch: [88] [1049600/1281167 (82%)]	Loss: 0.873793
[2022-03-31 05:09:45 | train] - Train Epoch: [88] [1062400/1281167 (83%)]	Loss: 1.026034
[2022-03-31 05:10:04 | train] - Train Epoch: [88] [1075200/1281167 (84%)]	Loss: 0.752253
[2022-03-31 05:10:24 | train] - Train Epoch: [88] [1088000/1281167 (85%)]	Loss: 0.956544
[2022-03-31 05:10:44 | train] - Train Epoch: [88] [1100800/1281167 (86%)]	Loss: 0.801827
[2022-03-31 05:11:03 | train] - Train Epoch: [88] [1113600/1281167 (87%)]	Loss: 0.855190
[2022-03-31 05:11:23 | train] - Train Epoch: [88] [1126400/1281167 (88%)]	Loss: 0.676797
[2022-03-31 05:11:42 | train] - Train Epoch: [88] [1139200/1281167 (89%)]	Loss: 1.199723
[2022-03-31 05:12:02 | train] - Train Epoch: [88] [1152000/1281167 (90%)]	Loss: 0.757152
[2022-03-31 05:12:22 | train] - Train Epoch: [88] [1164800/1281167 (91%)]	Loss: 0.675082
[2022-03-31 05:12:41 | train] - Train Epoch: [88] [1177600/1281167 (92%)]	Loss: 0.968147
[2022-03-31 05:13:01 | train] - Train Epoch: [88] [1190400/1281167 (93%)]	Loss: 0.977704
[2022-03-31 05:13:20 | train] - Train Epoch: [88] [1203200/1281167 (94%)]	Loss: 0.880379
[2022-03-31 05:13:39 | train] - Train Epoch: [88] [1216000/1281167 (95%)]	Loss: 0.887203
[2022-03-31 05:13:58 | train] - Train Epoch: [88] [1228800/1281167 (96%)]	Loss: 0.732371
[2022-03-31 05:14:18 | train] - Train Epoch: [88] [1241600/1281167 (97%)]	Loss: 0.745263
[2022-03-31 05:14:38 | train] - Train Epoch: [88] [1254400/1281167 (98%)]	Loss: 1.039371
[2022-03-31 05:14:57 | train] - Train Epoch: [88] [1267200/1281167 (99%)]	Loss: 1.154610
[2022-03-31 05:15:16 | train] - Train Epoch: [88] [1280000/1281167 (100%)]	Loss: 0.902862
[2022-03-31 05:15:18 | train] - Train Epoch: [88]	 Average Loss: 0.861348	 Total Acc : 78.9255	 Total Top5 Acc : 92.2757
[2022-03-31 05:15:18 | train] - -------88 epoch end-----------
========================================
-------88 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 05:16:47 | train] - 
Epoch [88] Test set: Average loss: 1.3671, Accuracy: 34981/50000 (69.9369%), Top-5 Accuracy: 88.9210%

[2022-03-31 05:16:47 | train] - save intermediate epoch [88] result


[2022-03-31 05:16:54 | train] - -------89 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 05:16:56 | train] - Train Epoch: [89] [0/1281167 (0%)]	Loss: 1.009118
[2022-03-31 05:17:17 | train] - Train Epoch: [89] [12800/1281167 (1%)]	Loss: 0.953574
[2022-03-31 05:17:38 | train] - Train Epoch: [89] [25600/1281167 (2%)]	Loss: 0.841052
[2022-03-31 05:18:00 | train] - Train Epoch: [89] [38400/1281167 (3%)]	Loss: 0.972973
[2022-03-31 05:18:19 | train] - Train Epoch: [89] [51200/1281167 (4%)]	Loss: 0.956640
[2022-03-31 05:18:39 | train] - Train Epoch: [89] [64000/1281167 (5%)]	Loss: 1.090041
[2022-03-31 05:19:00 | train] - Train Epoch: [89] [76800/1281167 (6%)]	Loss: 0.873089
[2022-03-31 05:19:20 | train] - Train Epoch: [89] [89600/1281167 (7%)]	Loss: 0.706507
[2022-03-31 05:19:40 | train] - Train Epoch: [89] [102400/1281167 (8%)]	Loss: 0.771783
[2022-03-31 05:19:59 | train] - Train Epoch: [89] [115200/1281167 (9%)]	Loss: 1.054959
[2022-03-31 05:20:19 | train] - Train Epoch: [89] [128000/1281167 (10%)]	Loss: 0.697384
[2022-03-31 05:20:40 | train] - Train Epoch: [89] [140800/1281167 (11%)]	Loss: 0.803650
[2022-03-31 05:21:00 | train] - Train Epoch: [89] [153600/1281167 (12%)]	Loss: 0.667391
[2022-03-31 05:21:19 | train] - Train Epoch: [89] [166400/1281167 (13%)]	Loss: 0.914262
[2022-03-31 05:21:38 | train] - Train Epoch: [89] [179200/1281167 (14%)]	Loss: 1.052666
[2022-03-31 05:21:59 | train] - Train Epoch: [89] [192000/1281167 (15%)]	Loss: 0.836820
[2022-03-31 05:22:19 | train] - Train Epoch: [89] [204800/1281167 (16%)]	Loss: 0.714775
[2022-03-31 05:22:37 | train] - Train Epoch: [89] [217600/1281167 (17%)]	Loss: 1.004957
[2022-03-31 05:22:56 | train] - Train Epoch: [89] [230400/1281167 (18%)]	Loss: 0.902253
[2022-03-31 05:23:15 | train] - Train Epoch: [89] [243200/1281167 (19%)]	Loss: 0.514780
[2022-03-31 05:23:35 | train] - Train Epoch: [89] [256000/1281167 (20%)]	Loss: 0.812696
[2022-03-31 05:23:55 | train] - Train Epoch: [89] [268800/1281167 (21%)]	Loss: 0.570566
[2022-03-31 05:24:15 | train] - Train Epoch: [89] [281600/1281167 (22%)]	Loss: 0.802617
[2022-03-31 05:24:34 | train] - Train Epoch: [89] [294400/1281167 (23%)]	Loss: 0.681910
[2022-03-31 05:24:54 | train] - Train Epoch: [89] [307200/1281167 (24%)]	Loss: 1.005896
[2022-03-31 05:25:14 | train] - Train Epoch: [89] [320000/1281167 (25%)]	Loss: 0.811276
[2022-03-31 05:25:33 | train] - Train Epoch: [89] [332800/1281167 (26%)]	Loss: 0.984574
[2022-03-31 05:25:52 | train] - Train Epoch: [89] [345600/1281167 (27%)]	Loss: 0.684352
[2022-03-31 05:26:12 | train] - Train Epoch: [89] [358400/1281167 (28%)]	Loss: 0.783139
[2022-03-31 05:26:32 | train] - Train Epoch: [89] [371200/1281167 (29%)]	Loss: 0.786441
[2022-03-31 05:26:52 | train] - Train Epoch: [89] [384000/1281167 (30%)]	Loss: 0.799960
[2022-03-31 05:27:12 | train] - Train Epoch: [89] [396800/1281167 (31%)]	Loss: 0.757791
[2022-03-31 05:27:32 | train] - Train Epoch: [89] [409600/1281167 (32%)]	Loss: 0.983817
[2022-03-31 05:27:52 | train] - Train Epoch: [89] [422400/1281167 (33%)]	Loss: 0.701055
[2022-03-31 05:28:11 | train] - Train Epoch: [89] [435200/1281167 (34%)]	Loss: 0.608939
[2022-03-31 05:28:31 | train] - Train Epoch: [89] [448000/1281167 (35%)]	Loss: 1.007648
[2022-03-31 05:28:50 | train] - Train Epoch: [89] [460800/1281167 (36%)]	Loss: 1.077370
[2022-03-31 05:29:10 | train] - Train Epoch: [89] [473600/1281167 (37%)]	Loss: 0.839642
[2022-03-31 05:29:29 | train] - Train Epoch: [89] [486400/1281167 (38%)]	Loss: 0.760514
[2022-03-31 05:29:50 | train] - Train Epoch: [89] [499200/1281167 (39%)]	Loss: 0.802933
[2022-03-31 05:30:10 | train] - Train Epoch: [89] [512000/1281167 (40%)]	Loss: 0.788095
[2022-03-31 05:30:29 | train] - Train Epoch: [89] [524800/1281167 (41%)]	Loss: 0.800594
[2022-03-31 05:30:49 | train] - Train Epoch: [89] [537600/1281167 (42%)]	Loss: 0.676346
[2022-03-31 05:31:09 | train] - Train Epoch: [89] [550400/1281167 (43%)]	Loss: 1.202340
[2022-03-31 05:31:28 | train] - Train Epoch: [89] [563200/1281167 (44%)]	Loss: 0.894626
[2022-03-31 05:31:48 | train] - Train Epoch: [89] [576000/1281167 (45%)]	Loss: 0.840852
[2022-03-31 05:32:08 | train] - Train Epoch: [89] [588800/1281167 (46%)]	Loss: 0.923026
[2022-03-31 05:32:28 | train] - Train Epoch: [89] [601600/1281167 (47%)]	Loss: 1.016109
[2022-03-31 05:32:48 | train] - Train Epoch: [89] [614400/1281167 (48%)]	Loss: 0.748280
[2022-03-31 05:33:08 | train] - Train Epoch: [89] [627200/1281167 (49%)]	Loss: 0.847894
[2022-03-31 05:33:27 | train] - Train Epoch: [89] [640000/1281167 (50%)]	Loss: 0.616322
[2022-03-31 05:33:47 | train] - Train Epoch: [89] [652800/1281167 (51%)]	Loss: 0.884465
[2022-03-31 05:34:07 | train] - Train Epoch: [89] [665600/1281167 (52%)]	Loss: 0.549414
[2022-03-31 05:34:26 | train] - Train Epoch: [89] [678400/1281167 (53%)]	Loss: 0.708604
[2022-03-31 05:34:46 | train] - Train Epoch: [89] [691200/1281167 (54%)]	Loss: 0.963194
[2022-03-31 05:35:05 | train] - Train Epoch: [89] [704000/1281167 (55%)]	Loss: 0.743940
[2022-03-31 05:35:24 | train] - Train Epoch: [89] [716800/1281167 (56%)]	Loss: 0.646778
[2022-03-31 05:35:44 | train] - Train Epoch: [89] [729600/1281167 (57%)]	Loss: 0.984947
[2022-03-31 05:36:03 | train] - Train Epoch: [89] [742400/1281167 (58%)]	Loss: 0.948408
[2022-03-31 05:36:23 | train] - Train Epoch: [89] [755200/1281167 (59%)]	Loss: 0.776157
[2022-03-31 05:36:42 | train] - Train Epoch: [89] [768000/1281167 (60%)]	Loss: 0.907136
[2022-03-31 05:37:02 | train] - Train Epoch: [89] [780800/1281167 (61%)]	Loss: 0.931064
[2022-03-31 05:37:22 | train] - Train Epoch: [89] [793600/1281167 (62%)]	Loss: 0.720432
[2022-03-31 05:37:41 | train] - Train Epoch: [89] [806400/1281167 (63%)]	Loss: 0.841324
[2022-03-31 05:38:01 | train] - Train Epoch: [89] [819200/1281167 (64%)]	Loss: 1.128498
[2022-03-31 05:38:21 | train] - Train Epoch: [89] [832000/1281167 (65%)]	Loss: 0.870673
[2022-03-31 05:38:40 | train] - Train Epoch: [89] [844800/1281167 (66%)]	Loss: 0.834705
[2022-03-31 05:39:00 | train] - Train Epoch: [89] [857600/1281167 (67%)]	Loss: 0.988060
[2022-03-31 05:39:19 | train] - Train Epoch: [89] [870400/1281167 (68%)]	Loss: 0.821507
[2022-03-31 05:39:40 | train] - Train Epoch: [89] [883200/1281167 (69%)]	Loss: 0.825772
[2022-03-31 05:40:00 | train] - Train Epoch: [89] [896000/1281167 (70%)]	Loss: 0.766190
[2022-03-31 05:40:19 | train] - Train Epoch: [89] [908800/1281167 (71%)]	Loss: 1.037725
[2022-03-31 05:40:39 | train] - Train Epoch: [89] [921600/1281167 (72%)]	Loss: 0.866792
[2022-03-31 05:40:58 | train] - Train Epoch: [89] [934400/1281167 (73%)]	Loss: 0.858737
[2022-03-31 05:41:18 | train] - Train Epoch: [89] [947200/1281167 (74%)]	Loss: 0.755467
[2022-03-31 05:41:38 | train] - Train Epoch: [89] [960000/1281167 (75%)]	Loss: 0.725341
[2022-03-31 05:41:58 | train] - Train Epoch: [89] [972800/1281167 (76%)]	Loss: 0.843264
[2022-03-31 05:42:18 | train] - Train Epoch: [89] [985600/1281167 (77%)]	Loss: 0.751848
[2022-03-31 05:42:38 | train] - Train Epoch: [89] [998400/1281167 (78%)]	Loss: 0.966346
[2022-03-31 05:42:57 | train] - Train Epoch: [89] [1011200/1281167 (79%)]	Loss: 0.664774
[2022-03-31 05:43:17 | train] - Train Epoch: [89] [1024000/1281167 (80%)]	Loss: 0.795865
[2022-03-31 05:43:37 | train] - Train Epoch: [89] [1036800/1281167 (81%)]	Loss: 0.700803
[2022-03-31 05:43:56 | train] - Train Epoch: [89] [1049600/1281167 (82%)]	Loss: 0.603491
[2022-03-31 05:44:16 | train] - Train Epoch: [89] [1062400/1281167 (83%)]	Loss: 0.928398
[2022-03-31 05:44:36 | train] - Train Epoch: [89] [1075200/1281167 (84%)]	Loss: 1.146683
[2022-03-31 05:44:55 | train] - Train Epoch: [89] [1088000/1281167 (85%)]	Loss: 0.835263
[2022-03-31 05:45:14 | train] - Train Epoch: [89] [1100800/1281167 (86%)]	Loss: 0.701763
[2022-03-31 05:45:33 | train] - Train Epoch: [89] [1113600/1281167 (87%)]	Loss: 1.043172
[2022-03-31 05:45:53 | train] - Train Epoch: [89] [1126400/1281167 (88%)]	Loss: 0.750106
[2022-03-31 05:46:13 | train] - Train Epoch: [89] [1139200/1281167 (89%)]	Loss: 0.870192
[2022-03-31 05:46:33 | train] - Train Epoch: [89] [1152000/1281167 (90%)]	Loss: 0.998814
[2022-03-31 05:46:52 | train] - Train Epoch: [89] [1164800/1281167 (91%)]	Loss: 0.826689
[2022-03-31 05:47:12 | train] - Train Epoch: [89] [1177600/1281167 (92%)]	Loss: 0.878910
[2022-03-31 05:47:31 | train] - Train Epoch: [89] [1190400/1281167 (93%)]	Loss: 0.926918
[2022-03-31 05:47:50 | train] - Train Epoch: [89] [1203200/1281167 (94%)]	Loss: 1.035046
[2022-03-31 05:48:10 | train] - Train Epoch: [89] [1216000/1281167 (95%)]	Loss: 0.877159
[2022-03-31 05:48:31 | train] - Train Epoch: [89] [1228800/1281167 (96%)]	Loss: 0.770210
[2022-03-31 05:48:50 | train] - Train Epoch: [89] [1241600/1281167 (97%)]	Loss: 0.759323
[2022-03-31 05:49:11 | train] - Train Epoch: [89] [1254400/1281167 (98%)]	Loss: 0.873005
[2022-03-31 05:49:30 | train] - Train Epoch: [89] [1267200/1281167 (99%)]	Loss: 0.806691
[2022-03-31 05:49:49 | train] - Train Epoch: [89] [1280000/1281167 (100%)]	Loss: 0.841932
[2022-03-31 05:49:51 | train] - Train Epoch: [89]	 Average Loss: 0.858341	 Total Acc : 78.9853	 Total Top5 Acc : 92.3172
[2022-03-31 05:49:51 | train] - -------89 epoch end-----------
========================================
-------89 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 05:51:22 | train] - 
Epoch [89] Test set: Average loss: 1.3758, Accuracy: 34977/50000 (69.9301%), Top-5 Accuracy: 88.9490%

[2022-03-31 05:51:22 | train] - save intermediate epoch [89] result


[2022-03-31 05:51:29 | train] - -------90 epoch start-----------
[2022-03-31 05:51:29 | train] - -------- logging 90 batch layer input tensor ------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
batch_grad_output shape : torch.Size([128, 64, 112, 112])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
[2022-03-31 05:51:52 | train] - -------- logging end 90 --------------------
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1000])
batch_grad_output tuples shape : [128]
[2022-03-31 05:51:54 | train] - Train Epoch: [90] [0/1281167 (0%)]	Loss: 1.209298
[2022-03-31 05:52:14 | train] - Train Epoch: [90] [12800/1281167 (1%)]	Loss: 1.009282
[2022-03-31 05:52:33 | train] - Train Epoch: [90] [25600/1281167 (2%)]	Loss: 0.864983
[2022-03-31 05:52:52 | train] - Train Epoch: [90] [38400/1281167 (3%)]	Loss: 0.990730
[2022-03-31 05:53:12 | train] - Train Epoch: [90] [51200/1281167 (4%)]	Loss: 0.587870
[2022-03-31 05:53:31 | train] - Train Epoch: [90] [64000/1281167 (5%)]	Loss: 0.928250
[2022-03-31 05:53:50 | train] - Train Epoch: [90] [76800/1281167 (6%)]	Loss: 0.641984
[2022-03-31 05:54:10 | train] - Train Epoch: [90] [89600/1281167 (7%)]	Loss: 0.848016
[2022-03-31 05:54:30 | train] - Train Epoch: [90] [102400/1281167 (8%)]	Loss: 0.645622
[2022-03-31 05:54:49 | train] - Train Epoch: [90] [115200/1281167 (9%)]	Loss: 0.787383
[2022-03-31 05:55:08 | train] - Train Epoch: [90] [128000/1281167 (10%)]	Loss: 0.666176
[2022-03-31 05:55:28 | train] - Train Epoch: [90] [140800/1281167 (11%)]	Loss: 1.095052
[2022-03-31 05:55:47 | train] - Train Epoch: [90] [153600/1281167 (12%)]	Loss: 0.834074
[2022-03-31 05:56:06 | train] - Train Epoch: [90] [166400/1281167 (13%)]	Loss: 0.614044
[2022-03-31 05:56:25 | train] - Train Epoch: [90] [179200/1281167 (14%)]	Loss: 0.896415
[2022-03-31 05:56:45 | train] - Train Epoch: [90] [192000/1281167 (15%)]	Loss: 0.928891
[2022-03-31 05:57:05 | train] - Train Epoch: [90] [204800/1281167 (16%)]	Loss: 0.571793
[2022-03-31 05:57:25 | train] - Train Epoch: [90] [217600/1281167 (17%)]	Loss: 1.053892
[2022-03-31 05:57:45 | train] - Train Epoch: [90] [230400/1281167 (18%)]	Loss: 0.920028
[2022-03-31 05:58:04 | train] - Train Epoch: [90] [243200/1281167 (19%)]	Loss: 0.679088
[2022-03-31 05:58:23 | train] - Train Epoch: [90] [256000/1281167 (20%)]	Loss: 0.913282
[2022-03-31 05:58:43 | train] - Train Epoch: [90] [268800/1281167 (21%)]	Loss: 1.128402
[2022-03-31 05:59:02 | train] - Train Epoch: [90] [281600/1281167 (22%)]	Loss: 0.824813
[2022-03-31 05:59:22 | train] - Train Epoch: [90] [294400/1281167 (23%)]	Loss: 0.841612
[2022-03-31 05:59:42 | train] - Train Epoch: [90] [307200/1281167 (24%)]	Loss: 1.061528
[2022-03-31 06:00:01 | train] - Train Epoch: [90] [320000/1281167 (25%)]	Loss: 1.064487
[2022-03-31 06:00:21 | train] - Train Epoch: [90] [332800/1281167 (26%)]	Loss: 0.857426
[2022-03-31 06:00:40 | train] - Train Epoch: [90] [345600/1281167 (27%)]	Loss: 0.822848
[2022-03-31 06:01:00 | train] - Train Epoch: [90] [358400/1281167 (28%)]	Loss: 1.081374
[2022-03-31 06:01:21 | train] - Train Epoch: [90] [371200/1281167 (29%)]	Loss: 0.588498
[2022-03-31 06:01:41 | train] - Train Epoch: [90] [384000/1281167 (30%)]	Loss: 0.934352
[2022-03-31 06:02:01 | train] - Train Epoch: [90] [396800/1281167 (31%)]	Loss: 0.855034
[2022-03-31 06:02:21 | train] - Train Epoch: [90] [409600/1281167 (32%)]	Loss: 0.899862
[2022-03-31 06:02:41 | train] - Train Epoch: [90] [422400/1281167 (33%)]	Loss: 0.955846
[2022-03-31 06:03:00 | train] - Train Epoch: [90] [435200/1281167 (34%)]	Loss: 1.098141
[2022-03-31 06:03:19 | train] - Train Epoch: [90] [448000/1281167 (35%)]	Loss: 0.583302
[2022-03-31 06:03:39 | train] - Train Epoch: [90] [460800/1281167 (36%)]	Loss: 0.773977
[2022-03-31 06:03:58 | train] - Train Epoch: [90] [473600/1281167 (37%)]	Loss: 0.840368
[2022-03-31 06:04:18 | train] - Train Epoch: [90] [486400/1281167 (38%)]	Loss: 1.066177
[2022-03-31 06:04:38 | train] - Train Epoch: [90] [499200/1281167 (39%)]	Loss: 0.620013
[2022-03-31 06:04:58 | train] - Train Epoch: [90] [512000/1281167 (40%)]	Loss: 0.977335
[2022-03-31 06:05:17 | train] - Train Epoch: [90] [524800/1281167 (41%)]	Loss: 0.939141
[2022-03-31 06:05:37 | train] - Train Epoch: [90] [537600/1281167 (42%)]	Loss: 0.754948
[2022-03-31 06:05:57 | train] - Train Epoch: [90] [550400/1281167 (43%)]	Loss: 0.793612
[2022-03-31 06:06:17 | train] - Train Epoch: [90] [563200/1281167 (44%)]	Loss: 0.808785
[2022-03-31 06:06:36 | train] - Train Epoch: [90] [576000/1281167 (45%)]	Loss: 0.826337
[2022-03-31 06:06:56 | train] - Train Epoch: [90] [588800/1281167 (46%)]	Loss: 0.764915
[2022-03-31 06:07:16 | train] - Train Epoch: [90] [601600/1281167 (47%)]	Loss: 0.730942
[2022-03-31 06:07:36 | train] - Train Epoch: [90] [614400/1281167 (48%)]	Loss: 0.876790
[2022-03-31 06:07:55 | train] - Train Epoch: [90] [627200/1281167 (49%)]	Loss: 0.754219
[2022-03-31 06:08:15 | train] - Train Epoch: [90] [640000/1281167 (50%)]	Loss: 1.134642
[2022-03-31 06:08:35 | train] - Train Epoch: [90] [652800/1281167 (51%)]	Loss: 0.871861
[2022-03-31 06:08:54 | train] - Train Epoch: [90] [665600/1281167 (52%)]	Loss: 0.805367
[2022-03-31 06:09:13 | train] - Train Epoch: [90] [678400/1281167 (53%)]	Loss: 0.806001
[2022-03-31 06:09:33 | train] - Train Epoch: [90] [691200/1281167 (54%)]	Loss: 0.886631
[2022-03-31 06:09:53 | train] - Train Epoch: [90] [704000/1281167 (55%)]	Loss: 0.793550
[2022-03-31 06:10:12 | train] - Train Epoch: [90] [716800/1281167 (56%)]	Loss: 0.727268
[2022-03-31 06:10:31 | train] - Train Epoch: [90] [729600/1281167 (57%)]	Loss: 1.060726
[2022-03-31 06:10:51 | train] - Train Epoch: [90] [742400/1281167 (58%)]	Loss: 0.906781
[2022-03-31 06:11:10 | train] - Train Epoch: [90] [755200/1281167 (59%)]	Loss: 0.684077
[2022-03-31 06:11:30 | train] - Train Epoch: [90] [768000/1281167 (60%)]	Loss: 0.936504
[2022-03-31 06:11:50 | train] - Train Epoch: [90] [780800/1281167 (61%)]	Loss: 0.818282
[2022-03-31 06:12:09 | train] - Train Epoch: [90] [793600/1281167 (62%)]	Loss: 0.996971
[2022-03-31 06:12:29 | train] - Train Epoch: [90] [806400/1281167 (63%)]	Loss: 0.867130
[2022-03-31 06:12:48 | train] - Train Epoch: [90] [819200/1281167 (64%)]	Loss: 0.956912
[2022-03-31 06:13:08 | train] - Train Epoch: [90] [832000/1281167 (65%)]	Loss: 0.888125
[2022-03-31 06:13:28 | train] - Train Epoch: [90] [844800/1281167 (66%)]	Loss: 1.053392
[2022-03-31 06:13:48 | train] - Train Epoch: [90] [857600/1281167 (67%)]	Loss: 0.756572
[2022-03-31 06:14:08 | train] - Train Epoch: [90] [870400/1281167 (68%)]	Loss: 1.040868
[2022-03-31 06:14:28 | train] - Train Epoch: [90] [883200/1281167 (69%)]	Loss: 0.764595
[2022-03-31 06:14:48 | train] - Train Epoch: [90] [896000/1281167 (70%)]	Loss: 0.948253
[2022-03-31 06:15:07 | train] - Train Epoch: [90] [908800/1281167 (71%)]	Loss: 0.625911
[2022-03-31 06:15:27 | train] - Train Epoch: [90] [921600/1281167 (72%)]	Loss: 0.991223
[2022-03-31 06:15:47 | train] - Train Epoch: [90] [934400/1281167 (73%)]	Loss: 0.822955
[2022-03-31 06:16:07 | train] - Train Epoch: [90] [947200/1281167 (74%)]	Loss: 1.007776
[2022-03-31 06:16:26 | train] - Train Epoch: [90] [960000/1281167 (75%)]	Loss: 0.728815
[2022-03-31 06:16:46 | train] - Train Epoch: [90] [972800/1281167 (76%)]	Loss: 0.697363
[2022-03-31 06:17:06 | train] - Train Epoch: [90] [985600/1281167 (77%)]	Loss: 0.680276
[2022-03-31 06:17:25 | train] - Train Epoch: [90] [998400/1281167 (78%)]	Loss: 0.775471
[2022-03-31 06:17:45 | train] - Train Epoch: [90] [1011200/1281167 (79%)]	Loss: 0.834880
[2022-03-31 06:18:04 | train] - Train Epoch: [90] [1024000/1281167 (80%)]	Loss: 0.893846
[2022-03-31 06:18:24 | train] - Train Epoch: [90] [1036800/1281167 (81%)]	Loss: 1.016194
[2022-03-31 06:18:43 | train] - Train Epoch: [90] [1049600/1281167 (82%)]	Loss: 0.981719
[2022-03-31 06:19:03 | train] - Train Epoch: [90] [1062400/1281167 (83%)]	Loss: 0.751410
[2022-03-31 06:19:23 | train] - Train Epoch: [90] [1075200/1281167 (84%)]	Loss: 0.774271
[2022-03-31 06:19:43 | train] - Train Epoch: [90] [1088000/1281167 (85%)]	Loss: 0.801202
[2022-03-31 06:20:02 | train] - Train Epoch: [90] [1100800/1281167 (86%)]	Loss: 0.719327
[2022-03-31 06:20:22 | train] - Train Epoch: [90] [1113600/1281167 (87%)]	Loss: 0.965196
[2022-03-31 06:20:41 | train] - Train Epoch: [90] [1126400/1281167 (88%)]	Loss: 0.702480
[2022-03-31 06:21:01 | train] - Train Epoch: [90] [1139200/1281167 (89%)]	Loss: 0.935658
[2022-03-31 06:21:21 | train] - Train Epoch: [90] [1152000/1281167 (90%)]	Loss: 0.752017
[2022-03-31 06:21:40 | train] - Train Epoch: [90] [1164800/1281167 (91%)]	Loss: 0.589623
[2022-03-31 06:22:01 | train] - Train Epoch: [90] [1177600/1281167 (92%)]	Loss: 0.846629
[2022-03-31 06:22:21 | train] - Train Epoch: [90] [1190400/1281167 (93%)]	Loss: 0.747447
[2022-03-31 06:22:40 | train] - Train Epoch: [90] [1203200/1281167 (94%)]	Loss: 0.914526
[2022-03-31 06:23:00 | train] - Train Epoch: [90] [1216000/1281167 (95%)]	Loss: 1.179874
[2022-03-31 06:23:20 | train] - Train Epoch: [90] [1228800/1281167 (96%)]	Loss: 0.838153
[2022-03-31 06:23:39 | train] - Train Epoch: [90] [1241600/1281167 (97%)]	Loss: 1.161749
[2022-03-31 06:23:58 | train] - Train Epoch: [90] [1254400/1281167 (98%)]	Loss: 1.054118
[2022-03-31 06:24:18 | train] - Train Epoch: [90] [1267200/1281167 (99%)]	Loss: 0.938196
[2022-03-31 06:24:38 | train] - Train Epoch: [90] [1280000/1281167 (100%)]	Loss: 1.055797
[2022-03-31 06:24:39 | train] - Train Epoch: [90]	 Average Loss: 0.855942	 Total Acc : 79.0924	 Total Top5 Acc : 92.3242
[2022-03-31 06:24:39 | train] - -------90 epoch end-----------
========================================
-------90 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 06:26:10 | train] - 
Epoch [90] Test set: Average loss: 1.3808, Accuracy: 34947/50000 (69.8701%), Top-5 Accuracy: 88.8651%

[2022-03-31 06:26:10 | train] - save intermediate epoch [90] result


[2022-03-31 06:26:17 | train] - -------91 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 06:26:19 | train] - Train Epoch: [91] [0/1281167 (0%)]	Loss: 0.882254
[2022-03-31 06:26:40 | train] - Train Epoch: [91] [12800/1281167 (1%)]	Loss: 0.840448
[2022-03-31 06:27:02 | train] - Train Epoch: [91] [25600/1281167 (2%)]	Loss: 0.605302
[2022-03-31 06:27:23 | train] - Train Epoch: [91] [38400/1281167 (3%)]	Loss: 0.939867
[2022-03-31 06:27:45 | train] - Train Epoch: [91] [51200/1281167 (4%)]	Loss: 0.879121
[2022-03-31 06:28:04 | train] - Train Epoch: [91] [64000/1281167 (5%)]	Loss: 0.715478
[2022-03-31 06:28:24 | train] - Train Epoch: [91] [76800/1281167 (6%)]	Loss: 0.756297
[2022-03-31 06:28:44 | train] - Train Epoch: [91] [89600/1281167 (7%)]	Loss: 0.881660
[2022-03-31 06:29:04 | train] - Train Epoch: [91] [102400/1281167 (8%)]	Loss: 0.747435
[2022-03-31 06:29:24 | train] - Train Epoch: [91] [115200/1281167 (9%)]	Loss: 0.810057
[2022-03-31 06:29:44 | train] - Train Epoch: [91] [128000/1281167 (10%)]	Loss: 0.981441
[2022-03-31 06:30:06 | train] - Train Epoch: [91] [140800/1281167 (11%)]	Loss: 0.783208
[2022-03-31 06:30:28 | train] - Train Epoch: [91] [153600/1281167 (12%)]	Loss: 0.753187
[2022-03-31 06:30:49 | train] - Train Epoch: [91] [166400/1281167 (13%)]	Loss: 0.759043
[2022-03-31 06:31:10 | train] - Train Epoch: [91] [179200/1281167 (14%)]	Loss: 0.780940
[2022-03-31 06:31:29 | train] - Train Epoch: [91] [192000/1281167 (15%)]	Loss: 0.844686
[2022-03-31 06:31:49 | train] - Train Epoch: [91] [204800/1281167 (16%)]	Loss: 0.760046
[2022-03-31 06:32:10 | train] - Train Epoch: [91] [217600/1281167 (17%)]	Loss: 1.009070
[2022-03-31 06:32:31 | train] - Train Epoch: [91] [230400/1281167 (18%)]	Loss: 0.849478
[2022-03-31 06:32:52 | train] - Train Epoch: [91] [243200/1281167 (19%)]	Loss: 0.712119
[2022-03-31 06:33:11 | train] - Train Epoch: [91] [256000/1281167 (20%)]	Loss: 0.802945
[2022-03-31 06:33:32 | train] - Train Epoch: [91] [268800/1281167 (21%)]	Loss: 0.738745
[2022-03-31 06:33:53 | train] - Train Epoch: [91] [281600/1281167 (22%)]	Loss: 1.003147
[2022-03-31 06:34:12 | train] - Train Epoch: [91] [294400/1281167 (23%)]	Loss: 0.716510
[2022-03-31 06:34:33 | train] - Train Epoch: [91] [307200/1281167 (24%)]	Loss: 0.986580
[2022-03-31 06:34:54 | train] - Train Epoch: [91] [320000/1281167 (25%)]	Loss: 1.021715
[2022-03-31 06:35:15 | train] - Train Epoch: [91] [332800/1281167 (26%)]	Loss: 0.775954
[2022-03-31 06:35:36 | train] - Train Epoch: [91] [345600/1281167 (27%)]	Loss: 0.873814
[2022-03-31 06:35:56 | train] - Train Epoch: [91] [358400/1281167 (28%)]	Loss: 0.568319
[2022-03-31 06:36:17 | train] - Train Epoch: [91] [371200/1281167 (29%)]	Loss: 0.850088
[2022-03-31 06:36:39 | train] - Train Epoch: [91] [384000/1281167 (30%)]	Loss: 0.672891
[2022-03-31 06:37:00 | train] - Train Epoch: [91] [396800/1281167 (31%)]	Loss: 0.803951
[2022-03-31 06:37:21 | train] - Train Epoch: [91] [409600/1281167 (32%)]	Loss: 0.835200
[2022-03-31 06:37:43 | train] - Train Epoch: [91] [422400/1281167 (33%)]	Loss: 0.813728
[2022-03-31 06:38:04 | train] - Train Epoch: [91] [435200/1281167 (34%)]	Loss: 0.816674
[2022-03-31 06:38:25 | train] - Train Epoch: [91] [448000/1281167 (35%)]	Loss: 0.843307
[2022-03-31 06:38:47 | train] - Train Epoch: [91] [460800/1281167 (36%)]	Loss: 0.709209
[2022-03-31 06:39:08 | train] - Train Epoch: [91] [473600/1281167 (37%)]	Loss: 0.813427
[2022-03-31 06:39:29 | train] - Train Epoch: [91] [486400/1281167 (38%)]	Loss: 0.946234
[2022-03-31 06:39:50 | train] - Train Epoch: [91] [499200/1281167 (39%)]	Loss: 0.959171
[2022-03-31 06:40:12 | train] - Train Epoch: [91] [512000/1281167 (40%)]	Loss: 0.943883
[2022-03-31 06:40:33 | train] - Train Epoch: [91] [524800/1281167 (41%)]	Loss: 0.866879
[2022-03-31 06:40:55 | train] - Train Epoch: [91] [537600/1281167 (42%)]	Loss: 0.889269
[2022-03-31 06:41:15 | train] - Train Epoch: [91] [550400/1281167 (43%)]	Loss: 0.788741
[2022-03-31 06:41:35 | train] - Train Epoch: [91] [563200/1281167 (44%)]	Loss: 0.814558
[2022-03-31 06:41:57 | train] - Train Epoch: [91] [576000/1281167 (45%)]	Loss: 1.083249
[2022-03-31 06:42:19 | train] - Train Epoch: [91] [588800/1281167 (46%)]	Loss: 0.725974
[2022-03-31 06:42:40 | train] - Train Epoch: [91] [601600/1281167 (47%)]	Loss: 0.995166
[2022-03-31 06:43:02 | train] - Train Epoch: [91] [614400/1281167 (48%)]	Loss: 0.830422
[2022-03-31 06:43:23 | train] - Train Epoch: [91] [627200/1281167 (49%)]	Loss: 0.771035
[2022-03-31 06:43:44 | train] - Train Epoch: [91] [640000/1281167 (50%)]	Loss: 0.785958
[2022-03-31 06:44:06 | train] - Train Epoch: [91] [652800/1281167 (51%)]	Loss: 1.079449
[2022-03-31 06:44:27 | train] - Train Epoch: [91] [665600/1281167 (52%)]	Loss: 0.743465
[2022-03-31 06:44:46 | train] - Train Epoch: [91] [678400/1281167 (53%)]	Loss: 0.905585
[2022-03-31 06:45:06 | train] - Train Epoch: [91] [691200/1281167 (54%)]	Loss: 0.788543
[2022-03-31 06:45:25 | train] - Train Epoch: [91] [704000/1281167 (55%)]	Loss: 0.733395
[2022-03-31 06:45:45 | train] - Train Epoch: [91] [716800/1281167 (56%)]	Loss: 0.879752
[2022-03-31 06:46:05 | train] - Train Epoch: [91] [729600/1281167 (57%)]	Loss: 0.912904
[2022-03-31 06:46:24 | train] - Train Epoch: [91] [742400/1281167 (58%)]	Loss: 1.076923
[2022-03-31 06:46:44 | train] - Train Epoch: [91] [755200/1281167 (59%)]	Loss: 0.888949
[2022-03-31 06:47:04 | train] - Train Epoch: [91] [768000/1281167 (60%)]	Loss: 0.729870
[2022-03-31 06:47:24 | train] - Train Epoch: [91] [780800/1281167 (61%)]	Loss: 0.782610
[2022-03-31 06:47:44 | train] - Train Epoch: [91] [793600/1281167 (62%)]	Loss: 0.910229
[2022-03-31 06:48:03 | train] - Train Epoch: [91] [806400/1281167 (63%)]	Loss: 0.823063
[2022-03-31 06:48:23 | train] - Train Epoch: [91] [819200/1281167 (64%)]	Loss: 1.135699
[2022-03-31 06:48:43 | train] - Train Epoch: [91] [832000/1281167 (65%)]	Loss: 1.105227
[2022-03-31 06:49:03 | train] - Train Epoch: [91] [844800/1281167 (66%)]	Loss: 0.845342
[2022-03-31 06:49:22 | train] - Train Epoch: [91] [857600/1281167 (67%)]	Loss: 0.858319
[2022-03-31 06:49:42 | train] - Train Epoch: [91] [870400/1281167 (68%)]	Loss: 0.709516
[2022-03-31 06:50:01 | train] - Train Epoch: [91] [883200/1281167 (69%)]	Loss: 0.910111
[2022-03-31 06:50:21 | train] - Train Epoch: [91] [896000/1281167 (70%)]	Loss: 1.133979
[2022-03-31 06:50:41 | train] - Train Epoch: [91] [908800/1281167 (71%)]	Loss: 0.541335
[2022-03-31 06:51:01 | train] - Train Epoch: [91] [921600/1281167 (72%)]	Loss: 0.914719
[2022-03-31 06:51:20 | train] - Train Epoch: [91] [934400/1281167 (73%)]	Loss: 0.607635
[2022-03-31 06:51:40 | train] - Train Epoch: [91] [947200/1281167 (74%)]	Loss: 0.784740
[2022-03-31 06:52:00 | train] - Train Epoch: [91] [960000/1281167 (75%)]	Loss: 0.836536
[2022-03-31 06:52:19 | train] - Train Epoch: [91] [972800/1281167 (76%)]	Loss: 0.729063
[2022-03-31 06:52:39 | train] - Train Epoch: [91] [985600/1281167 (77%)]	Loss: 0.869332
[2022-03-31 06:52:59 | train] - Train Epoch: [91] [998400/1281167 (78%)]	Loss: 0.917435
[2022-03-31 06:53:18 | train] - Train Epoch: [91] [1011200/1281167 (79%)]	Loss: 0.715955
[2022-03-31 06:53:37 | train] - Train Epoch: [91] [1024000/1281167 (80%)]	Loss: 0.633981
[2022-03-31 06:53:58 | train] - Train Epoch: [91] [1036800/1281167 (81%)]	Loss: 0.738010
[2022-03-31 06:54:18 | train] - Train Epoch: [91] [1049600/1281167 (82%)]	Loss: 0.842049
[2022-03-31 06:54:38 | train] - Train Epoch: [91] [1062400/1281167 (83%)]	Loss: 0.792253
[2022-03-31 06:54:57 | train] - Train Epoch: [91] [1075200/1281167 (84%)]	Loss: 0.765831
[2022-03-31 06:55:17 | train] - Train Epoch: [91] [1088000/1281167 (85%)]	Loss: 0.912995
[2022-03-31 06:55:36 | train] - Train Epoch: [91] [1100800/1281167 (86%)]	Loss: 0.588950
[2022-03-31 06:55:55 | train] - Train Epoch: [91] [1113600/1281167 (87%)]	Loss: 0.882662
[2022-03-31 06:56:15 | train] - Train Epoch: [91] [1126400/1281167 (88%)]	Loss: 0.684960
[2022-03-31 06:56:35 | train] - Train Epoch: [91] [1139200/1281167 (89%)]	Loss: 1.129149
[2022-03-31 06:56:55 | train] - Train Epoch: [91] [1152000/1281167 (90%)]	Loss: 0.852716
[2022-03-31 06:57:15 | train] - Train Epoch: [91] [1164800/1281167 (91%)]	Loss: 0.816212
[2022-03-31 06:57:34 | train] - Train Epoch: [91] [1177600/1281167 (92%)]	Loss: 0.917170
[2022-03-31 06:57:55 | train] - Train Epoch: [91] [1190400/1281167 (93%)]	Loss: 1.043427
[2022-03-31 06:58:15 | train] - Train Epoch: [91] [1203200/1281167 (94%)]	Loss: 1.067197
[2022-03-31 06:58:34 | train] - Train Epoch: [91] [1216000/1281167 (95%)]	Loss: 0.655558
[2022-03-31 06:58:54 | train] - Train Epoch: [91] [1228800/1281167 (96%)]	Loss: 0.802663
[2022-03-31 06:59:14 | train] - Train Epoch: [91] [1241600/1281167 (97%)]	Loss: 1.124443
[2022-03-31 06:59:33 | train] - Train Epoch: [91] [1254400/1281167 (98%)]	Loss: 0.934788
[2022-03-31 06:59:53 | train] - Train Epoch: [91] [1267200/1281167 (99%)]	Loss: 0.816171
[2022-03-31 07:00:14 | train] - Train Epoch: [91] [1280000/1281167 (100%)]	Loss: 0.974433
[2022-03-31 07:00:16 | train] - Train Epoch: [91]	 Average Loss: 0.851727	 Total Acc : 79.1753	 Total Top5 Acc : 92.3656
[2022-03-31 07:00:16 | train] - -------91 epoch end-----------
========================================
-------91 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 07:01:47 | train] - 
Epoch [91] Test set: Average loss: 1.3854, Accuracy: 34946/50000 (69.8633%), Top-5 Accuracy: 88.9806%

[2022-03-31 07:01:47 | train] - save intermediate epoch [91] result


[2022-03-31 07:01:54 | train] - -------92 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 07:01:56 | train] - Train Epoch: [92] [0/1281167 (0%)]	Loss: 0.857669
[2022-03-31 07:02:16 | train] - Train Epoch: [92] [12800/1281167 (1%)]	Loss: 0.945375
[2022-03-31 07:02:36 | train] - Train Epoch: [92] [25600/1281167 (2%)]	Loss: 0.712928
[2022-03-31 07:02:58 | train] - Train Epoch: [92] [38400/1281167 (3%)]	Loss: 0.875031
[2022-03-31 07:03:18 | train] - Train Epoch: [92] [51200/1281167 (4%)]	Loss: 0.982625
[2022-03-31 07:03:40 | train] - Train Epoch: [92] [64000/1281167 (5%)]	Loss: 0.550704
[2022-03-31 07:04:01 | train] - Train Epoch: [92] [76800/1281167 (6%)]	Loss: 0.843016
[2022-03-31 07:04:22 | train] - Train Epoch: [92] [89600/1281167 (7%)]	Loss: 0.853436
[2022-03-31 07:04:43 | train] - Train Epoch: [92] [102400/1281167 (8%)]	Loss: 0.905459
[2022-03-31 07:05:05 | train] - Train Epoch: [92] [115200/1281167 (9%)]	Loss: 0.936760
[2022-03-31 07:05:26 | train] - Train Epoch: [92] [128000/1281167 (10%)]	Loss: 0.722719
[2022-03-31 07:05:48 | train] - Train Epoch: [92] [140800/1281167 (11%)]	Loss: 0.879682
[2022-03-31 07:06:08 | train] - Train Epoch: [92] [153600/1281167 (12%)]	Loss: 1.046178
[2022-03-31 07:06:28 | train] - Train Epoch: [92] [166400/1281167 (13%)]	Loss: 0.755437
[2022-03-31 07:06:47 | train] - Train Epoch: [92] [179200/1281167 (14%)]	Loss: 0.839240
[2022-03-31 07:07:06 | train] - Train Epoch: [92] [192000/1281167 (15%)]	Loss: 0.908540
[2022-03-31 07:07:25 | train] - Train Epoch: [92] [204800/1281167 (16%)]	Loss: 0.742680
[2022-03-31 07:07:45 | train] - Train Epoch: [92] [217600/1281167 (17%)]	Loss: 0.762389
[2022-03-31 07:08:04 | train] - Train Epoch: [92] [230400/1281167 (18%)]	Loss: 1.005594
[2022-03-31 07:08:24 | train] - Train Epoch: [92] [243200/1281167 (19%)]	Loss: 0.851503
[2022-03-31 07:08:44 | train] - Train Epoch: [92] [256000/1281167 (20%)]	Loss: 0.900790
[2022-03-31 07:09:04 | train] - Train Epoch: [92] [268800/1281167 (21%)]	Loss: 0.763017
[2022-03-31 07:09:24 | train] - Train Epoch: [92] [281600/1281167 (22%)]	Loss: 0.798267
[2022-03-31 07:09:43 | train] - Train Epoch: [92] [294400/1281167 (23%)]	Loss: 0.770301
[2022-03-31 07:10:01 | train] - Train Epoch: [92] [307200/1281167 (24%)]	Loss: 0.870965
[2022-03-31 07:10:21 | train] - Train Epoch: [92] [320000/1281167 (25%)]	Loss: 1.024782
[2022-03-31 07:10:40 | train] - Train Epoch: [92] [332800/1281167 (26%)]	Loss: 0.830727
[2022-03-31 07:11:00 | train] - Train Epoch: [92] [345600/1281167 (27%)]	Loss: 1.073380
[2022-03-31 07:11:21 | train] - Train Epoch: [92] [358400/1281167 (28%)]	Loss: 0.748749
[2022-03-31 07:11:40 | train] - Train Epoch: [92] [371200/1281167 (29%)]	Loss: 0.846202
[2022-03-31 07:12:00 | train] - Train Epoch: [92] [384000/1281167 (30%)]	Loss: 0.882089
[2022-03-31 07:12:19 | train] - Train Epoch: [92] [396800/1281167 (31%)]	Loss: 1.133815
[2022-03-31 07:12:38 | train] - Train Epoch: [92] [409600/1281167 (32%)]	Loss: 0.868973
[2022-03-31 07:12:58 | train] - Train Epoch: [92] [422400/1281167 (33%)]	Loss: 0.581668
[2022-03-31 07:13:19 | train] - Train Epoch: [92] [435200/1281167 (34%)]	Loss: 0.812356
[2022-03-31 07:13:41 | train] - Train Epoch: [92] [448000/1281167 (35%)]	Loss: 1.244034
[2022-03-31 07:14:03 | train] - Train Epoch: [92] [460800/1281167 (36%)]	Loss: 0.761510
[2022-03-31 07:14:23 | train] - Train Epoch: [92] [473600/1281167 (37%)]	Loss: 1.020424
[2022-03-31 07:14:43 | train] - Train Epoch: [92] [486400/1281167 (38%)]	Loss: 0.896115
[2022-03-31 07:15:04 | train] - Train Epoch: [92] [499200/1281167 (39%)]	Loss: 0.889894
[2022-03-31 07:15:25 | train] - Train Epoch: [92] [512000/1281167 (40%)]	Loss: 0.815748
[2022-03-31 07:15:46 | train] - Train Epoch: [92] [524800/1281167 (41%)]	Loss: 0.859912
[2022-03-31 07:16:08 | train] - Train Epoch: [92] [537600/1281167 (42%)]	Loss: 0.951946
[2022-03-31 07:16:28 | train] - Train Epoch: [92] [550400/1281167 (43%)]	Loss: 0.844834
[2022-03-31 07:16:48 | train] - Train Epoch: [92] [563200/1281167 (44%)]	Loss: 0.847027
[2022-03-31 07:17:09 | train] - Train Epoch: [92] [576000/1281167 (45%)]	Loss: 0.753495
[2022-03-31 07:17:28 | train] - Train Epoch: [92] [588800/1281167 (46%)]	Loss: 0.758560
[2022-03-31 07:17:47 | train] - Train Epoch: [92] [601600/1281167 (47%)]	Loss: 0.649630
[2022-03-31 07:18:07 | train] - Train Epoch: [92] [614400/1281167 (48%)]	Loss: 0.778759
[2022-03-31 07:18:27 | train] - Train Epoch: [92] [627200/1281167 (49%)]	Loss: 1.036247
[2022-03-31 07:18:49 | train] - Train Epoch: [92] [640000/1281167 (50%)]	Loss: 1.006337
[2022-03-31 07:19:09 | train] - Train Epoch: [92] [652800/1281167 (51%)]	Loss: 0.798548
[2022-03-31 07:19:29 | train] - Train Epoch: [92] [665600/1281167 (52%)]	Loss: 1.062550
[2022-03-31 07:19:50 | train] - Train Epoch: [92] [678400/1281167 (53%)]	Loss: 0.883112
[2022-03-31 07:20:11 | train] - Train Epoch: [92] [691200/1281167 (54%)]	Loss: 0.836840
[2022-03-31 07:20:31 | train] - Train Epoch: [92] [704000/1281167 (55%)]	Loss: 0.942307
[2022-03-31 07:20:51 | train] - Train Epoch: [92] [716800/1281167 (56%)]	Loss: 1.099979
[2022-03-31 07:21:11 | train] - Train Epoch: [92] [729600/1281167 (57%)]	Loss: 0.687002
[2022-03-31 07:21:30 | train] - Train Epoch: [92] [742400/1281167 (58%)]	Loss: 0.774556
[2022-03-31 07:21:49 | train] - Train Epoch: [92] [755200/1281167 (59%)]	Loss: 1.070136
[2022-03-31 07:22:08 | train] - Train Epoch: [92] [768000/1281167 (60%)]	Loss: 0.796462
[2022-03-31 07:22:28 | train] - Train Epoch: [92] [780800/1281167 (61%)]	Loss: 0.817441
[2022-03-31 07:22:48 | train] - Train Epoch: [92] [793600/1281167 (62%)]	Loss: 0.739352
[2022-03-31 07:23:07 | train] - Train Epoch: [92] [806400/1281167 (63%)]	Loss: 0.968042
[2022-03-31 07:23:27 | train] - Train Epoch: [92] [819200/1281167 (64%)]	Loss: 0.770104
[2022-03-31 07:23:48 | train] - Train Epoch: [92] [832000/1281167 (65%)]	Loss: 0.799762
[2022-03-31 07:24:07 | train] - Train Epoch: [92] [844800/1281167 (66%)]	Loss: 0.944284
[2022-03-31 07:24:27 | train] - Train Epoch: [92] [857600/1281167 (67%)]	Loss: 0.997164
[2022-03-31 07:24:48 | train] - Train Epoch: [92] [870400/1281167 (68%)]	Loss: 0.893844
[2022-03-31 07:25:08 | train] - Train Epoch: [92] [883200/1281167 (69%)]	Loss: 0.978591
[2022-03-31 07:25:27 | train] - Train Epoch: [92] [896000/1281167 (70%)]	Loss: 0.962600
[2022-03-31 07:25:47 | train] - Train Epoch: [92] [908800/1281167 (71%)]	Loss: 0.978052
[2022-03-31 07:26:08 | train] - Train Epoch: [92] [921600/1281167 (72%)]	Loss: 0.664839
[2022-03-31 07:26:28 | train] - Train Epoch: [92] [934400/1281167 (73%)]	Loss: 0.990891
[2022-03-31 07:26:48 | train] - Train Epoch: [92] [947200/1281167 (74%)]	Loss: 0.770993
[2022-03-31 07:27:08 | train] - Train Epoch: [92] [960000/1281167 (75%)]	Loss: 0.826360
[2022-03-31 07:27:29 | train] - Train Epoch: [92] [972800/1281167 (76%)]	Loss: 1.305428
[2022-03-31 07:27:49 | train] - Train Epoch: [92] [985600/1281167 (77%)]	Loss: 0.886734
[2022-03-31 07:28:09 | train] - Train Epoch: [92] [998400/1281167 (78%)]	Loss: 0.803534
[2022-03-31 07:28:30 | train] - Train Epoch: [92] [1011200/1281167 (79%)]	Loss: 0.849601
[2022-03-31 07:28:50 | train] - Train Epoch: [92] [1024000/1281167 (80%)]	Loss: 0.786298
[2022-03-31 07:29:10 | train] - Train Epoch: [92] [1036800/1281167 (81%)]	Loss: 0.874988
[2022-03-31 07:29:30 | train] - Train Epoch: [92] [1049600/1281167 (82%)]	Loss: 0.768383
[2022-03-31 07:29:49 | train] - Train Epoch: [92] [1062400/1281167 (83%)]	Loss: 0.630428
[2022-03-31 07:30:08 | train] - Train Epoch: [92] [1075200/1281167 (84%)]	Loss: 0.930909
[2022-03-31 07:30:28 | train] - Train Epoch: [92] [1088000/1281167 (85%)]	Loss: 0.647120
[2022-03-31 07:30:48 | train] - Train Epoch: [92] [1100800/1281167 (86%)]	Loss: 1.245639
[2022-03-31 07:31:08 | train] - Train Epoch: [92] [1113600/1281167 (87%)]	Loss: 1.093927
[2022-03-31 07:31:28 | train] - Train Epoch: [92] [1126400/1281167 (88%)]	Loss: 0.991131
[2022-03-31 07:31:48 | train] - Train Epoch: [92] [1139200/1281167 (89%)]	Loss: 0.786726
[2022-03-31 07:32:08 | train] - Train Epoch: [92] [1152000/1281167 (90%)]	Loss: 0.792189
[2022-03-31 07:32:28 | train] - Train Epoch: [92] [1164800/1281167 (91%)]	Loss: 0.688624
[2022-03-31 07:32:48 | train] - Train Epoch: [92] [1177600/1281167 (92%)]	Loss: 0.760320
[2022-03-31 07:33:07 | train] - Train Epoch: [92] [1190400/1281167 (93%)]	Loss: 0.794486
[2022-03-31 07:33:27 | train] - Train Epoch: [92] [1203200/1281167 (94%)]	Loss: 0.909855
[2022-03-31 07:33:47 | train] - Train Epoch: [92] [1216000/1281167 (95%)]	Loss: 1.056994
[2022-03-31 07:34:07 | train] - Train Epoch: [92] [1228800/1281167 (96%)]	Loss: 0.654697
[2022-03-31 07:34:27 | train] - Train Epoch: [92] [1241600/1281167 (97%)]	Loss: 0.925432
[2022-03-31 07:34:48 | train] - Train Epoch: [92] [1254400/1281167 (98%)]	Loss: 0.839931
[2022-03-31 07:35:08 | train] - Train Epoch: [92] [1267200/1281167 (99%)]	Loss: 0.786008
[2022-03-31 07:35:29 | train] - Train Epoch: [92] [1280000/1281167 (100%)]	Loss: 0.758056
[2022-03-31 07:35:30 | train] - Train Epoch: [92]	 Average Loss: 0.848895	 Total Acc : 79.2692	 Total Top5 Acc : 92.3570
[2022-03-31 07:35:30 | train] - -------92 epoch end-----------
========================================
-------92 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 07:37:03 | train] - 
Epoch [92] Test set: Average loss: 1.3711, Accuracy: 34962/50000 (69.9013%), Top-5 Accuracy: 88.9686%

[2022-03-31 07:37:04 | train] - save intermediate epoch [92] result


[2022-03-31 07:37:11 | train] - -------93 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 07:37:13 | train] - Train Epoch: [93] [0/1281167 (0%)]	Loss: 0.991223
[2022-03-31 07:37:36 | train] - Train Epoch: [93] [12800/1281167 (1%)]	Loss: 1.089936
[2022-03-31 07:37:57 | train] - Train Epoch: [93] [25600/1281167 (2%)]	Loss: 1.067795
[2022-03-31 07:38:19 | train] - Train Epoch: [93] [38400/1281167 (3%)]	Loss: 0.801511
[2022-03-31 07:38:40 | train] - Train Epoch: [93] [51200/1281167 (4%)]	Loss: 0.761177
[2022-03-31 07:39:02 | train] - Train Epoch: [93] [64000/1281167 (5%)]	Loss: 1.245892
[2022-03-31 07:39:24 | train] - Train Epoch: [93] [76800/1281167 (6%)]	Loss: 0.877683
[2022-03-31 07:39:45 | train] - Train Epoch: [93] [89600/1281167 (7%)]	Loss: 0.831961
[2022-03-31 07:40:07 | train] - Train Epoch: [93] [102400/1281167 (8%)]	Loss: 0.956089
[2022-03-31 07:40:29 | train] - Train Epoch: [93] [115200/1281167 (9%)]	Loss: 0.739566
[2022-03-31 07:40:50 | train] - Train Epoch: [93] [128000/1281167 (10%)]	Loss: 1.004707
[2022-03-31 07:41:12 | train] - Train Epoch: [93] [140800/1281167 (11%)]	Loss: 0.979514
[2022-03-31 07:41:34 | train] - Train Epoch: [93] [153600/1281167 (12%)]	Loss: 0.859490
[2022-03-31 07:41:55 | train] - Train Epoch: [93] [166400/1281167 (13%)]	Loss: 0.778612
[2022-03-31 07:42:17 | train] - Train Epoch: [93] [179200/1281167 (14%)]	Loss: 0.744669
[2022-03-31 07:42:38 | train] - Train Epoch: [93] [192000/1281167 (15%)]	Loss: 0.932534
[2022-03-31 07:43:00 | train] - Train Epoch: [93] [204800/1281167 (16%)]	Loss: 0.646679
[2022-03-31 07:43:22 | train] - Train Epoch: [93] [217600/1281167 (17%)]	Loss: 0.861449
[2022-03-31 07:43:44 | train] - Train Epoch: [93] [230400/1281167 (18%)]	Loss: 0.544795
[2022-03-31 07:44:06 | train] - Train Epoch: [93] [243200/1281167 (19%)]	Loss: 0.723388
[2022-03-31 07:44:28 | train] - Train Epoch: [93] [256000/1281167 (20%)]	Loss: 0.647959
[2022-03-31 07:44:50 | train] - Train Epoch: [93] [268800/1281167 (21%)]	Loss: 0.860795
[2022-03-31 07:45:12 | train] - Train Epoch: [93] [281600/1281167 (22%)]	Loss: 0.822537
[2022-03-31 07:45:34 | train] - Train Epoch: [93] [294400/1281167 (23%)]	Loss: 0.711313
[2022-03-31 07:45:56 | train] - Train Epoch: [93] [307200/1281167 (24%)]	Loss: 0.888533
[2022-03-31 07:46:18 | train] - Train Epoch: [93] [320000/1281167 (25%)]	Loss: 0.897296
[2022-03-31 07:46:41 | train] - Train Epoch: [93] [332800/1281167 (26%)]	Loss: 0.858752
[2022-03-31 07:47:03 | train] - Train Epoch: [93] [345600/1281167 (27%)]	Loss: 0.820486
[2022-03-31 07:47:25 | train] - Train Epoch: [93] [358400/1281167 (28%)]	Loss: 0.826133
[2022-03-31 07:47:47 | train] - Train Epoch: [93] [371200/1281167 (29%)]	Loss: 0.982330
[2022-03-31 07:48:07 | train] - Train Epoch: [93] [384000/1281167 (30%)]	Loss: 0.712621
[2022-03-31 07:48:29 | train] - Train Epoch: [93] [396800/1281167 (31%)]	Loss: 0.976172
[2022-03-31 07:48:52 | train] - Train Epoch: [93] [409600/1281167 (32%)]	Loss: 0.586155
[2022-03-31 07:49:14 | train] - Train Epoch: [93] [422400/1281167 (33%)]	Loss: 0.903307
[2022-03-31 07:49:35 | train] - Train Epoch: [93] [435200/1281167 (34%)]	Loss: 0.777191
[2022-03-31 07:49:57 | train] - Train Epoch: [93] [448000/1281167 (35%)]	Loss: 0.864331
[2022-03-31 07:50:19 | train] - Train Epoch: [93] [460800/1281167 (36%)]	Loss: 1.207239
[2022-03-31 07:50:42 | train] - Train Epoch: [93] [473600/1281167 (37%)]	Loss: 0.725511
[2022-03-31 07:51:04 | train] - Train Epoch: [93] [486400/1281167 (38%)]	Loss: 1.114874
[2022-03-31 07:51:26 | train] - Train Epoch: [93] [499200/1281167 (39%)]	Loss: 0.782089
[2022-03-31 07:51:47 | train] - Train Epoch: [93] [512000/1281167 (40%)]	Loss: 0.956958
[2022-03-31 07:52:08 | train] - Train Epoch: [93] [524800/1281167 (41%)]	Loss: 0.600192
[2022-03-31 07:52:30 | train] - Train Epoch: [93] [537600/1281167 (42%)]	Loss: 0.993863
[2022-03-31 07:52:52 | train] - Train Epoch: [93] [550400/1281167 (43%)]	Loss: 0.745775
[2022-03-31 07:53:13 | train] - Train Epoch: [93] [563200/1281167 (44%)]	Loss: 1.047115
[2022-03-31 07:53:35 | train] - Train Epoch: [93] [576000/1281167 (45%)]	Loss: 0.707606
[2022-03-31 07:53:55 | train] - Train Epoch: [93] [588800/1281167 (46%)]	Loss: 0.791869
[2022-03-31 07:54:17 | train] - Train Epoch: [93] [601600/1281167 (47%)]	Loss: 1.024547
[2022-03-31 07:54:39 | train] - Train Epoch: [93] [614400/1281167 (48%)]	Loss: 0.868343
[2022-03-31 07:55:00 | train] - Train Epoch: [93] [627200/1281167 (49%)]	Loss: 0.849472
[2022-03-31 07:55:22 | train] - Train Epoch: [93] [640000/1281167 (50%)]	Loss: 0.688304
[2022-03-31 07:55:44 | train] - Train Epoch: [93] [652800/1281167 (51%)]	Loss: 1.124997
[2022-03-31 07:56:05 | train] - Train Epoch: [93] [665600/1281167 (52%)]	Loss: 0.937121
[2022-03-31 07:56:27 | train] - Train Epoch: [93] [678400/1281167 (53%)]	Loss: 0.584854
[2022-03-31 07:56:49 | train] - Train Epoch: [93] [691200/1281167 (54%)]	Loss: 0.787807
[2022-03-31 07:57:11 | train] - Train Epoch: [93] [704000/1281167 (55%)]	Loss: 0.893588
[2022-03-31 07:57:33 | train] - Train Epoch: [93] [716800/1281167 (56%)]	Loss: 0.898887
[2022-03-31 07:57:54 | train] - Train Epoch: [93] [729600/1281167 (57%)]	Loss: 0.807902
[2022-03-31 07:58:16 | train] - Train Epoch: [93] [742400/1281167 (58%)]	Loss: 0.963744
[2022-03-31 07:58:39 | train] - Train Epoch: [93] [755200/1281167 (59%)]	Loss: 1.044749
[2022-03-31 07:58:59 | train] - Train Epoch: [93] [768000/1281167 (60%)]	Loss: 0.928467
[2022-03-31 07:59:21 | train] - Train Epoch: [93] [780800/1281167 (61%)]	Loss: 1.021267
[2022-03-31 07:59:42 | train] - Train Epoch: [93] [793600/1281167 (62%)]	Loss: 0.827886
[2022-03-31 08:00:04 | train] - Train Epoch: [93] [806400/1281167 (63%)]	Loss: 0.704513
[2022-03-31 08:00:25 | train] - Train Epoch: [93] [819200/1281167 (64%)]	Loss: 0.834227
[2022-03-31 08:00:46 | train] - Train Epoch: [93] [832000/1281167 (65%)]	Loss: 0.845553
[2022-03-31 08:01:08 | train] - Train Epoch: [93] [844800/1281167 (66%)]	Loss: 0.705171
[2022-03-31 08:01:29 | train] - Train Epoch: [93] [857600/1281167 (67%)]	Loss: 0.699005
[2022-03-31 08:01:51 | train] - Train Epoch: [93] [870400/1281167 (68%)]	Loss: 0.864878
[2022-03-31 08:02:13 | train] - Train Epoch: [93] [883200/1281167 (69%)]	Loss: 0.998137
[2022-03-31 08:02:35 | train] - Train Epoch: [93] [896000/1281167 (70%)]	Loss: 0.752927
[2022-03-31 08:02:57 | train] - Train Epoch: [93] [908800/1281167 (71%)]	Loss: 0.887256
[2022-03-31 08:03:19 | train] - Train Epoch: [93] [921600/1281167 (72%)]	Loss: 1.005626
[2022-03-31 08:03:40 | train] - Train Epoch: [93] [934400/1281167 (73%)]	Loss: 0.897304
[2022-03-31 08:04:02 | train] - Train Epoch: [93] [947200/1281167 (74%)]	Loss: 0.727075
[2022-03-31 08:04:24 | train] - Train Epoch: [93] [960000/1281167 (75%)]	Loss: 0.781754
[2022-03-31 08:04:46 | train] - Train Epoch: [93] [972800/1281167 (76%)]	Loss: 0.729026
[2022-03-31 08:05:09 | train] - Train Epoch: [93] [985600/1281167 (77%)]	Loss: 0.763065
[2022-03-31 08:05:30 | train] - Train Epoch: [93] [998400/1281167 (78%)]	Loss: 1.186877
[2022-03-31 08:05:52 | train] - Train Epoch: [93] [1011200/1281167 (79%)]	Loss: 0.882731
[2022-03-31 08:06:14 | train] - Train Epoch: [93] [1024000/1281167 (80%)]	Loss: 0.845644
[2022-03-31 08:06:36 | train] - Train Epoch: [93] [1036800/1281167 (81%)]	Loss: 0.675485
[2022-03-31 08:06:58 | train] - Train Epoch: [93] [1049600/1281167 (82%)]	Loss: 0.881769
[2022-03-31 08:07:20 | train] - Train Epoch: [93] [1062400/1281167 (83%)]	Loss: 0.884654
[2022-03-31 08:07:41 | train] - Train Epoch: [93] [1075200/1281167 (84%)]	Loss: 0.875818
[2022-03-31 08:08:03 | train] - Train Epoch: [93] [1088000/1281167 (85%)]	Loss: 0.710301
[2022-03-31 08:08:24 | train] - Train Epoch: [93] [1100800/1281167 (86%)]	Loss: 0.903189
[2022-03-31 08:08:46 | train] - Train Epoch: [93] [1113600/1281167 (87%)]	Loss: 0.880494
[2022-03-31 08:09:08 | train] - Train Epoch: [93] [1126400/1281167 (88%)]	Loss: 0.688463
[2022-03-31 08:09:30 | train] - Train Epoch: [93] [1139200/1281167 (89%)]	Loss: 0.930965
[2022-03-31 08:09:52 | train] - Train Epoch: [93] [1152000/1281167 (90%)]	Loss: 0.563928
[2022-03-31 08:10:15 | train] - Train Epoch: [93] [1164800/1281167 (91%)]	Loss: 0.789407
[2022-03-31 08:10:36 | train] - Train Epoch: [93] [1177600/1281167 (92%)]	Loss: 0.660665
[2022-03-31 08:10:58 | train] - Train Epoch: [93] [1190400/1281167 (93%)]	Loss: 0.878387
[2022-03-31 08:11:20 | train] - Train Epoch: [93] [1203200/1281167 (94%)]	Loss: 1.178854
[2022-03-31 08:11:42 | train] - Train Epoch: [93] [1216000/1281167 (95%)]	Loss: 0.801042
[2022-03-31 08:12:04 | train] - Train Epoch: [93] [1228800/1281167 (96%)]	Loss: 1.078084
[2022-03-31 08:12:25 | train] - Train Epoch: [93] [1241600/1281167 (97%)]	Loss: 0.769658
[2022-03-31 08:12:46 | train] - Train Epoch: [93] [1254400/1281167 (98%)]	Loss: 0.710322
[2022-03-31 08:13:08 | train] - Train Epoch: [93] [1267200/1281167 (99%)]	Loss: 0.939595
[2022-03-31 08:13:30 | train] - Train Epoch: [93] [1280000/1281167 (100%)]	Loss: 0.775190
[2022-03-31 08:13:32 | train] - Train Epoch: [93]	 Average Loss: 0.843874	 Total Acc : 79.3486	 Total Top5 Acc : 92.4640
[2022-03-31 08:13:32 | train] - -------93 epoch end-----------
========================================
-------93 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 08:15:01 | train] - 
Epoch [93] Test set: Average loss: 1.3808, Accuracy: 34846/50000 (69.6671%), Top-5 Accuracy: 88.9098%

[2022-03-31 08:15:01 | train] - save intermediate epoch [93] result


[2022-03-31 08:15:09 | train] - -------94 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 08:15:11 | train] - Train Epoch: [94] [0/1281167 (0%)]	Loss: 0.632741
[2022-03-31 08:15:31 | train] - Train Epoch: [94] [12800/1281167 (1%)]	Loss: 0.825524
[2022-03-31 08:15:51 | train] - Train Epoch: [94] [25600/1281167 (2%)]	Loss: 0.926106
[2022-03-31 08:16:11 | train] - Train Epoch: [94] [38400/1281167 (3%)]	Loss: 0.828782
[2022-03-31 08:16:32 | train] - Train Epoch: [94] [51200/1281167 (4%)]	Loss: 0.821714
[2022-03-31 08:16:53 | train] - Train Epoch: [94] [64000/1281167 (5%)]	Loss: 0.677522
[2022-03-31 08:17:15 | train] - Train Epoch: [94] [76800/1281167 (6%)]	Loss: 0.702789
[2022-03-31 08:17:36 | train] - Train Epoch: [94] [89600/1281167 (7%)]	Loss: 0.786544
[2022-03-31 08:17:58 | train] - Train Epoch: [94] [102400/1281167 (8%)]	Loss: 0.687504
[2022-03-31 08:18:19 | train] - Train Epoch: [94] [115200/1281167 (9%)]	Loss: 0.896286
[2022-03-31 08:18:41 | train] - Train Epoch: [94] [128000/1281167 (10%)]	Loss: 1.033572
[2022-03-31 08:19:03 | train] - Train Epoch: [94] [140800/1281167 (11%)]	Loss: 1.022239
[2022-03-31 08:19:22 | train] - Train Epoch: [94] [153600/1281167 (12%)]	Loss: 0.867417
[2022-03-31 08:19:44 | train] - Train Epoch: [94] [166400/1281167 (13%)]	Loss: 0.898827
[2022-03-31 08:20:06 | train] - Train Epoch: [94] [179200/1281167 (14%)]	Loss: 1.329203
[2022-03-31 08:20:26 | train] - Train Epoch: [94] [192000/1281167 (15%)]	Loss: 0.837604
[2022-03-31 08:20:47 | train] - Train Epoch: [94] [204800/1281167 (16%)]	Loss: 0.629212
[2022-03-31 08:21:08 | train] - Train Epoch: [94] [217600/1281167 (17%)]	Loss: 0.743942
[2022-03-31 08:21:29 | train] - Train Epoch: [94] [230400/1281167 (18%)]	Loss: 0.927252
[2022-03-31 08:21:51 | train] - Train Epoch: [94] [243200/1281167 (19%)]	Loss: 0.864219
[2022-03-31 08:22:12 | train] - Train Epoch: [94] [256000/1281167 (20%)]	Loss: 0.764772
[2022-03-31 08:22:33 | train] - Train Epoch: [94] [268800/1281167 (21%)]	Loss: 1.047214
[2022-03-31 08:22:54 | train] - Train Epoch: [94] [281600/1281167 (22%)]	Loss: 1.036642
[2022-03-31 08:23:15 | train] - Train Epoch: [94] [294400/1281167 (23%)]	Loss: 0.712513
[2022-03-31 08:23:36 | train] - Train Epoch: [94] [307200/1281167 (24%)]	Loss: 0.853726
[2022-03-31 08:23:56 | train] - Train Epoch: [94] [320000/1281167 (25%)]	Loss: 0.636721
[2022-03-31 08:24:16 | train] - Train Epoch: [94] [332800/1281167 (26%)]	Loss: 0.639847
[2022-03-31 08:24:36 | train] - Train Epoch: [94] [345600/1281167 (27%)]	Loss: 0.620720
[2022-03-31 08:24:57 | train] - Train Epoch: [94] [358400/1281167 (28%)]	Loss: 0.667363
[2022-03-31 08:25:18 | train] - Train Epoch: [94] [371200/1281167 (29%)]	Loss: 0.779744
[2022-03-31 08:25:40 | train] - Train Epoch: [94] [384000/1281167 (30%)]	Loss: 0.992592
[2022-03-31 08:26:01 | train] - Train Epoch: [94] [396800/1281167 (31%)]	Loss: 0.658537
[2022-03-31 08:26:22 | train] - Train Epoch: [94] [409600/1281167 (32%)]	Loss: 0.746807
[2022-03-31 08:26:44 | train] - Train Epoch: [94] [422400/1281167 (33%)]	Loss: 0.623999
[2022-03-31 08:27:05 | train] - Train Epoch: [94] [435200/1281167 (34%)]	Loss: 1.012614
[2022-03-31 08:27:26 | train] - Train Epoch: [94] [448000/1281167 (35%)]	Loss: 0.846053
[2022-03-31 08:27:47 | train] - Train Epoch: [94] [460800/1281167 (36%)]	Loss: 0.732578
[2022-03-31 08:28:09 | train] - Train Epoch: [94] [473600/1281167 (37%)]	Loss: 0.811131
[2022-03-31 08:28:31 | train] - Train Epoch: [94] [486400/1281167 (38%)]	Loss: 0.972285
[2022-03-31 08:28:53 | train] - Train Epoch: [94] [499200/1281167 (39%)]	Loss: 0.948918
[2022-03-31 08:29:14 | train] - Train Epoch: [94] [512000/1281167 (40%)]	Loss: 0.923115
[2022-03-31 08:29:35 | train] - Train Epoch: [94] [524800/1281167 (41%)]	Loss: 0.797587
[2022-03-31 08:29:56 | train] - Train Epoch: [94] [537600/1281167 (42%)]	Loss: 0.764650
[2022-03-31 08:30:18 | train] - Train Epoch: [94] [550400/1281167 (43%)]	Loss: 0.734469
[2022-03-31 08:30:39 | train] - Train Epoch: [94] [563200/1281167 (44%)]	Loss: 0.883991
[2022-03-31 08:31:00 | train] - Train Epoch: [94] [576000/1281167 (45%)]	Loss: 0.856257
[2022-03-31 08:31:21 | train] - Train Epoch: [94] [588800/1281167 (46%)]	Loss: 0.946251
[2022-03-31 08:31:42 | train] - Train Epoch: [94] [601600/1281167 (47%)]	Loss: 0.721158
[2022-03-31 08:32:02 | train] - Train Epoch: [94] [614400/1281167 (48%)]	Loss: 0.825035
[2022-03-31 08:32:24 | train] - Train Epoch: [94] [627200/1281167 (49%)]	Loss: 1.010065
[2022-03-31 08:32:44 | train] - Train Epoch: [94] [640000/1281167 (50%)]	Loss: 0.695653
[2022-03-31 08:33:05 | train] - Train Epoch: [94] [652800/1281167 (51%)]	Loss: 0.725185
[2022-03-31 08:33:26 | train] - Train Epoch: [94] [665600/1281167 (52%)]	Loss: 0.779303
[2022-03-31 08:33:47 | train] - Train Epoch: [94] [678400/1281167 (53%)]	Loss: 0.940589
[2022-03-31 08:34:07 | train] - Train Epoch: [94] [691200/1281167 (54%)]	Loss: 0.648834
[2022-03-31 08:34:29 | train] - Train Epoch: [94] [704000/1281167 (55%)]	Loss: 0.723124
[2022-03-31 08:34:49 | train] - Train Epoch: [94] [716800/1281167 (56%)]	Loss: 0.773762
[2022-03-31 08:35:11 | train] - Train Epoch: [94] [729600/1281167 (57%)]	Loss: 0.873127
[2022-03-31 08:35:32 | train] - Train Epoch: [94] [742400/1281167 (58%)]	Loss: 0.908069
[2022-03-31 08:35:53 | train] - Train Epoch: [94] [755200/1281167 (59%)]	Loss: 0.880972
[2022-03-31 08:36:13 | train] - Train Epoch: [94] [768000/1281167 (60%)]	Loss: 0.683084
[2022-03-31 08:36:34 | train] - Train Epoch: [94] [780800/1281167 (61%)]	Loss: 0.561016
[2022-03-31 08:36:55 | train] - Train Epoch: [94] [793600/1281167 (62%)]	Loss: 1.269034
[2022-03-31 08:37:16 | train] - Train Epoch: [94] [806400/1281167 (63%)]	Loss: 0.604500
[2022-03-31 08:37:37 | train] - Train Epoch: [94] [819200/1281167 (64%)]	Loss: 0.999899
[2022-03-31 08:37:58 | train] - Train Epoch: [94] [832000/1281167 (65%)]	Loss: 0.890595
[2022-03-31 08:38:18 | train] - Train Epoch: [94] [844800/1281167 (66%)]	Loss: 0.677452
[2022-03-31 08:38:39 | train] - Train Epoch: [94] [857600/1281167 (67%)]	Loss: 0.789330
[2022-03-31 08:38:59 | train] - Train Epoch: [94] [870400/1281167 (68%)]	Loss: 0.888125
[2022-03-31 08:39:21 | train] - Train Epoch: [94] [883200/1281167 (69%)]	Loss: 0.765114
[2022-03-31 08:39:41 | train] - Train Epoch: [94] [896000/1281167 (70%)]	Loss: 0.845677
[2022-03-31 08:40:00 | train] - Train Epoch: [94] [908800/1281167 (71%)]	Loss: 0.634312
[2022-03-31 08:40:22 | train] - Train Epoch: [94] [921600/1281167 (72%)]	Loss: 0.582525
[2022-03-31 08:40:42 | train] - Train Epoch: [94] [934400/1281167 (73%)]	Loss: 0.637154
[2022-03-31 08:41:02 | train] - Train Epoch: [94] [947200/1281167 (74%)]	Loss: 0.871397
[2022-03-31 08:41:21 | train] - Train Epoch: [94] [960000/1281167 (75%)]	Loss: 0.910299
[2022-03-31 08:41:41 | train] - Train Epoch: [94] [972800/1281167 (76%)]	Loss: 0.736333
[2022-03-31 08:42:01 | train] - Train Epoch: [94] [985600/1281167 (77%)]	Loss: 1.023428
[2022-03-31 08:42:22 | train] - Train Epoch: [94] [998400/1281167 (78%)]	Loss: 0.645111
[2022-03-31 08:42:44 | train] - Train Epoch: [94] [1011200/1281167 (79%)]	Loss: 0.773506
[2022-03-31 08:43:06 | train] - Train Epoch: [94] [1024000/1281167 (80%)]	Loss: 0.847953
[2022-03-31 08:43:27 | train] - Train Epoch: [94] [1036800/1281167 (81%)]	Loss: 0.927862
[2022-03-31 08:43:48 | train] - Train Epoch: [94] [1049600/1281167 (82%)]	Loss: 1.003765
[2022-03-31 08:44:09 | train] - Train Epoch: [94] [1062400/1281167 (83%)]	Loss: 1.175780
[2022-03-31 08:44:31 | train] - Train Epoch: [94] [1075200/1281167 (84%)]	Loss: 0.586961
[2022-03-31 08:44:52 | train] - Train Epoch: [94] [1088000/1281167 (85%)]	Loss: 1.000527
[2022-03-31 08:45:12 | train] - Train Epoch: [94] [1100800/1281167 (86%)]	Loss: 0.955318
[2022-03-31 08:45:32 | train] - Train Epoch: [94] [1113600/1281167 (87%)]	Loss: 0.932429
[2022-03-31 08:45:53 | train] - Train Epoch: [94] [1126400/1281167 (88%)]	Loss: 0.635964
[2022-03-31 08:46:15 | train] - Train Epoch: [94] [1139200/1281167 (89%)]	Loss: 0.978859
[2022-03-31 08:46:36 | train] - Train Epoch: [94] [1152000/1281167 (90%)]	Loss: 1.062417
[2022-03-31 08:46:58 | train] - Train Epoch: [94] [1164800/1281167 (91%)]	Loss: 1.076969
[2022-03-31 08:47:18 | train] - Train Epoch: [94] [1177600/1281167 (92%)]	Loss: 0.954783
[2022-03-31 08:47:39 | train] - Train Epoch: [94] [1190400/1281167 (93%)]	Loss: 0.882198
[2022-03-31 08:48:00 | train] - Train Epoch: [94] [1203200/1281167 (94%)]	Loss: 0.581651
[2022-03-31 08:48:21 | train] - Train Epoch: [94] [1216000/1281167 (95%)]	Loss: 0.837246
[2022-03-31 08:48:42 | train] - Train Epoch: [94] [1228800/1281167 (96%)]	Loss: 0.881476
[2022-03-31 08:49:02 | train] - Train Epoch: [94] [1241600/1281167 (97%)]	Loss: 0.690579
[2022-03-31 08:49:23 | train] - Train Epoch: [94] [1254400/1281167 (98%)]	Loss: 0.693941
[2022-03-31 08:49:44 | train] - Train Epoch: [94] [1267200/1281167 (99%)]	Loss: 0.938069
[2022-03-31 08:50:05 | train] - Train Epoch: [94] [1280000/1281167 (100%)]	Loss: 0.770072
[2022-03-31 08:50:07 | train] - Train Epoch: [94]	 Average Loss: 0.841691	 Total Acc : 79.4306	 Total Top5 Acc : 92.4684
[2022-03-31 08:50:07 | train] - -------94 epoch end-----------
========================================
-------94 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 08:51:43 | train] - 
Epoch [94] Test set: Average loss: 1.3733, Accuracy: 34957/50000 (69.8865%), Top-5 Accuracy: 88.8991%

[2022-03-31 08:51:43 | train] - save intermediate epoch [94] result


[2022-03-31 08:51:51 | train] - -------95 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 08:51:53 | train] - Train Epoch: [95] [0/1281167 (0%)]	Loss: 0.766008
[2022-03-31 08:52:15 | train] - Train Epoch: [95] [12800/1281167 (1%)]	Loss: 0.808975
[2022-03-31 08:52:38 | train] - Train Epoch: [95] [25600/1281167 (2%)]	Loss: 0.715095
[2022-03-31 08:53:00 | train] - Train Epoch: [95] [38400/1281167 (3%)]	Loss: 0.896988
[2022-03-31 08:53:21 | train] - Train Epoch: [95] [51200/1281167 (4%)]	Loss: 0.774382
[2022-03-31 08:53:43 | train] - Train Epoch: [95] [64000/1281167 (5%)]	Loss: 0.693788
[2022-03-31 08:54:04 | train] - Train Epoch: [95] [76800/1281167 (6%)]	Loss: 0.722836
[2022-03-31 08:54:26 | train] - Train Epoch: [95] [89600/1281167 (7%)]	Loss: 0.954307
[2022-03-31 08:54:48 | train] - Train Epoch: [95] [102400/1281167 (8%)]	Loss: 0.977886
[2022-03-31 08:55:10 | train] - Train Epoch: [95] [115200/1281167 (9%)]	Loss: 0.697860
[2022-03-31 08:55:32 | train] - Train Epoch: [95] [128000/1281167 (10%)]	Loss: 0.824983
[2022-03-31 08:55:54 | train] - Train Epoch: [95] [140800/1281167 (11%)]	Loss: 0.663848
[2022-03-31 08:56:16 | train] - Train Epoch: [95] [153600/1281167 (12%)]	Loss: 0.733024
[2022-03-31 08:56:38 | train] - Train Epoch: [95] [166400/1281167 (13%)]	Loss: 0.907669
[2022-03-31 08:56:59 | train] - Train Epoch: [95] [179200/1281167 (14%)]	Loss: 0.913539
[2022-03-31 08:57:22 | train] - Train Epoch: [95] [192000/1281167 (15%)]	Loss: 0.820435
[2022-03-31 08:57:44 | train] - Train Epoch: [95] [204800/1281167 (16%)]	Loss: 0.998347
[2022-03-31 08:58:06 | train] - Train Epoch: [95] [217600/1281167 (17%)]	Loss: 0.841205
[2022-03-31 08:58:28 | train] - Train Epoch: [95] [230400/1281167 (18%)]	Loss: 1.005999
[2022-03-31 08:58:50 | train] - Train Epoch: [95] [243200/1281167 (19%)]	Loss: 0.860585
[2022-03-31 08:59:10 | train] - Train Epoch: [95] [256000/1281167 (20%)]	Loss: 1.056958
[2022-03-31 08:59:33 | train] - Train Epoch: [95] [268800/1281167 (21%)]	Loss: 0.841698
[2022-03-31 08:59:54 | train] - Train Epoch: [95] [281600/1281167 (22%)]	Loss: 0.763780
[2022-03-31 09:00:16 | train] - Train Epoch: [95] [294400/1281167 (23%)]	Loss: 0.733977
[2022-03-31 09:00:37 | train] - Train Epoch: [95] [307200/1281167 (24%)]	Loss: 0.987925
[2022-03-31 09:01:00 | train] - Train Epoch: [95] [320000/1281167 (25%)]	Loss: 0.800398
[2022-03-31 09:01:20 | train] - Train Epoch: [95] [332800/1281167 (26%)]	Loss: 0.778234
[2022-03-31 09:01:42 | train] - Train Epoch: [95] [345600/1281167 (27%)]	Loss: 0.932754
[2022-03-31 09:02:05 | train] - Train Epoch: [95] [358400/1281167 (28%)]	Loss: 0.905199
[2022-03-31 09:02:26 | train] - Train Epoch: [95] [371200/1281167 (29%)]	Loss: 0.800420
[2022-03-31 09:02:49 | train] - Train Epoch: [95] [384000/1281167 (30%)]	Loss: 0.590087
[2022-03-31 09:03:10 | train] - Train Epoch: [95] [396800/1281167 (31%)]	Loss: 0.731800
[2022-03-31 09:03:33 | train] - Train Epoch: [95] [409600/1281167 (32%)]	Loss: 0.954164
[2022-03-31 09:03:55 | train] - Train Epoch: [95] [422400/1281167 (33%)]	Loss: 0.770660
[2022-03-31 09:04:17 | train] - Train Epoch: [95] [435200/1281167 (34%)]	Loss: 0.698723
[2022-03-31 09:04:40 | train] - Train Epoch: [95] [448000/1281167 (35%)]	Loss: 0.671155
[2022-03-31 09:05:02 | train] - Train Epoch: [95] [460800/1281167 (36%)]	Loss: 1.052761
[2022-03-31 09:05:24 | train] - Train Epoch: [95] [473600/1281167 (37%)]	Loss: 0.675701
[2022-03-31 09:05:46 | train] - Train Epoch: [95] [486400/1281167 (38%)]	Loss: 0.781653
[2022-03-31 09:06:08 | train] - Train Epoch: [95] [499200/1281167 (39%)]	Loss: 1.004173
[2022-03-31 09:06:30 | train] - Train Epoch: [95] [512000/1281167 (40%)]	Loss: 1.040424
[2022-03-31 09:06:52 | train] - Train Epoch: [95] [524800/1281167 (41%)]	Loss: 0.734135
[2022-03-31 09:07:14 | train] - Train Epoch: [95] [537600/1281167 (42%)]	Loss: 0.734634
[2022-03-31 09:07:35 | train] - Train Epoch: [95] [550400/1281167 (43%)]	Loss: 0.889571
[2022-03-31 09:07:57 | train] - Train Epoch: [95] [563200/1281167 (44%)]	Loss: 0.829466
[2022-03-31 09:08:19 | train] - Train Epoch: [95] [576000/1281167 (45%)]	Loss: 0.847271
[2022-03-31 09:08:40 | train] - Train Epoch: [95] [588800/1281167 (46%)]	Loss: 1.234512
[2022-03-31 09:09:03 | train] - Train Epoch: [95] [601600/1281167 (47%)]	Loss: 0.612498
[2022-03-31 09:09:25 | train] - Train Epoch: [95] [614400/1281167 (48%)]	Loss: 0.669884
[2022-03-31 09:09:47 | train] - Train Epoch: [95] [627200/1281167 (49%)]	Loss: 0.679704
[2022-03-31 09:10:09 | train] - Train Epoch: [95] [640000/1281167 (50%)]	Loss: 0.858673
[2022-03-31 09:10:31 | train] - Train Epoch: [95] [652800/1281167 (51%)]	Loss: 1.086571
[2022-03-31 09:10:53 | train] - Train Epoch: [95] [665600/1281167 (52%)]	Loss: 0.898338
[2022-03-31 09:11:15 | train] - Train Epoch: [95] [678400/1281167 (53%)]	Loss: 0.658021
[2022-03-31 09:11:36 | train] - Train Epoch: [95] [691200/1281167 (54%)]	Loss: 0.795200
[2022-03-31 09:11:59 | train] - Train Epoch: [95] [704000/1281167 (55%)]	Loss: 0.968622
[2022-03-31 09:12:21 | train] - Train Epoch: [95] [716800/1281167 (56%)]	Loss: 0.945591
[2022-03-31 09:12:44 | train] - Train Epoch: [95] [729600/1281167 (57%)]	Loss: 0.884521
[2022-03-31 09:13:05 | train] - Train Epoch: [95] [742400/1281167 (58%)]	Loss: 1.201702
[2022-03-31 09:13:27 | train] - Train Epoch: [95] [755200/1281167 (59%)]	Loss: 0.961940
[2022-03-31 09:13:49 | train] - Train Epoch: [95] [768000/1281167 (60%)]	Loss: 0.918761
[2022-03-31 09:14:11 | train] - Train Epoch: [95] [780800/1281167 (61%)]	Loss: 0.927739
[2022-03-31 09:14:33 | train] - Train Epoch: [95] [793600/1281167 (62%)]	Loss: 0.824936
[2022-03-31 09:14:55 | train] - Train Epoch: [95] [806400/1281167 (63%)]	Loss: 0.807891
[2022-03-31 09:15:17 | train] - Train Epoch: [95] [819200/1281167 (64%)]	Loss: 0.613190
[2022-03-31 09:15:39 | train] - Train Epoch: [95] [832000/1281167 (65%)]	Loss: 0.694741
[2022-03-31 09:16:02 | train] - Train Epoch: [95] [844800/1281167 (66%)]	Loss: 0.987600
[2022-03-31 09:16:24 | train] - Train Epoch: [95] [857600/1281167 (67%)]	Loss: 0.904467
[2022-03-31 09:16:47 | train] - Train Epoch: [95] [870400/1281167 (68%)]	Loss: 0.900703
[2022-03-31 09:17:09 | train] - Train Epoch: [95] [883200/1281167 (69%)]	Loss: 0.750875
[2022-03-31 09:17:31 | train] - Train Epoch: [95] [896000/1281167 (70%)]	Loss: 0.466226
[2022-03-31 09:17:52 | train] - Train Epoch: [95] [908800/1281167 (71%)]	Loss: 0.827514
[2022-03-31 09:18:15 | train] - Train Epoch: [95] [921600/1281167 (72%)]	Loss: 0.709661
[2022-03-31 09:18:37 | train] - Train Epoch: [95] [934400/1281167 (73%)]	Loss: 1.050155
[2022-03-31 09:18:59 | train] - Train Epoch: [95] [947200/1281167 (74%)]	Loss: 0.805746
[2022-03-31 09:19:21 | train] - Train Epoch: [95] [960000/1281167 (75%)]	Loss: 0.827955
[2022-03-31 09:19:42 | train] - Train Epoch: [95] [972800/1281167 (76%)]	Loss: 0.472309
[2022-03-31 09:20:05 | train] - Train Epoch: [95] [985600/1281167 (77%)]	Loss: 0.885977
[2022-03-31 09:20:27 | train] - Train Epoch: [95] [998400/1281167 (78%)]	Loss: 0.787275
[2022-03-31 09:20:49 | train] - Train Epoch: [95] [1011200/1281167 (79%)]	Loss: 0.875793
[2022-03-31 09:21:12 | train] - Train Epoch: [95] [1024000/1281167 (80%)]	Loss: 0.749236
[2022-03-31 09:21:34 | train] - Train Epoch: [95] [1036800/1281167 (81%)]	Loss: 0.765049
[2022-03-31 09:21:55 | train] - Train Epoch: [95] [1049600/1281167 (82%)]	Loss: 0.904568
[2022-03-31 09:22:17 | train] - Train Epoch: [95] [1062400/1281167 (83%)]	Loss: 0.786996
[2022-03-31 09:22:39 | train] - Train Epoch: [95] [1075200/1281167 (84%)]	Loss: 0.902861
[2022-03-31 09:23:01 | train] - Train Epoch: [95] [1088000/1281167 (85%)]	Loss: 0.787057
[2022-03-31 09:23:22 | train] - Train Epoch: [95] [1100800/1281167 (86%)]	Loss: 0.615551
[2022-03-31 09:23:45 | train] - Train Epoch: [95] [1113600/1281167 (87%)]	Loss: 0.922007
[2022-03-31 09:24:07 | train] - Train Epoch: [95] [1126400/1281167 (88%)]	Loss: 0.730887
[2022-03-31 09:24:28 | train] - Train Epoch: [95] [1139200/1281167 (89%)]	Loss: 1.032327
[2022-03-31 09:24:50 | train] - Train Epoch: [95] [1152000/1281167 (90%)]	Loss: 0.836679
[2022-03-31 09:25:13 | train] - Train Epoch: [95] [1164800/1281167 (91%)]	Loss: 0.816639
[2022-03-31 09:25:34 | train] - Train Epoch: [95] [1177600/1281167 (92%)]	Loss: 0.666847
[2022-03-31 09:25:55 | train] - Train Epoch: [95] [1190400/1281167 (93%)]	Loss: 0.702356
[2022-03-31 09:26:16 | train] - Train Epoch: [95] [1203200/1281167 (94%)]	Loss: 1.096346
[2022-03-31 09:26:38 | train] - Train Epoch: [95] [1216000/1281167 (95%)]	Loss: 0.930406
[2022-03-31 09:26:59 | train] - Train Epoch: [95] [1228800/1281167 (96%)]	Loss: 0.912904
[2022-03-31 09:27:21 | train] - Train Epoch: [95] [1241600/1281167 (97%)]	Loss: 0.915156
[2022-03-31 09:27:42 | train] - Train Epoch: [95] [1254400/1281167 (98%)]	Loss: 0.676218
[2022-03-31 09:28:04 | train] - Train Epoch: [95] [1267200/1281167 (99%)]	Loss: 1.002488
[2022-03-31 09:28:25 | train] - Train Epoch: [95] [1280000/1281167 (100%)]	Loss: 1.129114
[2022-03-31 09:28:27 | train] - Train Epoch: [95]	 Average Loss: 0.836824	 Total Acc : 79.5353	 Total Top5 Acc : 92.5224
[2022-03-31 09:28:27 | train] - -------95 epoch end-----------
========================================
-------95 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 09:30:04 | train] - 
Epoch [95] Test set: Average loss: 1.3963, Accuracy: 34904/50000 (69.7806%), Top-5 Accuracy: 88.7388%

[2022-03-31 09:30:04 | train] - save intermediate epoch [95] result


[2022-03-31 09:30:13 | train] - -------96 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 09:30:15 | train] - Train Epoch: [96] [0/1281167 (0%)]	Loss: 0.841111
[2022-03-31 09:30:37 | train] - Train Epoch: [96] [12800/1281167 (1%)]	Loss: 0.788420
[2022-03-31 09:31:00 | train] - Train Epoch: [96] [25600/1281167 (2%)]	Loss: 0.873812
[2022-03-31 09:31:22 | train] - Train Epoch: [96] [38400/1281167 (3%)]	Loss: 0.753514
[2022-03-31 09:31:43 | train] - Train Epoch: [96] [51200/1281167 (4%)]	Loss: 0.917647
[2022-03-31 09:32:06 | train] - Train Epoch: [96] [64000/1281167 (5%)]	Loss: 0.994677
[2022-03-31 09:32:28 | train] - Train Epoch: [96] [76800/1281167 (6%)]	Loss: 1.059371
[2022-03-31 09:32:50 | train] - Train Epoch: [96] [89600/1281167 (7%)]	Loss: 0.913192
[2022-03-31 09:33:11 | train] - Train Epoch: [96] [102400/1281167 (8%)]	Loss: 0.974222
[2022-03-31 09:33:33 | train] - Train Epoch: [96] [115200/1281167 (9%)]	Loss: 1.004792
[2022-03-31 09:33:55 | train] - Train Epoch: [96] [128000/1281167 (10%)]	Loss: 0.952002
[2022-03-31 09:34:18 | train] - Train Epoch: [96] [140800/1281167 (11%)]	Loss: 0.897411
[2022-03-31 09:34:41 | train] - Train Epoch: [96] [153600/1281167 (12%)]	Loss: 0.633566
[2022-03-31 09:35:03 | train] - Train Epoch: [96] [166400/1281167 (13%)]	Loss: 0.911629
[2022-03-31 09:35:25 | train] - Train Epoch: [96] [179200/1281167 (14%)]	Loss: 0.613196
[2022-03-31 09:35:47 | train] - Train Epoch: [96] [192000/1281167 (15%)]	Loss: 0.996346
[2022-03-31 09:36:09 | train] - Train Epoch: [96] [204800/1281167 (16%)]	Loss: 0.850166
[2022-03-31 09:36:31 | train] - Train Epoch: [96] [217600/1281167 (17%)]	Loss: 0.962398
[2022-03-31 09:36:53 | train] - Train Epoch: [96] [230400/1281167 (18%)]	Loss: 0.881253
[2022-03-31 09:37:16 | train] - Train Epoch: [96] [243200/1281167 (19%)]	Loss: 0.779495
[2022-03-31 09:37:38 | train] - Train Epoch: [96] [256000/1281167 (20%)]	Loss: 0.754973
[2022-03-31 09:37:59 | train] - Train Epoch: [96] [268800/1281167 (21%)]	Loss: 1.028471
[2022-03-31 09:38:21 | train] - Train Epoch: [96] [281600/1281167 (22%)]	Loss: 0.809613
[2022-03-31 09:38:42 | train] - Train Epoch: [96] [294400/1281167 (23%)]	Loss: 0.836085
[2022-03-31 09:39:05 | train] - Train Epoch: [96] [307200/1281167 (24%)]	Loss: 0.641575
[2022-03-31 09:39:26 | train] - Train Epoch: [96] [320000/1281167 (25%)]	Loss: 0.825985
[2022-03-31 09:39:49 | train] - Train Epoch: [96] [332800/1281167 (26%)]	Loss: 0.870321
[2022-03-31 09:40:11 | train] - Train Epoch: [96] [345600/1281167 (27%)]	Loss: 0.838378
[2022-03-31 09:40:33 | train] - Train Epoch: [96] [358400/1281167 (28%)]	Loss: 1.100358
[2022-03-31 09:40:55 | train] - Train Epoch: [96] [371200/1281167 (29%)]	Loss: 0.763653
[2022-03-31 09:41:17 | train] - Train Epoch: [96] [384000/1281167 (30%)]	Loss: 0.727470
[2022-03-31 09:41:39 | train] - Train Epoch: [96] [396800/1281167 (31%)]	Loss: 0.688823
[2022-03-31 09:42:01 | train] - Train Epoch: [96] [409600/1281167 (32%)]	Loss: 0.864464
[2022-03-31 09:42:23 | train] - Train Epoch: [96] [422400/1281167 (33%)]	Loss: 0.761391
[2022-03-31 09:42:46 | train] - Train Epoch: [96] [435200/1281167 (34%)]	Loss: 0.804422
[2022-03-31 09:43:07 | train] - Train Epoch: [96] [448000/1281167 (35%)]	Loss: 0.655983
[2022-03-31 09:43:29 | train] - Train Epoch: [96] [460800/1281167 (36%)]	Loss: 0.821021
[2022-03-31 09:43:51 | train] - Train Epoch: [96] [473600/1281167 (37%)]	Loss: 1.054505
[2022-03-31 09:44:13 | train] - Train Epoch: [96] [486400/1281167 (38%)]	Loss: 1.069241
[2022-03-31 09:44:35 | train] - Train Epoch: [96] [499200/1281167 (39%)]	Loss: 1.037157
[2022-03-31 09:44:58 | train] - Train Epoch: [96] [512000/1281167 (40%)]	Loss: 0.977322
[2022-03-31 09:45:20 | train] - Train Epoch: [96] [524800/1281167 (41%)]	Loss: 1.143365
[2022-03-31 09:45:42 | train] - Train Epoch: [96] [537600/1281167 (42%)]	Loss: 1.365659
[2022-03-31 09:46:04 | train] - Train Epoch: [96] [550400/1281167 (43%)]	Loss: 0.958437
[2022-03-31 09:46:26 | train] - Train Epoch: [96] [563200/1281167 (44%)]	Loss: 0.900885
[2022-03-31 09:46:48 | train] - Train Epoch: [96] [576000/1281167 (45%)]	Loss: 0.740622
[2022-03-31 09:47:09 | train] - Train Epoch: [96] [588800/1281167 (46%)]	Loss: 0.685560
[2022-03-31 09:47:32 | train] - Train Epoch: [96] [601600/1281167 (47%)]	Loss: 1.105289
[2022-03-31 09:47:53 | train] - Train Epoch: [96] [614400/1281167 (48%)]	Loss: 0.891820
[2022-03-31 09:48:15 | train] - Train Epoch: [96] [627200/1281167 (49%)]	Loss: 0.739474
[2022-03-31 09:48:37 | train] - Train Epoch: [96] [640000/1281167 (50%)]	Loss: 0.865291
[2022-03-31 09:48:59 | train] - Train Epoch: [96] [652800/1281167 (51%)]	Loss: 0.588869
[2022-03-31 09:49:20 | train] - Train Epoch: [96] [665600/1281167 (52%)]	Loss: 0.861178
[2022-03-31 09:49:42 | train] - Train Epoch: [96] [678400/1281167 (53%)]	Loss: 0.686508
[2022-03-31 09:50:03 | train] - Train Epoch: [96] [691200/1281167 (54%)]	Loss: 0.777531
[2022-03-31 09:50:25 | train] - Train Epoch: [96] [704000/1281167 (55%)]	Loss: 0.697412
[2022-03-31 09:50:46 | train] - Train Epoch: [96] [716800/1281167 (56%)]	Loss: 0.669814
[2022-03-31 09:51:08 | train] - Train Epoch: [96] [729600/1281167 (57%)]	Loss: 0.480732
[2022-03-31 09:51:30 | train] - Train Epoch: [96] [742400/1281167 (58%)]	Loss: 0.643672
[2022-03-31 09:51:52 | train] - Train Epoch: [96] [755200/1281167 (59%)]	Loss: 0.597260
[2022-03-31 09:52:15 | train] - Train Epoch: [96] [768000/1281167 (60%)]	Loss: 0.968955
[2022-03-31 09:52:36 | train] - Train Epoch: [96] [780800/1281167 (61%)]	Loss: 0.862636
[2022-03-31 09:52:59 | train] - Train Epoch: [96] [793600/1281167 (62%)]	Loss: 0.821294
[2022-03-31 09:53:21 | train] - Train Epoch: [96] [806400/1281167 (63%)]	Loss: 0.966635
[2022-03-31 09:53:43 | train] - Train Epoch: [96] [819200/1281167 (64%)]	Loss: 0.810774
[2022-03-31 09:54:05 | train] - Train Epoch: [96] [832000/1281167 (65%)]	Loss: 0.957832
[2022-03-31 09:54:26 | train] - Train Epoch: [96] [844800/1281167 (66%)]	Loss: 0.775631
[2022-03-31 09:54:48 | train] - Train Epoch: [96] [857600/1281167 (67%)]	Loss: 0.987579
[2022-03-31 09:55:10 | train] - Train Epoch: [96] [870400/1281167 (68%)]	Loss: 0.893602
[2022-03-31 09:55:32 | train] - Train Epoch: [96] [883200/1281167 (69%)]	Loss: 0.726776
[2022-03-31 09:55:54 | train] - Train Epoch: [96] [896000/1281167 (70%)]	Loss: 0.777764
[2022-03-31 09:56:16 | train] - Train Epoch: [96] [908800/1281167 (71%)]	Loss: 0.643128
[2022-03-31 09:56:38 | train] - Train Epoch: [96] [921600/1281167 (72%)]	Loss: 0.772279
[2022-03-31 09:56:59 | train] - Train Epoch: [96] [934400/1281167 (73%)]	Loss: 0.833633
[2022-03-31 09:57:22 | train] - Train Epoch: [96] [947200/1281167 (74%)]	Loss: 0.970024
[2022-03-31 09:57:44 | train] - Train Epoch: [96] [960000/1281167 (75%)]	Loss: 0.694430
[2022-03-31 09:58:06 | train] - Train Epoch: [96] [972800/1281167 (76%)]	Loss: 0.701936
[2022-03-31 09:58:28 | train] - Train Epoch: [96] [985600/1281167 (77%)]	Loss: 0.855475
[2022-03-31 09:58:51 | train] - Train Epoch: [96] [998400/1281167 (78%)]	Loss: 0.471874
[2022-03-31 09:59:12 | train] - Train Epoch: [96] [1011200/1281167 (79%)]	Loss: 0.843940
[2022-03-31 09:59:35 | train] - Train Epoch: [96] [1024000/1281167 (80%)]	Loss: 0.981399
[2022-03-31 09:59:56 | train] - Train Epoch: [96] [1036800/1281167 (81%)]	Loss: 0.877899
[2022-03-31 10:00:18 | train] - Train Epoch: [96] [1049600/1281167 (82%)]	Loss: 0.679367
[2022-03-31 10:00:40 | train] - Train Epoch: [96] [1062400/1281167 (83%)]	Loss: 0.880690
[2022-03-31 10:01:02 | train] - Train Epoch: [96] [1075200/1281167 (84%)]	Loss: 0.872665
[2022-03-31 10:01:24 | train] - Train Epoch: [96] [1088000/1281167 (85%)]	Loss: 0.683673
[2022-03-31 10:01:46 | train] - Train Epoch: [96] [1100800/1281167 (86%)]	Loss: 0.714104
[2022-03-31 10:02:08 | train] - Train Epoch: [96] [1113600/1281167 (87%)]	Loss: 0.933476
[2022-03-31 10:02:30 | train] - Train Epoch: [96] [1126400/1281167 (88%)]	Loss: 0.709692
[2022-03-31 10:02:51 | train] - Train Epoch: [96] [1139200/1281167 (89%)]	Loss: 1.052443
[2022-03-31 10:03:13 | train] - Train Epoch: [96] [1152000/1281167 (90%)]	Loss: 0.747136
[2022-03-31 10:03:35 | train] - Train Epoch: [96] [1164800/1281167 (91%)]	Loss: 0.958865
[2022-03-31 10:03:57 | train] - Train Epoch: [96] [1177600/1281167 (92%)]	Loss: 0.593627
[2022-03-31 10:04:20 | train] - Train Epoch: [96] [1190400/1281167 (93%)]	Loss: 0.867514
[2022-03-31 10:04:42 | train] - Train Epoch: [96] [1203200/1281167 (94%)]	Loss: 0.764084
[2022-03-31 10:05:04 | train] - Train Epoch: [96] [1216000/1281167 (95%)]	Loss: 0.816969
[2022-03-31 10:05:25 | train] - Train Epoch: [96] [1228800/1281167 (96%)]	Loss: 0.818166
[2022-03-31 10:05:47 | train] - Train Epoch: [96] [1241600/1281167 (97%)]	Loss: 0.928904
[2022-03-31 10:06:09 | train] - Train Epoch: [96] [1254400/1281167 (98%)]	Loss: 0.960873
[2022-03-31 10:06:31 | train] - Train Epoch: [96] [1267200/1281167 (99%)]	Loss: 0.909396
[2022-03-31 10:06:53 | train] - Train Epoch: [96] [1280000/1281167 (100%)]	Loss: 0.956920
[2022-03-31 10:06:55 | train] - Train Epoch: [96]	 Average Loss: 0.833443	 Total Acc : 79.6124	 Total Top5 Acc : 92.5455
[2022-03-31 10:06:55 | train] - -------96 epoch end-----------
========================================
-------96 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 10:08:32 | train] - 
Epoch [96] Test set: Average loss: 1.3974, Accuracy: 34893/50000 (69.7586%), Top-5 Accuracy: 88.7988%

[2022-03-31 10:08:32 | train] - save intermediate epoch [96] result


[2022-03-31 10:08:41 | train] - -------97 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 10:08:43 | train] - Train Epoch: [97] [0/1281167 (0%)]	Loss: 0.750890
[2022-03-31 10:09:05 | train] - Train Epoch: [97] [12800/1281167 (1%)]	Loss: 0.777053
[2022-03-31 10:09:26 | train] - Train Epoch: [97] [25600/1281167 (2%)]	Loss: 0.856828
[2022-03-31 10:09:49 | train] - Train Epoch: [97] [38400/1281167 (3%)]	Loss: 0.649870
[2022-03-31 10:10:10 | train] - Train Epoch: [97] [51200/1281167 (4%)]	Loss: 0.804209
[2022-03-31 10:10:32 | train] - Train Epoch: [97] [64000/1281167 (5%)]	Loss: 0.818775
[2022-03-31 10:10:53 | train] - Train Epoch: [97] [76800/1281167 (6%)]	Loss: 0.721987
[2022-03-31 10:11:15 | train] - Train Epoch: [97] [89600/1281167 (7%)]	Loss: 0.805182
[2022-03-31 10:11:37 | train] - Train Epoch: [97] [102400/1281167 (8%)]	Loss: 0.705154
[2022-03-31 10:11:59 | train] - Train Epoch: [97] [115200/1281167 (9%)]	Loss: 0.608636
[2022-03-31 10:12:21 | train] - Train Epoch: [97] [128000/1281167 (10%)]	Loss: 0.736642
[2022-03-31 10:12:44 | train] - Train Epoch: [97] [140800/1281167 (11%)]	Loss: 0.787264
[2022-03-31 10:13:06 | train] - Train Epoch: [97] [153600/1281167 (12%)]	Loss: 0.888528
[2022-03-31 10:13:28 | train] - Train Epoch: [97] [166400/1281167 (13%)]	Loss: 0.796685
[2022-03-31 10:13:50 | train] - Train Epoch: [97] [179200/1281167 (14%)]	Loss: 0.906607
[2022-03-31 10:14:12 | train] - Train Epoch: [97] [192000/1281167 (15%)]	Loss: 0.883286
[2022-03-31 10:14:32 | train] - Train Epoch: [97] [204800/1281167 (16%)]	Loss: 0.775580
[2022-03-31 10:14:55 | train] - Train Epoch: [97] [217600/1281167 (17%)]	Loss: 1.008201
[2022-03-31 10:15:17 | train] - Train Epoch: [97] [230400/1281167 (18%)]	Loss: 0.769148
[2022-03-31 10:15:38 | train] - Train Epoch: [97] [243200/1281167 (19%)]	Loss: 0.719282
[2022-03-31 10:15:58 | train] - Train Epoch: [97] [256000/1281167 (20%)]	Loss: 0.803362
[2022-03-31 10:16:20 | train] - Train Epoch: [97] [268800/1281167 (21%)]	Loss: 1.003176
[2022-03-31 10:16:42 | train] - Train Epoch: [97] [281600/1281167 (22%)]	Loss: 0.730783
[2022-03-31 10:17:04 | train] - Train Epoch: [97] [294400/1281167 (23%)]	Loss: 0.988642
[2022-03-31 10:17:26 | train] - Train Epoch: [97] [307200/1281167 (24%)]	Loss: 0.838429
[2022-03-31 10:17:47 | train] - Train Epoch: [97] [320000/1281167 (25%)]	Loss: 0.841497
[2022-03-31 10:18:09 | train] - Train Epoch: [97] [332800/1281167 (26%)]	Loss: 1.042217
[2022-03-31 10:18:31 | train] - Train Epoch: [97] [345600/1281167 (27%)]	Loss: 1.023945
[2022-03-31 10:18:53 | train] - Train Epoch: [97] [358400/1281167 (28%)]	Loss: 0.943047
[2022-03-31 10:19:15 | train] - Train Epoch: [97] [371200/1281167 (29%)]	Loss: 0.862241
[2022-03-31 10:19:37 | train] - Train Epoch: [97] [384000/1281167 (30%)]	Loss: 0.950228
[2022-03-31 10:19:59 | train] - Train Epoch: [97] [396800/1281167 (31%)]	Loss: 0.744969
[2022-03-31 10:20:19 | train] - Train Epoch: [97] [409600/1281167 (32%)]	Loss: 0.895230
[2022-03-31 10:20:41 | train] - Train Epoch: [97] [422400/1281167 (33%)]	Loss: 0.959997
[2022-03-31 10:21:03 | train] - Train Epoch: [97] [435200/1281167 (34%)]	Loss: 1.004182
[2022-03-31 10:21:25 | train] - Train Epoch: [97] [448000/1281167 (35%)]	Loss: 0.754469
[2022-03-31 10:21:46 | train] - Train Epoch: [97] [460800/1281167 (36%)]	Loss: 0.950420
[2022-03-31 10:22:08 | train] - Train Epoch: [97] [473600/1281167 (37%)]	Loss: 0.814108
[2022-03-31 10:22:29 | train] - Train Epoch: [97] [486400/1281167 (38%)]	Loss: 0.644777
[2022-03-31 10:22:51 | train] - Train Epoch: [97] [499200/1281167 (39%)]	Loss: 0.888650
[2022-03-31 10:23:13 | train] - Train Epoch: [97] [512000/1281167 (40%)]	Loss: 0.689982
[2022-03-31 10:23:35 | train] - Train Epoch: [97] [524800/1281167 (41%)]	Loss: 0.647435
[2022-03-31 10:23:57 | train] - Train Epoch: [97] [537600/1281167 (42%)]	Loss: 0.872050
[2022-03-31 10:24:18 | train] - Train Epoch: [97] [550400/1281167 (43%)]	Loss: 0.871290
[2022-03-31 10:24:41 | train] - Train Epoch: [97] [563200/1281167 (44%)]	Loss: 0.865565
[2022-03-31 10:25:03 | train] - Train Epoch: [97] [576000/1281167 (45%)]	Loss: 1.018045
[2022-03-31 10:25:24 | train] - Train Epoch: [97] [588800/1281167 (46%)]	Loss: 0.679915
[2022-03-31 10:25:45 | train] - Train Epoch: [97] [601600/1281167 (47%)]	Loss: 0.841429
[2022-03-31 10:26:08 | train] - Train Epoch: [97] [614400/1281167 (48%)]	Loss: 0.965689
[2022-03-31 10:26:29 | train] - Train Epoch: [97] [627200/1281167 (49%)]	Loss: 0.549400
[2022-03-31 10:26:51 | train] - Train Epoch: [97] [640000/1281167 (50%)]	Loss: 1.067732
[2022-03-31 10:27:13 | train] - Train Epoch: [97] [652800/1281167 (51%)]	Loss: 0.796856
[2022-03-31 10:27:34 | train] - Train Epoch: [97] [665600/1281167 (52%)]	Loss: 0.876474
[2022-03-31 10:27:56 | train] - Train Epoch: [97] [678400/1281167 (53%)]	Loss: 0.920537
[2022-03-31 10:28:18 | train] - Train Epoch: [97] [691200/1281167 (54%)]	Loss: 0.757157
[2022-03-31 10:28:40 | train] - Train Epoch: [97] [704000/1281167 (55%)]	Loss: 0.609695
[2022-03-31 10:29:02 | train] - Train Epoch: [97] [716800/1281167 (56%)]	Loss: 0.994111
[2022-03-31 10:29:25 | train] - Train Epoch: [97] [729600/1281167 (57%)]	Loss: 0.569499
[2022-03-31 10:29:46 | train] - Train Epoch: [97] [742400/1281167 (58%)]	Loss: 0.814734
[2022-03-31 10:30:08 | train] - Train Epoch: [97] [755200/1281167 (59%)]	Loss: 0.832855
[2022-03-31 10:30:31 | train] - Train Epoch: [97] [768000/1281167 (60%)]	Loss: 0.848421
[2022-03-31 10:30:52 | train] - Train Epoch: [97] [780800/1281167 (61%)]	Loss: 0.596246
[2022-03-31 10:31:14 | train] - Train Epoch: [97] [793600/1281167 (62%)]	Loss: 0.908766
[2022-03-31 10:31:37 | train] - Train Epoch: [97] [806400/1281167 (63%)]	Loss: 0.867306
[2022-03-31 10:31:58 | train] - Train Epoch: [97] [819200/1281167 (64%)]	Loss: 0.822096
[2022-03-31 10:32:20 | train] - Train Epoch: [97] [832000/1281167 (65%)]	Loss: 0.785517
[2022-03-31 10:32:41 | train] - Train Epoch: [97] [844800/1281167 (66%)]	Loss: 0.844132
[2022-03-31 10:33:04 | train] - Train Epoch: [97] [857600/1281167 (67%)]	Loss: 1.009918
[2022-03-31 10:33:25 | train] - Train Epoch: [97] [870400/1281167 (68%)]	Loss: 0.798259
[2022-03-31 10:33:48 | train] - Train Epoch: [97] [883200/1281167 (69%)]	Loss: 0.840007
[2022-03-31 10:34:09 | train] - Train Epoch: [97] [896000/1281167 (70%)]	Loss: 0.821642
[2022-03-31 10:34:30 | train] - Train Epoch: [97] [908800/1281167 (71%)]	Loss: 1.121345
[2022-03-31 10:34:52 | train] - Train Epoch: [97] [921600/1281167 (72%)]	Loss: 0.901559
[2022-03-31 10:35:14 | train] - Train Epoch: [97] [934400/1281167 (73%)]	Loss: 1.007473
[2022-03-31 10:35:36 | train] - Train Epoch: [97] [947200/1281167 (74%)]	Loss: 1.014848
[2022-03-31 10:35:58 | train] - Train Epoch: [97] [960000/1281167 (75%)]	Loss: 0.739686
[2022-03-31 10:36:20 | train] - Train Epoch: [97] [972800/1281167 (76%)]	Loss: 0.769497
[2022-03-31 10:36:42 | train] - Train Epoch: [97] [985600/1281167 (77%)]	Loss: 1.053091
[2022-03-31 10:37:05 | train] - Train Epoch: [97] [998400/1281167 (78%)]	Loss: 0.881146
[2022-03-31 10:37:26 | train] - Train Epoch: [97] [1011200/1281167 (79%)]	Loss: 0.675738
[2022-03-31 10:37:49 | train] - Train Epoch: [97] [1024000/1281167 (80%)]	Loss: 0.874372
[2022-03-31 10:38:11 | train] - Train Epoch: [97] [1036800/1281167 (81%)]	Loss: 1.005714
[2022-03-31 10:38:33 | train] - Train Epoch: [97] [1049600/1281167 (82%)]	Loss: 0.850778
[2022-03-31 10:38:55 | train] - Train Epoch: [97] [1062400/1281167 (83%)]	Loss: 0.477767
[2022-03-31 10:39:18 | train] - Train Epoch: [97] [1075200/1281167 (84%)]	Loss: 0.584986
[2022-03-31 10:39:40 | train] - Train Epoch: [97] [1088000/1281167 (85%)]	Loss: 0.750982
[2022-03-31 10:40:02 | train] - Train Epoch: [97] [1100800/1281167 (86%)]	Loss: 0.754694
[2022-03-31 10:40:24 | train] - Train Epoch: [97] [1113600/1281167 (87%)]	Loss: 1.068157
[2022-03-31 10:40:46 | train] - Train Epoch: [97] [1126400/1281167 (88%)]	Loss: 0.834732
[2022-03-31 10:41:09 | train] - Train Epoch: [97] [1139200/1281167 (89%)]	Loss: 0.859399
[2022-03-31 10:41:31 | train] - Train Epoch: [97] [1152000/1281167 (90%)]	Loss: 0.539985
[2022-03-31 10:41:52 | train] - Train Epoch: [97] [1164800/1281167 (91%)]	Loss: 0.856306
[2022-03-31 10:42:15 | train] - Train Epoch: [97] [1177600/1281167 (92%)]	Loss: 0.869717
[2022-03-31 10:42:36 | train] - Train Epoch: [97] [1190400/1281167 (93%)]	Loss: 0.981325
[2022-03-31 10:42:58 | train] - Train Epoch: [97] [1203200/1281167 (94%)]	Loss: 0.990446
[2022-03-31 10:43:20 | train] - Train Epoch: [97] [1216000/1281167 (95%)]	Loss: 0.815540
[2022-03-31 10:43:42 | train] - Train Epoch: [97] [1228800/1281167 (96%)]	Loss: 0.708886
[2022-03-31 10:44:04 | train] - Train Epoch: [97] [1241600/1281167 (97%)]	Loss: 1.001473
[2022-03-31 10:44:26 | train] - Train Epoch: [97] [1254400/1281167 (98%)]	Loss: 1.045665
[2022-03-31 10:44:48 | train] - Train Epoch: [97] [1267200/1281167 (99%)]	Loss: 0.991702
[2022-03-31 10:45:09 | train] - Train Epoch: [97] [1280000/1281167 (100%)]	Loss: 1.066688
[2022-03-31 10:45:11 | train] - Train Epoch: [97]	 Average Loss: 0.831089	 Total Acc : 79.6499	 Total Top5 Acc : 92.5701
[2022-03-31 10:45:11 | train] - -------97 epoch end-----------
========================================
-------97 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 10:46:44 | train] - 
Epoch [97] Test set: Average loss: 1.3981, Accuracy: 34895/50000 (69.7650%), Top-5 Accuracy: 88.8975%

[2022-03-31 10:46:44 | train] - save intermediate epoch [97] result


[2022-03-31 10:46:54 | train] - -------98 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 10:46:56 | train] - Train Epoch: [98] [0/1281167 (0%)]	Loss: 0.928746
[2022-03-31 10:47:18 | train] - Train Epoch: [98] [12800/1281167 (1%)]	Loss: 0.850729
[2022-03-31 10:47:41 | train] - Train Epoch: [98] [25600/1281167 (2%)]	Loss: 0.767540
[2022-03-31 10:48:04 | train] - Train Epoch: [98] [38400/1281167 (3%)]	Loss: 0.683984
[2022-03-31 10:48:26 | train] - Train Epoch: [98] [51200/1281167 (4%)]	Loss: 0.776932
[2022-03-31 10:48:47 | train] - Train Epoch: [98] [64000/1281167 (5%)]	Loss: 1.063105
[2022-03-31 10:49:10 | train] - Train Epoch: [98] [76800/1281167 (6%)]	Loss: 0.679006
[2022-03-31 10:49:33 | train] - Train Epoch: [98] [89600/1281167 (7%)]	Loss: 1.010126
[2022-03-31 10:49:55 | train] - Train Epoch: [98] [102400/1281167 (8%)]	Loss: 0.509375
[2022-03-31 10:50:16 | train] - Train Epoch: [98] [115200/1281167 (9%)]	Loss: 0.789541
[2022-03-31 10:50:38 | train] - Train Epoch: [98] [128000/1281167 (10%)]	Loss: 0.987447
[2022-03-31 10:51:00 | train] - Train Epoch: [98] [140800/1281167 (11%)]	Loss: 0.821306
[2022-03-31 10:51:22 | train] - Train Epoch: [98] [153600/1281167 (12%)]	Loss: 1.230390
[2022-03-31 10:51:45 | train] - Train Epoch: [98] [166400/1281167 (13%)]	Loss: 0.925356
[2022-03-31 10:52:07 | train] - Train Epoch: [98] [179200/1281167 (14%)]	Loss: 0.900965
[2022-03-31 10:52:29 | train] - Train Epoch: [98] [192000/1281167 (15%)]	Loss: 0.900140
[2022-03-31 10:52:51 | train] - Train Epoch: [98] [204800/1281167 (16%)]	Loss: 0.822784
[2022-03-31 10:53:13 | train] - Train Epoch: [98] [217600/1281167 (17%)]	Loss: 0.863878
[2022-03-31 10:53:35 | train] - Train Epoch: [98] [230400/1281167 (18%)]	Loss: 0.970950
[2022-03-31 10:53:57 | train] - Train Epoch: [98] [243200/1281167 (19%)]	Loss: 0.826661
[2022-03-31 10:54:19 | train] - Train Epoch: [98] [256000/1281167 (20%)]	Loss: 0.906452
[2022-03-31 10:54:42 | train] - Train Epoch: [98] [268800/1281167 (21%)]	Loss: 0.787438
[2022-03-31 10:55:04 | train] - Train Epoch: [98] [281600/1281167 (22%)]	Loss: 0.820147
[2022-03-31 10:55:26 | train] - Train Epoch: [98] [294400/1281167 (23%)]	Loss: 0.919184
[2022-03-31 10:55:48 | train] - Train Epoch: [98] [307200/1281167 (24%)]	Loss: 0.969207
[2022-03-31 10:56:10 | train] - Train Epoch: [98] [320000/1281167 (25%)]	Loss: 1.032471
[2022-03-31 10:56:33 | train] - Train Epoch: [98] [332800/1281167 (26%)]	Loss: 0.896813
[2022-03-31 10:56:55 | train] - Train Epoch: [98] [345600/1281167 (27%)]	Loss: 0.839329
[2022-03-31 10:57:17 | train] - Train Epoch: [98] [358400/1281167 (28%)]	Loss: 0.732337
[2022-03-31 10:57:39 | train] - Train Epoch: [98] [371200/1281167 (29%)]	Loss: 0.781623
[2022-03-31 10:58:01 | train] - Train Epoch: [98] [384000/1281167 (30%)]	Loss: 0.917503
[2022-03-31 10:58:23 | train] - Train Epoch: [98] [396800/1281167 (31%)]	Loss: 0.921728
[2022-03-31 10:58:46 | train] - Train Epoch: [98] [409600/1281167 (32%)]	Loss: 0.852657
[2022-03-31 10:59:08 | train] - Train Epoch: [98] [422400/1281167 (33%)]	Loss: 0.746745
[2022-03-31 10:59:30 | train] - Train Epoch: [98] [435200/1281167 (34%)]	Loss: 0.910871
[2022-03-31 10:59:51 | train] - Train Epoch: [98] [448000/1281167 (35%)]	Loss: 0.969683
[2022-03-31 11:00:14 | train] - Train Epoch: [98] [460800/1281167 (36%)]	Loss: 0.721146
[2022-03-31 11:00:36 | train] - Train Epoch: [98] [473600/1281167 (37%)]	Loss: 0.695290
[2022-03-31 11:00:58 | train] - Train Epoch: [98] [486400/1281167 (38%)]	Loss: 0.732750
[2022-03-31 11:01:20 | train] - Train Epoch: [98] [499200/1281167 (39%)]	Loss: 0.522835
[2022-03-31 11:01:43 | train] - Train Epoch: [98] [512000/1281167 (40%)]	Loss: 0.763937
[2022-03-31 11:02:05 | train] - Train Epoch: [98] [524800/1281167 (41%)]	Loss: 0.838357
[2022-03-31 11:02:27 | train] - Train Epoch: [98] [537600/1281167 (42%)]	Loss: 0.976652
[2022-03-31 11:02:49 | train] - Train Epoch: [98] [550400/1281167 (43%)]	Loss: 0.974141
[2022-03-31 11:03:11 | train] - Train Epoch: [98] [563200/1281167 (44%)]	Loss: 0.895457
[2022-03-31 11:03:33 | train] - Train Epoch: [98] [576000/1281167 (45%)]	Loss: 0.883602
[2022-03-31 11:03:55 | train] - Train Epoch: [98] [588800/1281167 (46%)]	Loss: 0.636906
[2022-03-31 11:04:16 | train] - Train Epoch: [98] [601600/1281167 (47%)]	Loss: 0.956616
[2022-03-31 11:04:39 | train] - Train Epoch: [98] [614400/1281167 (48%)]	Loss: 0.716390
[2022-03-31 11:05:01 | train] - Train Epoch: [98] [627200/1281167 (49%)]	Loss: 1.008312
[2022-03-31 11:05:23 | train] - Train Epoch: [98] [640000/1281167 (50%)]	Loss: 1.008839
[2022-03-31 11:05:46 | train] - Train Epoch: [98] [652800/1281167 (51%)]	Loss: 0.743042
[2022-03-31 11:06:09 | train] - Train Epoch: [98] [665600/1281167 (52%)]	Loss: 0.752283
[2022-03-31 11:06:31 | train] - Train Epoch: [98] [678400/1281167 (53%)]	Loss: 1.172818
[2022-03-31 11:06:54 | train] - Train Epoch: [98] [691200/1281167 (54%)]	Loss: 0.745009
[2022-03-31 11:07:16 | train] - Train Epoch: [98] [704000/1281167 (55%)]	Loss: 0.763857
[2022-03-31 11:07:39 | train] - Train Epoch: [98] [716800/1281167 (56%)]	Loss: 0.571440
[2022-03-31 11:08:01 | train] - Train Epoch: [98] [729600/1281167 (57%)]	Loss: 0.888434
[2022-03-31 11:08:23 | train] - Train Epoch: [98] [742400/1281167 (58%)]	Loss: 1.035932
[2022-03-31 11:08:46 | train] - Train Epoch: [98] [755200/1281167 (59%)]	Loss: 0.839963
[2022-03-31 11:09:08 | train] - Train Epoch: [98] [768000/1281167 (60%)]	Loss: 0.665766
[2022-03-31 11:09:31 | train] - Train Epoch: [98] [780800/1281167 (61%)]	Loss: 0.783963
[2022-03-31 11:09:53 | train] - Train Epoch: [98] [793600/1281167 (62%)]	Loss: 0.834975
[2022-03-31 11:10:16 | train] - Train Epoch: [98] [806400/1281167 (63%)]	Loss: 0.984362
[2022-03-31 11:10:38 | train] - Train Epoch: [98] [819200/1281167 (64%)]	Loss: 0.959386
[2022-03-31 11:11:00 | train] - Train Epoch: [98] [832000/1281167 (65%)]	Loss: 0.643182
[2022-03-31 11:11:22 | train] - Train Epoch: [98] [844800/1281167 (66%)]	Loss: 0.574662
[2022-03-31 11:11:44 | train] - Train Epoch: [98] [857600/1281167 (67%)]	Loss: 1.089491
[2022-03-31 11:12:07 | train] - Train Epoch: [98] [870400/1281167 (68%)]	Loss: 0.790739
[2022-03-31 11:12:29 | train] - Train Epoch: [98] [883200/1281167 (69%)]	Loss: 0.850875
[2022-03-31 11:12:51 | train] - Train Epoch: [98] [896000/1281167 (70%)]	Loss: 0.865529
[2022-03-31 11:13:13 | train] - Train Epoch: [98] [908800/1281167 (71%)]	Loss: 0.704200
[2022-03-31 11:13:35 | train] - Train Epoch: [98] [921600/1281167 (72%)]	Loss: 0.743956
[2022-03-31 11:13:57 | train] - Train Epoch: [98] [934400/1281167 (73%)]	Loss: 0.767906
[2022-03-31 11:14:19 | train] - Train Epoch: [98] [947200/1281167 (74%)]	Loss: 0.871756
[2022-03-31 11:14:41 | train] - Train Epoch: [98] [960000/1281167 (75%)]	Loss: 0.938893
[2022-03-31 11:15:03 | train] - Train Epoch: [98] [972800/1281167 (76%)]	Loss: 0.858906
[2022-03-31 11:15:26 | train] - Train Epoch: [98] [985600/1281167 (77%)]	Loss: 0.879303
[2022-03-31 11:15:48 | train] - Train Epoch: [98] [998400/1281167 (78%)]	Loss: 0.814268
[2022-03-31 11:16:10 | train] - Train Epoch: [98] [1011200/1281167 (79%)]	Loss: 0.818844
[2022-03-31 11:16:33 | train] - Train Epoch: [98] [1024000/1281167 (80%)]	Loss: 0.734898
[2022-03-31 11:16:54 | train] - Train Epoch: [98] [1036800/1281167 (81%)]	Loss: 1.297987
[2022-03-31 11:17:16 | train] - Train Epoch: [98] [1049600/1281167 (82%)]	Loss: 0.800165
[2022-03-31 11:17:38 | train] - Train Epoch: [98] [1062400/1281167 (83%)]	Loss: 0.770460
[2022-03-31 11:18:01 | train] - Train Epoch: [98] [1075200/1281167 (84%)]	Loss: 0.749330
[2022-03-31 11:18:23 | train] - Train Epoch: [98] [1088000/1281167 (85%)]	Loss: 0.856573
[2022-03-31 11:18:46 | train] - Train Epoch: [98] [1100800/1281167 (86%)]	Loss: 0.673002
[2022-03-31 11:19:08 | train] - Train Epoch: [98] [1113600/1281167 (87%)]	Loss: 0.676072
[2022-03-31 11:19:30 | train] - Train Epoch: [98] [1126400/1281167 (88%)]	Loss: 1.156526
[2022-03-31 11:19:52 | train] - Train Epoch: [98] [1139200/1281167 (89%)]	Loss: 0.874655
[2022-03-31 11:20:14 | train] - Train Epoch: [98] [1152000/1281167 (90%)]	Loss: 0.800199
[2022-03-31 11:20:36 | train] - Train Epoch: [98] [1164800/1281167 (91%)]	Loss: 1.070123
[2022-03-31 11:20:58 | train] - Train Epoch: [98] [1177600/1281167 (92%)]	Loss: 0.848074
[2022-03-31 11:21:20 | train] - Train Epoch: [98] [1190400/1281167 (93%)]	Loss: 0.825553
[2022-03-31 11:21:43 | train] - Train Epoch: [98] [1203200/1281167 (94%)]	Loss: 0.730131
[2022-03-31 11:22:05 | train] - Train Epoch: [98] [1216000/1281167 (95%)]	Loss: 0.582045
[2022-03-31 11:22:27 | train] - Train Epoch: [98] [1228800/1281167 (96%)]	Loss: 0.935513
[2022-03-31 11:22:49 | train] - Train Epoch: [98] [1241600/1281167 (97%)]	Loss: 0.746581
[2022-03-31 11:23:11 | train] - Train Epoch: [98] [1254400/1281167 (98%)]	Loss: 0.924143
[2022-03-31 11:23:33 | train] - Train Epoch: [98] [1267200/1281167 (99%)]	Loss: 1.042092
[2022-03-31 11:23:55 | train] - Train Epoch: [98] [1280000/1281167 (100%)]	Loss: 0.992903
[2022-03-31 11:23:57 | train] - Train Epoch: [98]	 Average Loss: 0.829472	 Total Acc : 79.6997	 Total Top5 Acc : 92.5858
[2022-03-31 11:23:57 | train] - -------98 epoch end-----------
========================================
-------98 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 11:25:31 | train] - 
Epoch [98] Test set: Average loss: 1.4023, Accuracy: 34953/50000 (69.8809%), Top-5 Accuracy: 88.8339%

[2022-03-31 11:25:31 | train] - save intermediate epoch [98] result


[2022-03-31 11:25:40 | train] - -------99 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 11:25:42 | train] - Train Epoch: [99] [0/1281167 (0%)]	Loss: 0.913971
[2022-03-31 11:26:05 | train] - Train Epoch: [99] [12800/1281167 (1%)]	Loss: 0.897505
[2022-03-31 11:26:27 | train] - Train Epoch: [99] [25600/1281167 (2%)]	Loss: 0.801171
[2022-03-31 11:26:49 | train] - Train Epoch: [99] [38400/1281167 (3%)]	Loss: 0.788720
[2022-03-31 11:27:11 | train] - Train Epoch: [99] [51200/1281167 (4%)]	Loss: 0.702130
[2022-03-31 11:27:34 | train] - Train Epoch: [99] [64000/1281167 (5%)]	Loss: 0.832717
[2022-03-31 11:27:56 | train] - Train Epoch: [99] [76800/1281167 (6%)]	Loss: 0.938119
[2022-03-31 11:28:18 | train] - Train Epoch: [99] [89600/1281167 (7%)]	Loss: 0.749711
[2022-03-31 11:28:41 | train] - Train Epoch: [99] [102400/1281167 (8%)]	Loss: 0.868322
[2022-03-31 11:29:03 | train] - Train Epoch: [99] [115200/1281167 (9%)]	Loss: 0.818362
[2022-03-31 11:29:25 | train] - Train Epoch: [99] [128000/1281167 (10%)]	Loss: 0.773599
[2022-03-31 11:29:48 | train] - Train Epoch: [99] [140800/1281167 (11%)]	Loss: 0.802689
[2022-03-31 11:30:10 | train] - Train Epoch: [99] [153600/1281167 (12%)]	Loss: 0.785844
[2022-03-31 11:30:32 | train] - Train Epoch: [99] [166400/1281167 (13%)]	Loss: 0.695457
[2022-03-31 11:30:54 | train] - Train Epoch: [99] [179200/1281167 (14%)]	Loss: 0.727149
[2022-03-31 11:31:17 | train] - Train Epoch: [99] [192000/1281167 (15%)]	Loss: 0.954120
[2022-03-31 11:31:39 | train] - Train Epoch: [99] [204800/1281167 (16%)]	Loss: 0.956042
[2022-03-31 11:32:02 | train] - Train Epoch: [99] [217600/1281167 (17%)]	Loss: 0.862377
[2022-03-31 11:32:24 | train] - Train Epoch: [99] [230400/1281167 (18%)]	Loss: 0.793021
[2022-03-31 11:32:46 | train] - Train Epoch: [99] [243200/1281167 (19%)]	Loss: 0.554463
[2022-03-31 11:33:09 | train] - Train Epoch: [99] [256000/1281167 (20%)]	Loss: 0.789547
[2022-03-31 11:33:31 | train] - Train Epoch: [99] [268800/1281167 (21%)]	Loss: 1.040902
[2022-03-31 11:33:53 | train] - Train Epoch: [99] [281600/1281167 (22%)]	Loss: 0.826599
[2022-03-31 11:34:16 | train] - Train Epoch: [99] [294400/1281167 (23%)]	Loss: 0.648477
[2022-03-31 11:34:38 | train] - Train Epoch: [99] [307200/1281167 (24%)]	Loss: 0.640933
[2022-03-31 11:34:59 | train] - Train Epoch: [99] [320000/1281167 (25%)]	Loss: 1.027259
[2022-03-31 11:35:21 | train] - Train Epoch: [99] [332800/1281167 (26%)]	Loss: 0.834380
[2022-03-31 11:35:43 | train] - Train Epoch: [99] [345600/1281167 (27%)]	Loss: 0.730314
[2022-03-31 11:36:06 | train] - Train Epoch: [99] [358400/1281167 (28%)]	Loss: 0.805691
[2022-03-31 11:36:27 | train] - Train Epoch: [99] [371200/1281167 (29%)]	Loss: 0.631540
[2022-03-31 11:36:50 | train] - Train Epoch: [99] [384000/1281167 (30%)]	Loss: 0.644653
[2022-03-31 11:37:13 | train] - Train Epoch: [99] [396800/1281167 (31%)]	Loss: 0.877820
[2022-03-31 11:37:36 | train] - Train Epoch: [99] [409600/1281167 (32%)]	Loss: 0.737654
[2022-03-31 11:37:59 | train] - Train Epoch: [99] [422400/1281167 (33%)]	Loss: 0.853402
[2022-03-31 11:38:21 | train] - Train Epoch: [99] [435200/1281167 (34%)]	Loss: 1.073373
[2022-03-31 11:38:43 | train] - Train Epoch: [99] [448000/1281167 (35%)]	Loss: 0.897515
[2022-03-31 11:39:05 | train] - Train Epoch: [99] [460800/1281167 (36%)]	Loss: 0.839679
[2022-03-31 11:39:28 | train] - Train Epoch: [99] [473600/1281167 (37%)]	Loss: 0.669766
[2022-03-31 11:39:50 | train] - Train Epoch: [99] [486400/1281167 (38%)]	Loss: 0.952880
[2022-03-31 11:40:12 | train] - Train Epoch: [99] [499200/1281167 (39%)]	Loss: 0.653465
[2022-03-31 11:40:34 | train] - Train Epoch: [99] [512000/1281167 (40%)]	Loss: 0.888280
[2022-03-31 11:40:56 | train] - Train Epoch: [99] [524800/1281167 (41%)]	Loss: 0.710640
[2022-03-31 11:41:19 | train] - Train Epoch: [99] [537600/1281167 (42%)]	Loss: 0.713932
[2022-03-31 11:41:41 | train] - Train Epoch: [99] [550400/1281167 (43%)]	Loss: 1.117589
[2022-03-31 11:42:03 | train] - Train Epoch: [99] [563200/1281167 (44%)]	Loss: 0.884478
[2022-03-31 11:42:25 | train] - Train Epoch: [99] [576000/1281167 (45%)]	Loss: 0.938823
[2022-03-31 11:42:47 | train] - Train Epoch: [99] [588800/1281167 (46%)]	Loss: 0.572006
[2022-03-31 11:43:09 | train] - Train Epoch: [99] [601600/1281167 (47%)]	Loss: 0.665876
[2022-03-31 11:43:31 | train] - Train Epoch: [99] [614400/1281167 (48%)]	Loss: 0.658312
[2022-03-31 11:43:54 | train] - Train Epoch: [99] [627200/1281167 (49%)]	Loss: 0.881456
[2022-03-31 11:44:16 | train] - Train Epoch: [99] [640000/1281167 (50%)]	Loss: 0.844452
[2022-03-31 11:44:38 | train] - Train Epoch: [99] [652800/1281167 (51%)]	Loss: 0.587284
[2022-03-31 11:45:01 | train] - Train Epoch: [99] [665600/1281167 (52%)]	Loss: 0.636104
[2022-03-31 11:45:23 | train] - Train Epoch: [99] [678400/1281167 (53%)]	Loss: 0.861772
[2022-03-31 11:45:45 | train] - Train Epoch: [99] [691200/1281167 (54%)]	Loss: 0.862050
[2022-03-31 11:46:07 | train] - Train Epoch: [99] [704000/1281167 (55%)]	Loss: 0.827162
[2022-03-31 11:46:29 | train] - Train Epoch: [99] [716800/1281167 (56%)]	Loss: 0.975426
[2022-03-31 11:46:52 | train] - Train Epoch: [99] [729600/1281167 (57%)]	Loss: 0.935235
[2022-03-31 11:47:14 | train] - Train Epoch: [99] [742400/1281167 (58%)]	Loss: 0.910384
[2022-03-31 11:47:37 | train] - Train Epoch: [99] [755200/1281167 (59%)]	Loss: 0.840442
[2022-03-31 11:48:00 | train] - Train Epoch: [99] [768000/1281167 (60%)]	Loss: 0.970916
[2022-03-31 11:48:23 | train] - Train Epoch: [99] [780800/1281167 (61%)]	Loss: 0.919417
[2022-03-31 11:48:45 | train] - Train Epoch: [99] [793600/1281167 (62%)]	Loss: 0.923484
[2022-03-31 11:49:07 | train] - Train Epoch: [99] [806400/1281167 (63%)]	Loss: 1.006238
[2022-03-31 11:49:30 | train] - Train Epoch: [99] [819200/1281167 (64%)]	Loss: 0.762220
[2022-03-31 11:49:51 | train] - Train Epoch: [99] [832000/1281167 (65%)]	Loss: 1.255560
[2022-03-31 11:50:14 | train] - Train Epoch: [99] [844800/1281167 (66%)]	Loss: 0.778784
[2022-03-31 11:50:36 | train] - Train Epoch: [99] [857600/1281167 (67%)]	Loss: 0.974688
[2022-03-31 11:50:58 | train] - Train Epoch: [99] [870400/1281167 (68%)]	Loss: 0.936109
[2022-03-31 11:51:20 | train] - Train Epoch: [99] [883200/1281167 (69%)]	Loss: 0.819005
[2022-03-31 11:51:43 | train] - Train Epoch: [99] [896000/1281167 (70%)]	Loss: 0.852140
[2022-03-31 11:52:05 | train] - Train Epoch: [99] [908800/1281167 (71%)]	Loss: 1.239563
[2022-03-31 11:52:27 | train] - Train Epoch: [99] [921600/1281167 (72%)]	Loss: 0.713805
[2022-03-31 11:52:49 | train] - Train Epoch: [99] [934400/1281167 (73%)]	Loss: 0.958976
[2022-03-31 11:53:12 | train] - Train Epoch: [99] [947200/1281167 (74%)]	Loss: 0.854645
[2022-03-31 11:53:34 | train] - Train Epoch: [99] [960000/1281167 (75%)]	Loss: 0.880666
[2022-03-31 11:53:56 | train] - Train Epoch: [99] [972800/1281167 (76%)]	Loss: 0.614482
[2022-03-31 11:54:18 | train] - Train Epoch: [99] [985600/1281167 (77%)]	Loss: 0.683019
[2022-03-31 11:54:41 | train] - Train Epoch: [99] [998400/1281167 (78%)]	Loss: 1.146336
[2022-03-31 11:55:03 | train] - Train Epoch: [99] [1011200/1281167 (79%)]	Loss: 0.713388
[2022-03-31 11:55:25 | train] - Train Epoch: [99] [1024000/1281167 (80%)]	Loss: 1.011311
[2022-03-31 11:55:48 | train] - Train Epoch: [99] [1036800/1281167 (81%)]	Loss: 0.768313
[2022-03-31 11:56:10 | train] - Train Epoch: [99] [1049600/1281167 (82%)]	Loss: 0.737490
[2022-03-31 11:56:33 | train] - Train Epoch: [99] [1062400/1281167 (83%)]	Loss: 0.803798
[2022-03-31 11:56:54 | train] - Train Epoch: [99] [1075200/1281167 (84%)]	Loss: 0.840307
[2022-03-31 11:57:16 | train] - Train Epoch: [99] [1088000/1281167 (85%)]	Loss: 0.744373
[2022-03-31 11:57:38 | train] - Train Epoch: [99] [1100800/1281167 (86%)]	Loss: 0.673626
[2022-03-31 11:58:01 | train] - Train Epoch: [99] [1113600/1281167 (87%)]	Loss: 0.955058
[2022-03-31 11:58:22 | train] - Train Epoch: [99] [1126400/1281167 (88%)]	Loss: 0.738928
[2022-03-31 11:58:44 | train] - Train Epoch: [99] [1139200/1281167 (89%)]	Loss: 0.917682
[2022-03-31 11:59:07 | train] - Train Epoch: [99] [1152000/1281167 (90%)]	Loss: 0.956420
[2022-03-31 11:59:29 | train] - Train Epoch: [99] [1164800/1281167 (91%)]	Loss: 0.975487
[2022-03-31 11:59:51 | train] - Train Epoch: [99] [1177600/1281167 (92%)]	Loss: 0.880787
[2022-03-31 12:00:13 | train] - Train Epoch: [99] [1190400/1281167 (93%)]	Loss: 0.991567
[2022-03-31 12:00:35 | train] - Train Epoch: [99] [1203200/1281167 (94%)]	Loss: 1.028970
[2022-03-31 12:00:57 | train] - Train Epoch: [99] [1216000/1281167 (95%)]	Loss: 0.740899
[2022-03-31 12:01:19 | train] - Train Epoch: [99] [1228800/1281167 (96%)]	Loss: 0.893995
[2022-03-31 12:01:42 | train] - Train Epoch: [99] [1241600/1281167 (97%)]	Loss: 0.803809
[2022-03-31 12:02:04 | train] - Train Epoch: [99] [1254400/1281167 (98%)]	Loss: 0.687954
[2022-03-31 12:02:27 | train] - Train Epoch: [99] [1267200/1281167 (99%)]	Loss: 0.946580
[2022-03-31 12:02:49 | train] - Train Epoch: [99] [1280000/1281167 (100%)]	Loss: 0.798986
[2022-03-31 12:02:51 | train] - Train Epoch: [99]	 Average Loss: 0.823110	 Total Acc : 79.8812	 Total Top5 Acc : 92.6470
[2022-03-31 12:02:51 | train] - -------99 epoch end-----------
========================================
-------99 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 12:04:27 | train] - 
Epoch [99] Test set: Average loss: 1.3963, Accuracy: 34894/50000 (69.7594%), Top-5 Accuracy: 88.8151%

[2022-03-31 12:04:27 | train] - save intermediate epoch [99] result


[2022-03-31 12:04:37 | train] - -------100 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 12:04:38 | train] - Train Epoch: [100] [0/1281167 (0%)]	Loss: 0.818834
[2022-03-31 12:05:01 | train] - Train Epoch: [100] [12800/1281167 (1%)]	Loss: 0.865173
[2022-03-31 12:05:23 | train] - Train Epoch: [100] [25600/1281167 (2%)]	Loss: 0.835378
[2022-03-31 12:05:46 | train] - Train Epoch: [100] [38400/1281167 (3%)]	Loss: 0.925929
[2022-03-31 12:06:08 | train] - Train Epoch: [100] [51200/1281167 (4%)]	Loss: 0.994900
[2022-03-31 12:06:30 | train] - Train Epoch: [100] [64000/1281167 (5%)]	Loss: 1.002164
[2022-03-31 12:06:52 | train] - Train Epoch: [100] [76800/1281167 (6%)]	Loss: 0.917824
[2022-03-31 12:07:14 | train] - Train Epoch: [100] [89600/1281167 (7%)]	Loss: 0.860013
[2022-03-31 12:07:37 | train] - Train Epoch: [100] [102400/1281167 (8%)]	Loss: 0.610340
[2022-03-31 12:07:58 | train] - Train Epoch: [100] [115200/1281167 (9%)]	Loss: 0.726168
[2022-03-31 12:08:20 | train] - Train Epoch: [100] [128000/1281167 (10%)]	Loss: 0.780749
[2022-03-31 12:08:42 | train] - Train Epoch: [100] [140800/1281167 (11%)]	Loss: 0.803336
[2022-03-31 12:09:05 | train] - Train Epoch: [100] [153600/1281167 (12%)]	Loss: 0.792775
[2022-03-31 12:09:27 | train] - Train Epoch: [100] [166400/1281167 (13%)]	Loss: 1.017735
[2022-03-31 12:09:49 | train] - Train Epoch: [100] [179200/1281167 (14%)]	Loss: 0.611793
[2022-03-31 12:10:12 | train] - Train Epoch: [100] [192000/1281167 (15%)]	Loss: 0.833744
[2022-03-31 12:10:34 | train] - Train Epoch: [100] [204800/1281167 (16%)]	Loss: 0.734504
[2022-03-31 12:10:56 | train] - Train Epoch: [100] [217600/1281167 (17%)]	Loss: 0.769375
[2022-03-31 12:11:19 | train] - Train Epoch: [100] [230400/1281167 (18%)]	Loss: 1.043118
[2022-03-31 12:11:41 | train] - Train Epoch: [100] [243200/1281167 (19%)]	Loss: 0.758021
[2022-03-31 12:12:04 | train] - Train Epoch: [100] [256000/1281167 (20%)]	Loss: 0.740772
[2022-03-31 12:12:26 | train] - Train Epoch: [100] [268800/1281167 (21%)]	Loss: 0.722873
[2022-03-31 12:12:48 | train] - Train Epoch: [100] [281600/1281167 (22%)]	Loss: 1.124367
[2022-03-31 12:13:10 | train] - Train Epoch: [100] [294400/1281167 (23%)]	Loss: 0.855990
[2022-03-31 12:13:32 | train] - Train Epoch: [100] [307200/1281167 (24%)]	Loss: 0.953134
[2022-03-31 12:13:55 | train] - Train Epoch: [100] [320000/1281167 (25%)]	Loss: 0.883359
[2022-03-31 12:14:17 | train] - Train Epoch: [100] [332800/1281167 (26%)]	Loss: 0.876427
[2022-03-31 12:14:40 | train] - Train Epoch: [100] [345600/1281167 (27%)]	Loss: 0.829298
[2022-03-31 12:15:02 | train] - Train Epoch: [100] [358400/1281167 (28%)]	Loss: 0.656160
[2022-03-31 12:15:24 | train] - Train Epoch: [100] [371200/1281167 (29%)]	Loss: 1.071482
[2022-03-31 12:15:46 | train] - Train Epoch: [100] [384000/1281167 (30%)]	Loss: 0.695038
[2022-03-31 12:16:08 | train] - Train Epoch: [100] [396800/1281167 (31%)]	Loss: 0.635178
[2022-03-31 12:16:31 | train] - Train Epoch: [100] [409600/1281167 (32%)]	Loss: 0.665264
[2022-03-31 12:16:53 | train] - Train Epoch: [100] [422400/1281167 (33%)]	Loss: 0.525889
[2022-03-31 12:17:15 | train] - Train Epoch: [100] [435200/1281167 (34%)]	Loss: 0.651430
[2022-03-31 12:17:37 | train] - Train Epoch: [100] [448000/1281167 (35%)]	Loss: 0.837537
[2022-03-31 12:17:58 | train] - Train Epoch: [100] [460800/1281167 (36%)]	Loss: 0.625717
[2022-03-31 12:18:20 | train] - Train Epoch: [100] [473600/1281167 (37%)]	Loss: 0.771720
[2022-03-31 12:18:43 | train] - Train Epoch: [100] [486400/1281167 (38%)]	Loss: 0.803964
[2022-03-31 12:19:05 | train] - Train Epoch: [100] [499200/1281167 (39%)]	Loss: 0.770856
[2022-03-31 12:19:27 | train] - Train Epoch: [100] [512000/1281167 (40%)]	Loss: 0.747369
[2022-03-31 12:19:49 | train] - Train Epoch: [100] [524800/1281167 (41%)]	Loss: 1.052456
[2022-03-31 12:20:11 | train] - Train Epoch: [100] [537600/1281167 (42%)]	Loss: 1.001653
[2022-03-31 12:20:34 | train] - Train Epoch: [100] [550400/1281167 (43%)]	Loss: 1.035467
[2022-03-31 12:20:56 | train] - Train Epoch: [100] [563200/1281167 (44%)]	Loss: 0.916865
[2022-03-31 12:21:19 | train] - Train Epoch: [100] [576000/1281167 (45%)]	Loss: 0.905173
[2022-03-31 12:21:40 | train] - Train Epoch: [100] [588800/1281167 (46%)]	Loss: 0.636361
[2022-03-31 12:22:03 | train] - Train Epoch: [100] [601600/1281167 (47%)]	Loss: 0.901365
[2022-03-31 12:22:25 | train] - Train Epoch: [100] [614400/1281167 (48%)]	Loss: 0.715921
[2022-03-31 12:22:46 | train] - Train Epoch: [100] [627200/1281167 (49%)]	Loss: 0.877873
[2022-03-31 12:23:09 | train] - Train Epoch: [100] [640000/1281167 (50%)]	Loss: 0.652918
[2022-03-31 12:23:31 | train] - Train Epoch: [100] [652800/1281167 (51%)]	Loss: 1.057727
[2022-03-31 12:23:53 | train] - Train Epoch: [100] [665600/1281167 (52%)]	Loss: 0.771585
[2022-03-31 12:24:15 | train] - Train Epoch: [100] [678400/1281167 (53%)]	Loss: 0.668678
[2022-03-31 12:24:38 | train] - Train Epoch: [100] [691200/1281167 (54%)]	Loss: 0.865602
[2022-03-31 12:25:00 | train] - Train Epoch: [100] [704000/1281167 (55%)]	Loss: 0.650042
[2022-03-31 12:25:22 | train] - Train Epoch: [100] [716800/1281167 (56%)]	Loss: 0.597695
[2022-03-31 12:25:44 | train] - Train Epoch: [100] [729600/1281167 (57%)]	Loss: 0.784443
[2022-03-31 12:26:07 | train] - Train Epoch: [100] [742400/1281167 (58%)]	Loss: 0.741001
[2022-03-31 12:26:30 | train] - Train Epoch: [100] [755200/1281167 (59%)]	Loss: 0.660847
[2022-03-31 12:26:52 | train] - Train Epoch: [100] [768000/1281167 (60%)]	Loss: 0.684186
[2022-03-31 12:27:14 | train] - Train Epoch: [100] [780800/1281167 (61%)]	Loss: 0.864370
[2022-03-31 12:27:37 | train] - Train Epoch: [100] [793600/1281167 (62%)]	Loss: 0.965071
[2022-03-31 12:28:00 | train] - Train Epoch: [100] [806400/1281167 (63%)]	Loss: 0.841349
[2022-03-31 12:28:22 | train] - Train Epoch: [100] [819200/1281167 (64%)]	Loss: 0.878222
[2022-03-31 12:28:43 | train] - Train Epoch: [100] [832000/1281167 (65%)]	Loss: 0.830901
[2022-03-31 12:29:06 | train] - Train Epoch: [100] [844800/1281167 (66%)]	Loss: 0.722138
[2022-03-31 12:29:29 | train] - Train Epoch: [100] [857600/1281167 (67%)]	Loss: 0.784370
[2022-03-31 12:29:52 | train] - Train Epoch: [100] [870400/1281167 (68%)]	Loss: 0.897823
[2022-03-31 12:30:13 | train] - Train Epoch: [100] [883200/1281167 (69%)]	Loss: 0.774468
[2022-03-31 12:30:36 | train] - Train Epoch: [100] [896000/1281167 (70%)]	Loss: 0.829437
[2022-03-31 12:30:58 | train] - Train Epoch: [100] [908800/1281167 (71%)]	Loss: 0.848579
[2022-03-31 12:31:21 | train] - Train Epoch: [100] [921600/1281167 (72%)]	Loss: 0.811687
[2022-03-31 12:31:42 | train] - Train Epoch: [100] [934400/1281167 (73%)]	Loss: 0.856383
[2022-03-31 12:32:04 | train] - Train Epoch: [100] [947200/1281167 (74%)]	Loss: 0.736304
[2022-03-31 12:32:26 | train] - Train Epoch: [100] [960000/1281167 (75%)]	Loss: 0.907587
[2022-03-31 12:32:47 | train] - Train Epoch: [100] [972800/1281167 (76%)]	Loss: 0.935933
[2022-03-31 12:33:10 | train] - Train Epoch: [100] [985600/1281167 (77%)]	Loss: 0.650702
[2022-03-31 12:33:32 | train] - Train Epoch: [100] [998400/1281167 (78%)]	Loss: 1.093288
[2022-03-31 12:33:54 | train] - Train Epoch: [100] [1011200/1281167 (79%)]	Loss: 0.949234
[2022-03-31 12:34:16 | train] - Train Epoch: [100] [1024000/1281167 (80%)]	Loss: 1.005666
[2022-03-31 12:34:38 | train] - Train Epoch: [100] [1036800/1281167 (81%)]	Loss: 1.090440
[2022-03-31 12:35:01 | train] - Train Epoch: [100] [1049600/1281167 (82%)]	Loss: 0.609323
[2022-03-31 12:35:23 | train] - Train Epoch: [100] [1062400/1281167 (83%)]	Loss: 1.073183
[2022-03-31 12:35:45 | train] - Train Epoch: [100] [1075200/1281167 (84%)]	Loss: 0.985729
[2022-03-31 12:36:07 | train] - Train Epoch: [100] [1088000/1281167 (85%)]	Loss: 0.748069
[2022-03-31 12:36:28 | train] - Train Epoch: [100] [1100800/1281167 (86%)]	Loss: 0.975629
[2022-03-31 12:36:49 | train] - Train Epoch: [100] [1113600/1281167 (87%)]	Loss: 0.831688
[2022-03-31 12:37:11 | train] - Train Epoch: [100] [1126400/1281167 (88%)]	Loss: 0.987529
[2022-03-31 12:37:34 | train] - Train Epoch: [100] [1139200/1281167 (89%)]	Loss: 0.708665
[2022-03-31 12:37:56 | train] - Train Epoch: [100] [1152000/1281167 (90%)]	Loss: 0.690044
[2022-03-31 12:38:18 | train] - Train Epoch: [100] [1164800/1281167 (91%)]	Loss: 0.848216
[2022-03-31 12:38:39 | train] - Train Epoch: [100] [1177600/1281167 (92%)]	Loss: 1.118731
[2022-03-31 12:39:01 | train] - Train Epoch: [100] [1190400/1281167 (93%)]	Loss: 0.541688
[2022-03-31 12:39:23 | train] - Train Epoch: [100] [1203200/1281167 (94%)]	Loss: 0.719472
[2022-03-31 12:39:46 | train] - Train Epoch: [100] [1216000/1281167 (95%)]	Loss: 0.544449
[2022-03-31 12:40:08 | train] - Train Epoch: [100] [1228800/1281167 (96%)]	Loss: 1.097012
[2022-03-31 12:40:30 | train] - Train Epoch: [100] [1241600/1281167 (97%)]	Loss: 0.768377
[2022-03-31 12:40:52 | train] - Train Epoch: [100] [1254400/1281167 (98%)]	Loss: 0.960319
[2022-03-31 12:41:14 | train] - Train Epoch: [100] [1267200/1281167 (99%)]	Loss: 0.826852
[2022-03-31 12:41:36 | train] - Train Epoch: [100] [1280000/1281167 (100%)]	Loss: 0.951897
[2022-03-31 12:41:38 | train] - Train Epoch: [100]	 Average Loss: 0.820734	 Total Acc : 79.9374	 Total Top5 Acc : 92.6667
[2022-03-31 12:41:38 | train] - -------100 epoch end-----------
========================================
-------100 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 12:43:13 | train] - 
Epoch [100] Test set: Average loss: 1.4017, Accuracy: 34894/50000 (69.7642%), Top-5 Accuracy: 88.8255%

[2022-03-31 12:43:13 | train] - save intermediate epoch [100] result


[2022-03-31 12:43:23 | train] - -------101 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 12:43:25 | train] - Train Epoch: [101] [0/1281167 (0%)]	Loss: 0.651931
[2022-03-31 12:43:47 | train] - Train Epoch: [101] [12800/1281167 (1%)]	Loss: 0.642025
[2022-03-31 12:44:09 | train] - Train Epoch: [101] [25600/1281167 (2%)]	Loss: 0.802419
[2022-03-31 12:44:32 | train] - Train Epoch: [101] [38400/1281167 (3%)]	Loss: 0.656232
[2022-03-31 12:44:55 | train] - Train Epoch: [101] [51200/1281167 (4%)]	Loss: 0.715880
[2022-03-31 12:45:16 | train] - Train Epoch: [101] [64000/1281167 (5%)]	Loss: 0.749088
[2022-03-31 12:45:38 | train] - Train Epoch: [101] [76800/1281167 (6%)]	Loss: 0.793053
[2022-03-31 12:46:00 | train] - Train Epoch: [101] [89600/1281167 (7%)]	Loss: 0.733983
[2022-03-31 12:46:22 | train] - Train Epoch: [101] [102400/1281167 (8%)]	Loss: 0.961396
[2022-03-31 12:46:44 | train] - Train Epoch: [101] [115200/1281167 (9%)]	Loss: 0.808971
[2022-03-31 12:47:06 | train] - Train Epoch: [101] [128000/1281167 (10%)]	Loss: 1.098983
[2022-03-31 12:47:28 | train] - Train Epoch: [101] [140800/1281167 (11%)]	Loss: 0.812320
[2022-03-31 12:47:50 | train] - Train Epoch: [101] [153600/1281167 (12%)]	Loss: 0.747826
[2022-03-31 12:48:12 | train] - Train Epoch: [101] [166400/1281167 (13%)]	Loss: 0.742677
[2022-03-31 12:48:34 | train] - Train Epoch: [101] [179200/1281167 (14%)]	Loss: 0.808618
[2022-03-31 12:48:56 | train] - Train Epoch: [101] [192000/1281167 (15%)]	Loss: 0.601731
[2022-03-31 12:49:18 | train] - Train Epoch: [101] [204800/1281167 (16%)]	Loss: 0.958864
[2022-03-31 12:49:41 | train] - Train Epoch: [101] [217600/1281167 (17%)]	Loss: 0.847330
[2022-03-31 12:50:03 | train] - Train Epoch: [101] [230400/1281167 (18%)]	Loss: 0.861934
[2022-03-31 12:50:25 | train] - Train Epoch: [101] [243200/1281167 (19%)]	Loss: 0.966417
[2022-03-31 12:50:47 | train] - Train Epoch: [101] [256000/1281167 (20%)]	Loss: 0.822440
[2022-03-31 12:51:10 | train] - Train Epoch: [101] [268800/1281167 (21%)]	Loss: 0.647756
[2022-03-31 12:51:32 | train] - Train Epoch: [101] [281600/1281167 (22%)]	Loss: 0.660716
[2022-03-31 12:51:55 | train] - Train Epoch: [101] [294400/1281167 (23%)]	Loss: 0.938411
[2022-03-31 12:52:17 | train] - Train Epoch: [101] [307200/1281167 (24%)]	Loss: 0.784661
[2022-03-31 12:52:39 | train] - Train Epoch: [101] [320000/1281167 (25%)]	Loss: 0.780855
[2022-03-31 12:53:02 | train] - Train Epoch: [101] [332800/1281167 (26%)]	Loss: 0.795337
[2022-03-31 12:53:24 | train] - Train Epoch: [101] [345600/1281167 (27%)]	Loss: 0.741626
[2022-03-31 12:53:46 | train] - Train Epoch: [101] [358400/1281167 (28%)]	Loss: 0.836376
[2022-03-31 12:54:09 | train] - Train Epoch: [101] [371200/1281167 (29%)]	Loss: 0.778194
[2022-03-31 12:54:32 | train] - Train Epoch: [101] [384000/1281167 (30%)]	Loss: 0.883896
[2022-03-31 12:54:54 | train] - Train Epoch: [101] [396800/1281167 (31%)]	Loss: 0.871569
[2022-03-31 12:55:16 | train] - Train Epoch: [101] [409600/1281167 (32%)]	Loss: 0.698826
[2022-03-31 12:55:39 | train] - Train Epoch: [101] [422400/1281167 (33%)]	Loss: 0.667426
[2022-03-31 12:56:01 | train] - Train Epoch: [101] [435200/1281167 (34%)]	Loss: 0.742215
[2022-03-31 12:56:24 | train] - Train Epoch: [101] [448000/1281167 (35%)]	Loss: 0.741583
[2022-03-31 12:56:47 | train] - Train Epoch: [101] [460800/1281167 (36%)]	Loss: 0.861147
[2022-03-31 12:57:09 | train] - Train Epoch: [101] [473600/1281167 (37%)]	Loss: 1.067921
[2022-03-31 12:57:32 | train] - Train Epoch: [101] [486400/1281167 (38%)]	Loss: 1.056658
[2022-03-31 12:57:54 | train] - Train Epoch: [101] [499200/1281167 (39%)]	Loss: 0.917239
[2022-03-31 12:58:16 | train] - Train Epoch: [101] [512000/1281167 (40%)]	Loss: 0.928116
[2022-03-31 12:58:39 | train] - Train Epoch: [101] [524800/1281167 (41%)]	Loss: 0.654050
[2022-03-31 12:59:02 | train] - Train Epoch: [101] [537600/1281167 (42%)]	Loss: 1.041591
[2022-03-31 12:59:24 | train] - Train Epoch: [101] [550400/1281167 (43%)]	Loss: 0.895457
[2022-03-31 12:59:47 | train] - Train Epoch: [101] [563200/1281167 (44%)]	Loss: 0.799395
[2022-03-31 13:00:09 | train] - Train Epoch: [101] [576000/1281167 (45%)]	Loss: 0.613405
[2022-03-31 13:00:31 | train] - Train Epoch: [101] [588800/1281167 (46%)]	Loss: 0.953490
[2022-03-31 13:00:54 | train] - Train Epoch: [101] [601600/1281167 (47%)]	Loss: 0.743184
[2022-03-31 13:01:16 | train] - Train Epoch: [101] [614400/1281167 (48%)]	Loss: 0.731056
[2022-03-31 13:01:39 | train] - Train Epoch: [101] [627200/1281167 (49%)]	Loss: 0.928275
[2022-03-31 13:02:01 | train] - Train Epoch: [101] [640000/1281167 (50%)]	Loss: 0.678586
[2022-03-31 13:02:23 | train] - Train Epoch: [101] [652800/1281167 (51%)]	Loss: 0.529978
[2022-03-31 13:02:46 | train] - Train Epoch: [101] [665600/1281167 (52%)]	Loss: 0.905568
[2022-03-31 13:03:13 | train] - Train Epoch: [101] [678400/1281167 (53%)]	Loss: 0.840112
[2022-03-31 13:03:40 | train] - Train Epoch: [101] [691200/1281167 (54%)]	Loss: 0.549300
[2022-03-31 13:04:07 | train] - Train Epoch: [101] [704000/1281167 (55%)]	Loss: 0.678477
[2022-03-31 13:04:33 | train] - Train Epoch: [101] [716800/1281167 (56%)]	Loss: 0.896587
[2022-03-31 13:05:00 | train] - Train Epoch: [101] [729600/1281167 (57%)]	Loss: 0.821676
[2022-03-31 13:05:27 | train] - Train Epoch: [101] [742400/1281167 (58%)]	Loss: 0.776584
[2022-03-31 13:05:53 | train] - Train Epoch: [101] [755200/1281167 (59%)]	Loss: 0.838416
[2022-03-31 13:06:20 | train] - Train Epoch: [101] [768000/1281167 (60%)]	Loss: 0.968515
[2022-03-31 13:06:47 | train] - Train Epoch: [101] [780800/1281167 (61%)]	Loss: 0.830860
[2022-03-31 13:07:14 | train] - Train Epoch: [101] [793600/1281167 (62%)]	Loss: 0.875260
[2022-03-31 13:07:41 | train] - Train Epoch: [101] [806400/1281167 (63%)]	Loss: 0.955566
[2022-03-31 13:08:08 | train] - Train Epoch: [101] [819200/1281167 (64%)]	Loss: 0.710734
[2022-03-31 13:08:34 | train] - Train Epoch: [101] [832000/1281167 (65%)]	Loss: 0.954534
[2022-03-31 13:09:01 | train] - Train Epoch: [101] [844800/1281167 (66%)]	Loss: 0.799762
[2022-03-31 13:09:29 | train] - Train Epoch: [101] [857600/1281167 (67%)]	Loss: 0.948207
[2022-03-31 13:09:54 | train] - Train Epoch: [101] [870400/1281167 (68%)]	Loss: 0.655333
[2022-03-31 13:10:18 | train] - Train Epoch: [101] [883200/1281167 (69%)]	Loss: 0.985017
[2022-03-31 13:10:41 | train] - Train Epoch: [101] [896000/1281167 (70%)]	Loss: 0.653374
[2022-03-31 13:11:03 | train] - Train Epoch: [101] [908800/1281167 (71%)]	Loss: 0.598765
[2022-03-31 13:11:26 | train] - Train Epoch: [101] [921600/1281167 (72%)]	Loss: 0.762318
[2022-03-31 13:11:49 | train] - Train Epoch: [101] [934400/1281167 (73%)]	Loss: 0.721626
[2022-03-31 13:12:11 | train] - Train Epoch: [101] [947200/1281167 (74%)]	Loss: 0.695336
[2022-03-31 13:12:34 | train] - Train Epoch: [101] [960000/1281167 (75%)]	Loss: 0.985632
[2022-03-31 13:12:56 | train] - Train Epoch: [101] [972800/1281167 (76%)]	Loss: 0.893148
[2022-03-31 13:13:19 | train] - Train Epoch: [101] [985600/1281167 (77%)]	Loss: 1.084300
[2022-03-31 13:13:41 | train] - Train Epoch: [101] [998400/1281167 (78%)]	Loss: 0.965874
[2022-03-31 13:14:04 | train] - Train Epoch: [101] [1011200/1281167 (79%)]	Loss: 1.130882
[2022-03-31 13:14:26 | train] - Train Epoch: [101] [1024000/1281167 (80%)]	Loss: 0.892301
[2022-03-31 13:14:49 | train] - Train Epoch: [101] [1036800/1281167 (81%)]	Loss: 0.917393
[2022-03-31 13:15:12 | train] - Train Epoch: [101] [1049600/1281167 (82%)]	Loss: 0.741605
[2022-03-31 13:15:35 | train] - Train Epoch: [101] [1062400/1281167 (83%)]	Loss: 0.785856
[2022-03-31 13:15:57 | train] - Train Epoch: [101] [1075200/1281167 (84%)]	Loss: 0.785471
[2022-03-31 13:16:19 | train] - Train Epoch: [101] [1088000/1281167 (85%)]	Loss: 0.835796
[2022-03-31 13:16:41 | train] - Train Epoch: [101] [1100800/1281167 (86%)]	Loss: 0.646638
[2022-03-31 13:17:04 | train] - Train Epoch: [101] [1113600/1281167 (87%)]	Loss: 0.915779
[2022-03-31 13:17:27 | train] - Train Epoch: [101] [1126400/1281167 (88%)]	Loss: 0.813809
[2022-03-31 13:17:49 | train] - Train Epoch: [101] [1139200/1281167 (89%)]	Loss: 0.970375
[2022-03-31 13:18:12 | train] - Train Epoch: [101] [1152000/1281167 (90%)]	Loss: 0.797340
[2022-03-31 13:18:34 | train] - Train Epoch: [101] [1164800/1281167 (91%)]	Loss: 0.671722
[2022-03-31 13:18:57 | train] - Train Epoch: [101] [1177600/1281167 (92%)]	Loss: 0.718327
[2022-03-31 13:19:20 | train] - Train Epoch: [101] [1190400/1281167 (93%)]	Loss: 0.803720
[2022-03-31 13:19:43 | train] - Train Epoch: [101] [1203200/1281167 (94%)]	Loss: 0.750163
[2022-03-31 13:20:06 | train] - Train Epoch: [101] [1216000/1281167 (95%)]	Loss: 0.625497
[2022-03-31 13:20:28 | train] - Train Epoch: [101] [1228800/1281167 (96%)]	Loss: 0.565740
[2022-03-31 13:20:51 | train] - Train Epoch: [101] [1241600/1281167 (97%)]	Loss: 0.710839
[2022-03-31 13:21:14 | train] - Train Epoch: [101] [1254400/1281167 (98%)]	Loss: 0.650101
[2022-03-31 13:21:37 | train] - Train Epoch: [101] [1267200/1281167 (99%)]	Loss: 0.759008
[2022-03-31 13:21:59 | train] - Train Epoch: [101] [1280000/1281167 (100%)]	Loss: 0.621807
[2022-03-31 13:22:01 | train] - Train Epoch: [101]	 Average Loss: 0.815204	 Total Acc : 80.0357	 Total Top5 Acc : 92.7603
[2022-03-31 13:22:01 | train] - -------101 epoch end-----------
========================================
-------101 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 13:23:39 | train] - 
Epoch [101] Test set: Average loss: 1.3990, Accuracy: 34868/50000 (69.7075%), Top-5 Accuracy: 88.8527%

[2022-03-31 13:23:39 | train] - save intermediate epoch [101] result


[2022-03-31 13:23:50 | train] - -------102 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 13:23:52 | train] - Train Epoch: [102] [0/1281167 (0%)]	Loss: 0.844227
[2022-03-31 13:24:15 | train] - Train Epoch: [102] [12800/1281167 (1%)]	Loss: 0.795192
[2022-03-31 13:24:37 | train] - Train Epoch: [102] [25600/1281167 (2%)]	Loss: 0.612738
[2022-03-31 13:25:00 | train] - Train Epoch: [102] [38400/1281167 (3%)]	Loss: 0.829688
[2022-03-31 13:25:22 | train] - Train Epoch: [102] [51200/1281167 (4%)]	Loss: 0.480059
[2022-03-31 13:25:45 | train] - Train Epoch: [102] [64000/1281167 (5%)]	Loss: 0.735137
[2022-03-31 13:26:08 | train] - Train Epoch: [102] [76800/1281167 (6%)]	Loss: 0.889232
[2022-03-31 13:26:31 | train] - Train Epoch: [102] [89600/1281167 (7%)]	Loss: 0.723167
[2022-03-31 13:26:54 | train] - Train Epoch: [102] [102400/1281167 (8%)]	Loss: 0.792483
[2022-03-31 13:27:16 | train] - Train Epoch: [102] [115200/1281167 (9%)]	Loss: 0.510180
[2022-03-31 13:27:39 | train] - Train Epoch: [102] [128000/1281167 (10%)]	Loss: 0.687064
[2022-03-31 13:28:01 | train] - Train Epoch: [102] [140800/1281167 (11%)]	Loss: 0.840438
[2022-03-31 13:28:24 | train] - Train Epoch: [102] [153600/1281167 (12%)]	Loss: 0.828617
[2022-03-31 13:28:46 | train] - Train Epoch: [102] [166400/1281167 (13%)]	Loss: 0.811540
[2022-03-31 13:29:09 | train] - Train Epoch: [102] [179200/1281167 (14%)]	Loss: 0.837818
[2022-03-31 13:29:32 | train] - Train Epoch: [102] [192000/1281167 (15%)]	Loss: 0.763983
[2022-03-31 13:29:54 | train] - Train Epoch: [102] [204800/1281167 (16%)]	Loss: 0.924846
[2022-03-31 13:30:16 | train] - Train Epoch: [102] [217600/1281167 (17%)]	Loss: 0.997353
[2022-03-31 13:30:39 | train] - Train Epoch: [102] [230400/1281167 (18%)]	Loss: 0.704578
[2022-03-31 13:31:01 | train] - Train Epoch: [102] [243200/1281167 (19%)]	Loss: 0.781284
[2022-03-31 13:31:24 | train] - Train Epoch: [102] [256000/1281167 (20%)]	Loss: 1.020149
[2022-03-31 13:31:46 | train] - Train Epoch: [102] [268800/1281167 (21%)]	Loss: 0.857982
[2022-03-31 13:32:09 | train] - Train Epoch: [102] [281600/1281167 (22%)]	Loss: 0.716971
[2022-03-31 13:32:31 | train] - Train Epoch: [102] [294400/1281167 (23%)]	Loss: 0.686497
[2022-03-31 13:32:54 | train] - Train Epoch: [102] [307200/1281167 (24%)]	Loss: 0.788559
[2022-03-31 13:33:16 | train] - Train Epoch: [102] [320000/1281167 (25%)]	Loss: 0.583034
[2022-03-31 13:33:39 | train] - Train Epoch: [102] [332800/1281167 (26%)]	Loss: 0.964323
[2022-03-31 13:34:02 | train] - Train Epoch: [102] [345600/1281167 (27%)]	Loss: 0.708191
[2022-03-31 13:34:24 | train] - Train Epoch: [102] [358400/1281167 (28%)]	Loss: 0.710850
[2022-03-31 13:34:47 | train] - Train Epoch: [102] [371200/1281167 (29%)]	Loss: 0.754713
[2022-03-31 13:35:10 | train] - Train Epoch: [102] [384000/1281167 (30%)]	Loss: 0.861473
[2022-03-31 13:35:33 | train] - Train Epoch: [102] [396800/1281167 (31%)]	Loss: 0.819564
[2022-03-31 13:35:56 | train] - Train Epoch: [102] [409600/1281167 (32%)]	Loss: 0.578070
[2022-03-31 13:36:18 | train] - Train Epoch: [102] [422400/1281167 (33%)]	Loss: 0.846172
[2022-03-31 13:36:41 | train] - Train Epoch: [102] [435200/1281167 (34%)]	Loss: 0.932024
[2022-03-31 13:37:03 | train] - Train Epoch: [102] [448000/1281167 (35%)]	Loss: 0.649531
[2022-03-31 13:37:26 | train] - Train Epoch: [102] [460800/1281167 (36%)]	Loss: 0.970132
[2022-03-31 13:37:49 | train] - Train Epoch: [102] [473600/1281167 (37%)]	Loss: 0.676359
[2022-03-31 13:38:11 | train] - Train Epoch: [102] [486400/1281167 (38%)]	Loss: 0.981471
[2022-03-31 13:38:33 | train] - Train Epoch: [102] [499200/1281167 (39%)]	Loss: 0.786254
[2022-03-31 13:38:56 | train] - Train Epoch: [102] [512000/1281167 (40%)]	Loss: 0.596679
[2022-03-31 13:39:18 | train] - Train Epoch: [102] [524800/1281167 (41%)]	Loss: 0.714746
[2022-03-31 13:39:41 | train] - Train Epoch: [102] [537600/1281167 (42%)]	Loss: 0.799327
[2022-03-31 13:40:03 | train] - Train Epoch: [102] [550400/1281167 (43%)]	Loss: 0.602727
[2022-03-31 13:40:26 | train] - Train Epoch: [102] [563200/1281167 (44%)]	Loss: 0.807156
[2022-03-31 13:40:48 | train] - Train Epoch: [102] [576000/1281167 (45%)]	Loss: 0.827238
[2022-03-31 13:41:11 | train] - Train Epoch: [102] [588800/1281167 (46%)]	Loss: 0.768983
[2022-03-31 13:41:34 | train] - Train Epoch: [102] [601600/1281167 (47%)]	Loss: 0.590772
[2022-03-31 13:41:56 | train] - Train Epoch: [102] [614400/1281167 (48%)]	Loss: 0.902573
[2022-03-31 13:42:19 | train] - Train Epoch: [102] [627200/1281167 (49%)]	Loss: 0.833309
[2022-03-31 13:42:42 | train] - Train Epoch: [102] [640000/1281167 (50%)]	Loss: 0.943399
[2022-03-31 13:43:04 | train] - Train Epoch: [102] [652800/1281167 (51%)]	Loss: 0.755539
[2022-03-31 13:43:27 | train] - Train Epoch: [102] [665600/1281167 (52%)]	Loss: 0.556119
[2022-03-31 13:43:50 | train] - Train Epoch: [102] [678400/1281167 (53%)]	Loss: 1.017316
[2022-03-31 13:44:12 | train] - Train Epoch: [102] [691200/1281167 (54%)]	Loss: 0.925888
[2022-03-31 13:44:35 | train] - Train Epoch: [102] [704000/1281167 (55%)]	Loss: 0.801765
[2022-03-31 13:44:57 | train] - Train Epoch: [102] [716800/1281167 (56%)]	Loss: 0.698328
[2022-03-31 13:45:20 | train] - Train Epoch: [102] [729600/1281167 (57%)]	Loss: 0.751994
[2022-03-31 13:45:43 | train] - Train Epoch: [102] [742400/1281167 (58%)]	Loss: 0.983843
[2022-03-31 13:46:05 | train] - Train Epoch: [102] [755200/1281167 (59%)]	Loss: 0.901259
[2022-03-31 13:46:28 | train] - Train Epoch: [102] [768000/1281167 (60%)]	Loss: 0.796409
[2022-03-31 13:46:50 | train] - Train Epoch: [102] [780800/1281167 (61%)]	Loss: 0.671184
[2022-03-31 13:47:13 | train] - Train Epoch: [102] [793600/1281167 (62%)]	Loss: 0.674404
[2022-03-31 13:47:35 | train] - Train Epoch: [102] [806400/1281167 (63%)]	Loss: 0.769314
[2022-03-31 13:47:58 | train] - Train Epoch: [102] [819200/1281167 (64%)]	Loss: 0.647933
[2022-03-31 13:48:20 | train] - Train Epoch: [102] [832000/1281167 (65%)]	Loss: 0.796697
[2022-03-31 13:48:43 | train] - Train Epoch: [102] [844800/1281167 (66%)]	Loss: 0.755205
[2022-03-31 13:49:06 | train] - Train Epoch: [102] [857600/1281167 (67%)]	Loss: 0.717994
[2022-03-31 13:49:28 | train] - Train Epoch: [102] [870400/1281167 (68%)]	Loss: 0.752241
[2022-03-31 13:49:51 | train] - Train Epoch: [102] [883200/1281167 (69%)]	Loss: 0.902041
[2022-03-31 13:50:13 | train] - Train Epoch: [102] [896000/1281167 (70%)]	Loss: 0.833485
[2022-03-31 13:50:35 | train] - Train Epoch: [102] [908800/1281167 (71%)]	Loss: 0.991204
[2022-03-31 13:50:58 | train] - Train Epoch: [102] [921600/1281167 (72%)]	Loss: 0.842419
[2022-03-31 13:51:20 | train] - Train Epoch: [102] [934400/1281167 (73%)]	Loss: 0.949307
[2022-03-31 13:51:43 | train] - Train Epoch: [102] [947200/1281167 (74%)]	Loss: 0.933662
[2022-03-31 13:52:06 | train] - Train Epoch: [102] [960000/1281167 (75%)]	Loss: 1.040790
[2022-03-31 13:52:28 | train] - Train Epoch: [102] [972800/1281167 (76%)]	Loss: 0.789099
[2022-03-31 13:52:51 | train] - Train Epoch: [102] [985600/1281167 (77%)]	Loss: 0.558468
[2022-03-31 13:53:14 | train] - Train Epoch: [102] [998400/1281167 (78%)]	Loss: 0.858375
[2022-03-31 13:53:36 | train] - Train Epoch: [102] [1011200/1281167 (79%)]	Loss: 0.784400
[2022-03-31 13:53:59 | train] - Train Epoch: [102] [1024000/1281167 (80%)]	Loss: 0.683871
[2022-03-31 13:54:21 | train] - Train Epoch: [102] [1036800/1281167 (81%)]	Loss: 0.676780
[2022-03-31 13:54:44 | train] - Train Epoch: [102] [1049600/1281167 (82%)]	Loss: 1.055022
[2022-03-31 13:55:07 | train] - Train Epoch: [102] [1062400/1281167 (83%)]	Loss: 0.688420
[2022-03-31 13:55:29 | train] - Train Epoch: [102] [1075200/1281167 (84%)]	Loss: 0.671752
[2022-03-31 13:55:52 | train] - Train Epoch: [102] [1088000/1281167 (85%)]	Loss: 1.078585
[2022-03-31 13:56:14 | train] - Train Epoch: [102] [1100800/1281167 (86%)]	Loss: 0.879059
[2022-03-31 13:56:37 | train] - Train Epoch: [102] [1113600/1281167 (87%)]	Loss: 0.869847
[2022-03-31 13:56:59 | train] - Train Epoch: [102] [1126400/1281167 (88%)]	Loss: 0.873284
[2022-03-31 13:57:22 | train] - Train Epoch: [102] [1139200/1281167 (89%)]	Loss: 0.904089
[2022-03-31 13:57:44 | train] - Train Epoch: [102] [1152000/1281167 (90%)]	Loss: 0.789243
[2022-03-31 13:58:07 | train] - Train Epoch: [102] [1164800/1281167 (91%)]	Loss: 0.787995
[2022-03-31 13:58:30 | train] - Train Epoch: [102] [1177600/1281167 (92%)]	Loss: 0.953355
[2022-03-31 13:58:52 | train] - Train Epoch: [102] [1190400/1281167 (93%)]	Loss: 0.817113
[2022-03-31 13:59:15 | train] - Train Epoch: [102] [1203200/1281167 (94%)]	Loss: 0.605626
[2022-03-31 13:59:37 | train] - Train Epoch: [102] [1216000/1281167 (95%)]	Loss: 0.790925
[2022-03-31 14:00:00 | train] - Train Epoch: [102] [1228800/1281167 (96%)]	Loss: 1.012217
[2022-03-31 14:00:22 | train] - Train Epoch: [102] [1241600/1281167 (97%)]	Loss: 0.868391
[2022-03-31 14:00:45 | train] - Train Epoch: [102] [1254400/1281167 (98%)]	Loss: 0.884526
[2022-03-31 14:01:07 | train] - Train Epoch: [102] [1267200/1281167 (99%)]	Loss: 0.907921
[2022-03-31 14:01:30 | train] - Train Epoch: [102] [1280000/1281167 (100%)]	Loss: 0.614633
[2022-03-31 14:01:32 | train] - Train Epoch: [102]	 Average Loss: 0.813022	 Total Acc : 80.1169	 Total Top5 Acc : 92.7521
[2022-03-31 14:01:32 | train] - -------102 epoch end-----------
========================================
-------102 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 14:03:09 | train] - 
Epoch [102] Test set: Average loss: 1.4142, Accuracy: 34788/50000 (69.5500%), Top-5 Accuracy: 88.7836%

[2022-03-31 14:03:09 | train] - save intermediate epoch [102] result


[2022-03-31 14:03:19 | train] - -------103 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 14:03:21 | train] - Train Epoch: [103] [0/1281167 (0%)]	Loss: 0.817514
[2022-03-31 14:03:45 | train] - Train Epoch: [103] [12800/1281167 (1%)]	Loss: 0.779966
[2022-03-31 14:04:08 | train] - Train Epoch: [103] [25600/1281167 (2%)]	Loss: 0.787034
[2022-03-31 14:04:30 | train] - Train Epoch: [103] [38400/1281167 (3%)]	Loss: 0.613185
[2022-03-31 14:04:53 | train] - Train Epoch: [103] [51200/1281167 (4%)]	Loss: 0.693090
[2022-03-31 14:05:16 | train] - Train Epoch: [103] [64000/1281167 (5%)]	Loss: 0.819527
[2022-03-31 14:05:38 | train] - Train Epoch: [103] [76800/1281167 (6%)]	Loss: 0.770109
[2022-03-31 14:06:01 | train] - Train Epoch: [103] [89600/1281167 (7%)]	Loss: 0.810784
[2022-03-31 14:06:24 | train] - Train Epoch: [103] [102400/1281167 (8%)]	Loss: 0.599041
[2022-03-31 14:06:46 | train] - Train Epoch: [103] [115200/1281167 (9%)]	Loss: 1.020684
[2022-03-31 14:07:09 | train] - Train Epoch: [103] [128000/1281167 (10%)]	Loss: 0.724740
[2022-03-31 14:07:31 | train] - Train Epoch: [103] [140800/1281167 (11%)]	Loss: 0.609959
[2022-03-31 14:07:54 | train] - Train Epoch: [103] [153600/1281167 (12%)]	Loss: 0.856228
[2022-03-31 14:08:16 | train] - Train Epoch: [103] [166400/1281167 (13%)]	Loss: 0.707860
[2022-03-31 14:08:39 | train] - Train Epoch: [103] [179200/1281167 (14%)]	Loss: 0.576137
[2022-03-31 14:09:02 | train] - Train Epoch: [103] [192000/1281167 (15%)]	Loss: 0.824740
[2022-03-31 14:09:25 | train] - Train Epoch: [103] [204800/1281167 (16%)]	Loss: 0.677847
[2022-03-31 14:09:47 | train] - Train Epoch: [103] [217600/1281167 (17%)]	Loss: 0.903456
[2022-03-31 14:10:10 | train] - Train Epoch: [103] [230400/1281167 (18%)]	Loss: 0.665879
[2022-03-31 14:10:33 | train] - Train Epoch: [103] [243200/1281167 (19%)]	Loss: 0.819895
[2022-03-31 14:10:55 | train] - Train Epoch: [103] [256000/1281167 (20%)]	Loss: 0.748041
[2022-03-31 14:11:18 | train] - Train Epoch: [103] [268800/1281167 (21%)]	Loss: 0.548395
[2022-03-31 14:11:41 | train] - Train Epoch: [103] [281600/1281167 (22%)]	Loss: 1.126392
[2022-03-31 14:12:04 | train] - Train Epoch: [103] [294400/1281167 (23%)]	Loss: 0.890436
[2022-03-31 14:12:26 | train] - Train Epoch: [103] [307200/1281167 (24%)]	Loss: 1.146232
[2022-03-31 14:12:49 | train] - Train Epoch: [103] [320000/1281167 (25%)]	Loss: 0.924585
[2022-03-31 14:13:12 | train] - Train Epoch: [103] [332800/1281167 (26%)]	Loss: 1.322958
[2022-03-31 14:13:34 | train] - Train Epoch: [103] [345600/1281167 (27%)]	Loss: 0.596933
[2022-03-31 14:13:57 | train] - Train Epoch: [103] [358400/1281167 (28%)]	Loss: 0.904648
[2022-03-31 14:14:19 | train] - Train Epoch: [103] [371200/1281167 (29%)]	Loss: 0.916123
[2022-03-31 14:14:42 | train] - Train Epoch: [103] [384000/1281167 (30%)]	Loss: 0.578670
[2022-03-31 14:15:05 | train] - Train Epoch: [103] [396800/1281167 (31%)]	Loss: 0.794901
[2022-03-31 14:15:27 | train] - Train Epoch: [103] [409600/1281167 (32%)]	Loss: 0.934671
[2022-03-31 14:15:50 | train] - Train Epoch: [103] [422400/1281167 (33%)]	Loss: 0.756662
[2022-03-31 14:16:12 | train] - Train Epoch: [103] [435200/1281167 (34%)]	Loss: 0.541099
[2022-03-31 14:16:35 | train] - Train Epoch: [103] [448000/1281167 (35%)]	Loss: 0.769669
[2022-03-31 14:16:57 | train] - Train Epoch: [103] [460800/1281167 (36%)]	Loss: 0.840443
[2022-03-31 14:17:20 | train] - Train Epoch: [103] [473600/1281167 (37%)]	Loss: 0.791924
[2022-03-31 14:17:43 | train] - Train Epoch: [103] [486400/1281167 (38%)]	Loss: 0.972687
[2022-03-31 14:18:06 | train] - Train Epoch: [103] [499200/1281167 (39%)]	Loss: 0.949072
[2022-03-31 14:18:29 | train] - Train Epoch: [103] [512000/1281167 (40%)]	Loss: 0.715633
[2022-03-31 14:18:51 | train] - Train Epoch: [103] [524800/1281167 (41%)]	Loss: 0.773127
[2022-03-31 14:19:14 | train] - Train Epoch: [103] [537600/1281167 (42%)]	Loss: 0.836649
[2022-03-31 14:19:36 | train] - Train Epoch: [103] [550400/1281167 (43%)]	Loss: 0.833000
[2022-03-31 14:19:59 | train] - Train Epoch: [103] [563200/1281167 (44%)]	Loss: 1.048528
[2022-03-31 14:20:22 | train] - Train Epoch: [103] [576000/1281167 (45%)]	Loss: 0.958530
[2022-03-31 14:20:45 | train] - Train Epoch: [103] [588800/1281167 (46%)]	Loss: 0.697216
[2022-03-31 14:21:07 | train] - Train Epoch: [103] [601600/1281167 (47%)]	Loss: 0.881966
[2022-03-31 14:21:30 | train] - Train Epoch: [103] [614400/1281167 (48%)]	Loss: 0.853167
[2022-03-31 14:21:52 | train] - Train Epoch: [103] [627200/1281167 (49%)]	Loss: 0.727812
[2022-03-31 14:22:15 | train] - Train Epoch: [103] [640000/1281167 (50%)]	Loss: 0.832754
[2022-03-31 14:22:38 | train] - Train Epoch: [103] [652800/1281167 (51%)]	Loss: 1.035040
[2022-03-31 14:23:01 | train] - Train Epoch: [103] [665600/1281167 (52%)]	Loss: 0.833965
[2022-03-31 14:23:24 | train] - Train Epoch: [103] [678400/1281167 (53%)]	Loss: 0.877557
[2022-03-31 14:23:46 | train] - Train Epoch: [103] [691200/1281167 (54%)]	Loss: 0.934138
[2022-03-31 14:24:09 | train] - Train Epoch: [103] [704000/1281167 (55%)]	Loss: 0.639862
[2022-03-31 14:24:32 | train] - Train Epoch: [103] [716800/1281167 (56%)]	Loss: 0.877921
[2022-03-31 14:24:55 | train] - Train Epoch: [103] [729600/1281167 (57%)]	Loss: 0.675459
[2022-03-31 14:25:17 | train] - Train Epoch: [103] [742400/1281167 (58%)]	Loss: 1.059933
[2022-03-31 14:25:40 | train] - Train Epoch: [103] [755200/1281167 (59%)]	Loss: 1.170657
[2022-03-31 14:26:02 | train] - Train Epoch: [103] [768000/1281167 (60%)]	Loss: 0.773604
[2022-03-31 14:26:25 | train] - Train Epoch: [103] [780800/1281167 (61%)]	Loss: 0.793724
[2022-03-31 14:26:48 | train] - Train Epoch: [103] [793600/1281167 (62%)]	Loss: 0.940105
[2022-03-31 14:27:10 | train] - Train Epoch: [103] [806400/1281167 (63%)]	Loss: 1.072459
[2022-03-31 14:27:33 | train] - Train Epoch: [103] [819200/1281167 (64%)]	Loss: 0.827699
[2022-03-31 14:27:56 | train] - Train Epoch: [103] [832000/1281167 (65%)]	Loss: 0.723116
[2022-03-31 14:28:19 | train] - Train Epoch: [103] [844800/1281167 (66%)]	Loss: 0.930543
[2022-03-31 14:28:41 | train] - Train Epoch: [103] [857600/1281167 (67%)]	Loss: 0.919494
[2022-03-31 14:29:04 | train] - Train Epoch: [103] [870400/1281167 (68%)]	Loss: 0.770187
[2022-03-31 14:29:27 | train] - Train Epoch: [103] [883200/1281167 (69%)]	Loss: 0.787725
[2022-03-31 14:29:49 | train] - Train Epoch: [103] [896000/1281167 (70%)]	Loss: 0.887225
[2022-03-31 14:30:11 | train] - Train Epoch: [103] [908800/1281167 (71%)]	Loss: 0.947384
[2022-03-31 14:30:34 | train] - Train Epoch: [103] [921600/1281167 (72%)]	Loss: 0.709407
[2022-03-31 14:30:56 | train] - Train Epoch: [103] [934400/1281167 (73%)]	Loss: 0.684621
[2022-03-31 14:31:19 | train] - Train Epoch: [103] [947200/1281167 (74%)]	Loss: 0.541422
[2022-03-31 14:31:41 | train] - Train Epoch: [103] [960000/1281167 (75%)]	Loss: 0.702212
[2022-03-31 14:32:04 | train] - Train Epoch: [103] [972800/1281167 (76%)]	Loss: 0.843843
[2022-03-31 14:32:26 | train] - Train Epoch: [103] [985600/1281167 (77%)]	Loss: 0.930909
[2022-03-31 14:32:49 | train] - Train Epoch: [103] [998400/1281167 (78%)]	Loss: 0.674103
[2022-03-31 14:33:12 | train] - Train Epoch: [103] [1011200/1281167 (79%)]	Loss: 0.881921
[2022-03-31 14:33:34 | train] - Train Epoch: [103] [1024000/1281167 (80%)]	Loss: 0.770428
[2022-03-31 14:33:56 | train] - Train Epoch: [103] [1036800/1281167 (81%)]	Loss: 0.605618
[2022-03-31 14:34:19 | train] - Train Epoch: [103] [1049600/1281167 (82%)]	Loss: 1.045617
[2022-03-31 14:34:41 | train] - Train Epoch: [103] [1062400/1281167 (83%)]	Loss: 0.764829
[2022-03-31 14:35:04 | train] - Train Epoch: [103] [1075200/1281167 (84%)]	Loss: 1.050977
[2022-03-31 14:35:26 | train] - Train Epoch: [103] [1088000/1281167 (85%)]	Loss: 0.745592
[2022-03-31 14:35:49 | train] - Train Epoch: [103] [1100800/1281167 (86%)]	Loss: 0.773637
[2022-03-31 14:36:11 | train] - Train Epoch: [103] [1113600/1281167 (87%)]	Loss: 0.878706
[2022-03-31 14:36:31 | train] - Train Epoch: [103] [1126400/1281167 (88%)]	Loss: 0.878737
[2022-03-31 14:36:50 | train] - Train Epoch: [103] [1139200/1281167 (89%)]	Loss: 0.908342
[2022-03-31 14:37:10 | train] - Train Epoch: [103] [1152000/1281167 (90%)]	Loss: 0.858211
[2022-03-31 14:37:31 | train] - Train Epoch: [103] [1164800/1281167 (91%)]	Loss: 1.044340
[2022-03-31 14:37:51 | train] - Train Epoch: [103] [1177600/1281167 (92%)]	Loss: 0.667956
[2022-03-31 14:38:11 | train] - Train Epoch: [103] [1190400/1281167 (93%)]	Loss: 0.894868
[2022-03-31 14:38:31 | train] - Train Epoch: [103] [1203200/1281167 (94%)]	Loss: 0.661490
[2022-03-31 14:38:51 | train] - Train Epoch: [103] [1216000/1281167 (95%)]	Loss: 0.850398
[2022-03-31 14:39:12 | train] - Train Epoch: [103] [1228800/1281167 (96%)]	Loss: 0.799163
[2022-03-31 14:39:32 | train] - Train Epoch: [103] [1241600/1281167 (97%)]	Loss: 0.934071
[2022-03-31 14:39:52 | train] - Train Epoch: [103] [1254400/1281167 (98%)]	Loss: 0.814971
[2022-03-31 14:40:12 | train] - Train Epoch: [103] [1267200/1281167 (99%)]	Loss: 0.714388
[2022-03-31 14:40:33 | train] - Train Epoch: [103] [1280000/1281167 (100%)]	Loss: 0.737834
[2022-03-31 14:40:35 | train] - Train Epoch: [103]	 Average Loss: 0.809670	 Total Acc : 80.1799	 Total Top5 Acc : 92.7849
[2022-03-31 14:40:35 | train] - -------103 epoch end-----------
========================================
-------103 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 14:42:06 | train] - 
Epoch [103] Test set: Average loss: 1.4043, Accuracy: 34879/50000 (69.7283%), Top-5 Accuracy: 88.7432%

[2022-03-31 14:42:06 | train] - save intermediate epoch [103] result


[2022-03-31 14:42:17 | train] - -------104 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 14:42:19 | train] - Train Epoch: [104] [0/1281167 (0%)]	Loss: 0.525541
[2022-03-31 14:42:39 | train] - Train Epoch: [104] [12800/1281167 (1%)]	Loss: 0.982719
[2022-03-31 14:42:59 | train] - Train Epoch: [104] [25600/1281167 (2%)]	Loss: 0.813361
[2022-03-31 14:43:20 | train] - Train Epoch: [104] [38400/1281167 (3%)]	Loss: 0.703793
[2022-03-31 14:43:41 | train] - Train Epoch: [104] [51200/1281167 (4%)]	Loss: 0.914761
[2022-03-31 14:44:00 | train] - Train Epoch: [104] [64000/1281167 (5%)]	Loss: 0.563331
[2022-03-31 14:44:19 | train] - Train Epoch: [104] [76800/1281167 (6%)]	Loss: 0.681066
[2022-03-31 14:44:38 | train] - Train Epoch: [104] [89600/1281167 (7%)]	Loss: 0.660794
[2022-03-31 14:44:58 | train] - Train Epoch: [104] [102400/1281167 (8%)]	Loss: 0.722079
[2022-03-31 14:45:18 | train] - Train Epoch: [104] [115200/1281167 (9%)]	Loss: 0.876599
[2022-03-31 14:45:38 | train] - Train Epoch: [104] [128000/1281167 (10%)]	Loss: 0.576255
[2022-03-31 14:45:57 | train] - Train Epoch: [104] [140800/1281167 (11%)]	Loss: 0.660608
[2022-03-31 14:46:16 | train] - Train Epoch: [104] [153600/1281167 (12%)]	Loss: 0.664788
[2022-03-31 14:46:36 | train] - Train Epoch: [104] [166400/1281167 (13%)]	Loss: 1.027104
[2022-03-31 14:46:56 | train] - Train Epoch: [104] [179200/1281167 (14%)]	Loss: 0.588239
[2022-03-31 14:47:15 | train] - Train Epoch: [104] [192000/1281167 (15%)]	Loss: 1.016401
[2022-03-31 14:47:34 | train] - Train Epoch: [104] [204800/1281167 (16%)]	Loss: 0.683623
[2022-03-31 14:47:54 | train] - Train Epoch: [104] [217600/1281167 (17%)]	Loss: 0.977432
[2022-03-31 14:48:14 | train] - Train Epoch: [104] [230400/1281167 (18%)]	Loss: 0.695135
[2022-03-31 14:48:34 | train] - Train Epoch: [104] [243200/1281167 (19%)]	Loss: 1.066825
[2022-03-31 14:48:53 | train] - Train Epoch: [104] [256000/1281167 (20%)]	Loss: 0.555982
[2022-03-31 14:49:12 | train] - Train Epoch: [104] [268800/1281167 (21%)]	Loss: 0.763739
[2022-03-31 14:49:32 | train] - Train Epoch: [104] [281600/1281167 (22%)]	Loss: 0.920254
[2022-03-31 14:49:52 | train] - Train Epoch: [104] [294400/1281167 (23%)]	Loss: 0.787089
[2022-03-31 14:50:12 | train] - Train Epoch: [104] [307200/1281167 (24%)]	Loss: 0.697749
[2022-03-31 14:50:31 | train] - Train Epoch: [104] [320000/1281167 (25%)]	Loss: 0.839168
[2022-03-31 14:50:50 | train] - Train Epoch: [104] [332800/1281167 (26%)]	Loss: 0.693732
[2022-03-31 14:51:10 | train] - Train Epoch: [104] [345600/1281167 (27%)]	Loss: 0.628002
[2022-03-31 14:51:30 | train] - Train Epoch: [104] [358400/1281167 (28%)]	Loss: 0.737178
[2022-03-31 14:51:49 | train] - Train Epoch: [104] [371200/1281167 (29%)]	Loss: 0.859935
[2022-03-31 14:52:09 | train] - Train Epoch: [104] [384000/1281167 (30%)]	Loss: 0.722354
[2022-03-31 14:52:29 | train] - Train Epoch: [104] [396800/1281167 (31%)]	Loss: 0.686495
[2022-03-31 14:52:49 | train] - Train Epoch: [104] [409600/1281167 (32%)]	Loss: 0.859004
[2022-03-31 14:53:09 | train] - Train Epoch: [104] [422400/1281167 (33%)]	Loss: 0.840390
[2022-03-31 14:53:28 | train] - Train Epoch: [104] [435200/1281167 (34%)]	Loss: 0.924728
[2022-03-31 14:53:49 | train] - Train Epoch: [104] [448000/1281167 (35%)]	Loss: 0.954015
[2022-03-31 14:54:08 | train] - Train Epoch: [104] [460800/1281167 (36%)]	Loss: 0.709933
[2022-03-31 14:54:28 | train] - Train Epoch: [104] [473600/1281167 (37%)]	Loss: 0.977166
[2022-03-31 14:54:48 | train] - Train Epoch: [104] [486400/1281167 (38%)]	Loss: 0.553834
[2022-03-31 14:55:07 | train] - Train Epoch: [104] [499200/1281167 (39%)]	Loss: 0.887982
[2022-03-31 14:55:26 | train] - Train Epoch: [104] [512000/1281167 (40%)]	Loss: 0.705059
[2022-03-31 14:55:46 | train] - Train Epoch: [104] [524800/1281167 (41%)]	Loss: 0.844831
[2022-03-31 14:56:05 | train] - Train Epoch: [104] [537600/1281167 (42%)]	Loss: 0.554646
[2022-03-31 14:56:24 | train] - Train Epoch: [104] [550400/1281167 (43%)]	Loss: 0.810855
[2022-03-31 14:56:44 | train] - Train Epoch: [104] [563200/1281167 (44%)]	Loss: 0.693974
[2022-03-31 14:57:03 | train] - Train Epoch: [104] [576000/1281167 (45%)]	Loss: 0.655123
[2022-03-31 14:57:22 | train] - Train Epoch: [104] [588800/1281167 (46%)]	Loss: 0.821476
[2022-03-31 14:57:42 | train] - Train Epoch: [104] [601600/1281167 (47%)]	Loss: 0.887325
[2022-03-31 14:58:01 | train] - Train Epoch: [104] [614400/1281167 (48%)]	Loss: 0.922690
[2022-03-31 14:58:20 | train] - Train Epoch: [104] [627200/1281167 (49%)]	Loss: 0.804414
[2022-03-31 14:58:40 | train] - Train Epoch: [104] [640000/1281167 (50%)]	Loss: 0.807677
[2022-03-31 14:59:00 | train] - Train Epoch: [104] [652800/1281167 (51%)]	Loss: 0.977652
[2022-03-31 14:59:19 | train] - Train Epoch: [104] [665600/1281167 (52%)]	Loss: 0.589785
[2022-03-31 14:59:39 | train] - Train Epoch: [104] [678400/1281167 (53%)]	Loss: 0.960665
[2022-03-31 14:59:59 | train] - Train Epoch: [104] [691200/1281167 (54%)]	Loss: 0.936460
[2022-03-31 15:00:19 | train] - Train Epoch: [104] [704000/1281167 (55%)]	Loss: 0.803983
[2022-03-31 15:00:39 | train] - Train Epoch: [104] [716800/1281167 (56%)]	Loss: 0.993666
[2022-03-31 15:00:58 | train] - Train Epoch: [104] [729600/1281167 (57%)]	Loss: 1.055261
[2022-03-31 15:01:17 | train] - Train Epoch: [104] [742400/1281167 (58%)]	Loss: 0.755852
[2022-03-31 15:01:36 | train] - Train Epoch: [104] [755200/1281167 (59%)]	Loss: 0.906706
[2022-03-31 15:01:55 | train] - Train Epoch: [104] [768000/1281167 (60%)]	Loss: 0.530228
[2022-03-31 15:02:15 | train] - Train Epoch: [104] [780800/1281167 (61%)]	Loss: 0.670512
[2022-03-31 15:02:35 | train] - Train Epoch: [104] [793600/1281167 (62%)]	Loss: 0.791779
[2022-03-31 15:02:54 | train] - Train Epoch: [104] [806400/1281167 (63%)]	Loss: 0.986343
[2022-03-31 15:03:14 | train] - Train Epoch: [104] [819200/1281167 (64%)]	Loss: 0.960899
[2022-03-31 15:03:33 | train] - Train Epoch: [104] [832000/1281167 (65%)]	Loss: 0.729930
[2022-03-31 15:03:52 | train] - Train Epoch: [104] [844800/1281167 (66%)]	Loss: 1.023760
[2022-03-31 15:04:12 | train] - Train Epoch: [104] [857600/1281167 (67%)]	Loss: 0.831679
[2022-03-31 15:04:32 | train] - Train Epoch: [104] [870400/1281167 (68%)]	Loss: 0.844310
[2022-03-31 15:04:51 | train] - Train Epoch: [104] [883200/1281167 (69%)]	Loss: 1.032058
[2022-03-31 15:05:10 | train] - Train Epoch: [104] [896000/1281167 (70%)]	Loss: 0.808863
[2022-03-31 15:05:30 | train] - Train Epoch: [104] [908800/1281167 (71%)]	Loss: 0.729774
[2022-03-31 15:05:49 | train] - Train Epoch: [104] [921600/1281167 (72%)]	Loss: 0.714935
[2022-03-31 15:06:09 | train] - Train Epoch: [104] [934400/1281167 (73%)]	Loss: 0.653907
[2022-03-31 15:06:29 | train] - Train Epoch: [104] [947200/1281167 (74%)]	Loss: 0.742654
[2022-03-31 15:06:48 | train] - Train Epoch: [104] [960000/1281167 (75%)]	Loss: 0.886020
[2022-03-31 15:07:08 | train] - Train Epoch: [104] [972800/1281167 (76%)]	Loss: 0.850857
[2022-03-31 15:07:27 | train] - Train Epoch: [104] [985600/1281167 (77%)]	Loss: 0.858211
[2022-03-31 15:07:47 | train] - Train Epoch: [104] [998400/1281167 (78%)]	Loss: 0.531517
[2022-03-31 15:08:06 | train] - Train Epoch: [104] [1011200/1281167 (79%)]	Loss: 0.833108
[2022-03-31 15:08:26 | train] - Train Epoch: [104] [1024000/1281167 (80%)]	Loss: 0.760538
[2022-03-31 15:08:45 | train] - Train Epoch: [104] [1036800/1281167 (81%)]	Loss: 0.807377
[2022-03-31 15:09:05 | train] - Train Epoch: [104] [1049600/1281167 (82%)]	Loss: 0.780227
[2022-03-31 15:09:25 | train] - Train Epoch: [104] [1062400/1281167 (83%)]	Loss: 0.885158
[2022-03-31 15:09:45 | train] - Train Epoch: [104] [1075200/1281167 (84%)]	Loss: 0.699930
[2022-03-31 15:10:04 | train] - Train Epoch: [104] [1088000/1281167 (85%)]	Loss: 0.688100
[2022-03-31 15:10:24 | train] - Train Epoch: [104] [1100800/1281167 (86%)]	Loss: 0.909234
[2022-03-31 15:10:43 | train] - Train Epoch: [104] [1113600/1281167 (87%)]	Loss: 0.751363
[2022-03-31 15:11:03 | train] - Train Epoch: [104] [1126400/1281167 (88%)]	Loss: 0.893715
[2022-03-31 15:11:23 | train] - Train Epoch: [104] [1139200/1281167 (89%)]	Loss: 0.853961
[2022-03-31 15:11:42 | train] - Train Epoch: [104] [1152000/1281167 (90%)]	Loss: 0.915212
[2022-03-31 15:12:01 | train] - Train Epoch: [104] [1164800/1281167 (91%)]	Loss: 0.965518
[2022-03-31 15:12:20 | train] - Train Epoch: [104] [1177600/1281167 (92%)]	Loss: 0.832077
[2022-03-31 15:12:39 | train] - Train Epoch: [104] [1190400/1281167 (93%)]	Loss: 0.841386
[2022-03-31 15:12:59 | train] - Train Epoch: [104] [1203200/1281167 (94%)]	Loss: 0.686719
[2022-03-31 15:13:19 | train] - Train Epoch: [104] [1216000/1281167 (95%)]	Loss: 0.837669
[2022-03-31 15:13:39 | train] - Train Epoch: [104] [1228800/1281167 (96%)]	Loss: 0.942862
[2022-03-31 15:13:58 | train] - Train Epoch: [104] [1241600/1281167 (97%)]	Loss: 0.947558
[2022-03-31 15:14:19 | train] - Train Epoch: [104] [1254400/1281167 (98%)]	Loss: 0.805187
[2022-03-31 15:14:38 | train] - Train Epoch: [104] [1267200/1281167 (99%)]	Loss: 0.826281
[2022-03-31 15:14:58 | train] - Train Epoch: [104] [1280000/1281167 (100%)]	Loss: 0.823815
[2022-03-31 15:14:59 | train] - Train Epoch: [104]	 Average Loss: 0.806017	 Total Acc : 80.2959	 Total Top5 Acc : 92.8358
[2022-03-31 15:14:59 | train] - -------104 epoch end-----------
========================================
-------104 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 15:16:29 | train] - 
Epoch [104] Test set: Average loss: 1.4046, Accuracy: 34822/50000 (69.6228%), Top-5 Accuracy: 88.8411%

[2022-03-31 15:16:29 | train] - save intermediate epoch [104] result


[2022-03-31 15:16:40 | train] - -------105 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 15:16:42 | train] - Train Epoch: [105] [0/1281167 (0%)]	Loss: 0.735094
[2022-03-31 15:17:01 | train] - Train Epoch: [105] [12800/1281167 (1%)]	Loss: 0.526852
[2022-03-31 15:17:22 | train] - Train Epoch: [105] [25600/1281167 (2%)]	Loss: 1.017668
[2022-03-31 15:17:43 | train] - Train Epoch: [105] [38400/1281167 (3%)]	Loss: 0.652154
[2022-03-31 15:18:05 | train] - Train Epoch: [105] [51200/1281167 (4%)]	Loss: 0.655057
[2022-03-31 15:18:26 | train] - Train Epoch: [105] [64000/1281167 (5%)]	Loss: 0.697668
[2022-03-31 15:18:46 | train] - Train Epoch: [105] [76800/1281167 (6%)]	Loss: 0.687132
[2022-03-31 15:19:07 | train] - Train Epoch: [105] [89600/1281167 (7%)]	Loss: 0.806520
[2022-03-31 15:19:28 | train] - Train Epoch: [105] [102400/1281167 (8%)]	Loss: 0.635225
[2022-03-31 15:19:47 | train] - Train Epoch: [105] [115200/1281167 (9%)]	Loss: 0.736622
[2022-03-31 15:20:07 | train] - Train Epoch: [105] [128000/1281167 (10%)]	Loss: 0.781680
[2022-03-31 15:20:26 | train] - Train Epoch: [105] [140800/1281167 (11%)]	Loss: 0.721824
[2022-03-31 15:20:46 | train] - Train Epoch: [105] [153600/1281167 (12%)]	Loss: 0.700112
[2022-03-31 15:21:05 | train] - Train Epoch: [105] [166400/1281167 (13%)]	Loss: 0.681884
[2022-03-31 15:21:25 | train] - Train Epoch: [105] [179200/1281167 (14%)]	Loss: 0.623771
[2022-03-31 15:21:44 | train] - Train Epoch: [105] [192000/1281167 (15%)]	Loss: 1.016241
[2022-03-31 15:22:03 | train] - Train Epoch: [105] [204800/1281167 (16%)]	Loss: 0.684137
[2022-03-31 15:22:23 | train] - Train Epoch: [105] [217600/1281167 (17%)]	Loss: 0.872875
[2022-03-31 15:22:42 | train] - Train Epoch: [105] [230400/1281167 (18%)]	Loss: 0.690508
[2022-03-31 15:23:01 | train] - Train Epoch: [105] [243200/1281167 (19%)]	Loss: 0.865743
[2022-03-31 15:23:20 | train] - Train Epoch: [105] [256000/1281167 (20%)]	Loss: 0.760228
[2022-03-31 15:23:39 | train] - Train Epoch: [105] [268800/1281167 (21%)]	Loss: 0.843461
[2022-03-31 15:23:59 | train] - Train Epoch: [105] [281600/1281167 (22%)]	Loss: 0.740886
[2022-03-31 15:24:18 | train] - Train Epoch: [105] [294400/1281167 (23%)]	Loss: 0.765905
[2022-03-31 15:24:38 | train] - Train Epoch: [105] [307200/1281167 (24%)]	Loss: 0.840150
[2022-03-31 15:24:58 | train] - Train Epoch: [105] [320000/1281167 (25%)]	Loss: 0.811122
[2022-03-31 15:25:17 | train] - Train Epoch: [105] [332800/1281167 (26%)]	Loss: 0.792651
[2022-03-31 15:25:37 | train] - Train Epoch: [105] [345600/1281167 (27%)]	Loss: 0.535169
[2022-03-31 15:25:57 | train] - Train Epoch: [105] [358400/1281167 (28%)]	Loss: 1.075643
[2022-03-31 15:26:16 | train] - Train Epoch: [105] [371200/1281167 (29%)]	Loss: 0.905292
[2022-03-31 15:26:36 | train] - Train Epoch: [105] [384000/1281167 (30%)]	Loss: 0.838651
[2022-03-31 15:26:55 | train] - Train Epoch: [105] [396800/1281167 (31%)]	Loss: 0.620699
[2022-03-31 15:27:15 | train] - Train Epoch: [105] [409600/1281167 (32%)]	Loss: 0.699525
[2022-03-31 15:27:35 | train] - Train Epoch: [105] [422400/1281167 (33%)]	Loss: 0.983345
[2022-03-31 15:27:54 | train] - Train Epoch: [105] [435200/1281167 (34%)]	Loss: 0.725830
[2022-03-31 15:28:14 | train] - Train Epoch: [105] [448000/1281167 (35%)]	Loss: 0.800778
[2022-03-31 15:28:33 | train] - Train Epoch: [105] [460800/1281167 (36%)]	Loss: 0.852917
[2022-03-31 15:28:53 | train] - Train Epoch: [105] [473600/1281167 (37%)]	Loss: 0.839291
[2022-03-31 15:29:13 | train] - Train Epoch: [105] [486400/1281167 (38%)]	Loss: 0.959314
[2022-03-31 15:29:33 | train] - Train Epoch: [105] [499200/1281167 (39%)]	Loss: 0.938967
[2022-03-31 15:29:53 | train] - Train Epoch: [105] [512000/1281167 (40%)]	Loss: 0.752468
[2022-03-31 15:30:12 | train] - Train Epoch: [105] [524800/1281167 (41%)]	Loss: 0.663158
[2022-03-31 15:30:32 | train] - Train Epoch: [105] [537600/1281167 (42%)]	Loss: 0.772754
[2022-03-31 15:30:51 | train] - Train Epoch: [105] [550400/1281167 (43%)]	Loss: 0.961112
[2022-03-31 15:31:10 | train] - Train Epoch: [105] [563200/1281167 (44%)]	Loss: 0.962144
[2022-03-31 15:31:29 | train] - Train Epoch: [105] [576000/1281167 (45%)]	Loss: 0.815887
[2022-03-31 15:31:49 | train] - Train Epoch: [105] [588800/1281167 (46%)]	Loss: 0.821883
[2022-03-31 15:32:08 | train] - Train Epoch: [105] [601600/1281167 (47%)]	Loss: 1.111152
[2022-03-31 15:32:28 | train] - Train Epoch: [105] [614400/1281167 (48%)]	Loss: 0.855816
[2022-03-31 15:32:48 | train] - Train Epoch: [105] [627200/1281167 (49%)]	Loss: 0.965724
[2022-03-31 15:33:07 | train] - Train Epoch: [105] [640000/1281167 (50%)]	Loss: 0.946874
[2022-03-31 15:33:27 | train] - Train Epoch: [105] [652800/1281167 (51%)]	Loss: 0.695135
[2022-03-31 15:33:47 | train] - Train Epoch: [105] [665600/1281167 (52%)]	Loss: 0.705778
[2022-03-31 15:34:07 | train] - Train Epoch: [105] [678400/1281167 (53%)]	Loss: 0.875441
[2022-03-31 15:34:27 | train] - Train Epoch: [105] [691200/1281167 (54%)]	Loss: 0.614518
[2022-03-31 15:34:47 | train] - Train Epoch: [105] [704000/1281167 (55%)]	Loss: 0.798443
[2022-03-31 15:35:06 | train] - Train Epoch: [105] [716800/1281167 (56%)]	Loss: 0.688408
[2022-03-31 15:35:26 | train] - Train Epoch: [105] [729600/1281167 (57%)]	Loss: 1.044990
[2022-03-31 15:35:45 | train] - Train Epoch: [105] [742400/1281167 (58%)]	Loss: 0.773982
[2022-03-31 15:36:05 | train] - Train Epoch: [105] [755200/1281167 (59%)]	Loss: 0.929989
[2022-03-31 15:36:25 | train] - Train Epoch: [105] [768000/1281167 (60%)]	Loss: 0.594066
[2022-03-31 15:36:45 | train] - Train Epoch: [105] [780800/1281167 (61%)]	Loss: 0.837983
[2022-03-31 15:37:05 | train] - Train Epoch: [105] [793600/1281167 (62%)]	Loss: 0.977478
[2022-03-31 15:37:25 | train] - Train Epoch: [105] [806400/1281167 (63%)]	Loss: 0.779815
[2022-03-31 15:37:44 | train] - Train Epoch: [105] [819200/1281167 (64%)]	Loss: 0.725300
[2022-03-31 15:38:04 | train] - Train Epoch: [105] [832000/1281167 (65%)]	Loss: 0.756133
[2022-03-31 15:38:23 | train] - Train Epoch: [105] [844800/1281167 (66%)]	Loss: 0.683547
[2022-03-31 15:38:42 | train] - Train Epoch: [105] [857600/1281167 (67%)]	Loss: 0.912601
[2022-03-31 15:39:02 | train] - Train Epoch: [105] [870400/1281167 (68%)]	Loss: 0.746444
[2022-03-31 15:39:22 | train] - Train Epoch: [105] [883200/1281167 (69%)]	Loss: 0.841766
[2022-03-31 15:39:41 | train] - Train Epoch: [105] [896000/1281167 (70%)]	Loss: 1.081234
[2022-03-31 15:40:01 | train] - Train Epoch: [105] [908800/1281167 (71%)]	Loss: 0.926155
[2022-03-31 15:40:21 | train] - Train Epoch: [105] [921600/1281167 (72%)]	Loss: 0.628248
[2022-03-31 15:40:40 | train] - Train Epoch: [105] [934400/1281167 (73%)]	Loss: 0.947496
[2022-03-31 15:41:00 | train] - Train Epoch: [105] [947200/1281167 (74%)]	Loss: 0.892773
[2022-03-31 15:41:20 | train] - Train Epoch: [105] [960000/1281167 (75%)]	Loss: 0.881939
[2022-03-31 15:41:40 | train] - Train Epoch: [105] [972800/1281167 (76%)]	Loss: 0.772965
[2022-03-31 15:41:59 | train] - Train Epoch: [105] [985600/1281167 (77%)]	Loss: 0.825870
[2022-03-31 15:42:19 | train] - Train Epoch: [105] [998400/1281167 (78%)]	Loss: 0.876531
[2022-03-31 15:42:39 | train] - Train Epoch: [105] [1011200/1281167 (79%)]	Loss: 0.829275
[2022-03-31 15:42:59 | train] - Train Epoch: [105] [1024000/1281167 (80%)]	Loss: 0.619260
[2022-03-31 15:43:19 | train] - Train Epoch: [105] [1036800/1281167 (81%)]	Loss: 0.657731
[2022-03-31 15:43:38 | train] - Train Epoch: [105] [1049600/1281167 (82%)]	Loss: 0.749433
[2022-03-31 15:43:58 | train] - Train Epoch: [105] [1062400/1281167 (83%)]	Loss: 0.763943
[2022-03-31 15:44:17 | train] - Train Epoch: [105] [1075200/1281167 (84%)]	Loss: 0.700807
[2022-03-31 15:44:37 | train] - Train Epoch: [105] [1088000/1281167 (85%)]	Loss: 0.839287
[2022-03-31 15:44:57 | train] - Train Epoch: [105] [1100800/1281167 (86%)]	Loss: 0.717199
[2022-03-31 15:45:17 | train] - Train Epoch: [105] [1113600/1281167 (87%)]	Loss: 0.772544
[2022-03-31 15:45:37 | train] - Train Epoch: [105] [1126400/1281167 (88%)]	Loss: 0.781196
[2022-03-31 15:45:56 | train] - Train Epoch: [105] [1139200/1281167 (89%)]	Loss: 0.665066
[2022-03-31 15:46:17 | train] - Train Epoch: [105] [1152000/1281167 (90%)]	Loss: 0.869634
[2022-03-31 15:46:36 | train] - Train Epoch: [105] [1164800/1281167 (91%)]	Loss: 0.886539
[2022-03-31 15:46:59 | train] - Train Epoch: [105] [1177600/1281167 (92%)]	Loss: 0.952966
[2022-03-31 15:47:18 | train] - Train Epoch: [105] [1190400/1281167 (93%)]	Loss: 0.684257
[2022-03-31 15:47:38 | train] - Train Epoch: [105] [1203200/1281167 (94%)]	Loss: 0.940337
[2022-03-31 15:47:58 | train] - Train Epoch: [105] [1216000/1281167 (95%)]	Loss: 0.907226
[2022-03-31 15:48:18 | train] - Train Epoch: [105] [1228800/1281167 (96%)]	Loss: 0.603242
[2022-03-31 15:48:38 | train] - Train Epoch: [105] [1241600/1281167 (97%)]	Loss: 0.743354
[2022-03-31 15:48:58 | train] - Train Epoch: [105] [1254400/1281167 (98%)]	Loss: 0.726210
[2022-03-31 15:49:17 | train] - Train Epoch: [105] [1267200/1281167 (99%)]	Loss: 0.757475
[2022-03-31 15:49:37 | train] - Train Epoch: [105] [1280000/1281167 (100%)]	Loss: 0.820029
[2022-03-31 15:49:39 | train] - Train Epoch: [105]	 Average Loss: 0.801582	 Total Acc : 80.3499	 Total Top5 Acc : 92.8885
[2022-03-31 15:49:39 | train] - -------105 epoch end-----------
========================================
-------105 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 15:51:11 | train] - 
Epoch [105] Test set: Average loss: 1.4145, Accuracy: 34852/50000 (69.6767%), Top-5 Accuracy: 88.8707%

[2022-03-31 15:51:11 | train] - save intermediate epoch [105] result


[2022-03-31 15:51:23 | train] - -------106 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 15:51:25 | train] - Train Epoch: [106] [0/1281167 (0%)]	Loss: 0.895906
[2022-03-31 15:51:46 | train] - Train Epoch: [106] [12800/1281167 (1%)]	Loss: 0.840252
[2022-03-31 15:52:08 | train] - Train Epoch: [106] [25600/1281167 (2%)]	Loss: 0.656269
[2022-03-31 15:52:29 | train] - Train Epoch: [106] [38400/1281167 (3%)]	Loss: 0.587415
[2022-03-31 15:52:50 | train] - Train Epoch: [106] [51200/1281167 (4%)]	Loss: 0.766635
[2022-03-31 15:53:12 | train] - Train Epoch: [106] [64000/1281167 (5%)]	Loss: 0.885395
[2022-03-31 15:53:32 | train] - Train Epoch: [106] [76800/1281167 (6%)]	Loss: 0.909870
[2022-03-31 15:53:54 | train] - Train Epoch: [106] [89600/1281167 (7%)]	Loss: 0.798035
[2022-03-31 15:54:15 | train] - Train Epoch: [106] [102400/1281167 (8%)]	Loss: 0.744536
[2022-03-31 15:54:35 | train] - Train Epoch: [106] [115200/1281167 (9%)]	Loss: 0.852843
[2022-03-31 15:54:57 | train] - Train Epoch: [106] [128000/1281167 (10%)]	Loss: 1.103486
[2022-03-31 15:55:18 | train] - Train Epoch: [106] [140800/1281167 (11%)]	Loss: 0.666510
[2022-03-31 15:55:38 | train] - Train Epoch: [106] [153600/1281167 (12%)]	Loss: 0.678122
[2022-03-31 15:56:00 | train] - Train Epoch: [106] [166400/1281167 (13%)]	Loss: 0.702578
[2022-03-31 15:56:21 | train] - Train Epoch: [106] [179200/1281167 (14%)]	Loss: 0.568986
[2022-03-31 15:56:42 | train] - Train Epoch: [106] [192000/1281167 (15%)]	Loss: 0.854880
[2022-03-31 15:57:03 | train] - Train Epoch: [106] [204800/1281167 (16%)]	Loss: 0.769900
[2022-03-31 15:57:24 | train] - Train Epoch: [106] [217600/1281167 (17%)]	Loss: 0.866981
[2022-03-31 15:57:45 | train] - Train Epoch: [106] [230400/1281167 (18%)]	Loss: 0.836834
[2022-03-31 15:58:07 | train] - Train Epoch: [106] [243200/1281167 (19%)]	Loss: 1.026342
[2022-03-31 15:58:28 | train] - Train Epoch: [106] [256000/1281167 (20%)]	Loss: 0.553011
[2022-03-31 15:58:49 | train] - Train Epoch: [106] [268800/1281167 (21%)]	Loss: 0.738566
[2022-03-31 15:59:09 | train] - Train Epoch: [106] [281600/1281167 (22%)]	Loss: 0.594023
[2022-03-31 15:59:29 | train] - Train Epoch: [106] [294400/1281167 (23%)]	Loss: 0.768357
[2022-03-31 15:59:49 | train] - Train Epoch: [106] [307200/1281167 (24%)]	Loss: 0.852534
[2022-03-31 16:00:08 | train] - Train Epoch: [106] [320000/1281167 (25%)]	Loss: 0.609884
[2022-03-31 16:00:27 | train] - Train Epoch: [106] [332800/1281167 (26%)]	Loss: 0.748654
[2022-03-31 16:00:46 | train] - Train Epoch: [106] [345600/1281167 (27%)]	Loss: 0.904310
[2022-03-31 16:01:06 | train] - Train Epoch: [106] [358400/1281167 (28%)]	Loss: 0.655634
[2022-03-31 16:01:26 | train] - Train Epoch: [106] [371200/1281167 (29%)]	Loss: 0.985414
[2022-03-31 16:01:46 | train] - Train Epoch: [106] [384000/1281167 (30%)]	Loss: 0.619043
[2022-03-31 16:02:05 | train] - Train Epoch: [106] [396800/1281167 (31%)]	Loss: 1.203873
[2022-03-31 16:02:25 | train] - Train Epoch: [106] [409600/1281167 (32%)]	Loss: 0.714164
[2022-03-31 16:02:45 | train] - Train Epoch: [106] [422400/1281167 (33%)]	Loss: 0.621577
[2022-03-31 16:03:04 | train] - Train Epoch: [106] [435200/1281167 (34%)]	Loss: 0.858545
[2022-03-31 16:03:24 | train] - Train Epoch: [106] [448000/1281167 (35%)]	Loss: 0.850621
[2022-03-31 16:03:44 | train] - Train Epoch: [106] [460800/1281167 (36%)]	Loss: 0.520965
[2022-03-31 16:04:04 | train] - Train Epoch: [106] [473600/1281167 (37%)]	Loss: 0.711294
[2022-03-31 16:04:24 | train] - Train Epoch: [106] [486400/1281167 (38%)]	Loss: 0.718642
[2022-03-31 16:04:43 | train] - Train Epoch: [106] [499200/1281167 (39%)]	Loss: 0.818117
[2022-03-31 16:05:02 | train] - Train Epoch: [106] [512000/1281167 (40%)]	Loss: 0.692791
[2022-03-31 16:05:22 | train] - Train Epoch: [106] [524800/1281167 (41%)]	Loss: 0.619125
[2022-03-31 16:05:41 | train] - Train Epoch: [106] [537600/1281167 (42%)]	Loss: 0.656703
[2022-03-31 16:06:01 | train] - Train Epoch: [106] [550400/1281167 (43%)]	Loss: 0.893540
[2022-03-31 16:06:21 | train] - Train Epoch: [106] [563200/1281167 (44%)]	Loss: 0.594559
[2022-03-31 16:06:40 | train] - Train Epoch: [106] [576000/1281167 (45%)]	Loss: 0.870145
[2022-03-31 16:07:00 | train] - Train Epoch: [106] [588800/1281167 (46%)]	Loss: 0.703070
[2022-03-31 16:07:19 | train] - Train Epoch: [106] [601600/1281167 (47%)]	Loss: 0.743799
[2022-03-31 16:07:39 | train] - Train Epoch: [106] [614400/1281167 (48%)]	Loss: 0.595266
[2022-03-31 16:07:58 | train] - Train Epoch: [106] [627200/1281167 (49%)]	Loss: 0.705780
[2022-03-31 16:08:18 | train] - Train Epoch: [106] [640000/1281167 (50%)]	Loss: 0.911446
[2022-03-31 16:08:37 | train] - Train Epoch: [106] [652800/1281167 (51%)]	Loss: 0.859630
[2022-03-31 16:08:57 | train] - Train Epoch: [106] [665600/1281167 (52%)]	Loss: 0.892500
[2022-03-31 16:09:17 | train] - Train Epoch: [106] [678400/1281167 (53%)]	Loss: 0.652137
[2022-03-31 16:09:36 | train] - Train Epoch: [106] [691200/1281167 (54%)]	Loss: 0.826927
[2022-03-31 16:09:57 | train] - Train Epoch: [106] [704000/1281167 (55%)]	Loss: 0.777351
[2022-03-31 16:10:16 | train] - Train Epoch: [106] [716800/1281167 (56%)]	Loss: 1.190838
[2022-03-31 16:10:36 | train] - Train Epoch: [106] [729600/1281167 (57%)]	Loss: 1.088954
[2022-03-31 16:10:56 | train] - Train Epoch: [106] [742400/1281167 (58%)]	Loss: 0.888425
[2022-03-31 16:11:15 | train] - Train Epoch: [106] [755200/1281167 (59%)]	Loss: 0.480490
[2022-03-31 16:11:35 | train] - Train Epoch: [106] [768000/1281167 (60%)]	Loss: 0.995692
[2022-03-31 16:11:54 | train] - Train Epoch: [106] [780800/1281167 (61%)]	Loss: 0.833275
[2022-03-31 16:12:14 | train] - Train Epoch: [106] [793600/1281167 (62%)]	Loss: 0.759271
[2022-03-31 16:12:34 | train] - Train Epoch: [106] [806400/1281167 (63%)]	Loss: 0.742303
[2022-03-31 16:12:53 | train] - Train Epoch: [106] [819200/1281167 (64%)]	Loss: 0.569839
[2022-03-31 16:13:13 | train] - Train Epoch: [106] [832000/1281167 (65%)]	Loss: 0.683437
[2022-03-31 16:13:33 | train] - Train Epoch: [106] [844800/1281167 (66%)]	Loss: 0.751004
[2022-03-31 16:13:52 | train] - Train Epoch: [106] [857600/1281167 (67%)]	Loss: 0.855934
[2022-03-31 16:14:12 | train] - Train Epoch: [106] [870400/1281167 (68%)]	Loss: 0.800078
[2022-03-31 16:14:32 | train] - Train Epoch: [106] [883200/1281167 (69%)]	Loss: 0.563214
[2022-03-31 16:14:52 | train] - Train Epoch: [106] [896000/1281167 (70%)]	Loss: 0.673032
[2022-03-31 16:15:12 | train] - Train Epoch: [106] [908800/1281167 (71%)]	Loss: 0.593880
[2022-03-31 16:15:31 | train] - Train Epoch: [106] [921600/1281167 (72%)]	Loss: 0.835263
[2022-03-31 16:15:51 | train] - Train Epoch: [106] [934400/1281167 (73%)]	Loss: 0.684572
[2022-03-31 16:16:10 | train] - Train Epoch: [106] [947200/1281167 (74%)]	Loss: 0.781257
[2022-03-31 16:16:30 | train] - Train Epoch: [106] [960000/1281167 (75%)]	Loss: 0.731516
[2022-03-31 16:16:50 | train] - Train Epoch: [106] [972800/1281167 (76%)]	Loss: 0.692088
[2022-03-31 16:17:09 | train] - Train Epoch: [106] [985600/1281167 (77%)]	Loss: 0.874599
[2022-03-31 16:17:30 | train] - Train Epoch: [106] [998400/1281167 (78%)]	Loss: 0.787442
[2022-03-31 16:17:49 | train] - Train Epoch: [106] [1011200/1281167 (79%)]	Loss: 0.834655
[2022-03-31 16:18:09 | train] - Train Epoch: [106] [1024000/1281167 (80%)]	Loss: 0.857035
[2022-03-31 16:18:29 | train] - Train Epoch: [106] [1036800/1281167 (81%)]	Loss: 0.731385
[2022-03-31 16:18:49 | train] - Train Epoch: [106] [1049600/1281167 (82%)]	Loss: 1.071214
[2022-03-31 16:19:09 | train] - Train Epoch: [106] [1062400/1281167 (83%)]	Loss: 0.846359
[2022-03-31 16:19:28 | train] - Train Epoch: [106] [1075200/1281167 (84%)]	Loss: 1.027993
[2022-03-31 16:19:48 | train] - Train Epoch: [106] [1088000/1281167 (85%)]	Loss: 0.697544
[2022-03-31 16:20:08 | train] - Train Epoch: [106] [1100800/1281167 (86%)]	Loss: 0.998111
[2022-03-31 16:20:27 | train] - Train Epoch: [106] [1113600/1281167 (87%)]	Loss: 0.844147
[2022-03-31 16:20:47 | train] - Train Epoch: [106] [1126400/1281167 (88%)]	Loss: 0.661375
[2022-03-31 16:21:07 | train] - Train Epoch: [106] [1139200/1281167 (89%)]	Loss: 0.882246
[2022-03-31 16:21:26 | train] - Train Epoch: [106] [1152000/1281167 (90%)]	Loss: 0.669866
[2022-03-31 16:21:46 | train] - Train Epoch: [106] [1164800/1281167 (91%)]	Loss: 0.739406
[2022-03-31 16:22:05 | train] - Train Epoch: [106] [1177600/1281167 (92%)]	Loss: 0.567429
[2022-03-31 16:22:25 | train] - Train Epoch: [106] [1190400/1281167 (93%)]	Loss: 0.617084
[2022-03-31 16:22:44 | train] - Train Epoch: [106] [1203200/1281167 (94%)]	Loss: 0.888786
[2022-03-31 16:23:04 | train] - Train Epoch: [106] [1216000/1281167 (95%)]	Loss: 0.941683
[2022-03-31 16:23:24 | train] - Train Epoch: [106] [1228800/1281167 (96%)]	Loss: 0.850755
[2022-03-31 16:23:44 | train] - Train Epoch: [106] [1241600/1281167 (97%)]	Loss: 0.781098
[2022-03-31 16:24:03 | train] - Train Epoch: [106] [1254400/1281167 (98%)]	Loss: 0.818264
[2022-03-31 16:24:23 | train] - Train Epoch: [106] [1267200/1281167 (99%)]	Loss: 1.040298
[2022-03-31 16:24:42 | train] - Train Epoch: [106] [1280000/1281167 (100%)]	Loss: 0.799316
[2022-03-31 16:24:44 | train] - Train Epoch: [106]	 Average Loss: 0.797038	 Total Acc : 80.4698	 Total Top5 Acc : 92.9137
[2022-03-31 16:24:44 | train] - -------106 epoch end-----------
========================================
-------106 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 16:26:15 | train] - 
Epoch [106] Test set: Average loss: 1.4195, Accuracy: 34877/50000 (69.7243%), Top-5 Accuracy: 88.7952%

[2022-03-31 16:26:15 | train] - save intermediate epoch [106] result


[2022-03-31 16:26:27 | train] - -------107 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 16:26:29 | train] - Train Epoch: [107] [0/1281167 (0%)]	Loss: 1.033624
[2022-03-31 16:26:50 | train] - Train Epoch: [107] [12800/1281167 (1%)]	Loss: 0.759492
[2022-03-31 16:27:11 | train] - Train Epoch: [107] [25600/1281167 (2%)]	Loss: 0.833340
[2022-03-31 16:27:32 | train] - Train Epoch: [107] [38400/1281167 (3%)]	Loss: 0.707493
[2022-03-31 16:27:53 | train] - Train Epoch: [107] [51200/1281167 (4%)]	Loss: 0.664091
[2022-03-31 16:28:14 | train] - Train Epoch: [107] [64000/1281167 (5%)]	Loss: 0.779567
[2022-03-31 16:28:36 | train] - Train Epoch: [107] [76800/1281167 (6%)]	Loss: 0.841492
[2022-03-31 16:28:57 | train] - Train Epoch: [107] [89600/1281167 (7%)]	Loss: 0.747789
[2022-03-31 16:29:18 | train] - Train Epoch: [107] [102400/1281167 (8%)]	Loss: 0.723168
[2022-03-31 16:29:37 | train] - Train Epoch: [107] [115200/1281167 (9%)]	Loss: 0.985138
[2022-03-31 16:29:57 | train] - Train Epoch: [107] [128000/1281167 (10%)]	Loss: 0.974312
[2022-03-31 16:30:17 | train] - Train Epoch: [107] [140800/1281167 (11%)]	Loss: 0.635939
[2022-03-31 16:30:36 | train] - Train Epoch: [107] [153600/1281167 (12%)]	Loss: 0.776670
[2022-03-31 16:30:56 | train] - Train Epoch: [107] [166400/1281167 (13%)]	Loss: 0.814681
[2022-03-31 16:31:15 | train] - Train Epoch: [107] [179200/1281167 (14%)]	Loss: 0.641688
[2022-03-31 16:31:35 | train] - Train Epoch: [107] [192000/1281167 (15%)]	Loss: 0.710760
[2022-03-31 16:31:54 | train] - Train Epoch: [107] [204800/1281167 (16%)]	Loss: 0.721716
[2022-03-31 16:32:14 | train] - Train Epoch: [107] [217600/1281167 (17%)]	Loss: 0.724106
[2022-03-31 16:32:33 | train] - Train Epoch: [107] [230400/1281167 (18%)]	Loss: 0.661189
[2022-03-31 16:32:53 | train] - Train Epoch: [107] [243200/1281167 (19%)]	Loss: 0.662442
[2022-03-31 16:33:12 | train] - Train Epoch: [107] [256000/1281167 (20%)]	Loss: 0.659749
[2022-03-31 16:33:32 | train] - Train Epoch: [107] [268800/1281167 (21%)]	Loss: 0.814188
[2022-03-31 16:33:51 | train] - Train Epoch: [107] [281600/1281167 (22%)]	Loss: 0.811557
[2022-03-31 16:34:11 | train] - Train Epoch: [107] [294400/1281167 (23%)]	Loss: 0.635593
[2022-03-31 16:34:30 | train] - Train Epoch: [107] [307200/1281167 (24%)]	Loss: 0.724557
[2022-03-31 16:34:50 | train] - Train Epoch: [107] [320000/1281167 (25%)]	Loss: 0.909432
[2022-03-31 16:35:10 | train] - Train Epoch: [107] [332800/1281167 (26%)]	Loss: 0.815689
[2022-03-31 16:35:29 | train] - Train Epoch: [107] [345600/1281167 (27%)]	Loss: 1.081420
[2022-03-31 16:35:48 | train] - Train Epoch: [107] [358400/1281167 (28%)]	Loss: 0.715148
[2022-03-31 16:36:08 | train] - Train Epoch: [107] [371200/1281167 (29%)]	Loss: 0.816975
[2022-03-31 16:36:27 | train] - Train Epoch: [107] [384000/1281167 (30%)]	Loss: 0.909812
[2022-03-31 16:36:47 | train] - Train Epoch: [107] [396800/1281167 (31%)]	Loss: 0.777315
[2022-03-31 16:37:06 | train] - Train Epoch: [107] [409600/1281167 (32%)]	Loss: 0.886460
[2022-03-31 16:37:26 | train] - Train Epoch: [107] [422400/1281167 (33%)]	Loss: 0.731830
[2022-03-31 16:37:45 | train] - Train Epoch: [107] [435200/1281167 (34%)]	Loss: 0.828360
[2022-03-31 16:38:04 | train] - Train Epoch: [107] [448000/1281167 (35%)]	Loss: 0.655297
[2022-03-31 16:38:24 | train] - Train Epoch: [107] [460800/1281167 (36%)]	Loss: 0.645898
[2022-03-31 16:38:44 | train] - Train Epoch: [107] [473600/1281167 (37%)]	Loss: 0.796494
[2022-03-31 16:39:03 | train] - Train Epoch: [107] [486400/1281167 (38%)]	Loss: 0.974721
[2022-03-31 16:39:23 | train] - Train Epoch: [107] [499200/1281167 (39%)]	Loss: 0.629799
[2022-03-31 16:39:43 | train] - Train Epoch: [107] [512000/1281167 (40%)]	Loss: 0.825309
[2022-03-31 16:40:03 | train] - Train Epoch: [107] [524800/1281167 (41%)]	Loss: 0.881070
[2022-03-31 16:40:23 | train] - Train Epoch: [107] [537600/1281167 (42%)]	Loss: 0.731272
[2022-03-31 16:40:41 | train] - Train Epoch: [107] [550400/1281167 (43%)]	Loss: 0.948863
[2022-03-31 16:41:01 | train] - Train Epoch: [107] [563200/1281167 (44%)]	Loss: 0.875637
[2022-03-31 16:41:21 | train] - Train Epoch: [107] [576000/1281167 (45%)]	Loss: 0.724393
[2022-03-31 16:41:40 | train] - Train Epoch: [107] [588800/1281167 (46%)]	Loss: 0.773278
[2022-03-31 16:41:59 | train] - Train Epoch: [107] [601600/1281167 (47%)]	Loss: 0.604677
[2022-03-31 16:42:19 | train] - Train Epoch: [107] [614400/1281167 (48%)]	Loss: 0.500427
[2022-03-31 16:42:38 | train] - Train Epoch: [107] [627200/1281167 (49%)]	Loss: 0.885105
[2022-03-31 16:42:58 | train] - Train Epoch: [107] [640000/1281167 (50%)]	Loss: 0.883237
[2022-03-31 16:43:18 | train] - Train Epoch: [107] [652800/1281167 (51%)]	Loss: 0.883980
[2022-03-31 16:43:38 | train] - Train Epoch: [107] [665600/1281167 (52%)]	Loss: 0.934814
[2022-03-31 16:43:57 | train] - Train Epoch: [107] [678400/1281167 (53%)]	Loss: 0.961461
[2022-03-31 16:44:16 | train] - Train Epoch: [107] [691200/1281167 (54%)]	Loss: 0.893184
[2022-03-31 16:44:37 | train] - Train Epoch: [107] [704000/1281167 (55%)]	Loss: 0.671769
[2022-03-31 16:44:56 | train] - Train Epoch: [107] [716800/1281167 (56%)]	Loss: 0.923175
[2022-03-31 16:45:15 | train] - Train Epoch: [107] [729600/1281167 (57%)]	Loss: 0.966063
[2022-03-31 16:45:35 | train] - Train Epoch: [107] [742400/1281167 (58%)]	Loss: 0.803348
[2022-03-31 16:45:55 | train] - Train Epoch: [107] [755200/1281167 (59%)]	Loss: 0.650471
[2022-03-31 16:46:14 | train] - Train Epoch: [107] [768000/1281167 (60%)]	Loss: 0.892115
[2022-03-31 16:46:34 | train] - Train Epoch: [107] [780800/1281167 (61%)]	Loss: 0.713376
[2022-03-31 16:46:53 | train] - Train Epoch: [107] [793600/1281167 (62%)]	Loss: 0.778770
[2022-03-31 16:47:12 | train] - Train Epoch: [107] [806400/1281167 (63%)]	Loss: 0.785061
[2022-03-31 16:47:32 | train] - Train Epoch: [107] [819200/1281167 (64%)]	Loss: 0.875859
[2022-03-31 16:47:51 | train] - Train Epoch: [107] [832000/1281167 (65%)]	Loss: 0.532894
[2022-03-31 16:48:10 | train] - Train Epoch: [107] [844800/1281167 (66%)]	Loss: 0.851185
[2022-03-31 16:48:30 | train] - Train Epoch: [107] [857600/1281167 (67%)]	Loss: 0.606360
[2022-03-31 16:48:50 | train] - Train Epoch: [107] [870400/1281167 (68%)]	Loss: 0.686492
[2022-03-31 16:49:10 | train] - Train Epoch: [107] [883200/1281167 (69%)]	Loss: 0.682005
[2022-03-31 16:49:30 | train] - Train Epoch: [107] [896000/1281167 (70%)]	Loss: 0.840344
[2022-03-31 16:49:49 | train] - Train Epoch: [107] [908800/1281167 (71%)]	Loss: 0.673418
[2022-03-31 16:50:08 | train] - Train Epoch: [107] [921600/1281167 (72%)]	Loss: 0.907877
[2022-03-31 16:50:28 | train] - Train Epoch: [107] [934400/1281167 (73%)]	Loss: 0.697819
[2022-03-31 16:50:47 | train] - Train Epoch: [107] [947200/1281167 (74%)]	Loss: 0.925643
[2022-03-31 16:51:06 | train] - Train Epoch: [107] [960000/1281167 (75%)]	Loss: 0.885484
[2022-03-31 16:51:26 | train] - Train Epoch: [107] [972800/1281167 (76%)]	Loss: 0.991423
[2022-03-31 16:51:45 | train] - Train Epoch: [107] [985600/1281167 (77%)]	Loss: 0.698543
[2022-03-31 16:52:05 | train] - Train Epoch: [107] [998400/1281167 (78%)]	Loss: 0.945991
[2022-03-31 16:52:25 | train] - Train Epoch: [107] [1011200/1281167 (79%)]	Loss: 0.768815
[2022-03-31 16:52:44 | train] - Train Epoch: [107] [1024000/1281167 (80%)]	Loss: 0.721975
[2022-03-31 16:53:04 | train] - Train Epoch: [107] [1036800/1281167 (81%)]	Loss: 0.719936
[2022-03-31 16:53:24 | train] - Train Epoch: [107] [1049600/1281167 (82%)]	Loss: 0.854196
[2022-03-31 16:53:43 | train] - Train Epoch: [107] [1062400/1281167 (83%)]	Loss: 0.610890
[2022-03-31 16:54:03 | train] - Train Epoch: [107] [1075200/1281167 (84%)]	Loss: 0.780825
[2022-03-31 16:54:23 | train] - Train Epoch: [107] [1088000/1281167 (85%)]	Loss: 0.733990
[2022-03-31 16:54:43 | train] - Train Epoch: [107] [1100800/1281167 (86%)]	Loss: 0.745420
[2022-03-31 16:55:03 | train] - Train Epoch: [107] [1113600/1281167 (87%)]	Loss: 0.922028
[2022-03-31 16:55:22 | train] - Train Epoch: [107] [1126400/1281167 (88%)]	Loss: 1.115018
[2022-03-31 16:55:42 | train] - Train Epoch: [107] [1139200/1281167 (89%)]	Loss: 0.650082
[2022-03-31 16:56:01 | train] - Train Epoch: [107] [1152000/1281167 (90%)]	Loss: 0.835709
[2022-03-31 16:56:20 | train] - Train Epoch: [107] [1164800/1281167 (91%)]	Loss: 0.805356
[2022-03-31 16:56:40 | train] - Train Epoch: [107] [1177600/1281167 (92%)]	Loss: 0.938006
[2022-03-31 16:57:00 | train] - Train Epoch: [107] [1190400/1281167 (93%)]	Loss: 0.813437
[2022-03-31 16:57:20 | train] - Train Epoch: [107] [1203200/1281167 (94%)]	Loss: 0.422107
[2022-03-31 16:57:39 | train] - Train Epoch: [107] [1216000/1281167 (95%)]	Loss: 0.817556
[2022-03-31 16:57:59 | train] - Train Epoch: [107] [1228800/1281167 (96%)]	Loss: 0.892969
[2022-03-31 16:58:18 | train] - Train Epoch: [107] [1241600/1281167 (97%)]	Loss: 0.617166
[2022-03-31 16:58:37 | train] - Train Epoch: [107] [1254400/1281167 (98%)]	Loss: 0.987104
[2022-03-31 16:58:57 | train] - Train Epoch: [107] [1267200/1281167 (99%)]	Loss: 0.816677
[2022-03-31 16:59:16 | train] - Train Epoch: [107] [1280000/1281167 (100%)]	Loss: 0.583190
[2022-03-31 16:59:18 | train] - Train Epoch: [107]	 Average Loss: 0.796053	 Total Acc : 80.5410	 Total Top5 Acc : 92.9313
[2022-03-31 16:59:18 | train] - -------107 epoch end-----------
========================================
-------107 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 17:00:47 | train] - 
Epoch [107] Test set: Average loss: 1.4178, Accuracy: 34777/50000 (69.5257%), Top-5 Accuracy: 88.8059%

[2022-03-31 17:00:47 | train] - save intermediate epoch [107] result


[2022-03-31 17:00:59 | train] - -------108 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 17:01:01 | train] - Train Epoch: [108] [0/1281167 (0%)]	Loss: 0.744771
[2022-03-31 17:01:21 | train] - Train Epoch: [108] [12800/1281167 (1%)]	Loss: 0.818696
[2022-03-31 17:01:41 | train] - Train Epoch: [108] [25600/1281167 (2%)]	Loss: 0.850485
[2022-03-31 17:02:00 | train] - Train Epoch: [108] [38400/1281167 (3%)]	Loss: 0.649116
[2022-03-31 17:02:20 | train] - Train Epoch: [108] [51200/1281167 (4%)]	Loss: 0.531529
[2022-03-31 17:02:39 | train] - Train Epoch: [108] [64000/1281167 (5%)]	Loss: 0.739310
[2022-03-31 17:02:59 | train] - Train Epoch: [108] [76800/1281167 (6%)]	Loss: 0.523871
[2022-03-31 17:03:18 | train] - Train Epoch: [108] [89600/1281167 (7%)]	Loss: 0.917974
[2022-03-31 17:03:38 | train] - Train Epoch: [108] [102400/1281167 (8%)]	Loss: 1.185871
[2022-03-31 17:03:58 | train] - Train Epoch: [108] [115200/1281167 (9%)]	Loss: 0.710281
[2022-03-31 17:04:18 | train] - Train Epoch: [108] [128000/1281167 (10%)]	Loss: 0.786920
[2022-03-31 17:04:37 | train] - Train Epoch: [108] [140800/1281167 (11%)]	Loss: 0.722646
[2022-03-31 17:04:57 | train] - Train Epoch: [108] [153600/1281167 (12%)]	Loss: 0.659903
[2022-03-31 17:05:16 | train] - Train Epoch: [108] [166400/1281167 (13%)]	Loss: 0.913483
[2022-03-31 17:05:36 | train] - Train Epoch: [108] [179200/1281167 (14%)]	Loss: 0.929935
[2022-03-31 17:05:56 | train] - Train Epoch: [108] [192000/1281167 (15%)]	Loss: 0.725720
[2022-03-31 17:06:15 | train] - Train Epoch: [108] [204800/1281167 (16%)]	Loss: 0.900222
[2022-03-31 17:06:35 | train] - Train Epoch: [108] [217600/1281167 (17%)]	Loss: 0.624665
[2022-03-31 17:06:55 | train] - Train Epoch: [108] [230400/1281167 (18%)]	Loss: 0.614032
[2022-03-31 17:07:14 | train] - Train Epoch: [108] [243200/1281167 (19%)]	Loss: 0.834740
[2022-03-31 17:07:34 | train] - Train Epoch: [108] [256000/1281167 (20%)]	Loss: 0.834047
[2022-03-31 17:07:53 | train] - Train Epoch: [108] [268800/1281167 (21%)]	Loss: 0.681838
[2022-03-31 17:08:13 | train] - Train Epoch: [108] [281600/1281167 (22%)]	Loss: 1.045028
[2022-03-31 17:08:32 | train] - Train Epoch: [108] [294400/1281167 (23%)]	Loss: 0.554857
[2022-03-31 17:08:52 | train] - Train Epoch: [108] [307200/1281167 (24%)]	Loss: 0.716791
[2022-03-31 17:09:11 | train] - Train Epoch: [108] [320000/1281167 (25%)]	Loss: 0.596886
[2022-03-31 17:09:30 | train] - Train Epoch: [108] [332800/1281167 (26%)]	Loss: 0.744970
[2022-03-31 17:09:49 | train] - Train Epoch: [108] [345600/1281167 (27%)]	Loss: 0.607946
[2022-03-31 17:10:09 | train] - Train Epoch: [108] [358400/1281167 (28%)]	Loss: 0.686528
[2022-03-31 17:10:28 | train] - Train Epoch: [108] [371200/1281167 (29%)]	Loss: 0.864391
[2022-03-31 17:10:48 | train] - Train Epoch: [108] [384000/1281167 (30%)]	Loss: 0.717468
[2022-03-31 17:11:08 | train] - Train Epoch: [108] [396800/1281167 (31%)]	Loss: 0.853127
[2022-03-31 17:11:28 | train] - Train Epoch: [108] [409600/1281167 (32%)]	Loss: 0.764401
[2022-03-31 17:11:47 | train] - Train Epoch: [108] [422400/1281167 (33%)]	Loss: 0.571250
[2022-03-31 17:12:07 | train] - Train Epoch: [108] [435200/1281167 (34%)]	Loss: 0.508945
[2022-03-31 17:12:26 | train] - Train Epoch: [108] [448000/1281167 (35%)]	Loss: 0.672019
[2022-03-31 17:12:46 | train] - Train Epoch: [108] [460800/1281167 (36%)]	Loss: 0.691401
[2022-03-31 17:13:05 | train] - Train Epoch: [108] [473600/1281167 (37%)]	Loss: 0.596259
[2022-03-31 17:13:25 | train] - Train Epoch: [108] [486400/1281167 (38%)]	Loss: 0.688805
[2022-03-31 17:13:45 | train] - Train Epoch: [108] [499200/1281167 (39%)]	Loss: 0.891775
[2022-03-31 17:14:05 | train] - Train Epoch: [108] [512000/1281167 (40%)]	Loss: 0.643266
[2022-03-31 17:14:25 | train] - Train Epoch: [108] [524800/1281167 (41%)]	Loss: 0.789567
[2022-03-31 17:14:45 | train] - Train Epoch: [108] [537600/1281167 (42%)]	Loss: 0.801325
[2022-03-31 17:15:04 | train] - Train Epoch: [108] [550400/1281167 (43%)]	Loss: 0.862829
[2022-03-31 17:15:24 | train] - Train Epoch: [108] [563200/1281167 (44%)]	Loss: 0.638939
[2022-03-31 17:15:44 | train] - Train Epoch: [108] [576000/1281167 (45%)]	Loss: 0.934847
[2022-03-31 17:16:03 | train] - Train Epoch: [108] [588800/1281167 (46%)]	Loss: 0.868856
[2022-03-31 17:16:23 | train] - Train Epoch: [108] [601600/1281167 (47%)]	Loss: 0.793310
[2022-03-31 17:16:43 | train] - Train Epoch: [108] [614400/1281167 (48%)]	Loss: 0.780708
[2022-03-31 17:17:03 | train] - Train Epoch: [108] [627200/1281167 (49%)]	Loss: 0.737854
[2022-03-31 17:17:23 | train] - Train Epoch: [108] [640000/1281167 (50%)]	Loss: 0.940561
[2022-03-31 17:17:43 | train] - Train Epoch: [108] [652800/1281167 (51%)]	Loss: 0.596574
[2022-03-31 17:18:02 | train] - Train Epoch: [108] [665600/1281167 (52%)]	Loss: 0.510993
[2022-03-31 17:18:22 | train] - Train Epoch: [108] [678400/1281167 (53%)]	Loss: 0.675592
[2022-03-31 17:18:42 | train] - Train Epoch: [108] [691200/1281167 (54%)]	Loss: 1.002924
[2022-03-31 17:19:01 | train] - Train Epoch: [108] [704000/1281167 (55%)]	Loss: 0.935214
[2022-03-31 17:19:21 | train] - Train Epoch: [108] [716800/1281167 (56%)]	Loss: 0.740388
[2022-03-31 17:19:41 | train] - Train Epoch: [108] [729600/1281167 (57%)]	Loss: 0.781717
[2022-03-31 17:20:00 | train] - Train Epoch: [108] [742400/1281167 (58%)]	Loss: 0.905187
[2022-03-31 17:20:20 | train] - Train Epoch: [108] [755200/1281167 (59%)]	Loss: 0.873189
[2022-03-31 17:20:40 | train] - Train Epoch: [108] [768000/1281167 (60%)]	Loss: 0.715356
[2022-03-31 17:21:00 | train] - Train Epoch: [108] [780800/1281167 (61%)]	Loss: 1.029165
[2022-03-31 17:21:19 | train] - Train Epoch: [108] [793600/1281167 (62%)]	Loss: 0.913617
[2022-03-31 17:21:39 | train] - Train Epoch: [108] [806400/1281167 (63%)]	Loss: 0.527561
[2022-03-31 17:21:58 | train] - Train Epoch: [108] [819200/1281167 (64%)]	Loss: 0.851924
[2022-03-31 17:22:18 | train] - Train Epoch: [108] [832000/1281167 (65%)]	Loss: 0.589858
[2022-03-31 17:22:37 | train] - Train Epoch: [108] [844800/1281167 (66%)]	Loss: 0.730653
[2022-03-31 17:22:56 | train] - Train Epoch: [108] [857600/1281167 (67%)]	Loss: 0.730335
[2022-03-31 17:23:16 | train] - Train Epoch: [108] [870400/1281167 (68%)]	Loss: 0.869660
[2022-03-31 17:23:36 | train] - Train Epoch: [108] [883200/1281167 (69%)]	Loss: 0.854369
[2022-03-31 17:23:55 | train] - Train Epoch: [108] [896000/1281167 (70%)]	Loss: 0.725410
[2022-03-31 17:24:15 | train] - Train Epoch: [108] [908800/1281167 (71%)]	Loss: 0.572059
[2022-03-31 17:24:35 | train] - Train Epoch: [108] [921600/1281167 (72%)]	Loss: 0.976595
[2022-03-31 17:24:54 | train] - Train Epoch: [108] [934400/1281167 (73%)]	Loss: 0.896355
[2022-03-31 17:25:14 | train] - Train Epoch: [108] [947200/1281167 (74%)]	Loss: 0.681567
[2022-03-31 17:25:34 | train] - Train Epoch: [108] [960000/1281167 (75%)]	Loss: 0.864064
[2022-03-31 17:25:54 | train] - Train Epoch: [108] [972800/1281167 (76%)]	Loss: 0.779910
[2022-03-31 17:26:13 | train] - Train Epoch: [108] [985600/1281167 (77%)]	Loss: 0.629976
[2022-03-31 17:26:33 | train] - Train Epoch: [108] [998400/1281167 (78%)]	Loss: 0.788952
[2022-03-31 17:26:53 | train] - Train Epoch: [108] [1011200/1281167 (79%)]	Loss: 0.637747
[2022-03-31 17:27:12 | train] - Train Epoch: [108] [1024000/1281167 (80%)]	Loss: 0.602894
[2022-03-31 17:27:31 | train] - Train Epoch: [108] [1036800/1281167 (81%)]	Loss: 0.810163
[2022-03-31 17:27:51 | train] - Train Epoch: [108] [1049600/1281167 (82%)]	Loss: 0.986094
[2022-03-31 17:28:10 | train] - Train Epoch: [108] [1062400/1281167 (83%)]	Loss: 0.668903
[2022-03-31 17:28:29 | train] - Train Epoch: [108] [1075200/1281167 (84%)]	Loss: 0.689883
[2022-03-31 17:28:49 | train] - Train Epoch: [108] [1088000/1281167 (85%)]	Loss: 0.783359
[2022-03-31 17:29:08 | train] - Train Epoch: [108] [1100800/1281167 (86%)]	Loss: 1.091400
[2022-03-31 17:29:28 | train] - Train Epoch: [108] [1113600/1281167 (87%)]	Loss: 0.868608
[2022-03-31 17:29:48 | train] - Train Epoch: [108] [1126400/1281167 (88%)]	Loss: 0.904377
[2022-03-31 17:30:07 | train] - Train Epoch: [108] [1139200/1281167 (89%)]	Loss: 0.912730
[2022-03-31 17:30:27 | train] - Train Epoch: [108] [1152000/1281167 (90%)]	Loss: 0.594589
[2022-03-31 17:30:47 | train] - Train Epoch: [108] [1164800/1281167 (91%)]	Loss: 0.932590
[2022-03-31 17:31:06 | train] - Train Epoch: [108] [1177600/1281167 (92%)]	Loss: 0.801722
[2022-03-31 17:31:26 | train] - Train Epoch: [108] [1190400/1281167 (93%)]	Loss: 0.813942
[2022-03-31 17:31:46 | train] - Train Epoch: [108] [1203200/1281167 (94%)]	Loss: 0.881308
[2022-03-31 17:32:05 | train] - Train Epoch: [108] [1216000/1281167 (95%)]	Loss: 0.810442
[2022-03-31 17:32:25 | train] - Train Epoch: [108] [1228800/1281167 (96%)]	Loss: 0.705138
[2022-03-31 17:32:45 | train] - Train Epoch: [108] [1241600/1281167 (97%)]	Loss: 0.540687
[2022-03-31 17:33:05 | train] - Train Epoch: [108] [1254400/1281167 (98%)]	Loss: 0.747678
[2022-03-31 17:33:25 | train] - Train Epoch: [108] [1267200/1281167 (99%)]	Loss: 0.742647
[2022-03-31 17:33:44 | train] - Train Epoch: [108] [1280000/1281167 (100%)]	Loss: 0.723131
[2022-03-31 17:33:45 | train] - Train Epoch: [108]	 Average Loss: 0.790131	 Total Acc : 80.6751	 Total Top5 Acc : 93.0132
[2022-03-31 17:33:45 | train] - -------108 epoch end-----------
========================================
-------108 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 17:35:16 | train] - 
Epoch [108] Test set: Average loss: 1.4153, Accuracy: 34784/50000 (69.5396%), Top-5 Accuracy: 88.7656%

[2022-03-31 17:35:16 | train] - save intermediate epoch [108] result


[2022-03-31 17:35:28 | train] - -------109 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 17:35:30 | train] - Train Epoch: [109] [0/1281167 (0%)]	Loss: 0.936331
[2022-03-31 17:35:50 | train] - Train Epoch: [109] [12800/1281167 (1%)]	Loss: 1.097752
[2022-03-31 17:36:09 | train] - Train Epoch: [109] [25600/1281167 (2%)]	Loss: 0.742551
[2022-03-31 17:36:29 | train] - Train Epoch: [109] [38400/1281167 (3%)]	Loss: 0.539245
[2022-03-31 17:36:48 | train] - Train Epoch: [109] [51200/1281167 (4%)]	Loss: 1.062512
[2022-03-31 17:37:08 | train] - Train Epoch: [109] [64000/1281167 (5%)]	Loss: 0.793236
[2022-03-31 17:37:28 | train] - Train Epoch: [109] [76800/1281167 (6%)]	Loss: 0.805988
[2022-03-31 17:37:47 | train] - Train Epoch: [109] [89600/1281167 (7%)]	Loss: 1.193882
[2022-03-31 17:38:07 | train] - Train Epoch: [109] [102400/1281167 (8%)]	Loss: 0.782016
[2022-03-31 17:38:27 | train] - Train Epoch: [109] [115200/1281167 (9%)]	Loss: 0.713420
[2022-03-31 17:38:46 | train] - Train Epoch: [109] [128000/1281167 (10%)]	Loss: 0.660788
[2022-03-31 17:39:05 | train] - Train Epoch: [109] [140800/1281167 (11%)]	Loss: 0.682760
[2022-03-31 17:39:24 | train] - Train Epoch: [109] [153600/1281167 (12%)]	Loss: 0.747698
[2022-03-31 17:39:43 | train] - Train Epoch: [109] [166400/1281167 (13%)]	Loss: 0.666200
[2022-03-31 17:40:03 | train] - Train Epoch: [109] [179200/1281167 (14%)]	Loss: 0.605946
[2022-03-31 17:40:24 | train] - Train Epoch: [109] [192000/1281167 (15%)]	Loss: 0.783110
[2022-03-31 17:40:43 | train] - Train Epoch: [109] [204800/1281167 (16%)]	Loss: 0.678970
[2022-03-31 17:41:03 | train] - Train Epoch: [109] [217600/1281167 (17%)]	Loss: 0.793795
[2022-03-31 17:41:23 | train] - Train Epoch: [109] [230400/1281167 (18%)]	Loss: 0.702415
[2022-03-31 17:41:43 | train] - Train Epoch: [109] [243200/1281167 (19%)]	Loss: 0.675956
[2022-03-31 17:42:03 | train] - Train Epoch: [109] [256000/1281167 (20%)]	Loss: 0.821557
[2022-03-31 17:42:22 | train] - Train Epoch: [109] [268800/1281167 (21%)]	Loss: 0.635006
[2022-03-31 17:42:42 | train] - Train Epoch: [109] [281600/1281167 (22%)]	Loss: 0.695005
[2022-03-31 17:43:01 | train] - Train Epoch: [109] [294400/1281167 (23%)]	Loss: 1.045907
[2022-03-31 17:43:21 | train] - Train Epoch: [109] [307200/1281167 (24%)]	Loss: 0.954226
[2022-03-31 17:43:40 | train] - Train Epoch: [109] [320000/1281167 (25%)]	Loss: 1.058691
[2022-03-31 17:44:00 | train] - Train Epoch: [109] [332800/1281167 (26%)]	Loss: 0.814173
[2022-03-31 17:44:20 | train] - Train Epoch: [109] [345600/1281167 (27%)]	Loss: 0.890407
[2022-03-31 17:44:39 | train] - Train Epoch: [109] [358400/1281167 (28%)]	Loss: 0.867936
[2022-03-31 17:44:59 | train] - Train Epoch: [109] [371200/1281167 (29%)]	Loss: 0.778346
[2022-03-31 17:45:19 | train] - Train Epoch: [109] [384000/1281167 (30%)]	Loss: 0.582091
[2022-03-31 17:45:40 | train] - Train Epoch: [109] [396800/1281167 (31%)]	Loss: 0.588183
[2022-03-31 17:46:01 | train] - Train Epoch: [109] [409600/1281167 (32%)]	Loss: 0.733512
[2022-03-31 17:46:22 | train] - Train Epoch: [109] [422400/1281167 (33%)]	Loss: 0.817346
[2022-03-31 17:46:43 | train] - Train Epoch: [109] [435200/1281167 (34%)]	Loss: 0.733155
[2022-03-31 17:47:04 | train] - Train Epoch: [109] [448000/1281167 (35%)]	Loss: 0.720493
[2022-03-31 17:47:25 | train] - Train Epoch: [109] [460800/1281167 (36%)]	Loss: 0.719819
[2022-03-31 17:47:47 | train] - Train Epoch: [109] [473600/1281167 (37%)]	Loss: 0.878831
[2022-03-31 17:48:08 | train] - Train Epoch: [109] [486400/1281167 (38%)]	Loss: 0.806809
[2022-03-31 17:48:29 | train] - Train Epoch: [109] [499200/1281167 (39%)]	Loss: 0.720764
[2022-03-31 17:48:50 | train] - Train Epoch: [109] [512000/1281167 (40%)]	Loss: 0.803467
[2022-03-31 17:49:11 | train] - Train Epoch: [109] [524800/1281167 (41%)]	Loss: 0.863657
[2022-03-31 17:49:32 | train] - Train Epoch: [109] [537600/1281167 (42%)]	Loss: 0.586360
[2022-03-31 17:49:53 | train] - Train Epoch: [109] [550400/1281167 (43%)]	Loss: 0.849976
[2022-03-31 17:50:14 | train] - Train Epoch: [109] [563200/1281167 (44%)]	Loss: 0.736012
[2022-03-31 17:50:34 | train] - Train Epoch: [109] [576000/1281167 (45%)]	Loss: 0.768037
[2022-03-31 17:50:56 | train] - Train Epoch: [109] [588800/1281167 (46%)]	Loss: 0.697222
[2022-03-31 17:51:17 | train] - Train Epoch: [109] [601600/1281167 (47%)]	Loss: 0.908855
[2022-03-31 17:51:38 | train] - Train Epoch: [109] [614400/1281167 (48%)]	Loss: 0.660124
[2022-03-31 17:51:59 | train] - Train Epoch: [109] [627200/1281167 (49%)]	Loss: 0.554838
[2022-03-31 17:52:19 | train] - Train Epoch: [109] [640000/1281167 (50%)]	Loss: 0.691455
[2022-03-31 17:52:40 | train] - Train Epoch: [109] [652800/1281167 (51%)]	Loss: 0.854871
[2022-03-31 17:53:01 | train] - Train Epoch: [109] [665600/1281167 (52%)]	Loss: 0.741371
[2022-03-31 17:53:22 | train] - Train Epoch: [109] [678400/1281167 (53%)]	Loss: 0.781396
[2022-03-31 17:53:44 | train] - Train Epoch: [109] [691200/1281167 (54%)]	Loss: 0.697560
[2022-03-31 17:54:04 | train] - Train Epoch: [109] [704000/1281167 (55%)]	Loss: 0.665828
[2022-03-31 17:54:26 | train] - Train Epoch: [109] [716800/1281167 (56%)]	Loss: 0.732306
[2022-03-31 17:54:46 | train] - Train Epoch: [109] [729600/1281167 (57%)]	Loss: 0.707012
[2022-03-31 17:55:07 | train] - Train Epoch: [109] [742400/1281167 (58%)]	Loss: 1.001736
[2022-03-31 17:55:27 | train] - Train Epoch: [109] [755200/1281167 (59%)]	Loss: 0.832312
[2022-03-31 17:55:48 | train] - Train Epoch: [109] [768000/1281167 (60%)]	Loss: 0.665640
[2022-03-31 17:56:09 | train] - Train Epoch: [109] [780800/1281167 (61%)]	Loss: 1.058247
[2022-03-31 17:56:29 | train] - Train Epoch: [109] [793600/1281167 (62%)]	Loss: 0.705155
[2022-03-31 17:56:50 | train] - Train Epoch: [109] [806400/1281167 (63%)]	Loss: 0.656991
[2022-03-31 17:57:11 | train] - Train Epoch: [109] [819200/1281167 (64%)]	Loss: 0.714330
[2022-03-31 17:57:31 | train] - Train Epoch: [109] [832000/1281167 (65%)]	Loss: 1.072070
[2022-03-31 17:57:51 | train] - Train Epoch: [109] [844800/1281167 (66%)]	Loss: 0.696118
[2022-03-31 17:58:12 | train] - Train Epoch: [109] [857600/1281167 (67%)]	Loss: 1.012684
[2022-03-31 17:58:32 | train] - Train Epoch: [109] [870400/1281167 (68%)]	Loss: 0.867117
[2022-03-31 17:58:53 | train] - Train Epoch: [109] [883200/1281167 (69%)]	Loss: 0.708076
[2022-03-31 17:59:14 | train] - Train Epoch: [109] [896000/1281167 (70%)]	Loss: 0.632529
[2022-03-31 17:59:35 | train] - Train Epoch: [109] [908800/1281167 (71%)]	Loss: 0.752550
[2022-03-31 17:59:55 | train] - Train Epoch: [109] [921600/1281167 (72%)]	Loss: 1.108012
[2022-03-31 18:00:15 | train] - Train Epoch: [109] [934400/1281167 (73%)]	Loss: 0.740834
[2022-03-31 18:00:36 | train] - Train Epoch: [109] [947200/1281167 (74%)]	Loss: 0.576575
[2022-03-31 18:00:56 | train] - Train Epoch: [109] [960000/1281167 (75%)]	Loss: 0.911060
[2022-03-31 18:01:17 | train] - Train Epoch: [109] [972800/1281167 (76%)]	Loss: 0.821063
[2022-03-31 18:01:38 | train] - Train Epoch: [109] [985600/1281167 (77%)]	Loss: 0.830352
[2022-03-31 18:01:59 | train] - Train Epoch: [109] [998400/1281167 (78%)]	Loss: 0.975731
[2022-03-31 18:02:20 | train] - Train Epoch: [109] [1011200/1281167 (79%)]	Loss: 0.834274
[2022-03-31 18:02:40 | train] - Train Epoch: [109] [1024000/1281167 (80%)]	Loss: 0.953228
[2022-03-31 18:03:01 | train] - Train Epoch: [109] [1036800/1281167 (81%)]	Loss: 0.636664
[2022-03-31 18:03:22 | train] - Train Epoch: [109] [1049600/1281167 (82%)]	Loss: 1.017226
[2022-03-31 18:03:42 | train] - Train Epoch: [109] [1062400/1281167 (83%)]	Loss: 0.685049
[2022-03-31 18:04:03 | train] - Train Epoch: [109] [1075200/1281167 (84%)]	Loss: 1.064951
[2022-03-31 18:04:24 | train] - Train Epoch: [109] [1088000/1281167 (85%)]	Loss: 0.953712
[2022-03-31 18:04:45 | train] - Train Epoch: [109] [1100800/1281167 (86%)]	Loss: 0.939075
[2022-03-31 18:05:05 | train] - Train Epoch: [109] [1113600/1281167 (87%)]	Loss: 0.592757
[2022-03-31 18:05:26 | train] - Train Epoch: [109] [1126400/1281167 (88%)]	Loss: 0.863609
[2022-03-31 18:05:46 | train] - Train Epoch: [109] [1139200/1281167 (89%)]	Loss: 0.761455
[2022-03-31 18:06:07 | train] - Train Epoch: [109] [1152000/1281167 (90%)]	Loss: 0.684216
[2022-03-31 18:06:28 | train] - Train Epoch: [109] [1164800/1281167 (91%)]	Loss: 0.630167
[2022-03-31 18:06:49 | train] - Train Epoch: [109] [1177600/1281167 (92%)]	Loss: 0.942310
[2022-03-31 18:07:09 | train] - Train Epoch: [109] [1190400/1281167 (93%)]	Loss: 0.704149
[2022-03-31 18:07:30 | train] - Train Epoch: [109] [1203200/1281167 (94%)]	Loss: 0.723318
[2022-03-31 18:07:51 | train] - Train Epoch: [109] [1216000/1281167 (95%)]	Loss: 0.717015
[2022-03-31 18:08:11 | train] - Train Epoch: [109] [1228800/1281167 (96%)]	Loss: 0.800572
[2022-03-31 18:08:32 | train] - Train Epoch: [109] [1241600/1281167 (97%)]	Loss: 0.690249
[2022-03-31 18:08:51 | train] - Train Epoch: [109] [1254400/1281167 (98%)]	Loss: 0.842057
[2022-03-31 18:09:12 | train] - Train Epoch: [109] [1267200/1281167 (99%)]	Loss: 0.963195
[2022-03-31 18:09:34 | train] - Train Epoch: [109] [1280000/1281167 (100%)]	Loss: 0.897997
[2022-03-31 18:09:35 | train] - Train Epoch: [109]	 Average Loss: 0.787990	 Total Acc : 80.7061	 Total Top5 Acc : 93.0087
[2022-03-31 18:09:35 | train] - -------109 epoch end-----------
========================================
-------109 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 18:11:07 | train] - 
Epoch [109] Test set: Average loss: 1.4306, Accuracy: 34790/50000 (69.5480%), Top-5 Accuracy: 88.7420%

[2022-03-31 18:11:07 | train] - save intermediate epoch [109] result


[2022-03-31 18:11:20 | train] - -------110 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 18:11:22 | train] - Train Epoch: [110] [0/1281167 (0%)]	Loss: 0.830950
[2022-03-31 18:11:44 | train] - Train Epoch: [110] [12800/1281167 (1%)]	Loss: 0.942895
[2022-03-31 18:12:07 | train] - Train Epoch: [110] [25600/1281167 (2%)]	Loss: 0.900660
[2022-03-31 18:12:28 | train] - Train Epoch: [110] [38400/1281167 (3%)]	Loss: 0.778026
[2022-03-31 18:12:49 | train] - Train Epoch: [110] [51200/1281167 (4%)]	Loss: 0.903683
[2022-03-31 18:13:11 | train] - Train Epoch: [110] [64000/1281167 (5%)]	Loss: 0.659149
[2022-03-31 18:13:33 | train] - Train Epoch: [110] [76800/1281167 (6%)]	Loss: 0.770820
[2022-03-31 18:13:55 | train] - Train Epoch: [110] [89600/1281167 (7%)]	Loss: 0.579154
[2022-03-31 18:14:17 | train] - Train Epoch: [110] [102400/1281167 (8%)]	Loss: 0.789617
[2022-03-31 18:14:39 | train] - Train Epoch: [110] [115200/1281167 (9%)]	Loss: 0.610188
[2022-03-31 18:15:00 | train] - Train Epoch: [110] [128000/1281167 (10%)]	Loss: 1.053758
[2022-03-31 18:15:22 | train] - Train Epoch: [110] [140800/1281167 (11%)]	Loss: 0.728933
[2022-03-31 18:15:43 | train] - Train Epoch: [110] [153600/1281167 (12%)]	Loss: 0.903488
[2022-03-31 18:16:05 | train] - Train Epoch: [110] [166400/1281167 (13%)]	Loss: 0.812874
[2022-03-31 18:16:27 | train] - Train Epoch: [110] [179200/1281167 (14%)]	Loss: 0.892890
[2022-03-31 18:16:50 | train] - Train Epoch: [110] [192000/1281167 (15%)]	Loss: 0.783709
[2022-03-31 18:17:12 | train] - Train Epoch: [110] [204800/1281167 (16%)]	Loss: 0.704498
[2022-03-31 18:17:33 | train] - Train Epoch: [110] [217600/1281167 (17%)]	Loss: 0.707052
[2022-03-31 18:17:55 | train] - Train Epoch: [110] [230400/1281167 (18%)]	Loss: 0.644272
[2022-03-31 18:18:17 | train] - Train Epoch: [110] [243200/1281167 (19%)]	Loss: 0.702786
[2022-03-31 18:18:39 | train] - Train Epoch: [110] [256000/1281167 (20%)]	Loss: 0.790394
[2022-03-31 18:19:00 | train] - Train Epoch: [110] [268800/1281167 (21%)]	Loss: 0.804577
[2022-03-31 18:19:21 | train] - Train Epoch: [110] [281600/1281167 (22%)]	Loss: 0.769240
[2022-03-31 18:19:43 | train] - Train Epoch: [110] [294400/1281167 (23%)]	Loss: 0.605334
[2022-03-31 18:20:05 | train] - Train Epoch: [110] [307200/1281167 (24%)]	Loss: 0.878266
[2022-03-31 18:20:27 | train] - Train Epoch: [110] [320000/1281167 (25%)]	Loss: 0.538839
[2022-03-31 18:20:49 | train] - Train Epoch: [110] [332800/1281167 (26%)]	Loss: 0.811451
[2022-03-31 18:21:11 | train] - Train Epoch: [110] [345600/1281167 (27%)]	Loss: 0.640242
[2022-03-31 18:21:33 | train] - Train Epoch: [110] [358400/1281167 (28%)]	Loss: 0.631793
[2022-03-31 18:21:55 | train] - Train Epoch: [110] [371200/1281167 (29%)]	Loss: 0.939931
[2022-03-31 18:22:17 | train] - Train Epoch: [110] [384000/1281167 (30%)]	Loss: 0.790824
[2022-03-31 18:22:38 | train] - Train Epoch: [110] [396800/1281167 (31%)]	Loss: 0.599194
[2022-03-31 18:23:00 | train] - Train Epoch: [110] [409600/1281167 (32%)]	Loss: 0.578448
[2022-03-31 18:23:21 | train] - Train Epoch: [110] [422400/1281167 (33%)]	Loss: 0.811664
[2022-03-31 18:23:43 | train] - Train Epoch: [110] [435200/1281167 (34%)]	Loss: 0.787812
[2022-03-31 18:24:05 | train] - Train Epoch: [110] [448000/1281167 (35%)]	Loss: 0.814803
[2022-03-31 18:24:27 | train] - Train Epoch: [110] [460800/1281167 (36%)]	Loss: 0.717782
[2022-03-31 18:24:48 | train] - Train Epoch: [110] [473600/1281167 (37%)]	Loss: 0.941713
[2022-03-31 18:25:11 | train] - Train Epoch: [110] [486400/1281167 (38%)]	Loss: 0.734273
[2022-03-31 18:25:33 | train] - Train Epoch: [110] [499200/1281167 (39%)]	Loss: 1.080081
[2022-03-31 18:25:55 | train] - Train Epoch: [110] [512000/1281167 (40%)]	Loss: 0.568036
[2022-03-31 18:26:17 | train] - Train Epoch: [110] [524800/1281167 (41%)]	Loss: 0.756786
[2022-03-31 18:26:39 | train] - Train Epoch: [110] [537600/1281167 (42%)]	Loss: 0.883546
[2022-03-31 18:27:01 | train] - Train Epoch: [110] [550400/1281167 (43%)]	Loss: 0.675878
[2022-03-31 18:27:21 | train] - Train Epoch: [110] [563200/1281167 (44%)]	Loss: 0.657482
[2022-03-31 18:27:43 | train] - Train Epoch: [110] [576000/1281167 (45%)]	Loss: 0.455086
[2022-03-31 18:28:05 | train] - Train Epoch: [110] [588800/1281167 (46%)]	Loss: 1.176768
[2022-03-31 18:28:27 | train] - Train Epoch: [110] [601600/1281167 (47%)]	Loss: 0.705623
[2022-03-31 18:28:49 | train] - Train Epoch: [110] [614400/1281167 (48%)]	Loss: 0.767525
[2022-03-31 18:29:11 | train] - Train Epoch: [110] [627200/1281167 (49%)]	Loss: 0.713455
[2022-03-31 18:29:33 | train] - Train Epoch: [110] [640000/1281167 (50%)]	Loss: 0.688521
[2022-03-31 18:29:55 | train] - Train Epoch: [110] [652800/1281167 (51%)]	Loss: 0.957385
[2022-03-31 18:30:17 | train] - Train Epoch: [110] [665600/1281167 (52%)]	Loss: 0.764361
[2022-03-31 18:30:38 | train] - Train Epoch: [110] [678400/1281167 (53%)]	Loss: 0.766749
[2022-03-31 18:31:00 | train] - Train Epoch: [110] [691200/1281167 (54%)]	Loss: 0.627625
[2022-03-31 18:31:22 | train] - Train Epoch: [110] [704000/1281167 (55%)]	Loss: 0.894494
[2022-03-31 18:31:44 | train] - Train Epoch: [110] [716800/1281167 (56%)]	Loss: 0.576744
[2022-03-31 18:32:06 | train] - Train Epoch: [110] [729600/1281167 (57%)]	Loss: 0.849533
[2022-03-31 18:32:28 | train] - Train Epoch: [110] [742400/1281167 (58%)]	Loss: 0.817518
[2022-03-31 18:32:51 | train] - Train Epoch: [110] [755200/1281167 (59%)]	Loss: 0.801895
[2022-03-31 18:33:12 | train] - Train Epoch: [110] [768000/1281167 (60%)]	Loss: 0.622643
[2022-03-31 18:33:35 | train] - Train Epoch: [110] [780800/1281167 (61%)]	Loss: 0.926465
[2022-03-31 18:33:56 | train] - Train Epoch: [110] [793600/1281167 (62%)]	Loss: 0.791946
[2022-03-31 18:34:18 | train] - Train Epoch: [110] [806400/1281167 (63%)]	Loss: 0.899370
[2022-03-31 18:34:40 | train] - Train Epoch: [110] [819200/1281167 (64%)]	Loss: 0.828630
[2022-03-31 18:35:03 | train] - Train Epoch: [110] [832000/1281167 (65%)]	Loss: 0.734534
[2022-03-31 18:35:25 | train] - Train Epoch: [110] [844800/1281167 (66%)]	Loss: 0.818747
[2022-03-31 18:35:47 | train] - Train Epoch: [110] [857600/1281167 (67%)]	Loss: 0.679407
[2022-03-31 18:36:09 | train] - Train Epoch: [110] [870400/1281167 (68%)]	Loss: 0.655377
[2022-03-31 18:36:31 | train] - Train Epoch: [110] [883200/1281167 (69%)]	Loss: 0.742229
[2022-03-31 18:36:53 | train] - Train Epoch: [110] [896000/1281167 (70%)]	Loss: 1.058961
[2022-03-31 18:37:15 | train] - Train Epoch: [110] [908800/1281167 (71%)]	Loss: 0.701613
[2022-03-31 18:37:37 | train] - Train Epoch: [110] [921600/1281167 (72%)]	Loss: 0.692407
[2022-03-31 18:37:58 | train] - Train Epoch: [110] [934400/1281167 (73%)]	Loss: 0.806964
[2022-03-31 18:38:20 | train] - Train Epoch: [110] [947200/1281167 (74%)]	Loss: 0.952958
[2022-03-31 18:38:43 | train] - Train Epoch: [110] [960000/1281167 (75%)]	Loss: 0.857465
[2022-03-31 18:39:04 | train] - Train Epoch: [110] [972800/1281167 (76%)]	Loss: 0.726809
[2022-03-31 18:39:27 | train] - Train Epoch: [110] [985600/1281167 (77%)]	Loss: 0.733305
[2022-03-31 18:39:48 | train] - Train Epoch: [110] [998400/1281167 (78%)]	Loss: 0.849196
[2022-03-31 18:40:10 | train] - Train Epoch: [110] [1011200/1281167 (79%)]	Loss: 0.855926
[2022-03-31 18:40:32 | train] - Train Epoch: [110] [1024000/1281167 (80%)]	Loss: 1.156524
[2022-03-31 18:40:54 | train] - Train Epoch: [110] [1036800/1281167 (81%)]	Loss: 0.535204
[2022-03-31 18:41:15 | train] - Train Epoch: [110] [1049600/1281167 (82%)]	Loss: 0.729339
[2022-03-31 18:41:38 | train] - Train Epoch: [110] [1062400/1281167 (83%)]	Loss: 0.645554
[2022-03-31 18:41:59 | train] - Train Epoch: [110] [1075200/1281167 (84%)]	Loss: 0.688144
[2022-03-31 18:42:22 | train] - Train Epoch: [110] [1088000/1281167 (85%)]	Loss: 0.850094
[2022-03-31 18:42:43 | train] - Train Epoch: [110] [1100800/1281167 (86%)]	Loss: 0.706054
[2022-03-31 18:43:04 | train] - Train Epoch: [110] [1113600/1281167 (87%)]	Loss: 0.634940
[2022-03-31 18:43:26 | train] - Train Epoch: [110] [1126400/1281167 (88%)]	Loss: 0.904224
[2022-03-31 18:43:48 | train] - Train Epoch: [110] [1139200/1281167 (89%)]	Loss: 0.945764
[2022-03-31 18:44:10 | train] - Train Epoch: [110] [1152000/1281167 (90%)]	Loss: 0.819525
[2022-03-31 18:44:32 | train] - Train Epoch: [110] [1164800/1281167 (91%)]	Loss: 0.828583
[2022-03-31 18:44:54 | train] - Train Epoch: [110] [1177600/1281167 (92%)]	Loss: 0.812625
[2022-03-31 18:45:15 | train] - Train Epoch: [110] [1190400/1281167 (93%)]	Loss: 0.660616
[2022-03-31 18:45:36 | train] - Train Epoch: [110] [1203200/1281167 (94%)]	Loss: 0.751285
[2022-03-31 18:45:58 | train] - Train Epoch: [110] [1216000/1281167 (95%)]	Loss: 0.695465
[2022-03-31 18:46:20 | train] - Train Epoch: [110] [1228800/1281167 (96%)]	Loss: 0.638020
[2022-03-31 18:46:41 | train] - Train Epoch: [110] [1241600/1281167 (97%)]	Loss: 0.802165
[2022-03-31 18:47:03 | train] - Train Epoch: [110] [1254400/1281167 (98%)]	Loss: 0.790461
[2022-03-31 18:47:25 | train] - Train Epoch: [110] [1267200/1281167 (99%)]	Loss: 0.693612
[2022-03-31 18:47:47 | train] - Train Epoch: [110] [1280000/1281167 (100%)]	Loss: 0.647467
[2022-03-31 18:47:49 | train] - Train Epoch: [110]	 Average Loss: 0.783765	 Total Acc : 80.8170	 Total Top5 Acc : 93.0752
[2022-03-31 18:47:49 | train] - -------110 epoch end-----------
========================================
-------110 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 18:49:23 | train] - 
Epoch [110] Test set: Average loss: 1.4245, Accuracy: 34808/50000 (69.5900%), Top-5 Accuracy: 88.7092%

[2022-03-31 18:49:23 | train] - save intermediate epoch [110] result


[2022-03-31 18:49:36 | train] - -------111 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 18:49:38 | train] - Train Epoch: [111] [0/1281167 (0%)]	Loss: 0.820210
[2022-03-31 18:50:01 | train] - Train Epoch: [111] [12800/1281167 (1%)]	Loss: 0.924608
[2022-03-31 18:50:23 | train] - Train Epoch: [111] [25600/1281167 (2%)]	Loss: 0.957077
[2022-03-31 18:50:45 | train] - Train Epoch: [111] [38400/1281167 (3%)]	Loss: 0.744872
[2022-03-31 18:51:07 | train] - Train Epoch: [111] [51200/1281167 (4%)]	Loss: 0.612787
[2022-03-31 18:51:28 | train] - Train Epoch: [111] [64000/1281167 (5%)]	Loss: 0.701854
[2022-03-31 18:51:51 | train] - Train Epoch: [111] [76800/1281167 (6%)]	Loss: 0.724505
[2022-03-31 18:52:13 | train] - Train Epoch: [111] [89600/1281167 (7%)]	Loss: 0.767215
[2022-03-31 18:52:35 | train] - Train Epoch: [111] [102400/1281167 (8%)]	Loss: 0.797610
[2022-03-31 18:52:56 | train] - Train Epoch: [111] [115200/1281167 (9%)]	Loss: 0.648443
[2022-03-31 18:53:19 | train] - Train Epoch: [111] [128000/1281167 (10%)]	Loss: 0.750288
[2022-03-31 18:53:40 | train] - Train Epoch: [111] [140800/1281167 (11%)]	Loss: 0.677041
[2022-03-31 18:54:03 | train] - Train Epoch: [111] [153600/1281167 (12%)]	Loss: 0.453584
[2022-03-31 18:54:25 | train] - Train Epoch: [111] [166400/1281167 (13%)]	Loss: 0.738261
[2022-03-31 18:54:46 | train] - Train Epoch: [111] [179200/1281167 (14%)]	Loss: 0.608116
[2022-03-31 18:55:07 | train] - Train Epoch: [111] [192000/1281167 (15%)]	Loss: 0.429406
[2022-03-31 18:55:29 | train] - Train Epoch: [111] [204800/1281167 (16%)]	Loss: 0.766785
[2022-03-31 18:55:51 | train] - Train Epoch: [111] [217600/1281167 (17%)]	Loss: 1.032914
[2022-03-31 18:56:12 | train] - Train Epoch: [111] [230400/1281167 (18%)]	Loss: 1.002658
[2022-03-31 18:56:35 | train] - Train Epoch: [111] [243200/1281167 (19%)]	Loss: 0.562688
[2022-03-31 18:56:56 | train] - Train Epoch: [111] [256000/1281167 (20%)]	Loss: 0.692479
[2022-03-31 18:57:18 | train] - Train Epoch: [111] [268800/1281167 (21%)]	Loss: 0.645097
[2022-03-31 18:57:40 | train] - Train Epoch: [111] [281600/1281167 (22%)]	Loss: 0.726283
[2022-03-31 18:58:01 | train] - Train Epoch: [111] [294400/1281167 (23%)]	Loss: 0.866569
[2022-03-31 18:58:24 | train] - Train Epoch: [111] [307200/1281167 (24%)]	Loss: 0.752701
[2022-03-31 18:58:45 | train] - Train Epoch: [111] [320000/1281167 (25%)]	Loss: 0.908356
[2022-03-31 18:59:07 | train] - Train Epoch: [111] [332800/1281167 (26%)]	Loss: 0.785733
[2022-03-31 18:59:29 | train] - Train Epoch: [111] [345600/1281167 (27%)]	Loss: 0.643628
[2022-03-31 18:59:51 | train] - Train Epoch: [111] [358400/1281167 (28%)]	Loss: 0.563780
[2022-03-31 19:00:12 | train] - Train Epoch: [111] [371200/1281167 (29%)]	Loss: 0.676070
[2022-03-31 19:00:34 | train] - Train Epoch: [111] [384000/1281167 (30%)]	Loss: 0.703284
[2022-03-31 19:00:56 | train] - Train Epoch: [111] [396800/1281167 (31%)]	Loss: 0.709319
[2022-03-31 19:01:18 | train] - Train Epoch: [111] [409600/1281167 (32%)]	Loss: 0.847540
[2022-03-31 19:01:40 | train] - Train Epoch: [111] [422400/1281167 (33%)]	Loss: 0.777924
[2022-03-31 19:02:03 | train] - Train Epoch: [111] [435200/1281167 (34%)]	Loss: 0.825088
[2022-03-31 19:02:25 | train] - Train Epoch: [111] [448000/1281167 (35%)]	Loss: 0.883945
[2022-03-31 19:02:46 | train] - Train Epoch: [111] [460800/1281167 (36%)]	Loss: 0.742015
[2022-03-31 19:03:08 | train] - Train Epoch: [111] [473600/1281167 (37%)]	Loss: 0.667205
[2022-03-31 19:03:30 | train] - Train Epoch: [111] [486400/1281167 (38%)]	Loss: 0.711444
[2022-03-31 19:03:52 | train] - Train Epoch: [111] [499200/1281167 (39%)]	Loss: 0.580170
[2022-03-31 19:04:14 | train] - Train Epoch: [111] [512000/1281167 (40%)]	Loss: 0.758118
[2022-03-31 19:04:36 | train] - Train Epoch: [111] [524800/1281167 (41%)]	Loss: 0.965285
[2022-03-31 19:04:59 | train] - Train Epoch: [111] [537600/1281167 (42%)]	Loss: 0.787026
[2022-03-31 19:05:20 | train] - Train Epoch: [111] [550400/1281167 (43%)]	Loss: 0.719445
[2022-03-31 19:05:42 | train] - Train Epoch: [111] [563200/1281167 (44%)]	Loss: 1.016575
[2022-03-31 19:06:03 | train] - Train Epoch: [111] [576000/1281167 (45%)]	Loss: 1.008786
[2022-03-31 19:06:26 | train] - Train Epoch: [111] [588800/1281167 (46%)]	Loss: 0.683933
[2022-03-31 19:06:47 | train] - Train Epoch: [111] [601600/1281167 (47%)]	Loss: 0.750803
[2022-03-31 19:07:09 | train] - Train Epoch: [111] [614400/1281167 (48%)]	Loss: 0.775080
[2022-03-31 19:07:30 | train] - Train Epoch: [111] [627200/1281167 (49%)]	Loss: 0.878087
[2022-03-31 19:07:52 | train] - Train Epoch: [111] [640000/1281167 (50%)]	Loss: 0.593913
[2022-03-31 19:08:13 | train] - Train Epoch: [111] [652800/1281167 (51%)]	Loss: 0.976694
[2022-03-31 19:08:36 | train] - Train Epoch: [111] [665600/1281167 (52%)]	Loss: 0.625717
[2022-03-31 19:08:57 | train] - Train Epoch: [111] [678400/1281167 (53%)]	Loss: 0.823083
[2022-03-31 19:09:19 | train] - Train Epoch: [111] [691200/1281167 (54%)]	Loss: 0.917754
[2022-03-31 19:09:41 | train] - Train Epoch: [111] [704000/1281167 (55%)]	Loss: 0.563826
[2022-03-31 19:10:03 | train] - Train Epoch: [111] [716800/1281167 (56%)]	Loss: 0.639573
[2022-03-31 19:10:25 | train] - Train Epoch: [111] [729600/1281167 (57%)]	Loss: 0.889113
[2022-03-31 19:10:47 | train] - Train Epoch: [111] [742400/1281167 (58%)]	Loss: 0.776916
[2022-03-31 19:11:09 | train] - Train Epoch: [111] [755200/1281167 (59%)]	Loss: 0.847095
[2022-03-31 19:11:30 | train] - Train Epoch: [111] [768000/1281167 (60%)]	Loss: 0.912673
[2022-03-31 19:11:52 | train] - Train Epoch: [111] [780800/1281167 (61%)]	Loss: 0.873417
[2022-03-31 19:12:13 | train] - Train Epoch: [111] [793600/1281167 (62%)]	Loss: 0.719857
[2022-03-31 19:12:36 | train] - Train Epoch: [111] [806400/1281167 (63%)]	Loss: 0.647751
[2022-03-31 19:12:58 | train] - Train Epoch: [111] [819200/1281167 (64%)]	Loss: 1.042894
[2022-03-31 19:13:20 | train] - Train Epoch: [111] [832000/1281167 (65%)]	Loss: 0.816662
[2022-03-31 19:13:42 | train] - Train Epoch: [111] [844800/1281167 (66%)]	Loss: 0.669195
[2022-03-31 19:14:04 | train] - Train Epoch: [111] [857600/1281167 (67%)]	Loss: 0.989649
[2022-03-31 19:14:25 | train] - Train Epoch: [111] [870400/1281167 (68%)]	Loss: 0.854807
[2022-03-31 19:14:47 | train] - Train Epoch: [111] [883200/1281167 (69%)]	Loss: 0.781671
[2022-03-31 19:15:08 | train] - Train Epoch: [111] [896000/1281167 (70%)]	Loss: 0.781442
[2022-03-31 19:15:30 | train] - Train Epoch: [111] [908800/1281167 (71%)]	Loss: 0.705459
[2022-03-31 19:15:52 | train] - Train Epoch: [111] [921600/1281167 (72%)]	Loss: 0.818332
[2022-03-31 19:16:14 | train] - Train Epoch: [111] [934400/1281167 (73%)]	Loss: 0.747310
[2022-03-31 19:16:36 | train] - Train Epoch: [111] [947200/1281167 (74%)]	Loss: 1.029629
[2022-03-31 19:16:57 | train] - Train Epoch: [111] [960000/1281167 (75%)]	Loss: 0.778789
[2022-03-31 19:17:19 | train] - Train Epoch: [111] [972800/1281167 (76%)]	Loss: 0.927867
[2022-03-31 19:17:41 | train] - Train Epoch: [111] [985600/1281167 (77%)]	Loss: 0.933409
[2022-03-31 19:18:02 | train] - Train Epoch: [111] [998400/1281167 (78%)]	Loss: 0.611566
[2022-03-31 19:18:24 | train] - Train Epoch: [111] [1011200/1281167 (79%)]	Loss: 0.834452
[2022-03-31 19:18:45 | train] - Train Epoch: [111] [1024000/1281167 (80%)]	Loss: 0.652924
[2022-03-31 19:19:07 | train] - Train Epoch: [111] [1036800/1281167 (81%)]	Loss: 0.722170
[2022-03-31 19:19:29 | train] - Train Epoch: [111] [1049600/1281167 (82%)]	Loss: 0.603076
[2022-03-31 19:19:51 | train] - Train Epoch: [111] [1062400/1281167 (83%)]	Loss: 1.168897
[2022-03-31 19:20:13 | train] - Train Epoch: [111] [1075200/1281167 (84%)]	Loss: 0.630006
[2022-03-31 19:20:34 | train] - Train Epoch: [111] [1088000/1281167 (85%)]	Loss: 0.670813
[2022-03-31 19:20:56 | train] - Train Epoch: [111] [1100800/1281167 (86%)]	Loss: 0.946649
[2022-03-31 19:21:17 | train] - Train Epoch: [111] [1113600/1281167 (87%)]	Loss: 0.683098
[2022-03-31 19:21:39 | train] - Train Epoch: [111] [1126400/1281167 (88%)]	Loss: 0.601437
[2022-03-31 19:22:01 | train] - Train Epoch: [111] [1139200/1281167 (89%)]	Loss: 0.777946
[2022-03-31 19:22:23 | train] - Train Epoch: [111] [1152000/1281167 (90%)]	Loss: 0.804182
[2022-03-31 19:22:43 | train] - Train Epoch: [111] [1164800/1281167 (91%)]	Loss: 0.717611
[2022-03-31 19:23:05 | train] - Train Epoch: [111] [1177600/1281167 (92%)]	Loss: 0.829919
[2022-03-31 19:23:27 | train] - Train Epoch: [111] [1190400/1281167 (93%)]	Loss: 0.964735
[2022-03-31 19:23:48 | train] - Train Epoch: [111] [1203200/1281167 (94%)]	Loss: 1.308637
[2022-03-31 19:24:10 | train] - Train Epoch: [111] [1216000/1281167 (95%)]	Loss: 0.606675
[2022-03-31 19:24:32 | train] - Train Epoch: [111] [1228800/1281167 (96%)]	Loss: 0.541308
[2022-03-31 19:24:54 | train] - Train Epoch: [111] [1241600/1281167 (97%)]	Loss: 0.666505
[2022-03-31 19:25:15 | train] - Train Epoch: [111] [1254400/1281167 (98%)]	Loss: 0.898636
[2022-03-31 19:25:35 | train] - Train Epoch: [111] [1267200/1281167 (99%)]	Loss: 0.802622
[2022-03-31 19:25:56 | train] - Train Epoch: [111] [1280000/1281167 (100%)]	Loss: 0.758456
[2022-03-31 19:25:57 | train] - Train Epoch: [111]	 Average Loss: 0.781236	 Total Acc : 80.8693	 Total Top5 Acc : 93.0812
[2022-03-31 19:25:57 | train] - -------111 epoch end-----------
========================================
-------111 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 19:27:29 | train] - 
Epoch [111] Test set: Average loss: 1.4391, Accuracy: 34780/50000 (69.5316%), Top-5 Accuracy: 88.7308%

[2022-03-31 19:27:29 | train] - save intermediate epoch [111] result


[2022-03-31 19:27:42 | train] - -------112 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 19:27:44 | train] - Train Epoch: [112] [0/1281167 (0%)]	Loss: 0.768350
[2022-03-31 19:28:05 | train] - Train Epoch: [112] [12800/1281167 (1%)]	Loss: 0.622008
[2022-03-31 19:28:27 | train] - Train Epoch: [112] [25600/1281167 (2%)]	Loss: 0.647116
[2022-03-31 19:28:49 | train] - Train Epoch: [112] [38400/1281167 (3%)]	Loss: 0.891840
[2022-03-31 19:29:10 | train] - Train Epoch: [112] [51200/1281167 (4%)]	Loss: 0.983235
[2022-03-31 19:29:31 | train] - Train Epoch: [112] [64000/1281167 (5%)]	Loss: 0.800029
[2022-03-31 19:29:51 | train] - Train Epoch: [112] [76800/1281167 (6%)]	Loss: 0.755211
[2022-03-31 19:30:12 | train] - Train Epoch: [112] [89600/1281167 (7%)]	Loss: 1.006834
[2022-03-31 19:30:34 | train] - Train Epoch: [112] [102400/1281167 (8%)]	Loss: 0.538328
[2022-03-31 19:30:55 | train] - Train Epoch: [112] [115200/1281167 (9%)]	Loss: 0.731380
[2022-03-31 19:31:17 | train] - Train Epoch: [112] [128000/1281167 (10%)]	Loss: 0.749535
[2022-03-31 19:31:38 | train] - Train Epoch: [112] [140800/1281167 (11%)]	Loss: 0.939877
[2022-03-31 19:31:58 | train] - Train Epoch: [112] [153600/1281167 (12%)]	Loss: 0.854412
[2022-03-31 19:32:19 | train] - Train Epoch: [112] [166400/1281167 (13%)]	Loss: 0.646567
[2022-03-31 19:32:40 | train] - Train Epoch: [112] [179200/1281167 (14%)]	Loss: 0.724292
[2022-03-31 19:33:00 | train] - Train Epoch: [112] [192000/1281167 (15%)]	Loss: 0.710562
[2022-03-31 19:33:21 | train] - Train Epoch: [112] [204800/1281167 (16%)]	Loss: 0.634005
[2022-03-31 19:33:42 | train] - Train Epoch: [112] [217600/1281167 (17%)]	Loss: 0.980873
[2022-03-31 19:34:03 | train] - Train Epoch: [112] [230400/1281167 (18%)]	Loss: 0.879181
[2022-03-31 19:34:24 | train] - Train Epoch: [112] [243200/1281167 (19%)]	Loss: 1.001428
[2022-03-31 19:34:44 | train] - Train Epoch: [112] [256000/1281167 (20%)]	Loss: 0.891035
[2022-03-31 19:35:04 | train] - Train Epoch: [112] [268800/1281167 (21%)]	Loss: 0.744652
[2022-03-31 19:35:24 | train] - Train Epoch: [112] [281600/1281167 (22%)]	Loss: 0.751358
[2022-03-31 19:35:46 | train] - Train Epoch: [112] [294400/1281167 (23%)]	Loss: 0.718415
[2022-03-31 19:36:06 | train] - Train Epoch: [112] [307200/1281167 (24%)]	Loss: 0.720837
[2022-03-31 19:36:27 | train] - Train Epoch: [112] [320000/1281167 (25%)]	Loss: 0.537751
[2022-03-31 19:36:48 | train] - Train Epoch: [112] [332800/1281167 (26%)]	Loss: 0.981935
[2022-03-31 19:37:09 | train] - Train Epoch: [112] [345600/1281167 (27%)]	Loss: 0.679070
[2022-03-31 19:37:29 | train] - Train Epoch: [112] [358400/1281167 (28%)]	Loss: 0.686898
[2022-03-31 19:37:49 | train] - Train Epoch: [112] [371200/1281167 (29%)]	Loss: 0.902621
[2022-03-31 19:38:09 | train] - Train Epoch: [112] [384000/1281167 (30%)]	Loss: 0.871120
[2022-03-31 19:38:29 | train] - Train Epoch: [112] [396800/1281167 (31%)]	Loss: 1.003363
[2022-03-31 19:38:48 | train] - Train Epoch: [112] [409600/1281167 (32%)]	Loss: 0.700221
[2022-03-31 19:39:08 | train] - Train Epoch: [112] [422400/1281167 (33%)]	Loss: 0.844351
[2022-03-31 19:39:27 | train] - Train Epoch: [112] [435200/1281167 (34%)]	Loss: 0.811111
[2022-03-31 19:39:46 | train] - Train Epoch: [112] [448000/1281167 (35%)]	Loss: 0.505821
[2022-03-31 19:40:05 | train] - Train Epoch: [112] [460800/1281167 (36%)]	Loss: 1.013378
[2022-03-31 19:40:24 | train] - Train Epoch: [112] [473600/1281167 (37%)]	Loss: 0.583628
[2022-03-31 19:40:44 | train] - Train Epoch: [112] [486400/1281167 (38%)]	Loss: 0.775862
[2022-03-31 19:41:03 | train] - Train Epoch: [112] [499200/1281167 (39%)]	Loss: 0.687170
[2022-03-31 19:41:23 | train] - Train Epoch: [112] [512000/1281167 (40%)]	Loss: 0.724545
[2022-03-31 19:41:42 | train] - Train Epoch: [112] [524800/1281167 (41%)]	Loss: 0.661700
[2022-03-31 19:42:03 | train] - Train Epoch: [112] [537600/1281167 (42%)]	Loss: 0.763220
[2022-03-31 19:42:22 | train] - Train Epoch: [112] [550400/1281167 (43%)]	Loss: 0.616704
[2022-03-31 19:42:41 | train] - Train Epoch: [112] [563200/1281167 (44%)]	Loss: 0.729374
[2022-03-31 19:43:00 | train] - Train Epoch: [112] [576000/1281167 (45%)]	Loss: 0.767053
[2022-03-31 19:43:21 | train] - Train Epoch: [112] [588800/1281167 (46%)]	Loss: 0.870100
[2022-03-31 19:43:40 | train] - Train Epoch: [112] [601600/1281167 (47%)]	Loss: 0.621501
[2022-03-31 19:44:00 | train] - Train Epoch: [112] [614400/1281167 (48%)]	Loss: 0.895288
[2022-03-31 19:44:20 | train] - Train Epoch: [112] [627200/1281167 (49%)]	Loss: 1.011397
[2022-03-31 19:44:40 | train] - Train Epoch: [112] [640000/1281167 (50%)]	Loss: 0.625697
[2022-03-31 19:45:00 | train] - Train Epoch: [112] [652800/1281167 (51%)]	Loss: 0.620005
[2022-03-31 19:45:20 | train] - Train Epoch: [112] [665600/1281167 (52%)]	Loss: 0.742303
[2022-03-31 19:45:40 | train] - Train Epoch: [112] [678400/1281167 (53%)]	Loss: 0.768479
[2022-03-31 19:45:59 | train] - Train Epoch: [112] [691200/1281167 (54%)]	Loss: 0.839501
[2022-03-31 19:46:19 | train] - Train Epoch: [112] [704000/1281167 (55%)]	Loss: 0.643226
[2022-03-31 19:46:38 | train] - Train Epoch: [112] [716800/1281167 (56%)]	Loss: 0.894466
[2022-03-31 19:46:58 | train] - Train Epoch: [112] [729600/1281167 (57%)]	Loss: 0.803902
[2022-03-31 19:47:18 | train] - Train Epoch: [112] [742400/1281167 (58%)]	Loss: 0.594732
[2022-03-31 19:47:37 | train] - Train Epoch: [112] [755200/1281167 (59%)]	Loss: 0.690751
[2022-03-31 19:47:56 | train] - Train Epoch: [112] [768000/1281167 (60%)]	Loss: 1.065744
[2022-03-31 19:48:16 | train] - Train Epoch: [112] [780800/1281167 (61%)]	Loss: 0.814179
[2022-03-31 19:48:36 | train] - Train Epoch: [112] [793600/1281167 (62%)]	Loss: 0.675293
[2022-03-31 19:48:55 | train] - Train Epoch: [112] [806400/1281167 (63%)]	Loss: 0.875442
[2022-03-31 19:49:16 | train] - Train Epoch: [112] [819200/1281167 (64%)]	Loss: 0.859739
[2022-03-31 19:49:35 | train] - Train Epoch: [112] [832000/1281167 (65%)]	Loss: 0.689769
[2022-03-31 19:49:54 | train] - Train Epoch: [112] [844800/1281167 (66%)]	Loss: 0.669977
[2022-03-31 19:50:14 | train] - Train Epoch: [112] [857600/1281167 (67%)]	Loss: 0.946131
[2022-03-31 19:50:33 | train] - Train Epoch: [112] [870400/1281167 (68%)]	Loss: 0.908916
[2022-03-31 19:50:52 | train] - Train Epoch: [112] [883200/1281167 (69%)]	Loss: 1.047862
[2022-03-31 19:51:12 | train] - Train Epoch: [112] [896000/1281167 (70%)]	Loss: 0.676102
[2022-03-31 19:51:32 | train] - Train Epoch: [112] [908800/1281167 (71%)]	Loss: 0.587722
[2022-03-31 19:51:52 | train] - Train Epoch: [112] [921600/1281167 (72%)]	Loss: 0.620622
[2022-03-31 19:52:12 | train] - Train Epoch: [112] [934400/1281167 (73%)]	Loss: 0.732178
[2022-03-31 19:52:31 | train] - Train Epoch: [112] [947200/1281167 (74%)]	Loss: 0.609977
[2022-03-31 19:52:51 | train] - Train Epoch: [112] [960000/1281167 (75%)]	Loss: 0.751513
[2022-03-31 19:53:10 | train] - Train Epoch: [112] [972800/1281167 (76%)]	Loss: 0.716978
[2022-03-31 19:53:30 | train] - Train Epoch: [112] [985600/1281167 (77%)]	Loss: 0.632923
[2022-03-31 19:53:50 | train] - Train Epoch: [112] [998400/1281167 (78%)]	Loss: 0.873557
[2022-03-31 19:54:09 | train] - Train Epoch: [112] [1011200/1281167 (79%)]	Loss: 0.581996
[2022-03-31 19:54:29 | train] - Train Epoch: [112] [1024000/1281167 (80%)]	Loss: 0.843357
[2022-03-31 19:54:49 | train] - Train Epoch: [112] [1036800/1281167 (81%)]	Loss: 0.886314
[2022-03-31 19:55:09 | train] - Train Epoch: [112] [1049600/1281167 (82%)]	Loss: 1.017084
[2022-03-31 19:55:29 | train] - Train Epoch: [112] [1062400/1281167 (83%)]	Loss: 0.689775
[2022-03-31 19:55:49 | train] - Train Epoch: [112] [1075200/1281167 (84%)]	Loss: 0.842014
[2022-03-31 19:56:08 | train] - Train Epoch: [112] [1088000/1281167 (85%)]	Loss: 0.864013
[2022-03-31 19:56:27 | train] - Train Epoch: [112] [1100800/1281167 (86%)]	Loss: 0.831915
[2022-03-31 19:56:47 | train] - Train Epoch: [112] [1113600/1281167 (87%)]	Loss: 0.579342
[2022-03-31 19:57:06 | train] - Train Epoch: [112] [1126400/1281167 (88%)]	Loss: 0.847738
[2022-03-31 19:57:26 | train] - Train Epoch: [112] [1139200/1281167 (89%)]	Loss: 0.590777
[2022-03-31 19:57:46 | train] - Train Epoch: [112] [1152000/1281167 (90%)]	Loss: 0.856997
[2022-03-31 19:58:06 | train] - Train Epoch: [112] [1164800/1281167 (91%)]	Loss: 0.844295
[2022-03-31 19:58:25 | train] - Train Epoch: [112] [1177600/1281167 (92%)]	Loss: 1.172927
[2022-03-31 19:58:45 | train] - Train Epoch: [112] [1190400/1281167 (93%)]	Loss: 0.977972
[2022-03-31 19:59:04 | train] - Train Epoch: [112] [1203200/1281167 (94%)]	Loss: 0.831235
[2022-03-31 19:59:24 | train] - Train Epoch: [112] [1216000/1281167 (95%)]	Loss: 0.902377
[2022-03-31 19:59:43 | train] - Train Epoch: [112] [1228800/1281167 (96%)]	Loss: 0.823028
[2022-03-31 20:00:03 | train] - Train Epoch: [112] [1241600/1281167 (97%)]	Loss: 0.596993
[2022-03-31 20:00:22 | train] - Train Epoch: [112] [1254400/1281167 (98%)]	Loss: 0.683176
[2022-03-31 20:00:42 | train] - Train Epoch: [112] [1267200/1281167 (99%)]	Loss: 1.256913
[2022-03-31 20:01:01 | train] - Train Epoch: [112] [1280000/1281167 (100%)]	Loss: 0.726630
[2022-03-31 20:01:03 | train] - Train Epoch: [112]	 Average Loss: 0.776334	 Total Acc : 81.0172	 Total Top5 Acc : 93.1281
[2022-03-31 20:01:03 | train] - -------112 epoch end-----------
========================================
-------112 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 20:02:33 | train] - 
Epoch [112] Test set: Average loss: 1.4261, Accuracy: 34745/50000 (69.4617%), Top-5 Accuracy: 88.7680%

[2022-03-31 20:02:33 | train] - save intermediate epoch [112] result


[2022-03-31 20:02:47 | train] - -------113 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 20:02:49 | train] - Train Epoch: [113] [0/1281167 (0%)]	Loss: 0.683891
[2022-03-31 20:03:09 | train] - Train Epoch: [113] [12800/1281167 (1%)]	Loss: 0.568163
[2022-03-31 20:03:31 | train] - Train Epoch: [113] [25600/1281167 (2%)]	Loss: 0.789083
[2022-03-31 20:03:52 | train] - Train Epoch: [113] [38400/1281167 (3%)]	Loss: 0.967566
[2022-03-31 20:04:13 | train] - Train Epoch: [113] [51200/1281167 (4%)]	Loss: 0.756814
[2022-03-31 20:04:34 | train] - Train Epoch: [113] [64000/1281167 (5%)]	Loss: 0.670168
[2022-03-31 20:04:55 | train] - Train Epoch: [113] [76800/1281167 (6%)]	Loss: 0.896942
[2022-03-31 20:05:16 | train] - Train Epoch: [113] [89600/1281167 (7%)]	Loss: 0.812402
[2022-03-31 20:05:37 | train] - Train Epoch: [113] [102400/1281167 (8%)]	Loss: 0.945399
[2022-03-31 20:05:57 | train] - Train Epoch: [113] [115200/1281167 (9%)]	Loss: 0.601335
[2022-03-31 20:06:17 | train] - Train Epoch: [113] [128000/1281167 (10%)]	Loss: 0.756652
[2022-03-31 20:06:37 | train] - Train Epoch: [113] [140800/1281167 (11%)]	Loss: 0.895820
[2022-03-31 20:06:58 | train] - Train Epoch: [113] [153600/1281167 (12%)]	Loss: 0.651025
[2022-03-31 20:07:18 | train] - Train Epoch: [113] [166400/1281167 (13%)]	Loss: 0.810254
[2022-03-31 20:07:38 | train] - Train Epoch: [113] [179200/1281167 (14%)]	Loss: 0.667528
[2022-03-31 20:07:58 | train] - Train Epoch: [113] [192000/1281167 (15%)]	Loss: 0.851806
[2022-03-31 20:08:17 | train] - Train Epoch: [113] [204800/1281167 (16%)]	Loss: 0.620703
[2022-03-31 20:08:37 | train] - Train Epoch: [113] [217600/1281167 (17%)]	Loss: 0.582161
[2022-03-31 20:08:57 | train] - Train Epoch: [113] [230400/1281167 (18%)]	Loss: 0.792389
[2022-03-31 20:09:16 | train] - Train Epoch: [113] [243200/1281167 (19%)]	Loss: 0.844535
[2022-03-31 20:09:36 | train] - Train Epoch: [113] [256000/1281167 (20%)]	Loss: 0.694639
[2022-03-31 20:09:55 | train] - Train Epoch: [113] [268800/1281167 (21%)]	Loss: 0.692311
[2022-03-31 20:10:15 | train] - Train Epoch: [113] [281600/1281167 (22%)]	Loss: 0.881287
[2022-03-31 20:10:35 | train] - Train Epoch: [113] [294400/1281167 (23%)]	Loss: 0.839636
[2022-03-31 20:10:54 | train] - Train Epoch: [113] [307200/1281167 (24%)]	Loss: 0.654847
[2022-03-31 20:11:14 | train] - Train Epoch: [113] [320000/1281167 (25%)]	Loss: 0.755277
[2022-03-31 20:11:33 | train] - Train Epoch: [113] [332800/1281167 (26%)]	Loss: 0.960709
[2022-03-31 20:11:53 | train] - Train Epoch: [113] [345600/1281167 (27%)]	Loss: 0.811386
[2022-03-31 20:12:13 | train] - Train Epoch: [113] [358400/1281167 (28%)]	Loss: 0.472146
[2022-03-31 20:12:32 | train] - Train Epoch: [113] [371200/1281167 (29%)]	Loss: 0.883694
[2022-03-31 20:12:53 | train] - Train Epoch: [113] [384000/1281167 (30%)]	Loss: 0.661611
[2022-03-31 20:13:12 | train] - Train Epoch: [113] [396800/1281167 (31%)]	Loss: 0.730603
[2022-03-31 20:13:32 | train] - Train Epoch: [113] [409600/1281167 (32%)]	Loss: 0.688736
[2022-03-31 20:13:51 | train] - Train Epoch: [113] [422400/1281167 (33%)]	Loss: 0.878706
[2022-03-31 20:14:10 | train] - Train Epoch: [113] [435200/1281167 (34%)]	Loss: 0.804507
[2022-03-31 20:14:30 | train] - Train Epoch: [113] [448000/1281167 (35%)]	Loss: 0.706503
[2022-03-31 20:14:50 | train] - Train Epoch: [113] [460800/1281167 (36%)]	Loss: 0.936876
[2022-03-31 20:15:10 | train] - Train Epoch: [113] [473600/1281167 (37%)]	Loss: 0.936051
[2022-03-31 20:15:30 | train] - Train Epoch: [113] [486400/1281167 (38%)]	Loss: 1.003058
[2022-03-31 20:15:50 | train] - Train Epoch: [113] [499200/1281167 (39%)]	Loss: 0.848218
[2022-03-31 20:16:09 | train] - Train Epoch: [113] [512000/1281167 (40%)]	Loss: 0.649656
[2022-03-31 20:16:29 | train] - Train Epoch: [113] [524800/1281167 (41%)]	Loss: 0.854610
[2022-03-31 20:16:48 | train] - Train Epoch: [113] [537600/1281167 (42%)]	Loss: 0.711785
[2022-03-31 20:17:08 | train] - Train Epoch: [113] [550400/1281167 (43%)]	Loss: 0.634460
[2022-03-31 20:17:28 | train] - Train Epoch: [113] [563200/1281167 (44%)]	Loss: 0.671874
[2022-03-31 20:17:48 | train] - Train Epoch: [113] [576000/1281167 (45%)]	Loss: 0.673994
[2022-03-31 20:18:08 | train] - Train Epoch: [113] [588800/1281167 (46%)]	Loss: 0.762684
[2022-03-31 20:18:27 | train] - Train Epoch: [113] [601600/1281167 (47%)]	Loss: 0.573969
[2022-03-31 20:18:47 | train] - Train Epoch: [113] [614400/1281167 (48%)]	Loss: 0.941969
[2022-03-31 20:19:06 | train] - Train Epoch: [113] [627200/1281167 (49%)]	Loss: 0.714313
[2022-03-31 20:19:26 | train] - Train Epoch: [113] [640000/1281167 (50%)]	Loss: 0.775923
[2022-03-31 20:19:45 | train] - Train Epoch: [113] [652800/1281167 (51%)]	Loss: 0.883555
[2022-03-31 20:20:05 | train] - Train Epoch: [113] [665600/1281167 (52%)]	Loss: 0.677116
[2022-03-31 20:20:25 | train] - Train Epoch: [113] [678400/1281167 (53%)]	Loss: 0.768834
[2022-03-31 20:20:45 | train] - Train Epoch: [113] [691200/1281167 (54%)]	Loss: 0.931516
[2022-03-31 20:21:05 | train] - Train Epoch: [113] [704000/1281167 (55%)]	Loss: 0.692225
[2022-03-31 20:21:25 | train] - Train Epoch: [113] [716800/1281167 (56%)]	Loss: 0.867367
[2022-03-31 20:21:44 | train] - Train Epoch: [113] [729600/1281167 (57%)]	Loss: 0.836809
[2022-03-31 20:22:04 | train] - Train Epoch: [113] [742400/1281167 (58%)]	Loss: 0.662067
[2022-03-31 20:22:24 | train] - Train Epoch: [113] [755200/1281167 (59%)]	Loss: 0.659995
[2022-03-31 20:22:44 | train] - Train Epoch: [113] [768000/1281167 (60%)]	Loss: 0.658761
[2022-03-31 20:23:04 | train] - Train Epoch: [113] [780800/1281167 (61%)]	Loss: 0.801819
[2022-03-31 20:23:24 | train] - Train Epoch: [113] [793600/1281167 (62%)]	Loss: 0.988253
[2022-03-31 20:23:43 | train] - Train Epoch: [113] [806400/1281167 (63%)]	Loss: 0.911440
[2022-03-31 20:24:03 | train] - Train Epoch: [113] [819200/1281167 (64%)]	Loss: 0.655495
[2022-03-31 20:24:23 | train] - Train Epoch: [113] [832000/1281167 (65%)]	Loss: 0.646861
[2022-03-31 20:24:43 | train] - Train Epoch: [113] [844800/1281167 (66%)]	Loss: 0.601463
[2022-03-31 20:25:02 | train] - Train Epoch: [113] [857600/1281167 (67%)]	Loss: 0.876535
[2022-03-31 20:25:21 | train] - Train Epoch: [113] [870400/1281167 (68%)]	Loss: 0.832818
[2022-03-31 20:25:41 | train] - Train Epoch: [113] [883200/1281167 (69%)]	Loss: 1.017821
[2022-03-31 20:26:00 | train] - Train Epoch: [113] [896000/1281167 (70%)]	Loss: 0.599928
[2022-03-31 20:26:20 | train] - Train Epoch: [113] [908800/1281167 (71%)]	Loss: 0.807200
[2022-03-31 20:26:40 | train] - Train Epoch: [113] [921600/1281167 (72%)]	Loss: 0.642801
[2022-03-31 20:26:59 | train] - Train Epoch: [113] [934400/1281167 (73%)]	Loss: 0.633463
[2022-03-31 20:27:20 | train] - Train Epoch: [113] [947200/1281167 (74%)]	Loss: 0.773326
[2022-03-31 20:27:39 | train] - Train Epoch: [113] [960000/1281167 (75%)]	Loss: 0.753892
[2022-03-31 20:27:59 | train] - Train Epoch: [113] [972800/1281167 (76%)]	Loss: 0.864275
[2022-03-31 20:28:19 | train] - Train Epoch: [113] [985600/1281167 (77%)]	Loss: 0.642677
[2022-03-31 20:28:39 | train] - Train Epoch: [113] [998400/1281167 (78%)]	Loss: 0.533396
[2022-03-31 20:28:59 | train] - Train Epoch: [113] [1011200/1281167 (79%)]	Loss: 0.764343
[2022-03-31 20:29:19 | train] - Train Epoch: [113] [1024000/1281167 (80%)]	Loss: 0.762914
[2022-03-31 20:29:38 | train] - Train Epoch: [113] [1036800/1281167 (81%)]	Loss: 0.925428
[2022-03-31 20:29:58 | train] - Train Epoch: [113] [1049600/1281167 (82%)]	Loss: 0.578167
[2022-03-31 20:30:18 | train] - Train Epoch: [113] [1062400/1281167 (83%)]	Loss: 0.736355
[2022-03-31 20:30:37 | train] - Train Epoch: [113] [1075200/1281167 (84%)]	Loss: 0.774076
[2022-03-31 20:30:57 | train] - Train Epoch: [113] [1088000/1281167 (85%)]	Loss: 0.910503
[2022-03-31 20:31:16 | train] - Train Epoch: [113] [1100800/1281167 (86%)]	Loss: 0.712230
[2022-03-31 20:31:35 | train] - Train Epoch: [113] [1113600/1281167 (87%)]	Loss: 0.676549
[2022-03-31 20:31:55 | train] - Train Epoch: [113] [1126400/1281167 (88%)]	Loss: 0.806180
[2022-03-31 20:32:15 | train] - Train Epoch: [113] [1139200/1281167 (89%)]	Loss: 0.924719
[2022-03-31 20:32:34 | train] - Train Epoch: [113] [1152000/1281167 (90%)]	Loss: 0.816767
[2022-03-31 20:32:54 | train] - Train Epoch: [113] [1164800/1281167 (91%)]	Loss: 0.915833
[2022-03-31 20:33:14 | train] - Train Epoch: [113] [1177600/1281167 (92%)]	Loss: 0.819366
[2022-03-31 20:33:33 | train] - Train Epoch: [113] [1190400/1281167 (93%)]	Loss: 0.722377
[2022-03-31 20:33:52 | train] - Train Epoch: [113] [1203200/1281167 (94%)]	Loss: 0.909435
[2022-03-31 20:34:12 | train] - Train Epoch: [113] [1216000/1281167 (95%)]	Loss: 0.604936
[2022-03-31 20:34:32 | train] - Train Epoch: [113] [1228800/1281167 (96%)]	Loss: 0.697970
[2022-03-31 20:34:52 | train] - Train Epoch: [113] [1241600/1281167 (97%)]	Loss: 0.785390
[2022-03-31 20:35:11 | train] - Train Epoch: [113] [1254400/1281167 (98%)]	Loss: 0.725621
[2022-03-31 20:35:31 | train] - Train Epoch: [113] [1267200/1281167 (99%)]	Loss: 0.659845
[2022-03-31 20:35:50 | train] - Train Epoch: [113] [1280000/1281167 (100%)]	Loss: 0.694091
[2022-03-31 20:35:52 | train] - Train Epoch: [113]	 Average Loss: 0.771501	 Total Acc : 81.1227	 Total Top5 Acc : 93.2017
[2022-03-31 20:35:52 | train] - -------113 epoch end-----------
========================================
-------113 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 20:37:25 | train] - 
Epoch [113] Test set: Average loss: 1.4475, Accuracy: 34664/50000 (69.2987%), Top-5 Accuracy: 88.6485%

[2022-03-31 20:37:25 | train] - save intermediate epoch [113] result


[2022-03-31 20:37:39 | train] - -------114 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 20:37:41 | train] - Train Epoch: [114] [0/1281167 (0%)]	Loss: 0.795598
[2022-03-31 20:38:00 | train] - Train Epoch: [114] [12800/1281167 (1%)]	Loss: 0.656042
[2022-03-31 20:38:20 | train] - Train Epoch: [114] [25600/1281167 (2%)]	Loss: 0.861732
[2022-03-31 20:38:39 | train] - Train Epoch: [114] [38400/1281167 (3%)]	Loss: 0.996313
[2022-03-31 20:38:59 | train] - Train Epoch: [114] [51200/1281167 (4%)]	Loss: 0.729054
[2022-03-31 20:39:18 | train] - Train Epoch: [114] [64000/1281167 (5%)]	Loss: 0.731949
[2022-03-31 20:39:38 | train] - Train Epoch: [114] [76800/1281167 (6%)]	Loss: 0.716546
[2022-03-31 20:39:57 | train] - Train Epoch: [114] [89600/1281167 (7%)]	Loss: 0.685188
[2022-03-31 20:40:16 | train] - Train Epoch: [114] [102400/1281167 (8%)]	Loss: 0.798303
[2022-03-31 20:40:36 | train] - Train Epoch: [114] [115200/1281167 (9%)]	Loss: 0.882976
[2022-03-31 20:40:56 | train] - Train Epoch: [114] [128000/1281167 (10%)]	Loss: 0.673805
[2022-03-31 20:41:16 | train] - Train Epoch: [114] [140800/1281167 (11%)]	Loss: 0.637140
[2022-03-31 20:41:36 | train] - Train Epoch: [114] [153600/1281167 (12%)]	Loss: 1.110049
[2022-03-31 20:41:55 | train] - Train Epoch: [114] [166400/1281167 (13%)]	Loss: 0.712183
[2022-03-31 20:42:15 | train] - Train Epoch: [114] [179200/1281167 (14%)]	Loss: 0.725041
[2022-03-31 20:42:34 | train] - Train Epoch: [114] [192000/1281167 (15%)]	Loss: 0.758240
[2022-03-31 20:42:54 | train] - Train Epoch: [114] [204800/1281167 (16%)]	Loss: 0.605359
[2022-03-31 20:43:14 | train] - Train Epoch: [114] [217600/1281167 (17%)]	Loss: 0.924521
[2022-03-31 20:43:33 | train] - Train Epoch: [114] [230400/1281167 (18%)]	Loss: 0.642734
[2022-03-31 20:43:53 | train] - Train Epoch: [114] [243200/1281167 (19%)]	Loss: 0.619802
[2022-03-31 20:44:13 | train] - Train Epoch: [114] [256000/1281167 (20%)]	Loss: 0.960721
[2022-03-31 20:44:32 | train] - Train Epoch: [114] [268800/1281167 (21%)]	Loss: 0.771147
[2022-03-31 20:44:52 | train] - Train Epoch: [114] [281600/1281167 (22%)]	Loss: 0.793295
[2022-03-31 20:45:12 | train] - Train Epoch: [114] [294400/1281167 (23%)]	Loss: 0.811419
[2022-03-31 20:45:32 | train] - Train Epoch: [114] [307200/1281167 (24%)]	Loss: 0.775428
[2022-03-31 20:45:51 | train] - Train Epoch: [114] [320000/1281167 (25%)]	Loss: 0.857398
[2022-03-31 20:46:10 | train] - Train Epoch: [114] [332800/1281167 (26%)]	Loss: 0.659028
[2022-03-31 20:46:30 | train] - Train Epoch: [114] [345600/1281167 (27%)]	Loss: 0.557384
[2022-03-31 20:46:49 | train] - Train Epoch: [114] [358400/1281167 (28%)]	Loss: 0.715784
[2022-03-31 20:47:09 | train] - Train Epoch: [114] [371200/1281167 (29%)]	Loss: 0.841754
[2022-03-31 20:47:28 | train] - Train Epoch: [114] [384000/1281167 (30%)]	Loss: 0.767386
[2022-03-31 20:47:48 | train] - Train Epoch: [114] [396800/1281167 (31%)]	Loss: 0.485887
[2022-03-31 20:48:08 | train] - Train Epoch: [114] [409600/1281167 (32%)]	Loss: 0.675579
[2022-03-31 20:48:29 | train] - Train Epoch: [114] [422400/1281167 (33%)]	Loss: 0.671378
[2022-03-31 20:48:48 | train] - Train Epoch: [114] [435200/1281167 (34%)]	Loss: 0.922499
[2022-03-31 20:49:08 | train] - Train Epoch: [114] [448000/1281167 (35%)]	Loss: 0.982607
[2022-03-31 20:49:27 | train] - Train Epoch: [114] [460800/1281167 (36%)]	Loss: 0.713634
[2022-03-31 20:49:47 | train] - Train Epoch: [114] [473600/1281167 (37%)]	Loss: 0.817410
[2022-03-31 20:50:07 | train] - Train Epoch: [114] [486400/1281167 (38%)]	Loss: 0.718577
[2022-03-31 20:50:26 | train] - Train Epoch: [114] [499200/1281167 (39%)]	Loss: 0.570018
[2022-03-31 20:50:46 | train] - Train Epoch: [114] [512000/1281167 (40%)]	Loss: 0.949849
[2022-03-31 20:51:06 | train] - Train Epoch: [114] [524800/1281167 (41%)]	Loss: 0.835852
[2022-03-31 20:51:25 | train] - Train Epoch: [114] [537600/1281167 (42%)]	Loss: 0.858719
[2022-03-31 20:51:45 | train] - Train Epoch: [114] [550400/1281167 (43%)]	Loss: 0.840192
[2022-03-31 20:52:04 | train] - Train Epoch: [114] [563200/1281167 (44%)]	Loss: 0.575450
[2022-03-31 20:52:24 | train] - Train Epoch: [114] [576000/1281167 (45%)]	Loss: 0.737985
[2022-03-31 20:52:43 | train] - Train Epoch: [114] [588800/1281167 (46%)]	Loss: 0.841017
[2022-03-31 20:53:03 | train] - Train Epoch: [114] [601600/1281167 (47%)]	Loss: 0.797459
[2022-03-31 20:53:22 | train] - Train Epoch: [114] [614400/1281167 (48%)]	Loss: 0.848207
[2022-03-31 20:53:42 | train] - Train Epoch: [114] [627200/1281167 (49%)]	Loss: 0.718660
[2022-03-31 20:54:01 | train] - Train Epoch: [114] [640000/1281167 (50%)]	Loss: 0.954295
[2022-03-31 20:54:21 | train] - Train Epoch: [114] [652800/1281167 (51%)]	Loss: 1.002305
[2022-03-31 20:54:40 | train] - Train Epoch: [114] [665600/1281167 (52%)]	Loss: 0.723345
[2022-03-31 20:54:59 | train] - Train Epoch: [114] [678400/1281167 (53%)]	Loss: 0.853052
[2022-03-31 20:55:19 | train] - Train Epoch: [114] [691200/1281167 (54%)]	Loss: 0.697060
[2022-03-31 20:55:38 | train] - Train Epoch: [114] [704000/1281167 (55%)]	Loss: 0.594582
[2022-03-31 20:55:58 | train] - Train Epoch: [114] [716800/1281167 (56%)]	Loss: 0.800675
[2022-03-31 20:56:17 | train] - Train Epoch: [114] [729600/1281167 (57%)]	Loss: 0.634636
[2022-03-31 20:56:37 | train] - Train Epoch: [114] [742400/1281167 (58%)]	Loss: 0.829379
[2022-03-31 20:56:57 | train] - Train Epoch: [114] [755200/1281167 (59%)]	Loss: 0.672943
[2022-03-31 20:57:17 | train] - Train Epoch: [114] [768000/1281167 (60%)]	Loss: 0.675936
[2022-03-31 20:57:36 | train] - Train Epoch: [114] [780800/1281167 (61%)]	Loss: 0.917554
[2022-03-31 20:57:55 | train] - Train Epoch: [114] [793600/1281167 (62%)]	Loss: 0.775780
[2022-03-31 20:58:15 | train] - Train Epoch: [114] [806400/1281167 (63%)]	Loss: 0.677788
[2022-03-31 20:58:35 | train] - Train Epoch: [114] [819200/1281167 (64%)]	Loss: 1.150023
[2022-03-31 20:58:55 | train] - Train Epoch: [114] [832000/1281167 (65%)]	Loss: 0.747990
[2022-03-31 20:59:14 | train] - Train Epoch: [114] [844800/1281167 (66%)]	Loss: 0.844485
[2022-03-31 20:59:34 | train] - Train Epoch: [114] [857600/1281167 (67%)]	Loss: 0.817061
[2022-03-31 20:59:53 | train] - Train Epoch: [114] [870400/1281167 (68%)]	Loss: 0.811965
[2022-03-31 21:00:13 | train] - Train Epoch: [114] [883200/1281167 (69%)]	Loss: 0.563372
[2022-03-31 21:00:33 | train] - Train Epoch: [114] [896000/1281167 (70%)]	Loss: 0.973360
[2022-03-31 21:00:52 | train] - Train Epoch: [114] [908800/1281167 (71%)]	Loss: 0.691919
[2022-03-31 21:01:12 | train] - Train Epoch: [114] [921600/1281167 (72%)]	Loss: 1.006097
[2022-03-31 21:01:31 | train] - Train Epoch: [114] [934400/1281167 (73%)]	Loss: 0.684077
[2022-03-31 21:01:51 | train] - Train Epoch: [114] [947200/1281167 (74%)]	Loss: 0.875240
[2022-03-31 21:02:10 | train] - Train Epoch: [114] [960000/1281167 (75%)]	Loss: 0.661376
[2022-03-31 21:02:30 | train] - Train Epoch: [114] [972800/1281167 (76%)]	Loss: 0.655094
[2022-03-31 21:02:50 | train] - Train Epoch: [114] [985600/1281167 (77%)]	Loss: 0.917119
[2022-03-31 21:03:09 | train] - Train Epoch: [114] [998400/1281167 (78%)]	Loss: 0.797289
[2022-03-31 21:03:29 | train] - Train Epoch: [114] [1011200/1281167 (79%)]	Loss: 0.814039
[2022-03-31 21:03:49 | train] - Train Epoch: [114] [1024000/1281167 (80%)]	Loss: 0.620603
[2022-03-31 21:04:09 | train] - Train Epoch: [114] [1036800/1281167 (81%)]	Loss: 0.775037
[2022-03-31 21:04:29 | train] - Train Epoch: [114] [1049600/1281167 (82%)]	Loss: 0.444835
[2022-03-31 21:04:48 | train] - Train Epoch: [114] [1062400/1281167 (83%)]	Loss: 0.826693
[2022-03-31 21:05:08 | train] - Train Epoch: [114] [1075200/1281167 (84%)]	Loss: 0.598862
[2022-03-31 21:05:28 | train] - Train Epoch: [114] [1088000/1281167 (85%)]	Loss: 1.027501
[2022-03-31 21:05:47 | train] - Train Epoch: [114] [1100800/1281167 (86%)]	Loss: 0.874905
[2022-03-31 21:06:07 | train] - Train Epoch: [114] [1113600/1281167 (87%)]	Loss: 0.998162
[2022-03-31 21:06:27 | train] - Train Epoch: [114] [1126400/1281167 (88%)]	Loss: 0.794414
[2022-03-31 21:06:46 | train] - Train Epoch: [114] [1139200/1281167 (89%)]	Loss: 1.027490
[2022-03-31 21:07:06 | train] - Train Epoch: [114] [1152000/1281167 (90%)]	Loss: 0.679572
[2022-03-31 21:07:26 | train] - Train Epoch: [114] [1164800/1281167 (91%)]	Loss: 0.934876
[2022-03-31 21:07:46 | train] - Train Epoch: [114] [1177600/1281167 (92%)]	Loss: 0.645298
[2022-03-31 21:08:07 | train] - Train Epoch: [114] [1190400/1281167 (93%)]	Loss: 0.680301
[2022-03-31 21:08:27 | train] - Train Epoch: [114] [1203200/1281167 (94%)]	Loss: 0.889184
[2022-03-31 21:08:46 | train] - Train Epoch: [114] [1216000/1281167 (95%)]	Loss: 0.792298
[2022-03-31 21:09:06 | train] - Train Epoch: [114] [1228800/1281167 (96%)]	Loss: 0.761484
[2022-03-31 21:09:25 | train] - Train Epoch: [114] [1241600/1281167 (97%)]	Loss: 0.958576
[2022-03-31 21:09:45 | train] - Train Epoch: [114] [1254400/1281167 (98%)]	Loss: 0.696402
[2022-03-31 21:10:05 | train] - Train Epoch: [114] [1267200/1281167 (99%)]	Loss: 0.811186
[2022-03-31 21:10:25 | train] - Train Epoch: [114] [1280000/1281167 (100%)]	Loss: 0.696483
[2022-03-31 21:10:26 | train] - Train Epoch: [114]	 Average Loss: 0.767976	 Total Acc : 81.2137	 Total Top5 Acc : 93.2195
[2022-03-31 21:10:26 | train] - -------114 epoch end-----------
========================================
-------114 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 21:12:03 | train] - 
Epoch [114] Test set: Average loss: 1.4331, Accuracy: 34793/50000 (69.5588%), Top-5 Accuracy: 88.7184%

[2022-03-31 21:12:03 | train] - save intermediate epoch [114] result


[2022-03-31 21:12:17 | train] - -------115 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 21:12:19 | train] - Train Epoch: [115] [0/1281167 (0%)]	Loss: 0.554666
[2022-03-31 21:12:39 | train] - Train Epoch: [115] [12800/1281167 (1%)]	Loss: 0.712540
[2022-03-31 21:13:00 | train] - Train Epoch: [115] [25600/1281167 (2%)]	Loss: 0.707763
[2022-03-31 21:13:21 | train] - Train Epoch: [115] [38400/1281167 (3%)]	Loss: 0.797987
[2022-03-31 21:13:41 | train] - Train Epoch: [115] [51200/1281167 (4%)]	Loss: 0.843931
[2022-03-31 21:14:03 | train] - Train Epoch: [115] [64000/1281167 (5%)]	Loss: 0.771465
[2022-03-31 21:14:25 | train] - Train Epoch: [115] [76800/1281167 (6%)]	Loss: 0.981832
[2022-03-31 21:14:45 | train] - Train Epoch: [115] [89600/1281167 (7%)]	Loss: 0.739077
[2022-03-31 21:15:06 | train] - Train Epoch: [115] [102400/1281167 (8%)]	Loss: 0.617621
[2022-03-31 21:15:27 | train] - Train Epoch: [115] [115200/1281167 (9%)]	Loss: 0.749349
[2022-03-31 21:15:49 | train] - Train Epoch: [115] [128000/1281167 (10%)]	Loss: 0.570959
[2022-03-31 21:16:11 | train] - Train Epoch: [115] [140800/1281167 (11%)]	Loss: 0.817574
[2022-03-31 21:16:32 | train] - Train Epoch: [115] [153600/1281167 (12%)]	Loss: 1.038649
[2022-03-31 21:16:54 | train] - Train Epoch: [115] [166400/1281167 (13%)]	Loss: 0.529825
[2022-03-31 21:17:15 | train] - Train Epoch: [115] [179200/1281167 (14%)]	Loss: 0.970219
[2022-03-31 21:17:37 | train] - Train Epoch: [115] [192000/1281167 (15%)]	Loss: 1.027560
[2022-03-31 21:17:59 | train] - Train Epoch: [115] [204800/1281167 (16%)]	Loss: 0.704437
[2022-03-31 21:18:20 | train] - Train Epoch: [115] [217600/1281167 (17%)]	Loss: 0.556721
[2022-03-31 21:18:42 | train] - Train Epoch: [115] [230400/1281167 (18%)]	Loss: 0.728880
[2022-03-31 21:19:04 | train] - Train Epoch: [115] [243200/1281167 (19%)]	Loss: 0.892633
[2022-03-31 21:19:24 | train] - Train Epoch: [115] [256000/1281167 (20%)]	Loss: 0.574916
[2022-03-31 21:19:46 | train] - Train Epoch: [115] [268800/1281167 (21%)]	Loss: 0.827536
[2022-03-31 21:20:08 | train] - Train Epoch: [115] [281600/1281167 (22%)]	Loss: 0.844744
[2022-03-31 21:20:29 | train] - Train Epoch: [115] [294400/1281167 (23%)]	Loss: 0.609859
[2022-03-31 21:20:51 | train] - Train Epoch: [115] [307200/1281167 (24%)]	Loss: 0.789798
[2022-03-31 21:21:13 | train] - Train Epoch: [115] [320000/1281167 (25%)]	Loss: 0.860120
[2022-03-31 21:21:34 | train] - Train Epoch: [115] [332800/1281167 (26%)]	Loss: 0.638843
[2022-03-31 21:21:55 | train] - Train Epoch: [115] [345600/1281167 (27%)]	Loss: 1.013012
[2022-03-31 21:22:17 | train] - Train Epoch: [115] [358400/1281167 (28%)]	Loss: 0.570761
[2022-03-31 21:22:38 | train] - Train Epoch: [115] [371200/1281167 (29%)]	Loss: 0.708533
[2022-03-31 21:23:00 | train] - Train Epoch: [115] [384000/1281167 (30%)]	Loss: 0.756209
[2022-03-31 21:23:21 | train] - Train Epoch: [115] [396800/1281167 (31%)]	Loss: 0.673127
[2022-03-31 21:23:43 | train] - Train Epoch: [115] [409600/1281167 (32%)]	Loss: 0.848811
[2022-03-31 21:24:05 | train] - Train Epoch: [115] [422400/1281167 (33%)]	Loss: 0.906960
[2022-03-31 21:24:27 | train] - Train Epoch: [115] [435200/1281167 (34%)]	Loss: 0.608294
[2022-03-31 21:24:49 | train] - Train Epoch: [115] [448000/1281167 (35%)]	Loss: 0.881048
[2022-03-31 21:25:10 | train] - Train Epoch: [115] [460800/1281167 (36%)]	Loss: 0.558138
[2022-03-31 21:25:32 | train] - Train Epoch: [115] [473600/1281167 (37%)]	Loss: 0.613482
[2022-03-31 21:25:54 | train] - Train Epoch: [115] [486400/1281167 (38%)]	Loss: 0.775481
[2022-03-31 21:26:15 | train] - Train Epoch: [115] [499200/1281167 (39%)]	Loss: 0.629785
[2022-03-31 21:26:36 | train] - Train Epoch: [115] [512000/1281167 (40%)]	Loss: 0.721677
[2022-03-31 21:26:58 | train] - Train Epoch: [115] [524800/1281167 (41%)]	Loss: 0.711349
[2022-03-31 21:27:19 | train] - Train Epoch: [115] [537600/1281167 (42%)]	Loss: 0.677156
[2022-03-31 21:27:40 | train] - Train Epoch: [115] [550400/1281167 (43%)]	Loss: 0.714920
[2022-03-31 21:28:00 | train] - Train Epoch: [115] [563200/1281167 (44%)]	Loss: 0.616615
[2022-03-31 21:28:22 | train] - Train Epoch: [115] [576000/1281167 (45%)]	Loss: 0.823641
[2022-03-31 21:28:43 | train] - Train Epoch: [115] [588800/1281167 (46%)]	Loss: 0.690696
[2022-03-31 21:29:04 | train] - Train Epoch: [115] [601600/1281167 (47%)]	Loss: 1.107239
[2022-03-31 21:29:26 | train] - Train Epoch: [115] [614400/1281167 (48%)]	Loss: 0.609872
[2022-03-31 21:29:47 | train] - Train Epoch: [115] [627200/1281167 (49%)]	Loss: 0.654993
[2022-03-31 21:30:08 | train] - Train Epoch: [115] [640000/1281167 (50%)]	Loss: 1.107471
[2022-03-31 21:30:29 | train] - Train Epoch: [115] [652800/1281167 (51%)]	Loss: 0.863417
[2022-03-31 21:30:49 | train] - Train Epoch: [115] [665600/1281167 (52%)]	Loss: 0.775405
[2022-03-31 21:31:12 | train] - Train Epoch: [115] [678400/1281167 (53%)]	Loss: 1.120222
[2022-03-31 21:31:33 | train] - Train Epoch: [115] [691200/1281167 (54%)]	Loss: 0.621359
[2022-03-31 21:31:55 | train] - Train Epoch: [115] [704000/1281167 (55%)]	Loss: 0.460643
[2022-03-31 21:32:16 | train] - Train Epoch: [115] [716800/1281167 (56%)]	Loss: 0.889027
[2022-03-31 21:32:36 | train] - Train Epoch: [115] [729600/1281167 (57%)]	Loss: 0.872180
[2022-03-31 21:32:57 | train] - Train Epoch: [115] [742400/1281167 (58%)]	Loss: 0.646311
[2022-03-31 21:33:19 | train] - Train Epoch: [115] [755200/1281167 (59%)]	Loss: 0.821370
[2022-03-31 21:33:39 | train] - Train Epoch: [115] [768000/1281167 (60%)]	Loss: 0.866083
[2022-03-31 21:34:00 | train] - Train Epoch: [115] [780800/1281167 (61%)]	Loss: 0.805448
[2022-03-31 21:34:22 | train] - Train Epoch: [115] [793600/1281167 (62%)]	Loss: 0.733283
[2022-03-31 21:34:43 | train] - Train Epoch: [115] [806400/1281167 (63%)]	Loss: 0.939625
[2022-03-31 21:35:05 | train] - Train Epoch: [115] [819200/1281167 (64%)]	Loss: 0.878554
[2022-03-31 21:35:27 | train] - Train Epoch: [115] [832000/1281167 (65%)]	Loss: 0.699936
[2022-03-31 21:35:49 | train] - Train Epoch: [115] [844800/1281167 (66%)]	Loss: 0.600098
[2022-03-31 21:36:09 | train] - Train Epoch: [115] [857600/1281167 (67%)]	Loss: 0.667573
[2022-03-31 21:36:31 | train] - Train Epoch: [115] [870400/1281167 (68%)]	Loss: 0.503002
[2022-03-31 21:36:51 | train] - Train Epoch: [115] [883200/1281167 (69%)]	Loss: 0.572505
[2022-03-31 21:37:13 | train] - Train Epoch: [115] [896000/1281167 (70%)]	Loss: 0.690948
[2022-03-31 21:37:33 | train] - Train Epoch: [115] [908800/1281167 (71%)]	Loss: 0.968717
[2022-03-31 21:37:55 | train] - Train Epoch: [115] [921600/1281167 (72%)]	Loss: 0.651592
[2022-03-31 21:38:14 | train] - Train Epoch: [115] [934400/1281167 (73%)]	Loss: 0.706491
[2022-03-31 21:38:36 | train] - Train Epoch: [115] [947200/1281167 (74%)]	Loss: 0.569702
[2022-03-31 21:38:57 | train] - Train Epoch: [115] [960000/1281167 (75%)]	Loss: 0.788963
[2022-03-31 21:39:19 | train] - Train Epoch: [115] [972800/1281167 (76%)]	Loss: 0.803473
[2022-03-31 21:39:40 | train] - Train Epoch: [115] [985600/1281167 (77%)]	Loss: 0.806859
[2022-03-31 21:40:01 | train] - Train Epoch: [115] [998400/1281167 (78%)]	Loss: 0.595480
[2022-03-31 21:40:23 | train] - Train Epoch: [115] [1011200/1281167 (79%)]	Loss: 0.901447
[2022-03-31 21:40:45 | train] - Train Epoch: [115] [1024000/1281167 (80%)]	Loss: 0.571865
[2022-03-31 21:41:06 | train] - Train Epoch: [115] [1036800/1281167 (81%)]	Loss: 0.724031
[2022-03-31 21:41:26 | train] - Train Epoch: [115] [1049600/1281167 (82%)]	Loss: 0.711743
[2022-03-31 21:41:48 | train] - Train Epoch: [115] [1062400/1281167 (83%)]	Loss: 0.997095
[2022-03-31 21:42:09 | train] - Train Epoch: [115] [1075200/1281167 (84%)]	Loss: 0.767467
[2022-03-31 21:42:31 | train] - Train Epoch: [115] [1088000/1281167 (85%)]	Loss: 0.816693
[2022-03-31 21:42:53 | train] - Train Epoch: [115] [1100800/1281167 (86%)]	Loss: 1.009425
[2022-03-31 21:43:15 | train] - Train Epoch: [115] [1113600/1281167 (87%)]	Loss: 0.682329
[2022-03-31 21:43:37 | train] - Train Epoch: [115] [1126400/1281167 (88%)]	Loss: 0.857652
[2022-03-31 21:43:59 | train] - Train Epoch: [115] [1139200/1281167 (89%)]	Loss: 0.790924
[2022-03-31 21:44:20 | train] - Train Epoch: [115] [1152000/1281167 (90%)]	Loss: 0.884159
[2022-03-31 21:44:41 | train] - Train Epoch: [115] [1164800/1281167 (91%)]	Loss: 0.913589
[2022-03-31 21:45:02 | train] - Train Epoch: [115] [1177600/1281167 (92%)]	Loss: 0.724489
[2022-03-31 21:45:23 | train] - Train Epoch: [115] [1190400/1281167 (93%)]	Loss: 0.930899
[2022-03-31 21:45:45 | train] - Train Epoch: [115] [1203200/1281167 (94%)]	Loss: 0.719423
[2022-03-31 21:46:06 | train] - Train Epoch: [115] [1216000/1281167 (95%)]	Loss: 0.729618
[2022-03-31 21:46:28 | train] - Train Epoch: [115] [1228800/1281167 (96%)]	Loss: 0.621737
[2022-03-31 21:46:50 | train] - Train Epoch: [115] [1241600/1281167 (97%)]	Loss: 0.755300
[2022-03-31 21:47:11 | train] - Train Epoch: [115] [1254400/1281167 (98%)]	Loss: 0.719397
[2022-03-31 21:47:31 | train] - Train Epoch: [115] [1267200/1281167 (99%)]	Loss: 0.723038
[2022-03-31 21:47:52 | train] - Train Epoch: [115] [1280000/1281167 (100%)]	Loss: 0.667516
[2022-03-31 21:47:54 | train] - Train Epoch: [115]	 Average Loss: 0.763453	 Total Acc : 81.3320	 Total Top5 Acc : 93.2430
[2022-03-31 21:47:54 | train] - -------115 epoch end-----------
========================================
-------115 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 21:49:27 | train] - 
Epoch [115] Test set: Average loss: 1.4383, Accuracy: 34704/50000 (69.3822%), Top-5 Accuracy: 88.6681%

[2022-03-31 21:49:27 | train] - save intermediate epoch [115] result


[2022-03-31 21:49:41 | train] - -------116 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 21:49:44 | train] - Train Epoch: [116] [0/1281167 (0%)]	Loss: 0.664664
[2022-03-31 21:50:05 | train] - Train Epoch: [116] [12800/1281167 (1%)]	Loss: 0.631035
[2022-03-31 21:50:26 | train] - Train Epoch: [116] [25600/1281167 (2%)]	Loss: 0.793000
[2022-03-31 21:50:47 | train] - Train Epoch: [116] [38400/1281167 (3%)]	Loss: 0.830866
[2022-03-31 21:51:07 | train] - Train Epoch: [116] [51200/1281167 (4%)]	Loss: 0.606748
[2022-03-31 21:51:29 | train] - Train Epoch: [116] [64000/1281167 (5%)]	Loss: 0.745039
[2022-03-31 21:51:50 | train] - Train Epoch: [116] [76800/1281167 (6%)]	Loss: 0.833241
[2022-03-31 21:52:11 | train] - Train Epoch: [116] [89600/1281167 (7%)]	Loss: 1.003379
[2022-03-31 21:52:32 | train] - Train Epoch: [116] [102400/1281167 (8%)]	Loss: 1.127184
[2022-03-31 21:52:52 | train] - Train Epoch: [116] [115200/1281167 (9%)]	Loss: 0.844266
[2022-03-31 21:53:13 | train] - Train Epoch: [116] [128000/1281167 (10%)]	Loss: 0.774964
[2022-03-31 21:53:34 | train] - Train Epoch: [116] [140800/1281167 (11%)]	Loss: 0.704778
[2022-03-31 21:53:55 | train] - Train Epoch: [116] [153600/1281167 (12%)]	Loss: 0.528808
[2022-03-31 21:54:16 | train] - Train Epoch: [116] [166400/1281167 (13%)]	Loss: 0.663390
[2022-03-31 21:54:37 | train] - Train Epoch: [116] [179200/1281167 (14%)]	Loss: 0.800430
[2022-03-31 21:54:58 | train] - Train Epoch: [116] [192000/1281167 (15%)]	Loss: 0.623014
[2022-03-31 21:55:18 | train] - Train Epoch: [116] [204800/1281167 (16%)]	Loss: 0.586127
[2022-03-31 21:55:39 | train] - Train Epoch: [116] [217600/1281167 (17%)]	Loss: 0.829462
[2022-03-31 21:56:00 | train] - Train Epoch: [116] [230400/1281167 (18%)]	Loss: 0.576149
[2022-03-31 21:56:21 | train] - Train Epoch: [116] [243200/1281167 (19%)]	Loss: 0.747675
[2022-03-31 21:56:42 | train] - Train Epoch: [116] [256000/1281167 (20%)]	Loss: 0.879788
[2022-03-31 21:57:03 | train] - Train Epoch: [116] [268800/1281167 (21%)]	Loss: 0.603897
[2022-03-31 21:57:24 | train] - Train Epoch: [116] [281600/1281167 (22%)]	Loss: 0.827309
[2022-03-31 21:57:45 | train] - Train Epoch: [116] [294400/1281167 (23%)]	Loss: 0.598752
[2022-03-31 21:58:06 | train] - Train Epoch: [116] [307200/1281167 (24%)]	Loss: 0.776405
[2022-03-31 21:58:26 | train] - Train Epoch: [116] [320000/1281167 (25%)]	Loss: 0.743483
[2022-03-31 21:58:47 | train] - Train Epoch: [116] [332800/1281167 (26%)]	Loss: 0.773332
[2022-03-31 21:59:07 | train] - Train Epoch: [116] [345600/1281167 (27%)]	Loss: 1.306804
[2022-03-31 21:59:27 | train] - Train Epoch: [116] [358400/1281167 (28%)]	Loss: 0.817993
[2022-03-31 21:59:47 | train] - Train Epoch: [116] [371200/1281167 (29%)]	Loss: 0.720566
[2022-03-31 22:00:08 | train] - Train Epoch: [116] [384000/1281167 (30%)]	Loss: 0.815693
[2022-03-31 22:00:30 | train] - Train Epoch: [116] [396800/1281167 (31%)]	Loss: 0.969590
[2022-03-31 22:00:50 | train] - Train Epoch: [116] [409600/1281167 (32%)]	Loss: 0.648219
[2022-03-31 22:01:12 | train] - Train Epoch: [116] [422400/1281167 (33%)]	Loss: 0.833411
[2022-03-31 22:01:34 | train] - Train Epoch: [116] [435200/1281167 (34%)]	Loss: 1.027830
[2022-03-31 22:01:56 | train] - Train Epoch: [116] [448000/1281167 (35%)]	Loss: 1.073794
[2022-03-31 22:02:17 | train] - Train Epoch: [116] [460800/1281167 (36%)]	Loss: 0.548079
[2022-03-31 22:02:38 | train] - Train Epoch: [116] [473600/1281167 (37%)]	Loss: 0.786354
[2022-03-31 22:02:59 | train] - Train Epoch: [116] [486400/1281167 (38%)]	Loss: 0.925620
[2022-03-31 22:03:20 | train] - Train Epoch: [116] [499200/1281167 (39%)]	Loss: 0.913831
[2022-03-31 22:03:40 | train] - Train Epoch: [116] [512000/1281167 (40%)]	Loss: 0.984006
[2022-03-31 22:04:01 | train] - Train Epoch: [116] [524800/1281167 (41%)]	Loss: 1.017416
[2022-03-31 22:04:22 | train] - Train Epoch: [116] [537600/1281167 (42%)]	Loss: 0.915656
[2022-03-31 22:04:43 | train] - Train Epoch: [116] [550400/1281167 (43%)]	Loss: 0.891344
[2022-03-31 22:05:04 | train] - Train Epoch: [116] [563200/1281167 (44%)]	Loss: 0.664191
[2022-03-31 22:05:25 | train] - Train Epoch: [116] [576000/1281167 (45%)]	Loss: 0.770833
[2022-03-31 22:05:46 | train] - Train Epoch: [116] [588800/1281167 (46%)]	Loss: 0.870746
[2022-03-31 22:06:07 | train] - Train Epoch: [116] [601600/1281167 (47%)]	Loss: 0.720564
[2022-03-31 22:06:27 | train] - Train Epoch: [116] [614400/1281167 (48%)]	Loss: 0.974773
[2022-03-31 22:06:48 | train] - Train Epoch: [116] [627200/1281167 (49%)]	Loss: 0.655060
[2022-03-31 22:07:09 | train] - Train Epoch: [116] [640000/1281167 (50%)]	Loss: 0.793185
[2022-03-31 22:07:32 | train] - Train Epoch: [116] [652800/1281167 (51%)]	Loss: 0.709345
[2022-03-31 22:07:53 | train] - Train Epoch: [116] [665600/1281167 (52%)]	Loss: 0.658301
[2022-03-31 22:08:15 | train] - Train Epoch: [116] [678400/1281167 (53%)]	Loss: 0.515348
[2022-03-31 22:08:35 | train] - Train Epoch: [116] [691200/1281167 (54%)]	Loss: 0.684586
[2022-03-31 22:08:57 | train] - Train Epoch: [116] [704000/1281167 (55%)]	Loss: 0.491547
[2022-03-31 22:09:17 | train] - Train Epoch: [116] [716800/1281167 (56%)]	Loss: 0.733603
[2022-03-31 22:09:39 | train] - Train Epoch: [116] [729600/1281167 (57%)]	Loss: 0.617927
[2022-03-31 22:10:00 | train] - Train Epoch: [116] [742400/1281167 (58%)]	Loss: 0.848843
[2022-03-31 22:10:20 | train] - Train Epoch: [116] [755200/1281167 (59%)]	Loss: 0.597482
[2022-03-31 22:10:42 | train] - Train Epoch: [116] [768000/1281167 (60%)]	Loss: 0.642811
[2022-03-31 22:11:04 | train] - Train Epoch: [116] [780800/1281167 (61%)]	Loss: 0.874418
[2022-03-31 22:11:25 | train] - Train Epoch: [116] [793600/1281167 (62%)]	Loss: 0.752456
[2022-03-31 22:11:45 | train] - Train Epoch: [116] [806400/1281167 (63%)]	Loss: 0.784654
[2022-03-31 22:12:07 | train] - Train Epoch: [116] [819200/1281167 (64%)]	Loss: 0.761160
[2022-03-31 22:12:28 | train] - Train Epoch: [116] [832000/1281167 (65%)]	Loss: 0.921214
[2022-03-31 22:12:48 | train] - Train Epoch: [116] [844800/1281167 (66%)]	Loss: 0.981788
[2022-03-31 22:13:10 | train] - Train Epoch: [116] [857600/1281167 (67%)]	Loss: 0.990090
[2022-03-31 22:13:32 | train] - Train Epoch: [116] [870400/1281167 (68%)]	Loss: 0.777062
[2022-03-31 22:13:53 | train] - Train Epoch: [116] [883200/1281167 (69%)]	Loss: 0.592212
[2022-03-31 22:14:14 | train] - Train Epoch: [116] [896000/1281167 (70%)]	Loss: 0.800298
[2022-03-31 22:14:34 | train] - Train Epoch: [116] [908800/1281167 (71%)]	Loss: 0.968697
[2022-03-31 22:14:56 | train] - Train Epoch: [116] [921600/1281167 (72%)]	Loss: 0.675183
[2022-03-31 22:15:17 | train] - Train Epoch: [116] [934400/1281167 (73%)]	Loss: 0.557215
[2022-03-31 22:15:38 | train] - Train Epoch: [116] [947200/1281167 (74%)]	Loss: 0.668155
[2022-03-31 22:15:59 | train] - Train Epoch: [116] [960000/1281167 (75%)]	Loss: 0.806842
[2022-03-31 22:16:20 | train] - Train Epoch: [116] [972800/1281167 (76%)]	Loss: 0.863543
[2022-03-31 22:16:41 | train] - Train Epoch: [116] [985600/1281167 (77%)]	Loss: 1.045094
[2022-03-31 22:17:02 | train] - Train Epoch: [116] [998400/1281167 (78%)]	Loss: 0.945431
[2022-03-31 22:17:23 | train] - Train Epoch: [116] [1011200/1281167 (79%)]	Loss: 0.869945
[2022-03-31 22:17:45 | train] - Train Epoch: [116] [1024000/1281167 (80%)]	Loss: 0.657273
[2022-03-31 22:18:06 | train] - Train Epoch: [116] [1036800/1281167 (81%)]	Loss: 0.742812
[2022-03-31 22:18:28 | train] - Train Epoch: [116] [1049600/1281167 (82%)]	Loss: 0.592227
[2022-03-31 22:18:49 | train] - Train Epoch: [116] [1062400/1281167 (83%)]	Loss: 0.848274
[2022-03-31 22:19:09 | train] - Train Epoch: [116] [1075200/1281167 (84%)]	Loss: 0.705210
[2022-03-31 22:19:30 | train] - Train Epoch: [116] [1088000/1281167 (85%)]	Loss: 0.548635
[2022-03-31 22:19:52 | train] - Train Epoch: [116] [1100800/1281167 (86%)]	Loss: 0.827509
[2022-03-31 22:20:13 | train] - Train Epoch: [116] [1113600/1281167 (87%)]	Loss: 0.831050
[2022-03-31 22:20:34 | train] - Train Epoch: [116] [1126400/1281167 (88%)]	Loss: 0.859646
[2022-03-31 22:20:56 | train] - Train Epoch: [116] [1139200/1281167 (89%)]	Loss: 0.815356
[2022-03-31 22:21:17 | train] - Train Epoch: [116] [1152000/1281167 (90%)]	Loss: 0.907088
[2022-03-31 22:21:39 | train] - Train Epoch: [116] [1164800/1281167 (91%)]	Loss: 0.686032
[2022-03-31 22:21:59 | train] - Train Epoch: [116] [1177600/1281167 (92%)]	Loss: 0.861953
[2022-03-31 22:22:21 | train] - Train Epoch: [116] [1190400/1281167 (93%)]	Loss: 0.779184
[2022-03-31 22:22:44 | train] - Train Epoch: [116] [1203200/1281167 (94%)]	Loss: 0.966796
[2022-03-31 22:23:05 | train] - Train Epoch: [116] [1216000/1281167 (95%)]	Loss: 0.548861
[2022-03-31 22:23:26 | train] - Train Epoch: [116] [1228800/1281167 (96%)]	Loss: 0.860803
[2022-03-31 22:23:47 | train] - Train Epoch: [116] [1241600/1281167 (97%)]	Loss: 0.877130
[2022-03-31 22:24:09 | train] - Train Epoch: [116] [1254400/1281167 (98%)]	Loss: 0.684508
[2022-03-31 22:24:29 | train] - Train Epoch: [116] [1267200/1281167 (99%)]	Loss: 0.586709
[2022-03-31 22:24:50 | train] - Train Epoch: [116] [1280000/1281167 (100%)]	Loss: 0.738411
[2022-03-31 22:24:52 | train] - Train Epoch: [116]	 Average Loss: 0.760607	 Total Acc : 81.4031	 Total Top5 Acc : 93.2726
[2022-03-31 22:24:52 | train] - -------116 epoch end-----------
========================================
-------116 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 22:26:25 | train] - 
Epoch [116] Test set: Average loss: 1.4405, Accuracy: 34701/50000 (69.3738%), Top-5 Accuracy: 88.5750%

[2022-03-31 22:26:25 | train] - save intermediate epoch [116] result


[2022-03-31 22:26:39 | train] - -------117 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 22:26:41 | train] - Train Epoch: [117] [0/1281167 (0%)]	Loss: 0.584467
[2022-03-31 22:27:03 | train] - Train Epoch: [117] [12800/1281167 (1%)]	Loss: 0.681710
[2022-03-31 22:27:24 | train] - Train Epoch: [117] [25600/1281167 (2%)]	Loss: 0.784706
[2022-03-31 22:27:46 | train] - Train Epoch: [117] [38400/1281167 (3%)]	Loss: 0.692246
[2022-03-31 22:28:06 | train] - Train Epoch: [117] [51200/1281167 (4%)]	Loss: 0.548260
[2022-03-31 22:28:27 | train] - Train Epoch: [117] [64000/1281167 (5%)]	Loss: 1.004584
[2022-03-31 22:28:49 | train] - Train Epoch: [117] [76800/1281167 (6%)]	Loss: 0.758569
[2022-03-31 22:29:10 | train] - Train Epoch: [117] [89600/1281167 (7%)]	Loss: 0.565668
[2022-03-31 22:29:32 | train] - Train Epoch: [117] [102400/1281167 (8%)]	Loss: 0.681334
[2022-03-31 22:29:53 | train] - Train Epoch: [117] [115200/1281167 (9%)]	Loss: 0.745030
[2022-03-31 22:30:15 | train] - Train Epoch: [117] [128000/1281167 (10%)]	Loss: 0.784231
[2022-03-31 22:30:37 | train] - Train Epoch: [117] [140800/1281167 (11%)]	Loss: 0.610539
[2022-03-31 22:30:57 | train] - Train Epoch: [117] [153600/1281167 (12%)]	Loss: 1.123207
[2022-03-31 22:31:18 | train] - Train Epoch: [117] [166400/1281167 (13%)]	Loss: 0.674706
[2022-03-31 22:31:39 | train] - Train Epoch: [117] [179200/1281167 (14%)]	Loss: 0.750195
[2022-03-31 22:32:00 | train] - Train Epoch: [117] [192000/1281167 (15%)]	Loss: 0.687597
[2022-03-31 22:32:21 | train] - Train Epoch: [117] [204800/1281167 (16%)]	Loss: 0.943801
[2022-03-31 22:32:43 | train] - Train Epoch: [117] [217600/1281167 (17%)]	Loss: 0.654939
[2022-03-31 22:33:05 | train] - Train Epoch: [117] [230400/1281167 (18%)]	Loss: 0.731893
[2022-03-31 22:33:27 | train] - Train Epoch: [117] [243200/1281167 (19%)]	Loss: 0.684414
[2022-03-31 22:33:48 | train] - Train Epoch: [117] [256000/1281167 (20%)]	Loss: 0.485087
[2022-03-31 22:34:09 | train] - Train Epoch: [117] [268800/1281167 (21%)]	Loss: 1.024198
[2022-03-31 22:34:31 | train] - Train Epoch: [117] [281600/1281167 (22%)]	Loss: 0.612035
[2022-03-31 22:34:53 | train] - Train Epoch: [117] [294400/1281167 (23%)]	Loss: 0.896469
[2022-03-31 22:35:14 | train] - Train Epoch: [117] [307200/1281167 (24%)]	Loss: 0.693702
[2022-03-31 22:35:35 | train] - Train Epoch: [117] [320000/1281167 (25%)]	Loss: 0.976215
[2022-03-31 22:35:55 | train] - Train Epoch: [117] [332800/1281167 (26%)]	Loss: 0.827523
[2022-03-31 22:36:17 | train] - Train Epoch: [117] [345600/1281167 (27%)]	Loss: 0.954805
[2022-03-31 22:36:39 | train] - Train Epoch: [117] [358400/1281167 (28%)]	Loss: 0.910257
[2022-03-31 22:37:00 | train] - Train Epoch: [117] [371200/1281167 (29%)]	Loss: 0.732012
[2022-03-31 22:37:21 | train] - Train Epoch: [117] [384000/1281167 (30%)]	Loss: 0.938864
[2022-03-31 22:37:43 | train] - Train Epoch: [117] [396800/1281167 (31%)]	Loss: 0.636813
[2022-03-31 22:38:03 | train] - Train Epoch: [117] [409600/1281167 (32%)]	Loss: 0.940526
[2022-03-31 22:38:25 | train] - Train Epoch: [117] [422400/1281167 (33%)]	Loss: 0.869914
[2022-03-31 22:38:45 | train] - Train Epoch: [117] [435200/1281167 (34%)]	Loss: 0.815925
[2022-03-31 22:39:06 | train] - Train Epoch: [117] [448000/1281167 (35%)]	Loss: 0.859886
[2022-03-31 22:39:27 | train] - Train Epoch: [117] [460800/1281167 (36%)]	Loss: 0.643982
[2022-03-31 22:39:48 | train] - Train Epoch: [117] [473600/1281167 (37%)]	Loss: 0.710543
[2022-03-31 22:40:09 | train] - Train Epoch: [117] [486400/1281167 (38%)]	Loss: 0.766954
[2022-03-31 22:40:30 | train] - Train Epoch: [117] [499200/1281167 (39%)]	Loss: 0.573802
[2022-03-31 22:40:51 | train] - Train Epoch: [117] [512000/1281167 (40%)]	Loss: 0.602985
[2022-03-31 22:41:13 | train] - Train Epoch: [117] [524800/1281167 (41%)]	Loss: 0.768575
[2022-03-31 22:41:34 | train] - Train Epoch: [117] [537600/1281167 (42%)]	Loss: 0.748039
[2022-03-31 22:41:56 | train] - Train Epoch: [117] [550400/1281167 (43%)]	Loss: 0.714395
[2022-03-31 22:42:19 | train] - Train Epoch: [117] [563200/1281167 (44%)]	Loss: 0.739172
[2022-03-31 22:42:40 | train] - Train Epoch: [117] [576000/1281167 (45%)]	Loss: 0.709916
[2022-03-31 22:43:00 | train] - Train Epoch: [117] [588800/1281167 (46%)]	Loss: 0.797825
[2022-03-31 22:43:22 | train] - Train Epoch: [117] [601600/1281167 (47%)]	Loss: 0.928023
[2022-03-31 22:43:42 | train] - Train Epoch: [117] [614400/1281167 (48%)]	Loss: 0.539896
[2022-03-31 22:44:04 | train] - Train Epoch: [117] [627200/1281167 (49%)]	Loss: 0.724751
[2022-03-31 22:44:26 | train] - Train Epoch: [117] [640000/1281167 (50%)]	Loss: 0.727951
[2022-03-31 22:44:47 | train] - Train Epoch: [117] [652800/1281167 (51%)]	Loss: 0.864716
[2022-03-31 22:45:09 | train] - Train Epoch: [117] [665600/1281167 (52%)]	Loss: 0.625702
[2022-03-31 22:45:31 | train] - Train Epoch: [117] [678400/1281167 (53%)]	Loss: 0.750043
[2022-03-31 22:45:52 | train] - Train Epoch: [117] [691200/1281167 (54%)]	Loss: 1.069355
[2022-03-31 22:46:13 | train] - Train Epoch: [117] [704000/1281167 (55%)]	Loss: 0.718731
[2022-03-31 22:46:34 | train] - Train Epoch: [117] [716800/1281167 (56%)]	Loss: 0.410905
[2022-03-31 22:46:55 | train] - Train Epoch: [117] [729600/1281167 (57%)]	Loss: 0.634415
[2022-03-31 22:47:16 | train] - Train Epoch: [117] [742400/1281167 (58%)]	Loss: 0.641753
[2022-03-31 22:47:38 | train] - Train Epoch: [117] [755200/1281167 (59%)]	Loss: 0.841632
[2022-03-31 22:48:00 | train] - Train Epoch: [117] [768000/1281167 (60%)]	Loss: 0.577675
[2022-03-31 22:48:22 | train] - Train Epoch: [117] [780800/1281167 (61%)]	Loss: 0.676701
[2022-03-31 22:48:43 | train] - Train Epoch: [117] [793600/1281167 (62%)]	Loss: 1.084560
[2022-03-31 22:49:03 | train] - Train Epoch: [117] [806400/1281167 (63%)]	Loss: 0.639717
[2022-03-31 22:49:25 | train] - Train Epoch: [117] [819200/1281167 (64%)]	Loss: 0.751569
[2022-03-31 22:49:46 | train] - Train Epoch: [117] [832000/1281167 (65%)]	Loss: 0.800739
[2022-03-31 22:50:06 | train] - Train Epoch: [117] [844800/1281167 (66%)]	Loss: 1.011340
[2022-03-31 22:50:28 | train] - Train Epoch: [117] [857600/1281167 (67%)]	Loss: 0.709814
[2022-03-31 22:50:48 | train] - Train Epoch: [117] [870400/1281167 (68%)]	Loss: 0.638326
[2022-03-31 22:51:10 | train] - Train Epoch: [117] [883200/1281167 (69%)]	Loss: 0.804489
[2022-03-31 22:51:31 | train] - Train Epoch: [117] [896000/1281167 (70%)]	Loss: 0.567720
[2022-03-31 22:51:53 | train] - Train Epoch: [117] [908800/1281167 (71%)]	Loss: 0.824440
[2022-03-31 22:52:15 | train] - Train Epoch: [117] [921600/1281167 (72%)]	Loss: 0.826821
[2022-03-31 22:52:36 | train] - Train Epoch: [117] [934400/1281167 (73%)]	Loss: 0.656479
[2022-03-31 22:52:58 | train] - Train Epoch: [117] [947200/1281167 (74%)]	Loss: 0.731800
[2022-03-31 22:53:19 | train] - Train Epoch: [117] [960000/1281167 (75%)]	Loss: 0.865268
[2022-03-31 22:53:41 | train] - Train Epoch: [117] [972800/1281167 (76%)]	Loss: 0.541422
[2022-03-31 22:54:03 | train] - Train Epoch: [117] [985600/1281167 (77%)]	Loss: 0.565845
[2022-03-31 22:54:24 | train] - Train Epoch: [117] [998400/1281167 (78%)]	Loss: 0.897910
[2022-03-31 22:54:46 | train] - Train Epoch: [117] [1011200/1281167 (79%)]	Loss: 0.734396
[2022-03-31 22:55:07 | train] - Train Epoch: [117] [1024000/1281167 (80%)]	Loss: 0.684618
[2022-03-31 22:55:28 | train] - Train Epoch: [117] [1036800/1281167 (81%)]	Loss: 0.768230
[2022-03-31 22:55:49 | train] - Train Epoch: [117] [1049600/1281167 (82%)]	Loss: 0.830323
[2022-03-31 22:56:10 | train] - Train Epoch: [117] [1062400/1281167 (83%)]	Loss: 0.868699
[2022-03-31 22:56:31 | train] - Train Epoch: [117] [1075200/1281167 (84%)]	Loss: 0.585771
[2022-03-31 22:56:53 | train] - Train Epoch: [117] [1088000/1281167 (85%)]	Loss: 0.648941
[2022-03-31 22:57:13 | train] - Train Epoch: [117] [1100800/1281167 (86%)]	Loss: 0.796993
[2022-03-31 22:57:35 | train] - Train Epoch: [117] [1113600/1281167 (87%)]	Loss: 0.698986
[2022-03-31 22:57:56 | train] - Train Epoch: [117] [1126400/1281167 (88%)]	Loss: 0.969522
[2022-03-31 22:58:17 | train] - Train Epoch: [117] [1139200/1281167 (89%)]	Loss: 0.750372
[2022-03-31 22:58:39 | train] - Train Epoch: [117] [1152000/1281167 (90%)]	Loss: 0.914318
[2022-03-31 22:59:00 | train] - Train Epoch: [117] [1164800/1281167 (91%)]	Loss: 0.566918
[2022-03-31 22:59:21 | train] - Train Epoch: [117] [1177600/1281167 (92%)]	Loss: 0.681081
[2022-03-31 22:59:42 | train] - Train Epoch: [117] [1190400/1281167 (93%)]	Loss: 0.498162
[2022-03-31 23:00:04 | train] - Train Epoch: [117] [1203200/1281167 (94%)]	Loss: 0.669366
[2022-03-31 23:00:25 | train] - Train Epoch: [117] [1216000/1281167 (95%)]	Loss: 0.641155
[2022-03-31 23:00:47 | train] - Train Epoch: [117] [1228800/1281167 (96%)]	Loss: 0.833420
[2022-03-31 23:01:09 | train] - Train Epoch: [117] [1241600/1281167 (97%)]	Loss: 0.866358
[2022-03-31 23:01:30 | train] - Train Epoch: [117] [1254400/1281167 (98%)]	Loss: 0.562872
[2022-03-31 23:01:50 | train] - Train Epoch: [117] [1267200/1281167 (99%)]	Loss: 0.768413
[2022-03-31 23:02:11 | train] - Train Epoch: [117] [1280000/1281167 (100%)]	Loss: 0.688696
[2022-03-31 23:02:13 | train] - Train Epoch: [117]	 Average Loss: 0.755796	 Total Acc : 81.5143	 Total Top5 Acc : 93.3261
[2022-03-31 23:02:13 | train] - -------117 epoch end-----------
========================================
-------117 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 23:03:44 | train] - 
Epoch [117] Test set: Average loss: 1.4497, Accuracy: 34666/50000 (69.3099%), Top-5 Accuracy: 88.6001%

[2022-03-31 23:03:44 | train] - save intermediate epoch [117] result


[2022-03-31 23:04:00 | train] - -------118 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 23:04:02 | train] - Train Epoch: [118] [0/1281167 (0%)]	Loss: 1.048001
[2022-03-31 23:04:23 | train] - Train Epoch: [118] [12800/1281167 (1%)]	Loss: 0.561735
[2022-03-31 23:04:44 | train] - Train Epoch: [118] [25600/1281167 (2%)]	Loss: 0.764469
[2022-03-31 23:05:07 | train] - Train Epoch: [118] [38400/1281167 (3%)]	Loss: 0.840669
[2022-03-31 23:05:28 | train] - Train Epoch: [118] [51200/1281167 (4%)]	Loss: 0.765371
[2022-03-31 23:05:50 | train] - Train Epoch: [118] [64000/1281167 (5%)]	Loss: 0.814316
[2022-03-31 23:06:11 | train] - Train Epoch: [118] [76800/1281167 (6%)]	Loss: 0.880590
[2022-03-31 23:06:33 | train] - Train Epoch: [118] [89600/1281167 (7%)]	Loss: 0.742128
[2022-03-31 23:06:54 | train] - Train Epoch: [118] [102400/1281167 (8%)]	Loss: 0.640001
[2022-03-31 23:07:14 | train] - Train Epoch: [118] [115200/1281167 (9%)]	Loss: 0.871653
[2022-03-31 23:07:37 | train] - Train Epoch: [118] [128000/1281167 (10%)]	Loss: 0.837801
[2022-03-31 23:07:57 | train] - Train Epoch: [118] [140800/1281167 (11%)]	Loss: 0.638121
[2022-03-31 23:08:19 | train] - Train Epoch: [118] [153600/1281167 (12%)]	Loss: 0.650672
[2022-03-31 23:08:41 | train] - Train Epoch: [118] [166400/1281167 (13%)]	Loss: 0.558255
[2022-03-31 23:09:02 | train] - Train Epoch: [118] [179200/1281167 (14%)]	Loss: 0.643119
[2022-03-31 23:09:23 | train] - Train Epoch: [118] [192000/1281167 (15%)]	Loss: 0.854006
[2022-03-31 23:09:45 | train] - Train Epoch: [118] [204800/1281167 (16%)]	Loss: 0.750517
[2022-03-31 23:10:08 | train] - Train Epoch: [118] [217600/1281167 (17%)]	Loss: 0.816447
[2022-03-31 23:10:29 | train] - Train Epoch: [118] [230400/1281167 (18%)]	Loss: 0.886124
[2022-03-31 23:10:51 | train] - Train Epoch: [118] [243200/1281167 (19%)]	Loss: 0.565598
[2022-03-31 23:11:12 | train] - Train Epoch: [118] [256000/1281167 (20%)]	Loss: 0.884995
[2022-03-31 23:11:34 | train] - Train Epoch: [118] [268800/1281167 (21%)]	Loss: 0.482878
[2022-03-31 23:11:56 | train] - Train Epoch: [118] [281600/1281167 (22%)]	Loss: 0.821528
[2022-03-31 23:12:17 | train] - Train Epoch: [118] [294400/1281167 (23%)]	Loss: 0.685083
[2022-03-31 23:12:37 | train] - Train Epoch: [118] [307200/1281167 (24%)]	Loss: 0.975392
[2022-03-31 23:12:58 | train] - Train Epoch: [118] [320000/1281167 (25%)]	Loss: 1.009680
[2022-03-31 23:13:19 | train] - Train Epoch: [118] [332800/1281167 (26%)]	Loss: 0.798542
[2022-03-31 23:13:40 | train] - Train Epoch: [118] [345600/1281167 (27%)]	Loss: 0.559237
[2022-03-31 23:14:00 | train] - Train Epoch: [118] [358400/1281167 (28%)]	Loss: 0.788260
[2022-03-31 23:14:20 | train] - Train Epoch: [118] [371200/1281167 (29%)]	Loss: 0.711014
[2022-03-31 23:14:40 | train] - Train Epoch: [118] [384000/1281167 (30%)]	Loss: 0.629689
[2022-03-31 23:15:01 | train] - Train Epoch: [118] [396800/1281167 (31%)]	Loss: 0.771265
[2022-03-31 23:15:21 | train] - Train Epoch: [118] [409600/1281167 (32%)]	Loss: 0.516724
[2022-03-31 23:15:41 | train] - Train Epoch: [118] [422400/1281167 (33%)]	Loss: 0.439811
[2022-03-31 23:16:01 | train] - Train Epoch: [118] [435200/1281167 (34%)]	Loss: 0.796785
[2022-03-31 23:16:22 | train] - Train Epoch: [118] [448000/1281167 (35%)]	Loss: 0.717824
[2022-03-31 23:16:43 | train] - Train Epoch: [118] [460800/1281167 (36%)]	Loss: 1.010981
[2022-03-31 23:17:02 | train] - Train Epoch: [118] [473600/1281167 (37%)]	Loss: 0.750565
[2022-03-31 23:17:22 | train] - Train Epoch: [118] [486400/1281167 (38%)]	Loss: 0.778670
[2022-03-31 23:17:42 | train] - Train Epoch: [118] [499200/1281167 (39%)]	Loss: 0.474969
[2022-03-31 23:18:02 | train] - Train Epoch: [118] [512000/1281167 (40%)]	Loss: 0.718439
[2022-03-31 23:18:22 | train] - Train Epoch: [118] [524800/1281167 (41%)]	Loss: 0.542328
[2022-03-31 23:18:42 | train] - Train Epoch: [118] [537600/1281167 (42%)]	Loss: 0.630616
[2022-03-31 23:19:02 | train] - Train Epoch: [118] [550400/1281167 (43%)]	Loss: 0.592979
[2022-03-31 23:19:22 | train] - Train Epoch: [118] [563200/1281167 (44%)]	Loss: 0.645672
[2022-03-31 23:19:43 | train] - Train Epoch: [118] [576000/1281167 (45%)]	Loss: 0.578654
[2022-03-31 23:20:03 | train] - Train Epoch: [118] [588800/1281167 (46%)]	Loss: 0.831883
[2022-03-31 23:20:23 | train] - Train Epoch: [118] [601600/1281167 (47%)]	Loss: 1.080090
[2022-03-31 23:20:44 | train] - Train Epoch: [118] [614400/1281167 (48%)]	Loss: 0.762397
[2022-03-31 23:21:05 | train] - Train Epoch: [118] [627200/1281167 (49%)]	Loss: 0.819235
[2022-03-31 23:21:25 | train] - Train Epoch: [118] [640000/1281167 (50%)]	Loss: 0.921436
[2022-03-31 23:21:45 | train] - Train Epoch: [118] [652800/1281167 (51%)]	Loss: 0.756041
[2022-03-31 23:22:05 | train] - Train Epoch: [118] [665600/1281167 (52%)]	Loss: 0.880205
[2022-03-31 23:22:24 | train] - Train Epoch: [118] [678400/1281167 (53%)]	Loss: 0.696016
[2022-03-31 23:22:45 | train] - Train Epoch: [118] [691200/1281167 (54%)]	Loss: 0.647714
[2022-03-31 23:23:05 | train] - Train Epoch: [118] [704000/1281167 (55%)]	Loss: 0.593237
[2022-03-31 23:23:25 | train] - Train Epoch: [118] [716800/1281167 (56%)]	Loss: 0.873769
[2022-03-31 23:23:44 | train] - Train Epoch: [118] [729600/1281167 (57%)]	Loss: 0.686312
[2022-03-31 23:24:03 | train] - Train Epoch: [118] [742400/1281167 (58%)]	Loss: 0.762404
[2022-03-31 23:24:24 | train] - Train Epoch: [118] [755200/1281167 (59%)]	Loss: 0.941677
[2022-03-31 23:24:44 | train] - Train Epoch: [118] [768000/1281167 (60%)]	Loss: 0.837271
[2022-03-31 23:25:04 | train] - Train Epoch: [118] [780800/1281167 (61%)]	Loss: 0.895285
[2022-03-31 23:25:24 | train] - Train Epoch: [118] [793600/1281167 (62%)]	Loss: 0.843248
[2022-03-31 23:25:45 | train] - Train Epoch: [118] [806400/1281167 (63%)]	Loss: 1.069876
[2022-03-31 23:26:05 | train] - Train Epoch: [118] [819200/1281167 (64%)]	Loss: 0.803852
[2022-03-31 23:26:25 | train] - Train Epoch: [118] [832000/1281167 (65%)]	Loss: 0.952496
[2022-03-31 23:26:46 | train] - Train Epoch: [118] [844800/1281167 (66%)]	Loss: 0.526594
[2022-03-31 23:27:05 | train] - Train Epoch: [118] [857600/1281167 (67%)]	Loss: 0.690649
[2022-03-31 23:27:26 | train] - Train Epoch: [118] [870400/1281167 (68%)]	Loss: 0.627673
[2022-03-31 23:27:46 | train] - Train Epoch: [118] [883200/1281167 (69%)]	Loss: 0.490164
[2022-03-31 23:28:06 | train] - Train Epoch: [118] [896000/1281167 (70%)]	Loss: 0.776232
[2022-03-31 23:28:26 | train] - Train Epoch: [118] [908800/1281167 (71%)]	Loss: 0.787286
[2022-03-31 23:28:45 | train] - Train Epoch: [118] [921600/1281167 (72%)]	Loss: 0.800151
[2022-03-31 23:29:06 | train] - Train Epoch: [118] [934400/1281167 (73%)]	Loss: 0.678964
[2022-03-31 23:29:27 | train] - Train Epoch: [118] [947200/1281167 (74%)]	Loss: 0.699444
[2022-03-31 23:29:47 | train] - Train Epoch: [118] [960000/1281167 (75%)]	Loss: 0.631542
[2022-03-31 23:30:06 | train] - Train Epoch: [118] [972800/1281167 (76%)]	Loss: 0.767047
[2022-03-31 23:30:26 | train] - Train Epoch: [118] [985600/1281167 (77%)]	Loss: 0.964578
[2022-03-31 23:30:47 | train] - Train Epoch: [118] [998400/1281167 (78%)]	Loss: 0.730722
[2022-03-31 23:31:06 | train] - Train Epoch: [118] [1011200/1281167 (79%)]	Loss: 0.876387
[2022-03-31 23:31:26 | train] - Train Epoch: [118] [1024000/1281167 (80%)]	Loss: 0.488782
[2022-03-31 23:31:47 | train] - Train Epoch: [118] [1036800/1281167 (81%)]	Loss: 0.438185
[2022-03-31 23:32:07 | train] - Train Epoch: [118] [1049600/1281167 (82%)]	Loss: 0.662499
[2022-03-31 23:32:27 | train] - Train Epoch: [118] [1062400/1281167 (83%)]	Loss: 0.404929
[2022-03-31 23:32:47 | train] - Train Epoch: [118] [1075200/1281167 (84%)]	Loss: 0.484706
[2022-03-31 23:33:08 | train] - Train Epoch: [118] [1088000/1281167 (85%)]	Loss: 0.627063
[2022-03-31 23:33:28 | train] - Train Epoch: [118] [1100800/1281167 (86%)]	Loss: 0.915640
[2022-03-31 23:33:48 | train] - Train Epoch: [118] [1113600/1281167 (87%)]	Loss: 1.006254
[2022-03-31 23:34:08 | train] - Train Epoch: [118] [1126400/1281167 (88%)]	Loss: 0.604108
[2022-03-31 23:34:28 | train] - Train Epoch: [118] [1139200/1281167 (89%)]	Loss: 0.562612
[2022-03-31 23:34:48 | train] - Train Epoch: [118] [1152000/1281167 (90%)]	Loss: 1.023610
[2022-03-31 23:35:08 | train] - Train Epoch: [118] [1164800/1281167 (91%)]	Loss: 0.889209
[2022-03-31 23:35:28 | train] - Train Epoch: [118] [1177600/1281167 (92%)]	Loss: 0.684010
[2022-03-31 23:35:48 | train] - Train Epoch: [118] [1190400/1281167 (93%)]	Loss: 0.946104
[2022-03-31 23:36:08 | train] - Train Epoch: [118] [1203200/1281167 (94%)]	Loss: 0.449360
[2022-03-31 23:36:28 | train] - Train Epoch: [118] [1216000/1281167 (95%)]	Loss: 0.913168
[2022-03-31 23:36:48 | train] - Train Epoch: [118] [1228800/1281167 (96%)]	Loss: 0.824749
[2022-03-31 23:37:08 | train] - Train Epoch: [118] [1241600/1281167 (97%)]	Loss: 0.673441
[2022-03-31 23:37:28 | train] - Train Epoch: [118] [1254400/1281167 (98%)]	Loss: 0.698530
[2022-03-31 23:37:49 | train] - Train Epoch: [118] [1267200/1281167 (99%)]	Loss: 0.905803
[2022-03-31 23:38:09 | train] - Train Epoch: [118] [1280000/1281167 (100%)]	Loss: 0.861641
[2022-03-31 23:38:10 | train] - Train Epoch: [118]	 Average Loss: 0.752466	 Total Acc : 81.6532	 Total Top5 Acc : 93.3356
[2022-03-31 23:38:10 | train] - -------118 epoch end-----------
========================================
-------118 epoch end  -----------

----- test and print accuracy ------------------
[2022-03-31 23:39:41 | train] - 
Epoch [118] Test set: Average loss: 1.4526, Accuracy: 34663/50000 (69.3015%), Top-5 Accuracy: 88.5758%

[2022-03-31 23:39:41 | train] - save intermediate epoch [118] result


[2022-03-31 23:39:56 | train] - -------119 epoch start-----------
========================================
----- test end -------------------------


[2022-03-31 23:39:58 | train] - Train Epoch: [119] [0/1281167 (0%)]	Loss: 0.944046
[2022-03-31 23:40:18 | train] - Train Epoch: [119] [12800/1281167 (1%)]	Loss: 0.822335
[2022-03-31 23:40:38 | train] - Train Epoch: [119] [25600/1281167 (2%)]	Loss: 0.813535
[2022-03-31 23:40:58 | train] - Train Epoch: [119] [38400/1281167 (3%)]	Loss: 1.076197
[2022-03-31 23:41:18 | train] - Train Epoch: [119] [51200/1281167 (4%)]	Loss: 0.931251
[2022-03-31 23:41:38 | train] - Train Epoch: [119] [64000/1281167 (5%)]	Loss: 0.931584
[2022-03-31 23:41:57 | train] - Train Epoch: [119] [76800/1281167 (6%)]	Loss: 0.761660
[2022-03-31 23:42:17 | train] - Train Epoch: [119] [89600/1281167 (7%)]	Loss: 0.809522
[2022-03-31 23:42:37 | train] - Train Epoch: [119] [102400/1281167 (8%)]	Loss: 0.847899
[2022-03-31 23:42:57 | train] - Train Epoch: [119] [115200/1281167 (9%)]	Loss: 0.757410
[2022-03-31 23:43:17 | train] - Train Epoch: [119] [128000/1281167 (10%)]	Loss: 0.931971
[2022-03-31 23:43:37 | train] - Train Epoch: [119] [140800/1281167 (11%)]	Loss: 0.941266
[2022-03-31 23:43:57 | train] - Train Epoch: [119] [153600/1281167 (12%)]	Loss: 0.729040
[2022-03-31 23:44:16 | train] - Train Epoch: [119] [166400/1281167 (13%)]	Loss: 0.890191
[2022-03-31 23:44:36 | train] - Train Epoch: [119] [179200/1281167 (14%)]	Loss: 0.828763
[2022-03-31 23:44:56 | train] - Train Epoch: [119] [192000/1281167 (15%)]	Loss: 0.779217
[2022-03-31 23:45:16 | train] - Train Epoch: [119] [204800/1281167 (16%)]	Loss: 0.992925
[2022-03-31 23:45:35 | train] - Train Epoch: [119] [217600/1281167 (17%)]	Loss: 0.895189
[2022-03-31 23:45:56 | train] - Train Epoch: [119] [230400/1281167 (18%)]	Loss: 0.861449
[2022-03-31 23:46:16 | train] - Train Epoch: [119] [243200/1281167 (19%)]	Loss: 0.805214
[2022-03-31 23:46:36 | train] - Train Epoch: [119] [256000/1281167 (20%)]	Loss: 0.698789
[2022-03-31 23:46:55 | train] - Train Epoch: [119] [268800/1281167 (21%)]	Loss: 0.550878
[2022-03-31 23:47:16 | train] - Train Epoch: [119] [281600/1281167 (22%)]	Loss: 0.977468
[2022-03-31 23:47:36 | train] - Train Epoch: [119] [294400/1281167 (23%)]	Loss: 0.671737
[2022-03-31 23:47:56 | train] - Train Epoch: [119] [307200/1281167 (24%)]	Loss: 0.608001
[2022-03-31 23:48:16 | train] - Train Epoch: [119] [320000/1281167 (25%)]	Loss: 0.821247
[2022-03-31 23:48:36 | train] - Train Epoch: [119] [332800/1281167 (26%)]	Loss: 0.852054
[2022-03-31 23:48:56 | train] - Train Epoch: [119] [345600/1281167 (27%)]	Loss: 0.916319
[2022-03-31 23:49:16 | train] - Train Epoch: [119] [358400/1281167 (28%)]	Loss: 0.564976
[2022-03-31 23:49:34 | train] - Train Epoch: [119] [371200/1281167 (29%)]	Loss: 1.136556
[2022-03-31 23:49:54 | train] - Train Epoch: [119] [384000/1281167 (30%)]	Loss: 0.944535
[2022-03-31 23:50:14 | train] - Train Epoch: [119] [396800/1281167 (31%)]	Loss: 1.021250
[2022-03-31 23:50:34 | train] - Train Epoch: [119] [409600/1281167 (32%)]	Loss: 0.603036
[2022-03-31 23:50:54 | train] - Train Epoch: [119] [422400/1281167 (33%)]	Loss: 0.921515
[2022-03-31 23:51:14 | train] - Train Epoch: [119] [435200/1281167 (34%)]	Loss: 0.652518
[2022-03-31 23:51:34 | train] - Train Epoch: [119] [448000/1281167 (35%)]	Loss: 0.869855
[2022-03-31 23:51:53 | train] - Train Epoch: [119] [460800/1281167 (36%)]	Loss: 0.649872
[2022-03-31 23:52:13 | train] - Train Epoch: [119] [473600/1281167 (37%)]	Loss: 0.950454
[2022-03-31 23:52:33 | train] - Train Epoch: [119] [486400/1281167 (38%)]	Loss: 0.635328
[2022-03-31 23:52:53 | train] - Train Epoch: [119] [499200/1281167 (39%)]	Loss: 1.032291
[2022-03-31 23:53:13 | train] - Train Epoch: [119] [512000/1281167 (40%)]	Loss: 0.884528
[2022-03-31 23:53:32 | train] - Train Epoch: [119] [524800/1281167 (41%)]	Loss: 0.937468
[2022-03-31 23:53:53 | train] - Train Epoch: [119] [537600/1281167 (42%)]	Loss: 0.882548
[2022-03-31 23:54:13 | train] - Train Epoch: [119] [550400/1281167 (43%)]	Loss: 0.929048
[2022-03-31 23:54:33 | train] - Train Epoch: [119] [563200/1281167 (44%)]	Loss: 0.973334
[2022-03-31 23:54:53 | train] - Train Epoch: [119] [576000/1281167 (45%)]	Loss: 0.687777
[2022-03-31 23:55:13 | train] - Train Epoch: [119] [588800/1281167 (46%)]	Loss: 0.783125
[2022-03-31 23:55:33 | train] - Train Epoch: [119] [601600/1281167 (47%)]	Loss: 0.692155
[2022-03-31 23:55:53 | train] - Train Epoch: [119] [614400/1281167 (48%)]	Loss: 1.020924
[2022-03-31 23:56:13 | train] - Train Epoch: [119] [627200/1281167 (49%)]	Loss: 0.992447
[2022-03-31 23:56:33 | train] - Train Epoch: [119] [640000/1281167 (50%)]	Loss: 0.844156
[2022-03-31 23:56:53 | train] - Train Epoch: [119] [652800/1281167 (51%)]	Loss: 0.922355
[2022-03-31 23:57:13 | train] - Train Epoch: [119] [665600/1281167 (52%)]	Loss: 0.858675
[2022-03-31 23:57:33 | train] - Train Epoch: [119] [678400/1281167 (53%)]	Loss: 0.950936
[2022-03-31 23:57:53 | train] - Train Epoch: [119] [691200/1281167 (54%)]	Loss: 0.702709
[2022-03-31 23:58:12 | train] - Train Epoch: [119] [704000/1281167 (55%)]	Loss: 1.057607
[2022-03-31 23:58:32 | train] - Train Epoch: [119] [716800/1281167 (56%)]	Loss: 0.651453
[2022-03-31 23:58:52 | train] - Train Epoch: [119] [729600/1281167 (57%)]	Loss: 0.819182
[2022-03-31 23:59:11 | train] - Train Epoch: [119] [742400/1281167 (58%)]	Loss: 0.694375
[2022-03-31 23:59:31 | train] - Train Epoch: [119] [755200/1281167 (59%)]	Loss: 0.964606
[2022-03-31 23:59:50 | train] - Train Epoch: [119] [768000/1281167 (60%)]	Loss: 0.627230
[2022-04-01 00:00:10 | train] - Train Epoch: [119] [780800/1281167 (61%)]	Loss: 0.784348
[2022-04-01 00:00:30 | train] - Train Epoch: [119] [793600/1281167 (62%)]	Loss: 0.677402
[2022-04-01 00:00:49 | train] - Train Epoch: [119] [806400/1281167 (63%)]	Loss: 0.866871
[2022-04-01 00:01:10 | train] - Train Epoch: [119] [819200/1281167 (64%)]	Loss: 0.874535
[2022-04-01 00:01:30 | train] - Train Epoch: [119] [832000/1281167 (65%)]	Loss: 0.770954
[2022-04-01 00:01:49 | train] - Train Epoch: [119] [844800/1281167 (66%)]	Loss: 0.630529
[2022-04-01 00:02:09 | train] - Train Epoch: [119] [857600/1281167 (67%)]	Loss: 0.852893
[2022-04-01 00:02:29 | train] - Train Epoch: [119] [870400/1281167 (68%)]	Loss: 1.006636
[2022-04-01 00:02:48 | train] - Train Epoch: [119] [883200/1281167 (69%)]	Loss: 1.072432
[2022-04-01 00:03:08 | train] - Train Epoch: [119] [896000/1281167 (70%)]	Loss: 0.808499
[2022-04-01 00:03:27 | train] - Train Epoch: [119] [908800/1281167 (71%)]	Loss: 0.820948
[2022-04-01 00:03:47 | train] - Train Epoch: [119] [921600/1281167 (72%)]	Loss: 0.817733
[2022-04-01 00:04:06 | train] - Train Epoch: [119] [934400/1281167 (73%)]	Loss: 1.132172
[2022-04-01 00:04:26 | train] - Train Epoch: [119] [947200/1281167 (74%)]	Loss: 0.829011
[2022-04-01 00:04:46 | train] - Train Epoch: [119] [960000/1281167 (75%)]	Loss: 0.782345
[2022-04-01 00:05:06 | train] - Train Epoch: [119] [972800/1281167 (76%)]	Loss: 1.089950
[2022-04-01 00:05:25 | train] - Train Epoch: [119] [985600/1281167 (77%)]	Loss: 0.833391
[2022-04-01 00:05:45 | train] - Train Epoch: [119] [998400/1281167 (78%)]	Loss: 1.033626
[2022-04-01 00:06:05 | train] - Train Epoch: [119] [1011200/1281167 (79%)]	Loss: 1.125749
[2022-04-01 00:06:25 | train] - Train Epoch: [119] [1024000/1281167 (80%)]	Loss: 0.695230
[2022-04-01 00:06:44 | train] - Train Epoch: [119] [1036800/1281167 (81%)]	Loss: 1.019334
[2022-04-01 00:07:04 | train] - Train Epoch: [119] [1049600/1281167 (82%)]	Loss: 1.004606
[2022-04-01 00:07:24 | train] - Train Epoch: [119] [1062400/1281167 (83%)]	Loss: 0.709660
[2022-04-01 00:07:44 | train] - Train Epoch: [119] [1075200/1281167 (84%)]	Loss: 0.820209
[2022-04-01 00:08:03 | train] - Train Epoch: [119] [1088000/1281167 (85%)]	Loss: 0.776408
[2022-04-01 00:08:23 | train] - Train Epoch: [119] [1100800/1281167 (86%)]	Loss: 0.871576
[2022-04-01 00:08:43 | train] - Train Epoch: [119] [1113600/1281167 (87%)]	Loss: 0.862729
[2022-04-01 00:09:02 | train] - Train Epoch: [119] [1126400/1281167 (88%)]	Loss: 0.912825
[2022-04-01 00:09:22 | train] - Train Epoch: [119] [1139200/1281167 (89%)]	Loss: 0.682643
[2022-04-01 00:09:42 | train] - Train Epoch: [119] [1152000/1281167 (90%)]	Loss: 0.945791
[2022-04-01 00:10:02 | train] - Train Epoch: [119] [1164800/1281167 (91%)]	Loss: 0.773939
[2022-04-01 00:10:22 | train] - Train Epoch: [119] [1177600/1281167 (92%)]	Loss: 0.750930
[2022-04-01 00:10:42 | train] - Train Epoch: [119] [1190400/1281167 (93%)]	Loss: 0.924727
[2022-04-01 00:11:02 | train] - Train Epoch: [119] [1203200/1281167 (94%)]	Loss: 1.032761
[2022-04-01 00:11:23 | train] - Train Epoch: [119] [1216000/1281167 (95%)]	Loss: 0.806634
[2022-04-01 00:11:42 | train] - Train Epoch: [119] [1228800/1281167 (96%)]	Loss: 0.709781
[2022-04-01 00:12:02 | train] - Train Epoch: [119] [1241600/1281167 (97%)]	Loss: 0.664225
[2022-04-01 00:12:22 | train] - Train Epoch: [119] [1254400/1281167 (98%)]	Loss: 0.794174
[2022-04-01 00:12:41 | train] - Train Epoch: [119] [1267200/1281167 (99%)]	Loss: 0.636302
[2022-04-01 00:13:01 | train] - Train Epoch: [119] [1280000/1281167 (100%)]	Loss: 0.929404
[2022-04-01 00:13:03 | train] - Train Epoch: [119]	 Average Loss: 0.835831	 Total Acc : 79.4621	 Total Top5 Acc : 92.5335
[2022-04-01 00:13:03 | train] - -------119 epoch end-----------
========================================
-------119 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-01 00:14:32 | train] - 
Epoch [119] Test set: Average loss: 1.4535, Accuracy: 34708/50000 (69.3866%), Top-5 Accuracy: 88.5354%

[2022-04-01 00:14:32 | train] - save intermediate epoch [119] result


[2022-04-01 00:14:48 | train] - -------120 epoch start-----------
[2022-04-01 00:14:48 | train] - -------- logging 120 batch layer input tensor ------------------
========================================
----- test end -------------------------


Traceback (most recent call last):
  File "main.py", line 382, in <module>
    main()
  File "main.py", line 279, in main
    result_fwd_hook_list, result_bwd_hook_list = batchnorm_hook_result(net, check_data, check_label, optimizer, option)
  File "main.py", line 138, in batchnorm_hook_result
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 352, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 39.41 GiB total capacity; 36.52 GiB already allocated; 355.50 MiB free; 37.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[I 18:48:56.732 NotebookApp] jupyter_tensorboard extension loaded.
[I 18:48:57.075 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.8/site-packages/jupyterlab
[I 18:48:57.076 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab
[I 18:48:57.078 NotebookApp] [Jupytext Server Extension] NotebookApp.contents_manager_class is (a subclass of) jupytext.TextFileContentsManager already - OK
[I 18:48:57.079 NotebookApp] Serving notebooks from local directory: /root/torch/kjh_test
[I 18:48:57.079 NotebookApp] Jupyter Notebook 6.4.1 is running at:
[I 18:48:57.079 NotebookApp] http://hostname:8888/
[I 18:48:57.079 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 18:49:02.569 NotebookApp] 302 GET / (10.150.7.107) 0.730000ms
[I 18:49:02.605 NotebookApp] 302 GET /tree? (10.150.7.107) 1.160000ms
[I 18:49:25.872 NotebookApp] 302 POST /login?next=%2Ftree%3F (10.150.7.107) 53.820000ms
/opt/conda/lib/python3.8/json/encoder.py:257: UserWarning: date_default is deprecated since jupyter_client 7.0.0. Use jupyter_client.jsonutil.json_default.
  return _iterencode(o, 0)
[I 18:49:32.583 NotebookApp] 302 GET / (10.150.7.107) 0.610000ms
[I 18:49:32.593 NotebookApp] 302 GET /tree? (10.150.7.107) 0.560000ms
[I 18:49:38.077 NotebookApp] 302 POST /login?next=%2Ftree%3F (10.150.7.107) 37.080000ms
[2022-04-05 20:14:53 | train] - -------start batchnorm param logging -----------

[2022-04-05 20:14:53 | train] - -------end batchnorm param logging -----------

[2022-04-05 20:14:53 | train] - -------121 epoch start-----------
/data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
load log path /data/kjh/save_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/
load pretrained model : epoch 121
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
[2022-04-05 20:14:56 | train] - Train Epoch: [121] [0/1281167 (0%)]	Loss: 0.743177
[2022-04-05 20:15:24 | train] - Train Epoch: [121] [12800/1281167 (1%)]	Loss: 0.644450
[2022-04-05 20:15:55 | train] - Train Epoch: [121] [25600/1281167 (2%)]	Loss: 0.560018
[2022-04-05 20:16:24 | train] - Train Epoch: [121] [38400/1281167 (3%)]	Loss: 0.655806
[2022-04-05 20:16:55 | train] - Train Epoch: [121] [51200/1281167 (4%)]	Loss: 0.499447
[2022-04-05 20:17:24 | train] - Train Epoch: [121] [64000/1281167 (5%)]	Loss: 0.548596
[2022-04-05 20:17:53 | train] - Train Epoch: [121] [76800/1281167 (6%)]	Loss: 0.798099
[2022-04-05 20:18:22 | train] - Train Epoch: [121] [89600/1281167 (7%)]	Loss: 0.679006
[2022-04-05 20:18:51 | train] - Train Epoch: [121] [102400/1281167 (8%)]	Loss: 0.776780
[2022-04-05 20:19:20 | train] - Train Epoch: [121] [115200/1281167 (9%)]	Loss: 0.538215
[2022-04-05 20:19:48 | train] - Train Epoch: [121] [128000/1281167 (10%)]	Loss: 0.487738
[2022-04-05 20:20:18 | train] - Train Epoch: [121] [140800/1281167 (11%)]	Loss: 0.848780
[2022-04-05 20:20:47 | train] - Train Epoch: [121] [153600/1281167 (12%)]	Loss: 0.759503
[2022-04-05 20:21:17 | train] - Train Epoch: [121] [166400/1281167 (13%)]	Loss: 0.734004
[2022-04-05 20:21:47 | train] - Train Epoch: [121] [179200/1281167 (14%)]	Loss: 0.777316
[2022-04-05 20:22:16 | train] - Train Epoch: [121] [192000/1281167 (15%)]	Loss: 0.885554
[2022-04-05 20:22:45 | train] - Train Epoch: [121] [204800/1281167 (16%)]	Loss: 0.701527
[2022-04-05 20:23:14 | train] - Train Epoch: [121] [217600/1281167 (17%)]	Loss: 0.868939
[2022-04-05 20:23:42 | train] - Train Epoch: [121] [230400/1281167 (18%)]	Loss: 0.782360
[2022-04-05 20:24:11 | train] - Train Epoch: [121] [243200/1281167 (19%)]	Loss: 0.779562
[2022-04-05 20:24:40 | train] - Train Epoch: [121] [256000/1281167 (20%)]	Loss: 0.808674
[2022-04-05 20:25:09 | train] - Train Epoch: [121] [268800/1281167 (21%)]	Loss: 0.916043
[2022-04-05 20:25:38 | train] - Train Epoch: [121] [281600/1281167 (22%)]	Loss: 0.687509
[2022-04-05 20:26:07 | train] - Train Epoch: [121] [294400/1281167 (23%)]	Loss: 0.559901
[2022-04-05 20:26:36 | train] - Train Epoch: [121] [307200/1281167 (24%)]	Loss: 0.517403
[2022-04-05 20:27:05 | train] - Train Epoch: [121] [320000/1281167 (25%)]	Loss: 0.805838
[2022-04-05 20:27:34 | train] - Train Epoch: [121] [332800/1281167 (26%)]	Loss: 0.680629
[2022-04-05 20:28:02 | train] - Train Epoch: [121] [345600/1281167 (27%)]	Loss: 0.825427
[2022-04-05 20:28:33 | train] - Train Epoch: [121] [358400/1281167 (28%)]	Loss: 0.759671
[2022-04-05 20:29:02 | train] - Train Epoch: [121] [371200/1281167 (29%)]	Loss: 0.554116
[2022-04-05 20:29:32 | train] - Train Epoch: [121] [384000/1281167 (30%)]	Loss: 0.581303
[2022-04-05 20:30:02 | train] - Train Epoch: [121] [396800/1281167 (31%)]	Loss: 0.500907
[2022-04-05 20:30:32 | train] - Train Epoch: [121] [409600/1281167 (32%)]	Loss: 0.833183
[2022-04-05 20:31:02 | train] - Train Epoch: [121] [422400/1281167 (33%)]	Loss: 0.612956
[2022-04-05 20:31:32 | train] - Train Epoch: [121] [435200/1281167 (34%)]	Loss: 0.657731
[2022-04-05 20:32:02 | train] - Train Epoch: [121] [448000/1281167 (35%)]	Loss: 0.573124
[2022-04-05 20:32:32 | train] - Train Epoch: [121] [460800/1281167 (36%)]	Loss: 0.708549
[2022-04-05 20:33:02 | train] - Train Epoch: [121] [473600/1281167 (37%)]	Loss: 0.691590
[2022-04-05 20:33:31 | train] - Train Epoch: [121] [486400/1281167 (38%)]	Loss: 0.989221
[2022-04-05 20:34:01 | train] - Train Epoch: [121] [499200/1281167 (39%)]	Loss: 0.530854
[2022-04-05 20:34:30 | train] - Train Epoch: [121] [512000/1281167 (40%)]	Loss: 0.546308
[2022-04-05 20:35:00 | train] - Train Epoch: [121] [524800/1281167 (41%)]	Loss: 0.733361
[2022-04-05 20:35:29 | train] - Train Epoch: [121] [537600/1281167 (42%)]	Loss: 0.618080
[2022-04-05 20:35:59 | train] - Train Epoch: [121] [550400/1281167 (43%)]	Loss: 0.699241
[2022-04-05 20:36:29 | train] - Train Epoch: [121] [563200/1281167 (44%)]	Loss: 0.688613
[2022-04-05 20:36:58 | train] - Train Epoch: [121] [576000/1281167 (45%)]	Loss: 0.723276
[2022-04-05 20:37:27 | train] - Train Epoch: [121] [588800/1281167 (46%)]	Loss: 0.825619
[2022-04-05 20:37:55 | train] - Train Epoch: [121] [601600/1281167 (47%)]	Loss: 0.789145
[2022-04-05 20:38:24 | train] - Train Epoch: [121] [614400/1281167 (48%)]	Loss: 0.575692
[2022-04-05 20:38:54 | train] - Train Epoch: [121] [627200/1281167 (49%)]	Loss: 0.694690
[2022-04-05 20:39:24 | train] - Train Epoch: [121] [640000/1281167 (50%)]	Loss: 0.895324
[2022-04-05 20:39:54 | train] - Train Epoch: [121] [652800/1281167 (51%)]	Loss: 0.647191
[2022-04-05 20:40:24 | train] - Train Epoch: [121] [665600/1281167 (52%)]	Loss: 1.025880
[2022-04-05 20:40:53 | train] - Train Epoch: [121] [678400/1281167 (53%)]	Loss: 0.580429
[2022-04-05 20:41:25 | train] - Train Epoch: [121] [691200/1281167 (54%)]	Loss: 0.613948
[2022-04-05 20:41:54 | train] - Train Epoch: [121] [704000/1281167 (55%)]	Loss: 0.756551
[2022-04-05 20:42:23 | train] - Train Epoch: [121] [716800/1281167 (56%)]	Loss: 0.568902
[2022-04-05 20:42:52 | train] - Train Epoch: [121] [729600/1281167 (57%)]	Loss: 0.537835
[2022-04-05 20:43:21 | train] - Train Epoch: [121] [742400/1281167 (58%)]	Loss: 0.619393
[2022-04-05 20:43:50 | train] - Train Epoch: [121] [755200/1281167 (59%)]	Loss: 0.850895
[2022-04-05 20:44:19 | train] - Train Epoch: [121] [768000/1281167 (60%)]	Loss: 0.848735
[2022-04-05 20:44:49 | train] - Train Epoch: [121] [780800/1281167 (61%)]	Loss: 0.650943
[2022-04-05 20:45:17 | train] - Train Epoch: [121] [793600/1281167 (62%)]	Loss: 0.771692
[2022-04-05 20:45:47 | train] - Train Epoch: [121] [806400/1281167 (63%)]	Loss: 0.650452
[2022-04-05 20:46:16 | train] - Train Epoch: [121] [819200/1281167 (64%)]	Loss: 0.832173
[2022-04-05 20:46:45 | train] - Train Epoch: [121] [832000/1281167 (65%)]	Loss: 0.809883
[2022-04-05 20:47:14 | train] - Train Epoch: [121] [844800/1281167 (66%)]	Loss: 0.626005
[2022-04-05 20:47:45 | train] - Train Epoch: [121] [857600/1281167 (67%)]	Loss: 0.620717
[2022-04-05 20:48:14 | train] - Train Epoch: [121] [870400/1281167 (68%)]	Loss: 0.717234
[2022-04-05 20:48:45 | train] - Train Epoch: [121] [883200/1281167 (69%)]	Loss: 0.733055
[2022-04-05 20:49:13 | train] - Train Epoch: [121] [896000/1281167 (70%)]	Loss: 0.699863
[2022-04-05 20:49:41 | train] - Train Epoch: [121] [908800/1281167 (71%)]	Loss: 0.643086
[2022-04-05 20:50:09 | train] - Train Epoch: [121] [921600/1281167 (72%)]	Loss: 1.068750
[2022-04-05 20:50:37 | train] - Train Epoch: [121] [934400/1281167 (73%)]	Loss: 0.512039
[2022-04-05 20:51:06 | train] - Train Epoch: [121] [947200/1281167 (74%)]	Loss: 0.616046
[2022-04-05 20:51:35 | train] - Train Epoch: [121] [960000/1281167 (75%)]	Loss: 0.706752
[2022-04-05 20:52:03 | train] - Train Epoch: [121] [972800/1281167 (76%)]	Loss: 0.609874
[2022-04-05 20:52:32 | train] - Train Epoch: [121] [985600/1281167 (77%)]	Loss: 0.720785
[2022-04-05 20:53:01 | train] - Train Epoch: [121] [998400/1281167 (78%)]	Loss: 0.711691
[2022-04-05 20:53:30 | train] - Train Epoch: [121] [1011200/1281167 (79%)]	Loss: 0.671219
[2022-04-05 20:53:58 | train] - Train Epoch: [121] [1024000/1281167 (80%)]	Loss: 0.668596
[2022-04-05 20:54:30 | train] - Train Epoch: [121] [1036800/1281167 (81%)]	Loss: 0.620804
[2022-04-05 20:54:59 | train] - Train Epoch: [121] [1049600/1281167 (82%)]	Loss: 0.583173
[2022-04-05 20:55:27 | train] - Train Epoch: [121] [1062400/1281167 (83%)]	Loss: 0.576730
[2022-04-05 20:55:55 | train] - Train Epoch: [121] [1075200/1281167 (84%)]	Loss: 0.934236
[2022-04-05 20:56:23 | train] - Train Epoch: [121] [1088000/1281167 (85%)]	Loss: 0.534670
[2022-04-05 20:56:51 | train] - Train Epoch: [121] [1100800/1281167 (86%)]	Loss: 0.742374
[2022-04-05 20:57:19 | train] - Train Epoch: [121] [1113600/1281167 (87%)]	Loss: 0.495225
[2022-04-05 20:57:48 | train] - Train Epoch: [121] [1126400/1281167 (88%)]	Loss: 0.629958
[2022-04-05 20:58:17 | train] - Train Epoch: [121] [1139200/1281167 (89%)]	Loss: 0.946460
[2022-04-05 20:58:45 | train] - Train Epoch: [121] [1152000/1281167 (90%)]	Loss: 0.646439
[2022-04-05 20:59:14 | train] - Train Epoch: [121] [1164800/1281167 (91%)]	Loss: 0.800884
[2022-04-05 20:59:43 | train] - Train Epoch: [121] [1177600/1281167 (92%)]	Loss: 1.194672
[2022-04-05 21:00:14 | train] - Train Epoch: [121] [1190400/1281167 (93%)]	Loss: 0.686492
[2022-04-05 21:00:44 | train] - Train Epoch: [121] [1203200/1281167 (94%)]	Loss: 0.711721
[2022-04-05 21:01:15 | train] - Train Epoch: [121] [1216000/1281167 (95%)]	Loss: 0.547231
[2022-04-05 21:01:45 | train] - Train Epoch: [121] [1228800/1281167 (96%)]	Loss: 0.599489
[2022-04-05 21:02:17 | train] - Train Epoch: [121] [1241600/1281167 (97%)]	Loss: 0.923033
[2022-04-05 21:02:48 | train] - Train Epoch: [121] [1254400/1281167 (98%)]	Loss: 0.528781
[2022-04-05 21:03:17 | train] - Train Epoch: [121] [1267200/1281167 (99%)]	Loss: 0.876020
[2022-04-05 21:03:45 | train] - Train Epoch: [121] [1280000/1281167 (100%)]	Loss: 0.779951
[2022-04-05 21:03:47 | train] - Train Epoch: [121]	 Average Loss: 0.722177	 Total Acc : 82.5396	 Total Top5 Acc : 93.6700
[2022-04-05 21:03:47 | train] - -------121 epoch end-----------
========================================
-------121 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-05 21:05:55 | train] - 
Epoch [121] Test set: Average loss: 1.4295, Accuracy: 34885/50000 (69.7414%), Top-5 Accuracy: 88.7744%

[2022-04-05 21:05:55 | train] - save intermediate epoch [121] result


[2022-04-05 21:05:56 | train] - logging best performance 121 epoch
[2022-04-05 21:05:57 | train] - -------122 epoch start-----------
========================================
----- test end -------------------------


logging best performance 121 epoch
[2022-04-05 21:05:59 | train] - Train Epoch: [122] [0/1281167 (0%)]	Loss: 0.655446
[2022-04-05 21:06:26 | train] - Train Epoch: [122] [12800/1281167 (1%)]	Loss: 0.687121
[2022-04-05 21:06:54 | train] - Train Epoch: [122] [25600/1281167 (2%)]	Loss: 0.708319
[2022-04-05 21:07:23 | train] - Train Epoch: [122] [38400/1281167 (3%)]	Loss: 0.420548
[2022-04-05 21:07:50 | train] - Train Epoch: [122] [51200/1281167 (4%)]	Loss: 0.573101
[2022-04-05 21:08:17 | train] - Train Epoch: [122] [64000/1281167 (5%)]	Loss: 0.688542
[2022-04-05 21:08:45 | train] - Train Epoch: [122] [76800/1281167 (6%)]	Loss: 0.720501
[2022-04-05 21:09:12 | train] - Train Epoch: [122] [89600/1281167 (7%)]	Loss: 0.697825
[2022-04-05 21:09:39 | train] - Train Epoch: [122] [102400/1281167 (8%)]	Loss: 0.672675
[2022-04-05 21:10:05 | train] - Train Epoch: [122] [115200/1281167 (9%)]	Loss: 0.558650
[2022-04-05 21:10:31 | train] - Train Epoch: [122] [128000/1281167 (10%)]	Loss: 0.884603
[2022-04-05 21:10:58 | train] - Train Epoch: [122] [140800/1281167 (11%)]	Loss: 0.693686
[2022-04-05 21:11:25 | train] - Train Epoch: [122] [153600/1281167 (12%)]	Loss: 0.590890
[2022-04-05 21:11:53 | train] - Train Epoch: [122] [166400/1281167 (13%)]	Loss: 1.027016
[2022-04-05 21:12:20 | train] - Train Epoch: [122] [179200/1281167 (14%)]	Loss: 0.736684
[2022-04-05 21:12:46 | train] - Train Epoch: [122] [192000/1281167 (15%)]	Loss: 0.912575
[2022-04-05 21:13:14 | train] - Train Epoch: [122] [204800/1281167 (16%)]	Loss: 0.636217
[2022-04-05 21:13:41 | train] - Train Epoch: [122] [217600/1281167 (17%)]	Loss: 0.764334
[2022-04-05 21:14:08 | train] - Train Epoch: [122] [230400/1281167 (18%)]	Loss: 0.673534
[2022-04-05 21:14:36 | train] - Train Epoch: [122] [243200/1281167 (19%)]	Loss: 0.657901
[2022-04-05 21:15:03 | train] - Train Epoch: [122] [256000/1281167 (20%)]	Loss: 0.570631
[2022-04-05 21:15:30 | train] - Train Epoch: [122] [268800/1281167 (21%)]	Loss: 0.676331
[2022-04-05 21:15:58 | train] - Train Epoch: [122] [281600/1281167 (22%)]	Loss: 0.920104
[2022-04-05 21:16:26 | train] - Train Epoch: [122] [294400/1281167 (23%)]	Loss: 0.886902
[2022-04-05 21:16:53 | train] - Train Epoch: [122] [307200/1281167 (24%)]	Loss: 0.729255
[2022-04-05 21:17:20 | train] - Train Epoch: [122] [320000/1281167 (25%)]	Loss: 0.915637
[2022-04-05 21:17:46 | train] - Train Epoch: [122] [332800/1281167 (26%)]	Loss: 0.651184
[2022-04-05 21:18:13 | train] - Train Epoch: [122] [345600/1281167 (27%)]	Loss: 0.843404
[2022-04-05 21:18:39 | train] - Train Epoch: [122] [358400/1281167 (28%)]	Loss: 0.574353
[2022-04-05 21:19:06 | train] - Train Epoch: [122] [371200/1281167 (29%)]	Loss: 0.835993
[2022-04-05 21:19:34 | train] - Train Epoch: [122] [384000/1281167 (30%)]	Loss: 0.815706
[2022-04-05 21:20:00 | train] - Train Epoch: [122] [396800/1281167 (31%)]	Loss: 0.671229
[2022-04-05 21:20:27 | train] - Train Epoch: [122] [409600/1281167 (32%)]	Loss: 0.492479
[2022-04-05 21:20:56 | train] - Train Epoch: [122] [422400/1281167 (33%)]	Loss: 0.713817
[2022-04-05 21:21:23 | train] - Train Epoch: [122] [435200/1281167 (34%)]	Loss: 0.829030
[2022-04-05 21:21:50 | train] - Train Epoch: [122] [448000/1281167 (35%)]	Loss: 0.836746
[2022-04-05 21:22:18 | train] - Train Epoch: [122] [460800/1281167 (36%)]	Loss: 0.700829
[2022-04-05 21:22:44 | train] - Train Epoch: [122] [473600/1281167 (37%)]	Loss: 0.747918
[2022-04-05 21:23:12 | train] - Train Epoch: [122] [486400/1281167 (38%)]	Loss: 0.783487
[2022-04-05 21:23:39 | train] - Train Epoch: [122] [499200/1281167 (39%)]	Loss: 0.810422
[2022-04-05 21:24:08 | train] - Train Epoch: [122] [512000/1281167 (40%)]	Loss: 0.650688
[2022-04-05 21:24:35 | train] - Train Epoch: [122] [524800/1281167 (41%)]	Loss: 0.570008
[2022-04-05 21:25:01 | train] - Train Epoch: [122] [537600/1281167 (42%)]	Loss: 0.950537
[2022-04-05 21:25:28 | train] - Train Epoch: [122] [550400/1281167 (43%)]	Loss: 0.888921
[2022-04-05 21:25:57 | train] - Train Epoch: [122] [563200/1281167 (44%)]	Loss: 0.729225
[2022-04-05 21:26:24 | train] - Train Epoch: [122] [576000/1281167 (45%)]	Loss: 0.806699
[2022-04-05 21:26:52 | train] - Train Epoch: [122] [588800/1281167 (46%)]	Loss: 0.733053
[2022-04-05 21:27:20 | train] - Train Epoch: [122] [601600/1281167 (47%)]	Loss: 0.680151
[2022-04-05 21:27:47 | train] - Train Epoch: [122] [614400/1281167 (48%)]	Loss: 0.745579
[2022-04-05 21:28:15 | train] - Train Epoch: [122] [627200/1281167 (49%)]	Loss: 0.975334
[2022-04-05 21:28:42 | train] - Train Epoch: [122] [640000/1281167 (50%)]	Loss: 0.617311
[2022-04-05 21:29:10 | train] - Train Epoch: [122] [652800/1281167 (51%)]	Loss: 0.653975
[2022-04-05 21:29:38 | train] - Train Epoch: [122] [665600/1281167 (52%)]	Loss: 0.832731
[2022-04-05 21:30:06 | train] - Train Epoch: [122] [678400/1281167 (53%)]	Loss: 0.723588
[2022-04-05 21:30:33 | train] - Train Epoch: [122] [691200/1281167 (54%)]	Loss: 1.080575
[2022-04-05 21:30:59 | train] - Train Epoch: [122] [704000/1281167 (55%)]	Loss: 0.749658
[2022-04-05 21:31:26 | train] - Train Epoch: [122] [716800/1281167 (56%)]	Loss: 0.644441
[2022-04-05 21:31:53 | train] - Train Epoch: [122] [729600/1281167 (57%)]	Loss: 0.535002
[2022-04-05 21:32:20 | train] - Train Epoch: [122] [742400/1281167 (58%)]	Loss: 0.916053
[2022-04-05 21:32:46 | train] - Train Epoch: [122] [755200/1281167 (59%)]	Loss: 0.491706
[2022-04-05 21:33:14 | train] - Train Epoch: [122] [768000/1281167 (60%)]	Loss: 0.637388
[2022-04-05 21:33:41 | train] - Train Epoch: [122] [780800/1281167 (61%)]	Loss: 0.666110
[2022-04-05 21:34:08 | train] - Train Epoch: [122] [793600/1281167 (62%)]	Loss: 0.812846
[2022-04-05 21:34:35 | train] - Train Epoch: [122] [806400/1281167 (63%)]	Loss: 0.691739
[2022-04-05 21:35:03 | train] - Train Epoch: [122] [819200/1281167 (64%)]	Loss: 0.597785
[2022-04-05 21:35:29 | train] - Train Epoch: [122] [832000/1281167 (65%)]	Loss: 0.551281
[2022-04-05 21:35:57 | train] - Train Epoch: [122] [844800/1281167 (66%)]	Loss: 0.760830
[2022-04-05 21:36:24 | train] - Train Epoch: [122] [857600/1281167 (67%)]	Loss: 0.757495
[2022-04-05 21:36:51 | train] - Train Epoch: [122] [870400/1281167 (68%)]	Loss: 0.945292
[2022-04-05 21:37:18 | train] - Train Epoch: [122] [883200/1281167 (69%)]	Loss: 0.587058
[2022-04-05 21:37:47 | train] - Train Epoch: [122] [896000/1281167 (70%)]	Loss: 0.986116
[2022-04-05 21:38:14 | train] - Train Epoch: [122] [908800/1281167 (71%)]	Loss: 0.590759
[2022-04-05 21:38:42 | train] - Train Epoch: [122] [921600/1281167 (72%)]	Loss: 0.586337
[2022-04-05 21:39:09 | train] - Train Epoch: [122] [934400/1281167 (73%)]	Loss: 0.865497
[2022-04-05 21:39:37 | train] - Train Epoch: [122] [947200/1281167 (74%)]	Loss: 0.638005
[2022-04-05 21:40:04 | train] - Train Epoch: [122] [960000/1281167 (75%)]	Loss: 0.844095
[2022-04-05 21:40:32 | train] - Train Epoch: [122] [972800/1281167 (76%)]	Loss: 0.806903
[2022-04-05 21:40:59 | train] - Train Epoch: [122] [985600/1281167 (77%)]	Loss: 0.809144
[2022-04-05 21:41:27 | train] - Train Epoch: [122] [998400/1281167 (78%)]	Loss: 0.692606
[2022-04-05 21:41:54 | train] - Train Epoch: [122] [1011200/1281167 (79%)]	Loss: 0.773560
[2022-04-05 21:42:22 | train] - Train Epoch: [122] [1024000/1281167 (80%)]	Loss: 0.832271
[2022-04-05 21:42:49 | train] - Train Epoch: [122] [1036800/1281167 (81%)]	Loss: 0.779121
[2022-04-05 21:43:17 | train] - Train Epoch: [122] [1049600/1281167 (82%)]	Loss: 0.880036
[2022-04-05 21:43:44 | train] - Train Epoch: [122] [1062400/1281167 (83%)]	Loss: 0.880192
[2022-04-05 21:44:11 | train] - Train Epoch: [122] [1075200/1281167 (84%)]	Loss: 0.872149
[2022-04-05 21:44:39 | train] - Train Epoch: [122] [1088000/1281167 (85%)]	Loss: 0.481971
[2022-04-05 21:45:07 | train] - Train Epoch: [122] [1100800/1281167 (86%)]	Loss: 0.950499
[2022-04-05 21:45:35 | train] - Train Epoch: [122] [1113600/1281167 (87%)]	Loss: 0.814532
[2022-04-05 21:46:02 | train] - Train Epoch: [122] [1126400/1281167 (88%)]	Loss: 0.785201
[2022-04-05 21:46:29 | train] - Train Epoch: [122] [1139200/1281167 (89%)]	Loss: 0.773493
[2022-04-05 21:46:56 | train] - Train Epoch: [122] [1152000/1281167 (90%)]	Loss: 0.698445
[2022-04-05 21:47:23 | train] - Train Epoch: [122] [1164800/1281167 (91%)]	Loss: 0.617524
[2022-04-05 21:47:50 | train] - Train Epoch: [122] [1177600/1281167 (92%)]	Loss: 0.678040
[2022-04-05 21:48:17 | train] - Train Epoch: [122] [1190400/1281167 (93%)]	Loss: 0.710379
[2022-04-05 21:48:45 | train] - Train Epoch: [122] [1203200/1281167 (94%)]	Loss: 0.793235
[2022-04-05 21:49:13 | train] - Train Epoch: [122] [1216000/1281167 (95%)]	Loss: 0.771430
[2022-04-05 21:49:40 | train] - Train Epoch: [122] [1228800/1281167 (96%)]	Loss: 0.689053
[2022-04-05 21:50:07 | train] - Train Epoch: [122] [1241600/1281167 (97%)]	Loss: 0.600992
[2022-04-05 21:50:34 | train] - Train Epoch: [122] [1254400/1281167 (98%)]	Loss: 0.739770
[2022-04-05 21:51:01 | train] - Train Epoch: [122] [1267200/1281167 (99%)]	Loss: 0.761527
[2022-04-05 21:51:28 | train] - Train Epoch: [122] [1280000/1281167 (100%)]	Loss: 0.682800
[2022-04-05 21:51:31 | train] - Train Epoch: [122]	 Average Loss: 0.747212	 Total Acc : 81.8166	 Total Top5 Acc : 93.3877
[2022-04-05 21:51:31 | train] - -------122 epoch end-----------
========================================
-------122 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-05 21:53:37 | train] - 
Epoch [122] Test set: Average loss: 1.4331, Accuracy: 34861/50000 (69.6935%), Top-5 Accuracy: 88.7752%

[2022-04-05 21:53:37 | train] - save intermediate epoch [122] result


[2022-04-05 21:53:39 | train] - -------123 epoch start-----------
========================================
----- test end -------------------------


[2022-04-05 21:53:41 | train] - Train Epoch: [123] [0/1281167 (0%)]	Loss: 0.971954
[2022-04-05 21:54:09 | train] - Train Epoch: [123] [12800/1281167 (1%)]	Loss: 0.853033
[2022-04-05 21:54:36 | train] - Train Epoch: [123] [25600/1281167 (2%)]	Loss: 0.738407
[2022-04-05 21:55:05 | train] - Train Epoch: [123] [38400/1281167 (3%)]	Loss: 0.608894
[2022-04-05 21:55:33 | train] - Train Epoch: [123] [51200/1281167 (4%)]	Loss: 0.484342
[2022-04-05 21:56:01 | train] - Train Epoch: [123] [64000/1281167 (5%)]	Loss: 0.560370
[2022-04-05 21:56:28 | train] - Train Epoch: [123] [76800/1281167 (6%)]	Loss: 0.785639
[2022-04-05 21:56:56 | train] - Train Epoch: [123] [89600/1281167 (7%)]	Loss: 1.050344
[2022-04-05 21:57:24 | train] - Train Epoch: [123] [102400/1281167 (8%)]	Loss: 0.849525
[2022-04-05 21:57:52 | train] - Train Epoch: [123] [115200/1281167 (9%)]	Loss: 0.961489
[2022-04-05 21:58:21 | train] - Train Epoch: [123] [128000/1281167 (10%)]	Loss: 0.631948
[2022-04-05 21:58:48 | train] - Train Epoch: [123] [140800/1281167 (11%)]	Loss: 0.646465
[2022-04-05 21:59:17 | train] - Train Epoch: [123] [153600/1281167 (12%)]	Loss: 0.841544
[2022-04-05 21:59:45 | train] - Train Epoch: [123] [166400/1281167 (13%)]	Loss: 0.762280
[2022-04-05 22:00:13 | train] - Train Epoch: [123] [179200/1281167 (14%)]	Loss: 0.608675
[2022-04-05 22:00:41 | train] - Train Epoch: [123] [192000/1281167 (15%)]	Loss: 0.615101
[2022-04-05 22:01:10 | train] - Train Epoch: [123] [204800/1281167 (16%)]	Loss: 0.513254
[2022-04-05 22:01:38 | train] - Train Epoch: [123] [217600/1281167 (17%)]	Loss: 0.650870
[2022-04-05 22:02:06 | train] - Train Epoch: [123] [230400/1281167 (18%)]	Loss: 0.730782
[2022-04-05 22:02:35 | train] - Train Epoch: [123] [243200/1281167 (19%)]	Loss: 0.849320
[2022-04-05 22:03:04 | train] - Train Epoch: [123] [256000/1281167 (20%)]	Loss: 0.591520
[2022-04-05 22:03:32 | train] - Train Epoch: [123] [268800/1281167 (21%)]	Loss: 0.693693
[2022-04-05 22:04:01 | train] - Train Epoch: [123] [281600/1281167 (22%)]	Loss: 0.597446
[2022-04-05 22:04:28 | train] - Train Epoch: [123] [294400/1281167 (23%)]	Loss: 0.539147
[2022-04-05 22:04:56 | train] - Train Epoch: [123] [307200/1281167 (24%)]	Loss: 0.829601
[2022-04-05 22:05:25 | train] - Train Epoch: [123] [320000/1281167 (25%)]	Loss: 0.796486
[2022-04-05 22:05:53 | train] - Train Epoch: [123] [332800/1281167 (26%)]	Loss: 0.899071
[2022-04-05 22:06:21 | train] - Train Epoch: [123] [345600/1281167 (27%)]	Loss: 0.744892
[2022-04-05 22:06:49 | train] - Train Epoch: [123] [358400/1281167 (28%)]	Loss: 0.949629
[2022-04-05 22:07:16 | train] - Train Epoch: [123] [371200/1281167 (29%)]	Loss: 1.006172
[2022-04-05 22:07:44 | train] - Train Epoch: [123] [384000/1281167 (30%)]	Loss: 0.622857
[2022-04-05 22:08:12 | train] - Train Epoch: [123] [396800/1281167 (31%)]	Loss: 0.629521
[2022-04-05 22:08:41 | train] - Train Epoch: [123] [409600/1281167 (32%)]	Loss: 0.772308
[2022-04-05 22:09:08 | train] - Train Epoch: [123] [422400/1281167 (33%)]	Loss: 0.711117
[2022-04-05 22:09:36 | train] - Train Epoch: [123] [435200/1281167 (34%)]	Loss: 0.643909
[2022-04-05 22:10:05 | train] - Train Epoch: [123] [448000/1281167 (35%)]	Loss: 0.873554
[2022-04-05 22:10:33 | train] - Train Epoch: [123] [460800/1281167 (36%)]	Loss: 0.822602
[2022-04-05 22:11:00 | train] - Train Epoch: [123] [473600/1281167 (37%)]	Loss: 0.700833
[2022-04-05 22:11:29 | train] - Train Epoch: [123] [486400/1281167 (38%)]	Loss: 0.616936
[2022-04-05 22:11:57 | train] - Train Epoch: [123] [499200/1281167 (39%)]	Loss: 0.586540
[2022-04-05 22:12:24 | train] - Train Epoch: [123] [512000/1281167 (40%)]	Loss: 0.828107
[2022-04-05 22:12:52 | train] - Train Epoch: [123] [524800/1281167 (41%)]	Loss: 0.641182
[2022-04-05 22:13:19 | train] - Train Epoch: [123] [537600/1281167 (42%)]	Loss: 0.528297
[2022-04-05 22:13:48 | train] - Train Epoch: [123] [550400/1281167 (43%)]	Loss: 0.687903
[2022-04-05 22:14:16 | train] - Train Epoch: [123] [563200/1281167 (44%)]	Loss: 0.908642
[2022-04-05 22:14:45 | train] - Train Epoch: [123] [576000/1281167 (45%)]	Loss: 0.704552
[2022-04-05 22:15:12 | train] - Train Epoch: [123] [588800/1281167 (46%)]	Loss: 0.486773
[2022-04-05 22:15:39 | train] - Train Epoch: [123] [601600/1281167 (47%)]	Loss: 0.780141
[2022-04-05 22:16:07 | train] - Train Epoch: [123] [614400/1281167 (48%)]	Loss: 0.916964
[2022-04-05 22:16:34 | train] - Train Epoch: [123] [627200/1281167 (49%)]	Loss: 0.704430
[2022-04-05 22:17:03 | train] - Train Epoch: [123] [640000/1281167 (50%)]	Loss: 0.565283
[2022-04-05 22:17:31 | train] - Train Epoch: [123] [652800/1281167 (51%)]	Loss: 0.573922
[2022-04-05 22:17:59 | train] - Train Epoch: [123] [665600/1281167 (52%)]	Loss: 0.532093
[2022-04-05 22:18:27 | train] - Train Epoch: [123] [678400/1281167 (53%)]	Loss: 0.862103
[2022-04-05 22:18:55 | train] - Train Epoch: [123] [691200/1281167 (54%)]	Loss: 0.645419
[2022-04-05 22:19:23 | train] - Train Epoch: [123] [704000/1281167 (55%)]	Loss: 0.961644
[2022-04-05 22:19:50 | train] - Train Epoch: [123] [716800/1281167 (56%)]	Loss: 0.966095
[2022-04-05 22:20:18 | train] - Train Epoch: [123] [729600/1281167 (57%)]	Loss: 0.658460
[2022-04-05 22:20:46 | train] - Train Epoch: [123] [742400/1281167 (58%)]	Loss: 0.789087
[2022-04-05 22:21:14 | train] - Train Epoch: [123] [755200/1281167 (59%)]	Loss: 0.688878
[2022-04-05 22:21:42 | train] - Train Epoch: [123] [768000/1281167 (60%)]	Loss: 0.766200
[2022-04-05 22:22:10 | train] - Train Epoch: [123] [780800/1281167 (61%)]	Loss: 0.829530
[2022-04-05 22:22:38 | train] - Train Epoch: [123] [793600/1281167 (62%)]	Loss: 0.712041
[2022-04-05 22:23:06 | train] - Train Epoch: [123] [806400/1281167 (63%)]	Loss: 0.590602
[2022-04-05 22:23:34 | train] - Train Epoch: [123] [819200/1281167 (64%)]	Loss: 0.692334
[2022-04-05 22:24:01 | train] - Train Epoch: [123] [832000/1281167 (65%)]	Loss: 0.789224
[2022-04-05 22:24:28 | train] - Train Epoch: [123] [844800/1281167 (66%)]	Loss: 0.566900
[2022-04-05 22:24:57 | train] - Train Epoch: [123] [857600/1281167 (67%)]	Loss: 0.723247
[2022-04-05 22:25:24 | train] - Train Epoch: [123] [870400/1281167 (68%)]	Loss: 0.858850
[2022-04-05 22:25:52 | train] - Train Epoch: [123] [883200/1281167 (69%)]	Loss: 0.782313
[2022-04-05 22:26:21 | train] - Train Epoch: [123] [896000/1281167 (70%)]	Loss: 0.862088
[2022-04-05 22:26:48 | train] - Train Epoch: [123] [908800/1281167 (71%)]	Loss: 0.644684
[2022-04-05 22:27:16 | train] - Train Epoch: [123] [921600/1281167 (72%)]	Loss: 0.827465
[2022-04-05 22:27:44 | train] - Train Epoch: [123] [934400/1281167 (73%)]	Loss: 0.673015
[2022-04-05 22:28:12 | train] - Train Epoch: [123] [947200/1281167 (74%)]	Loss: 0.867601
[2022-04-05 22:28:41 | train] - Train Epoch: [123] [960000/1281167 (75%)]	Loss: 0.703126
[2022-04-05 22:29:09 | train] - Train Epoch: [123] [972800/1281167 (76%)]	Loss: 0.732440
[2022-04-05 22:29:37 | train] - Train Epoch: [123] [985600/1281167 (77%)]	Loss: 0.730141
[2022-04-05 22:30:05 | train] - Train Epoch: [123] [998400/1281167 (78%)]	Loss: 0.654864
[2022-04-05 22:30:33 | train] - Train Epoch: [123] [1011200/1281167 (79%)]	Loss: 0.485868
[2022-04-05 22:31:01 | train] - Train Epoch: [123] [1024000/1281167 (80%)]	Loss: 0.701960
[2022-04-05 22:31:29 | train] - Train Epoch: [123] [1036800/1281167 (81%)]	Loss: 0.818663
[2022-04-05 22:31:57 | train] - Train Epoch: [123] [1049600/1281167 (82%)]	Loss: 0.732359
[2022-04-05 22:32:25 | train] - Train Epoch: [123] [1062400/1281167 (83%)]	Loss: 0.603337
[2022-04-05 22:32:53 | train] - Train Epoch: [123] [1075200/1281167 (84%)]	Loss: 0.675790
[2022-04-05 22:33:21 | train] - Train Epoch: [123] [1088000/1281167 (85%)]	Loss: 0.601820
[2022-04-05 22:33:49 | train] - Train Epoch: [123] [1100800/1281167 (86%)]	Loss: 0.715574
[2022-04-05 22:34:17 | train] - Train Epoch: [123] [1113600/1281167 (87%)]	Loss: 0.732920
[2022-04-05 22:34:46 | train] - Train Epoch: [123] [1126400/1281167 (88%)]	Loss: 0.694484
[2022-04-05 22:35:13 | train] - Train Epoch: [123] [1139200/1281167 (89%)]	Loss: 0.757114
[2022-04-05 22:35:41 | train] - Train Epoch: [123] [1152000/1281167 (90%)]	Loss: 0.758969
[2022-04-05 22:36:09 | train] - Train Epoch: [123] [1164800/1281167 (91%)]	Loss: 0.934595
[2022-04-05 22:36:38 | train] - Train Epoch: [123] [1177600/1281167 (92%)]	Loss: 0.891622
[2022-04-05 22:37:06 | train] - Train Epoch: [123] [1190400/1281167 (93%)]	Loss: 0.648128
[2022-04-05 22:37:35 | train] - Train Epoch: [123] [1203200/1281167 (94%)]	Loss: 0.944841
[2022-04-05 22:38:04 | train] - Train Epoch: [123] [1216000/1281167 (95%)]	Loss: 0.897522
[2022-04-05 22:38:32 | train] - Train Epoch: [123] [1228800/1281167 (96%)]	Loss: 0.919534
[2022-04-05 22:39:00 | train] - Train Epoch: [123] [1241600/1281167 (97%)]	Loss: 0.419100
[2022-04-05 22:39:28 | train] - Train Epoch: [123] [1254400/1281167 (98%)]	Loss: 0.942744
[2022-04-05 22:39:56 | train] - Train Epoch: [123] [1267200/1281167 (99%)]	Loss: 0.866664
[2022-04-05 22:40:26 | train] - Train Epoch: [123] [1280000/1281167 (100%)]	Loss: 0.594168
[2022-04-05 22:40:28 | train] - Train Epoch: [123]	 Average Loss: 0.740015	 Total Acc : 82.0036	 Total Top5 Acc : 93.4580
[2022-04-05 22:40:28 | train] - -------123 epoch end-----------
========================================
-------123 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-05 22:42:32 | train] - 
Epoch [123] Test set: Average loss: 1.4363, Accuracy: 34883/50000 (69.7399%), Top-5 Accuracy: 88.7552%

[2022-04-05 22:42:32 | train] - save intermediate epoch [123] result


[2022-04-05 22:42:35 | train] - -------124 epoch start-----------
========================================
----- test end -------------------------


[2022-04-05 22:42:36 | train] - Train Epoch: [124] [0/1281167 (0%)]	Loss: 0.758748
[2022-04-05 22:43:03 | train] - Train Epoch: [124] [12800/1281167 (1%)]	Loss: 0.601371
[2022-04-05 22:43:31 | train] - Train Epoch: [124] [25600/1281167 (2%)]	Loss: 0.809865
[2022-04-05 22:43:59 | train] - Train Epoch: [124] [38400/1281167 (3%)]	Loss: 0.729004
[2022-04-05 22:44:27 | train] - Train Epoch: [124] [51200/1281167 (4%)]	Loss: 0.659360
[2022-04-05 22:44:55 | train] - Train Epoch: [124] [64000/1281167 (5%)]	Loss: 0.902623
[2022-04-05 22:45:24 | train] - Train Epoch: [124] [76800/1281167 (6%)]	Loss: 0.556888
[2022-04-05 22:45:51 | train] - Train Epoch: [124] [89600/1281167 (7%)]	Loss: 0.618538
[2022-04-05 22:46:20 | train] - Train Epoch: [124] [102400/1281167 (8%)]	Loss: 0.773995
[2022-04-05 22:46:47 | train] - Train Epoch: [124] [115200/1281167 (9%)]	Loss: 0.624028
[2022-04-05 22:47:15 | train] - Train Epoch: [124] [128000/1281167 (10%)]	Loss: 0.969624
[2022-04-05 22:47:43 | train] - Train Epoch: [124] [140800/1281167 (11%)]	Loss: 0.705060
[2022-04-05 22:48:10 | train] - Train Epoch: [124] [153600/1281167 (12%)]	Loss: 0.855248
[2022-04-05 22:48:38 | train] - Train Epoch: [124] [166400/1281167 (13%)]	Loss: 0.674390
[2022-04-05 22:49:05 | train] - Train Epoch: [124] [179200/1281167 (14%)]	Loss: 0.874204
[2022-04-05 22:49:33 | train] - Train Epoch: [124] [192000/1281167 (15%)]	Loss: 0.748638
[2022-04-05 22:50:00 | train] - Train Epoch: [124] [204800/1281167 (16%)]	Loss: 0.812222
[2022-04-05 22:50:28 | train] - Train Epoch: [124] [217600/1281167 (17%)]	Loss: 0.923336
[2022-04-05 22:50:56 | train] - Train Epoch: [124] [230400/1281167 (18%)]	Loss: 0.602691
[2022-04-05 22:51:23 | train] - Train Epoch: [124] [243200/1281167 (19%)]	Loss: 0.691196
[2022-04-05 22:51:52 | train] - Train Epoch: [124] [256000/1281167 (20%)]	Loss: 0.609007
[2022-04-05 22:52:19 | train] - Train Epoch: [124] [268800/1281167 (21%)]	Loss: 0.839368
[2022-04-05 22:52:47 | train] - Train Epoch: [124] [281600/1281167 (22%)]	Loss: 1.130841
[2022-04-05 22:53:15 | train] - Train Epoch: [124] [294400/1281167 (23%)]	Loss: 0.503957
[2022-04-05 22:53:43 | train] - Train Epoch: [124] [307200/1281167 (24%)]	Loss: 0.697669
[2022-04-05 22:54:11 | train] - Train Epoch: [124] [320000/1281167 (25%)]	Loss: 0.668419
[2022-04-05 22:54:39 | train] - Train Epoch: [124] [332800/1281167 (26%)]	Loss: 0.767447
[2022-04-05 22:55:07 | train] - Train Epoch: [124] [345600/1281167 (27%)]	Loss: 0.927076
[2022-04-05 22:55:35 | train] - Train Epoch: [124] [358400/1281167 (28%)]	Loss: 0.814527
[2022-04-05 22:56:02 | train] - Train Epoch: [124] [371200/1281167 (29%)]	Loss: 0.697946
[2022-04-05 22:56:30 | train] - Train Epoch: [124] [384000/1281167 (30%)]	Loss: 1.062825
[2022-04-05 22:56:58 | train] - Train Epoch: [124] [396800/1281167 (31%)]	Loss: 0.435456
[2022-04-05 22:57:26 | train] - Train Epoch: [124] [409600/1281167 (32%)]	Loss: 0.758893
[2022-04-05 22:57:53 | train] - Train Epoch: [124] [422400/1281167 (33%)]	Loss: 0.817792
[2022-04-05 22:58:21 | train] - Train Epoch: [124] [435200/1281167 (34%)]	Loss: 0.756504
[2022-04-05 22:58:49 | train] - Train Epoch: [124] [448000/1281167 (35%)]	Loss: 0.804256
[2022-04-05 22:59:17 | train] - Train Epoch: [124] [460800/1281167 (36%)]	Loss: 0.708008
[2022-04-05 22:59:45 | train] - Train Epoch: [124] [473600/1281167 (37%)]	Loss: 0.415203
[2022-04-05 23:00:14 | train] - Train Epoch: [124] [486400/1281167 (38%)]	Loss: 0.592325
[2022-04-05 23:00:42 | train] - Train Epoch: [124] [499200/1281167 (39%)]	Loss: 0.903602
[2022-04-05 23:01:10 | train] - Train Epoch: [124] [512000/1281167 (40%)]	Loss: 1.256022
[2022-04-05 23:01:39 | train] - Train Epoch: [124] [524800/1281167 (41%)]	Loss: 0.675935
[2022-04-05 23:02:07 | train] - Train Epoch: [124] [537600/1281167 (42%)]	Loss: 0.745960
[2022-04-05 23:02:34 | train] - Train Epoch: [124] [550400/1281167 (43%)]	Loss: 0.549960
[2022-04-05 23:03:02 | train] - Train Epoch: [124] [563200/1281167 (44%)]	Loss: 0.639815
[2022-04-05 23:03:29 | train] - Train Epoch: [124] [576000/1281167 (45%)]	Loss: 0.781212
[2022-04-05 23:03:58 | train] - Train Epoch: [124] [588800/1281167 (46%)]	Loss: 0.860557
[2022-04-05 23:04:25 | train] - Train Epoch: [124] [601600/1281167 (47%)]	Loss: 0.746704
[2022-04-05 23:04:52 | train] - Train Epoch: [124] [614400/1281167 (48%)]	Loss: 0.654284
[2022-04-05 23:05:20 | train] - Train Epoch: [124] [627200/1281167 (49%)]	Loss: 0.866726
[2022-04-05 23:05:47 | train] - Train Epoch: [124] [640000/1281167 (50%)]	Loss: 1.053048
[2022-04-05 23:06:15 | train] - Train Epoch: [124] [652800/1281167 (51%)]	Loss: 0.730345
[2022-04-05 23:06:43 | train] - Train Epoch: [124] [665600/1281167 (52%)]	Loss: 0.612165
[2022-04-05 23:07:11 | train] - Train Epoch: [124] [678400/1281167 (53%)]	Loss: 0.657330
[2022-04-05 23:07:38 | train] - Train Epoch: [124] [691200/1281167 (54%)]	Loss: 0.488718
[2022-04-05 23:08:06 | train] - Train Epoch: [124] [704000/1281167 (55%)]	Loss: 0.446550
[2022-04-05 23:08:34 | train] - Train Epoch: [124] [716800/1281167 (56%)]	Loss: 0.846730
[2022-04-05 23:09:01 | train] - Train Epoch: [124] [729600/1281167 (57%)]	Loss: 1.015016
[2022-04-05 23:09:29 | train] - Train Epoch: [124] [742400/1281167 (58%)]	Loss: 0.752942
[2022-04-05 23:09:56 | train] - Train Epoch: [124] [755200/1281167 (59%)]	Loss: 0.822712
[2022-04-05 23:10:24 | train] - Train Epoch: [124] [768000/1281167 (60%)]	Loss: 0.474172
[2022-04-05 23:10:51 | train] - Train Epoch: [124] [780800/1281167 (61%)]	Loss: 0.909588
[2022-04-05 23:11:20 | train] - Train Epoch: [124] [793600/1281167 (62%)]	Loss: 0.710679
[2022-04-05 23:11:48 | train] - Train Epoch: [124] [806400/1281167 (63%)]	Loss: 0.943347
[2022-04-05 23:12:15 | train] - Train Epoch: [124] [819200/1281167 (64%)]	Loss: 0.768758
[2022-04-05 23:12:44 | train] - Train Epoch: [124] [832000/1281167 (65%)]	Loss: 0.650056
[2022-04-05 23:13:12 | train] - Train Epoch: [124] [844800/1281167 (66%)]	Loss: 0.686710
[2022-04-05 23:13:40 | train] - Train Epoch: [124] [857600/1281167 (67%)]	Loss: 0.549582
[2022-04-05 23:14:08 | train] - Train Epoch: [124] [870400/1281167 (68%)]	Loss: 0.741308
[2022-04-05 23:14:37 | train] - Train Epoch: [124] [883200/1281167 (69%)]	Loss: 0.800581
[2022-04-05 23:15:04 | train] - Train Epoch: [124] [896000/1281167 (70%)]	Loss: 0.783124
[2022-04-05 23:15:32 | train] - Train Epoch: [124] [908800/1281167 (71%)]	Loss: 0.702329
[2022-04-05 23:16:00 | train] - Train Epoch: [124] [921600/1281167 (72%)]	Loss: 0.812452
[2022-04-05 23:16:29 | train] - Train Epoch: [124] [934400/1281167 (73%)]	Loss: 0.771453
[2022-04-05 23:16:58 | train] - Train Epoch: [124] [947200/1281167 (74%)]	Loss: 0.867664
[2022-04-05 23:17:27 | train] - Train Epoch: [124] [960000/1281167 (75%)]	Loss: 0.898375
[2022-04-05 23:17:55 | train] - Train Epoch: [124] [972800/1281167 (76%)]	Loss: 0.767429
[2022-04-05 23:18:23 | train] - Train Epoch: [124] [985600/1281167 (77%)]	Loss: 0.693488
[2022-04-05 23:18:51 | train] - Train Epoch: [124] [998400/1281167 (78%)]	Loss: 0.792081
[2022-04-05 23:19:19 | train] - Train Epoch: [124] [1011200/1281167 (79%)]	Loss: 0.668627
[2022-04-05 23:19:47 | train] - Train Epoch: [124] [1024000/1281167 (80%)]	Loss: 0.645241
[2022-04-05 23:20:14 | train] - Train Epoch: [124] [1036800/1281167 (81%)]	Loss: 0.510131
[2022-04-05 23:20:42 | train] - Train Epoch: [124] [1049600/1281167 (82%)]	Loss: 0.699738
[2022-04-05 23:21:10 | train] - Train Epoch: [124] [1062400/1281167 (83%)]	Loss: 0.819110
[2022-04-05 23:21:38 | train] - Train Epoch: [124] [1075200/1281167 (84%)]	Loss: 0.766876
[2022-04-05 23:22:05 | train] - Train Epoch: [124] [1088000/1281167 (85%)]	Loss: 0.826770
[2022-04-05 23:22:33 | train] - Train Epoch: [124] [1100800/1281167 (86%)]	Loss: 0.686162
[2022-04-05 23:23:01 | train] - Train Epoch: [124] [1113600/1281167 (87%)]	Loss: 0.523876
[2022-04-05 23:23:29 | train] - Train Epoch: [124] [1126400/1281167 (88%)]	Loss: 0.785902
[2022-04-05 23:23:58 | train] - Train Epoch: [124] [1139200/1281167 (89%)]	Loss: 0.550145
[2022-04-05 23:24:25 | train] - Train Epoch: [124] [1152000/1281167 (90%)]	Loss: 0.644190
[2022-04-05 23:24:53 | train] - Train Epoch: [124] [1164800/1281167 (91%)]	Loss: 0.839727
[2022-04-05 23:25:21 | train] - Train Epoch: [124] [1177600/1281167 (92%)]	Loss: 0.674983
[2022-04-05 23:25:49 | train] - Train Epoch: [124] [1190400/1281167 (93%)]	Loss: 0.978366
[2022-04-05 23:26:18 | train] - Train Epoch: [124] [1203200/1281167 (94%)]	Loss: 0.491754
[2022-04-05 23:26:47 | train] - Train Epoch: [124] [1216000/1281167 (95%)]	Loss: 0.754954
[2022-04-05 23:27:16 | train] - Train Epoch: [124] [1228800/1281167 (96%)]	Loss: 0.721892
[2022-04-05 23:27:43 | train] - Train Epoch: [124] [1241600/1281167 (97%)]	Loss: 0.677133
[2022-04-05 23:28:11 | train] - Train Epoch: [124] [1254400/1281167 (98%)]	Loss: 0.864253
[2022-04-05 23:28:39 | train] - Train Epoch: [124] [1267200/1281167 (99%)]	Loss: 0.698576
[2022-04-05 23:29:08 | train] - Train Epoch: [124] [1280000/1281167 (100%)]	Loss: 0.667632
[2022-04-05 23:29:10 | train] - Train Epoch: [124]	 Average Loss: 0.735450	 Total Acc : 82.0535	 Total Top5 Acc : 93.5307
[2022-04-05 23:29:10 | train] - -------124 epoch end-----------
========================================
-------124 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-05 23:31:12 | train] - 
Epoch [124] Test set: Average loss: 1.4226, Accuracy: 34921/50000 (69.8134%), Top-5 Accuracy: 88.8139%

[2022-04-05 23:31:12 | train] - save intermediate epoch [124] result


[2022-04-05 23:31:14 | train] - logging best performance 124 epoch
[2022-04-05 23:31:15 | train] - -------125 epoch start-----------
========================================
----- test end -------------------------


logging best performance 124 epoch
[2022-04-05 23:31:17 | train] - Train Epoch: [125] [0/1281167 (0%)]	Loss: 0.615797
[2022-04-05 23:31:43 | train] - Train Epoch: [125] [12800/1281167 (1%)]	Loss: 0.826467
[2022-04-05 23:32:09 | train] - Train Epoch: [125] [25600/1281167 (2%)]	Loss: 0.796692
[2022-04-05 23:32:35 | train] - Train Epoch: [125] [38400/1281167 (3%)]	Loss: 0.671742
[2022-04-05 23:33:00 | train] - Train Epoch: [125] [51200/1281167 (4%)]	Loss: 0.745134
[2022-04-05 23:33:26 | train] - Train Epoch: [125] [64000/1281167 (5%)]	Loss: 0.776805
[2022-04-05 23:33:52 | train] - Train Epoch: [125] [76800/1281167 (6%)]	Loss: 0.684287
[2022-04-05 23:34:18 | train] - Train Epoch: [125] [89600/1281167 (7%)]	Loss: 0.656039
[2022-04-05 23:34:42 | train] - Train Epoch: [125] [102400/1281167 (8%)]	Loss: 0.767505
[2022-04-05 23:35:10 | train] - Train Epoch: [125] [115200/1281167 (9%)]	Loss: 0.839510
[2022-04-05 23:35:36 | train] - Train Epoch: [125] [128000/1281167 (10%)]	Loss: 0.924668
[2022-04-05 23:36:02 | train] - Train Epoch: [125] [140800/1281167 (11%)]	Loss: 0.776140
[2022-04-05 23:36:28 | train] - Train Epoch: [125] [153600/1281167 (12%)]	Loss: 0.830302
[2022-04-05 23:36:54 | train] - Train Epoch: [125] [166400/1281167 (13%)]	Loss: 0.707939
[2022-04-05 23:37:19 | train] - Train Epoch: [125] [179200/1281167 (14%)]	Loss: 0.648089
[2022-04-05 23:37:46 | train] - Train Epoch: [125] [192000/1281167 (15%)]	Loss: 0.643866
[2022-04-05 23:38:11 | train] - Train Epoch: [125] [204800/1281167 (16%)]	Loss: 0.572365
[2022-04-05 23:38:37 | train] - Train Epoch: [125] [217600/1281167 (17%)]	Loss: 0.593764
[2022-04-05 23:39:03 | train] - Train Epoch: [125] [230400/1281167 (18%)]	Loss: 0.909044
[2022-04-05 23:39:29 | train] - Train Epoch: [125] [243200/1281167 (19%)]	Loss: 0.615532
[2022-04-05 23:39:55 | train] - Train Epoch: [125] [256000/1281167 (20%)]	Loss: 0.842562
[2022-04-05 23:40:21 | train] - Train Epoch: [125] [268800/1281167 (21%)]	Loss: 0.843985
[2022-04-05 23:40:48 | train] - Train Epoch: [125] [281600/1281167 (22%)]	Loss: 0.789329
[2022-04-05 23:41:14 | train] - Train Epoch: [125] [294400/1281167 (23%)]	Loss: 0.814863
[2022-04-05 23:41:39 | train] - Train Epoch: [125] [307200/1281167 (24%)]	Loss: 0.768616
[2022-04-05 23:42:06 | train] - Train Epoch: [125] [320000/1281167 (25%)]	Loss: 0.711527
[2022-04-05 23:42:32 | train] - Train Epoch: [125] [332800/1281167 (26%)]	Loss: 0.688597
[2022-04-05 23:42:58 | train] - Train Epoch: [125] [345600/1281167 (27%)]	Loss: 0.886776
[2022-04-05 23:43:25 | train] - Train Epoch: [125] [358400/1281167 (28%)]	Loss: 0.710771
[2022-04-05 23:43:50 | train] - Train Epoch: [125] [371200/1281167 (29%)]	Loss: 0.769662
[2022-04-05 23:44:16 | train] - Train Epoch: [125] [384000/1281167 (30%)]	Loss: 0.680656
[2022-04-05 23:44:41 | train] - Train Epoch: [125] [396800/1281167 (31%)]	Loss: 0.681485
[2022-04-05 23:45:06 | train] - Train Epoch: [125] [409600/1281167 (32%)]	Loss: 0.715695
[2022-04-05 23:45:32 | train] - Train Epoch: [125] [422400/1281167 (33%)]	Loss: 0.732287
[2022-04-05 23:45:59 | train] - Train Epoch: [125] [435200/1281167 (34%)]	Loss: 0.787333
[2022-04-05 23:46:25 | train] - Train Epoch: [125] [448000/1281167 (35%)]	Loss: 0.489789
[2022-04-05 23:46:51 | train] - Train Epoch: [125] [460800/1281167 (36%)]	Loss: 0.797569
[2022-04-05 23:47:16 | train] - Train Epoch: [125] [473600/1281167 (37%)]	Loss: 0.803125
[2022-04-05 23:47:42 | train] - Train Epoch: [125] [486400/1281167 (38%)]	Loss: 0.896209
[2022-04-05 23:48:08 | train] - Train Epoch: [125] [499200/1281167 (39%)]	Loss: 0.740555
[2022-04-05 23:48:33 | train] - Train Epoch: [125] [512000/1281167 (40%)]	Loss: 0.958096
[2022-04-05 23:48:59 | train] - Train Epoch: [125] [524800/1281167 (41%)]	Loss: 0.603402
[2022-04-05 23:49:25 | train] - Train Epoch: [125] [537600/1281167 (42%)]	Loss: 0.736384
[2022-04-05 23:49:50 | train] - Train Epoch: [125] [550400/1281167 (43%)]	Loss: 0.769517
[2022-04-05 23:50:17 | train] - Train Epoch: [125] [563200/1281167 (44%)]	Loss: 0.657520
[2022-04-05 23:50:43 | train] - Train Epoch: [125] [576000/1281167 (45%)]	Loss: 0.672118
[2022-04-05 23:51:09 | train] - Train Epoch: [125] [588800/1281167 (46%)]	Loss: 0.737907
[2022-04-05 23:51:35 | train] - Train Epoch: [125] [601600/1281167 (47%)]	Loss: 0.529859
[2022-04-05 23:52:01 | train] - Train Epoch: [125] [614400/1281167 (48%)]	Loss: 0.567646
[2022-04-05 23:52:26 | train] - Train Epoch: [125] [627200/1281167 (49%)]	Loss: 0.780911
[2022-04-05 23:52:52 | train] - Train Epoch: [125] [640000/1281167 (50%)]	Loss: 0.832592
[2022-04-05 23:53:18 | train] - Train Epoch: [125] [652800/1281167 (51%)]	Loss: 0.663731
[2022-04-05 23:53:44 | train] - Train Epoch: [125] [665600/1281167 (52%)]	Loss: 0.913707
[2022-04-05 23:54:09 | train] - Train Epoch: [125] [678400/1281167 (53%)]	Loss: 0.817021
[2022-04-05 23:54:36 | train] - Train Epoch: [125] [691200/1281167 (54%)]	Loss: 0.671859
[2022-04-05 23:55:01 | train] - Train Epoch: [125] [704000/1281167 (55%)]	Loss: 0.960226
[2022-04-05 23:55:27 | train] - Train Epoch: [125] [716800/1281167 (56%)]	Loss: 0.463448
[2022-04-05 23:55:53 | train] - Train Epoch: [125] [729600/1281167 (57%)]	Loss: 0.686705
[2022-04-05 23:56:18 | train] - Train Epoch: [125] [742400/1281167 (58%)]	Loss: 0.854663
[2022-04-05 23:56:44 | train] - Train Epoch: [125] [755200/1281167 (59%)]	Loss: 0.813727
[2022-04-05 23:57:10 | train] - Train Epoch: [125] [768000/1281167 (60%)]	Loss: 0.588597
[2022-04-05 23:57:35 | train] - Train Epoch: [125] [780800/1281167 (61%)]	Loss: 0.545613
[2022-04-05 23:58:01 | train] - Train Epoch: [125] [793600/1281167 (62%)]	Loss: 0.897708
[2022-04-05 23:58:27 | train] - Train Epoch: [125] [806400/1281167 (63%)]	Loss: 0.480548
[2022-04-05 23:58:53 | train] - Train Epoch: [125] [819200/1281167 (64%)]	Loss: 0.532979
[2022-04-05 23:59:19 | train] - Train Epoch: [125] [832000/1281167 (65%)]	Loss: 0.649615
[2022-04-05 23:59:44 | train] - Train Epoch: [125] [844800/1281167 (66%)]	Loss: 0.588732
[2022-04-06 00:00:10 | train] - Train Epoch: [125] [857600/1281167 (67%)]	Loss: 0.768373
[2022-04-06 00:00:36 | train] - Train Epoch: [125] [870400/1281167 (68%)]	Loss: 0.821837
[2022-04-06 00:01:02 | train] - Train Epoch: [125] [883200/1281167 (69%)]	Loss: 0.481327
[2022-04-06 00:01:28 | train] - Train Epoch: [125] [896000/1281167 (70%)]	Loss: 0.619918
[2022-04-06 00:01:53 | train] - Train Epoch: [125] [908800/1281167 (71%)]	Loss: 0.593405
[2022-04-06 00:02:18 | train] - Train Epoch: [125] [921600/1281167 (72%)]	Loss: 0.673672
[2022-04-06 00:02:45 | train] - Train Epoch: [125] [934400/1281167 (73%)]	Loss: 0.520925
[2022-04-06 00:03:09 | train] - Train Epoch: [125] [947200/1281167 (74%)]	Loss: 0.478798
[2022-04-06 00:03:35 | train] - Train Epoch: [125] [960000/1281167 (75%)]	Loss: 0.765044
[2022-04-06 00:04:01 | train] - Train Epoch: [125] [972800/1281167 (76%)]	Loss: 0.822838
[2022-04-06 00:04:28 | train] - Train Epoch: [125] [985600/1281167 (77%)]	Loss: 0.727875
[2022-04-06 00:04:53 | train] - Train Epoch: [125] [998400/1281167 (78%)]	Loss: 0.677999
[2022-04-06 00:05:18 | train] - Train Epoch: [125] [1011200/1281167 (79%)]	Loss: 0.613243
[2022-04-06 00:05:44 | train] - Train Epoch: [125] [1024000/1281167 (80%)]	Loss: 0.493521
[2022-04-06 00:06:09 | train] - Train Epoch: [125] [1036800/1281167 (81%)]	Loss: 0.825038
[2022-04-06 00:06:34 | train] - Train Epoch: [125] [1049600/1281167 (82%)]	Loss: 0.812663
[2022-04-06 00:07:00 | train] - Train Epoch: [125] [1062400/1281167 (83%)]	Loss: 0.803108
[2022-04-06 00:07:27 | train] - Train Epoch: [125] [1075200/1281167 (84%)]	Loss: 0.698578
[2022-04-06 00:07:52 | train] - Train Epoch: [125] [1088000/1281167 (85%)]	Loss: 0.679422
[2022-04-06 00:08:17 | train] - Train Epoch: [125] [1100800/1281167 (86%)]	Loss: 0.701731
[2022-04-06 00:08:42 | train] - Train Epoch: [125] [1113600/1281167 (87%)]	Loss: 0.747136
[2022-04-06 00:09:08 | train] - Train Epoch: [125] [1126400/1281167 (88%)]	Loss: 0.662037
[2022-04-06 00:09:33 | train] - Train Epoch: [125] [1139200/1281167 (89%)]	Loss: 0.843883
[2022-04-06 00:09:58 | train] - Train Epoch: [125] [1152000/1281167 (90%)]	Loss: 0.859104
[2022-04-06 00:10:24 | train] - Train Epoch: [125] [1164800/1281167 (91%)]	Loss: 0.646398
[2022-04-06 00:10:50 | train] - Train Epoch: [125] [1177600/1281167 (92%)]	Loss: 0.743968
[2022-04-06 00:11:16 | train] - Train Epoch: [125] [1190400/1281167 (93%)]	Loss: 0.684494
[2022-04-06 00:11:41 | train] - Train Epoch: [125] [1203200/1281167 (94%)]	Loss: 0.819203
[2022-04-06 00:12:07 | train] - Train Epoch: [125] [1216000/1281167 (95%)]	Loss: 0.732078
[2022-04-06 00:12:32 | train] - Train Epoch: [125] [1228800/1281167 (96%)]	Loss: 0.749386
[2022-04-06 00:12:59 | train] - Train Epoch: [125] [1241600/1281167 (97%)]	Loss: 0.833942
[2022-04-06 00:13:25 | train] - Train Epoch: [125] [1254400/1281167 (98%)]	Loss: 0.819736
[2022-04-06 00:13:51 | train] - Train Epoch: [125] [1267200/1281167 (99%)]	Loss: 0.606315
[2022-04-06 00:14:17 | train] - Train Epoch: [125] [1280000/1281167 (100%)]	Loss: 0.634996
[2022-04-06 00:14:19 | train] - Train Epoch: [125]	 Average Loss: 0.732141	 Total Acc : 82.1685	 Total Top5 Acc : 93.5540
[2022-04-06 00:14:19 | train] - -------125 epoch end-----------
========================================
-------125 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 00:16:14 | train] - 
Epoch [125] Test set: Average loss: 1.4408, Accuracy: 34911/50000 (69.7934%), Top-5 Accuracy: 88.7780%

[2022-04-06 00:16:14 | train] - save intermediate epoch [125] result


[2022-04-06 00:16:17 | train] - -------126 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 00:16:18 | train] - Train Epoch: [126] [0/1281167 (0%)]	Loss: 0.566278
[2022-04-06 00:16:45 | train] - Train Epoch: [126] [12800/1281167 (1%)]	Loss: 0.670646
[2022-04-06 00:17:12 | train] - Train Epoch: [126] [25600/1281167 (2%)]	Loss: 0.698139
[2022-04-06 00:17:39 | train] - Train Epoch: [126] [38400/1281167 (3%)]	Loss: 0.935107
[2022-04-06 00:18:05 | train] - Train Epoch: [126] [51200/1281167 (4%)]	Loss: 0.732277
[2022-04-06 00:18:31 | train] - Train Epoch: [126] [64000/1281167 (5%)]	Loss: 0.492237
[2022-04-06 00:18:58 | train] - Train Epoch: [126] [76800/1281167 (6%)]	Loss: 0.877994
[2022-04-06 00:19:24 | train] - Train Epoch: [126] [89600/1281167 (7%)]	Loss: 0.743570
[2022-04-06 00:19:50 | train] - Train Epoch: [126] [102400/1281167 (8%)]	Loss: 0.943972
[2022-04-06 00:20:17 | train] - Train Epoch: [126] [115200/1281167 (9%)]	Loss: 0.804949
[2022-04-06 00:20:44 | train] - Train Epoch: [126] [128000/1281167 (10%)]	Loss: 0.593441
[2022-04-06 00:21:11 | train] - Train Epoch: [126] [140800/1281167 (11%)]	Loss: 0.838145
[2022-04-06 00:21:37 | train] - Train Epoch: [126] [153600/1281167 (12%)]	Loss: 0.853959
[2022-04-06 00:22:04 | train] - Train Epoch: [126] [166400/1281167 (13%)]	Loss: 0.623076
[2022-04-06 00:22:31 | train] - Train Epoch: [126] [179200/1281167 (14%)]	Loss: 0.625786
[2022-04-06 00:22:57 | train] - Train Epoch: [126] [192000/1281167 (15%)]	Loss: 0.766417
[2022-04-06 00:23:24 | train] - Train Epoch: [126] [204800/1281167 (16%)]	Loss: 0.743426
[2022-04-06 00:23:50 | train] - Train Epoch: [126] [217600/1281167 (17%)]	Loss: 0.556700
[2022-04-06 00:24:18 | train] - Train Epoch: [126] [230400/1281167 (18%)]	Loss: 0.649681
[2022-04-06 00:24:45 | train] - Train Epoch: [126] [243200/1281167 (19%)]	Loss: 0.654481
[2022-04-06 00:25:12 | train] - Train Epoch: [126] [256000/1281167 (20%)]	Loss: 0.994912
[2022-04-06 00:25:38 | train] - Train Epoch: [126] [268800/1281167 (21%)]	Loss: 0.698754
[2022-04-06 00:26:05 | train] - Train Epoch: [126] [281600/1281167 (22%)]	Loss: 1.022314
[2022-04-06 00:26:32 | train] - Train Epoch: [126] [294400/1281167 (23%)]	Loss: 0.644385
[2022-04-06 00:26:58 | train] - Train Epoch: [126] [307200/1281167 (24%)]	Loss: 0.773209
[2022-04-06 00:27:25 | train] - Train Epoch: [126] [320000/1281167 (25%)]	Loss: 0.536149
[2022-04-06 00:27:52 | train] - Train Epoch: [126] [332800/1281167 (26%)]	Loss: 0.775836
[2022-04-06 00:28:19 | train] - Train Epoch: [126] [345600/1281167 (27%)]	Loss: 0.596994
[2022-04-06 00:28:46 | train] - Train Epoch: [126] [358400/1281167 (28%)]	Loss: 0.824543
[2022-04-06 00:29:13 | train] - Train Epoch: [126] [371200/1281167 (29%)]	Loss: 0.916262
[2022-04-06 00:29:40 | train] - Train Epoch: [126] [384000/1281167 (30%)]	Loss: 0.880420
[2022-04-06 00:30:07 | train] - Train Epoch: [126] [396800/1281167 (31%)]	Loss: 0.635274
[2022-04-06 00:30:35 | train] - Train Epoch: [126] [409600/1281167 (32%)]	Loss: 0.646215
[2022-04-06 00:31:02 | train] - Train Epoch: [126] [422400/1281167 (33%)]	Loss: 0.787838
[2022-04-06 00:31:28 | train] - Train Epoch: [126] [435200/1281167 (34%)]	Loss: 0.648657
[2022-04-06 00:31:55 | train] - Train Epoch: [126] [448000/1281167 (35%)]	Loss: 1.015218
[2022-04-06 00:32:21 | train] - Train Epoch: [126] [460800/1281167 (36%)]	Loss: 0.617839
[2022-04-06 00:32:48 | train] - Train Epoch: [126] [473600/1281167 (37%)]	Loss: 0.608709
[2022-04-06 00:33:14 | train] - Train Epoch: [126] [486400/1281167 (38%)]	Loss: 0.775009
[2022-04-06 00:33:41 | train] - Train Epoch: [126] [499200/1281167 (39%)]	Loss: 0.789690
[2022-04-06 00:34:07 | train] - Train Epoch: [126] [512000/1281167 (40%)]	Loss: 0.755370
[2022-04-06 00:34:34 | train] - Train Epoch: [126] [524800/1281167 (41%)]	Loss: 0.884045
[2022-04-06 00:35:00 | train] - Train Epoch: [126] [537600/1281167 (42%)]	Loss: 0.547148
[2022-04-06 00:35:26 | train] - Train Epoch: [126] [550400/1281167 (43%)]	Loss: 0.657013
[2022-04-06 00:35:53 | train] - Train Epoch: [126] [563200/1281167 (44%)]	Loss: 0.657287
[2022-04-06 00:36:19 | train] - Train Epoch: [126] [576000/1281167 (45%)]	Loss: 0.648554
[2022-04-06 00:36:46 | train] - Train Epoch: [126] [588800/1281167 (46%)]	Loss: 0.506743
[2022-04-06 00:37:12 | train] - Train Epoch: [126] [601600/1281167 (47%)]	Loss: 0.850929
[2022-04-06 00:37:40 | train] - Train Epoch: [126] [614400/1281167 (48%)]	Loss: 0.614980
[2022-04-06 00:38:07 | train] - Train Epoch: [126] [627200/1281167 (49%)]	Loss: 0.536168
[2022-04-06 00:38:34 | train] - Train Epoch: [126] [640000/1281167 (50%)]	Loss: 0.834356
[2022-04-06 00:39:00 | train] - Train Epoch: [126] [652800/1281167 (51%)]	Loss: 0.800692
[2022-04-06 00:39:28 | train] - Train Epoch: [126] [665600/1281167 (52%)]	Loss: 0.647356
[2022-04-06 00:39:55 | train] - Train Epoch: [126] [678400/1281167 (53%)]	Loss: 0.648234
[2022-04-06 00:40:21 | train] - Train Epoch: [126] [691200/1281167 (54%)]	Loss: 0.543544
[2022-04-06 00:40:48 | train] - Train Epoch: [126] [704000/1281167 (55%)]	Loss: 0.936906
[2022-04-06 00:41:15 | train] - Train Epoch: [126] [716800/1281167 (56%)]	Loss: 0.521625
[2022-04-06 00:41:42 | train] - Train Epoch: [126] [729600/1281167 (57%)]	Loss: 0.600850
[2022-04-06 00:42:09 | train] - Train Epoch: [126] [742400/1281167 (58%)]	Loss: 0.756385
[2022-04-06 00:42:36 | train] - Train Epoch: [126] [755200/1281167 (59%)]	Loss: 0.732116
[2022-04-06 00:43:03 | train] - Train Epoch: [126] [768000/1281167 (60%)]	Loss: 0.735628
[2022-04-06 00:43:30 | train] - Train Epoch: [126] [780800/1281167 (61%)]	Loss: 0.921453
[2022-04-06 00:43:57 | train] - Train Epoch: [126] [793600/1281167 (62%)]	Loss: 0.826041
[2022-04-06 00:44:24 | train] - Train Epoch: [126] [806400/1281167 (63%)]	Loss: 0.811401
[2022-04-06 00:44:51 | train] - Train Epoch: [126] [819200/1281167 (64%)]	Loss: 0.790615
[2022-04-06 00:45:17 | train] - Train Epoch: [126] [832000/1281167 (65%)]	Loss: 0.713442
[2022-04-06 00:45:43 | train] - Train Epoch: [126] [844800/1281167 (66%)]	Loss: 0.760491
[2022-04-06 00:46:09 | train] - Train Epoch: [126] [857600/1281167 (67%)]	Loss: 0.715751
[2022-04-06 00:46:36 | train] - Train Epoch: [126] [870400/1281167 (68%)]	Loss: 0.773282
[2022-04-06 00:47:01 | train] - Train Epoch: [126] [883200/1281167 (69%)]	Loss: 0.492242
[2022-04-06 00:47:28 | train] - Train Epoch: [126] [896000/1281167 (70%)]	Loss: 0.810999
[2022-04-06 00:47:54 | train] - Train Epoch: [126] [908800/1281167 (71%)]	Loss: 0.727966
[2022-04-06 00:48:21 | train] - Train Epoch: [126] [921600/1281167 (72%)]	Loss: 0.543575
[2022-04-06 00:48:48 | train] - Train Epoch: [126] [934400/1281167 (73%)]	Loss: 0.946531
[2022-04-06 00:49:15 | train] - Train Epoch: [126] [947200/1281167 (74%)]	Loss: 0.864872
[2022-04-06 00:49:41 | train] - Train Epoch: [126] [960000/1281167 (75%)]	Loss: 0.561229
[2022-04-06 00:50:07 | train] - Train Epoch: [126] [972800/1281167 (76%)]	Loss: 0.617426
[2022-04-06 00:50:33 | train] - Train Epoch: [126] [985600/1281167 (77%)]	Loss: 0.636257
[2022-04-06 00:51:00 | train] - Train Epoch: [126] [998400/1281167 (78%)]	Loss: 0.672495
[2022-04-06 00:51:26 | train] - Train Epoch: [126] [1011200/1281167 (79%)]	Loss: 0.845712
[2022-04-06 00:51:53 | train] - Train Epoch: [126] [1024000/1281167 (80%)]	Loss: 0.758671
[2022-04-06 00:52:19 | train] - Train Epoch: [126] [1036800/1281167 (81%)]	Loss: 0.651187
[2022-04-06 00:52:46 | train] - Train Epoch: [126] [1049600/1281167 (82%)]	Loss: 0.559411
[2022-04-06 00:53:12 | train] - Train Epoch: [126] [1062400/1281167 (83%)]	Loss: 0.837419
[2022-04-06 00:53:38 | train] - Train Epoch: [126] [1075200/1281167 (84%)]	Loss: 0.841976
[2022-04-06 00:54:05 | train] - Train Epoch: [126] [1088000/1281167 (85%)]	Loss: 0.649226
[2022-04-06 00:54:32 | train] - Train Epoch: [126] [1100800/1281167 (86%)]	Loss: 0.650483
[2022-04-06 00:54:59 | train] - Train Epoch: [126] [1113600/1281167 (87%)]	Loss: 0.610560
[2022-04-06 00:55:27 | train] - Train Epoch: [126] [1126400/1281167 (88%)]	Loss: 0.615903
[2022-04-06 00:55:54 | train] - Train Epoch: [126] [1139200/1281167 (89%)]	Loss: 0.724718
[2022-04-06 00:56:21 | train] - Train Epoch: [126] [1152000/1281167 (90%)]	Loss: 0.666320
[2022-04-06 00:56:47 | train] - Train Epoch: [126] [1164800/1281167 (91%)]	Loss: 0.388968
[2022-04-06 00:57:14 | train] - Train Epoch: [126] [1177600/1281167 (92%)]	Loss: 0.721251
[2022-04-06 00:57:42 | train] - Train Epoch: [126] [1190400/1281167 (93%)]	Loss: 0.658917
[2022-04-06 00:58:09 | train] - Train Epoch: [126] [1203200/1281167 (94%)]	Loss: 0.633127
[2022-04-06 00:58:36 | train] - Train Epoch: [126] [1216000/1281167 (95%)]	Loss: 0.842181
[2022-04-06 00:59:02 | train] - Train Epoch: [126] [1228800/1281167 (96%)]	Loss: 0.892512
[2022-04-06 00:59:29 | train] - Train Epoch: [126] [1241600/1281167 (97%)]	Loss: 0.649688
[2022-04-06 00:59:56 | train] - Train Epoch: [126] [1254400/1281167 (98%)]	Loss: 0.776849
[2022-04-06 01:00:23 | train] - Train Epoch: [126] [1267200/1281167 (99%)]	Loss: 0.566588
[2022-04-06 01:00:50 | train] - Train Epoch: [126] [1280000/1281167 (100%)]	Loss: 0.933454
[2022-04-06 01:00:52 | train] - Train Epoch: [126]	 Average Loss: 0.729613	 Total Acc : 82.2723	 Total Top5 Acc : 93.5912
[2022-04-06 01:00:52 | train] - -------126 epoch end-----------
========================================
-------126 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 01:02:52 | train] - 
Epoch [126] Test set: Average loss: 1.4340, Accuracy: 34968/50000 (69.9097%), Top-5 Accuracy: 88.8351%

[2022-04-06 01:02:52 | train] - save intermediate epoch [126] result


[2022-04-06 01:02:55 | train] - logging best performance 126 epoch
[2022-04-06 01:02:56 | train] - -------127 epoch start-----------
========================================
----- test end -------------------------


logging best performance 126 epoch
[2022-04-06 01:02:58 | train] - Train Epoch: [127] [0/1281167 (0%)]	Loss: 0.646873
[2022-04-06 01:03:25 | train] - Train Epoch: [127] [12800/1281167 (1%)]	Loss: 0.799111
[2022-04-06 01:03:51 | train] - Train Epoch: [127] [25600/1281167 (2%)]	Loss: 0.945687
[2022-04-06 01:04:18 | train] - Train Epoch: [127] [38400/1281167 (3%)]	Loss: 0.676451
[2022-04-06 01:04:44 | train] - Train Epoch: [127] [51200/1281167 (4%)]	Loss: 1.186184
[2022-04-06 01:05:11 | train] - Train Epoch: [127] [64000/1281167 (5%)]	Loss: 0.643664
[2022-04-06 01:05:37 | train] - Train Epoch: [127] [76800/1281167 (6%)]	Loss: 0.623022
[2022-04-06 01:06:04 | train] - Train Epoch: [127] [89600/1281167 (7%)]	Loss: 0.873730
[2022-04-06 01:06:31 | train] - Train Epoch: [127] [102400/1281167 (8%)]	Loss: 0.803239
[2022-04-06 01:06:57 | train] - Train Epoch: [127] [115200/1281167 (9%)]	Loss: 0.963096
[2022-04-06 01:07:24 | train] - Train Epoch: [127] [128000/1281167 (10%)]	Loss: 0.545296
[2022-04-06 01:07:50 | train] - Train Epoch: [127] [140800/1281167 (11%)]	Loss: 0.695810
[2022-04-06 01:08:16 | train] - Train Epoch: [127] [153600/1281167 (12%)]	Loss: 1.129055
[2022-04-06 01:08:43 | train] - Train Epoch: [127] [166400/1281167 (13%)]	Loss: 0.825983
[2022-04-06 01:09:10 | train] - Train Epoch: [127] [179200/1281167 (14%)]	Loss: 0.598276
[2022-04-06 01:09:37 | train] - Train Epoch: [127] [192000/1281167 (15%)]	Loss: 0.615460
[2022-04-06 01:10:03 | train] - Train Epoch: [127] [204800/1281167 (16%)]	Loss: 0.608318
[2022-04-06 01:10:29 | train] - Train Epoch: [127] [217600/1281167 (17%)]	Loss: 0.793863
[2022-04-06 01:10:57 | train] - Train Epoch: [127] [230400/1281167 (18%)]	Loss: 0.608849
[2022-04-06 01:11:23 | train] - Train Epoch: [127] [243200/1281167 (19%)]	Loss: 0.683616
[2022-04-06 01:11:50 | train] - Train Epoch: [127] [256000/1281167 (20%)]	Loss: 0.927872
[2022-04-06 01:12:17 | train] - Train Epoch: [127] [268800/1281167 (21%)]	Loss: 0.620596
[2022-04-06 01:12:44 | train] - Train Epoch: [127] [281600/1281167 (22%)]	Loss: 0.607226
[2022-04-06 01:13:11 | train] - Train Epoch: [127] [294400/1281167 (23%)]	Loss: 0.663301
[2022-04-06 01:13:37 | train] - Train Epoch: [127] [307200/1281167 (24%)]	Loss: 0.825973
[2022-04-06 01:14:03 | train] - Train Epoch: [127] [320000/1281167 (25%)]	Loss: 0.548815
[2022-04-06 01:14:29 | train] - Train Epoch: [127] [332800/1281167 (26%)]	Loss: 1.159072
[2022-04-06 01:14:56 | train] - Train Epoch: [127] [345600/1281167 (27%)]	Loss: 0.507903
[2022-04-06 01:15:23 | train] - Train Epoch: [127] [358400/1281167 (28%)]	Loss: 0.859745
[2022-04-06 01:15:49 | train] - Train Epoch: [127] [371200/1281167 (29%)]	Loss: 0.728993
[2022-04-06 01:16:15 | train] - Train Epoch: [127] [384000/1281167 (30%)]	Loss: 0.932788
[2022-04-06 01:16:41 | train] - Train Epoch: [127] [396800/1281167 (31%)]	Loss: 1.017943
[2022-04-06 01:17:08 | train] - Train Epoch: [127] [409600/1281167 (32%)]	Loss: 0.712547
[2022-04-06 01:17:34 | train] - Train Epoch: [127] [422400/1281167 (33%)]	Loss: 0.827591
[2022-04-06 01:18:00 | train] - Train Epoch: [127] [435200/1281167 (34%)]	Loss: 0.597078
[2022-04-06 01:18:26 | train] - Train Epoch: [127] [448000/1281167 (35%)]	Loss: 0.625326
[2022-04-06 01:18:53 | train] - Train Epoch: [127] [460800/1281167 (36%)]	Loss: 0.824937
[2022-04-06 01:19:20 | train] - Train Epoch: [127] [473600/1281167 (37%)]	Loss: 0.559613
[2022-04-06 01:19:47 | train] - Train Epoch: [127] [486400/1281167 (38%)]	Loss: 0.764364
[2022-04-06 01:20:15 | train] - Train Epoch: [127] [499200/1281167 (39%)]	Loss: 0.770543
[2022-04-06 01:20:42 | train] - Train Epoch: [127] [512000/1281167 (40%)]	Loss: 1.019202
[2022-04-06 01:21:08 | train] - Train Epoch: [127] [524800/1281167 (41%)]	Loss: 0.354583
[2022-04-06 01:21:35 | train] - Train Epoch: [127] [537600/1281167 (42%)]	Loss: 0.490649
[2022-04-06 01:22:01 | train] - Train Epoch: [127] [550400/1281167 (43%)]	Loss: 0.769363
[2022-04-06 01:22:28 | train] - Train Epoch: [127] [563200/1281167 (44%)]	Loss: 0.522673
[2022-04-06 01:22:54 | train] - Train Epoch: [127] [576000/1281167 (45%)]	Loss: 0.662133
[2022-04-06 01:23:21 | train] - Train Epoch: [127] [588800/1281167 (46%)]	Loss: 0.702809
[2022-04-06 01:23:47 | train] - Train Epoch: [127] [601600/1281167 (47%)]	Loss: 0.629707
[2022-04-06 01:24:14 | train] - Train Epoch: [127] [614400/1281167 (48%)]	Loss: 0.695395
[2022-04-06 01:24:40 | train] - Train Epoch: [127] [627200/1281167 (49%)]	Loss: 0.593369
[2022-04-06 01:25:06 | train] - Train Epoch: [127] [640000/1281167 (50%)]	Loss: 0.727875
[2022-04-06 01:25:32 | train] - Train Epoch: [127] [652800/1281167 (51%)]	Loss: 0.689372
[2022-04-06 01:25:59 | train] - Train Epoch: [127] [665600/1281167 (52%)]	Loss: 0.612000
[2022-04-06 01:26:26 | train] - Train Epoch: [127] [678400/1281167 (53%)]	Loss: 1.023244
[2022-04-06 01:26:52 | train] - Train Epoch: [127] [691200/1281167 (54%)]	Loss: 0.713319
[2022-04-06 01:27:19 | train] - Train Epoch: [127] [704000/1281167 (55%)]	Loss: 0.560485
[2022-04-06 01:27:45 | train] - Train Epoch: [127] [716800/1281167 (56%)]	Loss: 0.757838
[2022-04-06 01:28:12 | train] - Train Epoch: [127] [729600/1281167 (57%)]	Loss: 0.825477
[2022-04-06 01:28:39 | train] - Train Epoch: [127] [742400/1281167 (58%)]	Loss: 0.977795
[2022-04-06 01:29:04 | train] - Train Epoch: [127] [755200/1281167 (59%)]	Loss: 0.796313
[2022-04-06 01:29:31 | train] - Train Epoch: [127] [768000/1281167 (60%)]	Loss: 0.740992
[2022-04-06 01:29:58 | train] - Train Epoch: [127] [780800/1281167 (61%)]	Loss: 0.682038
[2022-04-06 01:30:26 | train] - Train Epoch: [127] [793600/1281167 (62%)]	Loss: 0.954562
[2022-04-06 01:30:54 | train] - Train Epoch: [127] [806400/1281167 (63%)]	Loss: 0.708668
[2022-04-06 01:31:20 | train] - Train Epoch: [127] [819200/1281167 (64%)]	Loss: 0.626831
[2022-04-06 01:31:47 | train] - Train Epoch: [127] [832000/1281167 (65%)]	Loss: 0.555742
[2022-04-06 01:32:15 | train] - Train Epoch: [127] [844800/1281167 (66%)]	Loss: 0.742841
[2022-04-06 01:32:42 | train] - Train Epoch: [127] [857600/1281167 (67%)]	Loss: 0.639436
[2022-04-06 01:33:09 | train] - Train Epoch: [127] [870400/1281167 (68%)]	Loss: 0.582453
[2022-04-06 01:33:37 | train] - Train Epoch: [127] [883200/1281167 (69%)]	Loss: 0.618398
[2022-04-06 01:34:04 | train] - Train Epoch: [127] [896000/1281167 (70%)]	Loss: 0.664906
[2022-04-06 01:34:30 | train] - Train Epoch: [127] [908800/1281167 (71%)]	Loss: 0.791100
[2022-04-06 01:34:58 | train] - Train Epoch: [127] [921600/1281167 (72%)]	Loss: 0.872479
[2022-04-06 01:35:25 | train] - Train Epoch: [127] [934400/1281167 (73%)]	Loss: 0.583865
[2022-04-06 01:35:52 | train] - Train Epoch: [127] [947200/1281167 (74%)]	Loss: 0.542919
[2022-04-06 01:36:19 | train] - Train Epoch: [127] [960000/1281167 (75%)]	Loss: 0.753399
[2022-04-06 01:36:46 | train] - Train Epoch: [127] [972800/1281167 (76%)]	Loss: 0.567860
[2022-04-06 01:37:13 | train] - Train Epoch: [127] [985600/1281167 (77%)]	Loss: 0.568341
[2022-04-06 01:37:41 | train] - Train Epoch: [127] [998400/1281167 (78%)]	Loss: 0.671311
[2022-04-06 01:38:08 | train] - Train Epoch: [127] [1011200/1281167 (79%)]	Loss: 0.603458
[2022-04-06 01:38:36 | train] - Train Epoch: [127] [1024000/1281167 (80%)]	Loss: 0.668444
[2022-04-06 01:39:03 | train] - Train Epoch: [127] [1036800/1281167 (81%)]	Loss: 0.709213
[2022-04-06 01:39:30 | train] - Train Epoch: [127] [1049600/1281167 (82%)]	Loss: 0.886067
[2022-04-06 01:39:57 | train] - Train Epoch: [127] [1062400/1281167 (83%)]	Loss: 0.534447
[2022-04-06 01:40:23 | train] - Train Epoch: [127] [1075200/1281167 (84%)]	Loss: 0.754218
[2022-04-06 01:40:50 | train] - Train Epoch: [127] [1088000/1281167 (85%)]	Loss: 0.960591
[2022-04-06 01:41:17 | train] - Train Epoch: [127] [1100800/1281167 (86%)]	Loss: 0.653302
[2022-04-06 01:41:44 | train] - Train Epoch: [127] [1113600/1281167 (87%)]	Loss: 0.646222
[2022-04-06 01:42:12 | train] - Train Epoch: [127] [1126400/1281167 (88%)]	Loss: 0.981709
[2022-04-06 01:42:39 | train] - Train Epoch: [127] [1139200/1281167 (89%)]	Loss: 0.651623
[2022-04-06 01:43:07 | train] - Train Epoch: [127] [1152000/1281167 (90%)]	Loss: 0.482834
[2022-04-06 01:43:34 | train] - Train Epoch: [127] [1164800/1281167 (91%)]	Loss: 0.773885
[2022-04-06 01:44:01 | train] - Train Epoch: [127] [1177600/1281167 (92%)]	Loss: 0.790354
[2022-04-06 01:44:28 | train] - Train Epoch: [127] [1190400/1281167 (93%)]	Loss: 0.523874
[2022-04-06 01:44:55 | train] - Train Epoch: [127] [1203200/1281167 (94%)]	Loss: 0.792318
[2022-04-06 01:45:23 | train] - Train Epoch: [127] [1216000/1281167 (95%)]	Loss: 0.806444
[2022-04-06 01:45:50 | train] - Train Epoch: [127] [1228800/1281167 (96%)]	Loss: 0.865991
[2022-04-06 01:46:17 | train] - Train Epoch: [127] [1241600/1281167 (97%)]	Loss: 0.819192
[2022-04-06 01:46:45 | train] - Train Epoch: [127] [1254400/1281167 (98%)]	Loss: 0.661283
[2022-04-06 01:47:12 | train] - Train Epoch: [127] [1267200/1281167 (99%)]	Loss: 0.695401
[2022-04-06 01:47:39 | train] - Train Epoch: [127] [1280000/1281167 (100%)]	Loss: 0.693554
[2022-04-06 01:47:41 | train] - Train Epoch: [127]	 Average Loss: 0.724193	 Total Acc : 82.3470	 Total Top5 Acc : 93.6367
[2022-04-06 01:47:41 | train] - -------127 epoch end-----------
========================================
-------127 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 01:49:38 | train] - 
Epoch [127] Test set: Average loss: 1.4316, Accuracy: 34908/50000 (69.7862%), Top-5 Accuracy: 88.8711%

[2022-04-06 01:49:38 | train] - save intermediate epoch [127] result


[2022-04-06 01:49:41 | train] - -------128 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 01:49:43 | train] - Train Epoch: [128] [0/1281167 (0%)]	Loss: 0.942500
[2022-04-06 01:50:11 | train] - Train Epoch: [128] [12800/1281167 (1%)]	Loss: 0.661223
[2022-04-06 01:50:39 | train] - Train Epoch: [128] [25600/1281167 (2%)]	Loss: 0.539711
[2022-04-06 01:51:07 | train] - Train Epoch: [128] [38400/1281167 (3%)]	Loss: 0.943365
[2022-04-06 01:51:35 | train] - Train Epoch: [128] [51200/1281167 (4%)]	Loss: 0.633844
[2022-04-06 01:52:04 | train] - Train Epoch: [128] [64000/1281167 (5%)]	Loss: 0.741234
[2022-04-06 01:52:32 | train] - Train Epoch: [128] [76800/1281167 (6%)]	Loss: 0.681678
[2022-04-06 01:53:01 | train] - Train Epoch: [128] [89600/1281167 (7%)]	Loss: 0.497560
[2022-04-06 01:53:29 | train] - Train Epoch: [128] [102400/1281167 (8%)]	Loss: 0.845112
[2022-04-06 01:53:58 | train] - Train Epoch: [128] [115200/1281167 (9%)]	Loss: 0.418021
[2022-04-06 01:54:26 | train] - Train Epoch: [128] [128000/1281167 (10%)]	Loss: 0.578801
[2022-04-06 01:54:55 | train] - Train Epoch: [128] [140800/1281167 (11%)]	Loss: 0.660210
[2022-04-06 01:55:22 | train] - Train Epoch: [128] [153600/1281167 (12%)]	Loss: 0.642960
[2022-04-06 01:55:50 | train] - Train Epoch: [128] [166400/1281167 (13%)]	Loss: 0.811388
[2022-04-06 01:56:17 | train] - Train Epoch: [128] [179200/1281167 (14%)]	Loss: 0.505308
[2022-04-06 01:56:46 | train] - Train Epoch: [128] [192000/1281167 (15%)]	Loss: 0.796233
[2022-04-06 01:57:14 | train] - Train Epoch: [128] [204800/1281167 (16%)]	Loss: 0.691970
[2022-04-06 01:57:42 | train] - Train Epoch: [128] [217600/1281167 (17%)]	Loss: 0.875464
[2022-04-06 01:58:09 | train] - Train Epoch: [128] [230400/1281167 (18%)]	Loss: 0.622683
[2022-04-06 01:58:37 | train] - Train Epoch: [128] [243200/1281167 (19%)]	Loss: 0.560524
[2022-04-06 01:59:05 | train] - Train Epoch: [128] [256000/1281167 (20%)]	Loss: 0.659250
[2022-04-06 01:59:33 | train] - Train Epoch: [128] [268800/1281167 (21%)]	Loss: 0.830305
[2022-04-06 02:00:01 | train] - Train Epoch: [128] [281600/1281167 (22%)]	Loss: 0.865621
[2022-04-06 02:00:30 | train] - Train Epoch: [128] [294400/1281167 (23%)]	Loss: 0.514464
[2022-04-06 02:00:58 | train] - Train Epoch: [128] [307200/1281167 (24%)]	Loss: 0.828329
[2022-04-06 02:01:26 | train] - Train Epoch: [128] [320000/1281167 (25%)]	Loss: 0.800978
[2022-04-06 02:01:54 | train] - Train Epoch: [128] [332800/1281167 (26%)]	Loss: 0.808543
[2022-04-06 02:02:22 | train] - Train Epoch: [128] [345600/1281167 (27%)]	Loss: 0.814977
[2022-04-06 02:02:49 | train] - Train Epoch: [128] [358400/1281167 (28%)]	Loss: 0.668006
[2022-04-06 02:03:17 | train] - Train Epoch: [128] [371200/1281167 (29%)]	Loss: 0.987134
[2022-04-06 02:03:46 | train] - Train Epoch: [128] [384000/1281167 (30%)]	Loss: 0.543277
[2022-04-06 02:04:13 | train] - Train Epoch: [128] [396800/1281167 (31%)]	Loss: 0.548011
[2022-04-06 02:04:41 | train] - Train Epoch: [128] [409600/1281167 (32%)]	Loss: 0.518078
[2022-04-06 02:05:10 | train] - Train Epoch: [128] [422400/1281167 (33%)]	Loss: 0.585530
[2022-04-06 02:05:39 | train] - Train Epoch: [128] [435200/1281167 (34%)]	Loss: 0.834065
[2022-04-06 02:06:06 | train] - Train Epoch: [128] [448000/1281167 (35%)]	Loss: 0.955047
[2022-04-06 02:06:34 | train] - Train Epoch: [128] [460800/1281167 (36%)]	Loss: 0.861221
[2022-04-06 02:07:01 | train] - Train Epoch: [128] [473600/1281167 (37%)]	Loss: 0.763577
[2022-04-06 02:07:29 | train] - Train Epoch: [128] [486400/1281167 (38%)]	Loss: 0.651922
[2022-04-06 02:07:58 | train] - Train Epoch: [128] [499200/1281167 (39%)]	Loss: 0.743300
[2022-04-06 02:08:26 | train] - Train Epoch: [128] [512000/1281167 (40%)]	Loss: 1.184037
[2022-04-06 02:08:54 | train] - Train Epoch: [128] [524800/1281167 (41%)]	Loss: 0.569141
[2022-04-06 02:09:21 | train] - Train Epoch: [128] [537600/1281167 (42%)]	Loss: 0.725270
[2022-04-06 02:09:49 | train] - Train Epoch: [128] [550400/1281167 (43%)]	Loss: 0.737800
[2022-04-06 02:10:18 | train] - Train Epoch: [128] [563200/1281167 (44%)]	Loss: 0.806641
[2022-04-06 02:10:46 | train] - Train Epoch: [128] [576000/1281167 (45%)]	Loss: 0.798250
[2022-04-06 02:11:14 | train] - Train Epoch: [128] [588800/1281167 (46%)]	Loss: 0.520745
[2022-04-06 02:11:42 | train] - Train Epoch: [128] [601600/1281167 (47%)]	Loss: 0.762663
[2022-04-06 02:12:10 | train] - Train Epoch: [128] [614400/1281167 (48%)]	Loss: 0.777687
[2022-04-06 02:12:38 | train] - Train Epoch: [128] [627200/1281167 (49%)]	Loss: 0.900830
[2022-04-06 02:13:07 | train] - Train Epoch: [128] [640000/1281167 (50%)]	Loss: 0.691275
[2022-04-06 02:13:35 | train] - Train Epoch: [128] [652800/1281167 (51%)]	Loss: 0.955148
[2022-04-06 02:14:03 | train] - Train Epoch: [128] [665600/1281167 (52%)]	Loss: 0.642300
[2022-04-06 02:14:33 | train] - Train Epoch: [128] [678400/1281167 (53%)]	Loss: 0.599183
[2022-04-06 02:15:00 | train] - Train Epoch: [128] [691200/1281167 (54%)]	Loss: 0.738848
[2022-04-06 02:15:29 | train] - Train Epoch: [128] [704000/1281167 (55%)]	Loss: 0.489077
[2022-04-06 02:15:57 | train] - Train Epoch: [128] [716800/1281167 (56%)]	Loss: 0.518901
[2022-04-06 02:16:25 | train] - Train Epoch: [128] [729600/1281167 (57%)]	Loss: 0.706511
[2022-04-06 02:16:54 | train] - Train Epoch: [128] [742400/1281167 (58%)]	Loss: 0.667506
[2022-04-06 02:17:21 | train] - Train Epoch: [128] [755200/1281167 (59%)]	Loss: 0.779869
[2022-04-06 02:17:48 | train] - Train Epoch: [128] [768000/1281167 (60%)]	Loss: 0.774434
[2022-04-06 02:18:17 | train] - Train Epoch: [128] [780800/1281167 (61%)]	Loss: 0.785554
[2022-04-06 02:18:45 | train] - Train Epoch: [128] [793600/1281167 (62%)]	Loss: 0.529761
[2022-04-06 02:19:13 | train] - Train Epoch: [128] [806400/1281167 (63%)]	Loss: 0.517962
[2022-04-06 02:19:41 | train] - Train Epoch: [128] [819200/1281167 (64%)]	Loss: 0.822706
[2022-04-06 02:20:09 | train] - Train Epoch: [128] [832000/1281167 (65%)]	Loss: 0.769013
[2022-04-06 02:20:38 | train] - Train Epoch: [128] [844800/1281167 (66%)]	Loss: 0.830224
[2022-04-06 02:21:06 | train] - Train Epoch: [128] [857600/1281167 (67%)]	Loss: 0.563730
[2022-04-06 02:21:34 | train] - Train Epoch: [128] [870400/1281167 (68%)]	Loss: 0.472915
[2022-04-06 02:22:03 | train] - Train Epoch: [128] [883200/1281167 (69%)]	Loss: 0.759465
[2022-04-06 02:22:31 | train] - Train Epoch: [128] [896000/1281167 (70%)]	Loss: 0.670912
[2022-04-06 02:22:59 | train] - Train Epoch: [128] [908800/1281167 (71%)]	Loss: 0.882022
[2022-04-06 02:23:28 | train] - Train Epoch: [128] [921600/1281167 (72%)]	Loss: 0.863367
[2022-04-06 02:23:55 | train] - Train Epoch: [128] [934400/1281167 (73%)]	Loss: 0.555940
[2022-04-06 02:24:23 | train] - Train Epoch: [128] [947200/1281167 (74%)]	Loss: 0.798259
[2022-04-06 02:24:51 | train] - Train Epoch: [128] [960000/1281167 (75%)]	Loss: 0.618446
[2022-04-06 02:25:20 | train] - Train Epoch: [128] [972800/1281167 (76%)]	Loss: 0.819911
[2022-04-06 02:25:49 | train] - Train Epoch: [128] [985600/1281167 (77%)]	Loss: 0.554327
[2022-04-06 02:26:17 | train] - Train Epoch: [128] [998400/1281167 (78%)]	Loss: 0.569375
[2022-04-06 02:26:46 | train] - Train Epoch: [128] [1011200/1281167 (79%)]	Loss: 0.758301
[2022-04-06 02:27:14 | train] - Train Epoch: [128] [1024000/1281167 (80%)]	Loss: 0.496425
[2022-04-06 02:27:43 | train] - Train Epoch: [128] [1036800/1281167 (81%)]	Loss: 0.749575
[2022-04-06 02:28:11 | train] - Train Epoch: [128] [1049600/1281167 (82%)]	Loss: 0.680779
[2022-04-06 02:28:40 | train] - Train Epoch: [128] [1062400/1281167 (83%)]	Loss: 0.770793
[2022-04-06 02:29:09 | train] - Train Epoch: [128] [1075200/1281167 (84%)]	Loss: 0.793874
[2022-04-06 02:29:37 | train] - Train Epoch: [128] [1088000/1281167 (85%)]	Loss: 0.934258
[2022-04-06 02:30:06 | train] - Train Epoch: [128] [1100800/1281167 (86%)]	Loss: 0.905265
[2022-04-06 02:30:35 | train] - Train Epoch: [128] [1113600/1281167 (87%)]	Loss: 0.749532
[2022-04-06 02:31:04 | train] - Train Epoch: [128] [1126400/1281167 (88%)]	Loss: 0.494240
[2022-04-06 02:31:32 | train] - Train Epoch: [128] [1139200/1281167 (89%)]	Loss: 0.674380
[2022-04-06 02:32:01 | train] - Train Epoch: [128] [1152000/1281167 (90%)]	Loss: 0.749133
[2022-04-06 02:32:30 | train] - Train Epoch: [128] [1164800/1281167 (91%)]	Loss: 0.610583
[2022-04-06 02:32:58 | train] - Train Epoch: [128] [1177600/1281167 (92%)]	Loss: 0.740967
[2022-04-06 02:33:27 | train] - Train Epoch: [128] [1190400/1281167 (93%)]	Loss: 0.728049
[2022-04-06 02:33:56 | train] - Train Epoch: [128] [1203200/1281167 (94%)]	Loss: 0.659572
[2022-04-06 02:34:25 | train] - Train Epoch: [128] [1216000/1281167 (95%)]	Loss: 0.548631
[2022-04-06 02:34:55 | train] - Train Epoch: [128] [1228800/1281167 (96%)]	Loss: 0.864065
[2022-04-06 02:35:24 | train] - Train Epoch: [128] [1241600/1281167 (97%)]	Loss: 0.815831
[2022-04-06 02:35:53 | train] - Train Epoch: [128] [1254400/1281167 (98%)]	Loss: 0.761911
[2022-04-06 02:36:22 | train] - Train Epoch: [128] [1267200/1281167 (99%)]	Loss: 0.865712
[2022-04-06 02:36:51 | train] - Train Epoch: [128] [1280000/1281167 (100%)]	Loss: 0.779141
[2022-04-06 02:36:53 | train] - Train Epoch: [128]	 Average Loss: 0.721565	 Total Acc : 82.4566	 Total Top5 Acc : 93.6564
[2022-04-06 02:36:53 | train] - -------128 epoch end-----------
========================================
-------128 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 02:38:49 | train] - 
Epoch [128] Test set: Average loss: 1.4347, Accuracy: 34911/50000 (69.7958%), Top-5 Accuracy: 88.7752%

[2022-04-06 02:38:49 | train] - save intermediate epoch [128] result


[2022-04-06 02:38:54 | train] - -------129 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 02:38:55 | train] - Train Epoch: [129] [0/1281167 (0%)]	Loss: 0.723415
[2022-04-06 02:39:24 | train] - Train Epoch: [129] [12800/1281167 (1%)]	Loss: 0.898246
[2022-04-06 02:39:52 | train] - Train Epoch: [129] [25600/1281167 (2%)]	Loss: 0.736121
[2022-04-06 02:40:18 | train] - Train Epoch: [129] [38400/1281167 (3%)]	Loss: 0.732909
[2022-04-06 02:40:47 | train] - Train Epoch: [129] [51200/1281167 (4%)]	Loss: 0.683416
[2022-04-06 02:41:14 | train] - Train Epoch: [129] [64000/1281167 (5%)]	Loss: 0.785677
[2022-04-06 02:41:43 | train] - Train Epoch: [129] [76800/1281167 (6%)]	Loss: 0.641117
[2022-04-06 02:42:11 | train] - Train Epoch: [129] [89600/1281167 (7%)]	Loss: 0.590942
[2022-04-06 02:42:38 | train] - Train Epoch: [129] [102400/1281167 (8%)]	Loss: 0.574967
[2022-04-06 02:43:06 | train] - Train Epoch: [129] [115200/1281167 (9%)]	Loss: 0.743718
[2022-04-06 02:43:34 | train] - Train Epoch: [129] [128000/1281167 (10%)]	Loss: 0.659207
[2022-04-06 02:44:02 | train] - Train Epoch: [129] [140800/1281167 (11%)]	Loss: 0.848785
[2022-04-06 02:44:30 | train] - Train Epoch: [129] [153600/1281167 (12%)]	Loss: 0.609160
[2022-04-06 02:44:57 | train] - Train Epoch: [129] [166400/1281167 (13%)]	Loss: 0.761169
[2022-04-06 02:45:24 | train] - Train Epoch: [129] [179200/1281167 (14%)]	Loss: 0.598953
[2022-04-06 02:45:52 | train] - Train Epoch: [129] [192000/1281167 (15%)]	Loss: 0.700912
[2022-04-06 02:46:20 | train] - Train Epoch: [129] [204800/1281167 (16%)]	Loss: 0.841144
[2022-04-06 02:46:48 | train] - Train Epoch: [129] [217600/1281167 (17%)]	Loss: 0.896006
[2022-04-06 02:47:16 | train] - Train Epoch: [129] [230400/1281167 (18%)]	Loss: 0.700357
[2022-04-06 02:47:44 | train] - Train Epoch: [129] [243200/1281167 (19%)]	Loss: 0.551729
[2022-04-06 02:48:12 | train] - Train Epoch: [129] [256000/1281167 (20%)]	Loss: 0.679988
[2022-04-06 02:48:39 | train] - Train Epoch: [129] [268800/1281167 (21%)]	Loss: 0.582733
[2022-04-06 02:49:07 | train] - Train Epoch: [129] [281600/1281167 (22%)]	Loss: 0.840685
[2022-04-06 02:49:34 | train] - Train Epoch: [129] [294400/1281167 (23%)]	Loss: 0.804234
[2022-04-06 02:50:02 | train] - Train Epoch: [129] [307200/1281167 (24%)]	Loss: 0.793392
[2022-04-06 02:50:30 | train] - Train Epoch: [129] [320000/1281167 (25%)]	Loss: 0.350273
[2022-04-06 02:50:58 | train] - Train Epoch: [129] [332800/1281167 (26%)]	Loss: 0.813226
[2022-04-06 02:51:26 | train] - Train Epoch: [129] [345600/1281167 (27%)]	Loss: 0.779390
[2022-04-06 02:51:54 | train] - Train Epoch: [129] [358400/1281167 (28%)]	Loss: 0.758495
[2022-04-06 02:52:22 | train] - Train Epoch: [129] [371200/1281167 (29%)]	Loss: 0.879102
[2022-04-06 02:52:50 | train] - Train Epoch: [129] [384000/1281167 (30%)]	Loss: 0.699018
[2022-04-06 02:53:18 | train] - Train Epoch: [129] [396800/1281167 (31%)]	Loss: 0.711593
[2022-04-06 02:53:46 | train] - Train Epoch: [129] [409600/1281167 (32%)]	Loss: 0.885268
[2022-04-06 02:54:15 | train] - Train Epoch: [129] [422400/1281167 (33%)]	Loss: 0.662828
[2022-04-06 02:54:43 | train] - Train Epoch: [129] [435200/1281167 (34%)]	Loss: 0.717135
[2022-04-06 02:55:09 | train] - Train Epoch: [129] [448000/1281167 (35%)]	Loss: 0.733448
[2022-04-06 02:55:37 | train] - Train Epoch: [129] [460800/1281167 (36%)]	Loss: 0.935205
[2022-04-06 02:56:05 | train] - Train Epoch: [129] [473600/1281167 (37%)]	Loss: 0.679441
[2022-04-06 02:56:33 | train] - Train Epoch: [129] [486400/1281167 (38%)]	Loss: 0.726540
[2022-04-06 02:57:01 | train] - Train Epoch: [129] [499200/1281167 (39%)]	Loss: 0.746025
[2022-04-06 02:57:28 | train] - Train Epoch: [129] [512000/1281167 (40%)]	Loss: 0.661106
[2022-04-06 02:57:57 | train] - Train Epoch: [129] [524800/1281167 (41%)]	Loss: 0.631756
[2022-04-06 02:58:25 | train] - Train Epoch: [129] [537600/1281167 (42%)]	Loss: 0.767243
[2022-04-06 02:58:52 | train] - Train Epoch: [129] [550400/1281167 (43%)]	Loss: 0.708200
[2022-04-06 02:59:20 | train] - Train Epoch: [129] [563200/1281167 (44%)]	Loss: 0.737955
[2022-04-06 02:59:48 | train] - Train Epoch: [129] [576000/1281167 (45%)]	Loss: 0.705796
[2022-04-06 03:00:15 | train] - Train Epoch: [129] [588800/1281167 (46%)]	Loss: 0.797792
[2022-04-06 03:00:43 | train] - Train Epoch: [129] [601600/1281167 (47%)]	Loss: 0.637270
[2022-04-06 03:01:10 | train] - Train Epoch: [129] [614400/1281167 (48%)]	Loss: 0.964097
[2022-04-06 03:01:38 | train] - Train Epoch: [129] [627200/1281167 (49%)]	Loss: 0.793469
[2022-04-06 03:02:05 | train] - Train Epoch: [129] [640000/1281167 (50%)]	Loss: 0.794355
[2022-04-06 03:02:33 | train] - Train Epoch: [129] [652800/1281167 (51%)]	Loss: 0.832602
[2022-04-06 03:03:01 | train] - Train Epoch: [129] [665600/1281167 (52%)]	Loss: 0.668244
[2022-04-06 03:03:29 | train] - Train Epoch: [129] [678400/1281167 (53%)]	Loss: 0.728397
[2022-04-06 03:03:56 | train] - Train Epoch: [129] [691200/1281167 (54%)]	Loss: 0.452367
[2022-04-06 03:04:23 | train] - Train Epoch: [129] [704000/1281167 (55%)]	Loss: 0.999982
[2022-04-06 03:04:51 | train] - Train Epoch: [129] [716800/1281167 (56%)]	Loss: 0.664123
[2022-04-06 03:05:19 | train] - Train Epoch: [129] [729600/1281167 (57%)]	Loss: 0.677182
[2022-04-06 03:05:46 | train] - Train Epoch: [129] [742400/1281167 (58%)]	Loss: 0.577705
[2022-04-06 03:06:14 | train] - Train Epoch: [129] [755200/1281167 (59%)]	Loss: 0.598626
[2022-04-06 03:06:41 | train] - Train Epoch: [129] [768000/1281167 (60%)]	Loss: 0.508772
[2022-04-06 03:07:10 | train] - Train Epoch: [129] [780800/1281167 (61%)]	Loss: 0.596354
[2022-04-06 03:07:38 | train] - Train Epoch: [129] [793600/1281167 (62%)]	Loss: 0.599083
[2022-04-06 03:08:06 | train] - Train Epoch: [129] [806400/1281167 (63%)]	Loss: 0.648848
[2022-04-06 03:08:35 | train] - Train Epoch: [129] [819200/1281167 (64%)]	Loss: 0.577960
[2022-04-06 03:09:02 | train] - Train Epoch: [129] [832000/1281167 (65%)]	Loss: 0.981661
[2022-04-06 03:09:30 | train] - Train Epoch: [129] [844800/1281167 (66%)]	Loss: 0.630678
[2022-04-06 03:09:59 | train] - Train Epoch: [129] [857600/1281167 (67%)]	Loss: 0.773011
[2022-04-06 03:10:27 | train] - Train Epoch: [129] [870400/1281167 (68%)]	Loss: 0.888700
[2022-04-06 03:10:56 | train] - Train Epoch: [129] [883200/1281167 (69%)]	Loss: 0.649252
[2022-04-06 03:11:23 | train] - Train Epoch: [129] [896000/1281167 (70%)]	Loss: 0.590775
[2022-04-06 03:11:51 | train] - Train Epoch: [129] [908800/1281167 (71%)]	Loss: 0.859989
[2022-04-06 03:12:19 | train] - Train Epoch: [129] [921600/1281167 (72%)]	Loss: 0.931017
[2022-04-06 03:12:47 | train] - Train Epoch: [129] [934400/1281167 (73%)]	Loss: 0.578323
[2022-04-06 03:13:14 | train] - Train Epoch: [129] [947200/1281167 (74%)]	Loss: 0.876279
[2022-04-06 03:13:43 | train] - Train Epoch: [129] [960000/1281167 (75%)]	Loss: 0.793255
[2022-04-06 03:14:11 | train] - Train Epoch: [129] [972800/1281167 (76%)]	Loss: 0.707948
[2022-04-06 03:14:39 | train] - Train Epoch: [129] [985600/1281167 (77%)]	Loss: 0.431607
[2022-04-06 03:15:07 | train] - Train Epoch: [129] [998400/1281167 (78%)]	Loss: 0.619859
[2022-04-06 03:15:36 | train] - Train Epoch: [129] [1011200/1281167 (79%)]	Loss: 0.890353
[2022-04-06 03:16:05 | train] - Train Epoch: [129] [1024000/1281167 (80%)]	Loss: 0.688390
[2022-04-06 03:16:32 | train] - Train Epoch: [129] [1036800/1281167 (81%)]	Loss: 0.793518
[2022-04-06 03:17:00 | train] - Train Epoch: [129] [1049600/1281167 (82%)]	Loss: 0.904074
[2022-04-06 03:17:28 | train] - Train Epoch: [129] [1062400/1281167 (83%)]	Loss: 0.805881
[2022-04-06 03:17:56 | train] - Train Epoch: [129] [1075200/1281167 (84%)]	Loss: 0.879536
[2022-04-06 03:18:25 | train] - Train Epoch: [129] [1088000/1281167 (85%)]	Loss: 0.872341
[2022-04-06 03:18:53 | train] - Train Epoch: [129] [1100800/1281167 (86%)]	Loss: 0.940468
[2022-04-06 03:19:22 | train] - Train Epoch: [129] [1113600/1281167 (87%)]	Loss: 0.657144
[2022-04-06 03:19:51 | train] - Train Epoch: [129] [1126400/1281167 (88%)]	Loss: 0.548647
[2022-04-06 03:20:19 | train] - Train Epoch: [129] [1139200/1281167 (89%)]	Loss: 0.650988
[2022-04-06 03:20:47 | train] - Train Epoch: [129] [1152000/1281167 (90%)]	Loss: 0.633700
[2022-04-06 03:21:15 | train] - Train Epoch: [129] [1164800/1281167 (91%)]	Loss: 0.786452
[2022-04-06 03:21:43 | train] - Train Epoch: [129] [1177600/1281167 (92%)]	Loss: 0.731369
[2022-04-06 03:22:12 | train] - Train Epoch: [129] [1190400/1281167 (93%)]	Loss: 0.948547
[2022-04-06 03:22:41 | train] - Train Epoch: [129] [1203200/1281167 (94%)]	Loss: 0.920931
[2022-04-06 03:23:10 | train] - Train Epoch: [129] [1216000/1281167 (95%)]	Loss: 0.632737
[2022-04-06 03:23:39 | train] - Train Epoch: [129] [1228800/1281167 (96%)]	Loss: 0.726756
[2022-04-06 03:24:07 | train] - Train Epoch: [129] [1241600/1281167 (97%)]	Loss: 0.625107
[2022-04-06 03:24:36 | train] - Train Epoch: [129] [1254400/1281167 (98%)]	Loss: 0.631351
[2022-04-06 03:25:05 | train] - Train Epoch: [129] [1267200/1281167 (99%)]	Loss: 0.720166
[2022-04-06 03:25:33 | train] - Train Epoch: [129] [1280000/1281167 (100%)]	Loss: 0.823376
[2022-04-06 03:25:36 | train] - Train Epoch: [129]	 Average Loss: 0.719115	 Total Acc : 82.5142	 Total Top5 Acc : 93.6987
[2022-04-06 03:25:36 | train] - -------129 epoch end-----------
========================================
-------129 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 03:27:34 | train] - 
Epoch [129] Test set: Average loss: 1.4307, Accuracy: 34891/50000 (69.7558%), Top-5 Accuracy: 88.7900%

[2022-04-06 03:27:34 | train] - save intermediate epoch [129] result


[2022-04-06 03:27:39 | train] - -------130 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 03:27:40 | train] - Train Epoch: [130] [0/1281167 (0%)]	Loss: 0.648715
[2022-04-06 03:28:07 | train] - Train Epoch: [130] [12800/1281167 (1%)]	Loss: 0.856683
[2022-04-06 03:28:33 | train] - Train Epoch: [130] [25600/1281167 (2%)]	Loss: 0.620829
[2022-04-06 03:29:00 | train] - Train Epoch: [130] [38400/1281167 (3%)]	Loss: 0.734327
[2022-04-06 03:29:26 | train] - Train Epoch: [130] [51200/1281167 (4%)]	Loss: 0.632683
[2022-04-06 03:29:52 | train] - Train Epoch: [130] [64000/1281167 (5%)]	Loss: 0.716722
[2022-04-06 03:30:18 | train] - Train Epoch: [130] [76800/1281167 (6%)]	Loss: 0.667382
[2022-04-06 03:30:45 | train] - Train Epoch: [130] [89600/1281167 (7%)]	Loss: 0.787062
[2022-04-06 03:31:11 | train] - Train Epoch: [130] [102400/1281167 (8%)]	Loss: 0.704439
[2022-04-06 03:31:38 | train] - Train Epoch: [130] [115200/1281167 (9%)]	Loss: 0.736849
[2022-04-06 03:32:04 | train] - Train Epoch: [130] [128000/1281167 (10%)]	Loss: 0.537284
[2022-04-06 03:32:30 | train] - Train Epoch: [130] [140800/1281167 (11%)]	Loss: 0.621938
[2022-04-06 03:32:57 | train] - Train Epoch: [130] [153600/1281167 (12%)]	Loss: 1.028853
[2022-04-06 03:33:25 | train] - Train Epoch: [130] [166400/1281167 (13%)]	Loss: 0.799174
[2022-04-06 03:33:51 | train] - Train Epoch: [130] [179200/1281167 (14%)]	Loss: 0.770652
[2022-04-06 03:34:18 | train] - Train Epoch: [130] [192000/1281167 (15%)]	Loss: 0.978852
[2022-04-06 03:34:44 | train] - Train Epoch: [130] [204800/1281167 (16%)]	Loss: 1.066423
[2022-04-06 03:35:12 | train] - Train Epoch: [130] [217600/1281167 (17%)]	Loss: 0.957002
[2022-04-06 03:35:38 | train] - Train Epoch: [130] [230400/1281167 (18%)]	Loss: 0.865371
[2022-04-06 03:36:04 | train] - Train Epoch: [130] [243200/1281167 (19%)]	Loss: 0.627846
[2022-04-06 03:36:32 | train] - Train Epoch: [130] [256000/1281167 (20%)]	Loss: 0.764849
[2022-04-06 03:36:59 | train] - Train Epoch: [130] [268800/1281167 (21%)]	Loss: 0.474923
[2022-04-06 03:37:25 | train] - Train Epoch: [130] [281600/1281167 (22%)]	Loss: 0.746049
[2022-04-06 03:37:51 | train] - Train Epoch: [130] [294400/1281167 (23%)]	Loss: 0.628872
[2022-04-06 03:38:18 | train] - Train Epoch: [130] [307200/1281167 (24%)]	Loss: 0.560393
[2022-04-06 03:38:46 | train] - Train Epoch: [130] [320000/1281167 (25%)]	Loss: 0.908679
[2022-04-06 03:39:12 | train] - Train Epoch: [130] [332800/1281167 (26%)]	Loss: 0.714158
[2022-04-06 03:39:40 | train] - Train Epoch: [130] [345600/1281167 (27%)]	Loss: 0.704988
[2022-04-06 03:40:06 | train] - Train Epoch: [130] [358400/1281167 (28%)]	Loss: 0.598040
[2022-04-06 03:40:33 | train] - Train Epoch: [130] [371200/1281167 (29%)]	Loss: 0.683298
[2022-04-06 03:41:00 | train] - Train Epoch: [130] [384000/1281167 (30%)]	Loss: 0.902719
[2022-04-06 03:41:28 | train] - Train Epoch: [130] [396800/1281167 (31%)]	Loss: 0.794579
[2022-04-06 03:41:55 | train] - Train Epoch: [130] [409600/1281167 (32%)]	Loss: 0.631947
[2022-04-06 03:42:21 | train] - Train Epoch: [130] [422400/1281167 (33%)]	Loss: 0.770179
[2022-04-06 03:42:48 | train] - Train Epoch: [130] [435200/1281167 (34%)]	Loss: 0.820233
[2022-04-06 03:43:14 | train] - Train Epoch: [130] [448000/1281167 (35%)]	Loss: 0.762790
[2022-04-06 03:43:40 | train] - Train Epoch: [130] [460800/1281167 (36%)]	Loss: 0.657904
[2022-04-06 03:44:07 | train] - Train Epoch: [130] [473600/1281167 (37%)]	Loss: 0.603893
[2022-04-06 03:44:34 | train] - Train Epoch: [130] [486400/1281167 (38%)]	Loss: 0.704552
[2022-04-06 03:45:00 | train] - Train Epoch: [130] [499200/1281167 (39%)]	Loss: 0.690670
[2022-04-06 03:45:26 | train] - Train Epoch: [130] [512000/1281167 (40%)]	Loss: 0.526843
[2022-04-06 03:45:52 | train] - Train Epoch: [130] [524800/1281167 (41%)]	Loss: 0.990629
[2022-04-06 03:46:20 | train] - Train Epoch: [130] [537600/1281167 (42%)]	Loss: 0.643387
[2022-04-06 03:46:47 | train] - Train Epoch: [130] [550400/1281167 (43%)]	Loss: 0.654597
[2022-04-06 03:47:13 | train] - Train Epoch: [130] [563200/1281167 (44%)]	Loss: 0.871905
[2022-04-06 03:47:40 | train] - Train Epoch: [130] [576000/1281167 (45%)]	Loss: 0.763266
[2022-04-06 03:48:06 | train] - Train Epoch: [130] [588800/1281167 (46%)]	Loss: 0.870025
[2022-04-06 03:48:35 | train] - Train Epoch: [130] [601600/1281167 (47%)]	Loss: 0.607153
[2022-04-06 03:49:01 | train] - Train Epoch: [130] [614400/1281167 (48%)]	Loss: 0.563294
[2022-04-06 03:49:28 | train] - Train Epoch: [130] [627200/1281167 (49%)]	Loss: 0.827338
[2022-04-06 03:49:55 | train] - Train Epoch: [130] [640000/1281167 (50%)]	Loss: 0.909083
[2022-04-06 03:50:21 | train] - Train Epoch: [130] [652800/1281167 (51%)]	Loss: 0.523749
[2022-04-06 03:50:48 | train] - Train Epoch: [130] [665600/1281167 (52%)]	Loss: 0.550712
[2022-04-06 03:51:16 | train] - Train Epoch: [130] [678400/1281167 (53%)]	Loss: 0.959881
[2022-04-06 03:51:42 | train] - Train Epoch: [130] [691200/1281167 (54%)]	Loss: 0.767611
[2022-04-06 03:52:08 | train] - Train Epoch: [130] [704000/1281167 (55%)]	Loss: 0.724222
[2022-04-06 03:52:34 | train] - Train Epoch: [130] [716800/1281167 (56%)]	Loss: 0.545185
[2022-04-06 03:53:01 | train] - Train Epoch: [130] [729600/1281167 (57%)]	Loss: 0.872869
[2022-04-06 03:53:28 | train] - Train Epoch: [130] [742400/1281167 (58%)]	Loss: 0.687380
[2022-04-06 03:53:55 | train] - Train Epoch: [130] [755200/1281167 (59%)]	Loss: 0.450978
[2022-04-06 03:54:21 | train] - Train Epoch: [130] [768000/1281167 (60%)]	Loss: 0.806545
[2022-04-06 03:54:48 | train] - Train Epoch: [130] [780800/1281167 (61%)]	Loss: 0.460172
[2022-04-06 03:55:15 | train] - Train Epoch: [130] [793600/1281167 (62%)]	Loss: 0.727391
[2022-04-06 03:55:41 | train] - Train Epoch: [130] [806400/1281167 (63%)]	Loss: 0.618468
[2022-04-06 03:56:08 | train] - Train Epoch: [130] [819200/1281167 (64%)]	Loss: 0.805981
[2022-04-06 03:56:35 | train] - Train Epoch: [130] [832000/1281167 (65%)]	Loss: 0.751537
[2022-04-06 03:57:02 | train] - Train Epoch: [130] [844800/1281167 (66%)]	Loss: 0.521401
[2022-04-06 03:57:29 | train] - Train Epoch: [130] [857600/1281167 (67%)]	Loss: 0.774302
[2022-04-06 03:57:55 | train] - Train Epoch: [130] [870400/1281167 (68%)]	Loss: 0.699798
[2022-04-06 03:58:22 | train] - Train Epoch: [130] [883200/1281167 (69%)]	Loss: 0.975269
[2022-04-06 03:58:48 | train] - Train Epoch: [130] [896000/1281167 (70%)]	Loss: 0.727944
[2022-04-06 03:59:16 | train] - Train Epoch: [130] [908800/1281167 (71%)]	Loss: 0.501672
[2022-04-06 03:59:43 | train] - Train Epoch: [130] [921600/1281167 (72%)]	Loss: 0.690136
[2022-04-06 04:00:09 | train] - Train Epoch: [130] [934400/1281167 (73%)]	Loss: 0.540462
[2022-04-06 04:00:36 | train] - Train Epoch: [130] [947200/1281167 (74%)]	Loss: 0.744253
[2022-04-06 04:01:04 | train] - Train Epoch: [130] [960000/1281167 (75%)]	Loss: 0.588764
[2022-04-06 04:01:30 | train] - Train Epoch: [130] [972800/1281167 (76%)]	Loss: 0.576144
[2022-04-06 04:01:58 | train] - Train Epoch: [130] [985600/1281167 (77%)]	Loss: 0.618015
[2022-04-06 04:02:24 | train] - Train Epoch: [130] [998400/1281167 (78%)]	Loss: 0.525257
[2022-04-06 04:02:51 | train] - Train Epoch: [130] [1011200/1281167 (79%)]	Loss: 0.635143
[2022-04-06 04:03:18 | train] - Train Epoch: [130] [1024000/1281167 (80%)]	Loss: 0.803441
[2022-04-06 04:03:45 | train] - Train Epoch: [130] [1036800/1281167 (81%)]	Loss: 0.705603
[2022-04-06 04:04:12 | train] - Train Epoch: [130] [1049600/1281167 (82%)]	Loss: 0.726158
[2022-04-06 04:04:39 | train] - Train Epoch: [130] [1062400/1281167 (83%)]	Loss: 0.827299
[2022-04-06 04:05:06 | train] - Train Epoch: [130] [1075200/1281167 (84%)]	Loss: 0.542887
[2022-04-06 04:05:33 | train] - Train Epoch: [130] [1088000/1281167 (85%)]	Loss: 0.822736
[2022-04-06 04:06:00 | train] - Train Epoch: [130] [1100800/1281167 (86%)]	Loss: 0.743568
[2022-04-06 04:06:28 | train] - Train Epoch: [130] [1113600/1281167 (87%)]	Loss: 0.665012
[2022-04-06 04:06:55 | train] - Train Epoch: [130] [1126400/1281167 (88%)]	Loss: 0.676571
[2022-04-06 04:07:23 | train] - Train Epoch: [130] [1139200/1281167 (89%)]	Loss: 0.734597
[2022-04-06 04:07:51 | train] - Train Epoch: [130] [1152000/1281167 (90%)]	Loss: 0.457451
[2022-04-06 04:08:18 | train] - Train Epoch: [130] [1164800/1281167 (91%)]	Loss: 0.697194
[2022-04-06 04:08:45 | train] - Train Epoch: [130] [1177600/1281167 (92%)]	Loss: 0.879051
[2022-04-06 04:09:12 | train] - Train Epoch: [130] [1190400/1281167 (93%)]	Loss: 0.705848
[2022-04-06 04:09:39 | train] - Train Epoch: [130] [1203200/1281167 (94%)]	Loss: 0.758458
[2022-04-06 04:10:07 | train] - Train Epoch: [130] [1216000/1281167 (95%)]	Loss: 0.781352
[2022-04-06 04:10:35 | train] - Train Epoch: [130] [1228800/1281167 (96%)]	Loss: 0.878170
[2022-04-06 04:11:02 | train] - Train Epoch: [130] [1241600/1281167 (97%)]	Loss: 0.697189
[2022-04-06 04:11:29 | train] - Train Epoch: [130] [1254400/1281167 (98%)]	Loss: 0.574163
[2022-04-06 04:11:57 | train] - Train Epoch: [130] [1267200/1281167 (99%)]	Loss: 0.707393
[2022-04-06 04:12:25 | train] - Train Epoch: [130] [1280000/1281167 (100%)]	Loss: 0.593851
[2022-04-06 04:12:27 | train] - Train Epoch: [130]	 Average Loss: 0.737867	 Total Acc : 82.0010	 Total Top5 Acc : 93.5045
[2022-04-06 04:12:27 | train] - -------130 epoch end-----------
========================================
-------130 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 04:14:25 | train] - 
Epoch [130] Test set: Average loss: 1.4340, Accuracy: 34934/50000 (69.8406%), Top-5 Accuracy: 88.7812%

[2022-04-06 04:14:25 | train] - save intermediate epoch [130] result


[2022-04-06 04:14:30 | train] - -------131 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 04:14:31 | train] - Train Epoch: [131] [0/1281167 (0%)]	Loss: 0.650042
[2022-04-06 04:15:00 | train] - Train Epoch: [131] [12800/1281167 (1%)]	Loss: 0.460480
[2022-04-06 04:15:27 | train] - Train Epoch: [131] [25600/1281167 (2%)]	Loss: 0.741410
[2022-04-06 04:15:54 | train] - Train Epoch: [131] [38400/1281167 (3%)]	Loss: 0.842757
[2022-04-06 04:16:21 | train] - Train Epoch: [131] [51200/1281167 (4%)]	Loss: 0.805311
[2022-04-06 04:16:49 | train] - Train Epoch: [131] [64000/1281167 (5%)]	Loss: 0.795981
[2022-04-06 04:17:16 | train] - Train Epoch: [131] [76800/1281167 (6%)]	Loss: 0.686358
[2022-04-06 04:17:45 | train] - Train Epoch: [131] [89600/1281167 (7%)]	Loss: 0.655869
[2022-04-06 04:18:12 | train] - Train Epoch: [131] [102400/1281167 (8%)]	Loss: 0.422358
[2022-04-06 04:18:40 | train] - Train Epoch: [131] [115200/1281167 (9%)]	Loss: 0.683759
[2022-04-06 04:19:07 | train] - Train Epoch: [131] [128000/1281167 (10%)]	Loss: 0.784816
[2022-04-06 04:19:34 | train] - Train Epoch: [131] [140800/1281167 (11%)]	Loss: 0.868864
[2022-04-06 04:20:01 | train] - Train Epoch: [131] [153600/1281167 (12%)]	Loss: 0.651257
[2022-04-06 04:20:28 | train] - Train Epoch: [131] [166400/1281167 (13%)]	Loss: 0.855955
[2022-04-06 04:20:56 | train] - Train Epoch: [131] [179200/1281167 (14%)]	Loss: 0.932065
[2022-04-06 04:21:23 | train] - Train Epoch: [131] [192000/1281167 (15%)]	Loss: 0.946409
[2022-04-06 04:21:50 | train] - Train Epoch: [131] [204800/1281167 (16%)]	Loss: 0.502886
[2022-04-06 04:22:18 | train] - Train Epoch: [131] [217600/1281167 (17%)]	Loss: 0.581025
[2022-04-06 04:22:46 | train] - Train Epoch: [131] [230400/1281167 (18%)]	Loss: 0.827859
[2022-04-06 04:23:13 | train] - Train Epoch: [131] [243200/1281167 (19%)]	Loss: 1.129379
[2022-04-06 04:23:41 | train] - Train Epoch: [131] [256000/1281167 (20%)]	Loss: 0.652755
[2022-04-06 04:24:09 | train] - Train Epoch: [131] [268800/1281167 (21%)]	Loss: 0.703460
[2022-04-06 04:24:36 | train] - Train Epoch: [131] [281600/1281167 (22%)]	Loss: 0.567581
[2022-04-06 04:25:04 | train] - Train Epoch: [131] [294400/1281167 (23%)]	Loss: 0.716948
[2022-04-06 04:25:31 | train] - Train Epoch: [131] [307200/1281167 (24%)]	Loss: 0.612878
[2022-04-06 04:26:01 | train] - Train Epoch: [131] [320000/1281167 (25%)]	Loss: 0.848781
[2022-04-06 04:26:28 | train] - Train Epoch: [131] [332800/1281167 (26%)]	Loss: 0.889708
[2022-04-06 04:26:56 | train] - Train Epoch: [131] [345600/1281167 (27%)]	Loss: 0.733556
[2022-04-06 04:27:23 | train] - Train Epoch: [131] [358400/1281167 (28%)]	Loss: 0.642415
[2022-04-06 04:27:50 | train] - Train Epoch: [131] [371200/1281167 (29%)]	Loss: 0.745703
[2022-04-06 04:28:19 | train] - Train Epoch: [131] [384000/1281167 (30%)]	Loss: 0.855058
[2022-04-06 04:28:45 | train] - Train Epoch: [131] [396800/1281167 (31%)]	Loss: 0.901327
[2022-04-06 04:29:13 | train] - Train Epoch: [131] [409600/1281167 (32%)]	Loss: 0.803702
[2022-04-06 04:29:41 | train] - Train Epoch: [131] [422400/1281167 (33%)]	Loss: 0.652538
[2022-04-06 04:30:07 | train] - Train Epoch: [131] [435200/1281167 (34%)]	Loss: 0.813978
[2022-04-06 04:30:34 | train] - Train Epoch: [131] [448000/1281167 (35%)]	Loss: 0.809077
[2022-04-06 04:31:02 | train] - Train Epoch: [131] [460800/1281167 (36%)]	Loss: 0.639035
[2022-04-06 04:31:30 | train] - Train Epoch: [131] [473600/1281167 (37%)]	Loss: 0.492770
[2022-04-06 04:31:58 | train] - Train Epoch: [131] [486400/1281167 (38%)]	Loss: 1.077005
[2022-04-06 04:32:25 | train] - Train Epoch: [131] [499200/1281167 (39%)]	Loss: 0.741415
[2022-04-06 04:32:53 | train] - Train Epoch: [131] [512000/1281167 (40%)]	Loss: 0.576397
[2022-04-06 04:33:20 | train] - Train Epoch: [131] [524800/1281167 (41%)]	Loss: 0.656948
[2022-04-06 04:33:48 | train] - Train Epoch: [131] [537600/1281167 (42%)]	Loss: 0.888668
[2022-04-06 04:34:16 | train] - Train Epoch: [131] [550400/1281167 (43%)]	Loss: 0.932051
[2022-04-06 04:34:44 | train] - Train Epoch: [131] [563200/1281167 (44%)]	Loss: 0.753223
[2022-04-06 04:35:11 | train] - Train Epoch: [131] [576000/1281167 (45%)]	Loss: 0.697475
[2022-04-06 04:35:39 | train] - Train Epoch: [131] [588800/1281167 (46%)]	Loss: 0.816343
[2022-04-06 04:36:07 | train] - Train Epoch: [131] [601600/1281167 (47%)]	Loss: 0.796180
[2022-04-06 04:36:35 | train] - Train Epoch: [131] [614400/1281167 (48%)]	Loss: 0.644912
[2022-04-06 04:37:03 | train] - Train Epoch: [131] [627200/1281167 (49%)]	Loss: 0.575604
[2022-04-06 04:37:30 | train] - Train Epoch: [131] [640000/1281167 (50%)]	Loss: 0.884529
[2022-04-06 04:37:58 | train] - Train Epoch: [131] [652800/1281167 (51%)]	Loss: 0.607441
[2022-04-06 04:38:25 | train] - Train Epoch: [131] [665600/1281167 (52%)]	Loss: 0.530130
[2022-04-06 04:38:53 | train] - Train Epoch: [131] [678400/1281167 (53%)]	Loss: 0.854145
[2022-04-06 04:39:21 | train] - Train Epoch: [131] [691200/1281167 (54%)]	Loss: 0.652051
[2022-04-06 04:39:49 | train] - Train Epoch: [131] [704000/1281167 (55%)]	Loss: 0.840018
[2022-04-06 04:40:17 | train] - Train Epoch: [131] [716800/1281167 (56%)]	Loss: 0.911944
[2022-04-06 04:40:44 | train] - Train Epoch: [131] [729600/1281167 (57%)]	Loss: 0.470811
[2022-04-06 04:41:13 | train] - Train Epoch: [131] [742400/1281167 (58%)]	Loss: 0.941344
[2022-04-06 04:41:41 | train] - Train Epoch: [131] [755200/1281167 (59%)]	Loss: 0.902616
[2022-04-06 04:42:09 | train] - Train Epoch: [131] [768000/1281167 (60%)]	Loss: 0.755075
[2022-04-06 04:42:37 | train] - Train Epoch: [131] [780800/1281167 (61%)]	Loss: 0.680478
[2022-04-06 04:43:04 | train] - Train Epoch: [131] [793600/1281167 (62%)]	Loss: 0.683474
[2022-04-06 04:43:32 | train] - Train Epoch: [131] [806400/1281167 (63%)]	Loss: 0.544649
[2022-04-06 04:44:00 | train] - Train Epoch: [131] [819200/1281167 (64%)]	Loss: 0.833836
[2022-04-06 04:44:28 | train] - Train Epoch: [131] [832000/1281167 (65%)]	Loss: 0.727696
[2022-04-06 04:44:56 | train] - Train Epoch: [131] [844800/1281167 (66%)]	Loss: 0.583048
[2022-04-06 04:45:24 | train] - Train Epoch: [131] [857600/1281167 (67%)]	Loss: 0.865016
[2022-04-06 04:45:52 | train] - Train Epoch: [131] [870400/1281167 (68%)]	Loss: 0.918717
[2022-04-06 04:46:21 | train] - Train Epoch: [131] [883200/1281167 (69%)]	Loss: 0.893983
[2022-04-06 04:46:48 | train] - Train Epoch: [131] [896000/1281167 (70%)]	Loss: 0.842993
[2022-04-06 04:47:16 | train] - Train Epoch: [131] [908800/1281167 (71%)]	Loss: 0.782447
[2022-04-06 04:47:44 | train] - Train Epoch: [131] [921600/1281167 (72%)]	Loss: 0.655004
[2022-04-06 04:48:13 | train] - Train Epoch: [131] [934400/1281167 (73%)]	Loss: 0.624880
[2022-04-06 04:48:41 | train] - Train Epoch: [131] [947200/1281167 (74%)]	Loss: 0.573469
[2022-04-06 04:49:09 | train] - Train Epoch: [131] [960000/1281167 (75%)]	Loss: 0.728742
[2022-04-06 04:49:38 | train] - Train Epoch: [131] [972800/1281167 (76%)]	Loss: 0.742778
[2022-04-06 04:50:07 | train] - Train Epoch: [131] [985600/1281167 (77%)]	Loss: 0.744046
[2022-04-06 04:50:34 | train] - Train Epoch: [131] [998400/1281167 (78%)]	Loss: 0.844777
[2022-04-06 04:51:04 | train] - Train Epoch: [131] [1011200/1281167 (79%)]	Loss: 0.693069
[2022-04-06 04:51:32 | train] - Train Epoch: [131] [1024000/1281167 (80%)]	Loss: 0.814853
[2022-04-06 04:52:00 | train] - Train Epoch: [131] [1036800/1281167 (81%)]	Loss: 0.662429
[2022-04-06 04:52:28 | train] - Train Epoch: [131] [1049600/1281167 (82%)]	Loss: 0.725168
[2022-04-06 04:52:57 | train] - Train Epoch: [131] [1062400/1281167 (83%)]	Loss: 0.492868
[2022-04-06 04:53:24 | train] - Train Epoch: [131] [1075200/1281167 (84%)]	Loss: 0.860059
[2022-04-06 04:53:53 | train] - Train Epoch: [131] [1088000/1281167 (85%)]	Loss: 0.661564
[2022-04-06 04:54:21 | train] - Train Epoch: [131] [1100800/1281167 (86%)]	Loss: 0.680050
[2022-04-06 04:54:49 | train] - Train Epoch: [131] [1113600/1281167 (87%)]	Loss: 0.688563
[2022-04-06 04:55:18 | train] - Train Epoch: [131] [1126400/1281167 (88%)]	Loss: 0.712798
[2022-04-06 04:55:47 | train] - Train Epoch: [131] [1139200/1281167 (89%)]	Loss: 0.665585
[2022-04-06 04:56:15 | train] - Train Epoch: [131] [1152000/1281167 (90%)]	Loss: 0.818455
[2022-04-06 04:56:44 | train] - Train Epoch: [131] [1164800/1281167 (91%)]	Loss: 0.862069
[2022-04-06 04:57:12 | train] - Train Epoch: [131] [1177600/1281167 (92%)]	Loss: 0.772706
[2022-04-06 04:57:41 | train] - Train Epoch: [131] [1190400/1281167 (93%)]	Loss: 0.694387
[2022-04-06 04:58:09 | train] - Train Epoch: [131] [1203200/1281167 (94%)]	Loss: 0.571808
[2022-04-06 04:58:38 | train] - Train Epoch: [131] [1216000/1281167 (95%)]	Loss: 0.957832
[2022-04-06 04:59:06 | train] - Train Epoch: [131] [1228800/1281167 (96%)]	Loss: 0.662751
[2022-04-06 04:59:35 | train] - Train Epoch: [131] [1241600/1281167 (97%)]	Loss: 0.794270
[2022-04-06 05:00:04 | train] - Train Epoch: [131] [1254400/1281167 (98%)]	Loss: 0.697297
[2022-04-06 05:00:32 | train] - Train Epoch: [131] [1267200/1281167 (99%)]	Loss: 0.965050
[2022-04-06 05:01:00 | train] - Train Epoch: [131] [1280000/1281167 (100%)]	Loss: 1.096448
[2022-04-06 05:01:03 | train] - Train Epoch: [131]	 Average Loss: 0.741360	 Total Acc : 81.9445	 Total Top5 Acc : 93.4529
[2022-04-06 05:01:03 | train] - -------131 epoch end-----------
========================================
-------131 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 05:03:01 | train] - 
Epoch [131] Test set: Average loss: 1.4451, Accuracy: 34838/50000 (69.6511%), Top-5 Accuracy: 88.7832%

[2022-04-06 05:03:01 | train] - save intermediate epoch [131] result


[2022-04-06 05:03:06 | train] - -------132 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 05:03:08 | train] - Train Epoch: [132] [0/1281167 (0%)]	Loss: 0.692891
[2022-04-06 05:03:35 | train] - Train Epoch: [132] [12800/1281167 (1%)]	Loss: 0.593888
[2022-04-06 05:04:02 | train] - Train Epoch: [132] [25600/1281167 (2%)]	Loss: 0.447256
[2022-04-06 05:04:29 | train] - Train Epoch: [132] [38400/1281167 (3%)]	Loss: 0.813092
[2022-04-06 05:04:56 | train] - Train Epoch: [132] [51200/1281167 (4%)]	Loss: 0.614691
[2022-04-06 05:05:24 | train] - Train Epoch: [132] [64000/1281167 (5%)]	Loss: 0.686017
[2022-04-06 05:05:51 | train] - Train Epoch: [132] [76800/1281167 (6%)]	Loss: 0.723715
[2022-04-06 05:06:19 | train] - Train Epoch: [132] [89600/1281167 (7%)]	Loss: 0.672737
[2022-04-06 05:06:47 | train] - Train Epoch: [132] [102400/1281167 (8%)]	Loss: 0.489370
[2022-04-06 05:07:14 | train] - Train Epoch: [132] [115200/1281167 (9%)]	Loss: 0.795742
[2022-04-06 05:07:42 | train] - Train Epoch: [132] [128000/1281167 (10%)]	Loss: 0.638884
[2022-04-06 05:08:09 | train] - Train Epoch: [132] [140800/1281167 (11%)]	Loss: 0.807095
[2022-04-06 05:08:37 | train] - Train Epoch: [132] [153600/1281167 (12%)]	Loss: 1.185008
[2022-04-06 05:09:03 | train] - Train Epoch: [132] [166400/1281167 (13%)]	Loss: 0.738233
[2022-04-06 05:09:30 | train] - Train Epoch: [132] [179200/1281167 (14%)]	Loss: 0.858866
[2022-04-06 05:09:58 | train] - Train Epoch: [132] [192000/1281167 (15%)]	Loss: 0.755056
[2022-04-06 05:10:26 | train] - Train Epoch: [132] [204800/1281167 (16%)]	Loss: 0.804516
[2022-04-06 05:10:54 | train] - Train Epoch: [132] [217600/1281167 (17%)]	Loss: 0.765180
[2022-04-06 05:11:22 | train] - Train Epoch: [132] [230400/1281167 (18%)]	Loss: 0.883307
[2022-04-06 05:11:49 | train] - Train Epoch: [132] [243200/1281167 (19%)]	Loss: 0.675618
[2022-04-06 05:12:16 | train] - Train Epoch: [132] [256000/1281167 (20%)]	Loss: 0.674899
[2022-04-06 05:12:44 | train] - Train Epoch: [132] [268800/1281167 (21%)]	Loss: 0.630251
[2022-04-06 05:13:11 | train] - Train Epoch: [132] [281600/1281167 (22%)]	Loss: 0.716390
[2022-04-06 05:13:39 | train] - Train Epoch: [132] [294400/1281167 (23%)]	Loss: 0.931781
[2022-04-06 05:14:06 | train] - Train Epoch: [132] [307200/1281167 (24%)]	Loss: 0.854893
[2022-04-06 05:14:34 | train] - Train Epoch: [132] [320000/1281167 (25%)]	Loss: 0.727700
[2022-04-06 05:15:02 | train] - Train Epoch: [132] [332800/1281167 (26%)]	Loss: 1.039114
[2022-04-06 05:15:29 | train] - Train Epoch: [132] [345600/1281167 (27%)]	Loss: 0.826084
[2022-04-06 05:15:56 | train] - Train Epoch: [132] [358400/1281167 (28%)]	Loss: 0.738476
[2022-04-06 05:16:24 | train] - Train Epoch: [132] [371200/1281167 (29%)]	Loss: 0.608098
[2022-04-06 05:16:51 | train] - Train Epoch: [132] [384000/1281167 (30%)]	Loss: 0.752795
[2022-04-06 05:17:19 | train] - Train Epoch: [132] [396800/1281167 (31%)]	Loss: 0.649455
[2022-04-06 05:17:47 | train] - Train Epoch: [132] [409600/1281167 (32%)]	Loss: 0.759652
[2022-04-06 05:18:15 | train] - Train Epoch: [132] [422400/1281167 (33%)]	Loss: 0.765720
[2022-04-06 05:18:45 | train] - Train Epoch: [132] [435200/1281167 (34%)]	Loss: 0.735661
[2022-04-06 05:19:13 | train] - Train Epoch: [132] [448000/1281167 (35%)]	Loss: 0.739048
[2022-04-06 05:19:41 | train] - Train Epoch: [132] [460800/1281167 (36%)]	Loss: 0.436690
[2022-04-06 05:20:09 | train] - Train Epoch: [132] [473600/1281167 (37%)]	Loss: 0.750687
[2022-04-06 05:20:36 | train] - Train Epoch: [132] [486400/1281167 (38%)]	Loss: 0.810261
[2022-04-06 05:21:03 | train] - Train Epoch: [132] [499200/1281167 (39%)]	Loss: 0.829656
[2022-04-06 05:21:31 | train] - Train Epoch: [132] [512000/1281167 (40%)]	Loss: 0.727879
[2022-04-06 05:21:59 | train] - Train Epoch: [132] [524800/1281167 (41%)]	Loss: 0.697825
[2022-04-06 05:22:28 | train] - Train Epoch: [132] [537600/1281167 (42%)]	Loss: 0.733694
[2022-04-06 05:22:55 | train] - Train Epoch: [132] [550400/1281167 (43%)]	Loss: 0.710651
[2022-04-06 05:23:22 | train] - Train Epoch: [132] [563200/1281167 (44%)]	Loss: 0.643630
[2022-04-06 05:23:50 | train] - Train Epoch: [132] [576000/1281167 (45%)]	Loss: 0.684331
[2022-04-06 05:24:18 | train] - Train Epoch: [132] [588800/1281167 (46%)]	Loss: 0.756738
[2022-04-06 05:24:45 | train] - Train Epoch: [132] [601600/1281167 (47%)]	Loss: 0.833329
[2022-04-06 05:25:12 | train] - Train Epoch: [132] [614400/1281167 (48%)]	Loss: 0.606248
[2022-04-06 05:25:39 | train] - Train Epoch: [132] [627200/1281167 (49%)]	Loss: 0.873100
[2022-04-06 05:26:06 | train] - Train Epoch: [132] [640000/1281167 (50%)]	Loss: 0.807852
[2022-04-06 05:26:34 | train] - Train Epoch: [132] [652800/1281167 (51%)]	Loss: 0.765072
[2022-04-06 05:27:01 | train] - Train Epoch: [132] [665600/1281167 (52%)]	Loss: 0.692011
[2022-04-06 05:27:29 | train] - Train Epoch: [132] [678400/1281167 (53%)]	Loss: 0.742296
[2022-04-06 05:27:58 | train] - Train Epoch: [132] [691200/1281167 (54%)]	Loss: 0.754209
[2022-04-06 05:28:27 | train] - Train Epoch: [132] [704000/1281167 (55%)]	Loss: 0.702019
[2022-04-06 05:28:55 | train] - Train Epoch: [132] [716800/1281167 (56%)]	Loss: 0.697464
[2022-04-06 05:29:22 | train] - Train Epoch: [132] [729600/1281167 (57%)]	Loss: 0.594348
[2022-04-06 05:29:50 | train] - Train Epoch: [132] [742400/1281167 (58%)]	Loss: 0.874066
[2022-04-06 05:30:17 | train] - Train Epoch: [132] [755200/1281167 (59%)]	Loss: 0.830628
[2022-04-06 05:30:45 | train] - Train Epoch: [132] [768000/1281167 (60%)]	Loss: 0.544338
[2022-04-06 05:31:13 | train] - Train Epoch: [132] [780800/1281167 (61%)]	Loss: 0.827770
[2022-04-06 05:31:42 | train] - Train Epoch: [132] [793600/1281167 (62%)]	Loss: 0.807732
[2022-04-06 05:32:09 | train] - Train Epoch: [132] [806400/1281167 (63%)]	Loss: 0.648461
[2022-04-06 05:32:36 | train] - Train Epoch: [132] [819200/1281167 (64%)]	Loss: 0.809338
[2022-04-06 05:33:04 | train] - Train Epoch: [132] [832000/1281167 (65%)]	Loss: 0.936963
[2022-04-06 05:33:32 | train] - Train Epoch: [132] [844800/1281167 (66%)]	Loss: 0.768775
[2022-04-06 05:33:59 | train] - Train Epoch: [132] [857600/1281167 (67%)]	Loss: 0.644586
[2022-04-06 05:34:26 | train] - Train Epoch: [132] [870400/1281167 (68%)]	Loss: 0.842356
[2022-04-06 05:34:55 | train] - Train Epoch: [132] [883200/1281167 (69%)]	Loss: 0.852654
[2022-04-06 05:35:22 | train] - Train Epoch: [132] [896000/1281167 (70%)]	Loss: 0.788328
[2022-04-06 05:35:51 | train] - Train Epoch: [132] [908800/1281167 (71%)]	Loss: 0.981565
[2022-04-06 05:36:19 | train] - Train Epoch: [132] [921600/1281167 (72%)]	Loss: 0.720031
[2022-04-06 05:36:47 | train] - Train Epoch: [132] [934400/1281167 (73%)]	Loss: 0.608730
[2022-04-06 05:37:15 | train] - Train Epoch: [132] [947200/1281167 (74%)]	Loss: 0.689972
[2022-04-06 05:37:42 | train] - Train Epoch: [132] [960000/1281167 (75%)]	Loss: 0.913900
[2022-04-06 05:38:10 | train] - Train Epoch: [132] [972800/1281167 (76%)]	Loss: 0.991168
[2022-04-06 05:38:37 | train] - Train Epoch: [132] [985600/1281167 (77%)]	Loss: 0.801851
[2022-04-06 05:39:05 | train] - Train Epoch: [132] [998400/1281167 (78%)]	Loss: 0.708459
[2022-04-06 05:39:32 | train] - Train Epoch: [132] [1011200/1281167 (79%)]	Loss: 0.807926
[2022-04-06 05:40:00 | train] - Train Epoch: [132] [1024000/1281167 (80%)]	Loss: 0.919694
[2022-04-06 05:40:29 | train] - Train Epoch: [132] [1036800/1281167 (81%)]	Loss: 0.869884
[2022-04-06 05:40:57 | train] - Train Epoch: [132] [1049600/1281167 (82%)]	Loss: 0.868481
[2022-04-06 05:41:25 | train] - Train Epoch: [132] [1062400/1281167 (83%)]	Loss: 0.742443
[2022-04-06 05:41:52 | train] - Train Epoch: [132] [1075200/1281167 (84%)]	Loss: 0.479275
[2022-04-06 05:42:21 | train] - Train Epoch: [132] [1088000/1281167 (85%)]	Loss: 0.699459
[2022-04-06 05:42:49 | train] - Train Epoch: [132] [1100800/1281167 (86%)]	Loss: 0.691188
[2022-04-06 05:43:19 | train] - Train Epoch: [132] [1113600/1281167 (87%)]	Loss: 0.839885
[2022-04-06 05:43:47 | train] - Train Epoch: [132] [1126400/1281167 (88%)]	Loss: 0.716081
[2022-04-06 05:44:16 | train] - Train Epoch: [132] [1139200/1281167 (89%)]	Loss: 0.635895
[2022-04-06 05:44:45 | train] - Train Epoch: [132] [1152000/1281167 (90%)]	Loss: 0.653876
[2022-04-06 05:45:14 | train] - Train Epoch: [132] [1164800/1281167 (91%)]	Loss: 0.743277
[2022-04-06 05:45:43 | train] - Train Epoch: [132] [1177600/1281167 (92%)]	Loss: 0.744048
[2022-04-06 05:46:12 | train] - Train Epoch: [132] [1190400/1281167 (93%)]	Loss: 0.712672
[2022-04-06 05:46:40 | train] - Train Epoch: [132] [1203200/1281167 (94%)]	Loss: 0.531445
[2022-04-06 05:47:09 | train] - Train Epoch: [132] [1216000/1281167 (95%)]	Loss: 0.885169
[2022-04-06 05:47:38 | train] - Train Epoch: [132] [1228800/1281167 (96%)]	Loss: 0.953988
[2022-04-06 05:48:06 | train] - Train Epoch: [132] [1241600/1281167 (97%)]	Loss: 0.763805
[2022-04-06 05:48:34 | train] - Train Epoch: [132] [1254400/1281167 (98%)]	Loss: 0.864374
[2022-04-06 05:49:03 | train] - Train Epoch: [132] [1267200/1281167 (99%)]	Loss: 0.867822
[2022-04-06 05:49:31 | train] - Train Epoch: [132] [1280000/1281167 (100%)]	Loss: 0.618125
[2022-04-06 05:49:34 | train] - Train Epoch: [132]	 Average Loss: 0.739415	 Total Acc : 81.9489	 Total Top5 Acc : 93.4726
[2022-04-06 05:49:34 | train] - -------132 epoch end-----------
========================================
-------132 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 05:51:31 | train] - 
Epoch [132] Test set: Average loss: 1.4445, Accuracy: 34942/50000 (69.8565%), Top-5 Accuracy: 88.8251%

[2022-04-06 05:51:31 | train] - save intermediate epoch [132] result


[2022-04-06 05:51:37 | train] - -------133 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 05:51:39 | train] - Train Epoch: [133] [0/1281167 (0%)]	Loss: 0.824572
[2022-04-06 05:52:05 | train] - Train Epoch: [133] [12800/1281167 (1%)]	Loss: 0.577477
[2022-04-06 05:52:31 | train] - Train Epoch: [133] [25600/1281167 (2%)]	Loss: 0.858431
[2022-04-06 05:52:59 | train] - Train Epoch: [133] [38400/1281167 (3%)]	Loss: 0.765950
[2022-04-06 05:53:25 | train] - Train Epoch: [133] [51200/1281167 (4%)]	Loss: 0.674832
[2022-04-06 05:53:51 | train] - Train Epoch: [133] [64000/1281167 (5%)]	Loss: 0.892887
[2022-04-06 05:54:18 | train] - Train Epoch: [133] [76800/1281167 (6%)]	Loss: 0.874892
[2022-04-06 05:54:45 | train] - Train Epoch: [133] [89600/1281167 (7%)]	Loss: 0.538401
[2022-04-06 05:55:11 | train] - Train Epoch: [133] [102400/1281167 (8%)]	Loss: 0.560292
[2022-04-06 05:55:37 | train] - Train Epoch: [133] [115200/1281167 (9%)]	Loss: 0.434777
[2022-04-06 05:56:03 | train] - Train Epoch: [133] [128000/1281167 (10%)]	Loss: 0.864470
[2022-04-06 05:56:30 | train] - Train Epoch: [133] [140800/1281167 (11%)]	Loss: 0.912905
[2022-04-06 05:56:55 | train] - Train Epoch: [133] [153600/1281167 (12%)]	Loss: 0.807917
[2022-04-06 05:57:21 | train] - Train Epoch: [133] [166400/1281167 (13%)]	Loss: 0.958123
[2022-04-06 05:57:48 | train] - Train Epoch: [133] [179200/1281167 (14%)]	Loss: 0.875260
[2022-04-06 05:58:15 | train] - Train Epoch: [133] [192000/1281167 (15%)]	Loss: 0.801197
[2022-04-06 05:58:42 | train] - Train Epoch: [133] [204800/1281167 (16%)]	Loss: 0.729199
[2022-04-06 05:59:09 | train] - Train Epoch: [133] [217600/1281167 (17%)]	Loss: 0.958026
[2022-04-06 05:59:35 | train] - Train Epoch: [133] [230400/1281167 (18%)]	Loss: 0.947727
[2022-04-06 06:00:03 | train] - Train Epoch: [133] [243200/1281167 (19%)]	Loss: 0.873851
[2022-04-06 06:00:30 | train] - Train Epoch: [133] [256000/1281167 (20%)]	Loss: 0.750170
[2022-04-06 06:00:56 | train] - Train Epoch: [133] [268800/1281167 (21%)]	Loss: 0.682960
[2022-04-06 06:01:24 | train] - Train Epoch: [133] [281600/1281167 (22%)]	Loss: 0.899009
[2022-04-06 06:01:50 | train] - Train Epoch: [133] [294400/1281167 (23%)]	Loss: 0.938708
[2022-04-06 06:02:16 | train] - Train Epoch: [133] [307200/1281167 (24%)]	Loss: 0.610051
[2022-04-06 06:02:43 | train] - Train Epoch: [133] [320000/1281167 (25%)]	Loss: 0.760906
[2022-04-06 06:03:10 | train] - Train Epoch: [133] [332800/1281167 (26%)]	Loss: 0.760649
[2022-04-06 06:03:37 | train] - Train Epoch: [133] [345600/1281167 (27%)]	Loss: 0.565909
[2022-04-06 06:04:04 | train] - Train Epoch: [133] [358400/1281167 (28%)]	Loss: 0.802198
[2022-04-06 06:04:30 | train] - Train Epoch: [133] [371200/1281167 (29%)]	Loss: 0.680862
[2022-04-06 06:04:57 | train] - Train Epoch: [133] [384000/1281167 (30%)]	Loss: 0.725306
[2022-04-06 06:05:23 | train] - Train Epoch: [133] [396800/1281167 (31%)]	Loss: 0.618095
[2022-04-06 06:05:50 | train] - Train Epoch: [133] [409600/1281167 (32%)]	Loss: 0.580168
[2022-04-06 06:06:17 | train] - Train Epoch: [133] [422400/1281167 (33%)]	Loss: 0.716843
[2022-04-06 06:06:43 | train] - Train Epoch: [133] [435200/1281167 (34%)]	Loss: 0.705535
[2022-04-06 06:07:10 | train] - Train Epoch: [133] [448000/1281167 (35%)]	Loss: 0.541827
[2022-04-06 06:07:37 | train] - Train Epoch: [133] [460800/1281167 (36%)]	Loss: 0.953644
[2022-04-06 06:08:05 | train] - Train Epoch: [133] [473600/1281167 (37%)]	Loss: 0.807897
[2022-04-06 06:08:31 | train] - Train Epoch: [133] [486400/1281167 (38%)]	Loss: 0.848017
[2022-04-06 06:08:59 | train] - Train Epoch: [133] [499200/1281167 (39%)]	Loss: 0.589743
[2022-04-06 06:09:26 | train] - Train Epoch: [133] [512000/1281167 (40%)]	Loss: 0.770240
[2022-04-06 06:09:52 | train] - Train Epoch: [133] [524800/1281167 (41%)]	Loss: 0.954611
[2022-04-06 06:10:18 | train] - Train Epoch: [133] [537600/1281167 (42%)]	Loss: 0.783649
[2022-04-06 06:10:45 | train] - Train Epoch: [133] [550400/1281167 (43%)]	Loss: 0.900630
[2022-04-06 06:11:12 | train] - Train Epoch: [133] [563200/1281167 (44%)]	Loss: 0.735333
[2022-04-06 06:11:39 | train] - Train Epoch: [133] [576000/1281167 (45%)]	Loss: 0.641339
[2022-04-06 06:12:05 | train] - Train Epoch: [133] [588800/1281167 (46%)]	Loss: 0.644163
[2022-04-06 06:12:32 | train] - Train Epoch: [133] [601600/1281167 (47%)]	Loss: 0.949230
[2022-04-06 06:12:59 | train] - Train Epoch: [133] [614400/1281167 (48%)]	Loss: 0.832937
[2022-04-06 06:13:26 | train] - Train Epoch: [133] [627200/1281167 (49%)]	Loss: 0.802207
[2022-04-06 06:13:53 | train] - Train Epoch: [133] [640000/1281167 (50%)]	Loss: 0.783667
[2022-04-06 06:14:20 | train] - Train Epoch: [133] [652800/1281167 (51%)]	Loss: 0.699355
[2022-04-06 06:14:46 | train] - Train Epoch: [133] [665600/1281167 (52%)]	Loss: 0.581419
[2022-04-06 06:15:13 | train] - Train Epoch: [133] [678400/1281167 (53%)]	Loss: 0.778302
[2022-04-06 06:15:41 | train] - Train Epoch: [133] [691200/1281167 (54%)]	Loss: 0.699527
[2022-04-06 06:16:07 | train] - Train Epoch: [133] [704000/1281167 (55%)]	Loss: 0.719357
[2022-04-06 06:16:34 | train] - Train Epoch: [133] [716800/1281167 (56%)]	Loss: 0.746388
[2022-04-06 06:17:01 | train] - Train Epoch: [133] [729600/1281167 (57%)]	Loss: 0.582246
[2022-04-06 06:17:27 | train] - Train Epoch: [133] [742400/1281167 (58%)]	Loss: 0.482637
[2022-04-06 06:17:53 | train] - Train Epoch: [133] [755200/1281167 (59%)]	Loss: 0.586629
[2022-04-06 06:18:19 | train] - Train Epoch: [133] [768000/1281167 (60%)]	Loss: 0.754890
[2022-04-06 06:18:46 | train] - Train Epoch: [133] [780800/1281167 (61%)]	Loss: 0.814340
[2022-04-06 06:19:13 | train] - Train Epoch: [133] [793600/1281167 (62%)]	Loss: 0.536540
[2022-04-06 06:19:40 | train] - Train Epoch: [133] [806400/1281167 (63%)]	Loss: 1.142845
[2022-04-06 06:20:06 | train] - Train Epoch: [133] [819200/1281167 (64%)]	Loss: 0.736105
[2022-04-06 06:20:33 | train] - Train Epoch: [133] [832000/1281167 (65%)]	Loss: 0.765528
[2022-04-06 06:21:00 | train] - Train Epoch: [133] [844800/1281167 (66%)]	Loss: 0.643961
[2022-04-06 06:21:27 | train] - Train Epoch: [133] [857600/1281167 (67%)]	Loss: 0.699941
[2022-04-06 06:21:53 | train] - Train Epoch: [133] [870400/1281167 (68%)]	Loss: 0.629617
[2022-04-06 06:22:20 | train] - Train Epoch: [133] [883200/1281167 (69%)]	Loss: 0.782258
[2022-04-06 06:22:47 | train] - Train Epoch: [133] [896000/1281167 (70%)]	Loss: 0.609639
[2022-04-06 06:23:14 | train] - Train Epoch: [133] [908800/1281167 (71%)]	Loss: 0.653300
[2022-04-06 06:23:41 | train] - Train Epoch: [133] [921600/1281167 (72%)]	Loss: 0.748190
[2022-04-06 06:24:08 | train] - Train Epoch: [133] [934400/1281167 (73%)]	Loss: 0.811980
[2022-04-06 06:24:35 | train] - Train Epoch: [133] [947200/1281167 (74%)]	Loss: 0.821521
[2022-04-06 06:25:02 | train] - Train Epoch: [133] [960000/1281167 (75%)]	Loss: 0.798870
[2022-04-06 06:25:29 | train] - Train Epoch: [133] [972800/1281167 (76%)]	Loss: 0.862704
[2022-04-06 06:25:55 | train] - Train Epoch: [133] [985600/1281167 (77%)]	Loss: 0.684908
[2022-04-06 06:26:22 | train] - Train Epoch: [133] [998400/1281167 (78%)]	Loss: 0.819249
[2022-04-06 06:26:50 | train] - Train Epoch: [133] [1011200/1281167 (79%)]	Loss: 0.623854
[2022-04-06 06:27:16 | train] - Train Epoch: [133] [1024000/1281167 (80%)]	Loss: 0.725940
[2022-04-06 06:27:42 | train] - Train Epoch: [133] [1036800/1281167 (81%)]	Loss: 0.937855
[2022-04-06 06:28:08 | train] - Train Epoch: [133] [1049600/1281167 (82%)]	Loss: 0.683255
[2022-04-06 06:28:35 | train] - Train Epoch: [133] [1062400/1281167 (83%)]	Loss: 0.642808
[2022-04-06 06:29:02 | train] - Train Epoch: [133] [1075200/1281167 (84%)]	Loss: 0.610527
[2022-04-06 06:29:28 | train] - Train Epoch: [133] [1088000/1281167 (85%)]	Loss: 0.880503
[2022-04-06 06:29:56 | train] - Train Epoch: [133] [1100800/1281167 (86%)]	Loss: 0.775703
[2022-04-06 06:30:23 | train] - Train Epoch: [133] [1113600/1281167 (87%)]	Loss: 0.869862
[2022-04-06 06:30:50 | train] - Train Epoch: [133] [1126400/1281167 (88%)]	Loss: 0.703145
[2022-04-06 06:31:17 | train] - Train Epoch: [133] [1139200/1281167 (89%)]	Loss: 0.658009
[2022-04-06 06:31:45 | train] - Train Epoch: [133] [1152000/1281167 (90%)]	Loss: 0.760460
[2022-04-06 06:32:13 | train] - Train Epoch: [133] [1164800/1281167 (91%)]	Loss: 0.573302
[2022-04-06 06:32:40 | train] - Train Epoch: [133] [1177600/1281167 (92%)]	Loss: 0.718118
[2022-04-06 06:33:08 | train] - Train Epoch: [133] [1190400/1281167 (93%)]	Loss: 0.658167
[2022-04-06 06:33:35 | train] - Train Epoch: [133] [1203200/1281167 (94%)]	Loss: 0.725083
[2022-04-06 06:34:03 | train] - Train Epoch: [133] [1216000/1281167 (95%)]	Loss: 0.778517
[2022-04-06 06:34:30 | train] - Train Epoch: [133] [1228800/1281167 (96%)]	Loss: 0.694335
[2022-04-06 06:34:58 | train] - Train Epoch: [133] [1241600/1281167 (97%)]	Loss: 0.639778
[2022-04-06 06:35:25 | train] - Train Epoch: [133] [1254400/1281167 (98%)]	Loss: 0.700678
[2022-04-06 06:35:52 | train] - Train Epoch: [133] [1267200/1281167 (99%)]	Loss: 0.657926
[2022-04-06 06:36:20 | train] - Train Epoch: [133] [1280000/1281167 (100%)]	Loss: 0.793542
[2022-04-06 06:36:22 | train] - Train Epoch: [133]	 Average Loss: 0.738613	 Total Acc : 82.0306	 Total Top5 Acc : 93.4818
[2022-04-06 06:36:22 | train] - -------133 epoch end-----------
========================================
-------133 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 06:38:18 | train] - 
Epoch [133] Test set: Average loss: 1.4444, Accuracy: 34956/50000 (69.8857%), Top-5 Accuracy: 88.7964%

[2022-04-06 06:38:18 | train] - save intermediate epoch [133] result


[2022-04-06 06:38:24 | train] - -------134 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 06:38:26 | train] - Train Epoch: [134] [0/1281167 (0%)]	Loss: 0.615442
[2022-04-06 06:38:52 | train] - Train Epoch: [134] [12800/1281167 (1%)]	Loss: 0.670763
[2022-04-06 06:39:17 | train] - Train Epoch: [134] [25600/1281167 (2%)]	Loss: 0.686491
[2022-04-06 06:39:42 | train] - Train Epoch: [134] [38400/1281167 (3%)]	Loss: 0.872224
[2022-04-06 06:40:07 | train] - Train Epoch: [134] [51200/1281167 (4%)]	Loss: 0.765438
[2022-04-06 06:40:33 | train] - Train Epoch: [134] [64000/1281167 (5%)]	Loss: 0.552466
[2022-04-06 06:40:58 | train] - Train Epoch: [134] [76800/1281167 (6%)]	Loss: 0.612153
[2022-04-06 06:41:24 | train] - Train Epoch: [134] [89600/1281167 (7%)]	Loss: 0.877704
[2022-04-06 06:41:49 | train] - Train Epoch: [134] [102400/1281167 (8%)]	Loss: 0.941653
[2022-04-06 06:42:15 | train] - Train Epoch: [134] [115200/1281167 (9%)]	Loss: 0.792333
[2022-04-06 06:42:40 | train] - Train Epoch: [134] [128000/1281167 (10%)]	Loss: 0.655917
[2022-04-06 06:43:06 | train] - Train Epoch: [134] [140800/1281167 (11%)]	Loss: 0.675164
[2022-04-06 06:43:32 | train] - Train Epoch: [134] [153600/1281167 (12%)]	Loss: 1.078657
[2022-04-06 06:43:57 | train] - Train Epoch: [134] [166400/1281167 (13%)]	Loss: 0.415592
[2022-04-06 06:44:23 | train] - Train Epoch: [134] [179200/1281167 (14%)]	Loss: 1.043622
[2022-04-06 06:44:49 | train] - Train Epoch: [134] [192000/1281167 (15%)]	Loss: 0.848932
[2022-04-06 06:45:13 | train] - Train Epoch: [134] [204800/1281167 (16%)]	Loss: 0.511823
[2022-04-06 06:45:38 | train] - Train Epoch: [134] [217600/1281167 (17%)]	Loss: 0.626005
[2022-04-06 06:46:05 | train] - Train Epoch: [134] [230400/1281167 (18%)]	Loss: 0.655631
[2022-04-06 06:46:30 | train] - Train Epoch: [134] [243200/1281167 (19%)]	Loss: 0.646859
[2022-04-06 06:46:55 | train] - Train Epoch: [134] [256000/1281167 (20%)]	Loss: 0.672644
[2022-04-06 06:47:20 | train] - Train Epoch: [134] [268800/1281167 (21%)]	Loss: 0.688056
[2022-04-06 06:47:46 | train] - Train Epoch: [134] [281600/1281167 (22%)]	Loss: 0.789913
[2022-04-06 06:48:11 | train] - Train Epoch: [134] [294400/1281167 (23%)]	Loss: 0.596168
[2022-04-06 06:48:36 | train] - Train Epoch: [134] [307200/1281167 (24%)]	Loss: 0.746114
[2022-04-06 06:49:02 | train] - Train Epoch: [134] [320000/1281167 (25%)]	Loss: 0.468242
[2022-04-06 06:49:27 | train] - Train Epoch: [134] [332800/1281167 (26%)]	Loss: 0.901632
[2022-04-06 06:49:52 | train] - Train Epoch: [134] [345600/1281167 (27%)]	Loss: 0.720324
[2022-04-06 06:50:17 | train] - Train Epoch: [134] [358400/1281167 (28%)]	Loss: 0.498085
[2022-04-06 06:50:42 | train] - Train Epoch: [134] [371200/1281167 (29%)]	Loss: 0.711015
[2022-04-06 06:51:07 | train] - Train Epoch: [134] [384000/1281167 (30%)]	Loss: 0.713191
[2022-04-06 06:51:33 | train] - Train Epoch: [134] [396800/1281167 (31%)]	Loss: 0.906409
[2022-04-06 06:51:59 | train] - Train Epoch: [134] [409600/1281167 (32%)]	Loss: 0.743498
[2022-04-06 06:52:24 | train] - Train Epoch: [134] [422400/1281167 (33%)]	Loss: 0.606812
[2022-04-06 06:52:51 | train] - Train Epoch: [134] [435200/1281167 (34%)]	Loss: 0.709716
[2022-04-06 06:53:16 | train] - Train Epoch: [134] [448000/1281167 (35%)]	Loss: 0.820787
[2022-04-06 06:53:41 | train] - Train Epoch: [134] [460800/1281167 (36%)]	Loss: 0.877743
[2022-04-06 06:54:07 | train] - Train Epoch: [134] [473600/1281167 (37%)]	Loss: 0.766759
[2022-04-06 06:54:32 | train] - Train Epoch: [134] [486400/1281167 (38%)]	Loss: 0.552148
[2022-04-06 06:54:57 | train] - Train Epoch: [134] [499200/1281167 (39%)]	Loss: 0.549968
[2022-04-06 06:55:23 | train] - Train Epoch: [134] [512000/1281167 (40%)]	Loss: 0.878473
[2022-04-06 06:55:49 | train] - Train Epoch: [134] [524800/1281167 (41%)]	Loss: 0.700241
[2022-04-06 06:56:14 | train] - Train Epoch: [134] [537600/1281167 (42%)]	Loss: 0.573717
[2022-04-06 06:56:40 | train] - Train Epoch: [134] [550400/1281167 (43%)]	Loss: 0.829652
[2022-04-06 06:57:05 | train] - Train Epoch: [134] [563200/1281167 (44%)]	Loss: 0.713478
[2022-04-06 06:57:31 | train] - Train Epoch: [134] [576000/1281167 (45%)]	Loss: 0.914647
[2022-04-06 06:57:57 | train] - Train Epoch: [134] [588800/1281167 (46%)]	Loss: 0.826323
[2022-04-06 06:58:22 | train] - Train Epoch: [134] [601600/1281167 (47%)]	Loss: 0.801533
[2022-04-06 06:58:47 | train] - Train Epoch: [134] [614400/1281167 (48%)]	Loss: 0.888504
[2022-04-06 06:59:13 | train] - Train Epoch: [134] [627200/1281167 (49%)]	Loss: 0.475778
[2022-04-06 06:59:38 | train] - Train Epoch: [134] [640000/1281167 (50%)]	Loss: 0.743811
[2022-04-06 07:00:03 | train] - Train Epoch: [134] [652800/1281167 (51%)]	Loss: 0.773197
[2022-04-06 07:00:29 | train] - Train Epoch: [134] [665600/1281167 (52%)]	Loss: 0.563192
[2022-04-06 07:00:54 | train] - Train Epoch: [134] [678400/1281167 (53%)]	Loss: 0.993787
[2022-04-06 07:01:20 | train] - Train Epoch: [134] [691200/1281167 (54%)]	Loss: 0.801826
[2022-04-06 07:01:45 | train] - Train Epoch: [134] [704000/1281167 (55%)]	Loss: 0.925881
[2022-04-06 07:02:11 | train] - Train Epoch: [134] [716800/1281167 (56%)]	Loss: 0.827484
[2022-04-06 07:02:36 | train] - Train Epoch: [134] [729600/1281167 (57%)]	Loss: 0.561780
[2022-04-06 07:03:03 | train] - Train Epoch: [134] [742400/1281167 (58%)]	Loss: 0.708011
[2022-04-06 07:03:29 | train] - Train Epoch: [134] [755200/1281167 (59%)]	Loss: 0.943426
[2022-04-06 07:03:54 | train] - Train Epoch: [134] [768000/1281167 (60%)]	Loss: 0.696397
[2022-04-06 07:04:20 | train] - Train Epoch: [134] [780800/1281167 (61%)]	Loss: 0.679371
[2022-04-06 07:04:46 | train] - Train Epoch: [134] [793600/1281167 (62%)]	Loss: 0.750381
[2022-04-06 07:05:11 | train] - Train Epoch: [134] [806400/1281167 (63%)]	Loss: 0.793817
[2022-04-06 07:05:37 | train] - Train Epoch: [134] [819200/1281167 (64%)]	Loss: 0.509104
[2022-04-06 07:06:02 | train] - Train Epoch: [134] [832000/1281167 (65%)]	Loss: 0.758247
[2022-04-06 07:06:28 | train] - Train Epoch: [134] [844800/1281167 (66%)]	Loss: 0.681887
[2022-04-06 07:06:54 | train] - Train Epoch: [134] [857600/1281167 (67%)]	Loss: 0.697649
[2022-04-06 07:07:20 | train] - Train Epoch: [134] [870400/1281167 (68%)]	Loss: 0.693155
[2022-04-06 07:07:45 | train] - Train Epoch: [134] [883200/1281167 (69%)]	Loss: 0.641085
[2022-04-06 07:08:10 | train] - Train Epoch: [134] [896000/1281167 (70%)]	Loss: 0.576546
[2022-04-06 07:08:37 | train] - Train Epoch: [134] [908800/1281167 (71%)]	Loss: 0.735190
[2022-04-06 07:09:03 | train] - Train Epoch: [134] [921600/1281167 (72%)]	Loss: 0.640729
[2022-04-06 07:09:29 | train] - Train Epoch: [134] [934400/1281167 (73%)]	Loss: 0.723144
[2022-04-06 07:09:54 | train] - Train Epoch: [134] [947200/1281167 (74%)]	Loss: 0.586977
[2022-04-06 07:10:21 | train] - Train Epoch: [134] [960000/1281167 (75%)]	Loss: 0.694548
[2022-04-06 07:10:47 | train] - Train Epoch: [134] [972800/1281167 (76%)]	Loss: 0.549945
[2022-04-06 07:11:14 | train] - Train Epoch: [134] [985600/1281167 (77%)]	Loss: 0.709093
[2022-04-06 07:11:40 | train] - Train Epoch: [134] [998400/1281167 (78%)]	Loss: 0.834881
[2022-04-06 07:12:06 | train] - Train Epoch: [134] [1011200/1281167 (79%)]	Loss: 0.615014
[2022-04-06 07:12:32 | train] - Train Epoch: [134] [1024000/1281167 (80%)]	Loss: 0.792687
[2022-04-06 07:12:58 | train] - Train Epoch: [134] [1036800/1281167 (81%)]	Loss: 0.539578
[2022-04-06 07:13:24 | train] - Train Epoch: [134] [1049600/1281167 (82%)]	Loss: 0.694045
[2022-04-06 07:13:50 | train] - Train Epoch: [134] [1062400/1281167 (83%)]	Loss: 0.460817
[2022-04-06 07:14:17 | train] - Train Epoch: [134] [1075200/1281167 (84%)]	Loss: 0.540670
[2022-04-06 07:14:44 | train] - Train Epoch: [134] [1088000/1281167 (85%)]	Loss: 0.761699
[2022-04-06 07:15:10 | train] - Train Epoch: [134] [1100800/1281167 (86%)]	Loss: 0.686273
[2022-04-06 07:15:36 | train] - Train Epoch: [134] [1113600/1281167 (87%)]	Loss: 0.684133
[2022-04-06 07:16:02 | train] - Train Epoch: [134] [1126400/1281167 (88%)]	Loss: 0.560091
[2022-04-06 07:16:28 | train] - Train Epoch: [134] [1139200/1281167 (89%)]	Loss: 0.784568
[2022-04-06 07:16:55 | train] - Train Epoch: [134] [1152000/1281167 (90%)]	Loss: 0.756364
[2022-04-06 07:17:21 | train] - Train Epoch: [134] [1164800/1281167 (91%)]	Loss: 0.681790
[2022-04-06 07:17:47 | train] - Train Epoch: [134] [1177600/1281167 (92%)]	Loss: 0.982343
[2022-04-06 07:18:15 | train] - Train Epoch: [134] [1190400/1281167 (93%)]	Loss: 0.752769
[2022-04-06 07:18:41 | train] - Train Epoch: [134] [1203200/1281167 (94%)]	Loss: 0.905154
[2022-04-06 07:19:07 | train] - Train Epoch: [134] [1216000/1281167 (95%)]	Loss: 0.748401
[2022-04-06 07:19:34 | train] - Train Epoch: [134] [1228800/1281167 (96%)]	Loss: 1.102608
[2022-04-06 07:20:00 | train] - Train Epoch: [134] [1241600/1281167 (97%)]	Loss: 0.780947
[2022-04-06 07:20:27 | train] - Train Epoch: [134] [1254400/1281167 (98%)]	Loss: 0.842453
[2022-04-06 07:20:54 | train] - Train Epoch: [134] [1267200/1281167 (99%)]	Loss: 0.663472
[2022-04-06 07:21:20 | train] - Train Epoch: [134] [1280000/1281167 (100%)]	Loss: 0.619024
[2022-04-06 07:21:22 | train] - Train Epoch: [134]	 Average Loss: 0.735786	 Total Acc : 82.0696	 Total Top5 Acc : 93.5171
[2022-04-06 07:21:22 | train] - -------134 epoch end-----------
========================================
-------134 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 07:23:09 | train] - 
Epoch [134] Test set: Average loss: 1.4431, Accuracy: 34889/50000 (69.7518%), Top-5 Accuracy: 88.7832%

[2022-04-06 07:23:09 | train] - save intermediate epoch [134] result


[2022-04-06 07:23:15 | train] - -------135 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 07:23:17 | train] - Train Epoch: [135] [0/1281167 (0%)]	Loss: 0.851218
[2022-04-06 07:23:43 | train] - Train Epoch: [135] [12800/1281167 (1%)]	Loss: 0.734427
[2022-04-06 07:24:09 | train] - Train Epoch: [135] [25600/1281167 (2%)]	Loss: 0.775986
[2022-04-06 07:24:36 | train] - Train Epoch: [135] [38400/1281167 (3%)]	Loss: 0.732137
[2022-04-06 07:25:02 | train] - Train Epoch: [135] [51200/1281167 (4%)]	Loss: 0.533086
[2022-04-06 07:25:29 | train] - Train Epoch: [135] [64000/1281167 (5%)]	Loss: 0.868006
[2022-04-06 07:25:56 | train] - Train Epoch: [135] [76800/1281167 (6%)]	Loss: 0.586454
[2022-04-06 07:26:23 | train] - Train Epoch: [135] [89600/1281167 (7%)]	Loss: 0.592361
[2022-04-06 07:26:50 | train] - Train Epoch: [135] [102400/1281167 (8%)]	Loss: 0.598129
[2022-04-06 07:27:17 | train] - Train Epoch: [135] [115200/1281167 (9%)]	Loss: 0.653512
[2022-04-06 07:27:43 | train] - Train Epoch: [135] [128000/1281167 (10%)]	Loss: 0.651498
[2022-04-06 07:28:10 | train] - Train Epoch: [135] [140800/1281167 (11%)]	Loss: 0.825740
[2022-04-06 07:28:37 | train] - Train Epoch: [135] [153600/1281167 (12%)]	Loss: 0.818445
[2022-04-06 07:29:04 | train] - Train Epoch: [135] [166400/1281167 (13%)]	Loss: 0.671070
[2022-04-06 07:29:31 | train] - Train Epoch: [135] [179200/1281167 (14%)]	Loss: 0.768922
[2022-04-06 07:29:58 | train] - Train Epoch: [135] [192000/1281167 (15%)]	Loss: 0.590302
[2022-04-06 07:30:24 | train] - Train Epoch: [135] [204800/1281167 (16%)]	Loss: 0.827598
[2022-04-06 07:30:51 | train] - Train Epoch: [135] [217600/1281167 (17%)]	Loss: 0.815226
[2022-04-06 07:31:17 | train] - Train Epoch: [135] [230400/1281167 (18%)]	Loss: 0.608539
[2022-04-06 07:31:43 | train] - Train Epoch: [135] [243200/1281167 (19%)]	Loss: 0.810986
[2022-04-06 07:32:10 | train] - Train Epoch: [135] [256000/1281167 (20%)]	Loss: 0.747273
[2022-04-06 07:32:36 | train] - Train Epoch: [135] [268800/1281167 (21%)]	Loss: 0.622775
[2022-04-06 07:33:03 | train] - Train Epoch: [135] [281600/1281167 (22%)]	Loss: 0.666457
[2022-04-06 07:33:29 | train] - Train Epoch: [135] [294400/1281167 (23%)]	Loss: 0.954360
[2022-04-06 07:33:56 | train] - Train Epoch: [135] [307200/1281167 (24%)]	Loss: 0.975473
[2022-04-06 07:34:22 | train] - Train Epoch: [135] [320000/1281167 (25%)]	Loss: 0.680079
[2022-04-06 07:34:48 | train] - Train Epoch: [135] [332800/1281167 (26%)]	Loss: 0.740005
[2022-04-06 07:35:16 | train] - Train Epoch: [135] [345600/1281167 (27%)]	Loss: 0.695810
[2022-04-06 07:35:42 | train] - Train Epoch: [135] [358400/1281167 (28%)]	Loss: 1.014146
[2022-04-06 07:36:08 | train] - Train Epoch: [135] [371200/1281167 (29%)]	Loss: 0.865801
[2022-04-06 07:36:35 | train] - Train Epoch: [135] [384000/1281167 (30%)]	Loss: 0.476975
[2022-04-06 07:37:01 | train] - Train Epoch: [135] [396800/1281167 (31%)]	Loss: 0.837213
[2022-04-06 07:37:28 | train] - Train Epoch: [135] [409600/1281167 (32%)]	Loss: 0.550520
[2022-04-06 07:37:55 | train] - Train Epoch: [135] [422400/1281167 (33%)]	Loss: 0.699597
[2022-04-06 07:38:20 | train] - Train Epoch: [135] [435200/1281167 (34%)]	Loss: 0.980997
[2022-04-06 07:38:47 | train] - Train Epoch: [135] [448000/1281167 (35%)]	Loss: 0.560378
[2022-04-06 07:39:14 | train] - Train Epoch: [135] [460800/1281167 (36%)]	Loss: 0.548472
[2022-04-06 07:39:40 | train] - Train Epoch: [135] [473600/1281167 (37%)]	Loss: 0.776101
[2022-04-06 07:40:07 | train] - Train Epoch: [135] [486400/1281167 (38%)]	Loss: 0.597520
[2022-04-06 07:40:34 | train] - Train Epoch: [135] [499200/1281167 (39%)]	Loss: 0.574116
[2022-04-06 07:41:00 | train] - Train Epoch: [135] [512000/1281167 (40%)]	Loss: 0.867365
[2022-04-06 07:41:27 | train] - Train Epoch: [135] [524800/1281167 (41%)]	Loss: 0.713546
[2022-04-06 07:41:52 | train] - Train Epoch: [135] [537600/1281167 (42%)]	Loss: 0.774900
[2022-04-06 07:42:19 | train] - Train Epoch: [135] [550400/1281167 (43%)]	Loss: 0.754003
[2022-04-06 07:42:46 | train] - Train Epoch: [135] [563200/1281167 (44%)]	Loss: 0.736271
[2022-04-06 07:43:12 | train] - Train Epoch: [135] [576000/1281167 (45%)]	Loss: 1.037376
[2022-04-06 07:43:38 | train] - Train Epoch: [135] [588800/1281167 (46%)]	Loss: 0.624333
[2022-04-06 07:44:05 | train] - Train Epoch: [135] [601600/1281167 (47%)]	Loss: 0.826536
[2022-04-06 07:44:31 | train] - Train Epoch: [135] [614400/1281167 (48%)]	Loss: 0.930172
[2022-04-06 07:44:56 | train] - Train Epoch: [135] [627200/1281167 (49%)]	Loss: 0.744247
[2022-04-06 07:45:23 | train] - Train Epoch: [135] [640000/1281167 (50%)]	Loss: 0.578337
[2022-04-06 07:45:49 | train] - Train Epoch: [135] [652800/1281167 (51%)]	Loss: 0.820090
[2022-04-06 07:46:15 | train] - Train Epoch: [135] [665600/1281167 (52%)]	Loss: 0.637872
[2022-04-06 07:46:42 | train] - Train Epoch: [135] [678400/1281167 (53%)]	Loss: 0.741835
[2022-04-06 07:47:08 | train] - Train Epoch: [135] [691200/1281167 (54%)]	Loss: 0.656856
[2022-04-06 07:47:34 | train] - Train Epoch: [135] [704000/1281167 (55%)]	Loss: 0.833119
[2022-04-06 07:48:00 | train] - Train Epoch: [135] [716800/1281167 (56%)]	Loss: 0.824271
[2022-04-06 07:48:26 | train] - Train Epoch: [135] [729600/1281167 (57%)]	Loss: 1.074330
[2022-04-06 07:48:53 | train] - Train Epoch: [135] [742400/1281167 (58%)]	Loss: 0.963899
[2022-04-06 07:49:20 | train] - Train Epoch: [135] [755200/1281167 (59%)]	Loss: 0.710196
[2022-04-06 07:49:47 | train] - Train Epoch: [135] [768000/1281167 (60%)]	Loss: 0.871231
[2022-04-06 07:50:14 | train] - Train Epoch: [135] [780800/1281167 (61%)]	Loss: 1.016502
[2022-04-06 07:50:39 | train] - Train Epoch: [135] [793600/1281167 (62%)]	Loss: 0.620492
[2022-04-06 07:51:05 | train] - Train Epoch: [135] [806400/1281167 (63%)]	Loss: 0.542591
[2022-04-06 07:51:31 | train] - Train Epoch: [135] [819200/1281167 (64%)]	Loss: 0.707571
[2022-04-06 07:51:58 | train] - Train Epoch: [135] [832000/1281167 (65%)]	Loss: 0.892428
[2022-04-06 07:52:25 | train] - Train Epoch: [135] [844800/1281167 (66%)]	Loss: 0.705203
[2022-04-06 07:52:52 | train] - Train Epoch: [135] [857600/1281167 (67%)]	Loss: 0.644526
[2022-04-06 07:53:18 | train] - Train Epoch: [135] [870400/1281167 (68%)]	Loss: 0.526901
[2022-04-06 07:53:45 | train] - Train Epoch: [135] [883200/1281167 (69%)]	Loss: 0.599258
[2022-04-06 07:54:11 | train] - Train Epoch: [135] [896000/1281167 (70%)]	Loss: 0.793407
[2022-04-06 07:54:38 | train] - Train Epoch: [135] [908800/1281167 (71%)]	Loss: 0.594925
[2022-04-06 07:55:04 | train] - Train Epoch: [135] [921600/1281167 (72%)]	Loss: 0.746452
[2022-04-06 07:55:31 | train] - Train Epoch: [135] [934400/1281167 (73%)]	Loss: 0.736367
[2022-04-06 07:55:58 | train] - Train Epoch: [135] [947200/1281167 (74%)]	Loss: 0.831557
[2022-04-06 07:56:24 | train] - Train Epoch: [135] [960000/1281167 (75%)]	Loss: 0.500708
[2022-04-06 07:56:51 | train] - Train Epoch: [135] [972800/1281167 (76%)]	Loss: 0.625757
[2022-04-06 07:57:18 | train] - Train Epoch: [135] [985600/1281167 (77%)]	Loss: 0.505934
[2022-04-06 07:57:46 | train] - Train Epoch: [135] [998400/1281167 (78%)]	Loss: 0.718187
[2022-04-06 07:58:13 | train] - Train Epoch: [135] [1011200/1281167 (79%)]	Loss: 0.669102
[2022-04-06 07:58:40 | train] - Train Epoch: [135] [1024000/1281167 (80%)]	Loss: 0.571551
[2022-04-06 07:59:06 | train] - Train Epoch: [135] [1036800/1281167 (81%)]	Loss: 0.617833
[2022-04-06 07:59:33 | train] - Train Epoch: [135] [1049600/1281167 (82%)]	Loss: 0.695982
[2022-04-06 08:00:01 | train] - Train Epoch: [135] [1062400/1281167 (83%)]	Loss: 0.535923
[2022-04-06 08:00:28 | train] - Train Epoch: [135] [1075200/1281167 (84%)]	Loss: 0.774980
[2022-04-06 08:00:55 | train] - Train Epoch: [135] [1088000/1281167 (85%)]	Loss: 0.562705
[2022-04-06 08:01:23 | train] - Train Epoch: [135] [1100800/1281167 (86%)]	Loss: 0.621332
[2022-04-06 08:01:51 | train] - Train Epoch: [135] [1113600/1281167 (87%)]	Loss: 0.772626
[2022-04-06 08:02:18 | train] - Train Epoch: [135] [1126400/1281167 (88%)]	Loss: 1.021778
[2022-04-06 08:02:45 | train] - Train Epoch: [135] [1139200/1281167 (89%)]	Loss: 0.726752
[2022-04-06 08:03:12 | train] - Train Epoch: [135] [1152000/1281167 (90%)]	Loss: 0.758016
[2022-04-06 08:03:39 | train] - Train Epoch: [135] [1164800/1281167 (91%)]	Loss: 0.857368
[2022-04-06 08:04:07 | train] - Train Epoch: [135] [1177600/1281167 (92%)]	Loss: 0.637535
[2022-04-06 08:04:35 | train] - Train Epoch: [135] [1190400/1281167 (93%)]	Loss: 0.688163
[2022-04-06 08:05:02 | train] - Train Epoch: [135] [1203200/1281167 (94%)]	Loss: 0.687707
[2022-04-06 08:05:29 | train] - Train Epoch: [135] [1216000/1281167 (95%)]	Loss: 0.566762
[2022-04-06 08:05:56 | train] - Train Epoch: [135] [1228800/1281167 (96%)]	Loss: 0.707648
[2022-04-06 08:06:23 | train] - Train Epoch: [135] [1241600/1281167 (97%)]	Loss: 0.592390
[2022-04-06 08:06:51 | train] - Train Epoch: [135] [1254400/1281167 (98%)]	Loss: 0.762290
[2022-04-06 08:07:19 | train] - Train Epoch: [135] [1267200/1281167 (99%)]	Loss: 0.667998
[2022-04-06 08:07:47 | train] - Train Epoch: [135] [1280000/1281167 (100%)]	Loss: 0.798203
[2022-04-06 08:07:50 | train] - Train Epoch: [135]	 Average Loss: 0.733923	 Total Acc : 82.1039	 Total Top5 Acc : 93.5125
[2022-04-06 08:07:50 | train] - -------135 epoch end-----------
========================================
-------135 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 08:09:37 | train] - 
Epoch [135] Test set: Average loss: 1.4382, Accuracy: 34927/50000 (69.8314%), Top-5 Accuracy: 88.7640%

[2022-04-06 08:09:37 | train] - save intermediate epoch [135] result


[2022-04-06 08:09:43 | train] - -------136 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 08:09:45 | train] - Train Epoch: [136] [0/1281167 (0%)]	Loss: 0.702844
[2022-04-06 08:10:11 | train] - Train Epoch: [136] [12800/1281167 (1%)]	Loss: 0.710551
[2022-04-06 08:10:37 | train] - Train Epoch: [136] [25600/1281167 (2%)]	Loss: 0.639119
[2022-04-06 08:11:03 | train] - Train Epoch: [136] [38400/1281167 (3%)]	Loss: 0.825321
[2022-04-06 08:11:31 | train] - Train Epoch: [136] [51200/1281167 (4%)]	Loss: 0.968579
[2022-04-06 08:11:57 | train] - Train Epoch: [136] [64000/1281167 (5%)]	Loss: 0.852217
[2022-04-06 08:12:23 | train] - Train Epoch: [136] [76800/1281167 (6%)]	Loss: 0.616031
[2022-04-06 08:12:50 | train] - Train Epoch: [136] [89600/1281167 (7%)]	Loss: 0.707817
[2022-04-06 08:13:17 | train] - Train Epoch: [136] [102400/1281167 (8%)]	Loss: 0.784603
[2022-04-06 08:13:44 | train] - Train Epoch: [136] [115200/1281167 (9%)]	Loss: 0.748200
[2022-04-06 08:14:11 | train] - Train Epoch: [136] [128000/1281167 (10%)]	Loss: 0.650264
[2022-04-06 08:14:38 | train] - Train Epoch: [136] [140800/1281167 (11%)]	Loss: 0.688260
[2022-04-06 08:15:05 | train] - Train Epoch: [136] [153600/1281167 (12%)]	Loss: 0.791921
[2022-04-06 08:15:32 | train] - Train Epoch: [136] [166400/1281167 (13%)]	Loss: 0.469622
[2022-04-06 08:15:59 | train] - Train Epoch: [136] [179200/1281167 (14%)]	Loss: 0.881515
[2022-04-06 08:16:26 | train] - Train Epoch: [136] [192000/1281167 (15%)]	Loss: 0.730057
[2022-04-06 08:16:52 | train] - Train Epoch: [136] [204800/1281167 (16%)]	Loss: 0.714643
[2022-04-06 08:17:19 | train] - Train Epoch: [136] [217600/1281167 (17%)]	Loss: 0.764290
[2022-04-06 08:17:45 | train] - Train Epoch: [136] [230400/1281167 (18%)]	Loss: 0.678376
[2022-04-06 08:18:11 | train] - Train Epoch: [136] [243200/1281167 (19%)]	Loss: 0.794313
[2022-04-06 08:18:39 | train] - Train Epoch: [136] [256000/1281167 (20%)]	Loss: 0.739412
[2022-04-06 08:19:05 | train] - Train Epoch: [136] [268800/1281167 (21%)]	Loss: 0.997454
[2022-04-06 08:19:31 | train] - Train Epoch: [136] [281600/1281167 (22%)]	Loss: 0.806072
[2022-04-06 08:19:57 | train] - Train Epoch: [136] [294400/1281167 (23%)]	Loss: 0.944754
[2022-04-06 08:20:23 | train] - Train Epoch: [136] [307200/1281167 (24%)]	Loss: 1.019172
[2022-04-06 08:20:50 | train] - Train Epoch: [136] [320000/1281167 (25%)]	Loss: 0.867947
[2022-04-06 08:21:16 | train] - Train Epoch: [136] [332800/1281167 (26%)]	Loss: 0.683886
[2022-04-06 08:21:43 | train] - Train Epoch: [136] [345600/1281167 (27%)]	Loss: 0.573062
[2022-04-06 08:22:09 | train] - Train Epoch: [136] [358400/1281167 (28%)]	Loss: 0.681560
[2022-04-06 08:22:35 | train] - Train Epoch: [136] [371200/1281167 (29%)]	Loss: 0.715218
[2022-04-06 08:23:02 | train] - Train Epoch: [136] [384000/1281167 (30%)]	Loss: 0.625485
[2022-04-06 08:23:29 | train] - Train Epoch: [136] [396800/1281167 (31%)]	Loss: 0.713451
[2022-04-06 08:23:56 | train] - Train Epoch: [136] [409600/1281167 (32%)]	Loss: 0.617710
[2022-04-06 08:24:21 | train] - Train Epoch: [136] [422400/1281167 (33%)]	Loss: 0.595127
[2022-04-06 08:24:47 | train] - Train Epoch: [136] [435200/1281167 (34%)]	Loss: 0.908134
[2022-04-06 08:25:14 | train] - Train Epoch: [136] [448000/1281167 (35%)]	Loss: 0.638000
[2022-04-06 08:25:41 | train] - Train Epoch: [136] [460800/1281167 (36%)]	Loss: 0.792183
[2022-04-06 08:26:08 | train] - Train Epoch: [136] [473600/1281167 (37%)]	Loss: 0.887697
[2022-04-06 08:26:35 | train] - Train Epoch: [136] [486400/1281167 (38%)]	Loss: 0.760035
[2022-04-06 08:27:02 | train] - Train Epoch: [136] [499200/1281167 (39%)]	Loss: 0.736370
[2022-04-06 08:27:28 | train] - Train Epoch: [136] [512000/1281167 (40%)]	Loss: 0.865819
[2022-04-06 08:27:55 | train] - Train Epoch: [136] [524800/1281167 (41%)]	Loss: 0.726834
[2022-04-06 08:28:22 | train] - Train Epoch: [136] [537600/1281167 (42%)]	Loss: 0.656304
[2022-04-06 08:28:48 | train] - Train Epoch: [136] [550400/1281167 (43%)]	Loss: 0.556259
[2022-04-06 08:29:15 | train] - Train Epoch: [136] [563200/1281167 (44%)]	Loss: 0.637468
[2022-04-06 08:29:43 | train] - Train Epoch: [136] [576000/1281167 (45%)]	Loss: 0.622236
[2022-04-06 08:30:09 | train] - Train Epoch: [136] [588800/1281167 (46%)]	Loss: 0.743314
[2022-04-06 08:30:36 | train] - Train Epoch: [136] [601600/1281167 (47%)]	Loss: 0.725348
[2022-04-06 08:31:03 | train] - Train Epoch: [136] [614400/1281167 (48%)]	Loss: 0.998707
[2022-04-06 08:31:30 | train] - Train Epoch: [136] [627200/1281167 (49%)]	Loss: 0.762660
[2022-04-06 08:31:57 | train] - Train Epoch: [136] [640000/1281167 (50%)]	Loss: 0.785820
[2022-04-06 08:32:24 | train] - Train Epoch: [136] [652800/1281167 (51%)]	Loss: 0.816217
[2022-04-06 08:32:51 | train] - Train Epoch: [136] [665600/1281167 (52%)]	Loss: 0.724539
[2022-04-06 08:33:18 | train] - Train Epoch: [136] [678400/1281167 (53%)]	Loss: 0.752823
[2022-04-06 08:33:45 | train] - Train Epoch: [136] [691200/1281167 (54%)]	Loss: 0.710388
[2022-04-06 08:34:12 | train] - Train Epoch: [136] [704000/1281167 (55%)]	Loss: 0.883540
[2022-04-06 08:34:38 | train] - Train Epoch: [136] [716800/1281167 (56%)]	Loss: 0.691253
[2022-04-06 08:35:05 | train] - Train Epoch: [136] [729600/1281167 (57%)]	Loss: 0.924120
[2022-04-06 08:35:32 | train] - Train Epoch: [136] [742400/1281167 (58%)]	Loss: 0.634380
[2022-04-06 08:35:59 | train] - Train Epoch: [136] [755200/1281167 (59%)]	Loss: 0.654880
[2022-04-06 08:36:26 | train] - Train Epoch: [136] [768000/1281167 (60%)]	Loss: 0.479780
[2022-04-06 08:36:53 | train] - Train Epoch: [136] [780800/1281167 (61%)]	Loss: 0.696553
[2022-04-06 08:37:20 | train] - Train Epoch: [136] [793600/1281167 (62%)]	Loss: 0.974157
[2022-04-06 08:37:47 | train] - Train Epoch: [136] [806400/1281167 (63%)]	Loss: 0.789136
[2022-04-06 08:38:14 | train] - Train Epoch: [136] [819200/1281167 (64%)]	Loss: 0.850441
[2022-04-06 08:38:42 | train] - Train Epoch: [136] [832000/1281167 (65%)]	Loss: 0.737763
[2022-04-06 08:39:08 | train] - Train Epoch: [136] [844800/1281167 (66%)]	Loss: 0.630023
[2022-04-06 08:39:35 | train] - Train Epoch: [136] [857600/1281167 (67%)]	Loss: 0.588251
[2022-04-06 08:40:02 | train] - Train Epoch: [136] [870400/1281167 (68%)]	Loss: 1.020763
[2022-04-06 08:40:29 | train] - Train Epoch: [136] [883200/1281167 (69%)]	Loss: 0.720571
[2022-04-06 08:40:56 | train] - Train Epoch: [136] [896000/1281167 (70%)]	Loss: 0.868573
[2022-04-06 08:41:23 | train] - Train Epoch: [136] [908800/1281167 (71%)]	Loss: 0.799049
[2022-04-06 08:41:50 | train] - Train Epoch: [136] [921600/1281167 (72%)]	Loss: 0.765721
[2022-04-06 08:42:17 | train] - Train Epoch: [136] [934400/1281167 (73%)]	Loss: 0.657945
[2022-04-06 08:42:45 | train] - Train Epoch: [136] [947200/1281167 (74%)]	Loss: 0.905200
[2022-04-06 08:43:11 | train] - Train Epoch: [136] [960000/1281167 (75%)]	Loss: 0.539110
[2022-04-06 08:43:38 | train] - Train Epoch: [136] [972800/1281167 (76%)]	Loss: 0.622651
[2022-04-06 08:44:05 | train] - Train Epoch: [136] [985600/1281167 (77%)]	Loss: 0.863641
[2022-04-06 08:44:32 | train] - Train Epoch: [136] [998400/1281167 (78%)]	Loss: 0.637931
[2022-04-06 08:45:01 | train] - Train Epoch: [136] [1011200/1281167 (79%)]	Loss: 0.653572
[2022-04-06 08:45:28 | train] - Train Epoch: [136] [1024000/1281167 (80%)]	Loss: 0.887105
[2022-04-06 08:45:55 | train] - Train Epoch: [136] [1036800/1281167 (81%)]	Loss: 0.736525
[2022-04-06 08:46:22 | train] - Train Epoch: [136] [1049600/1281167 (82%)]	Loss: 0.899820
[2022-04-06 08:46:49 | train] - Train Epoch: [136] [1062400/1281167 (83%)]	Loss: 0.553859
[2022-04-06 08:47:16 | train] - Train Epoch: [136] [1075200/1281167 (84%)]	Loss: 0.591935
[2022-04-06 08:47:43 | train] - Train Epoch: [136] [1088000/1281167 (85%)]	Loss: 0.720585
[2022-04-06 08:48:10 | train] - Train Epoch: [136] [1100800/1281167 (86%)]	Loss: 0.571506
[2022-04-06 08:48:38 | train] - Train Epoch: [136] [1113600/1281167 (87%)]	Loss: 0.626150
[2022-04-06 08:49:05 | train] - Train Epoch: [136] [1126400/1281167 (88%)]	Loss: 0.596924
[2022-04-06 08:49:33 | train] - Train Epoch: [136] [1139200/1281167 (89%)]	Loss: 0.717762
[2022-04-06 08:50:01 | train] - Train Epoch: [136] [1152000/1281167 (90%)]	Loss: 0.839650
[2022-04-06 08:50:29 | train] - Train Epoch: [136] [1164800/1281167 (91%)]	Loss: 0.621320
[2022-04-06 08:50:57 | train] - Train Epoch: [136] [1177600/1281167 (92%)]	Loss: 0.747616
[2022-04-06 08:51:25 | train] - Train Epoch: [136] [1190400/1281167 (93%)]	Loss: 0.615172
[2022-04-06 08:51:52 | train] - Train Epoch: [136] [1203200/1281167 (94%)]	Loss: 0.578502
[2022-04-06 08:52:20 | train] - Train Epoch: [136] [1216000/1281167 (95%)]	Loss: 0.930437
[2022-04-06 08:52:48 | train] - Train Epoch: [136] [1228800/1281167 (96%)]	Loss: 0.825266
[2022-04-06 08:53:15 | train] - Train Epoch: [136] [1241600/1281167 (97%)]	Loss: 0.580857
[2022-04-06 08:53:43 | train] - Train Epoch: [136] [1254400/1281167 (98%)]	Loss: 0.522277
[2022-04-06 08:54:11 | train] - Train Epoch: [136] [1267200/1281167 (99%)]	Loss: 0.741297
[2022-04-06 08:54:39 | train] - Train Epoch: [136] [1280000/1281167 (100%)]	Loss: 0.733218
[2022-04-06 08:54:41 | train] - Train Epoch: [136]	 Average Loss: 0.732508	 Total Acc : 82.1488	 Total Top5 Acc : 93.5412
[2022-04-06 08:54:41 | train] - -------136 epoch end-----------
========================================
-------136 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 08:56:38 | train] - 
Epoch [136] Test set: Average loss: 1.4328, Accuracy: 34886/50000 (69.7458%), Top-5 Accuracy: 88.7780%

[2022-04-06 08:56:38 | train] - save intermediate epoch [136] result


[2022-04-06 08:56:45 | train] - -------137 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 08:56:47 | train] - Train Epoch: [137] [0/1281167 (0%)]	Loss: 0.921739
[2022-04-06 08:57:12 | train] - Train Epoch: [137] [12800/1281167 (1%)]	Loss: 0.545245
[2022-04-06 08:57:38 | train] - Train Epoch: [137] [25600/1281167 (2%)]	Loss: 0.889636
[2022-04-06 08:58:06 | train] - Train Epoch: [137] [38400/1281167 (3%)]	Loss: 0.858212
[2022-04-06 08:58:32 | train] - Train Epoch: [137] [51200/1281167 (4%)]	Loss: 0.743233
[2022-04-06 08:58:58 | train] - Train Epoch: [137] [64000/1281167 (5%)]	Loss: 0.826184
[2022-04-06 08:59:25 | train] - Train Epoch: [137] [76800/1281167 (6%)]	Loss: 1.033034
[2022-04-06 08:59:53 | train] - Train Epoch: [137] [89600/1281167 (7%)]	Loss: 0.881348
[2022-04-06 09:00:19 | train] - Train Epoch: [137] [102400/1281167 (8%)]	Loss: 0.745813
[2022-04-06 09:00:46 | train] - Train Epoch: [137] [115200/1281167 (9%)]	Loss: 0.530419
[2022-04-06 09:01:13 | train] - Train Epoch: [137] [128000/1281167 (10%)]	Loss: 0.681447
[2022-04-06 09:01:38 | train] - Train Epoch: [137] [140800/1281167 (11%)]	Loss: 0.794602
[2022-04-06 09:02:05 | train] - Train Epoch: [137] [153600/1281167 (12%)]	Loss: 0.849690
[2022-04-06 09:02:32 | train] - Train Epoch: [137] [166400/1281167 (13%)]	Loss: 0.969616
[2022-04-06 09:02:58 | train] - Train Epoch: [137] [179200/1281167 (14%)]	Loss: 0.700088
[2022-04-06 09:03:25 | train] - Train Epoch: [137] [192000/1281167 (15%)]	Loss: 0.925621
[2022-04-06 09:03:52 | train] - Train Epoch: [137] [204800/1281167 (16%)]	Loss: 1.007735
[2022-04-06 09:04:19 | train] - Train Epoch: [137] [217600/1281167 (17%)]	Loss: 0.660088
[2022-04-06 09:04:45 | train] - Train Epoch: [137] [230400/1281167 (18%)]	Loss: 0.861664
[2022-04-06 09:05:11 | train] - Train Epoch: [137] [243200/1281167 (19%)]	Loss: 0.633680
[2022-04-06 09:05:37 | train] - Train Epoch: [137] [256000/1281167 (20%)]	Loss: 0.755814
[2022-04-06 09:06:04 | train] - Train Epoch: [137] [268800/1281167 (21%)]	Loss: 0.971401
[2022-04-06 09:06:30 | train] - Train Epoch: [137] [281600/1281167 (22%)]	Loss: 0.779503
[2022-04-06 09:06:56 | train] - Train Epoch: [137] [294400/1281167 (23%)]	Loss: 0.626826
[2022-04-06 09:07:22 | train] - Train Epoch: [137] [307200/1281167 (24%)]	Loss: 0.990431
[2022-04-06 09:07:50 | train] - Train Epoch: [137] [320000/1281167 (25%)]	Loss: 0.802418
[2022-04-06 09:08:16 | train] - Train Epoch: [137] [332800/1281167 (26%)]	Loss: 0.618256
[2022-04-06 09:08:43 | train] - Train Epoch: [137] [345600/1281167 (27%)]	Loss: 0.548884
[2022-04-06 09:09:10 | train] - Train Epoch: [137] [358400/1281167 (28%)]	Loss: 0.930241
[2022-04-06 09:09:37 | train] - Train Epoch: [137] [371200/1281167 (29%)]	Loss: 0.733344
[2022-04-06 09:10:03 | train] - Train Epoch: [137] [384000/1281167 (30%)]	Loss: 0.610211
[2022-04-06 09:10:30 | train] - Train Epoch: [137] [396800/1281167 (31%)]	Loss: 0.639499
[2022-04-06 09:10:56 | train] - Train Epoch: [137] [409600/1281167 (32%)]	Loss: 0.657942
[2022-04-06 09:11:22 | train] - Train Epoch: [137] [422400/1281167 (33%)]	Loss: 0.734173
[2022-04-06 09:11:49 | train] - Train Epoch: [137] [435200/1281167 (34%)]	Loss: 0.703597
[2022-04-06 09:12:16 | train] - Train Epoch: [137] [448000/1281167 (35%)]	Loss: 0.603845
[2022-04-06 09:12:42 | train] - Train Epoch: [137] [460800/1281167 (36%)]	Loss: 0.868756
[2022-04-06 09:13:09 | train] - Train Epoch: [137] [473600/1281167 (37%)]	Loss: 0.875796
[2022-04-06 09:13:36 | train] - Train Epoch: [137] [486400/1281167 (38%)]	Loss: 0.815741
[2022-04-06 09:14:03 | train] - Train Epoch: [137] [499200/1281167 (39%)]	Loss: 0.723488
[2022-04-06 09:14:29 | train] - Train Epoch: [137] [512000/1281167 (40%)]	Loss: 0.768516
[2022-04-06 09:14:55 | train] - Train Epoch: [137] [524800/1281167 (41%)]	Loss: 0.745988
[2022-04-06 09:15:22 | train] - Train Epoch: [137] [537600/1281167 (42%)]	Loss: 0.728761
[2022-04-06 09:15:49 | train] - Train Epoch: [137] [550400/1281167 (43%)]	Loss: 0.583539
[2022-04-06 09:16:14 | train] - Train Epoch: [137] [563200/1281167 (44%)]	Loss: 0.735296
[2022-04-06 09:16:41 | train] - Train Epoch: [137] [576000/1281167 (45%)]	Loss: 0.449434
[2022-04-06 09:17:08 | train] - Train Epoch: [137] [588800/1281167 (46%)]	Loss: 0.896521
[2022-04-06 09:17:34 | train] - Train Epoch: [137] [601600/1281167 (47%)]	Loss: 0.802904
[2022-04-06 09:18:01 | train] - Train Epoch: [137] [614400/1281167 (48%)]	Loss: 0.534830
[2022-04-06 09:18:28 | train] - Train Epoch: [137] [627200/1281167 (49%)]	Loss: 0.693767
[2022-04-06 09:18:54 | train] - Train Epoch: [137] [640000/1281167 (50%)]	Loss: 0.630410
[2022-04-06 09:19:20 | train] - Train Epoch: [137] [652800/1281167 (51%)]	Loss: 0.782552
[2022-04-06 09:19:47 | train] - Train Epoch: [137] [665600/1281167 (52%)]	Loss: 0.608328
[2022-04-06 09:20:13 | train] - Train Epoch: [137] [678400/1281167 (53%)]	Loss: 0.737861
[2022-04-06 09:20:40 | train] - Train Epoch: [137] [691200/1281167 (54%)]	Loss: 0.617066
[2022-04-06 09:21:06 | train] - Train Epoch: [137] [704000/1281167 (55%)]	Loss: 0.630812
[2022-04-06 09:21:33 | train] - Train Epoch: [137] [716800/1281167 (56%)]	Loss: 0.857821
[2022-04-06 09:21:59 | train] - Train Epoch: [137] [729600/1281167 (57%)]	Loss: 0.532276
[2022-04-06 09:22:26 | train] - Train Epoch: [137] [742400/1281167 (58%)]	Loss: 0.640013
[2022-04-06 09:22:53 | train] - Train Epoch: [137] [755200/1281167 (59%)]	Loss: 0.655879
[2022-04-06 09:23:20 | train] - Train Epoch: [137] [768000/1281167 (60%)]	Loss: 0.866895
[2022-04-06 09:23:46 | train] - Train Epoch: [137] [780800/1281167 (61%)]	Loss: 0.773333
[2022-04-06 09:24:14 | train] - Train Epoch: [137] [793600/1281167 (62%)]	Loss: 0.728213
[2022-04-06 09:24:40 | train] - Train Epoch: [137] [806400/1281167 (63%)]	Loss: 0.794600
[2022-04-06 09:25:07 | train] - Train Epoch: [137] [819200/1281167 (64%)]	Loss: 0.839404
[2022-04-06 09:25:33 | train] - Train Epoch: [137] [832000/1281167 (65%)]	Loss: 1.097108
[2022-04-06 09:26:00 | train] - Train Epoch: [137] [844800/1281167 (66%)]	Loss: 0.574491
[2022-04-06 09:26:27 | train] - Train Epoch: [137] [857600/1281167 (67%)]	Loss: 0.978770
[2022-04-06 09:26:55 | train] - Train Epoch: [137] [870400/1281167 (68%)]	Loss: 0.875879
[2022-04-06 09:27:22 | train] - Train Epoch: [137] [883200/1281167 (69%)]	Loss: 0.871187
[2022-04-06 09:27:49 | train] - Train Epoch: [137] [896000/1281167 (70%)]	Loss: 0.772551
[2022-04-06 09:28:16 | train] - Train Epoch: [137] [908800/1281167 (71%)]	Loss: 0.619834
[2022-04-06 09:28:43 | train] - Train Epoch: [137] [921600/1281167 (72%)]	Loss: 0.866418
[2022-04-06 09:29:10 | train] - Train Epoch: [137] [934400/1281167 (73%)]	Loss: 0.846738
[2022-04-06 09:29:37 | train] - Train Epoch: [137] [947200/1281167 (74%)]	Loss: 0.537920
[2022-04-06 09:30:04 | train] - Train Epoch: [137] [960000/1281167 (75%)]	Loss: 1.074845
[2022-04-06 09:30:31 | train] - Train Epoch: [137] [972800/1281167 (76%)]	Loss: 0.765734
[2022-04-06 09:30:57 | train] - Train Epoch: [137] [985600/1281167 (77%)]	Loss: 0.676228
[2022-04-06 09:31:24 | train] - Train Epoch: [137] [998400/1281167 (78%)]	Loss: 0.807013
[2022-04-06 09:31:51 | train] - Train Epoch: [137] [1011200/1281167 (79%)]	Loss: 0.803946
[2022-04-06 09:32:18 | train] - Train Epoch: [137] [1024000/1281167 (80%)]	Loss: 0.833735
[2022-04-06 09:32:46 | train] - Train Epoch: [137] [1036800/1281167 (81%)]	Loss: 0.689067
[2022-04-06 09:33:13 | train] - Train Epoch: [137] [1049600/1281167 (82%)]	Loss: 0.697047
[2022-04-06 09:33:40 | train] - Train Epoch: [137] [1062400/1281167 (83%)]	Loss: 0.555225
[2022-04-06 09:34:07 | train] - Train Epoch: [137] [1075200/1281167 (84%)]	Loss: 0.691211
[2022-04-06 09:34:34 | train] - Train Epoch: [137] [1088000/1281167 (85%)]	Loss: 0.719182
[2022-04-06 09:35:00 | train] - Train Epoch: [137] [1100800/1281167 (86%)]	Loss: 0.483739
[2022-04-06 09:35:28 | train] - Train Epoch: [137] [1113600/1281167 (87%)]	Loss: 0.679596
[2022-04-06 09:35:55 | train] - Train Epoch: [137] [1126400/1281167 (88%)]	Loss: 0.529831
[2022-04-06 09:36:22 | train] - Train Epoch: [137] [1139200/1281167 (89%)]	Loss: 0.697040
[2022-04-06 09:36:49 | train] - Train Epoch: [137] [1152000/1281167 (90%)]	Loss: 0.818252
[2022-04-06 09:37:17 | train] - Train Epoch: [137] [1164800/1281167 (91%)]	Loss: 0.953849
[2022-04-06 09:37:45 | train] - Train Epoch: [137] [1177600/1281167 (92%)]	Loss: 0.698255
[2022-04-06 09:38:13 | train] - Train Epoch: [137] [1190400/1281167 (93%)]	Loss: 0.757229
[2022-04-06 09:38:41 | train] - Train Epoch: [137] [1203200/1281167 (94%)]	Loss: 0.906564
[2022-04-06 09:39:10 | train] - Train Epoch: [137] [1216000/1281167 (95%)]	Loss: 0.451459
[2022-04-06 09:39:37 | train] - Train Epoch: [137] [1228800/1281167 (96%)]	Loss: 0.583342
[2022-04-06 09:40:05 | train] - Train Epoch: [137] [1241600/1281167 (97%)]	Loss: 0.768055
[2022-04-06 09:40:33 | train] - Train Epoch: [137] [1254400/1281167 (98%)]	Loss: 0.689203
[2022-04-06 09:41:00 | train] - Train Epoch: [137] [1267200/1281167 (99%)]	Loss: 0.454163
[2022-04-06 09:41:27 | train] - Train Epoch: [137] [1280000/1281167 (100%)]	Loss: 0.601514
[2022-04-06 09:41:29 | train] - Train Epoch: [137]	 Average Loss: 0.730762	 Total Acc : 82.1999	 Total Top5 Acc : 93.5321
[2022-04-06 09:41:29 | train] - -------137 epoch end-----------
========================================
-------137 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 09:43:27 | train] - 
Epoch [137] Test set: Average loss: 1.4333, Accuracy: 34961/50000 (69.8933%), Top-5 Accuracy: 88.8211%

[2022-04-06 09:43:27 | train] - save intermediate epoch [137] result


[2022-04-06 09:43:34 | train] - -------138 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 09:43:36 | train] - Train Epoch: [138] [0/1281167 (0%)]	Loss: 0.884830
[2022-04-06 09:44:03 | train] - Train Epoch: [138] [12800/1281167 (1%)]	Loss: 0.858630
[2022-04-06 09:44:29 | train] - Train Epoch: [138] [25600/1281167 (2%)]	Loss: 0.902997
[2022-04-06 09:44:55 | train] - Train Epoch: [138] [38400/1281167 (3%)]	Loss: 0.712911
[2022-04-06 09:45:21 | train] - Train Epoch: [138] [51200/1281167 (4%)]	Loss: 0.742176
[2022-04-06 09:45:47 | train] - Train Epoch: [138] [64000/1281167 (5%)]	Loss: 0.904344
[2022-04-06 09:46:14 | train] - Train Epoch: [138] [76800/1281167 (6%)]	Loss: 0.656469
[2022-04-06 09:46:41 | train] - Train Epoch: [138] [89600/1281167 (7%)]	Loss: 0.975780
[2022-04-06 09:47:08 | train] - Train Epoch: [138] [102400/1281167 (8%)]	Loss: 0.989741
[2022-04-06 09:47:35 | train] - Train Epoch: [138] [115200/1281167 (9%)]	Loss: 0.829112
[2022-04-06 09:48:01 | train] - Train Epoch: [138] [128000/1281167 (10%)]	Loss: 0.685105
[2022-04-06 09:48:28 | train] - Train Epoch: [138] [140800/1281167 (11%)]	Loss: 0.789145
[2022-04-06 09:48:54 | train] - Train Epoch: [138] [153600/1281167 (12%)]	Loss: 0.422198
[2022-04-06 09:49:20 | train] - Train Epoch: [138] [166400/1281167 (13%)]	Loss: 0.630219
[2022-04-06 09:49:47 | train] - Train Epoch: [138] [179200/1281167 (14%)]	Loss: 0.781778
[2022-04-06 09:50:14 | train] - Train Epoch: [138] [192000/1281167 (15%)]	Loss: 0.688235
[2022-04-06 09:50:39 | train] - Train Epoch: [138] [204800/1281167 (16%)]	Loss: 0.921481
[2022-04-06 09:51:07 | train] - Train Epoch: [138] [217600/1281167 (17%)]	Loss: 0.744629
[2022-04-06 09:51:32 | train] - Train Epoch: [138] [230400/1281167 (18%)]	Loss: 0.635589
[2022-04-06 09:51:59 | train] - Train Epoch: [138] [243200/1281167 (19%)]	Loss: 0.896447
[2022-04-06 09:52:26 | train] - Train Epoch: [138] [256000/1281167 (20%)]	Loss: 1.011750
[2022-04-06 09:52:52 | train] - Train Epoch: [138] [268800/1281167 (21%)]	Loss: 0.814201
[2022-04-06 09:53:18 | train] - Train Epoch: [138] [281600/1281167 (22%)]	Loss: 0.706105
[2022-04-06 09:53:45 | train] - Train Epoch: [138] [294400/1281167 (23%)]	Loss: 0.595342
[2022-04-06 09:54:10 | train] - Train Epoch: [138] [307200/1281167 (24%)]	Loss: 0.781678
[2022-04-06 09:54:36 | train] - Train Epoch: [138] [320000/1281167 (25%)]	Loss: 0.930865
[2022-04-06 09:55:01 | train] - Train Epoch: [138] [332800/1281167 (26%)]	Loss: 0.699721
[2022-04-06 09:55:28 | train] - Train Epoch: [138] [345600/1281167 (27%)]	Loss: 0.645664
[2022-04-06 09:55:55 | train] - Train Epoch: [138] [358400/1281167 (28%)]	Loss: 0.839854
[2022-04-06 09:56:21 | train] - Train Epoch: [138] [371200/1281167 (29%)]	Loss: 0.766725
[2022-04-06 09:56:48 | train] - Train Epoch: [138] [384000/1281167 (30%)]	Loss: 0.604045
[2022-04-06 09:57:15 | train] - Train Epoch: [138] [396800/1281167 (31%)]	Loss: 0.690669
[2022-04-06 09:57:42 | train] - Train Epoch: [138] [409600/1281167 (32%)]	Loss: 0.771609
[2022-04-06 09:58:09 | train] - Train Epoch: [138] [422400/1281167 (33%)]	Loss: 0.868860
[2022-04-06 09:58:36 | train] - Train Epoch: [138] [435200/1281167 (34%)]	Loss: 0.622997
[2022-04-06 09:59:02 | train] - Train Epoch: [138] [448000/1281167 (35%)]	Loss: 0.764147
[2022-04-06 09:59:29 | train] - Train Epoch: [138] [460800/1281167 (36%)]	Loss: 0.807832
[2022-04-06 09:59:55 | train] - Train Epoch: [138] [473600/1281167 (37%)]	Loss: 0.559330
[2022-04-06 10:00:21 | train] - Train Epoch: [138] [486400/1281167 (38%)]	Loss: 0.636725
[2022-04-06 10:00:48 | train] - Train Epoch: [138] [499200/1281167 (39%)]	Loss: 0.604822
[2022-04-06 10:01:15 | train] - Train Epoch: [138] [512000/1281167 (40%)]	Loss: 0.578737
[2022-04-06 10:01:41 | train] - Train Epoch: [138] [524800/1281167 (41%)]	Loss: 0.692146
[2022-04-06 10:02:07 | train] - Train Epoch: [138] [537600/1281167 (42%)]	Loss: 0.753502
[2022-04-06 10:02:34 | train] - Train Epoch: [138] [550400/1281167 (43%)]	Loss: 0.609647
[2022-04-06 10:03:00 | train] - Train Epoch: [138] [563200/1281167 (44%)]	Loss: 0.722136
[2022-04-06 10:03:26 | train] - Train Epoch: [138] [576000/1281167 (45%)]	Loss: 0.789534
[2022-04-06 10:03:53 | train] - Train Epoch: [138] [588800/1281167 (46%)]	Loss: 0.870447
[2022-04-06 10:04:19 | train] - Train Epoch: [138] [601600/1281167 (47%)]	Loss: 0.587297
[2022-04-06 10:04:45 | train] - Train Epoch: [138] [614400/1281167 (48%)]	Loss: 0.683396
[2022-04-06 10:05:11 | train] - Train Epoch: [138] [627200/1281167 (49%)]	Loss: 0.646834
[2022-04-06 10:05:37 | train] - Train Epoch: [138] [640000/1281167 (50%)]	Loss: 0.760049
[2022-04-06 10:06:03 | train] - Train Epoch: [138] [652800/1281167 (51%)]	Loss: 0.811019
[2022-04-06 10:06:30 | train] - Train Epoch: [138] [665600/1281167 (52%)]	Loss: 0.702741
[2022-04-06 10:06:57 | train] - Train Epoch: [138] [678400/1281167 (53%)]	Loss: 0.541984
[2022-04-06 10:07:23 | train] - Train Epoch: [138] [691200/1281167 (54%)]	Loss: 0.531753
[2022-04-06 10:07:51 | train] - Train Epoch: [138] [704000/1281167 (55%)]	Loss: 0.569676
[2022-04-06 10:08:18 | train] - Train Epoch: [138] [716800/1281167 (56%)]	Loss: 0.714058
[2022-04-06 10:08:45 | train] - Train Epoch: [138] [729600/1281167 (57%)]	Loss: 0.680904
[2022-04-06 10:09:11 | train] - Train Epoch: [138] [742400/1281167 (58%)]	Loss: 0.754298
[2022-04-06 10:09:38 | train] - Train Epoch: [138] [755200/1281167 (59%)]	Loss: 0.857361
[2022-04-06 10:10:06 | train] - Train Epoch: [138] [768000/1281167 (60%)]	Loss: 1.004509
[2022-04-06 10:10:32 | train] - Train Epoch: [138] [780800/1281167 (61%)]	Loss: 0.901127
[2022-04-06 10:10:59 | train] - Train Epoch: [138] [793600/1281167 (62%)]	Loss: 0.670306
[2022-04-06 10:11:25 | train] - Train Epoch: [138] [806400/1281167 (63%)]	Loss: 0.744231
[2022-04-06 10:11:51 | train] - Train Epoch: [138] [819200/1281167 (64%)]	Loss: 0.689678
[2022-04-06 10:12:18 | train] - Train Epoch: [138] [832000/1281167 (65%)]	Loss: 0.788918
[2022-04-06 10:12:45 | train] - Train Epoch: [138] [844800/1281167 (66%)]	Loss: 0.676233
[2022-04-06 10:13:12 | train] - Train Epoch: [138] [857600/1281167 (67%)]	Loss: 1.103432
[2022-04-06 10:13:38 | train] - Train Epoch: [138] [870400/1281167 (68%)]	Loss: 0.703955
[2022-04-06 10:14:04 | train] - Train Epoch: [138] [883200/1281167 (69%)]	Loss: 0.878531
[2022-04-06 10:14:32 | train] - Train Epoch: [138] [896000/1281167 (70%)]	Loss: 0.796684
[2022-04-06 10:14:58 | train] - Train Epoch: [138] [908800/1281167 (71%)]	Loss: 0.595205
[2022-04-06 10:15:26 | train] - Train Epoch: [138] [921600/1281167 (72%)]	Loss: 0.691633
[2022-04-06 10:15:53 | train] - Train Epoch: [138] [934400/1281167 (73%)]	Loss: 0.751579
[2022-04-06 10:16:20 | train] - Train Epoch: [138] [947200/1281167 (74%)]	Loss: 0.864753
[2022-04-06 10:16:47 | train] - Train Epoch: [138] [960000/1281167 (75%)]	Loss: 0.752977
[2022-04-06 10:17:14 | train] - Train Epoch: [138] [972800/1281167 (76%)]	Loss: 0.567661
[2022-04-06 10:17:41 | train] - Train Epoch: [138] [985600/1281167 (77%)]	Loss: 0.363034
[2022-04-06 10:18:08 | train] - Train Epoch: [138] [998400/1281167 (78%)]	Loss: 0.866687
[2022-04-06 10:18:34 | train] - Train Epoch: [138] [1011200/1281167 (79%)]	Loss: 0.851012
[2022-04-06 10:19:01 | train] - Train Epoch: [138] [1024000/1281167 (80%)]	Loss: 0.547897
[2022-04-06 10:19:27 | train] - Train Epoch: [138] [1036800/1281167 (81%)]	Loss: 0.666643
[2022-04-06 10:19:55 | train] - Train Epoch: [138] [1049600/1281167 (82%)]	Loss: 0.712685
[2022-04-06 10:20:22 | train] - Train Epoch: [138] [1062400/1281167 (83%)]	Loss: 0.619060
[2022-04-06 10:20:49 | train] - Train Epoch: [138] [1075200/1281167 (84%)]	Loss: 0.497576
[2022-04-06 10:21:18 | train] - Train Epoch: [138] [1088000/1281167 (85%)]	Loss: 0.799908
[2022-04-06 10:21:45 | train] - Train Epoch: [138] [1100800/1281167 (86%)]	Loss: 0.713507
[2022-04-06 10:22:13 | train] - Train Epoch: [138] [1113600/1281167 (87%)]	Loss: 0.781821
[2022-04-06 10:22:40 | train] - Train Epoch: [138] [1126400/1281167 (88%)]	Loss: 0.914468
[2022-04-06 10:23:07 | train] - Train Epoch: [138] [1139200/1281167 (89%)]	Loss: 0.551693
[2022-04-06 10:23:34 | train] - Train Epoch: [138] [1152000/1281167 (90%)]	Loss: 0.665847
[2022-04-06 10:24:01 | train] - Train Epoch: [138] [1164800/1281167 (91%)]	Loss: 0.684964
[2022-04-06 10:24:28 | train] - Train Epoch: [138] [1177600/1281167 (92%)]	Loss: 0.843134
[2022-04-06 10:24:55 | train] - Train Epoch: [138] [1190400/1281167 (93%)]	Loss: 0.540926
[2022-04-06 10:25:23 | train] - Train Epoch: [138] [1203200/1281167 (94%)]	Loss: 0.741885
[2022-04-06 10:25:51 | train] - Train Epoch: [138] [1216000/1281167 (95%)]	Loss: 0.683981
[2022-04-06 10:26:18 | train] - Train Epoch: [138] [1228800/1281167 (96%)]	Loss: 0.637751
[2022-04-06 10:26:46 | train] - Train Epoch: [138] [1241600/1281167 (97%)]	Loss: 0.894571
[2022-04-06 10:27:14 | train] - Train Epoch: [138] [1254400/1281167 (98%)]	Loss: 0.698561
[2022-04-06 10:27:42 | train] - Train Epoch: [138] [1267200/1281167 (99%)]	Loss: 0.884744
[2022-04-06 10:28:09 | train] - Train Epoch: [138] [1280000/1281167 (100%)]	Loss: 0.688750
[2022-04-06 10:28:12 | train] - Train Epoch: [138]	 Average Loss: 0.729209	 Total Acc : 82.2798	 Total Top5 Acc : 93.5530
[2022-04-06 10:28:12 | train] - -------138 epoch end-----------
========================================
-------138 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 10:30:03 | train] - 
Epoch [138] Test set: Average loss: 1.4439, Accuracy: 34931/50000 (69.8346%), Top-5 Accuracy: 88.7052%

[2022-04-06 10:30:03 | train] - save intermediate epoch [138] result


[2022-04-06 10:30:11 | train] - -------139 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 10:30:13 | train] - Train Epoch: [139] [0/1281167 (0%)]	Loss: 0.794073
[2022-04-06 10:30:39 | train] - Train Epoch: [139] [12800/1281167 (1%)]	Loss: 0.842504
[2022-04-06 10:31:05 | train] - Train Epoch: [139] [25600/1281167 (2%)]	Loss: 0.819822
[2022-04-06 10:31:32 | train] - Train Epoch: [139] [38400/1281167 (3%)]	Loss: 0.782686
[2022-04-06 10:31:59 | train] - Train Epoch: [139] [51200/1281167 (4%)]	Loss: 0.769122
[2022-04-06 10:32:25 | train] - Train Epoch: [139] [64000/1281167 (5%)]	Loss: 0.772111
[2022-04-06 10:32:52 | train] - Train Epoch: [139] [76800/1281167 (6%)]	Loss: 0.973068
[2022-04-06 10:33:18 | train] - Train Epoch: [139] [89600/1281167 (7%)]	Loss: 0.427292
[2022-04-06 10:33:44 | train] - Train Epoch: [139] [102400/1281167 (8%)]	Loss: 0.881885
[2022-04-06 10:34:12 | train] - Train Epoch: [139] [115200/1281167 (9%)]	Loss: 0.526822
[2022-04-06 10:34:39 | train] - Train Epoch: [139] [128000/1281167 (10%)]	Loss: 0.510928
[2022-04-06 10:35:06 | train] - Train Epoch: [139] [140800/1281167 (11%)]	Loss: 0.891176
[2022-04-06 10:35:32 | train] - Train Epoch: [139] [153600/1281167 (12%)]	Loss: 0.666913
[2022-04-06 10:35:58 | train] - Train Epoch: [139] [166400/1281167 (13%)]	Loss: 0.573593
[2022-04-06 10:36:25 | train] - Train Epoch: [139] [179200/1281167 (14%)]	Loss: 0.915316
[2022-04-06 10:36:52 | train] - Train Epoch: [139] [192000/1281167 (15%)]	Loss: 0.989013
[2022-04-06 10:37:18 | train] - Train Epoch: [139] [204800/1281167 (16%)]	Loss: 0.726350
[2022-04-06 10:37:44 | train] - Train Epoch: [139] [217600/1281167 (17%)]	Loss: 0.453831
[2022-04-06 10:38:10 | train] - Train Epoch: [139] [230400/1281167 (18%)]	Loss: 0.757349
[2022-04-06 10:38:37 | train] - Train Epoch: [139] [243200/1281167 (19%)]	Loss: 0.730675
[2022-04-06 10:39:04 | train] - Train Epoch: [139] [256000/1281167 (20%)]	Loss: 0.651128
[2022-04-06 10:39:31 | train] - Train Epoch: [139] [268800/1281167 (21%)]	Loss: 0.538841
[2022-04-06 10:39:56 | train] - Train Epoch: [139] [281600/1281167 (22%)]	Loss: 1.012311
[2022-04-06 10:40:23 | train] - Train Epoch: [139] [294400/1281167 (23%)]	Loss: 0.741441
[2022-04-06 10:40:50 | train] - Train Epoch: [139] [307200/1281167 (24%)]	Loss: 0.865919
[2022-04-06 10:41:17 | train] - Train Epoch: [139] [320000/1281167 (25%)]	Loss: 0.685800
[2022-04-06 10:41:43 | train] - Train Epoch: [139] [332800/1281167 (26%)]	Loss: 0.886770
[2022-04-06 10:42:10 | train] - Train Epoch: [139] [345600/1281167 (27%)]	Loss: 0.716763
[2022-04-06 10:42:36 | train] - Train Epoch: [139] [358400/1281167 (28%)]	Loss: 0.612858
[2022-04-06 10:43:03 | train] - Train Epoch: [139] [371200/1281167 (29%)]	Loss: 0.749327
[2022-04-06 10:43:29 | train] - Train Epoch: [139] [384000/1281167 (30%)]	Loss: 0.750415
[2022-04-06 10:43:56 | train] - Train Epoch: [139] [396800/1281167 (31%)]	Loss: 0.667487
[2022-04-06 10:44:22 | train] - Train Epoch: [139] [409600/1281167 (32%)]	Loss: 0.718069
[2022-04-06 10:44:49 | train] - Train Epoch: [139] [422400/1281167 (33%)]	Loss: 0.742472
[2022-04-06 10:45:16 | train] - Train Epoch: [139] [435200/1281167 (34%)]	Loss: 0.800526
[2022-04-06 10:45:42 | train] - Train Epoch: [139] [448000/1281167 (35%)]	Loss: 0.964806
[2022-04-06 10:46:09 | train] - Train Epoch: [139] [460800/1281167 (36%)]	Loss: 0.602377
[2022-04-06 10:46:36 | train] - Train Epoch: [139] [473600/1281167 (37%)]	Loss: 0.853126
[2022-04-06 10:47:04 | train] - Train Epoch: [139] [486400/1281167 (38%)]	Loss: 0.867134
[2022-04-06 10:47:31 | train] - Train Epoch: [139] [499200/1281167 (39%)]	Loss: 0.738458
[2022-04-06 10:47:56 | train] - Train Epoch: [139] [512000/1281167 (40%)]	Loss: 0.801568
[2022-04-06 10:48:23 | train] - Train Epoch: [139] [524800/1281167 (41%)]	Loss: 0.527833
[2022-04-06 10:48:51 | train] - Train Epoch: [139] [537600/1281167 (42%)]	Loss: 0.748069
[2022-04-06 10:49:17 | train] - Train Epoch: [139] [550400/1281167 (43%)]	Loss: 0.553186
[2022-04-06 10:49:43 | train] - Train Epoch: [139] [563200/1281167 (44%)]	Loss: 0.836884
[2022-04-06 10:50:09 | train] - Train Epoch: [139] [576000/1281167 (45%)]	Loss: 0.875869
[2022-04-06 10:50:37 | train] - Train Epoch: [139] [588800/1281167 (46%)]	Loss: 0.706359
[2022-04-06 10:51:03 | train] - Train Epoch: [139] [601600/1281167 (47%)]	Loss: 0.695997
[2022-04-06 10:51:29 | train] - Train Epoch: [139] [614400/1281167 (48%)]	Loss: 0.635877
[2022-04-06 10:51:56 | train] - Train Epoch: [139] [627200/1281167 (49%)]	Loss: 0.819683
[2022-04-06 10:52:23 | train] - Train Epoch: [139] [640000/1281167 (50%)]	Loss: 0.686273
[2022-04-06 10:52:49 | train] - Train Epoch: [139] [652800/1281167 (51%)]	Loss: 0.706306
[2022-04-06 10:53:15 | train] - Train Epoch: [139] [665600/1281167 (52%)]	Loss: 0.829498
[2022-04-06 10:53:42 | train] - Train Epoch: [139] [678400/1281167 (53%)]	Loss: 0.825682
[2022-04-06 10:54:09 | train] - Train Epoch: [139] [691200/1281167 (54%)]	Loss: 0.507357
[2022-04-06 10:54:36 | train] - Train Epoch: [139] [704000/1281167 (55%)]	Loss: 0.967806
[2022-04-06 10:55:03 | train] - Train Epoch: [139] [716800/1281167 (56%)]	Loss: 0.565358
[2022-04-06 10:55:29 | train] - Train Epoch: [139] [729600/1281167 (57%)]	Loss: 0.833618
[2022-04-06 10:55:56 | train] - Train Epoch: [139] [742400/1281167 (58%)]	Loss: 0.646770
[2022-04-06 10:56:22 | train] - Train Epoch: [139] [755200/1281167 (59%)]	Loss: 0.721631
[2022-04-06 10:56:49 | train] - Train Epoch: [139] [768000/1281167 (60%)]	Loss: 0.642875
[2022-04-06 10:57:15 | train] - Train Epoch: [139] [780800/1281167 (61%)]	Loss: 0.680796
[2022-04-06 10:57:41 | train] - Train Epoch: [139] [793600/1281167 (62%)]	Loss: 0.684380
[2022-04-06 10:58:09 | train] - Train Epoch: [139] [806400/1281167 (63%)]	Loss: 0.619021
[2022-04-06 10:58:36 | train] - Train Epoch: [139] [819200/1281167 (64%)]	Loss: 0.559149
[2022-04-06 10:59:02 | train] - Train Epoch: [139] [832000/1281167 (65%)]	Loss: 0.600169
[2022-04-06 10:59:29 | train] - Train Epoch: [139] [844800/1281167 (66%)]	Loss: 0.680750
[2022-04-06 10:59:56 | train] - Train Epoch: [139] [857600/1281167 (67%)]	Loss: 0.661888
[2022-04-06 11:00:22 | train] - Train Epoch: [139] [870400/1281167 (68%)]	Loss: 0.768330
[2022-04-06 11:00:48 | train] - Train Epoch: [139] [883200/1281167 (69%)]	Loss: 0.712114
[2022-04-06 11:01:15 | train] - Train Epoch: [139] [896000/1281167 (70%)]	Loss: 0.553746
[2022-04-06 11:01:42 | train] - Train Epoch: [139] [908800/1281167 (71%)]	Loss: 0.766109
[2022-04-06 11:02:08 | train] - Train Epoch: [139] [921600/1281167 (72%)]	Loss: 0.728421
[2022-04-06 11:02:35 | train] - Train Epoch: [139] [934400/1281167 (73%)]	Loss: 0.912854
[2022-04-06 11:03:02 | train] - Train Epoch: [139] [947200/1281167 (74%)]	Loss: 1.084334
[2022-04-06 11:03:30 | train] - Train Epoch: [139] [960000/1281167 (75%)]	Loss: 0.626865
[2022-04-06 11:03:57 | train] - Train Epoch: [139] [972800/1281167 (76%)]	Loss: 0.540450
[2022-04-06 11:04:23 | train] - Train Epoch: [139] [985600/1281167 (77%)]	Loss: 0.620535
[2022-04-06 11:04:50 | train] - Train Epoch: [139] [998400/1281167 (78%)]	Loss: 0.587087
[2022-04-06 11:05:16 | train] - Train Epoch: [139] [1011200/1281167 (79%)]	Loss: 0.989822
[2022-04-06 11:05:43 | train] - Train Epoch: [139] [1024000/1281167 (80%)]	Loss: 0.814872
[2022-04-06 11:06:09 | train] - Train Epoch: [139] [1036800/1281167 (81%)]	Loss: 0.594629
[2022-04-06 11:06:36 | train] - Train Epoch: [139] [1049600/1281167 (82%)]	Loss: 0.844757
[2022-04-06 11:07:04 | train] - Train Epoch: [139] [1062400/1281167 (83%)]	Loss: 0.749536
[2022-04-06 11:07:30 | train] - Train Epoch: [139] [1075200/1281167 (84%)]	Loss: 0.773908
[2022-04-06 11:07:57 | train] - Train Epoch: [139] [1088000/1281167 (85%)]	Loss: 0.713504
[2022-04-06 11:08:24 | train] - Train Epoch: [139] [1100800/1281167 (86%)]	Loss: 0.618080
[2022-04-06 11:08:51 | train] - Train Epoch: [139] [1113600/1281167 (87%)]	Loss: 0.770394
[2022-04-06 11:09:19 | train] - Train Epoch: [139] [1126400/1281167 (88%)]	Loss: 0.647110
[2022-04-06 11:09:46 | train] - Train Epoch: [139] [1139200/1281167 (89%)]	Loss: 0.697704
[2022-04-06 11:10:14 | train] - Train Epoch: [139] [1152000/1281167 (90%)]	Loss: 0.923272
[2022-04-06 11:10:42 | train] - Train Epoch: [139] [1164800/1281167 (91%)]	Loss: 0.769340
[2022-04-06 11:11:09 | train] - Train Epoch: [139] [1177600/1281167 (92%)]	Loss: 0.795138
[2022-04-06 11:11:36 | train] - Train Epoch: [139] [1190400/1281167 (93%)]	Loss: 0.759782
[2022-04-06 11:12:04 | train] - Train Epoch: [139] [1203200/1281167 (94%)]	Loss: 0.887481
[2022-04-06 11:12:31 | train] - Train Epoch: [139] [1216000/1281167 (95%)]	Loss: 0.706144
[2022-04-06 11:12:59 | train] - Train Epoch: [139] [1228800/1281167 (96%)]	Loss: 0.773993
[2022-04-06 11:13:27 | train] - Train Epoch: [139] [1241600/1281167 (97%)]	Loss: 0.740680
[2022-04-06 11:13:54 | train] - Train Epoch: [139] [1254400/1281167 (98%)]	Loss: 0.909816
[2022-04-06 11:14:22 | train] - Train Epoch: [139] [1267200/1281167 (99%)]	Loss: 1.020625
[2022-04-06 11:14:50 | train] - Train Epoch: [139] [1280000/1281167 (100%)]	Loss: 0.632498
[2022-04-06 11:14:52 | train] - Train Epoch: [139]	 Average Loss: 0.726082	 Total Acc : 82.3145	 Total Top5 Acc : 93.5722
[2022-04-06 11:14:52 | train] - -------139 epoch end-----------
========================================
-------139 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 11:16:47 | train] - 
Epoch [139] Test set: Average loss: 1.4422, Accuracy: 34877/50000 (69.7291%), Top-5 Accuracy: 88.8095%

[2022-04-06 11:16:47 | train] - save intermediate epoch [139] result


[2022-04-06 11:16:55 | train] - -------140 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 11:16:57 | train] - Train Epoch: [140] [0/1281167 (0%)]	Loss: 0.509639
[2022-04-06 11:17:25 | train] - Train Epoch: [140] [12800/1281167 (1%)]	Loss: 0.874954
[2022-04-06 11:17:52 | train] - Train Epoch: [140] [25600/1281167 (2%)]	Loss: 0.578868
[2022-04-06 11:18:20 | train] - Train Epoch: [140] [38400/1281167 (3%)]	Loss: 0.777556
[2022-04-06 11:18:48 | train] - Train Epoch: [140] [51200/1281167 (4%)]	Loss: 0.937317
[2022-04-06 11:19:15 | train] - Train Epoch: [140] [64000/1281167 (5%)]	Loss: 0.672432
[2022-04-06 11:19:43 | train] - Train Epoch: [140] [76800/1281167 (6%)]	Loss: 0.755191
[2022-04-06 11:20:11 | train] - Train Epoch: [140] [89600/1281167 (7%)]	Loss: 0.648689
[2022-04-06 11:20:38 | train] - Train Epoch: [140] [102400/1281167 (8%)]	Loss: 0.757806
[2022-04-06 11:21:06 | train] - Train Epoch: [140] [115200/1281167 (9%)]	Loss: 0.566325
[2022-04-06 11:21:34 | train] - Train Epoch: [140] [128000/1281167 (10%)]	Loss: 0.632962
[2022-04-06 11:22:01 | train] - Train Epoch: [140] [140800/1281167 (11%)]	Loss: 0.658205
[2022-04-06 11:22:29 | train] - Train Epoch: [140] [153600/1281167 (12%)]	Loss: 0.850714
[2022-04-06 11:22:57 | train] - Train Epoch: [140] [166400/1281167 (13%)]	Loss: 0.811527
[2022-04-06 11:23:24 | train] - Train Epoch: [140] [179200/1281167 (14%)]	Loss: 0.594092
[2022-04-06 11:23:52 | train] - Train Epoch: [140] [192000/1281167 (15%)]	Loss: 0.691801
[2022-04-06 11:24:20 | train] - Train Epoch: [140] [204800/1281167 (16%)]	Loss: 0.693022
[2022-04-06 11:24:48 | train] - Train Epoch: [140] [217600/1281167 (17%)]	Loss: 0.601019
[2022-04-06 11:25:16 | train] - Train Epoch: [140] [230400/1281167 (18%)]	Loss: 0.624620
[2022-04-06 11:25:44 | train] - Train Epoch: [140] [243200/1281167 (19%)]	Loss: 0.765758
[2022-04-06 11:26:12 | train] - Train Epoch: [140] [256000/1281167 (20%)]	Loss: 0.773773
[2022-04-06 11:26:40 | train] - Train Epoch: [140] [268800/1281167 (21%)]	Loss: 0.468351
[2022-04-06 11:27:08 | train] - Train Epoch: [140] [281600/1281167 (22%)]	Loss: 0.575479
[2022-04-06 11:27:34 | train] - Train Epoch: [140] [294400/1281167 (23%)]	Loss: 0.841410
[2022-04-06 11:28:02 | train] - Train Epoch: [140] [307200/1281167 (24%)]	Loss: 0.791981
[2022-04-06 11:28:29 | train] - Train Epoch: [140] [320000/1281167 (25%)]	Loss: 0.676288
[2022-04-06 11:28:56 | train] - Train Epoch: [140] [332800/1281167 (26%)]	Loss: 0.732670
[2022-04-06 11:29:24 | train] - Train Epoch: [140] [345600/1281167 (27%)]	Loss: 0.900189
[2022-04-06 11:29:51 | train] - Train Epoch: [140] [358400/1281167 (28%)]	Loss: 0.735582
[2022-04-06 11:30:19 | train] - Train Epoch: [140] [371200/1281167 (29%)]	Loss: 0.521172
[2022-04-06 11:30:46 | train] - Train Epoch: [140] [384000/1281167 (30%)]	Loss: 0.735776
[2022-04-06 11:31:13 | train] - Train Epoch: [140] [396800/1281167 (31%)]	Loss: 0.828959
[2022-04-06 11:31:40 | train] - Train Epoch: [140] [409600/1281167 (32%)]	Loss: 0.539701
[2022-04-06 11:32:07 | train] - Train Epoch: [140] [422400/1281167 (33%)]	Loss: 0.494621
[2022-04-06 11:32:35 | train] - Train Epoch: [140] [435200/1281167 (34%)]	Loss: 0.748010
[2022-04-06 11:33:02 | train] - Train Epoch: [140] [448000/1281167 (35%)]	Loss: 0.689130
[2022-04-06 11:33:30 | train] - Train Epoch: [140] [460800/1281167 (36%)]	Loss: 0.739198
[2022-04-06 11:33:58 | train] - Train Epoch: [140] [473600/1281167 (37%)]	Loss: 0.585485
[2022-04-06 11:34:26 | train] - Train Epoch: [140] [486400/1281167 (38%)]	Loss: 0.606238
[2022-04-06 11:34:54 | train] - Train Epoch: [140] [499200/1281167 (39%)]	Loss: 0.670663
[2022-04-06 11:35:21 | train] - Train Epoch: [140] [512000/1281167 (40%)]	Loss: 0.817261
[2022-04-06 11:35:49 | train] - Train Epoch: [140] [524800/1281167 (41%)]	Loss: 0.506895
[2022-04-06 11:36:16 | train] - Train Epoch: [140] [537600/1281167 (42%)]	Loss: 0.663785
[2022-04-06 11:36:44 | train] - Train Epoch: [140] [550400/1281167 (43%)]	Loss: 0.718768
[2022-04-06 11:37:12 | train] - Train Epoch: [140] [563200/1281167 (44%)]	Loss: 0.707151
[2022-04-06 11:37:40 | train] - Train Epoch: [140] [576000/1281167 (45%)]	Loss: 0.727883
[2022-04-06 11:38:06 | train] - Train Epoch: [140] [588800/1281167 (46%)]	Loss: 1.002124
[2022-04-06 11:38:34 | train] - Train Epoch: [140] [601600/1281167 (47%)]	Loss: 0.401731
[2022-04-06 11:39:01 | train] - Train Epoch: [140] [614400/1281167 (48%)]	Loss: 0.724643
[2022-04-06 11:39:28 | train] - Train Epoch: [140] [627200/1281167 (49%)]	Loss: 0.673539
[2022-04-06 11:39:55 | train] - Train Epoch: [140] [640000/1281167 (50%)]	Loss: 0.667702
[2022-04-06 11:40:23 | train] - Train Epoch: [140] [652800/1281167 (51%)]	Loss: 0.649265
[2022-04-06 11:40:50 | train] - Train Epoch: [140] [665600/1281167 (52%)]	Loss: 0.781970
[2022-04-06 11:41:17 | train] - Train Epoch: [140] [678400/1281167 (53%)]	Loss: 0.782542
[2022-04-06 11:41:45 | train] - Train Epoch: [140] [691200/1281167 (54%)]	Loss: 0.627563
[2022-04-06 11:42:13 | train] - Train Epoch: [140] [704000/1281167 (55%)]	Loss: 0.756529
[2022-04-06 11:42:41 | train] - Train Epoch: [140] [716800/1281167 (56%)]	Loss: 0.633158
[2022-04-06 11:43:08 | train] - Train Epoch: [140] [729600/1281167 (57%)]	Loss: 0.786426
[2022-04-06 11:43:36 | train] - Train Epoch: [140] [742400/1281167 (58%)]	Loss: 0.867148
[2022-04-06 11:44:03 | train] - Train Epoch: [140] [755200/1281167 (59%)]	Loss: 0.853802
[2022-04-06 11:44:31 | train] - Train Epoch: [140] [768000/1281167 (60%)]	Loss: 0.630667
[2022-04-06 11:44:59 | train] - Train Epoch: [140] [780800/1281167 (61%)]	Loss: 0.490446
[2022-04-06 11:45:25 | train] - Train Epoch: [140] [793600/1281167 (62%)]	Loss: 0.442608
[2022-04-06 11:45:54 | train] - Train Epoch: [140] [806400/1281167 (63%)]	Loss: 0.567990
[2022-04-06 11:46:20 | train] - Train Epoch: [140] [819200/1281167 (64%)]	Loss: 0.904145
[2022-04-06 11:46:48 | train] - Train Epoch: [140] [832000/1281167 (65%)]	Loss: 0.745618
[2022-04-06 11:47:16 | train] - Train Epoch: [140] [844800/1281167 (66%)]	Loss: 0.869032
[2022-04-06 11:47:43 | train] - Train Epoch: [140] [857600/1281167 (67%)]	Loss: 0.590023
[2022-04-06 11:48:11 | train] - Train Epoch: [140] [870400/1281167 (68%)]	Loss: 0.700144
[2022-04-06 11:48:38 | train] - Train Epoch: [140] [883200/1281167 (69%)]	Loss: 0.630148
[2022-04-06 11:49:05 | train] - Train Epoch: [140] [896000/1281167 (70%)]	Loss: 0.707770
[2022-04-06 11:49:32 | train] - Train Epoch: [140] [908800/1281167 (71%)]	Loss: 0.589172
[2022-04-06 11:50:00 | train] - Train Epoch: [140] [921600/1281167 (72%)]	Loss: 0.626329
[2022-04-06 11:50:28 | train] - Train Epoch: [140] [934400/1281167 (73%)]	Loss: 0.735920
[2022-04-06 11:50:56 | train] - Train Epoch: [140] [947200/1281167 (74%)]	Loss: 0.641884
[2022-04-06 11:51:23 | train] - Train Epoch: [140] [960000/1281167 (75%)]	Loss: 0.541197
[2022-04-06 11:51:51 | train] - Train Epoch: [140] [972800/1281167 (76%)]	Loss: 0.681266
[2022-04-06 11:52:18 | train] - Train Epoch: [140] [985600/1281167 (77%)]	Loss: 0.459650
[2022-04-06 11:52:45 | train] - Train Epoch: [140] [998400/1281167 (78%)]	Loss: 0.787604
[2022-04-06 11:53:12 | train] - Train Epoch: [140] [1011200/1281167 (79%)]	Loss: 0.692880
[2022-04-06 11:53:40 | train] - Train Epoch: [140] [1024000/1281167 (80%)]	Loss: 0.807114
[2022-04-06 11:54:07 | train] - Train Epoch: [140] [1036800/1281167 (81%)]	Loss: 0.369212
[2022-04-06 11:54:35 | train] - Train Epoch: [140] [1049600/1281167 (82%)]	Loss: 0.696645
[2022-04-06 11:55:02 | train] - Train Epoch: [140] [1062400/1281167 (83%)]	Loss: 0.915619
[2022-04-06 11:55:30 | train] - Train Epoch: [140] [1075200/1281167 (84%)]	Loss: 0.600990
[2022-04-06 11:55:58 | train] - Train Epoch: [140] [1088000/1281167 (85%)]	Loss: 0.848646
[2022-04-06 11:56:27 | train] - Train Epoch: [140] [1100800/1281167 (86%)]	Loss: 0.660465
[2022-04-06 11:56:55 | train] - Train Epoch: [140] [1113600/1281167 (87%)]	Loss: 0.740789
[2022-04-06 11:57:23 | train] - Train Epoch: [140] [1126400/1281167 (88%)]	Loss: 0.585463
[2022-04-06 11:57:51 | train] - Train Epoch: [140] [1139200/1281167 (89%)]	Loss: 1.070321
[2022-04-06 11:58:19 | train] - Train Epoch: [140] [1152000/1281167 (90%)]	Loss: 0.637524
[2022-04-06 11:58:46 | train] - Train Epoch: [140] [1164800/1281167 (91%)]	Loss: 0.568127
[2022-04-06 11:59:15 | train] - Train Epoch: [140] [1177600/1281167 (92%)]	Loss: 0.868480
[2022-04-06 11:59:42 | train] - Train Epoch: [140] [1190400/1281167 (93%)]	Loss: 0.840673
[2022-04-06 12:00:10 | train] - Train Epoch: [140] [1203200/1281167 (94%)]	Loss: 0.722576
[2022-04-06 12:00:38 | train] - Train Epoch: [140] [1216000/1281167 (95%)]	Loss: 0.733081
[2022-04-06 12:01:06 | train] - Train Epoch: [140] [1228800/1281167 (96%)]	Loss: 0.593619
[2022-04-06 12:01:35 | train] - Train Epoch: [140] [1241600/1281167 (97%)]	Loss: 0.607150
[2022-04-06 12:02:03 | train] - Train Epoch: [140] [1254400/1281167 (98%)]	Loss: 0.864026
[2022-04-06 12:02:31 | train] - Train Epoch: [140] [1267200/1281167 (99%)]	Loss: 1.009493
[2022-04-06 12:03:00 | train] - Train Epoch: [140] [1280000/1281167 (100%)]	Loss: 0.759991
[2022-04-06 12:03:02 | train] - Train Epoch: [140]	 Average Loss: 0.723856	 Total Acc : 82.3862	 Total Top5 Acc : 93.6371
[2022-04-06 12:03:02 | train] - -------140 epoch end-----------
========================================
-------140 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 12:04:58 | train] - 
Epoch [140] Test set: Average loss: 1.4321, Accuracy: 34840/50000 (69.6515%), Top-5 Accuracy: 88.7644%

[2022-04-06 12:04:58 | train] - save intermediate epoch [140] result


[2022-04-06 12:05:07 | train] - -------141 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 12:05:08 | train] - Train Epoch: [141] [0/1281167 (0%)]	Loss: 0.849795
[2022-04-06 12:05:35 | train] - Train Epoch: [141] [12800/1281167 (1%)]	Loss: 0.852249
[2022-04-06 12:06:03 | train] - Train Epoch: [141] [25600/1281167 (2%)]	Loss: 0.715899
[2022-04-06 12:06:31 | train] - Train Epoch: [141] [38400/1281167 (3%)]	Loss: 0.789866
[2022-04-06 12:06:58 | train] - Train Epoch: [141] [51200/1281167 (4%)]	Loss: 0.805030
[2022-04-06 12:07:26 | train] - Train Epoch: [141] [64000/1281167 (5%)]	Loss: 0.913977
[2022-04-06 12:07:54 | train] - Train Epoch: [141] [76800/1281167 (6%)]	Loss: 0.704362
[2022-04-06 12:08:21 | train] - Train Epoch: [141] [89600/1281167 (7%)]	Loss: 0.576719
[2022-04-06 12:08:49 | train] - Train Epoch: [141] [102400/1281167 (8%)]	Loss: 0.657046
[2022-04-06 12:09:17 | train] - Train Epoch: [141] [115200/1281167 (9%)]	Loss: 0.896067
[2022-04-06 12:09:44 | train] - Train Epoch: [141] [128000/1281167 (10%)]	Loss: 0.585570
[2022-04-06 12:10:12 | train] - Train Epoch: [141] [140800/1281167 (11%)]	Loss: 0.685751
[2022-04-06 12:10:40 | train] - Train Epoch: [141] [153600/1281167 (12%)]	Loss: 0.550460
[2022-04-06 12:11:09 | train] - Train Epoch: [141] [166400/1281167 (13%)]	Loss: 0.807664
[2022-04-06 12:11:35 | train] - Train Epoch: [141] [179200/1281167 (14%)]	Loss: 0.971468
[2022-04-06 12:12:03 | train] - Train Epoch: [141] [192000/1281167 (15%)]	Loss: 0.710983
[2022-04-06 12:12:32 | train] - Train Epoch: [141] [204800/1281167 (16%)]	Loss: 0.661518
[2022-04-06 12:12:58 | train] - Train Epoch: [141] [217600/1281167 (17%)]	Loss: 0.848053
[2022-04-06 12:13:27 | train] - Train Epoch: [141] [230400/1281167 (18%)]	Loss: 0.763382
[2022-04-06 12:13:55 | train] - Train Epoch: [141] [243200/1281167 (19%)]	Loss: 0.433037
[2022-04-06 12:14:24 | train] - Train Epoch: [141] [256000/1281167 (20%)]	Loss: 0.636134
[2022-04-06 12:14:52 | train] - Train Epoch: [141] [268800/1281167 (21%)]	Loss: 0.436747
[2022-04-06 12:15:19 | train] - Train Epoch: [141] [281600/1281167 (22%)]	Loss: 0.716113
[2022-04-06 12:15:47 | train] - Train Epoch: [141] [294400/1281167 (23%)]	Loss: 0.596963
[2022-04-06 12:16:14 | train] - Train Epoch: [141] [307200/1281167 (24%)]	Loss: 0.855564
[2022-04-06 12:16:41 | train] - Train Epoch: [141] [320000/1281167 (25%)]	Loss: 0.673917
[2022-04-06 12:17:08 | train] - Train Epoch: [141] [332800/1281167 (26%)]	Loss: 0.838566
[2022-04-06 12:17:35 | train] - Train Epoch: [141] [345600/1281167 (27%)]	Loss: 0.605758
[2022-04-06 12:18:02 | train] - Train Epoch: [141] [358400/1281167 (28%)]	Loss: 0.681403
[2022-04-06 12:18:29 | train] - Train Epoch: [141] [371200/1281167 (29%)]	Loss: 0.630173
[2022-04-06 12:18:55 | train] - Train Epoch: [141] [384000/1281167 (30%)]	Loss: 0.674046
[2022-04-06 12:19:22 | train] - Train Epoch: [141] [396800/1281167 (31%)]	Loss: 0.642042
[2022-04-06 12:19:49 | train] - Train Epoch: [141] [409600/1281167 (32%)]	Loss: 0.874358
[2022-04-06 12:20:15 | train] - Train Epoch: [141] [422400/1281167 (33%)]	Loss: 0.595967
[2022-04-06 12:20:43 | train] - Train Epoch: [141] [435200/1281167 (34%)]	Loss: 0.509440
[2022-04-06 12:21:10 | train] - Train Epoch: [141] [448000/1281167 (35%)]	Loss: 0.862997
[2022-04-06 12:21:36 | train] - Train Epoch: [141] [460800/1281167 (36%)]	Loss: 0.917312
[2022-04-06 12:22:04 | train] - Train Epoch: [141] [473600/1281167 (37%)]	Loss: 0.681655
[2022-04-06 12:22:31 | train] - Train Epoch: [141] [486400/1281167 (38%)]	Loss: 0.713391
[2022-04-06 12:22:58 | train] - Train Epoch: [141] [499200/1281167 (39%)]	Loss: 0.661489
[2022-04-06 12:23:25 | train] - Train Epoch: [141] [512000/1281167 (40%)]	Loss: 0.684511
[2022-04-06 12:23:52 | train] - Train Epoch: [141] [524800/1281167 (41%)]	Loss: 0.634068
[2022-04-06 12:24:19 | train] - Train Epoch: [141] [537600/1281167 (42%)]	Loss: 0.571674
[2022-04-06 12:24:47 | train] - Train Epoch: [141] [550400/1281167 (43%)]	Loss: 1.053782
[2022-04-06 12:25:14 | train] - Train Epoch: [141] [563200/1281167 (44%)]	Loss: 0.732994
[2022-04-06 12:25:40 | train] - Train Epoch: [141] [576000/1281167 (45%)]	Loss: 0.704865
[2022-04-06 12:26:07 | train] - Train Epoch: [141] [588800/1281167 (46%)]	Loss: 0.837148
[2022-04-06 12:26:35 | train] - Train Epoch: [141] [601600/1281167 (47%)]	Loss: 0.893648
[2022-04-06 12:27:03 | train] - Train Epoch: [141] [614400/1281167 (48%)]	Loss: 0.590316
[2022-04-06 12:27:30 | train] - Train Epoch: [141] [627200/1281167 (49%)]	Loss: 0.735711
[2022-04-06 12:27:57 | train] - Train Epoch: [141] [640000/1281167 (50%)]	Loss: 0.547436
[2022-04-06 12:28:23 | train] - Train Epoch: [141] [652800/1281167 (51%)]	Loss: 0.701553
[2022-04-06 12:28:51 | train] - Train Epoch: [141] [665600/1281167 (52%)]	Loss: 0.430833
[2022-04-06 12:29:17 | train] - Train Epoch: [141] [678400/1281167 (53%)]	Loss: 0.613708
[2022-04-06 12:29:45 | train] - Train Epoch: [141] [691200/1281167 (54%)]	Loss: 0.863361
[2022-04-06 12:30:12 | train] - Train Epoch: [141] [704000/1281167 (55%)]	Loss: 0.616230
[2022-04-06 12:30:38 | train] - Train Epoch: [141] [716800/1281167 (56%)]	Loss: 0.564149
[2022-04-06 12:31:05 | train] - Train Epoch: [141] [729600/1281167 (57%)]	Loss: 0.860870
[2022-04-06 12:31:32 | train] - Train Epoch: [141] [742400/1281167 (58%)]	Loss: 0.810798
[2022-04-06 12:31:59 | train] - Train Epoch: [141] [755200/1281167 (59%)]	Loss: 0.690598
[2022-04-06 12:32:26 | train] - Train Epoch: [141] [768000/1281167 (60%)]	Loss: 0.771682
[2022-04-06 12:32:53 | train] - Train Epoch: [141] [780800/1281167 (61%)]	Loss: 0.763812
[2022-04-06 12:33:19 | train] - Train Epoch: [141] [793600/1281167 (62%)]	Loss: 0.655310
[2022-04-06 12:33:46 | train] - Train Epoch: [141] [806400/1281167 (63%)]	Loss: 0.681842
[2022-04-06 12:34:14 | train] - Train Epoch: [141] [819200/1281167 (64%)]	Loss: 0.885547
[2022-04-06 12:34:41 | train] - Train Epoch: [141] [832000/1281167 (65%)]	Loss: 0.778137
[2022-04-06 12:35:08 | train] - Train Epoch: [141] [844800/1281167 (66%)]	Loss: 0.744494
[2022-04-06 12:35:35 | train] - Train Epoch: [141] [857600/1281167 (67%)]	Loss: 0.844144
[2022-04-06 12:36:02 | train] - Train Epoch: [141] [870400/1281167 (68%)]	Loss: 0.719712
[2022-04-06 12:36:29 | train] - Train Epoch: [141] [883200/1281167 (69%)]	Loss: 0.659308
[2022-04-06 12:36:56 | train] - Train Epoch: [141] [896000/1281167 (70%)]	Loss: 0.642031
[2022-04-06 12:37:24 | train] - Train Epoch: [141] [908800/1281167 (71%)]	Loss: 0.855709
[2022-04-06 12:37:51 | train] - Train Epoch: [141] [921600/1281167 (72%)]	Loss: 0.733742
[2022-04-06 12:38:18 | train] - Train Epoch: [141] [934400/1281167 (73%)]	Loss: 0.729084
[2022-04-06 12:38:45 | train] - Train Epoch: [141] [947200/1281167 (74%)]	Loss: 0.645327
[2022-04-06 12:39:12 | train] - Train Epoch: [141] [960000/1281167 (75%)]	Loss: 0.629309
[2022-04-06 12:39:40 | train] - Train Epoch: [141] [972800/1281167 (76%)]	Loss: 0.754800
[2022-04-06 12:40:06 | train] - Train Epoch: [141] [985600/1281167 (77%)]	Loss: 0.596349
[2022-04-06 12:40:33 | train] - Train Epoch: [141] [998400/1281167 (78%)]	Loss: 0.810062
[2022-04-06 12:41:00 | train] - Train Epoch: [141] [1011200/1281167 (79%)]	Loss: 0.531393
[2022-04-06 12:41:28 | train] - Train Epoch: [141] [1024000/1281167 (80%)]	Loss: 0.627793
[2022-04-06 12:41:55 | train] - Train Epoch: [141] [1036800/1281167 (81%)]	Loss: 0.578826
[2022-04-06 12:42:22 | train] - Train Epoch: [141] [1049600/1281167 (82%)]	Loss: 0.492425
[2022-04-06 12:42:49 | train] - Train Epoch: [141] [1062400/1281167 (83%)]	Loss: 0.819196
[2022-04-06 12:43:16 | train] - Train Epoch: [141] [1075200/1281167 (84%)]	Loss: 1.019991
[2022-04-06 12:43:44 | train] - Train Epoch: [141] [1088000/1281167 (85%)]	Loss: 0.687710
[2022-04-06 12:44:10 | train] - Train Epoch: [141] [1100800/1281167 (86%)]	Loss: 0.540978
[2022-04-06 12:44:38 | train] - Train Epoch: [141] [1113600/1281167 (87%)]	Loss: 0.972483
[2022-04-06 12:45:05 | train] - Train Epoch: [141] [1126400/1281167 (88%)]	Loss: 0.589014
[2022-04-06 12:45:32 | train] - Train Epoch: [141] [1139200/1281167 (89%)]	Loss: 0.716097
[2022-04-06 12:45:59 | train] - Train Epoch: [141] [1152000/1281167 (90%)]	Loss: 0.843146
[2022-04-06 12:46:27 | train] - Train Epoch: [141] [1164800/1281167 (91%)]	Loss: 0.688563
[2022-04-06 12:46:54 | train] - Train Epoch: [141] [1177600/1281167 (92%)]	Loss: 0.759855
[2022-04-06 12:47:22 | train] - Train Epoch: [141] [1190400/1281167 (93%)]	Loss: 0.780851
[2022-04-06 12:47:49 | train] - Train Epoch: [141] [1203200/1281167 (94%)]	Loss: 0.905356
[2022-04-06 12:48:17 | train] - Train Epoch: [141] [1216000/1281167 (95%)]	Loss: 0.712070
[2022-04-06 12:48:44 | train] - Train Epoch: [141] [1228800/1281167 (96%)]	Loss: 0.625724
[2022-04-06 12:49:11 | train] - Train Epoch: [141] [1241600/1281167 (97%)]	Loss: 0.610862
[2022-04-06 12:49:39 | train] - Train Epoch: [141] [1254400/1281167 (98%)]	Loss: 0.706516
[2022-04-06 12:50:07 | train] - Train Epoch: [141] [1267200/1281167 (99%)]	Loss: 0.725518
[2022-04-06 12:50:34 | train] - Train Epoch: [141] [1280000/1281167 (100%)]	Loss: 0.706429
[2022-04-06 12:50:36 | train] - Train Epoch: [141]	 Average Loss: 0.722586	 Total Acc : 82.4103	 Total Top5 Acc : 93.6431
[2022-04-06 12:50:36 | train] - -------141 epoch end-----------
========================================
-------141 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 12:52:28 | train] - 
Epoch [141] Test set: Average loss: 1.4431, Accuracy: 34929/50000 (69.8318%), Top-5 Accuracy: 88.7444%

[2022-04-06 12:52:28 | train] - save intermediate epoch [141] result


[2022-04-06 12:52:37 | train] - -------142 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 12:52:39 | train] - Train Epoch: [142] [0/1281167 (0%)]	Loss: 1.061714
[2022-04-06 12:53:06 | train] - Train Epoch: [142] [12800/1281167 (1%)]	Loss: 0.878688
[2022-04-06 12:53:34 | train] - Train Epoch: [142] [25600/1281167 (2%)]	Loss: 0.784239
[2022-04-06 12:54:00 | train] - Train Epoch: [142] [38400/1281167 (3%)]	Loss: 0.837758
[2022-04-06 12:54:28 | train] - Train Epoch: [142] [51200/1281167 (4%)]	Loss: 0.521266
[2022-04-06 12:54:57 | train] - Train Epoch: [142] [64000/1281167 (5%)]	Loss: 0.783581
[2022-04-06 12:55:25 | train] - Train Epoch: [142] [76800/1281167 (6%)]	Loss: 0.494490
[2022-04-06 12:55:52 | train] - Train Epoch: [142] [89600/1281167 (7%)]	Loss: 0.695353
[2022-04-06 12:56:19 | train] - Train Epoch: [142] [102400/1281167 (8%)]	Loss: 0.515881
[2022-04-06 12:56:46 | train] - Train Epoch: [142] [115200/1281167 (9%)]	Loss: 0.660791
[2022-04-06 12:57:14 | train] - Train Epoch: [142] [128000/1281167 (10%)]	Loss: 0.553335
[2022-04-06 12:57:42 | train] - Train Epoch: [142] [140800/1281167 (11%)]	Loss: 0.960421
[2022-04-06 12:58:10 | train] - Train Epoch: [142] [153600/1281167 (12%)]	Loss: 0.704395
[2022-04-06 12:58:38 | train] - Train Epoch: [142] [166400/1281167 (13%)]	Loss: 0.493234
[2022-04-06 12:59:06 | train] - Train Epoch: [142] [179200/1281167 (14%)]	Loss: 0.747377
[2022-04-06 12:59:33 | train] - Train Epoch: [142] [192000/1281167 (15%)]	Loss: 0.769073
[2022-04-06 13:00:01 | train] - Train Epoch: [142] [204800/1281167 (16%)]	Loss: 0.475722
[2022-04-06 13:00:28 | train] - Train Epoch: [142] [217600/1281167 (17%)]	Loss: 0.926147
[2022-04-06 13:00:55 | train] - Train Epoch: [142] [230400/1281167 (18%)]	Loss: 0.778484
[2022-04-06 13:01:22 | train] - Train Epoch: [142] [243200/1281167 (19%)]	Loss: 0.544089
[2022-04-06 13:01:50 | train] - Train Epoch: [142] [256000/1281167 (20%)]	Loss: 0.802091
[2022-04-06 13:02:18 | train] - Train Epoch: [142] [268800/1281167 (21%)]	Loss: 0.974021
[2022-04-06 13:02:44 | train] - Train Epoch: [142] [281600/1281167 (22%)]	Loss: 0.682265
[2022-04-06 13:03:12 | train] - Train Epoch: [142] [294400/1281167 (23%)]	Loss: 0.741701
[2022-04-06 13:03:39 | train] - Train Epoch: [142] [307200/1281167 (24%)]	Loss: 0.949434
[2022-04-06 13:04:07 | train] - Train Epoch: [142] [320000/1281167 (25%)]	Loss: 0.946030
[2022-04-06 13:04:34 | train] - Train Epoch: [142] [332800/1281167 (26%)]	Loss: 0.711189
[2022-04-06 13:05:01 | train] - Train Epoch: [142] [345600/1281167 (27%)]	Loss: 0.703099
[2022-04-06 13:05:29 | train] - Train Epoch: [142] [358400/1281167 (28%)]	Loss: 0.897680
[2022-04-06 13:05:56 | train] - Train Epoch: [142] [371200/1281167 (29%)]	Loss: 0.470880
[2022-04-06 13:06:24 | train] - Train Epoch: [142] [384000/1281167 (30%)]	Loss: 0.793768
[2022-04-06 13:06:52 | train] - Train Epoch: [142] [396800/1281167 (31%)]	Loss: 0.726709
[2022-04-06 13:07:20 | train] - Train Epoch: [142] [409600/1281167 (32%)]	Loss: 0.726933
[2022-04-06 13:07:48 | train] - Train Epoch: [142] [422400/1281167 (33%)]	Loss: 0.811192
[2022-04-06 13:08:15 | train] - Train Epoch: [142] [435200/1281167 (34%)]	Loss: 0.936448
[2022-04-06 13:08:43 | train] - Train Epoch: [142] [448000/1281167 (35%)]	Loss: 0.463883
[2022-04-06 13:09:11 | train] - Train Epoch: [142] [460800/1281167 (36%)]	Loss: 0.660635
[2022-04-06 13:09:38 | train] - Train Epoch: [142] [473600/1281167 (37%)]	Loss: 0.770302
[2022-04-06 13:10:05 | train] - Train Epoch: [142] [486400/1281167 (38%)]	Loss: 0.912846
[2022-04-06 13:10:33 | train] - Train Epoch: [142] [499200/1281167 (39%)]	Loss: 0.498768
[2022-04-06 13:11:02 | train] - Train Epoch: [142] [512000/1281167 (40%)]	Loss: 0.781432
[2022-04-06 13:11:30 | train] - Train Epoch: [142] [524800/1281167 (41%)]	Loss: 0.831306
[2022-04-06 13:11:57 | train] - Train Epoch: [142] [537600/1281167 (42%)]	Loss: 0.601484
[2022-04-06 13:12:24 | train] - Train Epoch: [142] [550400/1281167 (43%)]	Loss: 0.650934
[2022-04-06 13:12:52 | train] - Train Epoch: [142] [563200/1281167 (44%)]	Loss: 0.671243
[2022-04-06 13:13:20 | train] - Train Epoch: [142] [576000/1281167 (45%)]	Loss: 0.708108
[2022-04-06 13:13:48 | train] - Train Epoch: [142] [588800/1281167 (46%)]	Loss: 0.614074
[2022-04-06 13:14:16 | train] - Train Epoch: [142] [601600/1281167 (47%)]	Loss: 0.580678
[2022-04-06 13:14:44 | train] - Train Epoch: [142] [614400/1281167 (48%)]	Loss: 0.758009
[2022-04-06 13:15:11 | train] - Train Epoch: [142] [627200/1281167 (49%)]	Loss: 0.624319
[2022-04-06 13:15:38 | train] - Train Epoch: [142] [640000/1281167 (50%)]	Loss: 0.961543
[2022-04-06 13:16:05 | train] - Train Epoch: [142] [652800/1281167 (51%)]	Loss: 0.722469
[2022-04-06 13:16:33 | train] - Train Epoch: [142] [665600/1281167 (52%)]	Loss: 0.667068
[2022-04-06 13:17:01 | train] - Train Epoch: [142] [678400/1281167 (53%)]	Loss: 0.646793
[2022-04-06 13:17:28 | train] - Train Epoch: [142] [691200/1281167 (54%)]	Loss: 0.769163
[2022-04-06 13:17:56 | train] - Train Epoch: [142] [704000/1281167 (55%)]	Loss: 0.595321
[2022-04-06 13:18:24 | train] - Train Epoch: [142] [716800/1281167 (56%)]	Loss: 0.637466
[2022-04-06 13:18:51 | train] - Train Epoch: [142] [729600/1281167 (57%)]	Loss: 0.928436
[2022-04-06 13:19:18 | train] - Train Epoch: [142] [742400/1281167 (58%)]	Loss: 0.741473
[2022-04-06 13:19:45 | train] - Train Epoch: [142] [755200/1281167 (59%)]	Loss: 0.518429
[2022-04-06 13:20:12 | train] - Train Epoch: [142] [768000/1281167 (60%)]	Loss: 0.828596
[2022-04-06 13:20:40 | train] - Train Epoch: [142] [780800/1281167 (61%)]	Loss: 0.642758
[2022-04-06 13:21:08 | train] - Train Epoch: [142] [793600/1281167 (62%)]	Loss: 0.858541
[2022-04-06 13:21:37 | train] - Train Epoch: [142] [806400/1281167 (63%)]	Loss: 0.755577
[2022-04-06 13:22:04 | train] - Train Epoch: [142] [819200/1281167 (64%)]	Loss: 0.741173
[2022-04-06 13:22:31 | train] - Train Epoch: [142] [832000/1281167 (65%)]	Loss: 0.751334
[2022-04-06 13:22:59 | train] - Train Epoch: [142] [844800/1281167 (66%)]	Loss: 0.906209
[2022-04-06 13:23:27 | train] - Train Epoch: [142] [857600/1281167 (67%)]	Loss: 0.665258
[2022-04-06 13:23:55 | train] - Train Epoch: [142] [870400/1281167 (68%)]	Loss: 0.853446
[2022-04-06 13:24:23 | train] - Train Epoch: [142] [883200/1281167 (69%)]	Loss: 0.626007
[2022-04-06 13:24:51 | train] - Train Epoch: [142] [896000/1281167 (70%)]	Loss: 0.763221
[2022-04-06 13:25:18 | train] - Train Epoch: [142] [908800/1281167 (71%)]	Loss: 0.461231
[2022-04-06 13:25:46 | train] - Train Epoch: [142] [921600/1281167 (72%)]	Loss: 0.827881
[2022-04-06 13:26:14 | train] - Train Epoch: [142] [934400/1281167 (73%)]	Loss: 0.723917
[2022-04-06 13:26:41 | train] - Train Epoch: [142] [947200/1281167 (74%)]	Loss: 0.879917
[2022-04-06 13:27:09 | train] - Train Epoch: [142] [960000/1281167 (75%)]	Loss: 0.590824
[2022-04-06 13:27:37 | train] - Train Epoch: [142] [972800/1281167 (76%)]	Loss: 0.531175
[2022-04-06 13:28:05 | train] - Train Epoch: [142] [985600/1281167 (77%)]	Loss: 0.558673
[2022-04-06 13:28:32 | train] - Train Epoch: [142] [998400/1281167 (78%)]	Loss: 0.635982
[2022-04-06 13:29:00 | train] - Train Epoch: [142] [1011200/1281167 (79%)]	Loss: 0.665939
[2022-04-06 13:29:27 | train] - Train Epoch: [142] [1024000/1281167 (80%)]	Loss: 0.718679
[2022-04-06 13:29:55 | train] - Train Epoch: [142] [1036800/1281167 (81%)]	Loss: 0.807615
[2022-04-06 13:30:23 | train] - Train Epoch: [142] [1049600/1281167 (82%)]	Loss: 0.831988
[2022-04-06 13:30:51 | train] - Train Epoch: [142] [1062400/1281167 (83%)]	Loss: 0.655872
[2022-04-06 13:31:18 | train] - Train Epoch: [142] [1075200/1281167 (84%)]	Loss: 0.659116
[2022-04-06 13:31:46 | train] - Train Epoch: [142] [1088000/1281167 (85%)]	Loss: 0.626280
[2022-04-06 13:32:14 | train] - Train Epoch: [142] [1100800/1281167 (86%)]	Loss: 0.617506
[2022-04-06 13:32:42 | train] - Train Epoch: [142] [1113600/1281167 (87%)]	Loss: 0.794867
[I 13:33:04.916 NotebookApp] 302 GET / (10.150.7.107) 28.430000ms
[I 13:33:04.938 NotebookApp] 302 GET /tree? (10.150.7.107) 9.490000ms
[I 13:33:07.865 NotebookApp] 302 POST /login?next=%2Ftree%3F (10.150.7.107) 113.780000ms
[2022-04-06 13:33:11 | train] - Train Epoch: [142] [1126400/1281167 (88%)]	Loss: 0.573697
[2022-04-06 13:33:38 | train] - Train Epoch: [142] [1139200/1281167 (89%)]	Loss: 0.809246
[2022-04-06 13:34:06 | train] - Train Epoch: [142] [1152000/1281167 (90%)]	Loss: 0.614259
[2022-04-06 13:34:35 | train] - Train Epoch: [142] [1164800/1281167 (91%)]	Loss: 0.473801
[2022-04-06 13:35:02 | train] - Train Epoch: [142] [1177600/1281167 (92%)]	Loss: 0.726448
[2022-04-06 13:35:30 | train] - Train Epoch: [142] [1190400/1281167 (93%)]	Loss: 0.668108
[2022-04-06 13:35:59 | train] - Train Epoch: [142] [1203200/1281167 (94%)]	Loss: 0.753434
[2022-04-06 13:36:28 | train] - Train Epoch: [142] [1216000/1281167 (95%)]	Loss: 1.012859
[2022-04-06 13:36:56 | train] - Train Epoch: [142] [1228800/1281167 (96%)]	Loss: 0.785888
[2022-04-06 13:37:25 | train] - Train Epoch: [142] [1241600/1281167 (97%)]	Loss: 1.049996
[2022-04-06 13:37:53 | train] - Train Epoch: [142] [1254400/1281167 (98%)]	Loss: 0.944752
[2022-04-06 13:38:21 | train] - Train Epoch: [142] [1267200/1281167 (99%)]	Loss: 0.778315
[2022-04-06 13:38:50 | train] - Train Epoch: [142] [1280000/1281167 (100%)]	Loss: 0.966187
[2022-04-06 13:38:52 | train] - Train Epoch: [142]	 Average Loss: 0.721586	 Total Acc : 82.4537	 Total Top5 Acc : 93.6674
[2022-04-06 13:38:52 | train] - -------142 epoch end-----------
========================================
-------142 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 13:40:49 | train] - 
Epoch [142] Test set: Average loss: 1.4513, Accuracy: 34895/50000 (69.7650%), Top-5 Accuracy: 88.7292%

[2022-04-06 13:40:49 | train] - save intermediate epoch [142] result


[2022-04-06 13:40:58 | train] - -------143 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 13:41:00 | train] - Train Epoch: [143] [0/1281167 (0%)]	Loss: 0.717492
[2022-04-06 13:41:28 | train] - Train Epoch: [143] [12800/1281167 (1%)]	Loss: 0.707040
[2022-04-06 13:41:55 | train] - Train Epoch: [143] [25600/1281167 (2%)]	Loss: 0.492249
[2022-04-06 13:42:23 | train] - Train Epoch: [143] [38400/1281167 (3%)]	Loss: 0.810235
[2022-04-06 13:42:51 | train] - Train Epoch: [143] [51200/1281167 (4%)]	Loss: 0.779163
[2022-04-06 13:43:18 | train] - Train Epoch: [143] [64000/1281167 (5%)]	Loss: 0.639914
[2022-04-06 13:43:46 | train] - Train Epoch: [143] [76800/1281167 (6%)]	Loss: 0.647725
[2022-04-06 13:44:13 | train] - Train Epoch: [143] [89600/1281167 (7%)]	Loss: 0.743578
[2022-04-06 13:44:41 | train] - Train Epoch: [143] [102400/1281167 (8%)]	Loss: 0.662811
[2022-04-06 13:45:09 | train] - Train Epoch: [143] [115200/1281167 (9%)]	Loss: 0.700227
[2022-04-06 13:45:36 | train] - Train Epoch: [143] [128000/1281167 (10%)]	Loss: 0.862009
[2022-04-06 13:46:04 | train] - Train Epoch: [143] [140800/1281167 (11%)]	Loss: 0.657857
[2022-04-06 13:46:32 | train] - Train Epoch: [143] [153600/1281167 (12%)]	Loss: 0.654629
[2022-04-06 13:46:58 | train] - Train Epoch: [143] [166400/1281167 (13%)]	Loss: 0.644333
[2022-04-06 13:47:26 | train] - Train Epoch: [143] [179200/1281167 (14%)]	Loss: 0.683767
[2022-04-06 13:47:53 | train] - Train Epoch: [143] [192000/1281167 (15%)]	Loss: 0.735827
[2022-04-06 13:48:20 | train] - Train Epoch: [143] [204800/1281167 (16%)]	Loss: 0.589666
[2022-04-06 13:48:47 | train] - Train Epoch: [143] [217600/1281167 (17%)]	Loss: 0.859842
[2022-04-06 13:49:14 | train] - Train Epoch: [143] [230400/1281167 (18%)]	Loss: 0.703636
[2022-04-06 13:49:42 | train] - Train Epoch: [143] [243200/1281167 (19%)]	Loss: 0.610957
[2022-04-06 13:50:08 | train] - Train Epoch: [143] [256000/1281167 (20%)]	Loss: 0.686167
[2022-04-06 13:50:35 | train] - Train Epoch: [143] [268800/1281167 (21%)]	Loss: 0.613711
[2022-04-06 13:51:02 | train] - Train Epoch: [143] [281600/1281167 (22%)]	Loss: 0.874555
[2022-04-06 13:51:29 | train] - Train Epoch: [143] [294400/1281167 (23%)]	Loss: 0.579400
[2022-04-06 13:51:56 | train] - Train Epoch: [143] [307200/1281167 (24%)]	Loss: 0.783847
[2022-04-06 13:52:23 | train] - Train Epoch: [143] [320000/1281167 (25%)]	Loss: 0.866205
[2022-04-06 13:52:50 | train] - Train Epoch: [143] [332800/1281167 (26%)]	Loss: 0.606331
[2022-04-06 13:53:17 | train] - Train Epoch: [143] [345600/1281167 (27%)]	Loss: 0.772964
[2022-04-06 13:53:44 | train] - Train Epoch: [143] [358400/1281167 (28%)]	Loss: 0.459901
[2022-04-06 13:54:11 | train] - Train Epoch: [143] [371200/1281167 (29%)]	Loss: 0.781840
[2022-04-06 13:54:40 | train] - Train Epoch: [143] [384000/1281167 (30%)]	Loss: 0.585302
[2022-04-06 13:55:06 | train] - Train Epoch: [143] [396800/1281167 (31%)]	Loss: 0.687966
[2022-04-06 13:55:33 | train] - Train Epoch: [143] [409600/1281167 (32%)]	Loss: 0.675304
[2022-04-06 13:56:00 | train] - Train Epoch: [143] [422400/1281167 (33%)]	Loss: 0.666311
[2022-04-06 13:56:27 | train] - Train Epoch: [143] [435200/1281167 (34%)]	Loss: 0.678444
[2022-04-06 13:56:53 | train] - Train Epoch: [143] [448000/1281167 (35%)]	Loss: 0.732363
[2022-04-06 13:57:21 | train] - Train Epoch: [143] [460800/1281167 (36%)]	Loss: 0.598175
[2022-04-06 13:57:47 | train] - Train Epoch: [143] [473600/1281167 (37%)]	Loss: 0.663807
[2022-04-06 13:58:14 | train] - Train Epoch: [143] [486400/1281167 (38%)]	Loss: 0.833582
[2022-04-06 13:58:41 | train] - Train Epoch: [143] [499200/1281167 (39%)]	Loss: 0.862697
[2022-04-06 13:59:08 | train] - Train Epoch: [143] [512000/1281167 (40%)]	Loss: 0.800509
[2022-04-06 13:59:35 | train] - Train Epoch: [143] [524800/1281167 (41%)]	Loss: 0.757844
[2022-04-06 14:00:02 | train] - Train Epoch: [143] [537600/1281167 (42%)]	Loss: 0.781728
[2022-04-06 14:00:29 | train] - Train Epoch: [143] [550400/1281167 (43%)]	Loss: 0.634587
[2022-04-06 14:00:56 | train] - Train Epoch: [143] [563200/1281167 (44%)]	Loss: 0.679047
[2022-04-06 14:01:23 | train] - Train Epoch: [143] [576000/1281167 (45%)]	Loss: 0.962405
[2022-04-06 14:01:51 | train] - Train Epoch: [143] [588800/1281167 (46%)]	Loss: 0.622063
[2022-04-06 14:02:18 | train] - Train Epoch: [143] [601600/1281167 (47%)]	Loss: 0.814472
[2022-04-06 14:02:45 | train] - Train Epoch: [143] [614400/1281167 (48%)]	Loss: 0.653308
[2022-04-06 14:03:14 | train] - Train Epoch: [143] [627200/1281167 (49%)]	Loss: 0.623414
[2022-04-06 14:03:41 | train] - Train Epoch: [143] [640000/1281167 (50%)]	Loss: 0.634028
[2022-04-06 14:04:08 | train] - Train Epoch: [143] [652800/1281167 (51%)]	Loss: 0.932664
[2022-04-06 14:04:36 | train] - Train Epoch: [143] [665600/1281167 (52%)]	Loss: 0.633946
[2022-04-06 14:05:04 | train] - Train Epoch: [143] [678400/1281167 (53%)]	Loss: 0.761163
[2022-04-06 14:05:33 | train] - Train Epoch: [143] [691200/1281167 (54%)]	Loss: 0.664899
[2022-04-06 14:06:01 | train] - Train Epoch: [143] [704000/1281167 (55%)]	Loss: 0.619552
[2022-04-06 14:06:28 | train] - Train Epoch: [143] [716800/1281167 (56%)]	Loss: 0.793677
[2022-04-06 14:06:56 | train] - Train Epoch: [143] [729600/1281167 (57%)]	Loss: 0.754316
[I 14:07:23.026 NotebookApp] Creating new notebook in 
[2022-04-06 14:07:23 | train] - Train Epoch: [143] [742400/1281167 (58%)]	Loss: 0.958771
[I 14:07:23.277 NotebookApp] Saving Untitled.ipynb
Exception in callback <TaskStepMethWrapper object at 0x7f0b303035e0>()
handle: <Handle <TaskStepMethWrapper object at 0x7f0b303035e0>()>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
RuntimeError: Cannot enter into task <Task pending name='Task-216' coro=<RequestHandler._execute() running at /opt/conda/lib/python3.8/site-packages/tornado/web.py:1660> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/web.py:2326]> while another task <Task pending name='Task-215' coro=<MappingKernelManager.start_kernel() running at /opt/conda/lib/python3.8/site-packages/notebook/services/kernels/kernelmanager.py:176> cb=[IOLoop.add_future.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/ioloop.py:688]> is being executed.
Exception in callback <TaskWakeupMethWrapper object at 0x7f0b302ea910>(<Future finis...9d2"\r\n\r\n'>)
handle: <Handle <TaskWakeupMethWrapper object at 0x7f0b302ea910>(<Future finis...9d2"\r\n\r\n'>)>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
RuntimeError: Cannot enter into task <Task pending name='Task-206' coro=<HTTP1ServerConnection._server_request_loop() running at /opt/conda/lib/python3.8/site-packages/tornado/http1connection.py:823> wait_for=<Future finished result=b'GET /kernel...c9d2"\r\n\r\n'> cb=[IOLoop.add_future.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/ioloop.py:688]> while another task <Task pending name='Task-2' coro=<KernelManager._async_start_kernel() running at /opt/conda/lib/python3.8/site-packages/jupyter_client/manager.py:347>> is being executed.
/opt/conda/lib/python3.8/json/encoder.py:253: RuntimeWarning: coroutine 'RequestHandler._execute' was never awaited
  _iterencode = _make_iterencode(
RuntimeWarning: Enable tracemalloc to get the object allocation traceback
Task was destroyed but it is pending!
task: <Task pending name='Task-216' coro=<RequestHandler._execute() running at /opt/conda/lib/python3.8/site-packages/tornado/web.py:1660> cb=[_HandlerDelegate.execute.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/web.py:2326]>
Exception in callback <TaskWakeupMethWrapper object at 0x7f0b302d8190>(<Future finis... GMT\r\n\r\n'>)
handle: <Handle <TaskWakeupMethWrapper object at 0x7f0b302d8190>(<Future finis... GMT\r\n\r\n'>)>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
RuntimeError: Cannot enter into task <Task pending name='Task-186' coro=<HTTP1ServerConnection._server_request_loop() running at /opt/conda/lib/python3.8/site-packages/tornado/http1connection.py:823> wait_for=<Future finished result=b'GET /custom...4 GMT\r\n\r\n'> cb=[IOLoop.add_future.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/ioloop.py:688]> while another task <Task pending name='Task-1' coro=<MultiKernelManager._async_start_kernel() running at /opt/conda/lib/python3.8/site-packages/jupyter_client/multikernelmanager.py:187>> is being executed.
Exception in callback <TaskWakeupMethWrapper object at 0x7f0b302eaf10>(<Future finis...9d2"\r\n\r\n'>)
handle: <Handle <TaskWakeupMethWrapper object at 0x7f0b302eaf10>(<Future finis...9d2"\r\n\r\n'>)>
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/asyncio/events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
RuntimeError: Cannot enter into task <Task pending name='Task-207' coro=<HTTP1ServerConnection._server_request_loop() running at /opt/conda/lib/python3.8/site-packages/tornado/http1connection.py:823> wait_for=<Future finished result=b'GET /nbexte...c9d2"\r\n\r\n'> cb=[IOLoop.add_future.<locals>.<lambda>() at /opt/conda/lib/python3.8/site-packages/tornado/ioloop.py:688]> while another task <Task pending name='Task-1' coro=<MultiKernelManager._async_start_kernel() running at /opt/conda/lib/python3.8/site-packages/jupyter_client/multikernelmanager.py:187>> is being executed.
[I 14:07:30.866 NotebookApp] Kernel started: d6795a48-6c4e-4456-8ce6-0d102073ec65, name: python3
[2022-04-06 14:07:50 | train] - Train Epoch: [143] [755200/1281167 (59%)]	Loss: 0.697701
[2022-04-06 14:08:18 | train] - Train Epoch: [143] [768000/1281167 (60%)]	Loss: 0.560544
[2022-04-06 14:08:45 | train] - Train Epoch: [143] [780800/1281167 (61%)]	Loss: 0.671987
[2022-04-06 14:09:13 | train] - Train Epoch: [143] [793600/1281167 (62%)]	Loss: 0.761678
/opt/conda/lib/python3.8/json/encoder.py:257: UserWarning: date_default is deprecated since jupyter_client 7.0.0. Use jupyter_client.jsonutil.json_default.
  return _iterencode(o, 0)
[I 14:09:30.208 NotebookApp] Saving file at /Untitled.ipynb
[I 14:09:30.209 NotebookApp] Saving Untitled.ipynb
[2022-04-06 14:09:40 | train] - Train Epoch: [143] [806400/1281167 (63%)]	Loss: 0.685614
[2022-04-06 14:10:07 | train] - Train Epoch: [143] [819200/1281167 (64%)]	Loss: 1.034551
[2022-04-06 14:10:35 | train] - Train Epoch: [143] [832000/1281167 (65%)]	Loss: 0.950943
[2022-04-06 14:11:03 | train] - Train Epoch: [143] [844800/1281167 (66%)]	Loss: 0.673533
[2022-04-06 14:11:31 | train] - Train Epoch: [143] [857600/1281167 (67%)]	Loss: 0.730482
[2022-04-06 14:11:58 | train] - Train Epoch: [143] [870400/1281167 (68%)]	Loss: 0.598498
[W 14:12:05.652 NotebookApp] Notebook Untitled.ipynb is not trusted
[W 14:12:05.814 NotebookApp] 404 GET /nbextensions/widgets/notebook/js/extension.js?v=20220405184855 (10.150.7.107) 13.740000ms referer=http://10.150.21.78:9000/notebooks/Untitled.ipynb?kernel_name=python3
[2022-04-06 14:12:27 | train] - Train Epoch: [143] [883200/1281167 (69%)]	Loss: 0.811785
[2022-04-06 14:12:54 | train] - Train Epoch: [143] [896000/1281167 (70%)]	Loss: 0.931661
[2022-04-06 14:13:22 | train] - Train Epoch: [143] [908800/1281167 (71%)]	Loss: 0.443897
[2022-04-06 14:13:50 | train] - Train Epoch: [143] [921600/1281167 (72%)]	Loss: 0.751581
[I 14:14:05.723 NotebookApp] Saving file at /Untitled.ipynb
[I 14:14:05.724 NotebookApp] Saving Untitled.ipynb
[2022-04-06 14:14:18 | train] - Train Epoch: [143] [934400/1281167 (73%)]	Loss: 0.479566
[2022-04-06 14:14:45 | train] - Train Epoch: [143] [947200/1281167 (74%)]	Loss: 0.673380
[2022-04-06 14:15:14 | train] - Train Epoch: [143] [960000/1281167 (75%)]	Loss: 0.715171
[2022-04-06 14:15:41 | train] - Train Epoch: [143] [972800/1281167 (76%)]	Loss: 0.603519
[I 14:16:06.200 NotebookApp] Saving file at /Untitled.ipynb
[I 14:16:06.201 NotebookApp] Saving Untitled.ipynb
[2022-04-06 14:16:09 | train] - Train Epoch: [143] [985600/1281167 (77%)]	Loss: 0.697812
[2022-04-06 14:16:37 | train] - Train Epoch: [143] [998400/1281167 (78%)]	Loss: 0.755102
[2022-04-06 14:17:05 | train] - Train Epoch: [143] [1011200/1281167 (79%)]	Loss: 0.619052
[2022-04-06 14:17:34 | train] - Train Epoch: [143] [1024000/1281167 (80%)]	Loss: 0.504871
[2022-04-06 14:18:01 | train] - Train Epoch: [143] [1036800/1281167 (81%)]	Loss: 0.658666
[I 14:18:05.723 NotebookApp] Saving file at /Untitled.ipynb
[I 14:18:05.724 NotebookApp] Saving Untitled.ipynb
[2022-04-06 14:18:29 | train] - Train Epoch: [143] [1049600/1281167 (82%)]	Loss: 0.744661
[2022-04-06 14:18:57 | train] - Train Epoch: [143] [1062400/1281167 (83%)]	Loss: 0.632880
[2022-04-06 14:19:24 | train] - Train Epoch: [143] [1075200/1281167 (84%)]	Loss: 0.611862
[2022-04-06 14:19:52 | train] - Train Epoch: [143] [1088000/1281167 (85%)]	Loss: 0.759904
[2022-04-06 14:20:20 | train] - Train Epoch: [143] [1100800/1281167 (86%)]	Loss: 0.494920
[2022-04-06 14:20:47 | train] - Train Epoch: [143] [1113600/1281167 (87%)]	Loss: 0.798764
[2022-04-06 14:21:15 | train] - Train Epoch: [143] [1126400/1281167 (88%)]	Loss: 0.580190
[2022-04-06 14:21:43 | train] - Train Epoch: [143] [1139200/1281167 (89%)]	Loss: 0.972421
[2022-04-06 14:22:12 | train] - Train Epoch: [143] [1152000/1281167 (90%)]	Loss: 0.703223
[2022-04-06 14:22:40 | train] - Train Epoch: [143] [1164800/1281167 (91%)]	Loss: 0.691932
[2022-04-06 14:23:09 | train] - Train Epoch: [143] [1177600/1281167 (92%)]	Loss: 0.776088
[2022-04-06 14:23:37 | train] - Train Epoch: [143] [1190400/1281167 (93%)]	Loss: 0.892170
[2022-04-06 14:24:06 | train] - Train Epoch: [143] [1203200/1281167 (94%)]	Loss: 0.972249
[2022-04-06 14:24:35 | train] - Train Epoch: [143] [1216000/1281167 (95%)]	Loss: 0.510984
[2022-04-06 14:25:04 | train] - Train Epoch: [143] [1228800/1281167 (96%)]	Loss: 0.678407
[2022-04-06 14:25:32 | train] - Train Epoch: [143] [1241600/1281167 (97%)]	Loss: 1.022523
[2022-04-06 14:26:01 | train] - Train Epoch: [143] [1254400/1281167 (98%)]	Loss: 0.787984
[2022-04-06 14:26:29 | train] - Train Epoch: [143] [1267200/1281167 (99%)]	Loss: 0.698094
[2022-04-06 14:26:58 | train] - Train Epoch: [143] [1280000/1281167 (100%)]	Loss: 0.879363
[2022-04-06 14:27:00 | train] - Train Epoch: [143]	 Average Loss: 0.718989	 Total Acc : 82.5144	 Total Top5 Acc : 93.6623
[2022-04-06 14:27:00 | train] - -------143 epoch end-----------
========================================
-------143 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 14:28:53 | train] - 
Epoch [143] Test set: Average loss: 1.4448, Accuracy: 34902/50000 (69.7766%), Top-5 Accuracy: 88.8859%

[2022-04-06 14:28:53 | train] - save intermediate epoch [143] result


[2022-04-06 14:29:02 | train] - -------144 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 14:29:04 | train] - Train Epoch: [144] [0/1281167 (0%)]	Loss: 0.686148
[2022-04-06 14:29:30 | train] - Train Epoch: [144] [12800/1281167 (1%)]	Loss: 0.829563
[2022-04-06 14:29:57 | train] - Train Epoch: [144] [25600/1281167 (2%)]	Loss: 0.582637
[I 14:30:06.193 NotebookApp] Saving file at /Untitled.ipynb
[I 14:30:06.194 NotebookApp] Saving Untitled.ipynb
[2022-04-06 14:30:25 | train] - Train Epoch: [144] [38400/1281167 (3%)]	Loss: 0.721952
[2022-04-06 14:30:52 | train] - Train Epoch: [144] [51200/1281167 (4%)]	Loss: 0.830619
[2022-04-06 14:31:18 | train] - Train Epoch: [144] [64000/1281167 (5%)]	Loss: 0.485590
[2022-04-06 14:31:47 | train] - Train Epoch: [144] [76800/1281167 (6%)]	Loss: 0.707851
[2022-04-06 14:32:13 | train] - Train Epoch: [144] [89600/1281167 (7%)]	Loss: 0.722057
[2022-04-06 14:32:41 | train] - Train Epoch: [144] [102400/1281167 (8%)]	Loss: 0.705044
[2022-04-06 14:33:08 | train] - Train Epoch: [144] [115200/1281167 (9%)]	Loss: 0.770720
[2022-04-06 14:33:35 | train] - Train Epoch: [144] [128000/1281167 (10%)]	Loss: 0.569777
[I 14:33:50.499 NotebookApp] 302 GET / (10.150.7.107) 0.560000ms
[I 14:33:56.812 NotebookApp] Creating new notebook in 
[I 14:33:56.814 NotebookApp] Saving Untitled1.ipynb
[I 14:33:59.911 NotebookApp] Kernel started: 70aafaca-033a-4a2c-a6f9-8d60068e7fa8, name: python3
[2022-04-06 14:34:02 | train] - Train Epoch: [144] [140800/1281167 (11%)]	Loss: 0.727854
[2022-04-06 14:34:29 | train] - Train Epoch: [144] [153600/1281167 (12%)]	Loss: 0.839087
[2022-04-06 14:34:57 | train] - Train Epoch: [144] [166400/1281167 (13%)]	Loss: 0.647062
[2022-04-06 14:35:24 | train] - Train Epoch: [144] [179200/1281167 (14%)]	Loss: 0.732298
[2022-04-06 14:35:51 | train] - Train Epoch: [144] [192000/1281167 (15%)]	Loss: 0.772825
[I 14:35:59.903 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:35:59.904 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 14:36:19 | train] - Train Epoch: [144] [204800/1281167 (16%)]	Loss: 0.641937
[2022-04-06 14:36:46 | train] - Train Epoch: [144] [217600/1281167 (17%)]	Loss: 0.689744
[2022-04-06 14:37:14 | train] - Train Epoch: [144] [230400/1281167 (18%)]	Loss: 0.813391
[2022-04-06 14:37:42 | train] - Train Epoch: [144] [243200/1281167 (19%)]	Loss: 0.706309
[I 14:37:59.910 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:37:59.911 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 14:38:09 | train] - Train Epoch: [144] [256000/1281167 (20%)]	Loss: 0.758923
[2022-04-06 14:38:37 | train] - Train Epoch: [144] [268800/1281167 (21%)]	Loss: 0.666330
[2022-04-06 14:39:05 | train] - Train Epoch: [144] [281600/1281167 (22%)]	Loss: 0.672622
[2022-04-06 14:39:33 | train] - Train Epoch: [144] [294400/1281167 (23%)]	Loss: 0.605267
[2022-04-06 14:39:59 | train] - Train Epoch: [144] [307200/1281167 (24%)]	Loss: 0.707572
[2022-04-06 14:40:27 | train] - Train Epoch: [144] [320000/1281167 (25%)]	Loss: 0.897928
[2022-04-06 14:40:55 | train] - Train Epoch: [144] [332800/1281167 (26%)]	Loss: 0.711920
[2022-04-06 14:41:21 | train] - Train Epoch: [144] [345600/1281167 (27%)]	Loss: 0.963579
[2022-04-06 14:41:48 | train] - Train Epoch: [144] [358400/1281167 (28%)]	Loss: 0.657995
[2022-04-06 14:42:15 | train] - Train Epoch: [144] [371200/1281167 (29%)]	Loss: 0.730949
[2022-04-06 14:42:42 | train] - Train Epoch: [144] [384000/1281167 (30%)]	Loss: 0.814178
[2022-04-06 14:43:09 | train] - Train Epoch: [144] [396800/1281167 (31%)]	Loss: 1.039134
[2022-04-06 14:43:37 | train] - Train Epoch: [144] [409600/1281167 (32%)]	Loss: 0.747924
[2022-04-06 14:44:05 | train] - Train Epoch: [144] [422400/1281167 (33%)]	Loss: 0.449462
[2022-04-06 14:44:33 | train] - Train Epoch: [144] [435200/1281167 (34%)]	Loss: 0.702552
[2022-04-06 14:45:00 | train] - Train Epoch: [144] [448000/1281167 (35%)]	Loss: 1.066463
[2022-04-06 14:45:27 | train] - Train Epoch: [144] [460800/1281167 (36%)]	Loss: 0.650837
[2022-04-06 14:45:55 | train] - Train Epoch: [144] [473600/1281167 (37%)]	Loss: 0.876905
[2022-04-06 14:46:21 | train] - Train Epoch: [144] [486400/1281167 (38%)]	Loss: 0.740181
[2022-04-06 14:46:49 | train] - Train Epoch: [144] [499200/1281167 (39%)]	Loss: 0.738511
[2022-04-06 14:47:17 | train] - Train Epoch: [144] [512000/1281167 (40%)]	Loss: 0.637935
[2022-04-06 14:47:44 | train] - Train Epoch: [144] [524800/1281167 (41%)]	Loss: 0.767799
[2022-04-06 14:48:12 | train] - Train Epoch: [144] [537600/1281167 (42%)]	Loss: 0.815338
[2022-04-06 14:48:40 | train] - Train Epoch: [144] [550400/1281167 (43%)]	Loss: 0.748779
[2022-04-06 14:49:07 | train] - Train Epoch: [144] [563200/1281167 (44%)]	Loss: 0.756361
[2022-04-06 14:49:34 | train] - Train Epoch: [144] [576000/1281167 (45%)]	Loss: 0.632729
[2022-04-06 14:50:02 | train] - Train Epoch: [144] [588800/1281167 (46%)]	Loss: 0.639797
[2022-04-06 14:50:29 | train] - Train Epoch: [144] [601600/1281167 (47%)]	Loss: 0.563180
[2022-04-06 14:50:57 | train] - Train Epoch: [144] [614400/1281167 (48%)]	Loss: 0.576597
[2022-04-06 14:51:24 | train] - Train Epoch: [144] [627200/1281167 (49%)]	Loss: 0.811577
[2022-04-06 14:51:51 | train] - Train Epoch: [144] [640000/1281167 (50%)]	Loss: 0.883428
[2022-04-06 14:52:19 | train] - Train Epoch: [144] [652800/1281167 (51%)]	Loss: 0.691528
[2022-04-06 14:52:46 | train] - Train Epoch: [144] [665600/1281167 (52%)]	Loss: 0.903536
[2022-04-06 14:53:15 | train] - Train Epoch: [144] [678400/1281167 (53%)]	Loss: 0.724267
[2022-04-06 14:53:42 | train] - Train Epoch: [144] [691200/1281167 (54%)]	Loss: 0.704813
[2022-04-06 14:54:10 | train] - Train Epoch: [144] [704000/1281167 (55%)]	Loss: 0.756143
[2022-04-06 14:54:39 | train] - Train Epoch: [144] [716800/1281167 (56%)]	Loss: 0.948691
[2022-04-06 14:55:06 | train] - Train Epoch: [144] [729600/1281167 (57%)]	Loss: 0.578298
[2022-04-06 14:55:34 | train] - Train Epoch: [144] [742400/1281167 (58%)]	Loss: 0.595857
[2022-04-06 14:56:01 | train] - Train Epoch: [144] [755200/1281167 (59%)]	Loss: 0.983351
[2022-04-06 14:56:29 | train] - Train Epoch: [144] [768000/1281167 (60%)]	Loss: 0.643945
[2022-04-06 14:56:57 | train] - Train Epoch: [144] [780800/1281167 (61%)]	Loss: 0.652982
[2022-04-06 14:57:24 | train] - Train Epoch: [144] [793600/1281167 (62%)]	Loss: 0.619482
[2022-04-06 14:57:52 | train] - Train Epoch: [144] [806400/1281167 (63%)]	Loss: 0.785915
[2022-04-06 14:58:20 | train] - Train Epoch: [144] [819200/1281167 (64%)]	Loss: 0.641373
[2022-04-06 14:58:47 | train] - Train Epoch: [144] [832000/1281167 (65%)]	Loss: 0.687595
[2022-04-06 14:59:16 | train] - Train Epoch: [144] [844800/1281167 (66%)]	Loss: 0.813255
[2022-04-06 14:59:44 | train] - Train Epoch: [144] [857600/1281167 (67%)]	Loss: 0.803667
[2022-04-06 15:00:12 | train] - Train Epoch: [144] [870400/1281167 (68%)]	Loss: 0.697415
[2022-04-06 15:00:40 | train] - Train Epoch: [144] [883200/1281167 (69%)]	Loss: 0.881194
[2022-04-06 15:01:08 | train] - Train Epoch: [144] [896000/1281167 (70%)]	Loss: 0.777713
[2022-04-06 15:01:35 | train] - Train Epoch: [144] [908800/1281167 (71%)]	Loss: 0.750427
[2022-04-06 15:02:02 | train] - Train Epoch: [144] [921600/1281167 (72%)]	Loss: 0.566988
[2022-04-06 15:02:29 | train] - Train Epoch: [144] [934400/1281167 (73%)]	Loss: 0.865237
[2022-04-06 15:02:57 | train] - Train Epoch: [144] [947200/1281167 (74%)]	Loss: 0.657532
[2022-04-06 15:03:25 | train] - Train Epoch: [144] [960000/1281167 (75%)]	Loss: 0.689271
[2022-04-06 15:03:53 | train] - Train Epoch: [144] [972800/1281167 (76%)]	Loss: 1.093524
[2022-04-06 15:04:21 | train] - Train Epoch: [144] [985600/1281167 (77%)]	Loss: 0.726270
[2022-04-06 15:04:50 | train] - Train Epoch: [144] [998400/1281167 (78%)]	Loss: 0.657391
[2022-04-06 15:05:19 | train] - Train Epoch: [144] [1011200/1281167 (79%)]	Loss: 0.774621
[2022-04-06 15:05:45 | train] - Train Epoch: [144] [1024000/1281167 (80%)]	Loss: 0.618659
[2022-04-06 15:06:14 | train] - Train Epoch: [144] [1036800/1281167 (81%)]	Loss: 0.723584
[2022-04-06 15:06:42 | train] - Train Epoch: [144] [1049600/1281167 (82%)]	Loss: 0.643930
[2022-04-06 15:07:09 | train] - Train Epoch: [144] [1062400/1281167 (83%)]	Loss: 0.501535
[2022-04-06 15:07:37 | train] - Train Epoch: [144] [1075200/1281167 (84%)]	Loss: 0.804310
[2022-04-06 15:08:05 | train] - Train Epoch: [144] [1088000/1281167 (85%)]	Loss: 0.556668
[2022-04-06 15:08:33 | train] - Train Epoch: [144] [1100800/1281167 (86%)]	Loss: 1.089938
[2022-04-06 15:09:01 | train] - Train Epoch: [144] [1113600/1281167 (87%)]	Loss: 0.880303
[2022-04-06 15:09:29 | train] - Train Epoch: [144] [1126400/1281167 (88%)]	Loss: 0.876511
[2022-04-06 15:09:58 | train] - Train Epoch: [144] [1139200/1281167 (89%)]	Loss: 0.646359
[2022-04-06 15:10:26 | train] - Train Epoch: [144] [1152000/1281167 (90%)]	Loss: 0.675712
[2022-04-06 15:10:54 | train] - Train Epoch: [144] [1164800/1281167 (91%)]	Loss: 0.586605
[2022-04-06 15:11:23 | train] - Train Epoch: [144] [1177600/1281167 (92%)]	Loss: 0.612425
[2022-04-06 15:11:51 | train] - Train Epoch: [144] [1190400/1281167 (93%)]	Loss: 0.667803
[2022-04-06 15:12:20 | train] - Train Epoch: [144] [1203200/1281167 (94%)]	Loss: 0.807177
[2022-04-06 15:12:48 | train] - Train Epoch: [144] [1216000/1281167 (95%)]	Loss: 0.907065
[2022-04-06 15:13:16 | train] - Train Epoch: [144] [1228800/1281167 (96%)]	Loss: 0.549456
[2022-04-06 15:13:45 | train] - Train Epoch: [144] [1241600/1281167 (97%)]	Loss: 0.785155
[2022-04-06 15:14:14 | train] - Train Epoch: [144] [1254400/1281167 (98%)]	Loss: 0.685119
[2022-04-06 15:14:42 | train] - Train Epoch: [144] [1267200/1281167 (99%)]	Loss: 0.659713
[2022-04-06 15:15:11 | train] - Train Epoch: [144] [1280000/1281167 (100%)]	Loss: 0.643797
[2022-04-06 15:15:14 | train] - Train Epoch: [144]	 Average Loss: 0.717883	 Total Acc : 82.5791	 Total Top5 Acc : 93.6703
[2022-04-06 15:15:14 | train] - -------144 epoch end-----------
========================================
-------144 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 15:17:10 | train] - 
Epoch [144] Test set: Average loss: 1.4384, Accuracy: 34956/50000 (69.8833%), Top-5 Accuracy: 88.8763%

[2022-04-06 15:17:10 | train] - save intermediate epoch [144] result


[2022-04-06 15:17:20 | train] - -------145 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 15:17:21 | train] - Train Epoch: [145] [0/1281167 (0%)]	Loss: 0.858582
[2022-04-06 15:17:48 | train] - Train Epoch: [145] [12800/1281167 (1%)]	Loss: 0.948770
[2022-04-06 15:18:15 | train] - Train Epoch: [145] [25600/1281167 (2%)]	Loss: 0.897382
[2022-04-06 15:18:42 | train] - Train Epoch: [145] [38400/1281167 (3%)]	Loss: 0.691865
[2022-04-06 15:19:09 | train] - Train Epoch: [145] [51200/1281167 (4%)]	Loss: 0.683451
[2022-04-06 15:19:37 | train] - Train Epoch: [145] [64000/1281167 (5%)]	Loss: 1.113379
[2022-04-06 15:20:04 | train] - Train Epoch: [145] [76800/1281167 (6%)]	Loss: 0.763384
[2022-04-06 15:20:32 | train] - Train Epoch: [145] [89600/1281167 (7%)]	Loss: 0.686416
[2022-04-06 15:20:59 | train] - Train Epoch: [145] [102400/1281167 (8%)]	Loss: 0.865352
[2022-04-06 15:21:25 | train] - Train Epoch: [145] [115200/1281167 (9%)]	Loss: 0.582161
[2022-04-06 15:21:51 | train] - Train Epoch: [145] [128000/1281167 (10%)]	Loss: 0.883923
[2022-04-06 15:22:16 | train] - Train Epoch: [145] [140800/1281167 (11%)]	Loss: 0.832123
[2022-04-06 15:22:43 | train] - Train Epoch: [145] [153600/1281167 (12%)]	Loss: 0.716648
[2022-04-06 15:23:09 | train] - Train Epoch: [145] [166400/1281167 (13%)]	Loss: 0.672522
[2022-04-06 15:23:35 | train] - Train Epoch: [145] [179200/1281167 (14%)]	Loss: 0.671027
[2022-04-06 15:24:02 | train] - Train Epoch: [145] [192000/1281167 (15%)]	Loss: 0.808808
[2022-04-06 15:24:27 | train] - Train Epoch: [145] [204800/1281167 (16%)]	Loss: 0.495955
[2022-04-06 15:24:54 | train] - Train Epoch: [145] [217600/1281167 (17%)]	Loss: 0.678006
[2022-04-06 15:25:21 | train] - Train Epoch: [145] [230400/1281167 (18%)]	Loss: 0.446191
[2022-04-06 15:25:47 | train] - Train Epoch: [145] [243200/1281167 (19%)]	Loss: 0.617760
[2022-04-06 15:26:14 | train] - Train Epoch: [145] [256000/1281167 (20%)]	Loss: 0.550086
[2022-04-06 15:26:40 | train] - Train Epoch: [145] [268800/1281167 (21%)]	Loss: 0.675652
[2022-04-06 15:27:06 | train] - Train Epoch: [145] [281600/1281167 (22%)]	Loss: 0.696279
[2022-04-06 15:27:33 | train] - Train Epoch: [145] [294400/1281167 (23%)]	Loss: 0.599845
[2022-04-06 15:27:59 | train] - Train Epoch: [145] [307200/1281167 (24%)]	Loss: 0.745999
[2022-04-06 15:28:24 | train] - Train Epoch: [145] [320000/1281167 (25%)]	Loss: 0.734528
[2022-04-06 15:28:50 | train] - Train Epoch: [145] [332800/1281167 (26%)]	Loss: 0.735125
[2022-04-06 15:29:17 | train] - Train Epoch: [145] [345600/1281167 (27%)]	Loss: 0.680518
[2022-04-06 15:29:43 | train] - Train Epoch: [145] [358400/1281167 (28%)]	Loss: 0.751444
[2022-04-06 15:30:09 | train] - Train Epoch: [145] [371200/1281167 (29%)]	Loss: 0.844645
[2022-04-06 15:30:35 | train] - Train Epoch: [145] [384000/1281167 (30%)]	Loss: 0.582252
[2022-04-06 15:31:02 | train] - Train Epoch: [145] [396800/1281167 (31%)]	Loss: 0.867588
[2022-04-06 15:31:27 | train] - Train Epoch: [145] [409600/1281167 (32%)]	Loss: 0.524210
[2022-04-06 15:31:53 | train] - Train Epoch: [145] [422400/1281167 (33%)]	Loss: 0.744002
[2022-04-06 15:32:18 | train] - Train Epoch: [145] [435200/1281167 (34%)]	Loss: 0.612273
[2022-04-06 15:32:43 | train] - Train Epoch: [145] [448000/1281167 (35%)]	Loss: 0.754428
[2022-04-06 15:33:09 | train] - Train Epoch: [145] [460800/1281167 (36%)]	Loss: 1.055151
[2022-04-06 15:33:34 | train] - Train Epoch: [145] [473600/1281167 (37%)]	Loss: 0.585525
[2022-04-06 15:34:00 | train] - Train Epoch: [145] [486400/1281167 (38%)]	Loss: 0.916333
[2022-04-06 15:34:25 | train] - Train Epoch: [145] [499200/1281167 (39%)]	Loss: 0.609135
[2022-04-06 15:34:51 | train] - Train Epoch: [145] [512000/1281167 (40%)]	Loss: 0.806200
[2022-04-06 15:35:16 | train] - Train Epoch: [145] [524800/1281167 (41%)]	Loss: 0.495520
[2022-04-06 15:35:43 | train] - Train Epoch: [145] [537600/1281167 (42%)]	Loss: 0.884892
[2022-04-06 15:36:08 | train] - Train Epoch: [145] [550400/1281167 (43%)]	Loss: 0.638489
[2022-04-06 15:36:34 | train] - Train Epoch: [145] [563200/1281167 (44%)]	Loss: 0.889465
[2022-04-06 15:37:01 | train] - Train Epoch: [145] [576000/1281167 (45%)]	Loss: 0.622228
[2022-04-06 15:37:27 | train] - Train Epoch: [145] [588800/1281167 (46%)]	Loss: 0.692727
[2022-04-06 15:37:53 | train] - Train Epoch: [145] [601600/1281167 (47%)]	Loss: 0.869106
[2022-04-06 15:38:20 | train] - Train Epoch: [145] [614400/1281167 (48%)]	Loss: 0.723451
[2022-04-06 15:38:46 | train] - Train Epoch: [145] [627200/1281167 (49%)]	Loss: 0.765522
[2022-04-06 15:39:13 | train] - Train Epoch: [145] [640000/1281167 (50%)]	Loss: 0.566269
[2022-04-06 15:39:39 | train] - Train Epoch: [145] [652800/1281167 (51%)]	Loss: 0.954264
[2022-04-06 15:40:04 | train] - Train Epoch: [145] [665600/1281167 (52%)]	Loss: 0.814832
[2022-04-06 15:40:31 | train] - Train Epoch: [145] [678400/1281167 (53%)]	Loss: 0.507605
[2022-04-06 15:40:58 | train] - Train Epoch: [145] [691200/1281167 (54%)]	Loss: 0.686135
[2022-04-06 15:41:25 | train] - Train Epoch: [145] [704000/1281167 (55%)]	Loss: 0.786690
[2022-04-06 15:41:51 | train] - Train Epoch: [145] [716800/1281167 (56%)]	Loss: 0.756327
[2022-04-06 15:42:18 | train] - Train Epoch: [145] [729600/1281167 (57%)]	Loss: 0.618203
[2022-04-06 15:42:44 | train] - Train Epoch: [145] [742400/1281167 (58%)]	Loss: 0.835103
[2022-04-06 15:43:10 | train] - Train Epoch: [145] [755200/1281167 (59%)]	Loss: 0.882275
[2022-04-06 15:43:37 | train] - Train Epoch: [145] [768000/1281167 (60%)]	Loss: 0.791661
[2022-04-06 15:44:03 | train] - Train Epoch: [145] [780800/1281167 (61%)]	Loss: 0.865320
[2022-04-06 15:44:29 | train] - Train Epoch: [145] [793600/1281167 (62%)]	Loss: 0.715169
[2022-04-06 15:44:55 | train] - Train Epoch: [145] [806400/1281167 (63%)]	Loss: 0.625405
[2022-04-06 15:45:21 | train] - Train Epoch: [145] [819200/1281167 (64%)]	Loss: 0.694064
[2022-04-06 15:45:46 | train] - Train Epoch: [145] [832000/1281167 (65%)]	Loss: 0.713049
[2022-04-06 15:46:13 | train] - Train Epoch: [145] [844800/1281167 (66%)]	Loss: 0.552023
[2022-04-06 15:46:38 | train] - Train Epoch: [145] [857600/1281167 (67%)]	Loss: 0.585240
[2022-04-06 15:47:05 | train] - Train Epoch: [145] [870400/1281167 (68%)]	Loss: 0.709116
[2022-04-06 15:47:31 | train] - Train Epoch: [145] [883200/1281167 (69%)]	Loss: 0.843587
[2022-04-06 15:47:58 | train] - Train Epoch: [145] [896000/1281167 (70%)]	Loss: 0.665715
[2022-04-06 15:48:24 | train] - Train Epoch: [145] [908800/1281167 (71%)]	Loss: 0.779185
[2022-04-06 15:48:50 | train] - Train Epoch: [145] [921600/1281167 (72%)]	Loss: 0.821044
[2022-04-06 15:49:16 | train] - Train Epoch: [145] [934400/1281167 (73%)]	Loss: 0.751850
[2022-04-06 15:49:42 | train] - Train Epoch: [145] [947200/1281167 (74%)]	Loss: 0.633211
[2022-04-06 15:50:08 | train] - Train Epoch: [145] [960000/1281167 (75%)]	Loss: 0.628674
[2022-04-06 15:50:35 | train] - Train Epoch: [145] [972800/1281167 (76%)]	Loss: 0.545859
[2022-04-06 15:51:01 | train] - Train Epoch: [145] [985600/1281167 (77%)]	Loss: 0.626183
[2022-04-06 15:51:27 | train] - Train Epoch: [145] [998400/1281167 (78%)]	Loss: 1.014097
[2022-04-06 15:51:53 | train] - Train Epoch: [145] [1011200/1281167 (79%)]	Loss: 0.750918
[2022-04-06 15:52:19 | train] - Train Epoch: [145] [1024000/1281167 (80%)]	Loss: 0.689756
[2022-04-06 15:52:44 | train] - Train Epoch: [145] [1036800/1281167 (81%)]	Loss: 0.594011
[2022-04-06 15:53:10 | train] - Train Epoch: [145] [1049600/1281167 (82%)]	Loss: 0.762683
[2022-04-06 15:53:36 | train] - Train Epoch: [145] [1062400/1281167 (83%)]	Loss: 0.778526
[2022-04-06 15:54:03 | train] - Train Epoch: [145] [1075200/1281167 (84%)]	Loss: 0.733021
[2022-04-06 15:54:29 | train] - Train Epoch: [145] [1088000/1281167 (85%)]	Loss: 0.590109
[2022-04-06 15:54:55 | train] - Train Epoch: [145] [1100800/1281167 (86%)]	Loss: 0.750216
[2022-04-06 15:55:20 | train] - Train Epoch: [145] [1113600/1281167 (87%)]	Loss: 0.719795
[2022-04-06 15:55:47 | train] - Train Epoch: [145] [1126400/1281167 (88%)]	Loss: 0.571115
[2022-04-06 15:56:13 | train] - Train Epoch: [145] [1139200/1281167 (89%)]	Loss: 0.837294
[2022-04-06 15:56:40 | train] - Train Epoch: [145] [1152000/1281167 (90%)]	Loss: 0.455465
[2022-04-06 15:57:06 | train] - Train Epoch: [145] [1164800/1281167 (91%)]	Loss: 0.656055
[2022-04-06 15:57:33 | train] - Train Epoch: [145] [1177600/1281167 (92%)]	Loss: 0.571633
[2022-04-06 15:57:59 | train] - Train Epoch: [145] [1190400/1281167 (93%)]	Loss: 0.730155
[2022-04-06 15:58:26 | train] - Train Epoch: [145] [1203200/1281167 (94%)]	Loss: 1.014290
[2022-04-06 15:58:53 | train] - Train Epoch: [145] [1216000/1281167 (95%)]	Loss: 0.642220
[2022-04-06 15:59:20 | train] - Train Epoch: [145] [1228800/1281167 (96%)]	Loss: 0.932975
[2022-04-06 15:59:48 | train] - Train Epoch: [145] [1241600/1281167 (97%)]	Loss: 0.671675
[2022-04-06 16:00:16 | train] - Train Epoch: [145] [1254400/1281167 (98%)]	Loss: 0.608230
[2022-04-06 16:00:44 | train] - Train Epoch: [145] [1267200/1281167 (99%)]	Loss: 0.729047
[2022-04-06 16:01:12 | train] - Train Epoch: [145] [1280000/1281167 (100%)]	Loss: 0.613097
[2022-04-06 16:01:14 | train] - Train Epoch: [145]	 Average Loss: 0.713949	 Total Acc : 82.6275	 Total Top5 Acc : 93.7378
[2022-04-06 16:01:14 | train] - -------145 epoch end-----------
========================================
-------145 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 16:03:09 | train] - 
Epoch [145] Test set: Average loss: 1.4447, Accuracy: 34832/50000 (69.6379%), Top-5 Accuracy: 88.7272%

[2022-04-06 16:03:09 | train] - save intermediate epoch [145] result


[2022-04-06 16:03:19 | train] - -------146 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 16:03:21 | train] - Train Epoch: [146] [0/1281167 (0%)]	Loss: 0.528475
[2022-04-06 16:03:49 | train] - Train Epoch: [146] [12800/1281167 (1%)]	Loss: 0.723657
[2022-04-06 16:04:17 | train] - Train Epoch: [146] [25600/1281167 (2%)]	Loss: 0.760127
[2022-04-06 16:04:45 | train] - Train Epoch: [146] [38400/1281167 (3%)]	Loss: 0.729646
[2022-04-06 16:05:13 | train] - Train Epoch: [146] [51200/1281167 (4%)]	Loss: 0.705339
[2022-04-06 16:05:42 | train] - Train Epoch: [146] [64000/1281167 (5%)]	Loss: 0.539351
[2022-04-06 16:06:10 | train] - Train Epoch: [146] [76800/1281167 (6%)]	Loss: 0.578569
[2022-04-06 16:06:38 | train] - Train Epoch: [146] [89600/1281167 (7%)]	Loss: 0.646563
[2022-04-06 16:07:06 | train] - Train Epoch: [146] [102400/1281167 (8%)]	Loss: 0.602898
[2022-04-06 16:07:34 | train] - Train Epoch: [146] [115200/1281167 (9%)]	Loss: 0.737746
[2022-04-06 16:08:02 | train] - Train Epoch: [146] [128000/1281167 (10%)]	Loss: 0.900064
[2022-04-06 16:08:30 | train] - Train Epoch: [146] [140800/1281167 (11%)]	Loss: 0.894411
[2022-04-06 16:08:58 | train] - Train Epoch: [146] [153600/1281167 (12%)]	Loss: 0.739525
[2022-04-06 16:09:27 | train] - Train Epoch: [146] [166400/1281167 (13%)]	Loss: 0.736499
[2022-04-06 16:09:55 | train] - Train Epoch: [146] [179200/1281167 (14%)]	Loss: 1.216509
[2022-04-06 16:10:23 | train] - Train Epoch: [146] [192000/1281167 (15%)]	Loss: 0.613634
[2022-04-06 16:10:51 | train] - Train Epoch: [146] [204800/1281167 (16%)]	Loss: 0.530290
[2022-04-06 16:11:19 | train] - Train Epoch: [146] [217600/1281167 (17%)]	Loss: 0.602318
[2022-04-06 16:11:48 | train] - Train Epoch: [146] [230400/1281167 (18%)]	Loss: 0.808367
[2022-04-06 16:12:16 | train] - Train Epoch: [146] [243200/1281167 (19%)]	Loss: 0.723769
[2022-04-06 16:12:44 | train] - Train Epoch: [146] [256000/1281167 (20%)]	Loss: 0.655010
[2022-04-06 16:13:12 | train] - Train Epoch: [146] [268800/1281167 (21%)]	Loss: 0.893682
[2022-04-06 16:13:40 | train] - Train Epoch: [146] [281600/1281167 (22%)]	Loss: 0.885199
[2022-04-06 16:14:09 | train] - Train Epoch: [146] [294400/1281167 (23%)]	Loss: 0.588418
[2022-04-06 16:14:37 | train] - Train Epoch: [146] [307200/1281167 (24%)]	Loss: 0.669547
[2022-04-06 16:15:05 | train] - Train Epoch: [146] [320000/1281167 (25%)]	Loss: 0.560746
[2022-04-06 16:15:34 | train] - Train Epoch: [146] [332800/1281167 (26%)]	Loss: 0.538003
[2022-04-06 16:16:03 | train] - Train Epoch: [146] [345600/1281167 (27%)]	Loss: 0.484187
[2022-04-06 16:16:32 | train] - Train Epoch: [146] [358400/1281167 (28%)]	Loss: 0.564305
[2022-04-06 16:16:59 | train] - Train Epoch: [146] [371200/1281167 (29%)]	Loss: 0.676094
[2022-04-06 16:17:28 | train] - Train Epoch: [146] [384000/1281167 (30%)]	Loss: 0.813472
[2022-04-06 16:17:56 | train] - Train Epoch: [146] [396800/1281167 (31%)]	Loss: 0.574134
[2022-04-06 16:18:25 | train] - Train Epoch: [146] [409600/1281167 (32%)]	Loss: 0.634932
[2022-04-06 16:18:53 | train] - Train Epoch: [146] [422400/1281167 (33%)]	Loss: 0.502058
[2022-04-06 16:19:20 | train] - Train Epoch: [146] [435200/1281167 (34%)]	Loss: 0.842060
[2022-04-06 16:19:48 | train] - Train Epoch: [146] [448000/1281167 (35%)]	Loss: 0.695325
[2022-04-06 16:20:16 | train] - Train Epoch: [146] [460800/1281167 (36%)]	Loss: 0.585038
[2022-04-06 16:20:44 | train] - Train Epoch: [146] [473600/1281167 (37%)]	Loss: 0.678982
[2022-04-06 16:21:13 | train] - Train Epoch: [146] [486400/1281167 (38%)]	Loss: 0.874537
[2022-04-06 16:21:42 | train] - Train Epoch: [146] [499200/1281167 (39%)]	Loss: 0.787939
[2022-04-06 16:22:09 | train] - Train Epoch: [146] [512000/1281167 (40%)]	Loss: 0.787531
[2022-04-06 16:22:37 | train] - Train Epoch: [146] [524800/1281167 (41%)]	Loss: 0.663270
[2022-04-06 16:23:05 | train] - Train Epoch: [146] [537600/1281167 (42%)]	Loss: 0.658129
[2022-04-06 16:23:34 | train] - Train Epoch: [146] [550400/1281167 (43%)]	Loss: 0.565998
[2022-04-06 16:24:03 | train] - Train Epoch: [146] [563200/1281167 (44%)]	Loss: 0.773495
[2022-04-06 16:24:31 | train] - Train Epoch: [146] [576000/1281167 (45%)]	Loss: 0.693091
[2022-04-06 16:24:59 | train] - Train Epoch: [146] [588800/1281167 (46%)]	Loss: 0.814328
[2022-04-06 16:25:28 | train] - Train Epoch: [146] [601600/1281167 (47%)]	Loss: 0.575929
[2022-04-06 16:25:56 | train] - Train Epoch: [146] [614400/1281167 (48%)]	Loss: 0.662413
[2022-04-06 16:26:23 | train] - Train Epoch: [146] [627200/1281167 (49%)]	Loss: 0.904640
[2022-04-06 16:26:51 | train] - Train Epoch: [146] [640000/1281167 (50%)]	Loss: 0.602796
[2022-04-06 16:27:20 | train] - Train Epoch: [146] [652800/1281167 (51%)]	Loss: 0.614825
[2022-04-06 16:27:46 | train] - Train Epoch: [146] [665600/1281167 (52%)]	Loss: 0.632508
[2022-04-06 16:28:15 | train] - Train Epoch: [146] [678400/1281167 (53%)]	Loss: 0.797315
[2022-04-06 16:28:43 | train] - Train Epoch: [146] [691200/1281167 (54%)]	Loss: 0.538262
[2022-04-06 16:29:11 | train] - Train Epoch: [146] [704000/1281167 (55%)]	Loss: 0.577370
[2022-04-06 16:29:39 | train] - Train Epoch: [146] [716800/1281167 (56%)]	Loss: 0.668312
[I 16:30:00.126 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:30:00.127 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:30:07 | train] - Train Epoch: [146] [729600/1281167 (57%)]	Loss: 0.779230
[2022-04-06 16:30:35 | train] - Train Epoch: [146] [742400/1281167 (58%)]	Loss: 0.752613
[2022-04-06 16:31:03 | train] - Train Epoch: [146] [755200/1281167 (59%)]	Loss: 0.783556
[2022-04-06 16:31:30 | train] - Train Epoch: [146] [768000/1281167 (60%)]	Loss: 0.581170
[2022-04-06 16:31:58 | train] - Train Epoch: [146] [780800/1281167 (61%)]	Loss: 0.434547
[I 16:32:00.114 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:32:00.115 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:32:26 | train] - Train Epoch: [146] [793600/1281167 (62%)]	Loss: 1.110687
[2022-04-06 16:32:54 | train] - Train Epoch: [146] [806400/1281167 (63%)]	Loss: 0.514124
[2022-04-06 16:33:22 | train] - Train Epoch: [146] [819200/1281167 (64%)]	Loss: 0.874277
[2022-04-06 16:33:50 | train] - Train Epoch: [146] [832000/1281167 (65%)]	Loss: 0.795269
[I 16:34:00.117 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:34:00.118 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:34:18 | train] - Train Epoch: [146] [844800/1281167 (66%)]	Loss: 0.544186
[2022-04-06 16:34:46 | train] - Train Epoch: [146] [857600/1281167 (67%)]	Loss: 0.622856
[2022-04-06 16:35:15 | train] - Train Epoch: [146] [870400/1281167 (68%)]	Loss: 0.781588
[2022-04-06 16:35:43 | train] - Train Epoch: [146] [883200/1281167 (69%)]	Loss: 0.663803
[2022-04-06 16:36:10 | train] - Train Epoch: [146] [896000/1281167 (70%)]	Loss: 0.745464
[2022-04-06 16:36:38 | train] - Train Epoch: [146] [908800/1281167 (71%)]	Loss: 0.515670
[2022-04-06 16:37:05 | train] - Train Epoch: [146] [921600/1281167 (72%)]	Loss: 0.460448
[2022-04-06 16:37:34 | train] - Train Epoch: [146] [934400/1281167 (73%)]	Loss: 0.539837
[2022-04-06 16:38:01 | train] - Train Epoch: [146] [947200/1281167 (74%)]	Loss: 0.718079
[2022-04-06 16:38:29 | train] - Train Epoch: [146] [960000/1281167 (75%)]	Loss: 0.798651
[2022-04-06 16:38:58 | train] - Train Epoch: [146] [972800/1281167 (76%)]	Loss: 0.602460
[2022-04-06 16:39:26 | train] - Train Epoch: [146] [985600/1281167 (77%)]	Loss: 0.849038
[2022-04-06 16:39:54 | train] - Train Epoch: [146] [998400/1281167 (78%)]	Loss: 0.535431
[I 16:40:00.135 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:40:00.135 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:40:23 | train] - Train Epoch: [146] [1011200/1281167 (79%)]	Loss: 0.648718
[2022-04-06 16:40:51 | train] - Train Epoch: [146] [1024000/1281167 (80%)]	Loss: 0.671792
[2022-04-06 16:41:19 | train] - Train Epoch: [146] [1036800/1281167 (81%)]	Loss: 0.740043
[2022-04-06 16:41:47 | train] - Train Epoch: [146] [1049600/1281167 (82%)]	Loss: 0.821300
[I 16:42:00.174 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:42:00.175 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:42:15 | train] - Train Epoch: [146] [1062400/1281167 (83%)]	Loss: 1.020214
[2022-04-06 16:42:43 | train] - Train Epoch: [146] [1075200/1281167 (84%)]	Loss: 0.505651
[2022-04-06 16:43:11 | train] - Train Epoch: [146] [1088000/1281167 (85%)]	Loss: 0.885588
[2022-04-06 16:43:40 | train] - Train Epoch: [146] [1100800/1281167 (86%)]	Loss: 0.836600
[I 16:44:00.202 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:44:00.203 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 16:44:10 | train] - Train Epoch: [146] [1113600/1281167 (87%)]	Loss: 0.763722
[2022-04-06 16:44:38 | train] - Train Epoch: [146] [1126400/1281167 (88%)]	Loss: 0.511779
[2022-04-06 16:45:07 | train] - Train Epoch: [146] [1139200/1281167 (89%)]	Loss: 0.854642
[2022-04-06 16:45:35 | train] - Train Epoch: [146] [1152000/1281167 (90%)]	Loss: 0.966404
[2022-04-06 16:46:04 | train] - Train Epoch: [146] [1164800/1281167 (91%)]	Loss: 0.886501
[2022-04-06 16:46:32 | train] - Train Epoch: [146] [1177600/1281167 (92%)]	Loss: 0.814119
[2022-04-06 16:47:00 | train] - Train Epoch: [146] [1190400/1281167 (93%)]	Loss: 0.753033
[2022-04-06 16:47:29 | train] - Train Epoch: [146] [1203200/1281167 (94%)]	Loss: 0.499252
[2022-04-06 16:47:57 | train] - Train Epoch: [146] [1216000/1281167 (95%)]	Loss: 0.708611
[2022-04-06 16:48:25 | train] - Train Epoch: [146] [1228800/1281167 (96%)]	Loss: 0.731632
[2022-04-06 16:48:53 | train] - Train Epoch: [146] [1241600/1281167 (97%)]	Loss: 0.600601
[2022-04-06 16:49:22 | train] - Train Epoch: [146] [1254400/1281167 (98%)]	Loss: 0.593412
[2022-04-06 16:49:50 | train] - Train Epoch: [146] [1267200/1281167 (99%)]	Loss: 0.783593
[2022-04-06 16:50:19 | train] - Train Epoch: [146] [1280000/1281167 (100%)]	Loss: 0.666486
[2022-04-06 16:50:22 | train] - Train Epoch: [146]	 Average Loss: 0.713368	 Total Acc : 82.6795	 Total Top5 Acc : 93.6984
[2022-04-06 16:50:22 | train] - -------146 epoch end-----------
========================================
-------146 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 16:52:21 | train] - 
Epoch [146] Test set: Average loss: 1.4342, Accuracy: 34900/50000 (69.7738%), Top-5 Accuracy: 88.7832%

[2022-04-06 16:52:21 | train] - save intermediate epoch [146] result


[2022-04-06 16:52:32 | train] - -------147 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 16:52:33 | train] - Train Epoch: [147] [0/1281167 (0%)]	Loss: 0.660682
[2022-04-06 16:53:01 | train] - Train Epoch: [147] [12800/1281167 (1%)]	Loss: 0.701208
[2022-04-06 16:53:29 | train] - Train Epoch: [147] [25600/1281167 (2%)]	Loss: 0.580412
[2022-04-06 16:53:56 | train] - Train Epoch: [147] [38400/1281167 (3%)]	Loss: 0.784568
[2022-04-06 16:54:24 | train] - Train Epoch: [147] [51200/1281167 (4%)]	Loss: 0.678312
[2022-04-06 16:54:52 | train] - Train Epoch: [147] [64000/1281167 (5%)]	Loss: 0.618496
[2022-04-06 16:55:19 | train] - Train Epoch: [147] [76800/1281167 (6%)]	Loss: 0.570188
[2022-04-06 16:55:47 | train] - Train Epoch: [147] [89600/1281167 (7%)]	Loss: 0.815142
[2022-04-06 16:56:14 | train] - Train Epoch: [147] [102400/1281167 (8%)]	Loss: 0.827395
[2022-04-06 16:56:41 | train] - Train Epoch: [147] [115200/1281167 (9%)]	Loss: 0.620955
[2022-04-06 16:57:10 | train] - Train Epoch: [147] [128000/1281167 (10%)]	Loss: 0.728315
[2022-04-06 16:57:38 | train] - Train Epoch: [147] [140800/1281167 (11%)]	Loss: 0.530182
[2022-04-06 16:58:05 | train] - Train Epoch: [147] [153600/1281167 (12%)]	Loss: 0.605022
[2022-04-06 16:58:32 | train] - Train Epoch: [147] [166400/1281167 (13%)]	Loss: 0.787542
[2022-04-06 16:59:00 | train] - Train Epoch: [147] [179200/1281167 (14%)]	Loss: 0.784350
[2022-04-06 16:59:28 | train] - Train Epoch: [147] [192000/1281167 (15%)]	Loss: 0.748545
[2022-04-06 16:59:55 | train] - Train Epoch: [147] [204800/1281167 (16%)]	Loss: 0.886051
[2022-04-06 17:00:23 | train] - Train Epoch: [147] [217600/1281167 (17%)]	Loss: 0.717517
[2022-04-06 17:00:51 | train] - Train Epoch: [147] [230400/1281167 (18%)]	Loss: 0.865563
[2022-04-06 17:01:19 | train] - Train Epoch: [147] [243200/1281167 (19%)]	Loss: 0.755185
[2022-04-06 17:01:47 | train] - Train Epoch: [147] [256000/1281167 (20%)]	Loss: 0.993542
[2022-04-06 17:02:14 | train] - Train Epoch: [147] [268800/1281167 (21%)]	Loss: 0.714955
[2022-04-06 17:02:43 | train] - Train Epoch: [147] [281600/1281167 (22%)]	Loss: 0.666519
[2022-04-06 17:03:11 | train] - Train Epoch: [147] [294400/1281167 (23%)]	Loss: 0.617197
[2022-04-06 17:03:38 | train] - Train Epoch: [147] [307200/1281167 (24%)]	Loss: 0.837810
[2022-04-06 17:04:07 | train] - Train Epoch: [147] [320000/1281167 (25%)]	Loss: 0.610464
[2022-04-06 17:04:34 | train] - Train Epoch: [147] [332800/1281167 (26%)]	Loss: 0.711432
[2022-04-06 17:05:01 | train] - Train Epoch: [147] [345600/1281167 (27%)]	Loss: 0.826875
[2022-04-06 17:05:28 | train] - Train Epoch: [147] [358400/1281167 (28%)]	Loss: 0.774371
[2022-04-06 17:05:55 | train] - Train Epoch: [147] [371200/1281167 (29%)]	Loss: 0.660423
[2022-04-06 17:06:23 | train] - Train Epoch: [147] [384000/1281167 (30%)]	Loss: 0.516608
[2022-04-06 17:06:50 | train] - Train Epoch: [147] [396800/1281167 (31%)]	Loss: 0.618078
[2022-04-06 17:07:18 | train] - Train Epoch: [147] [409600/1281167 (32%)]	Loss: 0.758831
[2022-04-06 17:07:46 | train] - Train Epoch: [147] [422400/1281167 (33%)]	Loss: 0.617222
[2022-04-06 17:08:15 | train] - Train Epoch: [147] [435200/1281167 (34%)]	Loss: 0.546270
[2022-04-06 17:08:42 | train] - Train Epoch: [147] [448000/1281167 (35%)]	Loss: 0.577118
[2022-04-06 17:09:10 | train] - Train Epoch: [147] [460800/1281167 (36%)]	Loss: 0.933943
[2022-04-06 17:09:38 | train] - Train Epoch: [147] [473600/1281167 (37%)]	Loss: 0.590744
[2022-04-06 17:10:07 | train] - Train Epoch: [147] [486400/1281167 (38%)]	Loss: 0.676399
[2022-04-06 17:10:34 | train] - Train Epoch: [147] [499200/1281167 (39%)]	Loss: 0.881352
[2022-04-06 17:11:02 | train] - Train Epoch: [147] [512000/1281167 (40%)]	Loss: 0.893914
[2022-04-06 17:11:29 | train] - Train Epoch: [147] [524800/1281167 (41%)]	Loss: 0.605512
[2022-04-06 17:11:57 | train] - Train Epoch: [147] [537600/1281167 (42%)]	Loss: 0.589541
[2022-04-06 17:12:25 | train] - Train Epoch: [147] [550400/1281167 (43%)]	Loss: 0.732192
[2022-04-06 17:12:52 | train] - Train Epoch: [147] [563200/1281167 (44%)]	Loss: 0.640689
[2022-04-06 17:13:20 | train] - Train Epoch: [147] [576000/1281167 (45%)]	Loss: 0.696988
[2022-04-06 17:13:47 | train] - Train Epoch: [147] [588800/1281167 (46%)]	Loss: 1.049264
[2022-04-06 17:14:15 | train] - Train Epoch: [147] [601600/1281167 (47%)]	Loss: 0.499216
[2022-04-06 17:14:42 | train] - Train Epoch: [147] [614400/1281167 (48%)]	Loss: 0.598399
[2022-04-06 17:15:11 | train] - Train Epoch: [147] [627200/1281167 (49%)]	Loss: 0.531877
[2022-04-06 17:15:38 | train] - Train Epoch: [147] [640000/1281167 (50%)]	Loss: 0.707192
[2022-04-06 17:16:06 | train] - Train Epoch: [147] [652800/1281167 (51%)]	Loss: 0.914541
[2022-04-06 17:16:33 | train] - Train Epoch: [147] [665600/1281167 (52%)]	Loss: 0.736141
[2022-04-06 17:17:00 | train] - Train Epoch: [147] [678400/1281167 (53%)]	Loss: 0.558777
[2022-04-06 17:17:28 | train] - Train Epoch: [147] [691200/1281167 (54%)]	Loss: 0.700193
[2022-04-06 17:17:56 | train] - Train Epoch: [147] [704000/1281167 (55%)]	Loss: 0.868727
[2022-04-06 17:18:24 | train] - Train Epoch: [147] [716800/1281167 (56%)]	Loss: 0.839859
[2022-04-06 17:18:51 | train] - Train Epoch: [147] [729600/1281167 (57%)]	Loss: 0.696352
[2022-04-06 17:19:19 | train] - Train Epoch: [147] [742400/1281167 (58%)]	Loss: 1.081090
[2022-04-06 17:19:46 | train] - Train Epoch: [147] [755200/1281167 (59%)]	Loss: 0.809540
[2022-04-06 17:20:13 | train] - Train Epoch: [147] [768000/1281167 (60%)]	Loss: 0.771604
[2022-04-06 17:20:40 | train] - Train Epoch: [147] [780800/1281167 (61%)]	Loss: 0.732106
[2022-04-06 17:21:08 | train] - Train Epoch: [147] [793600/1281167 (62%)]	Loss: 0.705490
[2022-04-06 17:21:36 | train] - Train Epoch: [147] [806400/1281167 (63%)]	Loss: 0.676561
[2022-04-06 17:22:04 | train] - Train Epoch: [147] [819200/1281167 (64%)]	Loss: 0.467563
[2022-04-06 17:22:31 | train] - Train Epoch: [147] [832000/1281167 (65%)]	Loss: 0.581310
[2022-04-06 17:22:58 | train] - Train Epoch: [147] [844800/1281167 (66%)]	Loss: 0.851190
[2022-04-06 17:23:25 | train] - Train Epoch: [147] [857600/1281167 (67%)]	Loss: 0.791876
[2022-04-06 17:23:52 | train] - Train Epoch: [147] [870400/1281167 (68%)]	Loss: 0.731406
[2022-04-06 17:24:20 | train] - Train Epoch: [147] [883200/1281167 (69%)]	Loss: 0.626427
[2022-04-06 17:24:48 | train] - Train Epoch: [147] [896000/1281167 (70%)]	Loss: 0.376606
[2022-04-06 17:25:15 | train] - Train Epoch: [147] [908800/1281167 (71%)]	Loss: 0.733429
[2022-04-06 17:25:42 | train] - Train Epoch: [147] [921600/1281167 (72%)]	Loss: 0.606647
[I 17:26:00.270 NotebookApp] Saving file at /pdh_test.ipynb
[I 17:26:00.271 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 17:26:10 | train] - Train Epoch: [147] [934400/1281167 (73%)]	Loss: 0.879795
[2022-04-06 17:26:37 | train] - Train Epoch: [147] [947200/1281167 (74%)]	Loss: 0.679882
[2022-04-06 17:27:03 | train] - Train Epoch: [147] [960000/1281167 (75%)]	Loss: 0.672520
[2022-04-06 17:27:32 | train] - Train Epoch: [147] [972800/1281167 (76%)]	Loss: 0.384311
[2022-04-06 17:27:59 | train] - Train Epoch: [147] [985600/1281167 (77%)]	Loss: 0.769836
[2022-04-06 17:28:27 | train] - Train Epoch: [147] [998400/1281167 (78%)]	Loss: 0.643425
[2022-04-06 17:28:55 | train] - Train Epoch: [147] [1011200/1281167 (79%)]	Loss: 0.726802
[2022-04-06 17:29:22 | train] - Train Epoch: [147] [1024000/1281167 (80%)]	Loss: 0.609909
[2022-04-06 17:29:50 | train] - Train Epoch: [147] [1036800/1281167 (81%)]	Loss: 0.636082
[2022-04-06 17:30:18 | train] - Train Epoch: [147] [1049600/1281167 (82%)]	Loss: 0.800451
[2022-04-06 17:30:45 | train] - Train Epoch: [147] [1062400/1281167 (83%)]	Loss: 0.641266
[2022-04-06 17:31:13 | train] - Train Epoch: [147] [1075200/1281167 (84%)]	Loss: 0.768787
[2022-04-06 17:31:42 | train] - Train Epoch: [147] [1088000/1281167 (85%)]	Loss: 0.677546
[2022-04-06 17:32:09 | train] - Train Epoch: [147] [1100800/1281167 (86%)]	Loss: 0.530290
[2022-04-06 17:32:37 | train] - Train Epoch: [147] [1113600/1281167 (87%)]	Loss: 0.737202
[2022-04-06 17:33:05 | train] - Train Epoch: [147] [1126400/1281167 (88%)]	Loss: 0.626076
[2022-04-06 17:33:34 | train] - Train Epoch: [147] [1139200/1281167 (89%)]	Loss: 0.848378
[2022-04-06 17:34:01 | train] - Train Epoch: [147] [1152000/1281167 (90%)]	Loss: 0.734648
[2022-04-06 17:34:29 | train] - Train Epoch: [147] [1164800/1281167 (91%)]	Loss: 0.683128
[2022-04-06 17:34:58 | train] - Train Epoch: [147] [1177600/1281167 (92%)]	Loss: 0.548174
[2022-04-06 17:35:26 | train] - Train Epoch: [147] [1190400/1281167 (93%)]	Loss: 0.585444
[2022-04-06 17:35:53 | train] - Train Epoch: [147] [1203200/1281167 (94%)]	Loss: 0.957206
[2022-04-06 17:36:21 | train] - Train Epoch: [147] [1216000/1281167 (95%)]	Loss: 0.770589
[2022-04-06 17:36:49 | train] - Train Epoch: [147] [1228800/1281167 (96%)]	Loss: 0.767697
[2022-04-06 17:37:18 | train] - Train Epoch: [147] [1241600/1281167 (97%)]	Loss: 0.790334
[2022-04-06 17:37:47 | train] - Train Epoch: [147] [1254400/1281167 (98%)]	Loss: 0.579781
[2022-04-06 17:38:15 | train] - Train Epoch: [147] [1267200/1281167 (99%)]	Loss: 0.828018
[2022-04-06 17:38:43 | train] - Train Epoch: [147] [1280000/1281167 (100%)]	Loss: 0.946203
[2022-04-06 17:38:45 | train] - Train Epoch: [147]	 Average Loss: 0.710281	 Total Acc : 82.7226	 Total Top5 Acc : 93.7802
[2022-04-06 17:38:45 | train] - -------147 epoch end-----------
========================================
-------147 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 17:40:47 | train] - 
Epoch [147] Test set: Average loss: 1.4594, Accuracy: 34813/50000 (69.5988%), Top-5 Accuracy: 88.7512%

[2022-04-06 17:40:47 | train] - save intermediate epoch [147] result


[2022-04-06 17:40:58 | train] - -------148 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 17:41:00 | train] - Train Epoch: [148] [0/1281167 (0%)]	Loss: 0.733401
[2022-04-06 17:41:27 | train] - Train Epoch: [148] [12800/1281167 (1%)]	Loss: 0.689418
[2022-04-06 17:41:54 | train] - Train Epoch: [148] [25600/1281167 (2%)]	Loss: 0.766108
[2022-04-06 17:42:23 | train] - Train Epoch: [148] [38400/1281167 (3%)]	Loss: 0.656732
[2022-04-06 17:42:50 | train] - Train Epoch: [148] [51200/1281167 (4%)]	Loss: 0.798813
[2022-04-06 17:43:17 | train] - Train Epoch: [148] [64000/1281167 (5%)]	Loss: 0.803543
[2022-04-06 17:43:45 | train] - Train Epoch: [148] [76800/1281167 (6%)]	Loss: 0.927996
[2022-04-06 17:44:12 | train] - Train Epoch: [148] [89600/1281167 (7%)]	Loss: 0.813305
[2022-04-06 17:44:39 | train] - Train Epoch: [148] [102400/1281167 (8%)]	Loss: 0.872223
[2022-04-06 17:45:06 | train] - Train Epoch: [148] [115200/1281167 (9%)]	Loss: 0.874501
[2022-04-06 17:45:34 | train] - Train Epoch: [148] [128000/1281167 (10%)]	Loss: 0.835278
[2022-04-06 17:46:02 | train] - Train Epoch: [148] [140800/1281167 (11%)]	Loss: 0.744174
[2022-04-06 17:46:30 | train] - Train Epoch: [148] [153600/1281167 (12%)]	Loss: 0.512062
[2022-04-06 17:46:57 | train] - Train Epoch: [148] [166400/1281167 (13%)]	Loss: 0.768745
[2022-04-06 17:47:24 | train] - Train Epoch: [148] [179200/1281167 (14%)]	Loss: 0.515953
[2022-04-06 17:47:51 | train] - Train Epoch: [148] [192000/1281167 (15%)]	Loss: 0.823592
[2022-04-06 17:48:19 | train] - Train Epoch: [148] [204800/1281167 (16%)]	Loss: 0.775908
[2022-04-06 17:48:47 | train] - Train Epoch: [148] [217600/1281167 (17%)]	Loss: 0.828991
[2022-04-06 17:49:14 | train] - Train Epoch: [148] [230400/1281167 (18%)]	Loss: 0.798251
[2022-04-06 17:49:40 | train] - Train Epoch: [148] [243200/1281167 (19%)]	Loss: 0.686747
[2022-04-06 17:50:08 | train] - Train Epoch: [148] [256000/1281167 (20%)]	Loss: 0.659402
[2022-04-06 17:50:35 | train] - Train Epoch: [148] [268800/1281167 (21%)]	Loss: 0.844568
[2022-04-06 17:51:02 | train] - Train Epoch: [148] [281600/1281167 (22%)]	Loss: 0.697164
[2022-04-06 17:51:28 | train] - Train Epoch: [148] [294400/1281167 (23%)]	Loss: 0.736592
[2022-04-06 17:51:55 | train] - Train Epoch: [148] [307200/1281167 (24%)]	Loss: 0.536953
[2022-04-06 17:52:23 | train] - Train Epoch: [148] [320000/1281167 (25%)]	Loss: 0.698734
[2022-04-06 17:52:51 | train] - Train Epoch: [148] [332800/1281167 (26%)]	Loss: 0.692282
[2022-04-06 17:53:18 | train] - Train Epoch: [148] [345600/1281167 (27%)]	Loss: 0.717122
[2022-04-06 17:53:45 | train] - Train Epoch: [148] [358400/1281167 (28%)]	Loss: 0.951853
[2022-04-06 17:54:12 | train] - Train Epoch: [148] [371200/1281167 (29%)]	Loss: 0.620463
[2022-04-06 17:54:39 | train] - Train Epoch: [148] [384000/1281167 (30%)]	Loss: 0.609566
[2022-04-06 17:55:06 | train] - Train Epoch: [148] [396800/1281167 (31%)]	Loss: 0.578682
[2022-04-06 17:55:34 | train] - Train Epoch: [148] [409600/1281167 (32%)]	Loss: 0.819635
[2022-04-06 17:56:01 | train] - Train Epoch: [148] [422400/1281167 (33%)]	Loss: 0.653783
[2022-04-06 17:56:29 | train] - Train Epoch: [148] [435200/1281167 (34%)]	Loss: 0.697203
[2022-04-06 17:56:56 | train] - Train Epoch: [148] [448000/1281167 (35%)]	Loss: 0.512159
[2022-04-06 17:57:24 | train] - Train Epoch: [148] [460800/1281167 (36%)]	Loss: 0.710768
[2022-04-06 17:57:51 | train] - Train Epoch: [148] [473600/1281167 (37%)]	Loss: 0.887717
[2022-04-06 17:58:18 | train] - Train Epoch: [148] [486400/1281167 (38%)]	Loss: 0.888031
[2022-04-06 17:58:45 | train] - Train Epoch: [148] [499200/1281167 (39%)]	Loss: 0.877021
[2022-04-06 17:59:12 | train] - Train Epoch: [148] [512000/1281167 (40%)]	Loss: 0.849667
[2022-04-06 17:59:40 | train] - Train Epoch: [148] [524800/1281167 (41%)]	Loss: 0.968948
[2022-04-06 18:00:07 | train] - Train Epoch: [148] [537600/1281167 (42%)]	Loss: 1.249469
[2022-04-06 18:00:34 | train] - Train Epoch: [148] [550400/1281167 (43%)]	Loss: 0.845443
[2022-04-06 18:01:01 | train] - Train Epoch: [148] [563200/1281167 (44%)]	Loss: 0.786030
[2022-04-06 18:01:28 | train] - Train Epoch: [148] [576000/1281167 (45%)]	Loss: 0.609827
[2022-04-06 18:01:55 | train] - Train Epoch: [148] [588800/1281167 (46%)]	Loss: 0.575448
[2022-04-06 18:02:23 | train] - Train Epoch: [148] [601600/1281167 (47%)]	Loss: 0.915230
[2022-04-06 18:02:51 | train] - Train Epoch: [148] [614400/1281167 (48%)]	Loss: 0.747486
[2022-04-06 18:03:18 | train] - Train Epoch: [148] [627200/1281167 (49%)]	Loss: 0.649137
[2022-04-06 18:03:45 | train] - Train Epoch: [148] [640000/1281167 (50%)]	Loss: 0.751828
[2022-04-06 18:04:13 | train] - Train Epoch: [148] [652800/1281167 (51%)]	Loss: 0.469266
[2022-04-06 18:04:40 | train] - Train Epoch: [148] [665600/1281167 (52%)]	Loss: 0.685041
[2022-04-06 18:05:07 | train] - Train Epoch: [148] [678400/1281167 (53%)]	Loss: 0.619960
[2022-04-06 18:05:34 | train] - Train Epoch: [148] [691200/1281167 (54%)]	Loss: 0.676576
[2022-04-06 18:06:02 | train] - Train Epoch: [148] [704000/1281167 (55%)]	Loss: 0.558358
[2022-04-06 18:06:30 | train] - Train Epoch: [148] [716800/1281167 (56%)]	Loss: 0.518065
[2022-04-06 18:06:57 | train] - Train Epoch: [148] [729600/1281167 (57%)]	Loss: 0.341871
[2022-04-06 18:07:24 | train] - Train Epoch: [148] [742400/1281167 (58%)]	Loss: 0.550315
[2022-04-06 18:07:52 | train] - Train Epoch: [148] [755200/1281167 (59%)]	Loss: 0.480840
[2022-04-06 18:08:21 | train] - Train Epoch: [148] [768000/1281167 (60%)]	Loss: 0.848366
[2022-04-06 18:08:49 | train] - Train Epoch: [148] [780800/1281167 (61%)]	Loss: 0.712841
[2022-04-06 18:09:16 | train] - Train Epoch: [148] [793600/1281167 (62%)]	Loss: 0.694154
[2022-04-06 18:09:44 | train] - Train Epoch: [148] [806400/1281167 (63%)]	Loss: 0.763464
[2022-04-06 18:10:12 | train] - Train Epoch: [148] [819200/1281167 (64%)]	Loss: 0.663778
[2022-04-06 18:10:40 | train] - Train Epoch: [148] [832000/1281167 (65%)]	Loss: 0.809525
[2022-04-06 18:11:08 | train] - Train Epoch: [148] [844800/1281167 (66%)]	Loss: 0.657207
[2022-04-06 18:11:35 | train] - Train Epoch: [148] [857600/1281167 (67%)]	Loss: 0.822087
[2022-04-06 18:12:02 | train] - Train Epoch: [148] [870400/1281167 (68%)]	Loss: 0.781550
[2022-04-06 18:12:30 | train] - Train Epoch: [148] [883200/1281167 (69%)]	Loss: 0.636850
[2022-04-06 18:12:58 | train] - Train Epoch: [148] [896000/1281167 (70%)]	Loss: 0.659760
[2022-04-06 18:13:26 | train] - Train Epoch: [148] [908800/1281167 (71%)]	Loss: 0.557145
[2022-04-06 18:13:53 | train] - Train Epoch: [148] [921600/1281167 (72%)]	Loss: 0.688372
[2022-04-06 18:14:21 | train] - Train Epoch: [148] [934400/1281167 (73%)]	Loss: 0.715262
[2022-04-06 18:14:48 | train] - Train Epoch: [148] [947200/1281167 (74%)]	Loss: 0.821407
[2022-04-06 18:15:15 | train] - Train Epoch: [148] [960000/1281167 (75%)]	Loss: 0.592791
[2022-04-06 18:15:43 | train] - Train Epoch: [148] [972800/1281167 (76%)]	Loss: 0.603409
[2022-04-06 18:16:10 | train] - Train Epoch: [148] [985600/1281167 (77%)]	Loss: 0.818571
[2022-04-06 18:16:38 | train] - Train Epoch: [148] [998400/1281167 (78%)]	Loss: 0.372826
[2022-04-06 18:17:06 | train] - Train Epoch: [148] [1011200/1281167 (79%)]	Loss: 0.733610
[2022-04-06 18:17:33 | train] - Train Epoch: [148] [1024000/1281167 (80%)]	Loss: 0.851344
[2022-04-06 18:18:01 | train] - Train Epoch: [148] [1036800/1281167 (81%)]	Loss: 0.739082
[2022-04-06 18:18:29 | train] - Train Epoch: [148] [1049600/1281167 (82%)]	Loss: 0.605476
[2022-04-06 18:18:56 | train] - Train Epoch: [148] [1062400/1281167 (83%)]	Loss: 0.726361
[2022-04-06 18:19:24 | train] - Train Epoch: [148] [1075200/1281167 (84%)]	Loss: 0.796187
[2022-04-06 18:19:52 | train] - Train Epoch: [148] [1088000/1281167 (85%)]	Loss: 0.614546
[2022-04-06 18:20:19 | train] - Train Epoch: [148] [1100800/1281167 (86%)]	Loss: 0.586482
[2022-04-06 18:20:47 | train] - Train Epoch: [148] [1113600/1281167 (87%)]	Loss: 0.776000
[2022-04-06 18:21:14 | train] - Train Epoch: [148] [1126400/1281167 (88%)]	Loss: 0.560644
[2022-04-06 18:21:42 | train] - Train Epoch: [148] [1139200/1281167 (89%)]	Loss: 0.935865
[2022-04-06 18:22:10 | train] - Train Epoch: [148] [1152000/1281167 (90%)]	Loss: 0.563722
[2022-04-06 18:22:38 | train] - Train Epoch: [148] [1164800/1281167 (91%)]	Loss: 0.829396
[2022-04-06 18:23:06 | train] - Train Epoch: [148] [1177600/1281167 (92%)]	Loss: 0.493693
[2022-04-06 18:23:33 | train] - Train Epoch: [148] [1190400/1281167 (93%)]	Loss: 0.721348
[2022-04-06 18:24:01 | train] - Train Epoch: [148] [1203200/1281167 (94%)]	Loss: 0.635197
[2022-04-06 18:24:29 | train] - Train Epoch: [148] [1216000/1281167 (95%)]	Loss: 0.715312
[2022-04-06 18:24:57 | train] - Train Epoch: [148] [1228800/1281167 (96%)]	Loss: 0.670550
[2022-04-06 18:25:25 | train] - Train Epoch: [148] [1241600/1281167 (97%)]	Loss: 0.785857
[2022-04-06 18:25:53 | train] - Train Epoch: [148] [1254400/1281167 (98%)]	Loss: 0.814084
[2022-04-06 18:26:21 | train] - Train Epoch: [148] [1267200/1281167 (99%)]	Loss: 0.786716
[2022-04-06 18:26:49 | train] - Train Epoch: [148] [1280000/1281167 (100%)]	Loss: 0.859242
[2022-04-06 18:26:51 | train] - Train Epoch: [148]	 Average Loss: 0.707780	 Total Acc : 82.7986	 Total Top5 Acc : 93.7832
[2022-04-06 18:26:51 | train] - -------148 epoch end-----------
========================================
-------148 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 18:28:49 | train] - 
Epoch [148] Test set: Average loss: 1.4571, Accuracy: 34855/50000 (69.6815%), Top-5 Accuracy: 88.7392%

[2022-04-06 18:28:49 | train] - save intermediate epoch [148] result


[2022-04-06 18:29:00 | train] - -------149 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 18:29:02 | train] - Train Epoch: [149] [0/1281167 (0%)]	Loss: 0.614750
[2022-04-06 18:29:29 | train] - Train Epoch: [149] [12800/1281167 (1%)]	Loss: 0.636552
[2022-04-06 18:29:55 | train] - Train Epoch: [149] [25600/1281167 (2%)]	Loss: 0.744050
[2022-04-06 18:30:21 | train] - Train Epoch: [149] [38400/1281167 (3%)]	Loss: 0.577576
[2022-04-06 18:30:47 | train] - Train Epoch: [149] [51200/1281167 (4%)]	Loss: 0.665380
[2022-04-06 18:31:13 | train] - Train Epoch: [149] [64000/1281167 (5%)]	Loss: 0.689702
[2022-04-06 18:31:39 | train] - Train Epoch: [149] [76800/1281167 (6%)]	Loss: 0.635333
[2022-04-06 18:32:05 | train] - Train Epoch: [149] [89600/1281167 (7%)]	Loss: 0.714564
[2022-04-06 18:32:30 | train] - Train Epoch: [149] [102400/1281167 (8%)]	Loss: 0.625689
[2022-04-06 18:32:58 | train] - Train Epoch: [149] [115200/1281167 (9%)]	Loss: 0.486104
[2022-04-06 18:33:25 | train] - Train Epoch: [149] [128000/1281167 (10%)]	Loss: 0.612274
[2022-04-06 18:33:52 | train] - Train Epoch: [149] [140800/1281167 (11%)]	Loss: 0.652686
[2022-04-06 18:34:18 | train] - Train Epoch: [149] [153600/1281167 (12%)]	Loss: 0.686276
[2022-04-06 18:34:44 | train] - Train Epoch: [149] [166400/1281167 (13%)]	Loss: 0.674603
[2022-04-06 18:35:11 | train] - Train Epoch: [149] [179200/1281167 (14%)]	Loss: 0.779592
[2022-04-06 18:35:37 | train] - Train Epoch: [149] [192000/1281167 (15%)]	Loss: 0.792773
[2022-04-06 18:36:04 | train] - Train Epoch: [149] [204800/1281167 (16%)]	Loss: 0.638325
[2022-04-06 18:36:30 | train] - Train Epoch: [149] [217600/1281167 (17%)]	Loss: 0.842149
[2022-04-06 18:36:58 | train] - Train Epoch: [149] [230400/1281167 (18%)]	Loss: 0.633215
[2022-04-06 18:37:24 | train] - Train Epoch: [149] [243200/1281167 (19%)]	Loss: 0.595984
[2022-04-06 18:37:49 | train] - Train Epoch: [149] [256000/1281167 (20%)]	Loss: 0.721413
[2022-04-06 18:38:15 | train] - Train Epoch: [149] [268800/1281167 (21%)]	Loss: 0.865335
[2022-04-06 18:38:42 | train] - Train Epoch: [149] [281600/1281167 (22%)]	Loss: 0.623282
[2022-04-06 18:39:10 | train] - Train Epoch: [149] [294400/1281167 (23%)]	Loss: 0.871610
[2022-04-06 18:39:36 | train] - Train Epoch: [149] [307200/1281167 (24%)]	Loss: 0.702322
[2022-04-06 18:40:03 | train] - Train Epoch: [149] [320000/1281167 (25%)]	Loss: 0.726003
[2022-04-06 18:40:31 | train] - Train Epoch: [149] [332800/1281167 (26%)]	Loss: 0.868927
[2022-04-06 18:40:57 | train] - Train Epoch: [149] [345600/1281167 (27%)]	Loss: 0.917197
[2022-04-06 18:41:25 | train] - Train Epoch: [149] [358400/1281167 (28%)]	Loss: 0.789631
[2022-04-06 18:41:53 | train] - Train Epoch: [149] [371200/1281167 (29%)]	Loss: 0.730910
[2022-04-06 18:42:19 | train] - Train Epoch: [149] [384000/1281167 (30%)]	Loss: 0.739031
[2022-04-06 18:42:46 | train] - Train Epoch: [149] [396800/1281167 (31%)]	Loss: 0.599883
[2022-04-06 18:43:12 | train] - Train Epoch: [149] [409600/1281167 (32%)]	Loss: 0.744187
[2022-04-06 18:43:38 | train] - Train Epoch: [149] [422400/1281167 (33%)]	Loss: 0.840372
[I 18:44:00.381 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:44:00.382 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:44:04 | train] - Train Epoch: [149] [435200/1281167 (34%)]	Loss: 0.921158
[2022-04-06 18:44:30 | train] - Train Epoch: [149] [448000/1281167 (35%)]	Loss: 0.629790
[2022-04-06 18:44:57 | train] - Train Epoch: [149] [460800/1281167 (36%)]	Loss: 0.734253
[2022-04-06 18:45:24 | train] - Train Epoch: [149] [473600/1281167 (37%)]	Loss: 0.676343
[2022-04-06 18:45:50 | train] - Train Epoch: [149] [486400/1281167 (38%)]	Loss: 0.575141
[I 18:46:00.358 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:46:00.359 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:46:17 | train] - Train Epoch: [149] [499200/1281167 (39%)]	Loss: 0.766753
[2022-04-06 18:46:43 | train] - Train Epoch: [149] [512000/1281167 (40%)]	Loss: 0.567323
[2022-04-06 18:47:09 | train] - Train Epoch: [149] [524800/1281167 (41%)]	Loss: 0.504936
[2022-04-06 18:47:35 | train] - Train Epoch: [149] [537600/1281167 (42%)]	Loss: 0.694899
[I 18:48:00.365 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:48:00.366 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:48:02 | train] - Train Epoch: [149] [550400/1281167 (43%)]	Loss: 0.743467
[2022-04-06 18:48:29 | train] - Train Epoch: [149] [563200/1281167 (44%)]	Loss: 0.737620
[2022-04-06 18:48:55 | train] - Train Epoch: [149] [576000/1281167 (45%)]	Loss: 0.890156
[2022-04-06 18:49:22 | train] - Train Epoch: [149] [588800/1281167 (46%)]	Loss: 0.590088
[2022-04-06 18:49:49 | train] - Train Epoch: [149] [601600/1281167 (47%)]	Loss: 0.680867
[I 18:50:00.361 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:50:00.363 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:50:15 | train] - Train Epoch: [149] [614400/1281167 (48%)]	Loss: 0.836022
[2022-04-06 18:50:41 | train] - Train Epoch: [149] [627200/1281167 (49%)]	Loss: 0.426498
[2022-04-06 18:51:07 | train] - Train Epoch: [149] [640000/1281167 (50%)]	Loss: 0.898807
[2022-04-06 18:51:33 | train] - Train Epoch: [149] [652800/1281167 (51%)]	Loss: 0.644210
[2022-04-06 18:51:59 | train] - Train Epoch: [149] [665600/1281167 (52%)]	Loss: 0.733767
[I 18:52:00.369 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:52:00.370 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:52:25 | train] - Train Epoch: [149] [678400/1281167 (53%)]	Loss: 0.753894
[2022-04-06 18:52:51 | train] - Train Epoch: [149] [691200/1281167 (54%)]	Loss: 0.637762
[2022-04-06 18:53:18 | train] - Train Epoch: [149] [704000/1281167 (55%)]	Loss: 0.495415
[2022-04-06 18:53:45 | train] - Train Epoch: [149] [716800/1281167 (56%)]	Loss: 0.839332
[I 18:54:00.377 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:54:00.378 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:54:11 | train] - Train Epoch: [149] [729600/1281167 (57%)]	Loss: 0.453658
[2022-04-06 18:54:38 | train] - Train Epoch: [149] [742400/1281167 (58%)]	Loss: 0.619100
[2022-04-06 18:55:04 | train] - Train Epoch: [149] [755200/1281167 (59%)]	Loss: 0.668826
[2022-04-06 18:55:31 | train] - Train Epoch: [149] [768000/1281167 (60%)]	Loss: 0.740078
[2022-04-06 18:55:58 | train] - Train Epoch: [149] [780800/1281167 (61%)]	Loss: 0.511949
[I 18:56:00.385 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:56:00.385 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 18:56:24 | train] - Train Epoch: [149] [793600/1281167 (62%)]	Loss: 0.816717
[2022-04-06 18:56:51 | train] - Train Epoch: [149] [806400/1281167 (63%)]	Loss: 0.766136
[2022-04-06 18:57:18 | train] - Train Epoch: [149] [819200/1281167 (64%)]	Loss: 0.671250
[2022-04-06 18:57:45 | train] - Train Epoch: [149] [832000/1281167 (65%)]	Loss: 0.626952
[2022-04-06 18:58:11 | train] - Train Epoch: [149] [844800/1281167 (66%)]	Loss: 0.717628
[2022-04-06 18:58:37 | train] - Train Epoch: [149] [857600/1281167 (67%)]	Loss: 0.874838
[2022-04-06 18:59:04 | train] - Train Epoch: [149] [870400/1281167 (68%)]	Loss: 0.673721
[2022-04-06 18:59:31 | train] - Train Epoch: [149] [883200/1281167 (69%)]	Loss: 0.676894
[2022-04-06 18:59:58 | train] - Train Epoch: [149] [896000/1281167 (70%)]	Loss: 0.690948
[I 19:00:00.383 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:00:00.384 NotebookApp] Saving pdh_test.ipynb
[2022-04-06 19:00:24 | train] - Train Epoch: [149] [908800/1281167 (71%)]	Loss: 1.000198
[2022-04-06 19:00:51 | train] - Train Epoch: [149] [921600/1281167 (72%)]	Loss: 0.811118
[2022-04-06 19:01:18 | train] - Train Epoch: [149] [934400/1281167 (73%)]	Loss: 0.841325
[2022-04-06 19:01:45 | train] - Train Epoch: [149] [947200/1281167 (74%)]	Loss: 0.856922
[2022-04-06 19:02:11 | train] - Train Epoch: [149] [960000/1281167 (75%)]	Loss: 0.626673
[2022-04-06 19:02:39 | train] - Train Epoch: [149] [972800/1281167 (76%)]	Loss: 0.645911
[2022-04-06 19:03:05 | train] - Train Epoch: [149] [985600/1281167 (77%)]	Loss: 0.951910
[2022-04-06 19:03:32 | train] - Train Epoch: [149] [998400/1281167 (78%)]	Loss: 0.724949
[2022-04-06 19:03:59 | train] - Train Epoch: [149] [1011200/1281167 (79%)]	Loss: 0.583391
[2022-04-06 19:04:26 | train] - Train Epoch: [149] [1024000/1281167 (80%)]	Loss: 0.687286
[2022-04-06 19:04:53 | train] - Train Epoch: [149] [1036800/1281167 (81%)]	Loss: 0.848125
[2022-04-06 19:05:20 | train] - Train Epoch: [149] [1049600/1281167 (82%)]	Loss: 0.739182
[2022-04-06 19:05:46 | train] - Train Epoch: [149] [1062400/1281167 (83%)]	Loss: 0.384322
[2022-04-06 19:06:14 | train] - Train Epoch: [149] [1075200/1281167 (84%)]	Loss: 0.471640
[2022-04-06 19:06:41 | train] - Train Epoch: [149] [1088000/1281167 (85%)]	Loss: 0.570275
[2022-04-06 19:07:09 | train] - Train Epoch: [149] [1100800/1281167 (86%)]	Loss: 0.627306
[2022-04-06 19:07:36 | train] - Train Epoch: [149] [1113600/1281167 (87%)]	Loss: 0.915372
[2022-04-06 19:08:04 | train] - Train Epoch: [149] [1126400/1281167 (88%)]	Loss: 0.704205
[2022-04-06 19:08:31 | train] - Train Epoch: [149] [1139200/1281167 (89%)]	Loss: 0.738302
[2022-04-06 19:08:58 | train] - Train Epoch: [149] [1152000/1281167 (90%)]	Loss: 0.416436
[2022-04-06 19:09:24 | train] - Train Epoch: [149] [1164800/1281167 (91%)]	Loss: 0.736436
[2022-04-06 19:09:51 | train] - Train Epoch: [149] [1177600/1281167 (92%)]	Loss: 0.755546
[2022-04-06 19:10:18 | train] - Train Epoch: [149] [1190400/1281167 (93%)]	Loss: 0.826274
[2022-04-06 19:10:46 | train] - Train Epoch: [149] [1203200/1281167 (94%)]	Loss: 0.845108
[2022-04-06 19:11:13 | train] - Train Epoch: [149] [1216000/1281167 (95%)]	Loss: 0.642029
[2022-04-06 19:11:40 | train] - Train Epoch: [149] [1228800/1281167 (96%)]	Loss: 0.611258
[2022-04-06 19:12:06 | train] - Train Epoch: [149] [1241600/1281167 (97%)]	Loss: 0.865597
[2022-04-06 19:12:34 | train] - Train Epoch: [149] [1254400/1281167 (98%)]	Loss: 0.890313
[2022-04-06 19:13:01 | train] - Train Epoch: [149] [1267200/1281167 (99%)]	Loss: 0.845501
[2022-04-06 19:13:28 | train] - Train Epoch: [149] [1280000/1281167 (100%)]	Loss: 0.851566
[2022-04-06 19:13:30 | train] - Train Epoch: [149]	 Average Loss: 0.706584	 Total Acc : 82.8173	 Total Top5 Acc : 93.7748
[2022-04-06 19:13:30 | train] - -------149 epoch end-----------
========================================
-------149 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 19:15:29 | train] - 
Epoch [149] Test set: Average loss: 1.4505, Accuracy: 34931/50000 (69.8358%), Top-5 Accuracy: 88.6981%

[2022-04-06 19:15:29 | train] - save intermediate epoch [149] result


[2022-04-06 19:15:41 | train] - -------150 epoch start-----------
[2022-04-06 19:15:41 | train] - -------- logging 150 batch layer input tensor ------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
batch_grad_output shape : torch.Size([128, 64, 112, 112])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
[2022-04-06 19:16:09 | train] - -------- logging end 150 --------------------
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1000])
batch_grad_output tuples shape : [128]
[2022-04-06 19:16:11 | train] - Train Epoch: [150] [0/1281167 (0%)]	Loss: 0.813509
[2022-04-06 19:16:39 | train] - Train Epoch: [150] [12800/1281167 (1%)]	Loss: 0.757555
[2022-04-06 19:17:06 | train] - Train Epoch: [150] [25600/1281167 (2%)]	Loss: 0.679170
[2022-04-06 19:17:34 | train] - Train Epoch: [150] [38400/1281167 (3%)]	Loss: 0.585075
[2022-04-06 19:18:02 | train] - Train Epoch: [150] [51200/1281167 (4%)]	Loss: 0.687364
[2022-04-06 19:18:29 | train] - Train Epoch: [150] [64000/1281167 (5%)]	Loss: 0.931405
[2022-04-06 19:18:56 | train] - Train Epoch: [150] [76800/1281167 (6%)]	Loss: 0.570404
[2022-04-06 19:19:25 | train] - Train Epoch: [150] [89600/1281167 (7%)]	Loss: 0.934306
[2022-04-06 19:19:53 | train] - Train Epoch: [150] [102400/1281167 (8%)]	Loss: 0.470147
[2022-04-06 19:20:20 | train] - Train Epoch: [150] [115200/1281167 (9%)]	Loss: 0.699906
[2022-04-06 19:20:48 | train] - Train Epoch: [150] [128000/1281167 (10%)]	Loss: 0.883750
[2022-04-06 19:21:17 | train] - Train Epoch: [150] [140800/1281167 (11%)]	Loss: 0.727004
[2022-04-06 19:21:45 | train] - Train Epoch: [150] [153600/1281167 (12%)]	Loss: 1.034969
[2022-04-06 19:22:14 | train] - Train Epoch: [150] [166400/1281167 (13%)]	Loss: 0.734514
[2022-04-06 19:22:42 | train] - Train Epoch: [150] [179200/1281167 (14%)]	Loss: 0.803147
[2022-04-06 19:23:10 | train] - Train Epoch: [150] [192000/1281167 (15%)]	Loss: 0.812438
[2022-04-06 19:23:37 | train] - Train Epoch: [150] [204800/1281167 (16%)]	Loss: 0.681161
[2022-04-06 19:24:06 | train] - Train Epoch: [150] [217600/1281167 (17%)]	Loss: 0.745514
[2022-04-06 19:24:34 | train] - Train Epoch: [150] [230400/1281167 (18%)]	Loss: 0.825636
[2022-04-06 19:25:03 | train] - Train Epoch: [150] [243200/1281167 (19%)]	Loss: 0.720305
[2022-04-06 19:25:31 | train] - Train Epoch: [150] [256000/1281167 (20%)]	Loss: 0.776955
[2022-04-06 19:25:59 | train] - Train Epoch: [150] [268800/1281167 (21%)]	Loss: 0.653168
[2022-04-06 19:26:28 | train] - Train Epoch: [150] [281600/1281167 (22%)]	Loss: 0.693128
[2022-04-06 19:26:56 | train] - Train Epoch: [150] [294400/1281167 (23%)]	Loss: 0.800262
[2022-04-06 19:27:24 | train] - Train Epoch: [150] [307200/1281167 (24%)]	Loss: 0.827665
[2022-04-06 19:27:53 | train] - Train Epoch: [150] [320000/1281167 (25%)]	Loss: 0.932402
[2022-04-06 19:28:22 | train] - Train Epoch: [150] [332800/1281167 (26%)]	Loss: 0.778726
[2022-04-06 19:28:50 | train] - Train Epoch: [150] [345600/1281167 (27%)]	Loss: 0.732306
[2022-04-06 19:29:19 | train] - Train Epoch: [150] [358400/1281167 (28%)]	Loss: 0.628914
[2022-04-06 19:29:47 | train] - Train Epoch: [150] [371200/1281167 (29%)]	Loss: 0.650009
[2022-04-06 19:30:15 | train] - Train Epoch: [150] [384000/1281167 (30%)]	Loss: 0.774820
[2022-04-06 19:30:43 | train] - Train Epoch: [150] [396800/1281167 (31%)]	Loss: 0.796956
[2022-04-06 19:31:11 | train] - Train Epoch: [150] [409600/1281167 (32%)]	Loss: 0.722913
[2022-04-06 19:31:40 | train] - Train Epoch: [150] [422400/1281167 (33%)]	Loss: 0.662731
[2022-04-06 19:32:07 | train] - Train Epoch: [150] [435200/1281167 (34%)]	Loss: 0.759878
[2022-04-06 19:32:36 | train] - Train Epoch: [150] [448000/1281167 (35%)]	Loss: 0.848698
[2022-04-06 19:33:05 | train] - Train Epoch: [150] [460800/1281167 (36%)]	Loss: 0.594641
[2022-04-06 19:33:34 | train] - Train Epoch: [150] [473600/1281167 (37%)]	Loss: 0.585495
[2022-04-06 19:34:03 | train] - Train Epoch: [150] [486400/1281167 (38%)]	Loss: 0.576379
[2022-04-06 19:34:30 | train] - Train Epoch: [150] [499200/1281167 (39%)]	Loss: 0.450508
[2022-04-06 19:34:59 | train] - Train Epoch: [150] [512000/1281167 (40%)]	Loss: 0.656262
[2022-04-06 19:35:26 | train] - Train Epoch: [150] [524800/1281167 (41%)]	Loss: 0.691352
[2022-04-06 19:35:54 | train] - Train Epoch: [150] [537600/1281167 (42%)]	Loss: 0.848111
[2022-04-06 19:36:23 | train] - Train Epoch: [150] [550400/1281167 (43%)]	Loss: 0.876706
[2022-04-06 19:36:51 | train] - Train Epoch: [150] [563200/1281167 (44%)]	Loss: 0.734846
[2022-04-06 19:37:19 | train] - Train Epoch: [150] [576000/1281167 (45%)]	Loss: 0.717006
[2022-04-06 19:37:47 | train] - Train Epoch: [150] [588800/1281167 (46%)]	Loss: 0.521445
[2022-04-06 19:38:15 | train] - Train Epoch: [150] [601600/1281167 (47%)]	Loss: 0.784568
[2022-04-06 19:38:44 | train] - Train Epoch: [150] [614400/1281167 (48%)]	Loss: 0.615592
[2022-04-06 19:39:12 | train] - Train Epoch: [150] [627200/1281167 (49%)]	Loss: 0.905079
[2022-04-06 19:39:39 | train] - Train Epoch: [150] [640000/1281167 (50%)]	Loss: 0.873258
[2022-04-06 19:40:09 | train] - Train Epoch: [150] [652800/1281167 (51%)]	Loss: 0.604692
[2022-04-06 19:40:37 | train] - Train Epoch: [150] [665600/1281167 (52%)]	Loss: 0.637716
[2022-04-06 19:41:05 | train] - Train Epoch: [150] [678400/1281167 (53%)]	Loss: 1.005019
[2022-04-06 19:41:34 | train] - Train Epoch: [150] [691200/1281167 (54%)]	Loss: 0.645024
[2022-04-06 19:42:03 | train] - Train Epoch: [150] [704000/1281167 (55%)]	Loss: 0.637037
[2022-04-06 19:42:32 | train] - Train Epoch: [150] [716800/1281167 (56%)]	Loss: 0.471413
[2022-04-06 19:42:59 | train] - Train Epoch: [150] [729600/1281167 (57%)]	Loss: 0.729835
[2022-04-06 19:43:28 | train] - Train Epoch: [150] [742400/1281167 (58%)]	Loss: 0.926926
[2022-04-06 19:43:56 | train] - Train Epoch: [150] [755200/1281167 (59%)]	Loss: 0.696316
[2022-04-06 19:44:25 | train] - Train Epoch: [150] [768000/1281167 (60%)]	Loss: 0.524135
[2022-04-06 19:44:53 | train] - Train Epoch: [150] [780800/1281167 (61%)]	Loss: 0.679862
[2022-04-06 19:45:20 | train] - Train Epoch: [150] [793600/1281167 (62%)]	Loss: 0.700081
[2022-04-06 19:45:49 | train] - Train Epoch: [150] [806400/1281167 (63%)]	Loss: 0.848860
[2022-04-06 19:46:17 | train] - Train Epoch: [150] [819200/1281167 (64%)]	Loss: 0.849272
[2022-04-06 19:46:46 | train] - Train Epoch: [150] [832000/1281167 (65%)]	Loss: 0.528790
[2022-04-06 19:47:14 | train] - Train Epoch: [150] [844800/1281167 (66%)]	Loss: 0.451881
[2022-04-06 19:47:43 | train] - Train Epoch: [150] [857600/1281167 (67%)]	Loss: 0.954804
[2022-04-06 19:48:12 | train] - Train Epoch: [150] [870400/1281167 (68%)]	Loss: 0.688866
[2022-04-06 19:48:41 | train] - Train Epoch: [150] [883200/1281167 (69%)]	Loss: 0.707788
[2022-04-06 19:49:09 | train] - Train Epoch: [150] [896000/1281167 (70%)]	Loss: 0.697938
[2022-04-06 19:49:37 | train] - Train Epoch: [150] [908800/1281167 (71%)]	Loss: 0.634094
[2022-04-06 19:50:05 | train] - Train Epoch: [150] [921600/1281167 (72%)]	Loss: 0.638912
[2022-04-06 19:50:34 | train] - Train Epoch: [150] [934400/1281167 (73%)]	Loss: 0.703444
[2022-04-06 19:51:01 | train] - Train Epoch: [150] [947200/1281167 (74%)]	Loss: 0.730970
[2022-04-06 19:51:31 | train] - Train Epoch: [150] [960000/1281167 (75%)]	Loss: 0.735816
[2022-04-06 19:51:59 | train] - Train Epoch: [150] [972800/1281167 (76%)]	Loss: 0.780648
[2022-04-06 19:52:28 | train] - Train Epoch: [150] [985600/1281167 (77%)]	Loss: 0.758606
[2022-04-06 19:52:57 | train] - Train Epoch: [150] [998400/1281167 (78%)]	Loss: 0.728595
[2022-04-06 19:53:25 | train] - Train Epoch: [150] [1011200/1281167 (79%)]	Loss: 0.682604
[2022-04-06 19:53:54 | train] - Train Epoch: [150] [1024000/1281167 (80%)]	Loss: 0.585601
[2022-04-06 19:54:22 | train] - Train Epoch: [150] [1036800/1281167 (81%)]	Loss: 1.127273
[2022-04-06 19:54:50 | train] - Train Epoch: [150] [1049600/1281167 (82%)]	Loss: 0.668919
[2022-04-06 19:55:18 | train] - Train Epoch: [150] [1062400/1281167 (83%)]	Loss: 0.623019
[2022-04-06 19:55:47 | train] - Train Epoch: [150] [1075200/1281167 (84%)]	Loss: 0.615459
[2022-04-06 19:56:15 | train] - Train Epoch: [150] [1088000/1281167 (85%)]	Loss: 0.730184
[2022-04-06 19:56:44 | train] - Train Epoch: [150] [1100800/1281167 (86%)]	Loss: 0.609672
[2022-04-06 19:57:11 | train] - Train Epoch: [150] [1113600/1281167 (87%)]	Loss: 0.521603
[2022-04-06 19:57:41 | train] - Train Epoch: [150] [1126400/1281167 (88%)]	Loss: 1.062520
[2022-04-06 19:58:10 | train] - Train Epoch: [150] [1139200/1281167 (89%)]	Loss: 0.739334
[2022-04-06 19:58:38 | train] - Train Epoch: [150] [1152000/1281167 (90%)]	Loss: 0.699179
[2022-04-06 19:59:07 | train] - Train Epoch: [150] [1164800/1281167 (91%)]	Loss: 0.915967
[2022-04-06 19:59:35 | train] - Train Epoch: [150] [1177600/1281167 (92%)]	Loss: 0.737380
[2022-04-06 20:00:04 | train] - Train Epoch: [150] [1190400/1281167 (93%)]	Loss: 0.697863
[2022-04-06 20:00:31 | train] - Train Epoch: [150] [1203200/1281167 (94%)]	Loss: 0.636133
[2022-04-06 20:00:59 | train] - Train Epoch: [150] [1216000/1281167 (95%)]	Loss: 0.478541
[2022-04-06 20:01:28 | train] - Train Epoch: [150] [1228800/1281167 (96%)]	Loss: 0.762689
[2022-04-06 20:01:56 | train] - Train Epoch: [150] [1241600/1281167 (97%)]	Loss: 0.614015
[2022-04-06 20:02:24 | train] - Train Epoch: [150] [1254400/1281167 (98%)]	Loss: 0.779533
[2022-04-06 20:02:51 | train] - Train Epoch: [150] [1267200/1281167 (99%)]	Loss: 0.896297
[2022-04-06 20:03:20 | train] - Train Epoch: [150] [1280000/1281167 (100%)]	Loss: 0.806107
[2022-04-06 20:03:22 | train] - Train Epoch: [150]	 Average Loss: 0.706207	 Total Acc : 82.8640	 Total Top5 Acc : 93.7865
[2022-04-06 20:03:22 | train] - -------150 epoch end-----------
========================================
-------150 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 20:05:19 | train] - 
Epoch [150] Test set: Average loss: 1.4587, Accuracy: 34921/50000 (69.8182%), Top-5 Accuracy: 88.6861%

[2022-04-06 20:05:19 | train] - save intermediate epoch [150] result


[2022-04-06 20:05:31 | train] - -------151 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 20:05:33 | train] - Train Epoch: [151] [0/1281167 (0%)]	Loss: 0.765020
[2022-04-06 20:06:00 | train] - Train Epoch: [151] [12800/1281167 (1%)]	Loss: 0.795069
[2022-04-06 20:06:27 | train] - Train Epoch: [151] [25600/1281167 (2%)]	Loss: 0.643179
[2022-04-06 20:06:55 | train] - Train Epoch: [151] [38400/1281167 (3%)]	Loss: 0.639124
[2022-04-06 20:07:22 | train] - Train Epoch: [151] [51200/1281167 (4%)]	Loss: 0.620268
[2022-04-06 20:07:50 | train] - Train Epoch: [151] [64000/1281167 (5%)]	Loss: 0.690621
[2022-04-06 20:08:18 | train] - Train Epoch: [151] [76800/1281167 (6%)]	Loss: 0.825627
[2022-04-06 20:08:45 | train] - Train Epoch: [151] [89600/1281167 (7%)]	Loss: 0.646777
[2022-04-06 20:09:13 | train] - Train Epoch: [151] [102400/1281167 (8%)]	Loss: 0.754202
[2022-04-06 20:09:41 | train] - Train Epoch: [151] [115200/1281167 (9%)]	Loss: 0.726525
[2022-04-06 20:10:10 | train] - Train Epoch: [151] [128000/1281167 (10%)]	Loss: 0.658338
[2022-04-06 20:10:37 | train] - Train Epoch: [151] [140800/1281167 (11%)]	Loss: 0.686174
[2022-04-06 20:11:04 | train] - Train Epoch: [151] [153600/1281167 (12%)]	Loss: 0.633058
[2022-04-06 20:11:32 | train] - Train Epoch: [151] [166400/1281167 (13%)]	Loss: 0.590654
[2022-04-06 20:12:00 | train] - Train Epoch: [151] [179200/1281167 (14%)]	Loss: 0.650129
[2022-04-06 20:12:28 | train] - Train Epoch: [151] [192000/1281167 (15%)]	Loss: 0.837733
[2022-04-06 20:12:56 | train] - Train Epoch: [151] [204800/1281167 (16%)]	Loss: 0.824295
[2022-04-06 20:13:25 | train] - Train Epoch: [151] [217600/1281167 (17%)]	Loss: 0.742687
[2022-04-06 20:13:52 | train] - Train Epoch: [151] [230400/1281167 (18%)]	Loss: 0.683329
[2022-04-06 20:14:20 | train] - Train Epoch: [151] [243200/1281167 (19%)]	Loss: 0.494648
[2022-04-06 20:14:49 | train] - Train Epoch: [151] [256000/1281167 (20%)]	Loss: 0.688713
[2022-04-06 20:15:17 | train] - Train Epoch: [151] [268800/1281167 (21%)]	Loss: 0.872447
[2022-04-06 20:15:45 | train] - Train Epoch: [151] [281600/1281167 (22%)]	Loss: 0.740560
[2022-04-06 20:16:12 | train] - Train Epoch: [151] [294400/1281167 (23%)]	Loss: 0.533474
[2022-04-06 20:16:40 | train] - Train Epoch: [151] [307200/1281167 (24%)]	Loss: 0.545679
[2022-04-06 20:17:07 | train] - Train Epoch: [151] [320000/1281167 (25%)]	Loss: 0.902547
[2022-04-06 20:17:34 | train] - Train Epoch: [151] [332800/1281167 (26%)]	Loss: 0.700642
[2022-04-06 20:18:01 | train] - Train Epoch: [151] [345600/1281167 (27%)]	Loss: 0.608104
[2022-04-06 20:18:28 | train] - Train Epoch: [151] [358400/1281167 (28%)]	Loss: 0.650669
[2022-04-06 20:18:57 | train] - Train Epoch: [151] [371200/1281167 (29%)]	Loss: 0.543092
[2022-04-06 20:19:25 | train] - Train Epoch: [151] [384000/1281167 (30%)]	Loss: 0.571208
[2022-04-06 20:19:52 | train] - Train Epoch: [151] [396800/1281167 (31%)]	Loss: 0.739049
[2022-04-06 20:20:19 | train] - Train Epoch: [151] [409600/1281167 (32%)]	Loss: 0.610682
[2022-04-06 20:20:46 | train] - Train Epoch: [151] [422400/1281167 (33%)]	Loss: 0.719412
[2022-04-06 20:21:15 | train] - Train Epoch: [151] [435200/1281167 (34%)]	Loss: 0.978019
[2022-04-06 20:21:42 | train] - Train Epoch: [151] [448000/1281167 (35%)]	Loss: 0.777912
[2022-04-06 20:22:10 | train] - Train Epoch: [151] [460800/1281167 (36%)]	Loss: 0.655999
[2022-04-06 20:22:36 | train] - Train Epoch: [151] [473600/1281167 (37%)]	Loss: 0.566420
[2022-04-06 20:23:03 | train] - Train Epoch: [151] [486400/1281167 (38%)]	Loss: 0.759212
[2022-04-06 20:23:31 | train] - Train Epoch: [151] [499200/1281167 (39%)]	Loss: 0.528561
[2022-04-06 20:23:58 | train] - Train Epoch: [151] [512000/1281167 (40%)]	Loss: 0.773747
[2022-04-06 20:24:25 | train] - Train Epoch: [151] [524800/1281167 (41%)]	Loss: 0.608004
[2022-04-06 20:24:53 | train] - Train Epoch: [151] [537600/1281167 (42%)]	Loss: 0.622389
[2022-04-06 20:25:22 | train] - Train Epoch: [151] [550400/1281167 (43%)]	Loss: 0.907620
[2022-04-06 20:25:49 | train] - Train Epoch: [151] [563200/1281167 (44%)]	Loss: 0.731948
[2022-04-06 20:26:18 | train] - Train Epoch: [151] [576000/1281167 (45%)]	Loss: 0.805543
[2022-04-06 20:26:46 | train] - Train Epoch: [151] [588800/1281167 (46%)]	Loss: 0.466887
[2022-04-06 20:27:15 | train] - Train Epoch: [151] [601600/1281167 (47%)]	Loss: 0.548984
[2022-04-06 20:27:42 | train] - Train Epoch: [151] [614400/1281167 (48%)]	Loss: 0.509960
[2022-04-06 20:28:11 | train] - Train Epoch: [151] [627200/1281167 (49%)]	Loss: 0.721668
[2022-04-06 20:28:40 | train] - Train Epoch: [151] [640000/1281167 (50%)]	Loss: 0.740174
[2022-04-06 20:29:09 | train] - Train Epoch: [151] [652800/1281167 (51%)]	Loss: 0.516914
[2022-04-06 20:29:36 | train] - Train Epoch: [151] [665600/1281167 (52%)]	Loss: 0.555010
[2022-04-06 20:30:04 | train] - Train Epoch: [151] [678400/1281167 (53%)]	Loss: 0.680350
[2022-04-06 20:30:32 | train] - Train Epoch: [151] [691200/1281167 (54%)]	Loss: 0.691487
[2022-04-06 20:31:00 | train] - Train Epoch: [151] [704000/1281167 (55%)]	Loss: 0.730215
[2022-04-06 20:31:27 | train] - Train Epoch: [151] [716800/1281167 (56%)]	Loss: 0.898325
[2022-04-06 20:31:55 | train] - Train Epoch: [151] [729600/1281167 (57%)]	Loss: 0.787795
[2022-04-06 20:32:23 | train] - Train Epoch: [151] [742400/1281167 (58%)]	Loss: 0.750705
[2022-04-06 20:32:50 | train] - Train Epoch: [151] [755200/1281167 (59%)]	Loss: 0.720108
[2022-04-06 20:33:18 | train] - Train Epoch: [151] [768000/1281167 (60%)]	Loss: 0.848967
[2022-04-06 20:33:46 | train] - Train Epoch: [151] [780800/1281167 (61%)]	Loss: 0.731824
[2022-04-06 20:34:13 | train] - Train Epoch: [151] [793600/1281167 (62%)]	Loss: 0.755066
[2022-04-06 20:34:42 | train] - Train Epoch: [151] [806400/1281167 (63%)]	Loss: 0.930829
[2022-04-06 20:35:10 | train] - Train Epoch: [151] [819200/1281167 (64%)]	Loss: 0.611580
[2022-04-06 20:35:37 | train] - Train Epoch: [151] [832000/1281167 (65%)]	Loss: 1.112448
[2022-04-06 20:36:05 | train] - Train Epoch: [151] [844800/1281167 (66%)]	Loss: 0.680182
[2022-04-06 20:36:34 | train] - Train Epoch: [151] [857600/1281167 (67%)]	Loss: 0.898447
[2022-04-06 20:37:01 | train] - Train Epoch: [151] [870400/1281167 (68%)]	Loss: 0.785782
[2022-04-06 20:37:29 | train] - Train Epoch: [151] [883200/1281167 (69%)]	Loss: 0.685706
[2022-04-06 20:37:58 | train] - Train Epoch: [151] [896000/1281167 (70%)]	Loss: 0.716494
[2022-04-06 20:38:25 | train] - Train Epoch: [151] [908800/1281167 (71%)]	Loss: 1.129821
[2022-04-06 20:38:53 | train] - Train Epoch: [151] [921600/1281167 (72%)]	Loss: 0.581951
[2022-04-06 20:39:22 | train] - Train Epoch: [151] [934400/1281167 (73%)]	Loss: 0.796153
[2022-04-06 20:39:51 | train] - Train Epoch: [151] [947200/1281167 (74%)]	Loss: 0.741375
[2022-04-06 20:40:18 | train] - Train Epoch: [151] [960000/1281167 (75%)]	Loss: 0.726489
[2022-04-06 20:40:46 | train] - Train Epoch: [151] [972800/1281167 (76%)]	Loss: 0.535024
[2022-04-06 20:41:14 | train] - Train Epoch: [151] [985600/1281167 (77%)]	Loss: 0.603473
[2022-04-06 20:41:42 | train] - Train Epoch: [151] [998400/1281167 (78%)]	Loss: 0.992303
[2022-04-06 20:42:11 | train] - Train Epoch: [151] [1011200/1281167 (79%)]	Loss: 0.613599
[2022-04-06 20:42:38 | train] - Train Epoch: [151] [1024000/1281167 (80%)]	Loss: 0.852125
[2022-04-06 20:43:06 | train] - Train Epoch: [151] [1036800/1281167 (81%)]	Loss: 0.630191
[2022-04-06 20:43:34 | train] - Train Epoch: [151] [1049600/1281167 (82%)]	Loss: 0.601656
[2022-04-06 20:44:01 | train] - Train Epoch: [151] [1062400/1281167 (83%)]	Loss: 0.678133
[2022-04-06 20:44:29 | train] - Train Epoch: [151] [1075200/1281167 (84%)]	Loss: 0.695912
[2022-04-06 20:44:57 | train] - Train Epoch: [151] [1088000/1281167 (85%)]	Loss: 0.624483
[2022-04-06 20:45:24 | train] - Train Epoch: [151] [1100800/1281167 (86%)]	Loss: 0.528768
[2022-04-06 20:45:51 | train] - Train Epoch: [151] [1113600/1281167 (87%)]	Loss: 0.801154
[2022-04-06 20:46:19 | train] - Train Epoch: [151] [1126400/1281167 (88%)]	Loss: 0.632147
[2022-04-06 20:46:46 | train] - Train Epoch: [151] [1139200/1281167 (89%)]	Loss: 0.780111
[2022-04-06 20:47:14 | train] - Train Epoch: [151] [1152000/1281167 (90%)]	Loss: 0.793561
[2022-04-06 20:47:42 | train] - Train Epoch: [151] [1164800/1281167 (91%)]	Loss: 0.817276
[2022-04-06 20:48:11 | train] - Train Epoch: [151] [1177600/1281167 (92%)]	Loss: 0.764958
[2022-04-06 20:48:39 | train] - Train Epoch: [151] [1190400/1281167 (93%)]	Loss: 0.806386
[2022-04-06 20:49:07 | train] - Train Epoch: [151] [1203200/1281167 (94%)]	Loss: 0.910299
[2022-04-06 20:49:36 | train] - Train Epoch: [151] [1216000/1281167 (95%)]	Loss: 0.609259
[2022-04-06 20:50:04 | train] - Train Epoch: [151] [1228800/1281167 (96%)]	Loss: 0.803304
[2022-04-06 20:50:33 | train] - Train Epoch: [151] [1241600/1281167 (97%)]	Loss: 0.628553
[2022-04-06 20:51:01 | train] - Train Epoch: [151] [1254400/1281167 (98%)]	Loss: 0.617121
[2022-04-06 20:51:30 | train] - Train Epoch: [151] [1267200/1281167 (99%)]	Loss: 0.790981
[2022-04-06 20:51:58 | train] - Train Epoch: [151] [1280000/1281167 (100%)]	Loss: 0.663878
[2022-04-06 20:52:00 | train] - Train Epoch: [151]	 Average Loss: 0.701708	 Total Acc : 82.9946	 Total Top5 Acc : 93.8279
[2022-04-06 20:52:00 | train] - -------151 epoch end-----------
========================================
-------151 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 20:53:56 | train] - 
Epoch [151] Test set: Average loss: 1.4538, Accuracy: 34896/50000 (69.7646%), Top-5 Accuracy: 88.7300%

[2022-04-06 20:53:56 | train] - save intermediate epoch [151] result


[2022-04-06 20:54:10 | train] - -------152 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 20:54:11 | train] - Train Epoch: [152] [0/1281167 (0%)]	Loss: 0.715700
[2022-04-06 20:54:40 | train] - Train Epoch: [152] [12800/1281167 (1%)]	Loss: 0.756823
[2022-04-06 20:55:07 | train] - Train Epoch: [152] [25600/1281167 (2%)]	Loss: 0.741155
[2022-04-06 20:55:34 | train] - Train Epoch: [152] [38400/1281167 (3%)]	Loss: 0.770714
[2022-04-06 20:56:01 | train] - Train Epoch: [152] [51200/1281167 (4%)]	Loss: 0.846849
[2022-04-06 20:56:29 | train] - Train Epoch: [152] [64000/1281167 (5%)]	Loss: 0.901009
[2022-04-06 20:56:57 | train] - Train Epoch: [152] [76800/1281167 (6%)]	Loss: 0.861759
[2022-04-06 20:57:25 | train] - Train Epoch: [152] [89600/1281167 (7%)]	Loss: 0.721627
[2022-04-06 20:57:53 | train] - Train Epoch: [152] [102400/1281167 (8%)]	Loss: 0.509632
[2022-04-06 20:58:20 | train] - Train Epoch: [152] [115200/1281167 (9%)]	Loss: 0.609188
[2022-04-06 20:58:47 | train] - Train Epoch: [152] [128000/1281167 (10%)]	Loss: 0.682849
[2022-04-06 20:59:15 | train] - Train Epoch: [152] [140800/1281167 (11%)]	Loss: 0.685202
[2022-04-06 20:59:42 | train] - Train Epoch: [152] [153600/1281167 (12%)]	Loss: 0.702420
[2022-04-06 21:00:10 | train] - Train Epoch: [152] [166400/1281167 (13%)]	Loss: 0.860600
[2022-04-06 21:00:37 | train] - Train Epoch: [152] [179200/1281167 (14%)]	Loss: 0.459362
[2022-04-06 21:01:06 | train] - Train Epoch: [152] [192000/1281167 (15%)]	Loss: 0.721081
[2022-04-06 21:01:35 | train] - Train Epoch: [152] [204800/1281167 (16%)]	Loss: 0.575494
[2022-04-06 21:02:02 | train] - Train Epoch: [152] [217600/1281167 (17%)]	Loss: 0.660235
[2022-04-06 21:02:30 | train] - Train Epoch: [152] [230400/1281167 (18%)]	Loss: 0.928495
[2022-04-06 21:02:56 | train] - Train Epoch: [152] [243200/1281167 (19%)]	Loss: 0.648813
[2022-04-06 21:03:24 | train] - Train Epoch: [152] [256000/1281167 (20%)]	Loss: 0.594597
[2022-04-06 21:03:51 | train] - Train Epoch: [152] [268800/1281167 (21%)]	Loss: 0.622247
[2022-04-06 21:04:18 | train] - Train Epoch: [152] [281600/1281167 (22%)]	Loss: 0.974467
[2022-04-06 21:04:44 | train] - Train Epoch: [152] [294400/1281167 (23%)]	Loss: 0.765276
[2022-04-06 21:05:12 | train] - Train Epoch: [152] [307200/1281167 (24%)]	Loss: 0.846201
[2022-04-06 21:05:39 | train] - Train Epoch: [152] [320000/1281167 (25%)]	Loss: 0.720143
[2022-04-06 21:06:06 | train] - Train Epoch: [152] [332800/1281167 (26%)]	Loss: 0.756690
[2022-04-06 21:06:34 | train] - Train Epoch: [152] [345600/1281167 (27%)]	Loss: 0.691968
[2022-04-06 21:07:01 | train] - Train Epoch: [152] [358400/1281167 (28%)]	Loss: 0.582460
[2022-04-06 21:07:29 | train] - Train Epoch: [152] [371200/1281167 (29%)]	Loss: 0.967676
[2022-04-06 21:07:56 | train] - Train Epoch: [152] [384000/1281167 (30%)]	Loss: 0.603650
[2022-04-06 21:08:25 | train] - Train Epoch: [152] [396800/1281167 (31%)]	Loss: 0.533283
[2022-04-06 21:08:52 | train] - Train Epoch: [152] [409600/1281167 (32%)]	Loss: 0.567796
[2022-04-06 21:09:19 | train] - Train Epoch: [152] [422400/1281167 (33%)]	Loss: 0.420955
[2022-04-06 21:09:46 | train] - Train Epoch: [152] [435200/1281167 (34%)]	Loss: 0.543380
[2022-04-06 21:10:13 | train] - Train Epoch: [152] [448000/1281167 (35%)]	Loss: 0.707478
[2022-04-06 21:10:40 | train] - Train Epoch: [152] [460800/1281167 (36%)]	Loss: 0.520422
[2022-04-06 21:11:08 | train] - Train Epoch: [152] [473600/1281167 (37%)]	Loss: 0.654383
[2022-04-06 21:11:36 | train] - Train Epoch: [152] [486400/1281167 (38%)]	Loss: 0.616135
[2022-04-06 21:12:04 | train] - Train Epoch: [152] [499200/1281167 (39%)]	Loss: 0.717962
[2022-04-06 21:12:32 | train] - Train Epoch: [152] [512000/1281167 (40%)]	Loss: 0.669325
[2022-04-06 21:12:59 | train] - Train Epoch: [152] [524800/1281167 (41%)]	Loss: 0.937411
[2022-04-06 21:13:28 | train] - Train Epoch: [152] [537600/1281167 (42%)]	Loss: 0.877959
[2022-04-06 21:13:56 | train] - Train Epoch: [152] [550400/1281167 (43%)]	Loss: 0.891428
[2022-04-06 21:14:23 | train] - Train Epoch: [152] [563200/1281167 (44%)]	Loss: 0.805772
[2022-04-06 21:14:52 | train] - Train Epoch: [152] [576000/1281167 (45%)]	Loss: 0.779619
[2022-04-06 21:15:20 | train] - Train Epoch: [152] [588800/1281167 (46%)]	Loss: 0.559455
[2022-04-06 21:15:47 | train] - Train Epoch: [152] [601600/1281167 (47%)]	Loss: 0.792001
[2022-04-06 21:16:15 | train] - Train Epoch: [152] [614400/1281167 (48%)]	Loss: 0.597842
[2022-04-06 21:16:42 | train] - Train Epoch: [152] [627200/1281167 (49%)]	Loss: 0.760112
[2022-04-06 21:17:10 | train] - Train Epoch: [152] [640000/1281167 (50%)]	Loss: 0.579591
[2022-04-06 21:17:38 | train] - Train Epoch: [152] [652800/1281167 (51%)]	Loss: 0.941979
[2022-04-06 21:18:05 | train] - Train Epoch: [152] [665600/1281167 (52%)]	Loss: 0.645997
[2022-04-06 21:18:33 | train] - Train Epoch: [152] [678400/1281167 (53%)]	Loss: 0.619923
[2022-04-06 21:19:00 | train] - Train Epoch: [152] [691200/1281167 (54%)]	Loss: 0.715144
[2022-04-06 21:19:28 | train] - Train Epoch: [152] [704000/1281167 (55%)]	Loss: 0.517636
[2022-04-06 21:19:56 | train] - Train Epoch: [152] [716800/1281167 (56%)]	Loss: 0.481518
[2022-04-06 21:20:24 | train] - Train Epoch: [152] [729600/1281167 (57%)]	Loss: 0.631395
[2022-04-06 21:20:51 | train] - Train Epoch: [152] [742400/1281167 (58%)]	Loss: 0.644316
[2022-04-06 21:21:19 | train] - Train Epoch: [152] [755200/1281167 (59%)]	Loss: 0.562274
[2022-04-06 21:21:47 | train] - Train Epoch: [152] [768000/1281167 (60%)]	Loss: 0.567109
[2022-04-06 21:22:15 | train] - Train Epoch: [152] [780800/1281167 (61%)]	Loss: 0.766228
[2022-04-06 21:22:44 | train] - Train Epoch: [152] [793600/1281167 (62%)]	Loss: 0.847699
[2022-04-06 21:23:13 | train] - Train Epoch: [152] [806400/1281167 (63%)]	Loss: 0.730038
[2022-04-06 21:23:42 | train] - Train Epoch: [152] [819200/1281167 (64%)]	Loss: 0.757033
[2022-04-06 21:24:10 | train] - Train Epoch: [152] [832000/1281167 (65%)]	Loss: 0.726039
[2022-04-06 21:24:37 | train] - Train Epoch: [152] [844800/1281167 (66%)]	Loss: 0.632136
[2022-04-06 21:25:05 | train] - Train Epoch: [152] [857600/1281167 (67%)]	Loss: 0.645828
[2022-04-06 21:25:32 | train] - Train Epoch: [152] [870400/1281167 (68%)]	Loss: 0.736776
[2022-04-06 21:25:59 | train] - Train Epoch: [152] [883200/1281167 (69%)]	Loss: 0.688562
[2022-04-06 21:26:27 | train] - Train Epoch: [152] [896000/1281167 (70%)]	Loss: 0.685463
[2022-04-06 21:26:54 | train] - Train Epoch: [152] [908800/1281167 (71%)]	Loss: 0.723570
[2022-04-06 21:27:23 | train] - Train Epoch: [152] [921600/1281167 (72%)]	Loss: 0.654807
[2022-04-06 21:27:52 | train] - Train Epoch: [152] [934400/1281167 (73%)]	Loss: 0.709713
[2022-04-06 21:28:19 | train] - Train Epoch: [152] [947200/1281167 (74%)]	Loss: 0.656889
[2022-04-06 21:28:47 | train] - Train Epoch: [152] [960000/1281167 (75%)]	Loss: 0.772061
[2022-04-06 21:29:15 | train] - Train Epoch: [152] [972800/1281167 (76%)]	Loss: 0.758304
[2022-04-06 21:29:43 | train] - Train Epoch: [152] [985600/1281167 (77%)]	Loss: 0.525359
[2022-04-06 21:30:11 | train] - Train Epoch: [152] [998400/1281167 (78%)]	Loss: 0.894678
[2022-04-06 21:30:38 | train] - Train Epoch: [152] [1011200/1281167 (79%)]	Loss: 0.802935
[2022-04-06 21:31:05 | train] - Train Epoch: [152] [1024000/1281167 (80%)]	Loss: 0.867378
[2022-04-06 21:31:33 | train] - Train Epoch: [152] [1036800/1281167 (81%)]	Loss: 1.002477
[2022-04-06 21:32:01 | train] - Train Epoch: [152] [1049600/1281167 (82%)]	Loss: 0.518928
[2022-04-06 21:32:28 | train] - Train Epoch: [152] [1062400/1281167 (83%)]	Loss: 0.897188
[2022-04-06 21:32:56 | train] - Train Epoch: [152] [1075200/1281167 (84%)]	Loss: 0.838631
[2022-04-06 21:33:23 | train] - Train Epoch: [152] [1088000/1281167 (85%)]	Loss: 0.638072
[2022-04-06 21:33:50 | train] - Train Epoch: [152] [1100800/1281167 (86%)]	Loss: 0.848499
[2022-04-06 21:34:18 | train] - Train Epoch: [152] [1113600/1281167 (87%)]	Loss: 0.747299
[2022-04-06 21:34:46 | train] - Train Epoch: [152] [1126400/1281167 (88%)]	Loss: 0.845526
[2022-04-06 21:35:14 | train] - Train Epoch: [152] [1139200/1281167 (89%)]	Loss: 0.564419
[2022-04-06 21:35:43 | train] - Train Epoch: [152] [1152000/1281167 (90%)]	Loss: 0.622217
[2022-04-06 21:36:12 | train] - Train Epoch: [152] [1164800/1281167 (91%)]	Loss: 0.732838
[2022-04-06 21:36:39 | train] - Train Epoch: [152] [1177600/1281167 (92%)]	Loss: 0.970224
[2022-04-06 21:37:08 | train] - Train Epoch: [152] [1190400/1281167 (93%)]	Loss: 0.470219
[2022-04-06 21:37:37 | train] - Train Epoch: [152] [1203200/1281167 (94%)]	Loss: 0.581915
[2022-04-06 21:38:05 | train] - Train Epoch: [152] [1216000/1281167 (95%)]	Loss: 0.432843
[2022-04-06 21:38:33 | train] - Train Epoch: [152] [1228800/1281167 (96%)]	Loss: 0.930239
[2022-04-06 21:39:01 | train] - Train Epoch: [152] [1241600/1281167 (97%)]	Loss: 0.640974
[2022-04-06 21:39:30 | train] - Train Epoch: [152] [1254400/1281167 (98%)]	Loss: 0.869861
[2022-04-06 21:39:58 | train] - Train Epoch: [152] [1267200/1281167 (99%)]	Loss: 0.692893
[2022-04-06 21:40:26 | train] - Train Epoch: [152] [1280000/1281167 (100%)]	Loss: 0.862754
[2022-04-06 21:40:28 | train] - Train Epoch: [152]	 Average Loss: 0.699883	 Total Acc : 83.0062	 Total Top5 Acc : 93.8449
[2022-04-06 21:40:28 | train] - -------152 epoch end-----------
========================================
-------152 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 21:42:24 | train] - 
Epoch [152] Test set: Average loss: 1.4506, Accuracy: 34937/50000 (69.8477%), Top-5 Accuracy: 88.6541%

[2022-04-06 21:42:24 | train] - save intermediate epoch [152] result


[2022-04-06 21:42:38 | train] - -------153 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 21:42:40 | train] - Train Epoch: [153] [0/1281167 (0%)]	Loss: 0.534362
[I 21:42:40.903 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:1b34e09ecc8543839a93f036ed39a0a1
[2022-04-06 21:43:07 | train] - Train Epoch: [153] [12800/1281167 (1%)]	Loss: 0.537117
[2022-04-06 21:43:34 | train] - Train Epoch: [153] [25600/1281167 (2%)]	Loss: 0.656526
[2022-04-06 21:44:02 | train] - Train Epoch: [153] [38400/1281167 (3%)]	Loss: 0.560358
[2022-04-06 21:44:29 | train] - Train Epoch: [153] [51200/1281167 (4%)]	Loss: 0.613554
[2022-04-06 21:44:56 | train] - Train Epoch: [153] [64000/1281167 (5%)]	Loss: 0.630424
[2022-04-06 21:45:23 | train] - Train Epoch: [153] [76800/1281167 (6%)]	Loss: 0.654511
[2022-04-06 21:45:49 | train] - Train Epoch: [153] [89600/1281167 (7%)]	Loss: 0.617581
[2022-04-06 21:46:16 | train] - Train Epoch: [153] [102400/1281167 (8%)]	Loss: 0.810543
[2022-04-06 21:46:43 | train] - Train Epoch: [153] [115200/1281167 (9%)]	Loss: 0.714820
[2022-04-06 21:47:10 | train] - Train Epoch: [153] [128000/1281167 (10%)]	Loss: 0.987496
[2022-04-06 21:47:37 | train] - Train Epoch: [153] [140800/1281167 (11%)]	Loss: 0.697259
[2022-04-06 21:48:03 | train] - Train Epoch: [153] [153600/1281167 (12%)]	Loss: 0.656708
[2022-04-06 21:48:31 | train] - Train Epoch: [153] [166400/1281167 (13%)]	Loss: 0.645227
[2022-04-06 21:48:58 | train] - Train Epoch: [153] [179200/1281167 (14%)]	Loss: 0.674913
[2022-04-06 21:49:25 | train] - Train Epoch: [153] [192000/1281167 (15%)]	Loss: 0.521901
[2022-04-06 21:49:52 | train] - Train Epoch: [153] [204800/1281167 (16%)]	Loss: 0.805336
[2022-04-06 21:50:19 | train] - Train Epoch: [153] [217600/1281167 (17%)]	Loss: 0.670002
[2022-04-06 21:50:47 | train] - Train Epoch: [153] [230400/1281167 (18%)]	Loss: 0.713049
[2022-04-06 21:51:14 | train] - Train Epoch: [153] [243200/1281167 (19%)]	Loss: 0.819580
[2022-04-06 21:51:42 | train] - Train Epoch: [153] [256000/1281167 (20%)]	Loss: 0.697901
[2022-04-06 21:52:10 | train] - Train Epoch: [153] [268800/1281167 (21%)]	Loss: 0.520052
[2022-04-06 21:52:37 | train] - Train Epoch: [153] [281600/1281167 (22%)]	Loss: 0.513567
[2022-04-06 21:53:06 | train] - Train Epoch: [153] [294400/1281167 (23%)]	Loss: 0.786333
[2022-04-06 21:53:33 | train] - Train Epoch: [153] [307200/1281167 (24%)]	Loss: 0.635755
[2022-04-06 21:54:00 | train] - Train Epoch: [153] [320000/1281167 (25%)]	Loss: 0.675701
[2022-04-06 21:54:27 | train] - Train Epoch: [153] [332800/1281167 (26%)]	Loss: 0.713325
[2022-04-06 21:54:54 | train] - Train Epoch: [153] [345600/1281167 (27%)]	Loss: 0.636675
[2022-04-06 21:55:21 | train] - Train Epoch: [153] [358400/1281167 (28%)]	Loss: 0.713676
[2022-04-06 21:55:48 | train] - Train Epoch: [153] [371200/1281167 (29%)]	Loss: 0.698276
[2022-04-06 21:56:15 | train] - Train Epoch: [153] [384000/1281167 (30%)]	Loss: 0.736142
[2022-04-06 21:56:42 | train] - Train Epoch: [153] [396800/1281167 (31%)]	Loss: 0.744377
[2022-04-06 21:57:10 | train] - Train Epoch: [153] [409600/1281167 (32%)]	Loss: 0.584281
[2022-04-06 21:57:38 | train] - Train Epoch: [153] [422400/1281167 (33%)]	Loss: 0.564985
[2022-04-06 21:58:06 | train] - Train Epoch: [153] [435200/1281167 (34%)]	Loss: 0.628776
[2022-04-06 21:58:34 | train] - Train Epoch: [153] [448000/1281167 (35%)]	Loss: 0.635152
[2022-04-06 21:59:01 | train] - Train Epoch: [153] [460800/1281167 (36%)]	Loss: 0.696818
[2022-04-06 21:59:29 | train] - Train Epoch: [153] [473600/1281167 (37%)]	Loss: 0.915941
[2022-04-06 21:59:58 | train] - Train Epoch: [153] [486400/1281167 (38%)]	Loss: 0.931424
[2022-04-06 22:00:26 | train] - Train Epoch: [153] [499200/1281167 (39%)]	Loss: 0.776478
[2022-04-06 22:00:53 | train] - Train Epoch: [153] [512000/1281167 (40%)]	Loss: 0.753182
[2022-04-06 22:01:22 | train] - Train Epoch: [153] [524800/1281167 (41%)]	Loss: 0.555699
[2022-04-06 22:01:49 | train] - Train Epoch: [153] [537600/1281167 (42%)]	Loss: 0.844785
[2022-04-06 22:02:16 | train] - Train Epoch: [153] [550400/1281167 (43%)]	Loss: 0.715362
[2022-04-06 22:02:43 | train] - Train Epoch: [153] [563200/1281167 (44%)]	Loss: 0.708674
[2022-04-06 22:03:11 | train] - Train Epoch: [153] [576000/1281167 (45%)]	Loss: 0.541635
[2022-04-06 22:03:38 | train] - Train Epoch: [153] [588800/1281167 (46%)]	Loss: 0.857786
[2022-04-06 22:04:06 | train] - Train Epoch: [153] [601600/1281167 (47%)]	Loss: 0.622259
[2022-04-06 22:04:32 | train] - Train Epoch: [153] [614400/1281167 (48%)]	Loss: 0.629180
[2022-04-06 22:04:59 | train] - Train Epoch: [153] [627200/1281167 (49%)]	Loss: 0.751218
[2022-04-06 22:05:27 | train] - Train Epoch: [153] [640000/1281167 (50%)]	Loss: 0.545625
[2022-04-06 22:05:54 | train] - Train Epoch: [153] [652800/1281167 (51%)]	Loss: 0.456823
[2022-04-06 22:06:21 | train] - Train Epoch: [153] [665600/1281167 (52%)]	Loss: 0.783979
[2022-04-06 22:06:48 | train] - Train Epoch: [153] [678400/1281167 (53%)]	Loss: 0.717143
[2022-04-06 22:07:16 | train] - Train Epoch: [153] [691200/1281167 (54%)]	Loss: 0.451967
[2022-04-06 22:07:43 | train] - Train Epoch: [153] [704000/1281167 (55%)]	Loss: 0.598600
[2022-04-06 22:08:10 | train] - Train Epoch: [153] [716800/1281167 (56%)]	Loss: 0.787251
[2022-04-06 22:08:38 | train] - Train Epoch: [153] [729600/1281167 (57%)]	Loss: 0.668578
[2022-04-06 22:09:05 | train] - Train Epoch: [153] [742400/1281167 (58%)]	Loss: 0.686599
[2022-04-06 22:09:31 | train] - Train Epoch: [153] [755200/1281167 (59%)]	Loss: 0.743350
[2022-04-06 22:09:59 | train] - Train Epoch: [153] [768000/1281167 (60%)]	Loss: 0.823238
[2022-04-06 22:10:26 | train] - Train Epoch: [153] [780800/1281167 (61%)]	Loss: 0.732670
[2022-04-06 22:10:53 | train] - Train Epoch: [153] [793600/1281167 (62%)]	Loss: 0.682084
[2022-04-06 22:11:20 | train] - Train Epoch: [153] [806400/1281167 (63%)]	Loss: 0.855011
[2022-04-06 22:11:48 | train] - Train Epoch: [153] [819200/1281167 (64%)]	Loss: 0.602757
[2022-04-06 22:12:15 | train] - Train Epoch: [153] [832000/1281167 (65%)]	Loss: 0.813604
[2022-04-06 22:12:43 | train] - Train Epoch: [153] [844800/1281167 (66%)]	Loss: 0.646590
[2022-04-06 22:13:11 | train] - Train Epoch: [153] [857600/1281167 (67%)]	Loss: 0.802734
[2022-04-06 22:13:39 | train] - Train Epoch: [153] [870400/1281167 (68%)]	Loss: 0.543634
[2022-04-06 22:14:08 | train] - Train Epoch: [153] [883200/1281167 (69%)]	Loss: 0.810706
[2022-04-06 22:14:35 | train] - Train Epoch: [153] [896000/1281167 (70%)]	Loss: 0.574073
[2022-04-06 22:15:03 | train] - Train Epoch: [153] [908800/1281167 (71%)]	Loss: 0.495415
[2022-04-06 22:15:30 | train] - Train Epoch: [153] [921600/1281167 (72%)]	Loss: 0.657443
[2022-04-06 22:15:59 | train] - Train Epoch: [153] [934400/1281167 (73%)]	Loss: 0.622526
[2022-04-06 22:16:27 | train] - Train Epoch: [153] [947200/1281167 (74%)]	Loss: 0.564916
[2022-04-06 22:16:54 | train] - Train Epoch: [153] [960000/1281167 (75%)]	Loss: 0.831908
[2022-04-06 22:17:22 | train] - Train Epoch: [153] [972800/1281167 (76%)]	Loss: 0.794020
[2022-04-06 22:17:50 | train] - Train Epoch: [153] [985600/1281167 (77%)]	Loss: 0.960620
[2022-04-06 22:18:17 | train] - Train Epoch: [153] [998400/1281167 (78%)]	Loss: 0.805215
[2022-04-06 22:18:44 | train] - Train Epoch: [153] [1011200/1281167 (79%)]	Loss: 0.955146
[2022-04-06 22:19:12 | train] - Train Epoch: [153] [1024000/1281167 (80%)]	Loss: 0.817356
[2022-04-06 22:19:39 | train] - Train Epoch: [153] [1036800/1281167 (81%)]	Loss: 0.743025
[2022-04-06 22:20:06 | train] - Train Epoch: [153] [1049600/1281167 (82%)]	Loss: 0.627507
[2022-04-06 22:20:33 | train] - Train Epoch: [153] [1062400/1281167 (83%)]	Loss: 0.669369
[2022-04-06 22:21:01 | train] - Train Epoch: [153] [1075200/1281167 (84%)]	Loss: 0.638240
[2022-04-06 22:21:29 | train] - Train Epoch: [153] [1088000/1281167 (85%)]	Loss: 0.681933
[2022-04-06 22:21:57 | train] - Train Epoch: [153] [1100800/1281167 (86%)]	Loss: 0.540815
[2022-04-06 22:22:25 | train] - Train Epoch: [153] [1113600/1281167 (87%)]	Loss: 0.786078
[2022-04-06 22:22:53 | train] - Train Epoch: [153] [1126400/1281167 (88%)]	Loss: 0.666792
[2022-04-06 22:23:21 | train] - Train Epoch: [153] [1139200/1281167 (89%)]	Loss: 0.836871
[2022-04-06 22:23:50 | train] - Train Epoch: [153] [1152000/1281167 (90%)]	Loss: 0.677247
[2022-04-06 22:24:17 | train] - Train Epoch: [153] [1164800/1281167 (91%)]	Loss: 0.581120
[2022-04-06 22:24:46 | train] - Train Epoch: [153] [1177600/1281167 (92%)]	Loss: 0.624922
[2022-04-06 22:25:14 | train] - Train Epoch: [153] [1190400/1281167 (93%)]	Loss: 0.673363
[2022-04-06 22:25:42 | train] - Train Epoch: [153] [1203200/1281167 (94%)]	Loss: 0.624978
[2022-04-06 22:26:10 | train] - Train Epoch: [153] [1216000/1281167 (95%)]	Loss: 0.536737
[2022-04-06 22:26:38 | train] - Train Epoch: [153] [1228800/1281167 (96%)]	Loss: 0.447400
[2022-04-06 22:27:07 | train] - Train Epoch: [153] [1241600/1281167 (97%)]	Loss: 0.570912
[2022-04-06 22:27:35 | train] - Train Epoch: [153] [1254400/1281167 (98%)]	Loss: 0.513297
[2022-04-06 22:28:03 | train] - Train Epoch: [153] [1267200/1281167 (99%)]	Loss: 0.620910
[2022-04-06 22:28:31 | train] - Train Epoch: [153] [1280000/1281167 (100%)]	Loss: 0.507635
[2022-04-06 22:28:33 | train] - Train Epoch: [153]	 Average Loss: 0.695524	 Total Acc : 83.1156	 Total Top5 Acc : 93.9064
[2022-04-06 22:28:33 | train] - -------153 epoch end-----------
========================================
-------153 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 22:30:25 | train] - 
Epoch [153] Test set: Average loss: 1.4479, Accuracy: 34950/50000 (69.8761%), Top-5 Accuracy: 88.8319%

[2022-04-06 22:30:25 | train] - save intermediate epoch [153] result


[2022-04-06 22:30:38 | train] - -------154 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 22:30:39 | train] - Train Epoch: [154] [0/1281167 (0%)]	Loss: 0.700775
[2022-04-06 22:31:07 | train] - Train Epoch: [154] [12800/1281167 (1%)]	Loss: 0.685492
[2022-04-06 22:31:33 | train] - Train Epoch: [154] [25600/1281167 (2%)]	Loss: 0.497217
[2022-04-06 22:31:59 | train] - Train Epoch: [154] [38400/1281167 (3%)]	Loss: 0.720994
[2022-04-06 22:32:26 | train] - Train Epoch: [154] [51200/1281167 (4%)]	Loss: 0.356186
[2022-04-06 22:32:53 | train] - Train Epoch: [154] [64000/1281167 (5%)]	Loss: 0.621953
[2022-04-06 22:33:20 | train] - Train Epoch: [154] [76800/1281167 (6%)]	Loss: 0.804920
[2022-04-06 22:33:46 | train] - Train Epoch: [154] [89600/1281167 (7%)]	Loss: 0.607774
[2022-04-06 22:34:13 | train] - Train Epoch: [154] [102400/1281167 (8%)]	Loss: 0.644678
[2022-04-06 22:34:41 | train] - Train Epoch: [154] [115200/1281167 (9%)]	Loss: 0.439450
[2022-04-06 22:35:08 | train] - Train Epoch: [154] [128000/1281167 (10%)]	Loss: 0.564363
[2022-04-06 22:35:35 | train] - Train Epoch: [154] [140800/1281167 (11%)]	Loss: 0.730014
[2022-04-06 22:36:02 | train] - Train Epoch: [154] [153600/1281167 (12%)]	Loss: 0.718758
[2022-04-06 22:36:29 | train] - Train Epoch: [154] [166400/1281167 (13%)]	Loss: 0.675905
[2022-04-06 22:36:56 | train] - Train Epoch: [154] [179200/1281167 (14%)]	Loss: 0.773091
[2022-04-06 22:37:23 | train] - Train Epoch: [154] [192000/1281167 (15%)]	Loss: 0.649056
[2022-04-06 22:37:50 | train] - Train Epoch: [154] [204800/1281167 (16%)]	Loss: 0.808097
[2022-04-06 22:38:19 | train] - Train Epoch: [154] [217600/1281167 (17%)]	Loss: 0.850714
[2022-04-06 22:38:46 | train] - Train Epoch: [154] [230400/1281167 (18%)]	Loss: 0.566542
[2022-04-06 22:39:13 | train] - Train Epoch: [154] [243200/1281167 (19%)]	Loss: 0.709250
[2022-04-06 22:39:41 | train] - Train Epoch: [154] [256000/1281167 (20%)]	Loss: 0.893948
[2022-04-06 22:40:08 | train] - Train Epoch: [154] [268800/1281167 (21%)]	Loss: 0.747917
[2022-04-06 22:40:36 | train] - Train Epoch: [154] [281600/1281167 (22%)]	Loss: 0.622455
[2022-04-06 22:41:03 | train] - Train Epoch: [154] [294400/1281167 (23%)]	Loss: 0.592481
[2022-04-06 22:41:30 | train] - Train Epoch: [154] [307200/1281167 (24%)]	Loss: 0.633598
[2022-04-06 22:41:58 | train] - Train Epoch: [154] [320000/1281167 (25%)]	Loss: 0.511748
[2022-04-06 22:42:25 | train] - Train Epoch: [154] [332800/1281167 (26%)]	Loss: 0.824608
[2022-04-06 22:42:52 | train] - Train Epoch: [154] [345600/1281167 (27%)]	Loss: 0.603680
[2022-04-06 22:43:20 | train] - Train Epoch: [154] [358400/1281167 (28%)]	Loss: 0.622463
[2022-04-06 22:43:47 | train] - Train Epoch: [154] [371200/1281167 (29%)]	Loss: 0.668798
[2022-04-06 22:44:15 | train] - Train Epoch: [154] [384000/1281167 (30%)]	Loss: 0.750546
[2022-04-06 22:44:44 | train] - Train Epoch: [154] [396800/1281167 (31%)]	Loss: 0.684408
[2022-04-06 22:45:11 | train] - Train Epoch: [154] [409600/1281167 (32%)]	Loss: 0.466175
[2022-04-06 22:45:39 | train] - Train Epoch: [154] [422400/1281167 (33%)]	Loss: 0.720948
[2022-04-06 22:46:07 | train] - Train Epoch: [154] [435200/1281167 (34%)]	Loss: 0.852857
[2022-04-06 22:46:35 | train] - Train Epoch: [154] [448000/1281167 (35%)]	Loss: 0.539104
[2022-04-06 22:47:02 | train] - Train Epoch: [154] [460800/1281167 (36%)]	Loss: 0.806862
[2022-04-06 22:47:29 | train] - Train Epoch: [154] [473600/1281167 (37%)]	Loss: 0.615189
[2022-04-06 22:47:57 | train] - Train Epoch: [154] [486400/1281167 (38%)]	Loss: 0.850883
[2022-04-06 22:48:24 | train] - Train Epoch: [154] [499200/1281167 (39%)]	Loss: 0.682960
[2022-04-06 22:48:51 | train] - Train Epoch: [154] [512000/1281167 (40%)]	Loss: 0.508930
[2022-04-06 22:49:18 | train] - Train Epoch: [154] [524800/1281167 (41%)]	Loss: 0.616137
[2022-04-06 22:49:45 | train] - Train Epoch: [154] [537600/1281167 (42%)]	Loss: 0.716318
[2022-04-06 22:50:12 | train] - Train Epoch: [154] [550400/1281167 (43%)]	Loss: 0.497545
[2022-04-06 22:50:40 | train] - Train Epoch: [154] [563200/1281167 (44%)]	Loss: 0.661138
[2022-04-06 22:51:07 | train] - Train Epoch: [154] [576000/1281167 (45%)]	Loss: 0.684489
[2022-04-06 22:51:34 | train] - Train Epoch: [154] [588800/1281167 (46%)]	Loss: 0.641498
[2022-04-06 22:52:01 | train] - Train Epoch: [154] [601600/1281167 (47%)]	Loss: 0.472661
[2022-04-06 22:52:28 | train] - Train Epoch: [154] [614400/1281167 (48%)]	Loss: 0.733719
[2022-04-06 22:52:55 | train] - Train Epoch: [154] [627200/1281167 (49%)]	Loss: 0.733583
[2022-04-06 22:53:22 | train] - Train Epoch: [154] [640000/1281167 (50%)]	Loss: 0.778819
[2022-04-06 22:53:49 | train] - Train Epoch: [154] [652800/1281167 (51%)]	Loss: 0.664143
[2022-04-06 22:54:17 | train] - Train Epoch: [154] [665600/1281167 (52%)]	Loss: 0.465582
[2022-04-06 22:54:46 | train] - Train Epoch: [154] [678400/1281167 (53%)]	Loss: 0.883827
[2022-04-06 22:55:13 | train] - Train Epoch: [154] [691200/1281167 (54%)]	Loss: 0.813764
[2022-04-06 22:55:41 | train] - Train Epoch: [154] [704000/1281167 (55%)]	Loss: 0.717006
[2022-04-06 22:56:09 | train] - Train Epoch: [154] [716800/1281167 (56%)]	Loss: 0.610076
[2022-04-06 22:56:37 | train] - Train Epoch: [154] [729600/1281167 (57%)]	Loss: 0.643955
[2022-04-06 22:57:05 | train] - Train Epoch: [154] [742400/1281167 (58%)]	Loss: 0.885120
[2022-04-06 22:57:34 | train] - Train Epoch: [154] [755200/1281167 (59%)]	Loss: 0.732444
[2022-04-06 22:58:03 | train] - Train Epoch: [154] [768000/1281167 (60%)]	Loss: 0.687680
[2022-04-06 22:58:31 | train] - Train Epoch: [154] [780800/1281167 (61%)]	Loss: 0.570539
[2022-04-06 22:58:58 | train] - Train Epoch: [154] [793600/1281167 (62%)]	Loss: 0.565283
[2022-04-06 22:59:26 | train] - Train Epoch: [154] [806400/1281167 (63%)]	Loss: 0.655276
[2022-04-06 22:59:54 | train] - Train Epoch: [154] [819200/1281167 (64%)]	Loss: 0.575486
[2022-04-06 23:00:22 | train] - Train Epoch: [154] [832000/1281167 (65%)]	Loss: 0.689100
[2022-04-06 23:00:50 | train] - Train Epoch: [154] [844800/1281167 (66%)]	Loss: 0.613293
[2022-04-06 23:01:17 | train] - Train Epoch: [154] [857600/1281167 (67%)]	Loss: 0.630951
[2022-04-06 23:01:44 | train] - Train Epoch: [154] [870400/1281167 (68%)]	Loss: 0.615546
[2022-04-06 23:02:11 | train] - Train Epoch: [154] [883200/1281167 (69%)]	Loss: 0.788139
[2022-04-06 23:02:39 | train] - Train Epoch: [154] [896000/1281167 (70%)]	Loss: 0.706278
[2022-04-06 23:03:06 | train] - Train Epoch: [154] [908800/1281167 (71%)]	Loss: 0.883153
[2022-04-06 23:03:34 | train] - Train Epoch: [154] [921600/1281167 (72%)]	Loss: 0.711221
[2022-04-06 23:04:01 | train] - Train Epoch: [154] [934400/1281167 (73%)]	Loss: 0.807595
[2022-04-06 23:04:28 | train] - Train Epoch: [154] [947200/1281167 (74%)]	Loss: 0.842919
[2022-04-06 23:04:56 | train] - Train Epoch: [154] [960000/1281167 (75%)]	Loss: 0.906726
[2022-04-06 23:05:23 | train] - Train Epoch: [154] [972800/1281167 (76%)]	Loss: 0.670855
[2022-04-06 23:05:51 | train] - Train Epoch: [154] [985600/1281167 (77%)]	Loss: 0.449985
[2022-04-06 23:06:19 | train] - Train Epoch: [154] [998400/1281167 (78%)]	Loss: 0.707557
[2022-04-06 23:06:47 | train] - Train Epoch: [154] [1011200/1281167 (79%)]	Loss: 0.635954
[2022-04-06 23:07:14 | train] - Train Epoch: [154] [1024000/1281167 (80%)]	Loss: 0.582644
[2022-04-06 23:07:41 | train] - Train Epoch: [154] [1036800/1281167 (81%)]	Loss: 0.551213
[2022-04-06 23:08:09 | train] - Train Epoch: [154] [1049600/1281167 (82%)]	Loss: 0.935702
[2022-04-06 23:08:36 | train] - Train Epoch: [154] [1062400/1281167 (83%)]	Loss: 0.590842
[2022-04-06 23:09:04 | train] - Train Epoch: [154] [1075200/1281167 (84%)]	Loss: 0.584869
[2022-04-06 23:09:31 | train] - Train Epoch: [154] [1088000/1281167 (85%)]	Loss: 0.935204
[2022-04-06 23:09:58 | train] - Train Epoch: [154] [1100800/1281167 (86%)]	Loss: 0.750157
[2022-04-06 23:10:25 | train] - Train Epoch: [154] [1113600/1281167 (87%)]	Loss: 0.725998
[2022-04-06 23:10:53 | train] - Train Epoch: [154] [1126400/1281167 (88%)]	Loss: 0.728360
[2022-04-06 23:11:21 | train] - Train Epoch: [154] [1139200/1281167 (89%)]	Loss: 0.706465
[2022-04-06 23:11:49 | train] - Train Epoch: [154] [1152000/1281167 (90%)]	Loss: 0.633926
[2022-04-06 23:12:16 | train] - Train Epoch: [154] [1164800/1281167 (91%)]	Loss: 0.692661
[2022-04-06 23:12:44 | train] - Train Epoch: [154] [1177600/1281167 (92%)]	Loss: 0.796924
[2022-04-06 23:13:12 | train] - Train Epoch: [154] [1190400/1281167 (93%)]	Loss: 0.721700
[2022-04-06 23:13:41 | train] - Train Epoch: [154] [1203200/1281167 (94%)]	Loss: 0.536237
[2022-04-06 23:14:10 | train] - Train Epoch: [154] [1216000/1281167 (95%)]	Loss: 0.665745
[2022-04-06 23:14:38 | train] - Train Epoch: [154] [1228800/1281167 (96%)]	Loss: 0.814181
[2022-04-06 23:15:06 | train] - Train Epoch: [154] [1241600/1281167 (97%)]	Loss: 0.698103
[2022-04-06 23:15:35 | train] - Train Epoch: [154] [1254400/1281167 (98%)]	Loss: 0.718035
[2022-04-06 23:16:03 | train] - Train Epoch: [154] [1267200/1281167 (99%)]	Loss: 0.746466
[2022-04-06 23:16:32 | train] - Train Epoch: [154] [1280000/1281167 (100%)]	Loss: 0.493412
[2022-04-06 23:16:34 | train] - Train Epoch: [154]	 Average Loss: 0.695030	 Total Acc : 83.1360	 Total Top5 Acc : 93.9128
[2022-04-06 23:16:34 | train] - -------154 epoch end-----------
========================================
-------154 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-06 23:18:25 | train] - 
Epoch [154] Test set: Average loss: 1.4621, Accuracy: 34868/50000 (69.7123%), Top-5 Accuracy: 88.7452%

[2022-04-06 23:18:25 | train] - save intermediate epoch [154] result


[2022-04-06 23:18:39 | train] - -------155 epoch start-----------
========================================
----- test end -------------------------


[2022-04-06 23:18:41 | train] - Train Epoch: [155] [0/1281167 (0%)]	Loss: 0.709038
[2022-04-06 23:19:06 | train] - Train Epoch: [155] [12800/1281167 (1%)]	Loss: 0.675979
[2022-04-06 23:19:31 | train] - Train Epoch: [155] [25600/1281167 (2%)]	Loss: 0.690212
[2022-04-06 23:19:56 | train] - Train Epoch: [155] [38400/1281167 (3%)]	Loss: 0.519167
[2022-04-06 23:20:22 | train] - Train Epoch: [155] [51200/1281167 (4%)]	Loss: 0.619676
[2022-04-06 23:20:47 | train] - Train Epoch: [155] [64000/1281167 (5%)]	Loss: 0.736338
[2022-04-06 23:21:12 | train] - Train Epoch: [155] [76800/1281167 (6%)]	Loss: 0.669155
[2022-04-06 23:21:37 | train] - Train Epoch: [155] [89600/1281167 (7%)]	Loss: 0.690069
[2022-04-06 23:22:02 | train] - Train Epoch: [155] [102400/1281167 (8%)]	Loss: 0.499649
[2022-04-06 23:22:26 | train] - Train Epoch: [155] [115200/1281167 (9%)]	Loss: 0.915916
[2022-04-06 23:22:51 | train] - Train Epoch: [155] [128000/1281167 (10%)]	Loss: 0.594985
[2022-04-06 23:23:16 | train] - Train Epoch: [155] [140800/1281167 (11%)]	Loss: 0.518782
[2022-04-06 23:23:41 | train] - Train Epoch: [155] [153600/1281167 (12%)]	Loss: 0.728795
[2022-04-06 23:24:07 | train] - Train Epoch: [155] [166400/1281167 (13%)]	Loss: 0.615915
[2022-04-06 23:24:32 | train] - Train Epoch: [155] [179200/1281167 (14%)]	Loss: 0.472812
[2022-04-06 23:24:58 | train] - Train Epoch: [155] [192000/1281167 (15%)]	Loss: 0.714364
[2022-04-06 23:25:23 | train] - Train Epoch: [155] [204800/1281167 (16%)]	Loss: 0.564819
[2022-04-06 23:25:49 | train] - Train Epoch: [155] [217600/1281167 (17%)]	Loss: 0.857267
[2022-04-06 23:26:14 | train] - Train Epoch: [155] [230400/1281167 (18%)]	Loss: 0.561541
[2022-04-06 23:26:39 | train] - Train Epoch: [155] [243200/1281167 (19%)]	Loss: 0.703115
[2022-04-06 23:27:05 | train] - Train Epoch: [155] [256000/1281167 (20%)]	Loss: 0.674243
[2022-04-06 23:27:30 | train] - Train Epoch: [155] [268800/1281167 (21%)]	Loss: 0.486279
[2022-04-06 23:27:56 | train] - Train Epoch: [155] [281600/1281167 (22%)]	Loss: 0.946608
[2022-04-06 23:28:20 | train] - Train Epoch: [155] [294400/1281167 (23%)]	Loss: 0.822763
[2022-04-06 23:28:45 | train] - Train Epoch: [155] [307200/1281167 (24%)]	Loss: 0.953741
[2022-04-06 23:29:10 | train] - Train Epoch: [155] [320000/1281167 (25%)]	Loss: 0.793250
[2022-04-06 23:29:35 | train] - Train Epoch: [155] [332800/1281167 (26%)]	Loss: 1.192106
[2022-04-06 23:30:00 | train] - Train Epoch: [155] [345600/1281167 (27%)]	Loss: 0.532456
[2022-04-06 23:30:25 | train] - Train Epoch: [155] [358400/1281167 (28%)]	Loss: 0.748255
[2022-04-06 23:30:50 | train] - Train Epoch: [155] [371200/1281167 (29%)]	Loss: 0.800754
[2022-04-06 23:31:14 | train] - Train Epoch: [155] [384000/1281167 (30%)]	Loss: 0.463716
[2022-04-06 23:31:40 | train] - Train Epoch: [155] [396800/1281167 (31%)]	Loss: 0.681276
[2022-04-06 23:32:05 | train] - Train Epoch: [155] [409600/1281167 (32%)]	Loss: 0.775642
[2022-04-06 23:32:31 | train] - Train Epoch: [155] [422400/1281167 (33%)]	Loss: 0.668254
[2022-04-06 23:32:56 | train] - Train Epoch: [155] [435200/1281167 (34%)]	Loss: 0.463947
[2022-04-06 23:33:21 | train] - Train Epoch: [155] [448000/1281167 (35%)]	Loss: 0.631804
[2022-04-06 23:33:45 | train] - Train Epoch: [155] [460800/1281167 (36%)]	Loss: 0.768747
[2022-04-06 23:34:10 | train] - Train Epoch: [155] [473600/1281167 (37%)]	Loss: 0.705626
[2022-04-06 23:34:36 | train] - Train Epoch: [155] [486400/1281167 (38%)]	Loss: 0.855692
[2022-04-06 23:35:01 | train] - Train Epoch: [155] [499200/1281167 (39%)]	Loss: 0.840523
[2022-04-06 23:35:26 | train] - Train Epoch: [155] [512000/1281167 (40%)]	Loss: 0.606579
[2022-04-06 23:35:51 | train] - Train Epoch: [155] [524800/1281167 (41%)]	Loss: 0.696799
[2022-04-06 23:36:17 | train] - Train Epoch: [155] [537600/1281167 (42%)]	Loss: 0.716214
[2022-04-06 23:36:42 | train] - Train Epoch: [155] [550400/1281167 (43%)]	Loss: 0.709514
[2022-04-06 23:37:07 | train] - Train Epoch: [155] [563200/1281167 (44%)]	Loss: 0.851715
[2022-04-06 23:37:32 | train] - Train Epoch: [155] [576000/1281167 (45%)]	Loss: 0.847234
[2022-04-06 23:37:58 | train] - Train Epoch: [155] [588800/1281167 (46%)]	Loss: 0.590577
[2022-04-06 23:38:24 | train] - Train Epoch: [155] [601600/1281167 (47%)]	Loss: 0.764803
[2022-04-06 23:38:48 | train] - Train Epoch: [155] [614400/1281167 (48%)]	Loss: 0.751825
[2022-04-06 23:39:13 | train] - Train Epoch: [155] [627200/1281167 (49%)]	Loss: 0.629155
[2022-04-06 23:39:39 | train] - Train Epoch: [155] [640000/1281167 (50%)]	Loss: 0.720580
[2022-04-06 23:40:04 | train] - Train Epoch: [155] [652800/1281167 (51%)]	Loss: 0.901154
[2022-04-06 23:40:30 | train] - Train Epoch: [155] [665600/1281167 (52%)]	Loss: 0.697513
[2022-04-06 23:40:55 | train] - Train Epoch: [155] [678400/1281167 (53%)]	Loss: 0.791976
[2022-04-06 23:41:20 | train] - Train Epoch: [155] [691200/1281167 (54%)]	Loss: 0.764484
[2022-04-06 23:41:44 | train] - Train Epoch: [155] [704000/1281167 (55%)]	Loss: 0.534888
[2022-04-06 23:42:09 | train] - Train Epoch: [155] [716800/1281167 (56%)]	Loss: 0.748248
[2022-04-06 23:42:35 | train] - Train Epoch: [155] [729600/1281167 (57%)]	Loss: 0.604591
[2022-04-06 23:43:00 | train] - Train Epoch: [155] [742400/1281167 (58%)]	Loss: 0.918521
[2022-04-06 23:43:25 | train] - Train Epoch: [155] [755200/1281167 (59%)]	Loss: 1.053592
[2022-04-06 23:43:49 | train] - Train Epoch: [155] [768000/1281167 (60%)]	Loss: 0.629175
[2022-04-06 23:44:14 | train] - Train Epoch: [155] [780800/1281167 (61%)]	Loss: 0.686825
[2022-04-06 23:44:40 | train] - Train Epoch: [155] [793600/1281167 (62%)]	Loss: 0.785696
[2022-04-06 23:45:05 | train] - Train Epoch: [155] [806400/1281167 (63%)]	Loss: 0.966849
[2022-04-06 23:45:30 | train] - Train Epoch: [155] [819200/1281167 (64%)]	Loss: 0.668718
[2022-04-06 23:45:56 | train] - Train Epoch: [155] [832000/1281167 (65%)]	Loss: 0.617888
[2022-04-06 23:46:21 | train] - Train Epoch: [155] [844800/1281167 (66%)]	Loss: 0.789544
[2022-04-06 23:46:46 | train] - Train Epoch: [155] [857600/1281167 (67%)]	Loss: 0.792145
[I 23:46:51.995 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:85df883ef0564c53898ff4a2141c9bb0
[2022-04-06 23:47:12 | train] - Train Epoch: [155] [870400/1281167 (68%)]	Loss: 0.653637
[2022-04-06 23:47:38 | train] - Train Epoch: [155] [883200/1281167 (69%)]	Loss: 0.670443
[2022-04-06 23:48:04 | train] - Train Epoch: [155] [896000/1281167 (70%)]	Loss: 0.760763
[2022-04-06 23:48:30 | train] - Train Epoch: [155] [908800/1281167 (71%)]	Loss: 0.848823
[2022-04-06 23:48:56 | train] - Train Epoch: [155] [921600/1281167 (72%)]	Loss: 0.592202
[2022-04-06 23:49:22 | train] - Train Epoch: [155] [934400/1281167 (73%)]	Loss: 0.574123
[2022-04-06 23:49:47 | train] - Train Epoch: [155] [947200/1281167 (74%)]	Loss: 0.440628
[2022-04-06 23:50:13 | train] - Train Epoch: [155] [960000/1281167 (75%)]	Loss: 0.582854
[2022-04-06 23:50:38 | train] - Train Epoch: [155] [972800/1281167 (76%)]	Loss: 0.744771
[2022-04-06 23:51:04 | train] - Train Epoch: [155] [985600/1281167 (77%)]	Loss: 0.802831
[2022-04-06 23:51:29 | train] - Train Epoch: [155] [998400/1281167 (78%)]	Loss: 0.560284
[2022-04-06 23:51:55 | train] - Train Epoch: [155] [1011200/1281167 (79%)]	Loss: 0.765534
[2022-04-06 23:52:21 | train] - Train Epoch: [155] [1024000/1281167 (80%)]	Loss: 0.621247
[2022-04-06 23:52:45 | train] - Train Epoch: [155] [1036800/1281167 (81%)]	Loss: 0.513291
[2022-04-06 23:53:11 | train] - Train Epoch: [155] [1049600/1281167 (82%)]	Loss: 0.945717
[2022-04-06 23:53:37 | train] - Train Epoch: [155] [1062400/1281167 (83%)]	Loss: 0.635495
[2022-04-06 23:54:02 | train] - Train Epoch: [155] [1075200/1281167 (84%)]	Loss: 0.952353
[2022-04-06 23:54:27 | train] - Train Epoch: [155] [1088000/1281167 (85%)]	Loss: 0.645314
[2022-04-06 23:54:53 | train] - Train Epoch: [155] [1100800/1281167 (86%)]	Loss: 0.641196
[2022-04-06 23:55:19 | train] - Train Epoch: [155] [1113600/1281167 (87%)]	Loss: 0.770965
[2022-04-06 23:55:45 | train] - Train Epoch: [155] [1126400/1281167 (88%)]	Loss: 0.708224
[2022-04-06 23:56:10 | train] - Train Epoch: [155] [1139200/1281167 (89%)]	Loss: 0.738940
[2022-04-06 23:56:37 | train] - Train Epoch: [155] [1152000/1281167 (90%)]	Loss: 0.751659
[2022-04-06 23:57:02 | train] - Train Epoch: [155] [1164800/1281167 (91%)]	Loss: 0.847642
[2022-04-06 23:57:29 | train] - Train Epoch: [155] [1177600/1281167 (92%)]	Loss: 0.600637
[2022-04-06 23:57:55 | train] - Train Epoch: [155] [1190400/1281167 (93%)]	Loss: 0.755514
[2022-04-06 23:58:21 | train] - Train Epoch: [155] [1203200/1281167 (94%)]	Loss: 0.549075
[2022-04-06 23:58:48 | train] - Train Epoch: [155] [1216000/1281167 (95%)]	Loss: 0.774435
[2022-04-06 23:59:14 | train] - Train Epoch: [155] [1228800/1281167 (96%)]	Loss: 0.685581
[2022-04-06 23:59:41 | train] - Train Epoch: [155] [1241600/1281167 (97%)]	Loss: 0.833090
[2022-04-07 00:00:07 | train] - Train Epoch: [155] [1254400/1281167 (98%)]	Loss: 0.681890
[2022-04-07 00:00:33 | train] - Train Epoch: [155] [1267200/1281167 (99%)]	Loss: 0.607854
[2022-04-07 00:01:00 | train] - Train Epoch: [155] [1280000/1281167 (100%)]	Loss: 0.643902
[2022-04-07 00:01:02 | train] - Train Epoch: [155]	 Average Loss: 0.692202	 Total Acc : 83.2088	 Total Top5 Acc : 93.9454
[2022-04-07 00:01:02 | train] - -------155 epoch end-----------
========================================
-------155 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 00:02:56 | train] - 
Epoch [155] Test set: Average loss: 1.4558, Accuracy: 34859/50000 (69.6895%), Top-5 Accuracy: 88.7320%

[2022-04-07 00:02:56 | train] - save intermediate epoch [155] result


[2022-04-07 00:03:10 | train] - -------156 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 00:03:12 | train] - Train Epoch: [156] [0/1281167 (0%)]	Loss: 0.438206
[2022-04-07 00:03:37 | train] - Train Epoch: [156] [12800/1281167 (1%)]	Loss: 0.839943
[2022-04-07 00:04:05 | train] - Train Epoch: [156] [25600/1281167 (2%)]	Loss: 0.636948
[2022-04-07 00:04:30 | train] - Train Epoch: [156] [38400/1281167 (3%)]	Loss: 0.569035
[2022-04-07 00:04:56 | train] - Train Epoch: [156] [51200/1281167 (4%)]	Loss: 0.810190
[2022-04-07 00:05:24 | train] - Train Epoch: [156] [64000/1281167 (5%)]	Loss: 0.484249
[2022-04-07 00:05:50 | train] - Train Epoch: [156] [76800/1281167 (6%)]	Loss: 0.596553
[2022-04-07 00:06:17 | train] - Train Epoch: [156] [89600/1281167 (7%)]	Loss: 0.545790
[2022-04-07 00:06:44 | train] - Train Epoch: [156] [102400/1281167 (8%)]	Loss: 0.612970
[2022-04-07 00:07:11 | train] - Train Epoch: [156] [115200/1281167 (9%)]	Loss: 0.755640
[2022-04-07 00:07:38 | train] - Train Epoch: [156] [128000/1281167 (10%)]	Loss: 0.453452
[2022-04-07 00:08:05 | train] - Train Epoch: [156] [140800/1281167 (11%)]	Loss: 0.539518
[2022-04-07 00:08:32 | train] - Train Epoch: [156] [153600/1281167 (12%)]	Loss: 0.556690
[2022-04-07 00:09:00 | train] - Train Epoch: [156] [166400/1281167 (13%)]	Loss: 0.879655
[2022-04-07 00:09:27 | train] - Train Epoch: [156] [179200/1281167 (14%)]	Loss: 0.506968
[2022-04-07 00:09:53 | train] - Train Epoch: [156] [192000/1281167 (15%)]	Loss: 0.859366
[2022-04-07 00:10:20 | train] - Train Epoch: [156] [204800/1281167 (16%)]	Loss: 0.564852
[2022-04-07 00:10:47 | train] - Train Epoch: [156] [217600/1281167 (17%)]	Loss: 0.861094
[2022-04-07 00:11:14 | train] - Train Epoch: [156] [230400/1281167 (18%)]	Loss: 0.605923
[2022-04-07 00:11:42 | train] - Train Epoch: [156] [243200/1281167 (19%)]	Loss: 0.915078
[2022-04-07 00:12:08 | train] - Train Epoch: [156] [256000/1281167 (20%)]	Loss: 0.462389
[2022-04-07 00:12:36 | train] - Train Epoch: [156] [268800/1281167 (21%)]	Loss: 0.628260
[2022-04-07 00:13:03 | train] - Train Epoch: [156] [281600/1281167 (22%)]	Loss: 0.779638
[2022-04-07 00:13:30 | train] - Train Epoch: [156] [294400/1281167 (23%)]	Loss: 0.704438
[2022-04-07 00:13:57 | train] - Train Epoch: [156] [307200/1281167 (24%)]	Loss: 0.623280
[2022-04-07 00:14:24 | train] - Train Epoch: [156] [320000/1281167 (25%)]	Loss: 0.711900
[2022-04-07 00:14:52 | train] - Train Epoch: [156] [332800/1281167 (26%)]	Loss: 0.567593
[2022-04-07 00:15:20 | train] - Train Epoch: [156] [345600/1281167 (27%)]	Loss: 0.566626
[2022-04-07 00:15:47 | train] - Train Epoch: [156] [358400/1281167 (28%)]	Loss: 0.620105
[2022-04-07 00:16:13 | train] - Train Epoch: [156] [371200/1281167 (29%)]	Loss: 0.748336
[2022-04-07 00:16:40 | train] - Train Epoch: [156] [384000/1281167 (30%)]	Loss: 0.626922
[2022-04-07 00:17:08 | train] - Train Epoch: [156] [396800/1281167 (31%)]	Loss: 0.603728
[2022-04-07 00:17:35 | train] - Train Epoch: [156] [409600/1281167 (32%)]	Loss: 0.797204
[2022-04-07 00:18:02 | train] - Train Epoch: [156] [422400/1281167 (33%)]	Loss: 0.724886
[2022-04-07 00:18:29 | train] - Train Epoch: [156] [435200/1281167 (34%)]	Loss: 0.836053
[2022-04-07 00:18:57 | train] - Train Epoch: [156] [448000/1281167 (35%)]	Loss: 0.817718
[2022-04-07 00:19:24 | train] - Train Epoch: [156] [460800/1281167 (36%)]	Loss: 0.631629
[2022-04-07 00:19:52 | train] - Train Epoch: [156] [473600/1281167 (37%)]	Loss: 0.836927
[2022-04-07 00:20:18 | train] - Train Epoch: [156] [486400/1281167 (38%)]	Loss: 0.502391
[2022-04-07 00:20:46 | train] - Train Epoch: [156] [499200/1281167 (39%)]	Loss: 0.776110
[2022-04-07 00:21:14 | train] - Train Epoch: [156] [512000/1281167 (40%)]	Loss: 0.622219
[2022-04-07 00:21:42 | train] - Train Epoch: [156] [524800/1281167 (41%)]	Loss: 0.702332
[2022-04-07 00:22:10 | train] - Train Epoch: [156] [537600/1281167 (42%)]	Loss: 0.493724
[2022-04-07 00:22:38 | train] - Train Epoch: [156] [550400/1281167 (43%)]	Loss: 0.689621
[2022-04-07 00:23:06 | train] - Train Epoch: [156] [563200/1281167 (44%)]	Loss: 0.592263
[2022-04-07 00:23:33 | train] - Train Epoch: [156] [576000/1281167 (45%)]	Loss: 0.603593
[2022-04-07 00:24:01 | train] - Train Epoch: [156] [588800/1281167 (46%)]	Loss: 0.709482
[2022-04-07 00:24:29 | train] - Train Epoch: [156] [601600/1281167 (47%)]	Loss: 0.776780
[2022-04-07 00:24:58 | train] - Train Epoch: [156] [614400/1281167 (48%)]	Loss: 0.803795
[2022-04-07 00:25:26 | train] - Train Epoch: [156] [627200/1281167 (49%)]	Loss: 0.638820
[2022-04-07 00:25:53 | train] - Train Epoch: [156] [640000/1281167 (50%)]	Loss: 0.683819
[2022-04-07 00:26:21 | train] - Train Epoch: [156] [652800/1281167 (51%)]	Loss: 0.819979
[2022-04-07 00:26:48 | train] - Train Epoch: [156] [665600/1281167 (52%)]	Loss: 0.468251
[2022-04-07 00:27:14 | train] - Train Epoch: [156] [678400/1281167 (53%)]	Loss: 0.836343
[2022-04-07 00:27:41 | train] - Train Epoch: [156] [691200/1281167 (54%)]	Loss: 0.787797
[2022-04-07 00:28:08 | train] - Train Epoch: [156] [704000/1281167 (55%)]	Loss: 0.680103
[2022-04-07 00:28:33 | train] - Train Epoch: [156] [716800/1281167 (56%)]	Loss: 0.826523
[2022-04-07 00:29:01 | train] - Train Epoch: [156] [729600/1281167 (57%)]	Loss: 0.888671
[2022-04-07 00:29:27 | train] - Train Epoch: [156] [742400/1281167 (58%)]	Loss: 0.659727
[2022-04-07 00:29:53 | train] - Train Epoch: [156] [755200/1281167 (59%)]	Loss: 0.765935
[2022-04-07 00:30:20 | train] - Train Epoch: [156] [768000/1281167 (60%)]	Loss: 0.421565
[2022-04-07 00:30:47 | train] - Train Epoch: [156] [780800/1281167 (61%)]	Loss: 0.555202
[2022-04-07 00:31:14 | train] - Train Epoch: [156] [793600/1281167 (62%)]	Loss: 0.671825
[2022-04-07 00:31:41 | train] - Train Epoch: [156] [806400/1281167 (63%)]	Loss: 0.854871
[2022-04-07 00:32:07 | train] - Train Epoch: [156] [819200/1281167 (64%)]	Loss: 0.783984
[2022-04-07 00:32:34 | train] - Train Epoch: [156] [832000/1281167 (65%)]	Loss: 0.610888
[2022-04-07 00:33:02 | train] - Train Epoch: [156] [844800/1281167 (66%)]	Loss: 0.911616
[2022-04-07 00:33:28 | train] - Train Epoch: [156] [857600/1281167 (67%)]	Loss: 0.712102
[2022-04-07 00:33:55 | train] - Train Epoch: [156] [870400/1281167 (68%)]	Loss: 0.754296
[2022-04-07 00:34:22 | train] - Train Epoch: [156] [883200/1281167 (69%)]	Loss: 0.884837
[2022-04-07 00:34:49 | train] - Train Epoch: [156] [896000/1281167 (70%)]	Loss: 0.699332
[2022-04-07 00:35:16 | train] - Train Epoch: [156] [908800/1281167 (71%)]	Loss: 0.622515
[2022-04-07 00:35:42 | train] - Train Epoch: [156] [921600/1281167 (72%)]	Loss: 0.621002
[2022-04-07 00:36:09 | train] - Train Epoch: [156] [934400/1281167 (73%)]	Loss: 0.552112
[2022-04-07 00:36:35 | train] - Train Epoch: [156] [947200/1281167 (74%)]	Loss: 0.594633
[2022-04-07 00:37:02 | train] - Train Epoch: [156] [960000/1281167 (75%)]	Loss: 0.746899
[2022-04-07 00:37:29 | train] - Train Epoch: [156] [972800/1281167 (76%)]	Loss: 0.711222
[2022-04-07 00:37:55 | train] - Train Epoch: [156] [985600/1281167 (77%)]	Loss: 0.749547
[2022-04-07 00:38:22 | train] - Train Epoch: [156] [998400/1281167 (78%)]	Loss: 0.431526
[2022-04-07 00:38:49 | train] - Train Epoch: [156] [1011200/1281167 (79%)]	Loss: 0.693547
[2022-04-07 00:39:16 | train] - Train Epoch: [156] [1024000/1281167 (80%)]	Loss: 0.609725
[2022-04-07 00:39:43 | train] - Train Epoch: [156] [1036800/1281167 (81%)]	Loss: 0.689526
[2022-04-07 00:40:10 | train] - Train Epoch: [156] [1049600/1281167 (82%)]	Loss: 0.654547
[2022-04-07 00:40:37 | train] - Train Epoch: [156] [1062400/1281167 (83%)]	Loss: 0.782672
[2022-04-07 00:41:04 | train] - Train Epoch: [156] [1075200/1281167 (84%)]	Loss: 0.598977
[2022-04-07 00:41:30 | train] - Train Epoch: [156] [1088000/1281167 (85%)]	Loss: 0.554836
[2022-04-07 00:41:57 | train] - Train Epoch: [156] [1100800/1281167 (86%)]	Loss: 0.761315
[2022-04-07 00:42:25 | train] - Train Epoch: [156] [1113600/1281167 (87%)]	Loss: 0.652859
[2022-04-07 00:42:53 | train] - Train Epoch: [156] [1126400/1281167 (88%)]	Loss: 0.776378
[2022-04-07 00:43:21 | train] - Train Epoch: [156] [1139200/1281167 (89%)]	Loss: 0.712968
[2022-04-07 00:43:48 | train] - Train Epoch: [156] [1152000/1281167 (90%)]	Loss: 0.832326
[2022-04-07 00:44:16 | train] - Train Epoch: [156] [1164800/1281167 (91%)]	Loss: 0.843964
[2022-04-07 00:44:44 | train] - Train Epoch: [156] [1177600/1281167 (92%)]	Loss: 0.715867
[2022-04-07 00:45:11 | train] - Train Epoch: [156] [1190400/1281167 (93%)]	Loss: 0.713329
[2022-04-07 00:45:39 | train] - Train Epoch: [156] [1203200/1281167 (94%)]	Loss: 0.568823
[2022-04-07 00:46:08 | train] - Train Epoch: [156] [1216000/1281167 (95%)]	Loss: 0.720266
[2022-04-07 00:46:35 | train] - Train Epoch: [156] [1228800/1281167 (96%)]	Loss: 0.836062
[2022-04-07 00:47:02 | train] - Train Epoch: [156] [1241600/1281167 (97%)]	Loss: 0.833547
[2022-04-07 00:47:30 | train] - Train Epoch: [156] [1254400/1281167 (98%)]	Loss: 0.683681
[2022-04-07 00:47:57 | train] - Train Epoch: [156] [1267200/1281167 (99%)]	Loss: 0.696616
[2022-04-07 00:48:25 | train] - Train Epoch: [156] [1280000/1281167 (100%)]	Loss: 0.651631
[2022-04-07 00:48:27 | train] - Train Epoch: [156]	 Average Loss: 0.689640	 Total Acc : 83.2769	 Total Top5 Acc : 93.9496
[2022-04-07 00:48:27 | train] - -------156 epoch end-----------
========================================
-------156 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 00:50:25 | train] - 
Epoch [156] Test set: Average loss: 1.4488, Accuracy: 34858/50000 (69.6911%), Top-5 Accuracy: 88.7232%

[2022-04-07 00:50:25 | train] - save intermediate epoch [156] result


[2022-04-07 00:50:41 | train] - -------157 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 00:50:43 | train] - Train Epoch: [157] [0/1281167 (0%)]	Loss: 0.655026
[2022-04-07 00:51:10 | train] - Train Epoch: [157] [12800/1281167 (1%)]	Loss: 0.441430
[2022-04-07 00:51:37 | train] - Train Epoch: [157] [25600/1281167 (2%)]	Loss: 0.912795
[2022-04-07 00:52:05 | train] - Train Epoch: [157] [38400/1281167 (3%)]	Loss: 0.556441
[2022-04-07 00:52:32 | train] - Train Epoch: [157] [51200/1281167 (4%)]	Loss: 0.537870
[2022-04-07 00:52:58 | train] - Train Epoch: [157] [64000/1281167 (5%)]	Loss: 0.645919
[2022-04-07 00:53:25 | train] - Train Epoch: [157] [76800/1281167 (6%)]	Loss: 0.582728
[2022-04-07 00:53:53 | train] - Train Epoch: [157] [89600/1281167 (7%)]	Loss: 0.693659
[2022-04-07 00:54:20 | train] - Train Epoch: [157] [102400/1281167 (8%)]	Loss: 0.531570
[2022-04-07 00:54:47 | train] - Train Epoch: [157] [115200/1281167 (9%)]	Loss: 0.641896
[2022-04-07 00:55:15 | train] - Train Epoch: [157] [128000/1281167 (10%)]	Loss: 0.690712
[2022-04-07 00:55:43 | train] - Train Epoch: [157] [140800/1281167 (11%)]	Loss: 0.608001
[2022-04-07 00:56:11 | train] - Train Epoch: [157] [153600/1281167 (12%)]	Loss: 0.576395
[2022-04-07 00:56:38 | train] - Train Epoch: [157] [166400/1281167 (13%)]	Loss: 0.578075
[2022-04-07 00:57:06 | train] - Train Epoch: [157] [179200/1281167 (14%)]	Loss: 0.517868
[2022-04-07 00:57:33 | train] - Train Epoch: [157] [192000/1281167 (15%)]	Loss: 0.836193
[2022-04-07 00:58:00 | train] - Train Epoch: [157] [204800/1281167 (16%)]	Loss: 0.590163
[2022-04-07 00:58:28 | train] - Train Epoch: [157] [217600/1281167 (17%)]	Loss: 0.753859
[2022-04-07 00:58:54 | train] - Train Epoch: [157] [230400/1281167 (18%)]	Loss: 0.558634
[2022-04-07 00:59:21 | train] - Train Epoch: [157] [243200/1281167 (19%)]	Loss: 0.764837
[2022-04-07 00:59:48 | train] - Train Epoch: [157] [256000/1281167 (20%)]	Loss: 0.668855
[2022-04-07 01:00:14 | train] - Train Epoch: [157] [268800/1281167 (21%)]	Loss: 0.722332
[2022-04-07 01:00:42 | train] - Train Epoch: [157] [281600/1281167 (22%)]	Loss: 0.627639
[2022-04-07 01:01:09 | train] - Train Epoch: [157] [294400/1281167 (23%)]	Loss: 0.629851
[2022-04-07 01:01:36 | train] - Train Epoch: [157] [307200/1281167 (24%)]	Loss: 0.720163
[2022-04-07 01:02:03 | train] - Train Epoch: [157] [320000/1281167 (25%)]	Loss: 0.742802
[2022-04-07 01:02:30 | train] - Train Epoch: [157] [332800/1281167 (26%)]	Loss: 0.683519
[2022-04-07 01:02:58 | train] - Train Epoch: [157] [345600/1281167 (27%)]	Loss: 0.439928
[2022-04-07 01:03:26 | train] - Train Epoch: [157] [358400/1281167 (28%)]	Loss: 0.904570
[2022-04-07 01:03:54 | train] - Train Epoch: [157] [371200/1281167 (29%)]	Loss: 0.777925
[2022-04-07 01:04:21 | train] - Train Epoch: [157] [384000/1281167 (30%)]	Loss: 0.700132
[2022-04-07 01:04:49 | train] - Train Epoch: [157] [396800/1281167 (31%)]	Loss: 0.520285
[2022-04-07 01:05:16 | train] - Train Epoch: [157] [409600/1281167 (32%)]	Loss: 0.586243
[2022-04-07 01:05:43 | train] - Train Epoch: [157] [422400/1281167 (33%)]	Loss: 0.851246
[2022-04-07 01:06:11 | train] - Train Epoch: [157] [435200/1281167 (34%)]	Loss: 0.572134
[2022-04-07 01:06:37 | train] - Train Epoch: [157] [448000/1281167 (35%)]	Loss: 0.648317
[2022-04-07 01:07:05 | train] - Train Epoch: [157] [460800/1281167 (36%)]	Loss: 0.707341
[2022-04-07 01:07:33 | train] - Train Epoch: [157] [473600/1281167 (37%)]	Loss: 0.772356
[2022-04-07 01:08:01 | train] - Train Epoch: [157] [486400/1281167 (38%)]	Loss: 0.839297
[2022-04-07 01:08:28 | train] - Train Epoch: [157] [499200/1281167 (39%)]	Loss: 0.806007
[2022-04-07 01:08:56 | train] - Train Epoch: [157] [512000/1281167 (40%)]	Loss: 0.602299
[2022-04-07 01:09:22 | train] - Train Epoch: [157] [524800/1281167 (41%)]	Loss: 0.550087
[2022-04-07 01:09:49 | train] - Train Epoch: [157] [537600/1281167 (42%)]	Loss: 0.698200
[2022-04-07 01:10:15 | train] - Train Epoch: [157] [550400/1281167 (43%)]	Loss: 0.846985
[2022-04-07 01:10:43 | train] - Train Epoch: [157] [563200/1281167 (44%)]	Loss: 0.828729
[2022-04-07 01:11:10 | train] - Train Epoch: [157] [576000/1281167 (45%)]	Loss: 0.698515
[2022-04-07 01:11:38 | train] - Train Epoch: [157] [588800/1281167 (46%)]	Loss: 0.742790
[2022-04-07 01:12:05 | train] - Train Epoch: [157] [601600/1281167 (47%)]	Loss: 0.984972
[2022-04-07 01:12:32 | train] - Train Epoch: [157] [614400/1281167 (48%)]	Loss: 0.726618
[2022-04-07 01:12:59 | train] - Train Epoch: [157] [627200/1281167 (49%)]	Loss: 0.809228
[2022-04-07 01:13:26 | train] - Train Epoch: [157] [640000/1281167 (50%)]	Loss: 0.842528
[2022-04-07 01:13:52 | train] - Train Epoch: [157] [652800/1281167 (51%)]	Loss: 0.621245
[2022-04-07 01:14:21 | train] - Train Epoch: [157] [665600/1281167 (52%)]	Loss: 0.628558
[2022-04-07 01:14:48 | train] - Train Epoch: [157] [678400/1281167 (53%)]	Loss: 0.802131
[2022-04-07 01:15:16 | train] - Train Epoch: [157] [691200/1281167 (54%)]	Loss: 0.492247
[2022-04-07 01:15:44 | train] - Train Epoch: [157] [704000/1281167 (55%)]	Loss: 0.679107
[2022-04-07 01:16:11 | train] - Train Epoch: [157] [716800/1281167 (56%)]	Loss: 0.582719
[2022-04-07 01:16:39 | train] - Train Epoch: [157] [729600/1281167 (57%)]	Loss: 0.936741
[2022-04-07 01:17:06 | train] - Train Epoch: [157] [742400/1281167 (58%)]	Loss: 0.634259
[2022-04-07 01:17:34 | train] - Train Epoch: [157] [755200/1281167 (59%)]	Loss: 0.804913
[2022-04-07 01:18:01 | train] - Train Epoch: [157] [768000/1281167 (60%)]	Loss: 0.473747
[2022-04-07 01:18:28 | train] - Train Epoch: [157] [780800/1281167 (61%)]	Loss: 0.693207
[2022-04-07 01:18:55 | train] - Train Epoch: [157] [793600/1281167 (62%)]	Loss: 0.853204
[2022-04-07 01:19:23 | train] - Train Epoch: [157] [806400/1281167 (63%)]	Loss: 0.644318
[2022-04-07 01:19:51 | train] - Train Epoch: [157] [819200/1281167 (64%)]	Loss: 0.609730
[2022-04-07 01:20:19 | train] - Train Epoch: [157] [832000/1281167 (65%)]	Loss: 0.615560
[2022-04-07 01:20:47 | train] - Train Epoch: [157] [844800/1281167 (66%)]	Loss: 0.570432
[2022-04-07 01:21:13 | train] - Train Epoch: [157] [857600/1281167 (67%)]	Loss: 0.815489
[2022-04-07 01:21:41 | train] - Train Epoch: [157] [870400/1281167 (68%)]	Loss: 0.648553
[2022-04-07 01:22:09 | train] - Train Epoch: [157] [883200/1281167 (69%)]	Loss: 0.715037
[2022-04-07 01:22:37 | train] - Train Epoch: [157] [896000/1281167 (70%)]	Loss: 0.938423
[2022-04-07 01:23:04 | train] - Train Epoch: [157] [908800/1281167 (71%)]	Loss: 0.775278
[2022-04-07 01:23:32 | train] - Train Epoch: [157] [921600/1281167 (72%)]	Loss: 0.496988
[2022-04-07 01:23:59 | train] - Train Epoch: [157] [934400/1281167 (73%)]	Loss: 0.814028
[2022-04-07 01:24:27 | train] - Train Epoch: [157] [947200/1281167 (74%)]	Loss: 0.771725
[2022-04-07 01:24:55 | train] - Train Epoch: [157] [960000/1281167 (75%)]	Loss: 0.759856
[2022-04-07 01:25:24 | train] - Train Epoch: [157] [972800/1281167 (76%)]	Loss: 0.674535
[2022-04-07 01:25:52 | train] - Train Epoch: [157] [985600/1281167 (77%)]	Loss: 0.706459
[2022-04-07 01:26:20 | train] - Train Epoch: [157] [998400/1281167 (78%)]	Loss: 0.695520
[2022-04-07 01:26:48 | train] - Train Epoch: [157] [1011200/1281167 (79%)]	Loss: 0.643245
[2022-04-07 01:27:16 | train] - Train Epoch: [157] [1024000/1281167 (80%)]	Loss: 0.526575
[2022-04-07 01:27:43 | train] - Train Epoch: [157] [1036800/1281167 (81%)]	Loss: 0.598745
[2022-04-07 01:28:11 | train] - Train Epoch: [157] [1049600/1281167 (82%)]	Loss: 0.592922
[2022-04-07 01:28:40 | train] - Train Epoch: [157] [1062400/1281167 (83%)]	Loss: 0.651296
[2022-04-07 01:29:07 | train] - Train Epoch: [157] [1075200/1281167 (84%)]	Loss: 0.626826
[2022-04-07 01:29:35 | train] - Train Epoch: [157] [1088000/1281167 (85%)]	Loss: 0.713150
[2022-04-07 01:30:03 | train] - Train Epoch: [157] [1100800/1281167 (86%)]	Loss: 0.615176
[2022-04-07 01:30:31 | train] - Train Epoch: [157] [1113600/1281167 (87%)]	Loss: 0.650024
[2022-04-07 01:31:00 | train] - Train Epoch: [157] [1126400/1281167 (88%)]	Loss: 0.666533
[2022-04-07 01:31:28 | train] - Train Epoch: [157] [1139200/1281167 (89%)]	Loss: 0.554012
[2022-04-07 01:31:56 | train] - Train Epoch: [157] [1152000/1281167 (90%)]	Loss: 0.746929
[2022-04-07 01:32:24 | train] - Train Epoch: [157] [1164800/1281167 (91%)]	Loss: 0.758620
[2022-04-07 01:32:53 | train] - Train Epoch: [157] [1177600/1281167 (92%)]	Loss: 0.821260
[2022-04-07 01:33:20 | train] - Train Epoch: [157] [1190400/1281167 (93%)]	Loss: 0.584008
[2022-04-07 01:33:49 | train] - Train Epoch: [157] [1203200/1281167 (94%)]	Loss: 0.794955
[2022-04-07 01:34:18 | train] - Train Epoch: [157] [1216000/1281167 (95%)]	Loss: 0.796260
[2022-04-07 01:34:45 | train] - Train Epoch: [157] [1228800/1281167 (96%)]	Loss: 0.531451
[2022-04-07 01:35:13 | train] - Train Epoch: [157] [1241600/1281167 (97%)]	Loss: 0.630228
[2022-04-07 01:35:42 | train] - Train Epoch: [157] [1254400/1281167 (98%)]	Loss: 0.586243
[2022-04-07 01:36:11 | train] - Train Epoch: [157] [1267200/1281167 (99%)]	Loss: 0.662986
[2022-04-07 01:36:40 | train] - Train Epoch: [157] [1280000/1281167 (100%)]	Loss: 0.705683
[2022-04-07 01:36:42 | train] - Train Epoch: [157]	 Average Loss: 0.686233	 Total Acc : 83.3502	 Total Top5 Acc : 93.9949
[2022-04-07 01:36:42 | train] - -------157 epoch end-----------
========================================
-------157 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 01:38:42 | train] - 
Epoch [157] Test set: Average loss: 1.4604, Accuracy: 34875/50000 (69.7227%), Top-5 Accuracy: 88.7999%

[2022-04-07 01:38:42 | train] - save intermediate epoch [157] result


[2022-04-07 01:38:56 | train] - -------158 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 01:38:58 | train] - Train Epoch: [158] [0/1281167 (0%)]	Loss: 0.813814
[2022-04-07 01:39:26 | train] - Train Epoch: [158] [12800/1281167 (1%)]	Loss: 0.788022
[2022-04-07 01:39:55 | train] - Train Epoch: [158] [25600/1281167 (2%)]	Loss: 0.537738
[2022-04-07 01:40:22 | train] - Train Epoch: [158] [38400/1281167 (3%)]	Loss: 0.484566
[2022-04-07 01:40:50 | train] - Train Epoch: [158] [51200/1281167 (4%)]	Loss: 0.670920
[2022-04-07 01:41:17 | train] - Train Epoch: [158] [64000/1281167 (5%)]	Loss: 0.735609
[2022-04-07 01:41:44 | train] - Train Epoch: [158] [76800/1281167 (6%)]	Loss: 0.800091
[2022-04-07 01:42:13 | train] - Train Epoch: [158] [89600/1281167 (7%)]	Loss: 0.687239
[2022-04-07 01:42:40 | train] - Train Epoch: [158] [102400/1281167 (8%)]	Loss: 0.648753
[2022-04-07 01:43:08 | train] - Train Epoch: [158] [115200/1281167 (9%)]	Loss: 0.724360
[2022-04-07 01:43:36 | train] - Train Epoch: [158] [128000/1281167 (10%)]	Loss: 0.925381
[2022-04-07 01:44:04 | train] - Train Epoch: [158] [140800/1281167 (11%)]	Loss: 0.562845
[2022-04-07 01:44:31 | train] - Train Epoch: [158] [153600/1281167 (12%)]	Loss: 0.559671
[2022-04-07 01:44:59 | train] - Train Epoch: [158] [166400/1281167 (13%)]	Loss: 0.590700
[2022-04-07 01:45:26 | train] - Train Epoch: [158] [179200/1281167 (14%)]	Loss: 0.505656
[2022-04-07 01:45:53 | train] - Train Epoch: [158] [192000/1281167 (15%)]	Loss: 0.740296
[2022-04-07 01:46:21 | train] - Train Epoch: [158] [204800/1281167 (16%)]	Loss: 0.652111
[2022-04-07 01:46:48 | train] - Train Epoch: [158] [217600/1281167 (17%)]	Loss: 0.707218
[2022-04-07 01:47:16 | train] - Train Epoch: [158] [230400/1281167 (18%)]	Loss: 0.714009
[2022-04-07 01:47:43 | train] - Train Epoch: [158] [243200/1281167 (19%)]	Loss: 0.909051
[2022-04-07 01:48:12 | train] - Train Epoch: [158] [256000/1281167 (20%)]	Loss: 0.490449
[2022-04-07 01:48:40 | train] - Train Epoch: [158] [268800/1281167 (21%)]	Loss: 0.630326
[2022-04-07 01:49:07 | train] - Train Epoch: [158] [281600/1281167 (22%)]	Loss: 0.490894
[2022-04-07 01:49:34 | train] - Train Epoch: [158] [294400/1281167 (23%)]	Loss: 0.649074
[2022-04-07 01:50:01 | train] - Train Epoch: [158] [307200/1281167 (24%)]	Loss: 0.747385
[2022-04-07 01:50:29 | train] - Train Epoch: [158] [320000/1281167 (25%)]	Loss: 0.513701
[2022-04-07 01:50:56 | train] - Train Epoch: [158] [332800/1281167 (26%)]	Loss: 0.634291
[2022-04-07 01:51:23 | train] - Train Epoch: [158] [345600/1281167 (27%)]	Loss: 0.780013
[2022-04-07 01:51:50 | train] - Train Epoch: [158] [358400/1281167 (28%)]	Loss: 0.566472
[2022-04-07 01:52:19 | train] - Train Epoch: [158] [371200/1281167 (29%)]	Loss: 0.859286
[2022-04-07 01:52:46 | train] - Train Epoch: [158] [384000/1281167 (30%)]	Loss: 0.538052
[2022-04-07 01:53:14 | train] - Train Epoch: [158] [396800/1281167 (31%)]	Loss: 1.049075
[2022-04-07 01:53:41 | train] - Train Epoch: [158] [409600/1281167 (32%)]	Loss: 0.625228
[2022-04-07 01:54:09 | train] - Train Epoch: [158] [422400/1281167 (33%)]	Loss: 0.519083
[2022-04-07 01:54:36 | train] - Train Epoch: [158] [435200/1281167 (34%)]	Loss: 0.704916
[2022-04-07 01:55:03 | train] - Train Epoch: [158] [448000/1281167 (35%)]	Loss: 0.744285
[2022-04-07 01:55:30 | train] - Train Epoch: [158] [460800/1281167 (36%)]	Loss: 0.447309
[2022-04-07 01:55:58 | train] - Train Epoch: [158] [473600/1281167 (37%)]	Loss: 0.608733
[2022-04-07 01:56:25 | train] - Train Epoch: [158] [486400/1281167 (38%)]	Loss: 0.597438
[2022-04-07 01:56:52 | train] - Train Epoch: [158] [499200/1281167 (39%)]	Loss: 0.678244
[2022-04-07 01:57:20 | train] - Train Epoch: [158] [512000/1281167 (40%)]	Loss: 0.609640
[2022-04-07 01:57:48 | train] - Train Epoch: [158] [524800/1281167 (41%)]	Loss: 0.511697
[2022-04-07 01:58:15 | train] - Train Epoch: [158] [537600/1281167 (42%)]	Loss: 0.562415
[2022-04-07 01:58:43 | train] - Train Epoch: [158] [550400/1281167 (43%)]	Loss: 0.781064
[2022-04-07 01:59:10 | train] - Train Epoch: [158] [563200/1281167 (44%)]	Loss: 0.495023
[2022-04-07 01:59:37 | train] - Train Epoch: [158] [576000/1281167 (45%)]	Loss: 0.712641
[2022-04-07 02:00:05 | train] - Train Epoch: [158] [588800/1281167 (46%)]	Loss: 0.580627
[2022-04-07 02:00:33 | train] - Train Epoch: [158] [601600/1281167 (47%)]	Loss: 0.626466
[2022-04-07 02:01:02 | train] - Train Epoch: [158] [614400/1281167 (48%)]	Loss: 0.518601
[2022-04-07 02:01:30 | train] - Train Epoch: [158] [627200/1281167 (49%)]	Loss: 0.641391
[2022-04-07 02:01:57 | train] - Train Epoch: [158] [640000/1281167 (50%)]	Loss: 0.790838
[2022-04-07 02:02:26 | train] - Train Epoch: [158] [652800/1281167 (51%)]	Loss: 0.735161
[2022-04-07 02:02:54 | train] - Train Epoch: [158] [665600/1281167 (52%)]	Loss: 0.765527
[2022-04-07 02:03:21 | train] - Train Epoch: [158] [678400/1281167 (53%)]	Loss: 0.541653
[2022-04-07 02:03:49 | train] - Train Epoch: [158] [691200/1281167 (54%)]	Loss: 0.754316
[2022-04-07 02:04:17 | train] - Train Epoch: [158] [704000/1281167 (55%)]	Loss: 0.653072
[2022-04-07 02:04:45 | train] - Train Epoch: [158] [716800/1281167 (56%)]	Loss: 1.002729
[2022-04-07 02:05:12 | train] - Train Epoch: [158] [729600/1281167 (57%)]	Loss: 0.961813
[2022-04-07 02:05:40 | train] - Train Epoch: [158] [742400/1281167 (58%)]	Loss: 0.764113
[2022-04-07 02:06:07 | train] - Train Epoch: [158] [755200/1281167 (59%)]	Loss: 0.388904
[2022-04-07 02:06:35 | train] - Train Epoch: [158] [768000/1281167 (60%)]	Loss: 0.829909
[2022-04-07 02:07:03 | train] - Train Epoch: [158] [780800/1281167 (61%)]	Loss: 0.728553
[2022-04-07 02:07:30 | train] - Train Epoch: [158] [793600/1281167 (62%)]	Loss: 0.613437
[2022-04-07 02:07:57 | train] - Train Epoch: [158] [806400/1281167 (63%)]	Loss: 0.597411
[2022-04-07 02:08:25 | train] - Train Epoch: [158] [819200/1281167 (64%)]	Loss: 0.472252
[2022-04-07 02:08:51 | train] - Train Epoch: [158] [832000/1281167 (65%)]	Loss: 0.588529
[2022-04-07 02:09:19 | train] - Train Epoch: [158] [844800/1281167 (66%)]	Loss: 0.591923
[2022-04-07 02:09:46 | train] - Train Epoch: [158] [857600/1281167 (67%)]	Loss: 0.761452
[2022-04-07 02:10:14 | train] - Train Epoch: [158] [870400/1281167 (68%)]	Loss: 0.643503
[2022-04-07 02:10:42 | train] - Train Epoch: [158] [883200/1281167 (69%)]	Loss: 0.425972
[2022-04-07 02:11:09 | train] - Train Epoch: [158] [896000/1281167 (70%)]	Loss: 0.531062
[2022-04-07 02:11:38 | train] - Train Epoch: [158] [908800/1281167 (71%)]	Loss: 0.502945
[2022-04-07 02:12:06 | train] - Train Epoch: [158] [921600/1281167 (72%)]	Loss: 0.726358
[2022-04-07 02:12:33 | train] - Train Epoch: [158] [934400/1281167 (73%)]	Loss: 0.612137
[2022-04-07 02:13:01 | train] - Train Epoch: [158] [947200/1281167 (74%)]	Loss: 0.679631
[2022-04-07 02:13:30 | train] - Train Epoch: [158] [960000/1281167 (75%)]	Loss: 0.642685
[2022-04-07 02:13:57 | train] - Train Epoch: [158] [972800/1281167 (76%)]	Loss: 0.617175
[2022-04-07 02:14:25 | train] - Train Epoch: [158] [985600/1281167 (77%)]	Loss: 0.752083
[2022-04-07 02:14:53 | train] - Train Epoch: [158] [998400/1281167 (78%)]	Loss: 0.673931
[2022-04-07 02:15:21 | train] - Train Epoch: [158] [1011200/1281167 (79%)]	Loss: 0.756723
[2022-04-07 02:15:49 | train] - Train Epoch: [158] [1024000/1281167 (80%)]	Loss: 0.783617
[2022-04-07 02:16:16 | train] - Train Epoch: [158] [1036800/1281167 (81%)]	Loss: 0.608688
[2022-04-07 02:16:44 | train] - Train Epoch: [158] [1049600/1281167 (82%)]	Loss: 0.938763
[2022-04-07 02:17:11 | train] - Train Epoch: [158] [1062400/1281167 (83%)]	Loss: 0.686621
[2022-04-07 02:17:40 | train] - Train Epoch: [158] [1075200/1281167 (84%)]	Loss: 0.909781
[2022-04-07 02:18:09 | train] - Train Epoch: [158] [1088000/1281167 (85%)]	Loss: 0.578293
[2022-04-07 02:18:36 | train] - Train Epoch: [158] [1100800/1281167 (86%)]	Loss: 0.875226
[2022-04-07 02:19:03 | train] - Train Epoch: [158] [1113600/1281167 (87%)]	Loss: 0.701496
[2022-04-07 02:19:31 | train] - Train Epoch: [158] [1126400/1281167 (88%)]	Loss: 0.594038
[2022-04-07 02:20:00 | train] - Train Epoch: [158] [1139200/1281167 (89%)]	Loss: 0.716217
[2022-04-07 02:20:28 | train] - Train Epoch: [158] [1152000/1281167 (90%)]	Loss: 0.551472
[2022-04-07 02:20:55 | train] - Train Epoch: [158] [1164800/1281167 (91%)]	Loss: 0.595127
[2022-04-07 02:21:23 | train] - Train Epoch: [158] [1177600/1281167 (92%)]	Loss: 0.482600
[2022-04-07 02:21:51 | train] - Train Epoch: [158] [1190400/1281167 (93%)]	Loss: 0.505122
[2022-04-07 02:22:20 | train] - Train Epoch: [158] [1203200/1281167 (94%)]	Loss: 0.747806
[2022-04-07 02:22:48 | train] - Train Epoch: [158] [1216000/1281167 (95%)]	Loss: 0.799703
[2022-04-07 02:23:18 | train] - Train Epoch: [158] [1228800/1281167 (96%)]	Loss: 0.700278
[2022-04-07 02:23:47 | train] - Train Epoch: [158] [1241600/1281167 (97%)]	Loss: 0.671978
[2022-04-07 02:24:16 | train] - Train Epoch: [158] [1254400/1281167 (98%)]	Loss: 0.705832
[2022-04-07 02:24:45 | train] - Train Epoch: [158] [1267200/1281167 (99%)]	Loss: 0.909917
[2022-04-07 02:25:13 | train] - Train Epoch: [158] [1280000/1281167 (100%)]	Loss: 0.697997
[2022-04-07 02:25:15 | train] - Train Epoch: [158]	 Average Loss: 0.682612	 Total Acc : 83.4546	 Total Top5 Acc : 94.0076
[2022-04-07 02:25:15 | train] - -------158 epoch end-----------
========================================
-------158 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 02:27:10 | train] - 
Epoch [158] Test set: Average loss: 1.4582, Accuracy: 34918/50000 (69.8110%), Top-5 Accuracy: 88.7900%

[2022-04-07 02:27:10 | train] - save intermediate epoch [158] result


[2022-04-07 02:27:25 | train] - -------159 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 02:27:27 | train] - Train Epoch: [159] [0/1281167 (0%)]	Loss: 0.914469
[2022-04-07 02:27:54 | train] - Train Epoch: [159] [12800/1281167 (1%)]	Loss: 0.650307
[2022-04-07 02:28:22 | train] - Train Epoch: [159] [25600/1281167 (2%)]	Loss: 0.683802
[2022-04-07 02:28:49 | train] - Train Epoch: [159] [38400/1281167 (3%)]	Loss: 0.625147
[2022-04-07 02:29:17 | train] - Train Epoch: [159] [51200/1281167 (4%)]	Loss: 0.599913
[2022-04-07 02:29:45 | train] - Train Epoch: [159] [64000/1281167 (5%)]	Loss: 0.677736
[2022-04-07 02:30:13 | train] - Train Epoch: [159] [76800/1281167 (6%)]	Loss: 0.751355
[2022-04-07 02:30:40 | train] - Train Epoch: [159] [89600/1281167 (7%)]	Loss: 0.643001
[2022-04-07 02:31:09 | train] - Train Epoch: [159] [102400/1281167 (8%)]	Loss: 0.613309
[2022-04-07 02:31:38 | train] - Train Epoch: [159] [115200/1281167 (9%)]	Loss: 0.884281
[2022-04-07 02:32:06 | train] - Train Epoch: [159] [128000/1281167 (10%)]	Loss: 0.858465
[2022-04-07 02:32:33 | train] - Train Epoch: [159] [140800/1281167 (11%)]	Loss: 0.617740
[2022-04-07 02:33:02 | train] - Train Epoch: [159] [153600/1281167 (12%)]	Loss: 0.624048
[2022-04-07 02:33:31 | train] - Train Epoch: [159] [166400/1281167 (13%)]	Loss: 0.658415
[2022-04-07 02:33:59 | train] - Train Epoch: [159] [179200/1281167 (14%)]	Loss: 0.529661
[2022-04-07 02:34:27 | train] - Train Epoch: [159] [192000/1281167 (15%)]	Loss: 0.629127
[2022-04-07 02:34:56 | train] - Train Epoch: [159] [204800/1281167 (16%)]	Loss: 0.635075
[2022-04-07 02:35:24 | train] - Train Epoch: [159] [217600/1281167 (17%)]	Loss: 0.620846
[2022-04-07 02:35:52 | train] - Train Epoch: [159] [230400/1281167 (18%)]	Loss: 0.586220
[2022-04-07 02:36:20 | train] - Train Epoch: [159] [243200/1281167 (19%)]	Loss: 0.549609
[2022-04-07 02:36:48 | train] - Train Epoch: [159] [256000/1281167 (20%)]	Loss: 0.535579
[2022-04-07 02:37:15 | train] - Train Epoch: [159] [268800/1281167 (21%)]	Loss: 0.706680
[2022-04-07 02:37:42 | train] - Train Epoch: [159] [281600/1281167 (22%)]	Loss: 0.726628
[2022-04-07 02:38:10 | train] - Train Epoch: [159] [294400/1281167 (23%)]	Loss: 0.558034
[2022-04-07 02:38:37 | train] - Train Epoch: [159] [307200/1281167 (24%)]	Loss: 0.581513
[2022-04-07 02:39:04 | train] - Train Epoch: [159] [320000/1281167 (25%)]	Loss: 0.756662
[2022-04-07 02:39:32 | train] - Train Epoch: [159] [332800/1281167 (26%)]	Loss: 0.668135
[2022-04-07 02:39:59 | train] - Train Epoch: [159] [345600/1281167 (27%)]	Loss: 0.987270
[2022-04-07 02:40:27 | train] - Train Epoch: [159] [358400/1281167 (28%)]	Loss: 0.613503
[2022-04-07 02:40:54 | train] - Train Epoch: [159] [371200/1281167 (29%)]	Loss: 0.713783
[2022-04-07 02:41:21 | train] - Train Epoch: [159] [384000/1281167 (30%)]	Loss: 0.773301
[2022-04-07 02:41:48 | train] - Train Epoch: [159] [396800/1281167 (31%)]	Loss: 0.662661
[2022-04-07 02:42:15 | train] - Train Epoch: [159] [409600/1281167 (32%)]	Loss: 0.774453
[2022-04-07 02:42:43 | train] - Train Epoch: [159] [422400/1281167 (33%)]	Loss: 0.651096
[2022-04-07 02:43:11 | train] - Train Epoch: [159] [435200/1281167 (34%)]	Loss: 0.723725
[2022-04-07 02:43:38 | train] - Train Epoch: [159] [448000/1281167 (35%)]	Loss: 0.548768
[2022-04-07 02:44:05 | train] - Train Epoch: [159] [460800/1281167 (36%)]	Loss: 0.538082
[2022-04-07 02:44:31 | train] - Train Epoch: [159] [473600/1281167 (37%)]	Loss: 0.704047
[2022-04-07 02:44:59 | train] - Train Epoch: [159] [486400/1281167 (38%)]	Loss: 0.801067
[2022-04-07 02:45:27 | train] - Train Epoch: [159] [499200/1281167 (39%)]	Loss: 0.502333
[2022-04-07 02:45:54 | train] - Train Epoch: [159] [512000/1281167 (40%)]	Loss: 0.662102
[2022-04-07 02:46:21 | train] - Train Epoch: [159] [524800/1281167 (41%)]	Loss: 0.772921
[2022-04-07 02:46:48 | train] - Train Epoch: [159] [537600/1281167 (42%)]	Loss: 0.600953
[2022-04-07 02:47:15 | train] - Train Epoch: [159] [550400/1281167 (43%)]	Loss: 0.794998
[2022-04-07 02:47:43 | train] - Train Epoch: [159] [563200/1281167 (44%)]	Loss: 0.748394
[2022-04-07 02:48:11 | train] - Train Epoch: [159] [576000/1281167 (45%)]	Loss: 0.633150
[2022-04-07 02:48:39 | train] - Train Epoch: [159] [588800/1281167 (46%)]	Loss: 0.701014
[2022-04-07 02:49:05 | train] - Train Epoch: [159] [601600/1281167 (47%)]	Loss: 0.568497
[2022-04-07 02:49:33 | train] - Train Epoch: [159] [614400/1281167 (48%)]	Loss: 0.443316
[2022-04-07 02:50:00 | train] - Train Epoch: [159] [627200/1281167 (49%)]	Loss: 0.775023
[2022-04-07 02:50:27 | train] - Train Epoch: [159] [640000/1281167 (50%)]	Loss: 0.743027
[2022-04-07 02:50:54 | train] - Train Epoch: [159] [652800/1281167 (51%)]	Loss: 0.722348
[2022-04-07 02:51:22 | train] - Train Epoch: [159] [665600/1281167 (52%)]	Loss: 0.802634
[2022-04-07 02:51:49 | train] - Train Epoch: [159] [678400/1281167 (53%)]	Loss: 0.831200
[2022-04-07 02:52:17 | train] - Train Epoch: [159] [691200/1281167 (54%)]	Loss: 0.797351
[2022-04-07 02:52:45 | train] - Train Epoch: [159] [704000/1281167 (55%)]	Loss: 0.541947
[2022-04-07 02:53:12 | train] - Train Epoch: [159] [716800/1281167 (56%)]	Loss: 0.840350
[2022-04-07 02:53:39 | train] - Train Epoch: [159] [729600/1281167 (57%)]	Loss: 0.813056
[2022-04-07 02:54:07 | train] - Train Epoch: [159] [742400/1281167 (58%)]	Loss: 0.723925
[2022-04-07 02:54:34 | train] - Train Epoch: [159] [755200/1281167 (59%)]	Loss: 0.571057
[2022-04-07 02:55:01 | train] - Train Epoch: [159] [768000/1281167 (60%)]	Loss: 0.807146
[2022-04-07 02:55:30 | train] - Train Epoch: [159] [780800/1281167 (61%)]	Loss: 0.632286
[2022-04-07 02:55:58 | train] - Train Epoch: [159] [793600/1281167 (62%)]	Loss: 0.692868
[2022-04-07 02:56:25 | train] - Train Epoch: [159] [806400/1281167 (63%)]	Loss: 0.688700
[2022-04-07 02:56:52 | train] - Train Epoch: [159] [819200/1281167 (64%)]	Loss: 0.819071
[2022-04-07 02:57:20 | train] - Train Epoch: [159] [832000/1281167 (65%)]	Loss: 0.433800
[2022-04-07 02:57:48 | train] - Train Epoch: [159] [844800/1281167 (66%)]	Loss: 0.751971
[2022-04-07 02:58:16 | train] - Train Epoch: [159] [857600/1281167 (67%)]	Loss: 0.517894
[2022-04-07 02:58:44 | train] - Train Epoch: [159] [870400/1281167 (68%)]	Loss: 0.558667
[2022-04-07 02:59:12 | train] - Train Epoch: [159] [883200/1281167 (69%)]	Loss: 0.560700
[2022-04-07 02:59:40 | train] - Train Epoch: [159] [896000/1281167 (70%)]	Loss: 0.688859
[2022-04-07 03:00:09 | train] - Train Epoch: [159] [908800/1281167 (71%)]	Loss: 0.571793
[2022-04-07 03:00:36 | train] - Train Epoch: [159] [921600/1281167 (72%)]	Loss: 0.768832
[2022-04-07 03:01:04 | train] - Train Epoch: [159] [934400/1281167 (73%)]	Loss: 0.588773
[2022-04-07 03:01:32 | train] - Train Epoch: [159] [947200/1281167 (74%)]	Loss: 0.830458
[2022-04-07 03:02:01 | train] - Train Epoch: [159] [960000/1281167 (75%)]	Loss: 0.781336
[2022-04-07 03:02:28 | train] - Train Epoch: [159] [972800/1281167 (76%)]	Loss: 0.876284
[2022-04-07 03:02:56 | train] - Train Epoch: [159] [985600/1281167 (77%)]	Loss: 0.634518
[2022-04-07 03:03:24 | train] - Train Epoch: [159] [998400/1281167 (78%)]	Loss: 0.843910
[2022-04-07 03:03:52 | train] - Train Epoch: [159] [1011200/1281167 (79%)]	Loss: 0.650903
[2022-04-07 03:04:19 | train] - Train Epoch: [159] [1024000/1281167 (80%)]	Loss: 0.673735
[2022-04-07 03:04:47 | train] - Train Epoch: [159] [1036800/1281167 (81%)]	Loss: 0.600546
[2022-04-07 03:05:15 | train] - Train Epoch: [159] [1049600/1281167 (82%)]	Loss: 0.711013
[2022-04-07 03:05:43 | train] - Train Epoch: [159] [1062400/1281167 (83%)]	Loss: 0.565068
[2022-04-07 03:06:10 | train] - Train Epoch: [159] [1075200/1281167 (84%)]	Loss: 0.668674
[2022-04-07 03:06:39 | train] - Train Epoch: [159] [1088000/1281167 (85%)]	Loss: 0.638427
[2022-04-07 03:07:07 | train] - Train Epoch: [159] [1100800/1281167 (86%)]	Loss: 0.646148
[2022-04-07 03:07:35 | train] - Train Epoch: [159] [1113600/1281167 (87%)]	Loss: 0.776754
[2022-04-07 03:08:05 | train] - Train Epoch: [159] [1126400/1281167 (88%)]	Loss: 0.922061
[2022-04-07 03:08:32 | train] - Train Epoch: [159] [1139200/1281167 (89%)]	Loss: 0.538177
[2022-04-07 03:09:00 | train] - Train Epoch: [159] [1152000/1281167 (90%)]	Loss: 0.745950
[2022-04-07 03:09:29 | train] - Train Epoch: [159] [1164800/1281167 (91%)]	Loss: 0.695093
[2022-04-07 03:09:57 | train] - Train Epoch: [159] [1177600/1281167 (92%)]	Loss: 0.813809
[2022-04-07 03:10:25 | train] - Train Epoch: [159] [1190400/1281167 (93%)]	Loss: 0.665761
[2022-04-07 03:10:54 | train] - Train Epoch: [159] [1203200/1281167 (94%)]	Loss: 0.322504
[2022-04-07 03:11:23 | train] - Train Epoch: [159] [1216000/1281167 (95%)]	Loss: 0.716188
[2022-04-07 03:11:52 | train] - Train Epoch: [159] [1228800/1281167 (96%)]	Loss: 0.748339
[2022-04-07 03:12:21 | train] - Train Epoch: [159] [1241600/1281167 (97%)]	Loss: 0.522044
[2022-04-07 03:12:51 | train] - Train Epoch: [159] [1254400/1281167 (98%)]	Loss: 0.858089
[2022-04-07 03:13:19 | train] - Train Epoch: [159] [1267200/1281167 (99%)]	Loss: 0.692490
[2022-04-07 03:13:48 | train] - Train Epoch: [159] [1280000/1281167 (100%)]	Loss: 0.511710
[2022-04-07 03:13:51 | train] - Train Epoch: [159]	 Average Loss: 0.682111	 Total Acc : 83.4835	 Total Top5 Acc : 94.0359
[2022-04-07 03:13:51 | train] - -------159 epoch end-----------
========================================
-------159 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 03:15:45 | train] - 
Epoch [159] Test set: Average loss: 1.4477, Accuracy: 34905/50000 (69.7826%), Top-5 Accuracy: 88.7460%

[2022-04-07 03:15:45 | train] - save intermediate epoch [159] result


[2022-04-07 03:16:00 | train] - -------160 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 03:16:02 | train] - Train Epoch: [160] [0/1281167 (0%)]	Loss: 0.574073
[2022-04-07 03:16:30 | train] - Train Epoch: [160] [12800/1281167 (1%)]	Loss: 0.735024
[2022-04-07 03:16:57 | train] - Train Epoch: [160] [25600/1281167 (2%)]	Loss: 0.710569
[2022-04-07 03:17:25 | train] - Train Epoch: [160] [38400/1281167 (3%)]	Loss: 0.591721
[2022-04-07 03:17:52 | train] - Train Epoch: [160] [51200/1281167 (4%)]	Loss: 0.430236
[2022-04-07 03:18:19 | train] - Train Epoch: [160] [64000/1281167 (5%)]	Loss: 0.642478
[2022-04-07 03:18:47 | train] - Train Epoch: [160] [76800/1281167 (6%)]	Loss: 0.435208
[2022-04-07 03:19:15 | train] - Train Epoch: [160] [89600/1281167 (7%)]	Loss: 0.781084
[2022-04-07 03:19:42 | train] - Train Epoch: [160] [102400/1281167 (8%)]	Loss: 1.068758
[2022-04-07 03:20:10 | train] - Train Epoch: [160] [115200/1281167 (9%)]	Loss: 0.637930
[2022-04-07 03:20:38 | train] - Train Epoch: [160] [128000/1281167 (10%)]	Loss: 0.705485
[2022-04-07 03:21:05 | train] - Train Epoch: [160] [140800/1281167 (11%)]	Loss: 0.610987
[2022-04-07 03:21:32 | train] - Train Epoch: [160] [153600/1281167 (12%)]	Loss: 0.592273
[2022-04-07 03:22:01 | train] - Train Epoch: [160] [166400/1281167 (13%)]	Loss: 0.853247
[2022-04-07 03:22:28 | train] - Train Epoch: [160] [179200/1281167 (14%)]	Loss: 0.810170
[2022-04-07 03:22:56 | train] - Train Epoch: [160] [192000/1281167 (15%)]	Loss: 0.589846
[2022-04-07 03:23:23 | train] - Train Epoch: [160] [204800/1281167 (16%)]	Loss: 0.761750
[2022-04-07 03:23:51 | train] - Train Epoch: [160] [217600/1281167 (17%)]	Loss: 0.519520
[2022-04-07 03:24:18 | train] - Train Epoch: [160] [230400/1281167 (18%)]	Loss: 0.562615
[2022-04-07 03:24:45 | train] - Train Epoch: [160] [243200/1281167 (19%)]	Loss: 0.694187
[2022-04-07 03:25:12 | train] - Train Epoch: [160] [256000/1281167 (20%)]	Loss: 0.746666
[2022-04-07 03:25:39 | train] - Train Epoch: [160] [268800/1281167 (21%)]	Loss: 0.605301
[2022-04-07 03:26:06 | train] - Train Epoch: [160] [281600/1281167 (22%)]	Loss: 0.898905
[2022-04-07 03:26:33 | train] - Train Epoch: [160] [294400/1281167 (23%)]	Loss: 0.484143
[2022-04-07 03:27:00 | train] - Train Epoch: [160] [307200/1281167 (24%)]	Loss: 0.566979
[2022-04-07 03:27:28 | train] - Train Epoch: [160] [320000/1281167 (25%)]	Loss: 0.517484
[2022-04-07 03:27:55 | train] - Train Epoch: [160] [332800/1281167 (26%)]	Loss: 0.626424
[2022-04-07 03:28:22 | train] - Train Epoch: [160] [345600/1281167 (27%)]	Loss: 0.543426
[2022-04-07 03:28:50 | train] - Train Epoch: [160] [358400/1281167 (28%)]	Loss: 0.529635
[2022-04-07 03:29:16 | train] - Train Epoch: [160] [371200/1281167 (29%)]	Loss: 0.738337
[2022-04-07 03:29:45 | train] - Train Epoch: [160] [384000/1281167 (30%)]	Loss: 0.627800
[2022-04-07 03:30:13 | train] - Train Epoch: [160] [396800/1281167 (31%)]	Loss: 0.735001
[2022-04-07 03:30:40 | train] - Train Epoch: [160] [409600/1281167 (32%)]	Loss: 0.615096
[2022-04-07 03:31:07 | train] - Train Epoch: [160] [422400/1281167 (33%)]	Loss: 0.475467
[2022-04-07 03:31:34 | train] - Train Epoch: [160] [435200/1281167 (34%)]	Loss: 0.441259
[2022-04-07 03:32:02 | train] - Train Epoch: [160] [448000/1281167 (35%)]	Loss: 0.582706
[2022-04-07 03:32:28 | train] - Train Epoch: [160] [460800/1281167 (36%)]	Loss: 0.563585
[2022-04-07 03:32:56 | train] - Train Epoch: [160] [473600/1281167 (37%)]	Loss: 0.484302
[2022-04-07 03:33:23 | train] - Train Epoch: [160] [486400/1281167 (38%)]	Loss: 0.605162
[2022-04-07 03:33:49 | train] - Train Epoch: [160] [499200/1281167 (39%)]	Loss: 0.766002
[2022-04-07 03:34:16 | train] - Train Epoch: [160] [512000/1281167 (40%)]	Loss: 0.581385
[2022-04-07 03:34:43 | train] - Train Epoch: [160] [524800/1281167 (41%)]	Loss: 0.670352
[2022-04-07 03:35:11 | train] - Train Epoch: [160] [537600/1281167 (42%)]	Loss: 0.696155
[2022-04-07 03:35:38 | train] - Train Epoch: [160] [550400/1281167 (43%)]	Loss: 0.790215
[2022-04-07 03:36:05 | train] - Train Epoch: [160] [563200/1281167 (44%)]	Loss: 0.498037
[2022-04-07 03:36:31 | train] - Train Epoch: [160] [576000/1281167 (45%)]	Loss: 0.807112
[2022-04-07 03:36:59 | train] - Train Epoch: [160] [588800/1281167 (46%)]	Loss: 0.791853
[2022-04-07 03:37:26 | train] - Train Epoch: [160] [601600/1281167 (47%)]	Loss: 0.669306
[2022-04-07 03:37:53 | train] - Train Epoch: [160] [614400/1281167 (48%)]	Loss: 0.713322
[2022-04-07 03:38:21 | train] - Train Epoch: [160] [627200/1281167 (49%)]	Loss: 0.619517
[2022-04-07 03:38:49 | train] - Train Epoch: [160] [640000/1281167 (50%)]	Loss: 0.812594
[2022-04-07 03:39:18 | train] - Train Epoch: [160] [652800/1281167 (51%)]	Loss: 0.480875
[2022-04-07 03:39:45 | train] - Train Epoch: [160] [665600/1281167 (52%)]	Loss: 0.459278
[2022-04-07 03:40:12 | train] - Train Epoch: [160] [678400/1281167 (53%)]	Loss: 0.532321
[2022-04-07 03:40:41 | train] - Train Epoch: [160] [691200/1281167 (54%)]	Loss: 0.847431
[2022-04-07 03:41:08 | train] - Train Epoch: [160] [704000/1281167 (55%)]	Loss: 0.853637
[2022-04-07 03:41:36 | train] - Train Epoch: [160] [716800/1281167 (56%)]	Loss: 0.636531
[2022-04-07 03:42:03 | train] - Train Epoch: [160] [729600/1281167 (57%)]	Loss: 0.652377
[2022-04-07 03:42:31 | train] - Train Epoch: [160] [742400/1281167 (58%)]	Loss: 0.842500
[2022-04-07 03:42:58 | train] - Train Epoch: [160] [755200/1281167 (59%)]	Loss: 0.714422
[2022-04-07 03:43:25 | train] - Train Epoch: [160] [768000/1281167 (60%)]	Loss: 0.596917
[2022-04-07 03:43:52 | train] - Train Epoch: [160] [780800/1281167 (61%)]	Loss: 0.889584
[2022-04-07 03:44:19 | train] - Train Epoch: [160] [793600/1281167 (62%)]	Loss: 0.784208
[2022-04-07 03:44:46 | train] - Train Epoch: [160] [806400/1281167 (63%)]	Loss: 0.439270
[2022-04-07 03:45:14 | train] - Train Epoch: [160] [819200/1281167 (64%)]	Loss: 0.715954
[2022-04-07 03:45:41 | train] - Train Epoch: [160] [832000/1281167 (65%)]	Loss: 0.475340
[2022-04-07 03:46:08 | train] - Train Epoch: [160] [844800/1281167 (66%)]	Loss: 0.610026
[2022-04-07 03:46:35 | train] - Train Epoch: [160] [857600/1281167 (67%)]	Loss: 0.639851
[2022-04-07 03:47:02 | train] - Train Epoch: [160] [870400/1281167 (68%)]	Loss: 0.750654
[2022-04-07 03:47:30 | train] - Train Epoch: [160] [883200/1281167 (69%)]	Loss: 0.747680
[2022-04-07 03:47:58 | train] - Train Epoch: [160] [896000/1281167 (70%)]	Loss: 0.653977
[2022-04-07 03:48:26 | train] - Train Epoch: [160] [908800/1281167 (71%)]	Loss: 0.454467
[2022-04-07 03:48:53 | train] - Train Epoch: [160] [921600/1281167 (72%)]	Loss: 0.812076
[2022-04-07 03:49:21 | train] - Train Epoch: [160] [934400/1281167 (73%)]	Loss: 0.805311
[2022-04-07 03:49:48 | train] - Train Epoch: [160] [947200/1281167 (74%)]	Loss: 0.594583
[2022-04-07 03:50:16 | train] - Train Epoch: [160] [960000/1281167 (75%)]	Loss: 0.745172
[2022-04-07 03:50:44 | train] - Train Epoch: [160] [972800/1281167 (76%)]	Loss: 0.687793
[2022-04-07 03:51:12 | train] - Train Epoch: [160] [985600/1281167 (77%)]	Loss: 0.552456
[2022-04-07 03:51:40 | train] - Train Epoch: [160] [998400/1281167 (78%)]	Loss: 0.619487
[2022-04-07 03:52:09 | train] - Train Epoch: [160] [1011200/1281167 (79%)]	Loss: 0.535380
[2022-04-07 03:52:36 | train] - Train Epoch: [160] [1024000/1281167 (80%)]	Loss: 0.482930
[2022-04-07 03:53:05 | train] - Train Epoch: [160] [1036800/1281167 (81%)]	Loss: 0.712038
[2022-04-07 03:53:33 | train] - Train Epoch: [160] [1049600/1281167 (82%)]	Loss: 0.801095
[2022-04-07 03:54:01 | train] - Train Epoch: [160] [1062400/1281167 (83%)]	Loss: 0.512227
[2022-04-07 03:54:28 | train] - Train Epoch: [160] [1075200/1281167 (84%)]	Loss: 0.580454
[2022-04-07 03:54:57 | train] - Train Epoch: [160] [1088000/1281167 (85%)]	Loss: 0.646782
[2022-04-07 03:55:27 | train] - Train Epoch: [160] [1100800/1281167 (86%)]	Loss: 0.978217
[2022-04-07 03:55:55 | train] - Train Epoch: [160] [1113600/1281167 (87%)]	Loss: 0.711754
[2022-04-07 03:56:23 | train] - Train Epoch: [160] [1126400/1281167 (88%)]	Loss: 0.793025
[2022-04-07 03:56:52 | train] - Train Epoch: [160] [1139200/1281167 (89%)]	Loss: 0.734169
[2022-04-07 03:57:22 | train] - Train Epoch: [160] [1152000/1281167 (90%)]	Loss: 0.521691
[2022-04-07 03:57:50 | train] - Train Epoch: [160] [1164800/1281167 (91%)]	Loss: 0.815656
[2022-04-07 03:58:19 | train] - Train Epoch: [160] [1177600/1281167 (92%)]	Loss: 0.683312
[2022-04-07 03:58:47 | train] - Train Epoch: [160] [1190400/1281167 (93%)]	Loss: 0.717649
[2022-04-07 03:59:16 | train] - Train Epoch: [160] [1203200/1281167 (94%)]	Loss: 0.768974
[2022-04-07 03:59:44 | train] - Train Epoch: [160] [1216000/1281167 (95%)]	Loss: 0.673901
[2022-04-07 04:00:13 | train] - Train Epoch: [160] [1228800/1281167 (96%)]	Loss: 0.590040
[2022-04-07 04:00:42 | train] - Train Epoch: [160] [1241600/1281167 (97%)]	Loss: 0.449882
[2022-04-07 04:01:10 | train] - Train Epoch: [160] [1254400/1281167 (98%)]	Loss: 0.605976
[2022-04-07 04:01:38 | train] - Train Epoch: [160] [1267200/1281167 (99%)]	Loss: 0.662867
[2022-04-07 04:02:07 | train] - Train Epoch: [160] [1280000/1281167 (100%)]	Loss: 0.640132
[2022-04-07 04:02:09 | train] - Train Epoch: [160]	 Average Loss: 0.674547	 Total Acc : 83.6935	 Total Top5 Acc : 94.1266
[2022-04-07 04:02:09 | train] - -------160 epoch end-----------
========================================
-------160 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 04:04:09 | train] - 
Epoch [160] Test set: Average loss: 1.4542, Accuracy: 34915/50000 (69.8014%), Top-5 Accuracy: 88.6641%

[2022-04-07 04:04:09 | train] - save intermediate epoch [160] result


[2022-04-07 04:04:24 | train] - -------161 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 04:04:25 | train] - Train Epoch: [161] [0/1281167 (0%)]	Loss: 0.821802
[2022-04-07 04:04:53 | train] - Train Epoch: [161] [12800/1281167 (1%)]	Loss: 0.983053
[2022-04-07 04:05:20 | train] - Train Epoch: [161] [25600/1281167 (2%)]	Loss: 0.570870
[2022-04-07 04:05:47 | train] - Train Epoch: [161] [38400/1281167 (3%)]	Loss: 0.467619
[2022-04-07 04:06:16 | train] - Train Epoch: [161] [51200/1281167 (4%)]	Loss: 0.936995
[2022-04-07 04:06:43 | train] - Train Epoch: [161] [64000/1281167 (5%)]	Loss: 0.674657
[2022-04-07 04:07:10 | train] - Train Epoch: [161] [76800/1281167 (6%)]	Loss: 0.664867
[2022-04-07 04:07:37 | train] - Train Epoch: [161] [89600/1281167 (7%)]	Loss: 1.087835
[2022-04-07 04:08:05 | train] - Train Epoch: [161] [102400/1281167 (8%)]	Loss: 0.624298
[2022-04-07 04:08:32 | train] - Train Epoch: [161] [115200/1281167 (9%)]	Loss: 0.648665
[2022-04-07 04:09:00 | train] - Train Epoch: [161] [128000/1281167 (10%)]	Loss: 0.547470
[2022-04-07 04:09:29 | train] - Train Epoch: [161] [140800/1281167 (11%)]	Loss: 0.619397
[2022-04-07 04:09:56 | train] - Train Epoch: [161] [153600/1281167 (12%)]	Loss: 0.691933
[2022-04-07 04:10:23 | train] - Train Epoch: [161] [166400/1281167 (13%)]	Loss: 0.588172
[2022-04-07 04:10:50 | train] - Train Epoch: [161] [179200/1281167 (14%)]	Loss: 0.518900
[2022-04-07 04:11:18 | train] - Train Epoch: [161] [192000/1281167 (15%)]	Loss: 0.633378
[2022-04-07 04:11:46 | train] - Train Epoch: [161] [204800/1281167 (16%)]	Loss: 0.601445
[2022-04-07 04:12:13 | train] - Train Epoch: [161] [217600/1281167 (17%)]	Loss: 0.710892
[2022-04-07 04:12:40 | train] - Train Epoch: [161] [230400/1281167 (18%)]	Loss: 0.619533
[2022-04-07 04:13:07 | train] - Train Epoch: [161] [243200/1281167 (19%)]	Loss: 0.595606
[2022-04-07 04:13:34 | train] - Train Epoch: [161] [256000/1281167 (20%)]	Loss: 0.723712
[2022-04-07 04:14:01 | train] - Train Epoch: [161] [268800/1281167 (21%)]	Loss: 0.566123
[2022-04-07 04:14:29 | train] - Train Epoch: [161] [281600/1281167 (22%)]	Loss: 0.619734
[2022-04-07 04:14:56 | train] - Train Epoch: [161] [294400/1281167 (23%)]	Loss: 0.923384
[2022-04-07 04:15:24 | train] - Train Epoch: [161] [307200/1281167 (24%)]	Loss: 0.797452
[2022-04-07 04:15:51 | train] - Train Epoch: [161] [320000/1281167 (25%)]	Loss: 0.821504
[2022-04-07 04:16:18 | train] - Train Epoch: [161] [332800/1281167 (26%)]	Loss: 0.679035
[2022-04-07 04:16:46 | train] - Train Epoch: [161] [345600/1281167 (27%)]	Loss: 0.793264
[2022-04-07 04:17:13 | train] - Train Epoch: [161] [358400/1281167 (28%)]	Loss: 0.759360
[2022-04-07 04:17:41 | train] - Train Epoch: [161] [371200/1281167 (29%)]	Loss: 0.651400
[2022-04-07 04:18:09 | train] - Train Epoch: [161] [384000/1281167 (30%)]	Loss: 0.457579
[2022-04-07 04:18:36 | train] - Train Epoch: [161] [396800/1281167 (31%)]	Loss: 0.540501
[2022-04-07 04:19:04 | train] - Train Epoch: [161] [409600/1281167 (32%)]	Loss: 0.641737
[2022-04-07 04:19:32 | train] - Train Epoch: [161] [422400/1281167 (33%)]	Loss: 0.696887
[2022-04-07 04:19:59 | train] - Train Epoch: [161] [435200/1281167 (34%)]	Loss: 0.622129
[2022-04-07 04:20:27 | train] - Train Epoch: [161] [448000/1281167 (35%)]	Loss: 0.603810
[2022-04-07 04:20:54 | train] - Train Epoch: [161] [460800/1281167 (36%)]	Loss: 0.616409
[2022-04-07 04:21:23 | train] - Train Epoch: [161] [473600/1281167 (37%)]	Loss: 0.761538
[2022-04-07 04:21:50 | train] - Train Epoch: [161] [486400/1281167 (38%)]	Loss: 0.719309
[2022-04-07 04:22:18 | train] - Train Epoch: [161] [499200/1281167 (39%)]	Loss: 0.604166
[2022-04-07 04:22:45 | train] - Train Epoch: [161] [512000/1281167 (40%)]	Loss: 0.691027
[2022-04-07 04:23:12 | train] - Train Epoch: [161] [524800/1281167 (41%)]	Loss: 0.695632
[2022-04-07 04:23:40 | train] - Train Epoch: [161] [537600/1281167 (42%)]	Loss: 0.522235
[2022-04-07 04:24:08 | train] - Train Epoch: [161] [550400/1281167 (43%)]	Loss: 0.745200
[2022-04-07 04:24:36 | train] - Train Epoch: [161] [563200/1281167 (44%)]	Loss: 0.610148
[2022-04-07 04:25:03 | train] - Train Epoch: [161] [576000/1281167 (45%)]	Loss: 0.670901
[2022-04-07 04:25:31 | train] - Train Epoch: [161] [588800/1281167 (46%)]	Loss: 0.585291
[2022-04-07 04:25:58 | train] - Train Epoch: [161] [601600/1281167 (47%)]	Loss: 0.813594
[2022-04-07 04:26:25 | train] - Train Epoch: [161] [614400/1281167 (48%)]	Loss: 0.575533
[2022-04-07 04:26:53 | train] - Train Epoch: [161] [627200/1281167 (49%)]	Loss: 0.474760
[2022-04-07 04:27:19 | train] - Train Epoch: [161] [640000/1281167 (50%)]	Loss: 0.589487
[2022-04-07 04:27:46 | train] - Train Epoch: [161] [652800/1281167 (51%)]	Loss: 0.698098
[2022-04-07 04:28:15 | train] - Train Epoch: [161] [665600/1281167 (52%)]	Loss: 0.580429
[2022-04-07 04:28:42 | train] - Train Epoch: [161] [678400/1281167 (53%)]	Loss: 0.615316
[2022-04-07 04:29:10 | train] - Train Epoch: [161] [691200/1281167 (54%)]	Loss: 0.594572
[2022-04-07 04:29:38 | train] - Train Epoch: [161] [704000/1281167 (55%)]	Loss: 0.597858
[2022-04-07 04:30:06 | train] - Train Epoch: [161] [716800/1281167 (56%)]	Loss: 0.588390
[2022-04-07 04:30:33 | train] - Train Epoch: [161] [729600/1281167 (57%)]	Loss: 0.560448
[2022-04-07 04:31:01 | train] - Train Epoch: [161] [742400/1281167 (58%)]	Loss: 0.842194
[2022-04-07 04:31:28 | train] - Train Epoch: [161] [755200/1281167 (59%)]	Loss: 0.739466
[2022-04-07 04:31:55 | train] - Train Epoch: [161] [768000/1281167 (60%)]	Loss: 0.591097
[2022-04-07 04:32:23 | train] - Train Epoch: [161] [780800/1281167 (61%)]	Loss: 0.929958
[2022-04-07 04:32:51 | train] - Train Epoch: [161] [793600/1281167 (62%)]	Loss: 0.619934
[2022-04-07 04:33:18 | train] - Train Epoch: [161] [806400/1281167 (63%)]	Loss: 0.560693
[2022-04-07 04:33:46 | train] - Train Epoch: [161] [819200/1281167 (64%)]	Loss: 0.533819
[2022-04-07 04:34:13 | train] - Train Epoch: [161] [832000/1281167 (65%)]	Loss: 0.896509
[2022-04-07 04:34:40 | train] - Train Epoch: [161] [844800/1281167 (66%)]	Loss: 0.605790
[2022-04-07 04:35:08 | train] - Train Epoch: [161] [857600/1281167 (67%)]	Loss: 0.862089
[2022-04-07 04:35:35 | train] - Train Epoch: [161] [870400/1281167 (68%)]	Loss: 0.750908
[2022-04-07 04:36:03 | train] - Train Epoch: [161] [883200/1281167 (69%)]	Loss: 0.621252
[2022-04-07 04:36:31 | train] - Train Epoch: [161] [896000/1281167 (70%)]	Loss: 0.596834
[2022-04-07 04:36:58 | train] - Train Epoch: [161] [908800/1281167 (71%)]	Loss: 0.614240
[2022-04-07 04:37:25 | train] - Train Epoch: [161] [921600/1281167 (72%)]	Loss: 0.945784
[2022-04-07 04:37:53 | train] - Train Epoch: [161] [934400/1281167 (73%)]	Loss: 0.626890
[2022-04-07 04:38:22 | train] - Train Epoch: [161] [947200/1281167 (74%)]	Loss: 0.529006
[2022-04-07 04:38:50 | train] - Train Epoch: [161] [960000/1281167 (75%)]	Loss: 0.731969
[2022-04-07 04:39:17 | train] - Train Epoch: [161] [972800/1281167 (76%)]	Loss: 0.688402
[2022-04-07 04:39:46 | train] - Train Epoch: [161] [985600/1281167 (77%)]	Loss: 0.680597
[2022-04-07 04:40:13 | train] - Train Epoch: [161] [998400/1281167 (78%)]	Loss: 0.887201
[2022-04-07 04:40:42 | train] - Train Epoch: [161] [1011200/1281167 (79%)]	Loss: 0.665109
[2022-04-07 04:41:09 | train] - Train Epoch: [161] [1024000/1281167 (80%)]	Loss: 0.818161
[2022-04-07 04:41:37 | train] - Train Epoch: [161] [1036800/1281167 (81%)]	Loss: 0.565944
[2022-04-07 04:42:04 | train] - Train Epoch: [161] [1049600/1281167 (82%)]	Loss: 0.900517
[2022-04-07 04:42:33 | train] - Train Epoch: [161] [1062400/1281167 (83%)]	Loss: 0.542256
[2022-04-07 04:43:00 | train] - Train Epoch: [161] [1075200/1281167 (84%)]	Loss: 0.945684
[2022-04-07 04:43:28 | train] - Train Epoch: [161] [1088000/1281167 (85%)]	Loss: 0.809149
[2022-04-07 04:43:56 | train] - Train Epoch: [161] [1100800/1281167 (86%)]	Loss: 0.795594
[2022-04-07 04:44:24 | train] - Train Epoch: [161] [1113600/1281167 (87%)]	Loss: 0.482885
[2022-04-07 04:44:53 | train] - Train Epoch: [161] [1126400/1281167 (88%)]	Loss: 0.702331
[2022-04-07 04:45:21 | train] - Train Epoch: [161] [1139200/1281167 (89%)]	Loss: 0.654465
[2022-04-07 04:45:48 | train] - Train Epoch: [161] [1152000/1281167 (90%)]	Loss: 0.535811
[2022-04-07 04:46:18 | train] - Train Epoch: [161] [1164800/1281167 (91%)]	Loss: 0.565071
[2022-04-07 04:46:45 | train] - Train Epoch: [161] [1177600/1281167 (92%)]	Loss: 0.784620
[2022-04-07 04:47:13 | train] - Train Epoch: [161] [1190400/1281167 (93%)]	Loss: 0.588067
[2022-04-07 04:47:41 | train] - Train Epoch: [161] [1203200/1281167 (94%)]	Loss: 0.598844
[2022-04-07 04:48:10 | train] - Train Epoch: [161] [1216000/1281167 (95%)]	Loss: 0.558736
[2022-04-07 04:48:39 | train] - Train Epoch: [161] [1228800/1281167 (96%)]	Loss: 0.723008
[2022-04-07 04:49:07 | train] - Train Epoch: [161] [1241600/1281167 (97%)]	Loss: 0.640228
[2022-04-07 04:49:35 | train] - Train Epoch: [161] [1254400/1281167 (98%)]	Loss: 0.666840
[2022-04-07 04:50:03 | train] - Train Epoch: [161] [1267200/1281167 (99%)]	Loss: 0.804071
[2022-04-07 04:50:32 | train] - Train Epoch: [161] [1280000/1281167 (100%)]	Loss: 0.770532
[2022-04-07 04:50:34 | train] - Train Epoch: [161]	 Average Loss: 0.672810	 Total Acc : 83.7400	 Total Top5 Acc : 94.1288
[2022-04-07 04:50:34 | train] - -------161 epoch end-----------
========================================
-------161 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 04:52:34 | train] - 
Epoch [161] Test set: Average loss: 1.4661, Accuracy: 34888/50000 (69.7474%), Top-5 Accuracy: 88.6973%

[2022-04-07 04:52:34 | train] - save intermediate epoch [161] result


[2022-04-07 04:52:50 | train] - -------162 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 04:52:52 | train] - Train Epoch: [162] [0/1281167 (0%)]	Loss: 0.757249
[2022-04-07 04:53:20 | train] - Train Epoch: [162] [12800/1281167 (1%)]	Loss: 0.840426
[2022-04-07 04:53:49 | train] - Train Epoch: [162] [25600/1281167 (2%)]	Loss: 0.768860
[2022-04-07 04:54:17 | train] - Train Epoch: [162] [38400/1281167 (3%)]	Loss: 0.683741
[2022-04-07 04:54:44 | train] - Train Epoch: [162] [51200/1281167 (4%)]	Loss: 0.818435
[2022-04-07 04:55:11 | train] - Train Epoch: [162] [64000/1281167 (5%)]	Loss: 0.546612
[2022-04-07 04:55:39 | train] - Train Epoch: [162] [76800/1281167 (6%)]	Loss: 0.677181
[2022-04-07 04:56:07 | train] - Train Epoch: [162] [89600/1281167 (7%)]	Loss: 0.436337
[2022-04-07 04:56:34 | train] - Train Epoch: [162] [102400/1281167 (8%)]	Loss: 0.661596
[2022-04-07 04:57:01 | train] - Train Epoch: [162] [115200/1281167 (9%)]	Loss: 0.508900
[2022-04-07 04:57:28 | train] - Train Epoch: [162] [128000/1281167 (10%)]	Loss: 0.923816
[2022-04-07 04:57:56 | train] - Train Epoch: [162] [140800/1281167 (11%)]	Loss: 0.632939
[2022-04-07 04:58:24 | train] - Train Epoch: [162] [153600/1281167 (12%)]	Loss: 0.751499
[2022-04-07 04:58:51 | train] - Train Epoch: [162] [166400/1281167 (13%)]	Loss: 0.731487
[2022-04-07 04:59:19 | train] - Train Epoch: [162] [179200/1281167 (14%)]	Loss: 0.758658
[2022-04-07 04:59:46 | train] - Train Epoch: [162] [192000/1281167 (15%)]	Loss: 0.671008
[2022-04-07 05:00:15 | train] - Train Epoch: [162] [204800/1281167 (16%)]	Loss: 0.587041
[2022-04-07 05:00:42 | train] - Train Epoch: [162] [217600/1281167 (17%)]	Loss: 0.620477
[2022-04-07 05:01:08 | train] - Train Epoch: [162] [230400/1281167 (18%)]	Loss: 0.536783
[2022-04-07 05:01:36 | train] - Train Epoch: [162] [243200/1281167 (19%)]	Loss: 0.589162
[2022-04-07 05:02:05 | train] - Train Epoch: [162] [256000/1281167 (20%)]	Loss: 0.722700
[2022-04-07 05:02:32 | train] - Train Epoch: [162] [268800/1281167 (21%)]	Loss: 0.726204
[2022-04-07 05:02:58 | train] - Train Epoch: [162] [281600/1281167 (22%)]	Loss: 0.609253
[2022-04-07 05:03:26 | train] - Train Epoch: [162] [294400/1281167 (23%)]	Loss: 0.536559
[2022-04-07 05:03:53 | train] - Train Epoch: [162] [307200/1281167 (24%)]	Loss: 0.743393
[2022-04-07 05:04:20 | train] - Train Epoch: [162] [320000/1281167 (25%)]	Loss: 0.473495
[2022-04-07 05:04:46 | train] - Train Epoch: [162] [332800/1281167 (26%)]	Loss: 0.692050
[2022-04-07 05:05:14 | train] - Train Epoch: [162] [345600/1281167 (27%)]	Loss: 0.548401
[2022-04-07 05:05:40 | train] - Train Epoch: [162] [358400/1281167 (28%)]	Loss: 0.483382
[2022-04-07 05:06:08 | train] - Train Epoch: [162] [371200/1281167 (29%)]	Loss: 0.775020
[2022-04-07 05:06:35 | train] - Train Epoch: [162] [384000/1281167 (30%)]	Loss: 0.686611
[2022-04-07 05:07:01 | train] - Train Epoch: [162] [396800/1281167 (31%)]	Loss: 0.487624
[2022-04-07 05:07:29 | train] - Train Epoch: [162] [409600/1281167 (32%)]	Loss: 0.503912
[2022-04-07 05:07:56 | train] - Train Epoch: [162] [422400/1281167 (33%)]	Loss: 0.683744
[2022-04-07 05:08:22 | train] - Train Epoch: [162] [435200/1281167 (34%)]	Loss: 0.646108
[2022-04-07 05:08:49 | train] - Train Epoch: [162] [448000/1281167 (35%)]	Loss: 0.656317
[2022-04-07 05:09:16 | train] - Train Epoch: [162] [460800/1281167 (36%)]	Loss: 0.602672
[2022-04-07 05:09:43 | train] - Train Epoch: [162] [473600/1281167 (37%)]	Loss: 0.773287
[2022-04-07 05:10:11 | train] - Train Epoch: [162] [486400/1281167 (38%)]	Loss: 0.626359
[2022-04-07 05:10:38 | train] - Train Epoch: [162] [499200/1281167 (39%)]	Loss: 0.872319
[2022-04-07 05:11:04 | train] - Train Epoch: [162] [512000/1281167 (40%)]	Loss: 0.489867
[2022-04-07 05:11:32 | train] - Train Epoch: [162] [524800/1281167 (41%)]	Loss: 0.618396
[2022-04-07 05:11:59 | train] - Train Epoch: [162] [537600/1281167 (42%)]	Loss: 0.753163
[2022-04-07 05:12:25 | train] - Train Epoch: [162] [550400/1281167 (43%)]	Loss: 0.561402
[2022-04-07 05:12:52 | train] - Train Epoch: [162] [563200/1281167 (44%)]	Loss: 0.499039
[2022-04-07 05:13:20 | train] - Train Epoch: [162] [576000/1281167 (45%)]	Loss: 0.387638
[2022-04-07 05:13:47 | train] - Train Epoch: [162] [588800/1281167 (46%)]	Loss: 1.080027
[2022-04-07 05:14:14 | train] - Train Epoch: [162] [601600/1281167 (47%)]	Loss: 0.612965
[2022-04-07 05:14:42 | train] - Train Epoch: [162] [614400/1281167 (48%)]	Loss: 0.623923
[2022-04-07 05:15:09 | train] - Train Epoch: [162] [627200/1281167 (49%)]	Loss: 0.606474
[2022-04-07 05:15:38 | train] - Train Epoch: [162] [640000/1281167 (50%)]	Loss: 0.586554
[2022-04-07 05:16:06 | train] - Train Epoch: [162] [652800/1281167 (51%)]	Loss: 0.759796
[2022-04-07 05:16:34 | train] - Train Epoch: [162] [665600/1281167 (52%)]	Loss: 0.641941
[2022-04-07 05:17:02 | train] - Train Epoch: [162] [678400/1281167 (53%)]	Loss: 0.682166
[2022-04-07 05:17:28 | train] - Train Epoch: [162] [691200/1281167 (54%)]	Loss: 0.522228
[2022-04-07 05:17:55 | train] - Train Epoch: [162] [704000/1281167 (55%)]	Loss: 0.755900
[2022-04-07 05:18:24 | train] - Train Epoch: [162] [716800/1281167 (56%)]	Loss: 0.487157
[2022-04-07 05:18:52 | train] - Train Epoch: [162] [729600/1281167 (57%)]	Loss: 0.738847
[2022-04-07 05:19:20 | train] - Train Epoch: [162] [742400/1281167 (58%)]	Loss: 0.711564
[2022-04-07 05:19:48 | train] - Train Epoch: [162] [755200/1281167 (59%)]	Loss: 0.700190
[2022-04-07 05:20:16 | train] - Train Epoch: [162] [768000/1281167 (60%)]	Loss: 0.464622
[2022-04-07 05:20:43 | train] - Train Epoch: [162] [780800/1281167 (61%)]	Loss: 0.799629
[2022-04-07 05:21:10 | train] - Train Epoch: [162] [793600/1281167 (62%)]	Loss: 0.671002
[2022-04-07 05:21:37 | train] - Train Epoch: [162] [806400/1281167 (63%)]	Loss: 0.808320
[2022-04-07 05:22:04 | train] - Train Epoch: [162] [819200/1281167 (64%)]	Loss: 0.676523
[2022-04-07 05:22:32 | train] - Train Epoch: [162] [832000/1281167 (65%)]	Loss: 0.618123
[2022-04-07 05:23:00 | train] - Train Epoch: [162] [844800/1281167 (66%)]	Loss: 0.627022
[2022-04-07 05:23:28 | train] - Train Epoch: [162] [857600/1281167 (67%)]	Loss: 0.559412
[2022-04-07 05:23:54 | train] - Train Epoch: [162] [870400/1281167 (68%)]	Loss: 0.571946
[2022-04-07 05:24:22 | train] - Train Epoch: [162] [883200/1281167 (69%)]	Loss: 0.584304
[2022-04-07 05:24:49 | train] - Train Epoch: [162] [896000/1281167 (70%)]	Loss: 0.938268
[2022-04-07 05:25:17 | train] - Train Epoch: [162] [908800/1281167 (71%)]	Loss: 0.576912
[2022-04-07 05:25:44 | train] - Train Epoch: [162] [921600/1281167 (72%)]	Loss: 0.600019
[2022-04-07 05:26:12 | train] - Train Epoch: [162] [934400/1281167 (73%)]	Loss: 0.694886
[2022-04-07 05:26:39 | train] - Train Epoch: [162] [947200/1281167 (74%)]	Loss: 0.806285
[2022-04-07 05:27:07 | train] - Train Epoch: [162] [960000/1281167 (75%)]	Loss: 0.764680
[2022-04-07 05:27:34 | train] - Train Epoch: [162] [972800/1281167 (76%)]	Loss: 0.613837
[2022-04-07 05:28:01 | train] - Train Epoch: [162] [985600/1281167 (77%)]	Loss: 0.586357
[2022-04-07 05:28:28 | train] - Train Epoch: [162] [998400/1281167 (78%)]	Loss: 0.777244
[2022-04-07 05:28:55 | train] - Train Epoch: [162] [1011200/1281167 (79%)]	Loss: 0.705739
[2022-04-07 05:29:22 | train] - Train Epoch: [162] [1024000/1281167 (80%)]	Loss: 0.988185
[2022-04-07 05:29:50 | train] - Train Epoch: [162] [1036800/1281167 (81%)]	Loss: 0.451578
[2022-04-07 05:30:17 | train] - Train Epoch: [162] [1049600/1281167 (82%)]	Loss: 0.604668
[2022-04-07 05:30:45 | train] - Train Epoch: [162] [1062400/1281167 (83%)]	Loss: 0.575253
[2022-04-07 05:31:13 | train] - Train Epoch: [162] [1075200/1281167 (84%)]	Loss: 0.611666
[2022-04-07 05:31:41 | train] - Train Epoch: [162] [1088000/1281167 (85%)]	Loss: 0.732037
[2022-04-07 05:32:08 | train] - Train Epoch: [162] [1100800/1281167 (86%)]	Loss: 0.639011
[2022-04-07 05:32:36 | train] - Train Epoch: [162] [1113600/1281167 (87%)]	Loss: 0.575064
[2022-04-07 05:33:03 | train] - Train Epoch: [162] [1126400/1281167 (88%)]	Loss: 0.769668
[2022-04-07 05:33:32 | train] - Train Epoch: [162] [1139200/1281167 (89%)]	Loss: 0.829873
[2022-04-07 05:34:00 | train] - Train Epoch: [162] [1152000/1281167 (90%)]	Loss: 0.683729
[2022-04-07 05:34:28 | train] - Train Epoch: [162] [1164800/1281167 (91%)]	Loss: 0.697373
[2022-04-07 05:34:56 | train] - Train Epoch: [162] [1177600/1281167 (92%)]	Loss: 0.687377
[2022-04-07 05:35:24 | train] - Train Epoch: [162] [1190400/1281167 (93%)]	Loss: 0.546573
[2022-04-07 05:35:52 | train] - Train Epoch: [162] [1203200/1281167 (94%)]	Loss: 0.627775
[2022-04-07 05:36:21 | train] - Train Epoch: [162] [1216000/1281167 (95%)]	Loss: 0.600686
[2022-04-07 05:36:49 | train] - Train Epoch: [162] [1228800/1281167 (96%)]	Loss: 0.533394
[2022-04-07 05:37:17 | train] - Train Epoch: [162] [1241600/1281167 (97%)]	Loss: 0.671700
[2022-04-07 05:37:45 | train] - Train Epoch: [162] [1254400/1281167 (98%)]	Loss: 0.666842
[2022-04-07 05:38:14 | train] - Train Epoch: [162] [1267200/1281167 (99%)]	Loss: 0.601567
[2022-04-07 05:38:43 | train] - Train Epoch: [162] [1280000/1281167 (100%)]	Loss: 0.503151
[2022-04-07 05:38:45 | train] - Train Epoch: [162]	 Average Loss: 0.669481	 Total Acc : 83.8290	 Total Top5 Acc : 94.1677
[2022-04-07 05:38:45 | train] - -------162 epoch end-----------
========================================
-------162 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 05:40:42 | train] - 
Epoch [162] Test set: Average loss: 1.4531, Accuracy: 34932/50000 (69.8366%), Top-5 Accuracy: 88.6773%

[2022-04-07 05:40:42 | train] - save intermediate epoch [162] result


[2022-04-07 05:40:58 | train] - -------163 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 05:41:00 | train] - Train Epoch: [163] [0/1281167 (0%)]	Loss: 0.690599
[2022-04-07 05:41:27 | train] - Train Epoch: [163] [12800/1281167 (1%)]	Loss: 0.842667
[2022-04-07 05:41:55 | train] - Train Epoch: [163] [25600/1281167 (2%)]	Loss: 0.836008
[2022-04-07 05:42:23 | train] - Train Epoch: [163] [38400/1281167 (3%)]	Loss: 0.603497
[2022-04-07 05:42:50 | train] - Train Epoch: [163] [51200/1281167 (4%)]	Loss: 0.513701
[2022-04-07 05:43:18 | train] - Train Epoch: [163] [64000/1281167 (5%)]	Loss: 0.563366
[2022-04-07 05:43:45 | train] - Train Epoch: [163] [76800/1281167 (6%)]	Loss: 0.559972
[2022-04-07 05:44:12 | train] - Train Epoch: [163] [89600/1281167 (7%)]	Loss: 0.670954
[2022-04-07 05:44:39 | train] - Train Epoch: [163] [102400/1281167 (8%)]	Loss: 0.700636
[2022-04-07 05:45:06 | train] - Train Epoch: [163] [115200/1281167 (9%)]	Loss: 0.543885
[2022-04-07 05:45:33 | train] - Train Epoch: [163] [128000/1281167 (10%)]	Loss: 0.677462
[2022-04-07 05:46:01 | train] - Train Epoch: [163] [140800/1281167 (11%)]	Loss: 0.616390
[2022-04-07 05:46:28 | train] - Train Epoch: [163] [153600/1281167 (12%)]	Loss: 0.424194
[2022-04-07 05:46:55 | train] - Train Epoch: [163] [166400/1281167 (13%)]	Loss: 0.638860
[2022-04-07 05:47:22 | train] - Train Epoch: [163] [179200/1281167 (14%)]	Loss: 0.492653
[2022-04-07 05:47:49 | train] - Train Epoch: [163] [192000/1281167 (15%)]	Loss: 0.366864
[2022-04-07 05:48:18 | train] - Train Epoch: [163] [204800/1281167 (16%)]	Loss: 0.661863
[2022-04-07 05:48:46 | train] - Train Epoch: [163] [217600/1281167 (17%)]	Loss: 0.929630
[2022-04-07 05:49:13 | train] - Train Epoch: [163] [230400/1281167 (18%)]	Loss: 0.864193
[2022-04-07 05:49:41 | train] - Train Epoch: [163] [243200/1281167 (19%)]	Loss: 0.454933
[2022-04-07 05:50:10 | train] - Train Epoch: [163] [256000/1281167 (20%)]	Loss: 0.629197
[2022-04-07 05:50:38 | train] - Train Epoch: [163] [268800/1281167 (21%)]	Loss: 0.538541
[2022-04-07 05:51:05 | train] - Train Epoch: [163] [281600/1281167 (22%)]	Loss: 0.632522
[2022-04-07 05:51:32 | train] - Train Epoch: [163] [294400/1281167 (23%)]	Loss: 0.762546
[2022-04-07 05:51:59 | train] - Train Epoch: [163] [307200/1281167 (24%)]	Loss: 0.629112
[2022-04-07 05:52:27 | train] - Train Epoch: [163] [320000/1281167 (25%)]	Loss: 0.818164
[2022-04-07 05:52:55 | train] - Train Epoch: [163] [332800/1281167 (26%)]	Loss: 0.672233
[2022-04-07 05:53:23 | train] - Train Epoch: [163] [345600/1281167 (27%)]	Loss: 0.548779
[2022-04-07 05:53:50 | train] - Train Epoch: [163] [358400/1281167 (28%)]	Loss: 0.424708
[2022-04-07 05:54:18 | train] - Train Epoch: [163] [371200/1281167 (29%)]	Loss: 0.600844
[2022-04-07 05:54:46 | train] - Train Epoch: [163] [384000/1281167 (30%)]	Loss: 0.580319
[2022-04-07 05:55:13 | train] - Train Epoch: [163] [396800/1281167 (31%)]	Loss: 0.652992
[2022-04-07 05:55:41 | train] - Train Epoch: [163] [409600/1281167 (32%)]	Loss: 0.732211
[2022-04-07 05:56:09 | train] - Train Epoch: [163] [422400/1281167 (33%)]	Loss: 0.650305
[2022-04-07 05:56:37 | train] - Train Epoch: [163] [435200/1281167 (34%)]	Loss: 0.736461
[2022-04-07 05:57:05 | train] - Train Epoch: [163] [448000/1281167 (35%)]	Loss: 0.784601
[2022-04-07 05:57:33 | train] - Train Epoch: [163] [460800/1281167 (36%)]	Loss: 0.628165
[2022-04-07 05:58:01 | train] - Train Epoch: [163] [473600/1281167 (37%)]	Loss: 0.573987
[2022-04-07 05:58:29 | train] - Train Epoch: [163] [486400/1281167 (38%)]	Loss: 0.616126
[2022-04-07 05:58:57 | train] - Train Epoch: [163] [499200/1281167 (39%)]	Loss: 0.455265
[2022-04-07 05:59:24 | train] - Train Epoch: [163] [512000/1281167 (40%)]	Loss: 0.675315
[2022-04-07 05:59:52 | train] - Train Epoch: [163] [524800/1281167 (41%)]	Loss: 0.804790
[2022-04-07 06:00:19 | train] - Train Epoch: [163] [537600/1281167 (42%)]	Loss: 0.669520
[2022-04-07 06:00:48 | train] - Train Epoch: [163] [550400/1281167 (43%)]	Loss: 0.587786
[2022-04-07 06:01:18 | train] - Train Epoch: [163] [563200/1281167 (44%)]	Loss: 0.884337
[2022-04-07 06:01:46 | train] - Train Epoch: [163] [576000/1281167 (45%)]	Loss: 0.933698
[2022-04-07 06:02:13 | train] - Train Epoch: [163] [588800/1281167 (46%)]	Loss: 0.585462
[2022-04-07 06:02:41 | train] - Train Epoch: [163] [601600/1281167 (47%)]	Loss: 0.607130
[2022-04-07 06:03:09 | train] - Train Epoch: [163] [614400/1281167 (48%)]	Loss: 0.690776
[2022-04-07 06:03:36 | train] - Train Epoch: [163] [627200/1281167 (49%)]	Loss: 0.722866
[2022-04-07 06:04:04 | train] - Train Epoch: [163] [640000/1281167 (50%)]	Loss: 0.497472
[2022-04-07 06:04:32 | train] - Train Epoch: [163] [652800/1281167 (51%)]	Loss: 0.860168
[2022-04-07 06:05:00 | train] - Train Epoch: [163] [665600/1281167 (52%)]	Loss: 0.492724
[2022-04-07 06:05:28 | train] - Train Epoch: [163] [678400/1281167 (53%)]	Loss: 0.699090
[2022-04-07 06:05:56 | train] - Train Epoch: [163] [691200/1281167 (54%)]	Loss: 0.702869
[2022-04-07 06:06:24 | train] - Train Epoch: [163] [704000/1281167 (55%)]	Loss: 0.459031
[2022-04-07 06:06:52 | train] - Train Epoch: [163] [716800/1281167 (56%)]	Loss: 0.554414
[2022-04-07 06:07:20 | train] - Train Epoch: [163] [729600/1281167 (57%)]	Loss: 0.759500
[2022-04-07 06:07:48 | train] - Train Epoch: [163] [742400/1281167 (58%)]	Loss: 0.641913
[2022-04-07 06:08:15 | train] - Train Epoch: [163] [755200/1281167 (59%)]	Loss: 0.762431
[2022-04-07 06:08:43 | train] - Train Epoch: [163] [768000/1281167 (60%)]	Loss: 0.745475
[2022-04-07 06:09:11 | train] - Train Epoch: [163] [780800/1281167 (61%)]	Loss: 0.685479
[2022-04-07 06:09:38 | train] - Train Epoch: [163] [793600/1281167 (62%)]	Loss: 0.588027
[2022-04-07 06:10:06 | train] - Train Epoch: [163] [806400/1281167 (63%)]	Loss: 0.570119
[2022-04-07 06:10:34 | train] - Train Epoch: [163] [819200/1281167 (64%)]	Loss: 0.915586
[2022-04-07 06:11:02 | train] - Train Epoch: [163] [832000/1281167 (65%)]	Loss: 0.706671
[2022-04-07 06:11:30 | train] - Train Epoch: [163] [844800/1281167 (66%)]	Loss: 0.583487
[2022-04-07 06:11:58 | train] - Train Epoch: [163] [857600/1281167 (67%)]	Loss: 0.860981
[2022-04-07 06:12:26 | train] - Train Epoch: [163] [870400/1281167 (68%)]	Loss: 0.768106
[2022-04-07 06:12:54 | train] - Train Epoch: [163] [883200/1281167 (69%)]	Loss: 0.695700
[2022-04-07 06:13:22 | train] - Train Epoch: [163] [896000/1281167 (70%)]	Loss: 0.658251
[2022-04-07 06:13:49 | train] - Train Epoch: [163] [908800/1281167 (71%)]	Loss: 0.581747
[2022-04-07 06:14:17 | train] - Train Epoch: [163] [921600/1281167 (72%)]	Loss: 0.696281
[2022-04-07 06:14:45 | train] - Train Epoch: [163] [934400/1281167 (73%)]	Loss: 0.657315
[2022-04-07 06:15:15 | train] - Train Epoch: [163] [947200/1281167 (74%)]	Loss: 0.891632
[2022-04-07 06:15:43 | train] - Train Epoch: [163] [960000/1281167 (75%)]	Loss: 0.588278
[2022-04-07 06:16:11 | train] - Train Epoch: [163] [972800/1281167 (76%)]	Loss: 0.799672
[2022-04-07 06:16:39 | train] - Train Epoch: [163] [985600/1281167 (77%)]	Loss: 0.811526
[2022-04-07 06:17:07 | train] - Train Epoch: [163] [998400/1281167 (78%)]	Loss: 0.478923
[2022-04-07 06:17:34 | train] - Train Epoch: [163] [1011200/1281167 (79%)]	Loss: 0.704781
[2022-04-07 06:18:01 | train] - Train Epoch: [163] [1024000/1281167 (80%)]	Loss: 0.524971
[2022-04-07 06:18:28 | train] - Train Epoch: [163] [1036800/1281167 (81%)]	Loss: 0.640870
[2022-04-07 06:18:55 | train] - Train Epoch: [163] [1049600/1281167 (82%)]	Loss: 0.504696
[2022-04-07 06:19:22 | train] - Train Epoch: [163] [1062400/1281167 (83%)]	Loss: 1.074565
[2022-04-07 06:19:50 | train] - Train Epoch: [163] [1075200/1281167 (84%)]	Loss: 0.523873
[2022-04-07 06:20:18 | train] - Train Epoch: [163] [1088000/1281167 (85%)]	Loss: 0.594327
[2022-04-07 06:20:46 | train] - Train Epoch: [163] [1100800/1281167 (86%)]	Loss: 0.828118
[2022-04-07 06:21:14 | train] - Train Epoch: [163] [1113600/1281167 (87%)]	Loss: 0.547208
[2022-04-07 06:21:41 | train] - Train Epoch: [163] [1126400/1281167 (88%)]	Loss: 0.518465
[2022-04-07 06:22:09 | train] - Train Epoch: [163] [1139200/1281167 (89%)]	Loss: 0.644611
[2022-04-07 06:22:36 | train] - Train Epoch: [163] [1152000/1281167 (90%)]	Loss: 0.681419
[2022-04-07 06:23:05 | train] - Train Epoch: [163] [1164800/1281167 (91%)]	Loss: 0.596000
[2022-04-07 06:23:33 | train] - Train Epoch: [163] [1177600/1281167 (92%)]	Loss: 0.698376
[2022-04-07 06:24:00 | train] - Train Epoch: [163] [1190400/1281167 (93%)]	Loss: 0.838848
[2022-04-07 06:24:29 | train] - Train Epoch: [163] [1203200/1281167 (94%)]	Loss: 1.120421
[2022-04-07 06:24:56 | train] - Train Epoch: [163] [1216000/1281167 (95%)]	Loss: 0.524768
[2022-04-07 06:25:25 | train] - Train Epoch: [163] [1228800/1281167 (96%)]	Loss: 0.361527
[2022-04-07 06:25:53 | train] - Train Epoch: [163] [1241600/1281167 (97%)]	Loss: 0.553592
[2022-04-07 06:26:21 | train] - Train Epoch: [163] [1254400/1281167 (98%)]	Loss: 0.749687
[2022-04-07 06:26:50 | train] - Train Epoch: [163] [1267200/1281167 (99%)]	Loss: 0.720274
[2022-04-07 06:27:18 | train] - Train Epoch: [163] [1280000/1281167 (100%)]	Loss: 0.674022
[2022-04-07 06:27:20 | train] - Train Epoch: [163]	 Average Loss: 0.666775	 Total Acc : 83.8879	 Total Top5 Acc : 94.1728
[2022-04-07 06:27:20 | train] - -------163 epoch end-----------
========================================
-------163 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 06:29:18 | train] - 
Epoch [163] Test set: Average loss: 1.4615, Accuracy: 34871/50000 (69.7123%), Top-5 Accuracy: 88.7180%

[2022-04-07 06:29:18 | train] - save intermediate epoch [163] result


[2022-04-07 06:29:34 | train] - -------164 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 06:29:35 | train] - Train Epoch: [164] [0/1281167 (0%)]	Loss: 0.652089
[2022-04-07 06:30:02 | train] - Train Epoch: [164] [12800/1281167 (1%)]	Loss: 0.505439
[2022-04-07 06:30:29 | train] - Train Epoch: [164] [25600/1281167 (2%)]	Loss: 0.537674
[2022-04-07 06:30:57 | train] - Train Epoch: [164] [38400/1281167 (3%)]	Loss: 0.828538
[2022-04-07 06:31:24 | train] - Train Epoch: [164] [51200/1281167 (4%)]	Loss: 0.871222
[2022-04-07 06:31:52 | train] - Train Epoch: [164] [64000/1281167 (5%)]	Loss: 0.680678
[2022-04-07 06:32:19 | train] - Train Epoch: [164] [76800/1281167 (6%)]	Loss: 0.673857
[2022-04-07 06:32:46 | train] - Train Epoch: [164] [89600/1281167 (7%)]	Loss: 0.924504
[2022-04-07 06:33:13 | train] - Train Epoch: [164] [102400/1281167 (8%)]	Loss: 0.454076
[2022-04-07 06:33:41 | train] - Train Epoch: [164] [115200/1281167 (9%)]	Loss: 0.658263
[2022-04-07 06:34:09 | train] - Train Epoch: [164] [128000/1281167 (10%)]	Loss: 0.676103
[2022-04-07 06:34:37 | train] - Train Epoch: [164] [140800/1281167 (11%)]	Loss: 0.789283
[2022-04-07 06:35:03 | train] - Train Epoch: [164] [153600/1281167 (12%)]	Loss: 0.677360
[2022-04-07 06:35:31 | train] - Train Epoch: [164] [166400/1281167 (13%)]	Loss: 0.555962
[2022-04-07 06:35:58 | train] - Train Epoch: [164] [179200/1281167 (14%)]	Loss: 0.554800
[2022-04-07 06:36:26 | train] - Train Epoch: [164] [192000/1281167 (15%)]	Loss: 0.625111
[2022-04-07 06:36:53 | train] - Train Epoch: [164] [204800/1281167 (16%)]	Loss: 0.526411
[2022-04-07 06:37:21 | train] - Train Epoch: [164] [217600/1281167 (17%)]	Loss: 0.893248
[2022-04-07 06:37:48 | train] - Train Epoch: [164] [230400/1281167 (18%)]	Loss: 0.802962
[2022-04-07 06:38:16 | train] - Train Epoch: [164] [243200/1281167 (19%)]	Loss: 0.838431
[2022-04-07 06:38:44 | train] - Train Epoch: [164] [256000/1281167 (20%)]	Loss: 0.795415
[2022-04-07 06:39:12 | train] - Train Epoch: [164] [268800/1281167 (21%)]	Loss: 0.622250
[2022-04-07 06:39:40 | train] - Train Epoch: [164] [281600/1281167 (22%)]	Loss: 0.635282
[2022-04-07 06:40:08 | train] - Train Epoch: [164] [294400/1281167 (23%)]	Loss: 0.600609
[2022-04-07 06:40:36 | train] - Train Epoch: [164] [307200/1281167 (24%)]	Loss: 0.581923
[2022-04-07 06:41:04 | train] - Train Epoch: [164] [320000/1281167 (25%)]	Loss: 0.399398
[2022-04-07 06:41:32 | train] - Train Epoch: [164] [332800/1281167 (26%)]	Loss: 0.858909
[2022-04-07 06:41:59 | train] - Train Epoch: [164] [345600/1281167 (27%)]	Loss: 0.638929
[2022-04-07 06:42:26 | train] - Train Epoch: [164] [358400/1281167 (28%)]	Loss: 0.616939
[2022-04-07 06:42:53 | train] - Train Epoch: [164] [371200/1281167 (29%)]	Loss: 0.798447
[2022-04-07 06:43:21 | train] - Train Epoch: [164] [384000/1281167 (30%)]	Loss: 0.769165
[2022-04-07 06:43:49 | train] - Train Epoch: [164] [396800/1281167 (31%)]	Loss: 0.813306
[2022-04-07 06:44:15 | train] - Train Epoch: [164] [409600/1281167 (32%)]	Loss: 0.627394
[2022-04-07 06:44:42 | train] - Train Epoch: [164] [422400/1281167 (33%)]	Loss: 0.698889
[2022-04-07 06:45:10 | train] - Train Epoch: [164] [435200/1281167 (34%)]	Loss: 0.732463
[2022-04-07 06:45:36 | train] - Train Epoch: [164] [448000/1281167 (35%)]	Loss: 0.435779
[2022-04-07 06:46:03 | train] - Train Epoch: [164] [460800/1281167 (36%)]	Loss: 0.901959
[2022-04-07 06:46:30 | train] - Train Epoch: [164] [473600/1281167 (37%)]	Loss: 0.465999
[2022-04-07 06:46:58 | train] - Train Epoch: [164] [486400/1281167 (38%)]	Loss: 0.608459
[2022-04-07 06:47:25 | train] - Train Epoch: [164] [499200/1281167 (39%)]	Loss: 0.646510
[2022-04-07 06:47:53 | train] - Train Epoch: [164] [512000/1281167 (40%)]	Loss: 0.630534
[2022-04-07 06:48:20 | train] - Train Epoch: [164] [524800/1281167 (41%)]	Loss: 0.549095
[2022-04-07 06:48:48 | train] - Train Epoch: [164] [537600/1281167 (42%)]	Loss: 0.693866
[2022-04-07 06:49:15 | train] - Train Epoch: [164] [550400/1281167 (43%)]	Loss: 0.503333
[2022-04-07 06:49:42 | train] - Train Epoch: [164] [563200/1281167 (44%)]	Loss: 0.611328
[2022-04-07 06:50:10 | train] - Train Epoch: [164] [576000/1281167 (45%)]	Loss: 0.635453
[2022-04-07 06:50:37 | train] - Train Epoch: [164] [588800/1281167 (46%)]	Loss: 0.722251
[2022-04-07 06:51:04 | train] - Train Epoch: [164] [601600/1281167 (47%)]	Loss: 0.495483
[2022-04-07 06:51:31 | train] - Train Epoch: [164] [614400/1281167 (48%)]	Loss: 0.812023
[2022-04-07 06:51:58 | train] - Train Epoch: [164] [627200/1281167 (49%)]	Loss: 0.901137
[2022-04-07 06:52:25 | train] - Train Epoch: [164] [640000/1281167 (50%)]	Loss: 0.548280
[2022-04-07 06:52:53 | train] - Train Epoch: [164] [652800/1281167 (51%)]	Loss: 0.514663
[2022-04-07 06:53:21 | train] - Train Epoch: [164] [665600/1281167 (52%)]	Loss: 0.630782
[2022-04-07 06:53:49 | train] - Train Epoch: [164] [678400/1281167 (53%)]	Loss: 0.623330
[2022-04-07 06:54:16 | train] - Train Epoch: [164] [691200/1281167 (54%)]	Loss: 0.748862
[2022-04-07 06:54:44 | train] - Train Epoch: [164] [704000/1281167 (55%)]	Loss: 0.520716
[2022-04-07 06:55:12 | train] - Train Epoch: [164] [716800/1281167 (56%)]	Loss: 0.789729
[2022-04-07 06:55:40 | train] - Train Epoch: [164] [729600/1281167 (57%)]	Loss: 0.690764
[2022-04-07 06:56:07 | train] - Train Epoch: [164] [742400/1281167 (58%)]	Loss: 0.490339
[2022-04-07 06:56:35 | train] - Train Epoch: [164] [755200/1281167 (59%)]	Loss: 0.604502
[2022-04-07 06:57:03 | train] - Train Epoch: [164] [768000/1281167 (60%)]	Loss: 0.894003
[2022-04-07 06:57:31 | train] - Train Epoch: [164] [780800/1281167 (61%)]	Loss: 0.634223
[2022-04-07 06:57:59 | train] - Train Epoch: [164] [793600/1281167 (62%)]	Loss: 0.541213
[2022-04-07 06:58:25 | train] - Train Epoch: [164] [806400/1281167 (63%)]	Loss: 0.735577
[2022-04-07 06:58:53 | train] - Train Epoch: [164] [819200/1281167 (64%)]	Loss: 0.750202
[2022-04-07 06:59:20 | train] - Train Epoch: [164] [832000/1281167 (65%)]	Loss: 0.549494
[2022-04-07 06:59:49 | train] - Train Epoch: [164] [844800/1281167 (66%)]	Loss: 0.551023
[2022-04-07 07:00:18 | train] - Train Epoch: [164] [857600/1281167 (67%)]	Loss: 0.771851
[2022-04-07 07:00:47 | train] - Train Epoch: [164] [870400/1281167 (68%)]	Loss: 0.715308
[2022-04-07 07:01:14 | train] - Train Epoch: [164] [883200/1281167 (69%)]	Loss: 0.887692
[2022-04-07 07:01:43 | train] - Train Epoch: [164] [896000/1281167 (70%)]	Loss: 0.560963
[2022-04-07 07:02:11 | train] - Train Epoch: [164] [908800/1281167 (71%)]	Loss: 0.483221
[2022-04-07 07:02:38 | train] - Train Epoch: [164] [921600/1281167 (72%)]	Loss: 0.515987
[2022-04-07 07:03:07 | train] - Train Epoch: [164] [934400/1281167 (73%)]	Loss: 0.574556
[2022-04-07 07:03:35 | train] - Train Epoch: [164] [947200/1281167 (74%)]	Loss: 0.479767
[2022-04-07 07:04:04 | train] - Train Epoch: [164] [960000/1281167 (75%)]	Loss: 0.601969
[2022-04-07 07:04:31 | train] - Train Epoch: [164] [972800/1281167 (76%)]	Loss: 0.646237
[2022-04-07 07:04:59 | train] - Train Epoch: [164] [985600/1281167 (77%)]	Loss: 0.569313
[2022-04-07 07:05:26 | train] - Train Epoch: [164] [998400/1281167 (78%)]	Loss: 0.722852
[2022-04-07 07:05:54 | train] - Train Epoch: [164] [1011200/1281167 (79%)]	Loss: 0.493406
[2022-04-07 07:06:21 | train] - Train Epoch: [164] [1024000/1281167 (80%)]	Loss: 0.731941
[2022-04-07 07:06:49 | train] - Train Epoch: [164] [1036800/1281167 (81%)]	Loss: 0.742873
[2022-04-07 07:07:17 | train] - Train Epoch: [164] [1049600/1281167 (82%)]	Loss: 0.859900
[2022-04-07 07:07:44 | train] - Train Epoch: [164] [1062400/1281167 (83%)]	Loss: 0.531494
[2022-04-07 07:08:13 | train] - Train Epoch: [164] [1075200/1281167 (84%)]	Loss: 0.708530
[2022-04-07 07:08:41 | train] - Train Epoch: [164] [1088000/1281167 (85%)]	Loss: 0.778454
[2022-04-07 07:09:08 | train] - Train Epoch: [164] [1100800/1281167 (86%)]	Loss: 0.707249
[2022-04-07 07:09:36 | train] - Train Epoch: [164] [1113600/1281167 (87%)]	Loss: 0.493602
[2022-04-07 07:10:04 | train] - Train Epoch: [164] [1126400/1281167 (88%)]	Loss: 0.718042
[2022-04-07 07:10:32 | train] - Train Epoch: [164] [1139200/1281167 (89%)]	Loss: 0.459450
[2022-04-07 07:11:01 | train] - Train Epoch: [164] [1152000/1281167 (90%)]	Loss: 0.738152
[2022-04-07 07:11:29 | train] - Train Epoch: [164] [1164800/1281167 (91%)]	Loss: 0.710613
[2022-04-07 07:11:57 | train] - Train Epoch: [164] [1177600/1281167 (92%)]	Loss: 1.011661
[2022-04-07 07:12:26 | train] - Train Epoch: [164] [1190400/1281167 (93%)]	Loss: 0.826264
[2022-04-07 07:12:53 | train] - Train Epoch: [164] [1203200/1281167 (94%)]	Loss: 0.735719
[2022-04-07 07:13:23 | train] - Train Epoch: [164] [1216000/1281167 (95%)]	Loss: 0.770258
[2022-04-07 07:13:51 | train] - Train Epoch: [164] [1228800/1281167 (96%)]	Loss: 0.714212
[2022-04-07 07:14:18 | train] - Train Epoch: [164] [1241600/1281167 (97%)]	Loss: 0.483952
[2022-04-07 07:14:46 | train] - Train Epoch: [164] [1254400/1281167 (98%)]	Loss: 0.592187
[2022-04-07 07:15:15 | train] - Train Epoch: [164] [1267200/1281167 (99%)]	Loss: 1.097813
[2022-04-07 07:15:43 | train] - Train Epoch: [164] [1280000/1281167 (100%)]	Loss: 0.635471
[2022-04-07 07:15:45 | train] - Train Epoch: [164]	 Average Loss: 0.662648	 Total Acc : 83.9796	 Total Top5 Acc : 94.2317
[2022-04-07 07:15:45 | train] - -------164 epoch end-----------
========================================
-------164 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 07:17:40 | train] - 
Epoch [164] Test set: Average loss: 1.4492, Accuracy: 34933/50000 (69.8410%), Top-5 Accuracy: 88.7732%

[2022-04-07 07:17:40 | train] - save intermediate epoch [164] result


[2022-04-07 07:17:57 | train] - -------165 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 07:17:59 | train] - Train Epoch: [165] [0/1281167 (0%)]	Loss: 0.573738
[2022-04-07 07:18:25 | train] - Train Epoch: [165] [12800/1281167 (1%)]	Loss: 0.478325
[2022-04-07 07:18:52 | train] - Train Epoch: [165] [25600/1281167 (2%)]	Loss: 0.701445
[2022-04-07 07:19:19 | train] - Train Epoch: [165] [38400/1281167 (3%)]	Loss: 0.865687
[2022-04-07 07:19:46 | train] - Train Epoch: [165] [51200/1281167 (4%)]	Loss: 0.687105
[2022-04-07 07:20:13 | train] - Train Epoch: [165] [64000/1281167 (5%)]	Loss: 0.559718
[2022-04-07 07:20:40 | train] - Train Epoch: [165] [76800/1281167 (6%)]	Loss: 0.790026
[2022-04-07 07:21:07 | train] - Train Epoch: [165] [89600/1281167 (7%)]	Loss: 0.691235
[2022-04-07 07:21:34 | train] - Train Epoch: [165] [102400/1281167 (8%)]	Loss: 0.769460
[2022-04-07 07:22:02 | train] - Train Epoch: [165] [115200/1281167 (9%)]	Loss: 0.479937
[2022-04-07 07:22:30 | train] - Train Epoch: [165] [128000/1281167 (10%)]	Loss: 0.645090
[2022-04-07 07:22:57 | train] - Train Epoch: [165] [140800/1281167 (11%)]	Loss: 0.787252
[2022-04-07 07:23:25 | train] - Train Epoch: [165] [153600/1281167 (12%)]	Loss: 0.494987
[2022-04-07 07:23:52 | train] - Train Epoch: [165] [166400/1281167 (13%)]	Loss: 0.730520
[2022-04-07 07:24:20 | train] - Train Epoch: [165] [179200/1281167 (14%)]	Loss: 0.544378
[2022-04-07 07:24:48 | train] - Train Epoch: [165] [192000/1281167 (15%)]	Loss: 0.738592
[2022-04-07 07:25:16 | train] - Train Epoch: [165] [204800/1281167 (16%)]	Loss: 0.548558
[2022-04-07 07:25:44 | train] - Train Epoch: [165] [217600/1281167 (17%)]	Loss: 0.501184
[2022-04-07 07:26:12 | train] - Train Epoch: [165] [230400/1281167 (18%)]	Loss: 0.695885
[2022-04-07 07:26:38 | train] - Train Epoch: [165] [243200/1281167 (19%)]	Loss: 0.741069
[2022-04-07 07:27:05 | train] - Train Epoch: [165] [256000/1281167 (20%)]	Loss: 0.610494
[2022-04-07 07:27:31 | train] - Train Epoch: [165] [268800/1281167 (21%)]	Loss: 0.563111
[2022-04-07 07:27:58 | train] - Train Epoch: [165] [281600/1281167 (22%)]	Loss: 0.763542
[2022-04-07 07:28:25 | train] - Train Epoch: [165] [294400/1281167 (23%)]	Loss: 0.650412
[2022-04-07 07:28:52 | train] - Train Epoch: [165] [307200/1281167 (24%)]	Loss: 0.518607
[2022-04-07 07:29:19 | train] - Train Epoch: [165] [320000/1281167 (25%)]	Loss: 0.698472
[2022-04-07 07:29:47 | train] - Train Epoch: [165] [332800/1281167 (26%)]	Loss: 0.809305
[2022-04-07 07:30:15 | train] - Train Epoch: [165] [345600/1281167 (27%)]	Loss: 0.705666
[2022-04-07 07:30:42 | train] - Train Epoch: [165] [358400/1281167 (28%)]	Loss: 0.388302
[2022-04-07 07:31:08 | train] - Train Epoch: [165] [371200/1281167 (29%)]	Loss: 0.734069
[2022-04-07 07:31:35 | train] - Train Epoch: [165] [384000/1281167 (30%)]	Loss: 0.546686
[2022-04-07 07:32:02 | train] - Train Epoch: [165] [396800/1281167 (31%)]	Loss: 0.631561
[2022-04-07 07:32:29 | train] - Train Epoch: [165] [409600/1281167 (32%)]	Loss: 0.579994
[2022-04-07 07:32:57 | train] - Train Epoch: [165] [422400/1281167 (33%)]	Loss: 0.793465
[2022-04-07 07:33:24 | train] - Train Epoch: [165] [435200/1281167 (34%)]	Loss: 0.670358
[2022-04-07 07:33:52 | train] - Train Epoch: [165] [448000/1281167 (35%)]	Loss: 0.591262
[2022-04-07 07:34:19 | train] - Train Epoch: [165] [460800/1281167 (36%)]	Loss: 0.747984
[2022-04-07 07:34:46 | train] - Train Epoch: [165] [473600/1281167 (37%)]	Loss: 0.871947
[2022-04-07 07:35:13 | train] - Train Epoch: [165] [486400/1281167 (38%)]	Loss: 0.904930
[2022-04-07 07:35:42 | train] - Train Epoch: [165] [499200/1281167 (39%)]	Loss: 0.723947
[2022-04-07 07:36:08 | train] - Train Epoch: [165] [512000/1281167 (40%)]	Loss: 0.568860
[2022-04-07 07:36:35 | train] - Train Epoch: [165] [524800/1281167 (41%)]	Loss: 0.786667
[2022-04-07 07:37:01 | train] - Train Epoch: [165] [537600/1281167 (42%)]	Loss: 0.600335
[2022-04-07 07:37:29 | train] - Train Epoch: [165] [550400/1281167 (43%)]	Loss: 0.479947
[2022-04-07 07:37:56 | train] - Train Epoch: [165] [563200/1281167 (44%)]	Loss: 0.598549
[2022-04-07 07:38:23 | train] - Train Epoch: [165] [576000/1281167 (45%)]	Loss: 0.553181
[2022-04-07 07:38:50 | train] - Train Epoch: [165] [588800/1281167 (46%)]	Loss: 0.695340
[2022-04-07 07:39:16 | train] - Train Epoch: [165] [601600/1281167 (47%)]	Loss: 0.441302
[2022-04-07 07:39:43 | train] - Train Epoch: [165] [614400/1281167 (48%)]	Loss: 0.788452
[2022-04-07 07:40:11 | train] - Train Epoch: [165] [627200/1281167 (49%)]	Loss: 0.606451
[2022-04-07 07:40:38 | train] - Train Epoch: [165] [640000/1281167 (50%)]	Loss: 0.651860
[2022-04-07 07:41:04 | train] - Train Epoch: [165] [652800/1281167 (51%)]	Loss: 0.730632
[2022-04-07 07:41:32 | train] - Train Epoch: [165] [665600/1281167 (52%)]	Loss: 0.564072
[2022-04-07 07:42:00 | train] - Train Epoch: [165] [678400/1281167 (53%)]	Loss: 0.698619
[2022-04-07 07:42:27 | train] - Train Epoch: [165] [691200/1281167 (54%)]	Loss: 0.833250
[2022-04-07 07:42:53 | train] - Train Epoch: [165] [704000/1281167 (55%)]	Loss: 0.609209
[2022-04-07 07:43:21 | train] - Train Epoch: [165] [716800/1281167 (56%)]	Loss: 0.726175
[2022-04-07 07:43:48 | train] - Train Epoch: [165] [729600/1281167 (57%)]	Loss: 0.739566
[2022-04-07 07:44:15 | train] - Train Epoch: [165] [742400/1281167 (58%)]	Loss: 0.572474
[2022-04-07 07:44:42 | train] - Train Epoch: [165] [755200/1281167 (59%)]	Loss: 0.570222
[2022-04-07 07:45:09 | train] - Train Epoch: [165] [768000/1281167 (60%)]	Loss: 0.577654
[2022-04-07 07:45:36 | train] - Train Epoch: [165] [780800/1281167 (61%)]	Loss: 0.680979
[2022-04-07 07:46:04 | train] - Train Epoch: [165] [793600/1281167 (62%)]	Loss: 0.850443
[2022-04-07 07:46:31 | train] - Train Epoch: [165] [806400/1281167 (63%)]	Loss: 0.809003
[2022-04-07 07:46:59 | train] - Train Epoch: [165] [819200/1281167 (64%)]	Loss: 0.572388
[2022-04-07 07:47:25 | train] - Train Epoch: [165] [832000/1281167 (65%)]	Loss: 0.575373
[2022-04-07 07:47:52 | train] - Train Epoch: [165] [844800/1281167 (66%)]	Loss: 0.529666
[2022-04-07 07:48:19 | train] - Train Epoch: [165] [857600/1281167 (67%)]	Loss: 0.761942
[2022-04-07 07:48:45 | train] - Train Epoch: [165] [870400/1281167 (68%)]	Loss: 0.695600
[2022-04-07 07:49:12 | train] - Train Epoch: [165] [883200/1281167 (69%)]	Loss: 0.887921
[2022-04-07 07:49:40 | train] - Train Epoch: [165] [896000/1281167 (70%)]	Loss: 0.509676
[2022-04-07 07:50:07 | train] - Train Epoch: [165] [908800/1281167 (71%)]	Loss: 0.694651
[2022-04-07 07:50:35 | train] - Train Epoch: [165] [921600/1281167 (72%)]	Loss: 0.538350
[2022-04-07 07:51:02 | train] - Train Epoch: [165] [934400/1281167 (73%)]	Loss: 0.551238
[2022-04-07 07:51:29 | train] - Train Epoch: [165] [947200/1281167 (74%)]	Loss: 0.648720
[2022-04-07 07:51:57 | train] - Train Epoch: [165] [960000/1281167 (75%)]	Loss: 0.657145
[2022-04-07 07:52:24 | train] - Train Epoch: [165] [972800/1281167 (76%)]	Loss: 0.742266
[2022-04-07 07:52:53 | train] - Train Epoch: [165] [985600/1281167 (77%)]	Loss: 0.536585
[2022-04-07 07:53:22 | train] - Train Epoch: [165] [998400/1281167 (78%)]	Loss: 0.460328
[2022-04-07 07:53:50 | train] - Train Epoch: [165] [1011200/1281167 (79%)]	Loss: 0.630265
[2022-04-07 07:54:19 | train] - Train Epoch: [165] [1024000/1281167 (80%)]	Loss: 0.648438
[2022-04-07 07:54:47 | train] - Train Epoch: [165] [1036800/1281167 (81%)]	Loss: 0.812915
[2022-04-07 07:55:15 | train] - Train Epoch: [165] [1049600/1281167 (82%)]	Loss: 0.503121
[2022-04-07 07:55:43 | train] - Train Epoch: [165] [1062400/1281167 (83%)]	Loss: 0.570027
[2022-04-07 07:56:11 | train] - Train Epoch: [165] [1075200/1281167 (84%)]	Loss: 0.674131
[2022-04-07 07:56:39 | train] - Train Epoch: [165] [1088000/1281167 (85%)]	Loss: 0.765025
[2022-04-07 07:57:07 | train] - Train Epoch: [165] [1100800/1281167 (86%)]	Loss: 0.640309
[2022-04-07 07:57:37 | train] - Train Epoch: [165] [1113600/1281167 (87%)]	Loss: 0.542704
[2022-04-07 07:58:05 | train] - Train Epoch: [165] [1126400/1281167 (88%)]	Loss: 0.692349
[2022-04-07 07:58:33 | train] - Train Epoch: [165] [1139200/1281167 (89%)]	Loss: 0.823720
[2022-04-07 07:59:02 | train] - Train Epoch: [165] [1152000/1281167 (90%)]	Loss: 0.678761
[2022-04-07 07:59:31 | train] - Train Epoch: [165] [1164800/1281167 (91%)]	Loss: 0.817845
[2022-04-07 07:59:59 | train] - Train Epoch: [165] [1177600/1281167 (92%)]	Loss: 0.740332
[2022-04-07 08:00:26 | train] - Train Epoch: [165] [1190400/1281167 (93%)]	Loss: 0.630001
[2022-04-07 08:00:54 | train] - Train Epoch: [165] [1203200/1281167 (94%)]	Loss: 0.773372
[2022-04-07 08:01:22 | train] - Train Epoch: [165] [1216000/1281167 (95%)]	Loss: 0.474422
[2022-04-07 08:01:49 | train] - Train Epoch: [165] [1228800/1281167 (96%)]	Loss: 0.585294
[2022-04-07 08:02:17 | train] - Train Epoch: [165] [1241600/1281167 (97%)]	Loss: 0.684658
[2022-04-07 08:02:45 | train] - Train Epoch: [165] [1254400/1281167 (98%)]	Loss: 0.622091
[2022-04-07 08:03:14 | train] - Train Epoch: [165] [1267200/1281167 (99%)]	Loss: 0.570202
[2022-04-07 08:03:41 | train] - Train Epoch: [165] [1280000/1281167 (100%)]	Loss: 0.570862
[2022-04-07 08:03:44 | train] - Train Epoch: [165]	 Average Loss: 0.658911	 Total Acc : 84.0908	 Total Top5 Acc : 94.2820
[2022-04-07 08:03:44 | train] - -------165 epoch end-----------
========================================
-------165 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 08:05:33 | train] - 
Epoch [165] Test set: Average loss: 1.4558, Accuracy: 34942/50000 (69.8589%), Top-5 Accuracy: 88.7864%

[2022-04-07 08:05:33 | train] - save intermediate epoch [165] result


[2022-04-07 08:05:50 | train] - -------166 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 08:05:51 | train] - Train Epoch: [166] [0/1281167 (0%)]	Loss: 0.720513
[2022-04-07 08:06:18 | train] - Train Epoch: [166] [12800/1281167 (1%)]	Loss: 0.572483
[2022-04-07 08:06:45 | train] - Train Epoch: [166] [25600/1281167 (2%)]	Loss: 0.732719
[2022-04-07 08:07:11 | train] - Train Epoch: [166] [38400/1281167 (3%)]	Loss: 0.888398
[2022-04-07 08:07:39 | train] - Train Epoch: [166] [51200/1281167 (4%)]	Loss: 0.655303
[2022-04-07 08:08:06 | train] - Train Epoch: [166] [64000/1281167 (5%)]	Loss: 0.596278
[2022-04-07 08:08:33 | train] - Train Epoch: [166] [76800/1281167 (6%)]	Loss: 0.605805
[2022-04-07 08:09:00 | train] - Train Epoch: [166] [89600/1281167 (7%)]	Loss: 0.561522
[2022-04-07 08:09:27 | train] - Train Epoch: [166] [102400/1281167 (8%)]	Loss: 0.714079
[2022-04-07 08:09:53 | train] - Train Epoch: [166] [115200/1281167 (9%)]	Loss: 0.808294
[2022-04-07 08:10:21 | train] - Train Epoch: [166] [128000/1281167 (10%)]	Loss: 0.613051
[2022-04-07 08:10:48 | train] - Train Epoch: [166] [140800/1281167 (11%)]	Loss: 0.532898
[2022-04-07 08:11:15 | train] - Train Epoch: [166] [153600/1281167 (12%)]	Loss: 0.951340
[2022-04-07 08:11:42 | train] - Train Epoch: [166] [166400/1281167 (13%)]	Loss: 0.592730
[2022-04-07 08:12:10 | train] - Train Epoch: [166] [179200/1281167 (14%)]	Loss: 0.622202
[2022-04-07 08:12:37 | train] - Train Epoch: [166] [192000/1281167 (15%)]	Loss: 0.627206
[2022-04-07 08:13:05 | train] - Train Epoch: [166] [204800/1281167 (16%)]	Loss: 0.527980
[2022-04-07 08:13:32 | train] - Train Epoch: [166] [217600/1281167 (17%)]	Loss: 0.826950
[2022-04-07 08:13:59 | train] - Train Epoch: [166] [230400/1281167 (18%)]	Loss: 0.563682
[2022-04-07 08:14:26 | train] - Train Epoch: [166] [243200/1281167 (19%)]	Loss: 0.532882
[2022-04-07 08:14:53 | train] - Train Epoch: [166] [256000/1281167 (20%)]	Loss: 0.895037
[2022-04-07 08:15:20 | train] - Train Epoch: [166] [268800/1281167 (21%)]	Loss: 0.678052
[2022-04-07 08:15:47 | train] - Train Epoch: [166] [281600/1281167 (22%)]	Loss: 0.710360
[2022-04-07 08:16:15 | train] - Train Epoch: [166] [294400/1281167 (23%)]	Loss: 0.755224
[2022-04-07 08:16:42 | train] - Train Epoch: [166] [307200/1281167 (24%)]	Loss: 0.640817
[2022-04-07 08:17:10 | train] - Train Epoch: [166] [320000/1281167 (25%)]	Loss: 0.716171
[2022-04-07 08:17:37 | train] - Train Epoch: [166] [332800/1281167 (26%)]	Loss: 0.553554
[2022-04-07 08:18:04 | train] - Train Epoch: [166] [345600/1281167 (27%)]	Loss: 0.484276
[2022-04-07 08:18:31 | train] - Train Epoch: [166] [358400/1281167 (28%)]	Loss: 0.623570
[2022-04-07 08:18:59 | train] - Train Epoch: [166] [371200/1281167 (29%)]	Loss: 0.729701
[2022-04-07 08:19:27 | train] - Train Epoch: [166] [384000/1281167 (30%)]	Loss: 0.653231
[2022-04-07 08:19:53 | train] - Train Epoch: [166] [396800/1281167 (31%)]	Loss: 0.397145
[2022-04-07 08:20:20 | train] - Train Epoch: [166] [409600/1281167 (32%)]	Loss: 0.586587
[2022-04-07 08:20:47 | train] - Train Epoch: [166] [422400/1281167 (33%)]	Loss: 0.624262
[2022-04-07 08:21:14 | train] - Train Epoch: [166] [435200/1281167 (34%)]	Loss: 0.801280
[2022-04-07 08:21:40 | train] - Train Epoch: [166] [448000/1281167 (35%)]	Loss: 0.818445
[2022-04-07 08:22:07 | train] - Train Epoch: [166] [460800/1281167 (36%)]	Loss: 0.635207
[2022-04-07 08:22:34 | train] - Train Epoch: [166] [473600/1281167 (37%)]	Loss: 0.699980
[2022-04-07 08:23:02 | train] - Train Epoch: [166] [486400/1281167 (38%)]	Loss: 0.596543
[2022-04-07 08:23:29 | train] - Train Epoch: [166] [499200/1281167 (39%)]	Loss: 0.447882
[2022-04-07 08:23:56 | train] - Train Epoch: [166] [512000/1281167 (40%)]	Loss: 0.800084
[2022-04-07 08:24:24 | train] - Train Epoch: [166] [524800/1281167 (41%)]	Loss: 0.712981
[2022-04-07 08:24:51 | train] - Train Epoch: [166] [537600/1281167 (42%)]	Loss: 0.758099
[2022-04-07 08:25:18 | train] - Train Epoch: [166] [550400/1281167 (43%)]	Loss: 0.693507
[2022-04-07 08:25:45 | train] - Train Epoch: [166] [563200/1281167 (44%)]	Loss: 0.437197
[2022-04-07 08:26:13 | train] - Train Epoch: [166] [576000/1281167 (45%)]	Loss: 0.617554
[2022-04-07 08:26:39 | train] - Train Epoch: [166] [588800/1281167 (46%)]	Loss: 0.724919
[2022-04-07 08:27:06 | train] - Train Epoch: [166] [601600/1281167 (47%)]	Loss: 0.705630
[2022-04-07 08:27:34 | train] - Train Epoch: [166] [614400/1281167 (48%)]	Loss: 0.741311
[2022-04-07 08:28:01 | train] - Train Epoch: [166] [627200/1281167 (49%)]	Loss: 0.612053
[2022-04-07 08:28:28 | train] - Train Epoch: [166] [640000/1281167 (50%)]	Loss: 0.854376
[2022-04-07 08:28:55 | train] - Train Epoch: [166] [652800/1281167 (51%)]	Loss: 0.876252
[2022-04-07 08:29:22 | train] - Train Epoch: [166] [665600/1281167 (52%)]	Loss: 0.645380
[2022-04-07 08:29:49 | train] - Train Epoch: [166] [678400/1281167 (53%)]	Loss: 0.698909
[2022-04-07 08:30:16 | train] - Train Epoch: [166] [691200/1281167 (54%)]	Loss: 0.562060
[2022-04-07 08:30:43 | train] - Train Epoch: [166] [704000/1281167 (55%)]	Loss: 0.484005
[2022-04-07 08:31:10 | train] - Train Epoch: [166] [716800/1281167 (56%)]	Loss: 0.675420
[2022-04-07 08:31:37 | train] - Train Epoch: [166] [729600/1281167 (57%)]	Loss: 0.565081
[2022-04-07 08:32:04 | train] - Train Epoch: [166] [742400/1281167 (58%)]	Loss: 0.750524
[2022-04-07 08:32:31 | train] - Train Epoch: [166] [755200/1281167 (59%)]	Loss: 0.550866
[2022-04-07 08:32:58 | train] - Train Epoch: [166] [768000/1281167 (60%)]	Loss: 0.542482
[2022-04-07 08:33:25 | train] - Train Epoch: [166] [780800/1281167 (61%)]	Loss: 0.823022
[2022-04-07 08:33:52 | train] - Train Epoch: [166] [793600/1281167 (62%)]	Loss: 0.626132
[2022-04-07 08:34:19 | train] - Train Epoch: [166] [806400/1281167 (63%)]	Loss: 0.546667
[2022-04-07 08:34:46 | train] - Train Epoch: [166] [819200/1281167 (64%)]	Loss: 1.027300
[2022-04-07 08:35:15 | train] - Train Epoch: [166] [832000/1281167 (65%)]	Loss: 0.651216
[2022-04-07 08:35:42 | train] - Train Epoch: [166] [844800/1281167 (66%)]	Loss: 0.762491
[2022-04-07 08:36:09 | train] - Train Epoch: [166] [857600/1281167 (67%)]	Loss: 0.657051
[2022-04-07 08:36:36 | train] - Train Epoch: [166] [870400/1281167 (68%)]	Loss: 0.749949
[2022-04-07 08:37:04 | train] - Train Epoch: [166] [883200/1281167 (69%)]	Loss: 0.443940
[2022-04-07 08:37:31 | train] - Train Epoch: [166] [896000/1281167 (70%)]	Loss: 0.858884
[2022-04-07 08:37:59 | train] - Train Epoch: [166] [908800/1281167 (71%)]	Loss: 0.563847
[2022-04-07 08:38:26 | train] - Train Epoch: [166] [921600/1281167 (72%)]	Loss: 0.808572
[2022-04-07 08:38:53 | train] - Train Epoch: [166] [934400/1281167 (73%)]	Loss: 0.577021
[2022-04-07 08:39:21 | train] - Train Epoch: [166] [947200/1281167 (74%)]	Loss: 0.731804
[2022-04-07 08:39:48 | train] - Train Epoch: [166] [960000/1281167 (75%)]	Loss: 0.574521
[2022-04-07 08:40:15 | train] - Train Epoch: [166] [972800/1281167 (76%)]	Loss: 0.585758
[2022-04-07 08:40:43 | train] - Train Epoch: [166] [985600/1281167 (77%)]	Loss: 0.803024
[2022-04-07 08:41:10 | train] - Train Epoch: [166] [998400/1281167 (78%)]	Loss: 0.644075
[2022-04-07 08:41:38 | train] - Train Epoch: [166] [1011200/1281167 (79%)]	Loss: 0.660194
[2022-04-07 08:42:05 | train] - Train Epoch: [166] [1024000/1281167 (80%)]	Loss: 0.519365
[2022-04-07 08:42:32 | train] - Train Epoch: [166] [1036800/1281167 (81%)]	Loss: 0.621994
[2022-04-07 08:42:59 | train] - Train Epoch: [166] [1049600/1281167 (82%)]	Loss: 0.360822
[2022-04-07 08:43:26 | train] - Train Epoch: [166] [1062400/1281167 (83%)]	Loss: 0.691668
[2022-04-07 08:43:53 | train] - Train Epoch: [166] [1075200/1281167 (84%)]	Loss: 0.518691
[2022-04-07 08:44:21 | train] - Train Epoch: [166] [1088000/1281167 (85%)]	Loss: 0.863927
[2022-04-07 08:44:47 | train] - Train Epoch: [166] [1100800/1281167 (86%)]	Loss: 0.744896
[2022-04-07 08:45:14 | train] - Train Epoch: [166] [1113600/1281167 (87%)]	Loss: 0.832499
[2022-04-07 08:45:41 | train] - Train Epoch: [166] [1126400/1281167 (88%)]	Loss: 0.715204
[2022-04-07 08:46:08 | train] - Train Epoch: [166] [1139200/1281167 (89%)]	Loss: 0.814546
[2022-04-07 08:46:35 | train] - Train Epoch: [166] [1152000/1281167 (90%)]	Loss: 0.557497
[2022-04-07 08:47:02 | train] - Train Epoch: [166] [1164800/1281167 (91%)]	Loss: 0.784963
[2022-04-07 08:47:29 | train] - Train Epoch: [166] [1177600/1281167 (92%)]	Loss: 0.548238
[2022-04-07 08:47:59 | train] - Train Epoch: [166] [1190400/1281167 (93%)]	Loss: 0.534588
[2022-04-07 08:48:27 | train] - Train Epoch: [166] [1203200/1281167 (94%)]	Loss: 0.702354
[2022-04-07 08:48:55 | train] - Train Epoch: [166] [1216000/1281167 (95%)]	Loss: 0.654378
[2022-04-07 08:49:24 | train] - Train Epoch: [166] [1228800/1281167 (96%)]	Loss: 0.628957
[2022-04-07 08:49:52 | train] - Train Epoch: [166] [1241600/1281167 (97%)]	Loss: 0.786853
[2022-04-07 08:50:20 | train] - Train Epoch: [166] [1254400/1281167 (98%)]	Loss: 0.592759
[2022-04-07 08:50:49 | train] - Train Epoch: [166] [1267200/1281167 (99%)]	Loss: 0.697622
[2022-04-07 08:51:16 | train] - Train Epoch: [166] [1280000/1281167 (100%)]	Loss: 0.544864
[2022-04-07 08:51:19 | train] - Train Epoch: [166]	 Average Loss: 0.655917	 Total Acc : 84.1675	 Total Top5 Acc : 94.2998
[2022-04-07 08:51:19 | train] - -------166 epoch end-----------
========================================
-------166 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 08:53:15 | train] - 
Epoch [166] Test set: Average loss: 1.4541, Accuracy: 34895/50000 (69.7626%), Top-5 Accuracy: 88.7852%

[2022-04-07 08:53:15 | train] - save intermediate epoch [166] result


[2022-04-07 08:53:32 | train] - -------167 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 08:53:34 | train] - Train Epoch: [167] [0/1281167 (0%)]	Loss: 0.511153
[2022-04-07 08:54:01 | train] - Train Epoch: [167] [12800/1281167 (1%)]	Loss: 0.601125
[2022-04-07 08:54:29 | train] - Train Epoch: [167] [25600/1281167 (2%)]	Loss: 0.621556
[2022-04-07 08:54:56 | train] - Train Epoch: [167] [38400/1281167 (3%)]	Loss: 0.724629
[2022-04-07 08:55:23 | train] - Train Epoch: [167] [51200/1281167 (4%)]	Loss: 0.712125
[2022-04-07 08:55:50 | train] - Train Epoch: [167] [64000/1281167 (5%)]	Loss: 0.740172
[2022-04-07 08:56:18 | train] - Train Epoch: [167] [76800/1281167 (6%)]	Loss: 0.896918
[2022-04-07 08:56:45 | train] - Train Epoch: [167] [89600/1281167 (7%)]	Loss: 0.605856
[2022-04-07 08:57:13 | train] - Train Epoch: [167] [102400/1281167 (8%)]	Loss: 0.505112
[2022-04-07 08:57:41 | train] - Train Epoch: [167] [115200/1281167 (9%)]	Loss: 0.670006
[2022-04-07 08:58:08 | train] - Train Epoch: [167] [128000/1281167 (10%)]	Loss: 0.454541
[2022-04-07 08:58:36 | train] - Train Epoch: [167] [140800/1281167 (11%)]	Loss: 0.655294
[2022-04-07 08:59:03 | train] - Train Epoch: [167] [153600/1281167 (12%)]	Loss: 0.894257
[2022-04-07 08:59:30 | train] - Train Epoch: [167] [166400/1281167 (13%)]	Loss: 0.438992
[2022-04-07 08:59:57 | train] - Train Epoch: [167] [179200/1281167 (14%)]	Loss: 0.792519
[2022-04-07 09:00:25 | train] - Train Epoch: [167] [192000/1281167 (15%)]	Loss: 0.867930
[2022-04-07 09:00:54 | train] - Train Epoch: [167] [204800/1281167 (16%)]	Loss: 0.564549
[2022-04-07 09:01:22 | train] - Train Epoch: [167] [217600/1281167 (17%)]	Loss: 0.449039
[2022-04-07 09:01:49 | train] - Train Epoch: [167] [230400/1281167 (18%)]	Loss: 0.634672
[2022-04-07 09:02:17 | train] - Train Epoch: [167] [243200/1281167 (19%)]	Loss: 0.731948
[2022-04-07 09:02:45 | train] - Train Epoch: [167] [256000/1281167 (20%)]	Loss: 0.476229
[2022-04-07 09:03:12 | train] - Train Epoch: [167] [268800/1281167 (21%)]	Loss: 0.685275
[2022-04-07 09:03:40 | train] - Train Epoch: [167] [281600/1281167 (22%)]	Loss: 0.725593
[2022-04-07 09:04:07 | train] - Train Epoch: [167] [294400/1281167 (23%)]	Loss: 0.515283
[2022-04-07 09:04:35 | train] - Train Epoch: [167] [307200/1281167 (24%)]	Loss: 0.685518
[2022-04-07 09:05:03 | train] - Train Epoch: [167] [320000/1281167 (25%)]	Loss: 0.731812
[2022-04-07 09:05:30 | train] - Train Epoch: [167] [332800/1281167 (26%)]	Loss: 0.553403
[2022-04-07 09:05:58 | train] - Train Epoch: [167] [345600/1281167 (27%)]	Loss: 0.888336
[2022-04-07 09:06:25 | train] - Train Epoch: [167] [358400/1281167 (28%)]	Loss: 0.523488
[2022-04-07 09:06:54 | train] - Train Epoch: [167] [371200/1281167 (29%)]	Loss: 0.626475
[2022-04-07 09:07:21 | train] - Train Epoch: [167] [384000/1281167 (30%)]	Loss: 0.623721
[2022-04-07 09:07:51 | train] - Train Epoch: [167] [396800/1281167 (31%)]	Loss: 0.628236
[2022-04-07 09:08:19 | train] - Train Epoch: [167] [409600/1281167 (32%)]	Loss: 0.717752
[2022-04-07 09:08:48 | train] - Train Epoch: [167] [422400/1281167 (33%)]	Loss: 0.756188
[2022-04-07 09:09:17 | train] - Train Epoch: [167] [435200/1281167 (34%)]	Loss: 0.507068
[2022-04-07 09:09:47 | train] - Train Epoch: [167] [448000/1281167 (35%)]	Loss: 0.717337
[2022-04-07 09:10:15 | train] - Train Epoch: [167] [460800/1281167 (36%)]	Loss: 0.443405
[2022-04-07 09:10:44 | train] - Train Epoch: [167] [473600/1281167 (37%)]	Loss: 0.559614
[2022-04-07 09:11:11 | train] - Train Epoch: [167] [486400/1281167 (38%)]	Loss: 0.665605
[2022-04-07 09:11:38 | train] - Train Epoch: [167] [499200/1281167 (39%)]	Loss: 0.562932
[2022-04-07 09:12:06 | train] - Train Epoch: [167] [512000/1281167 (40%)]	Loss: 0.585161
[2022-04-07 09:12:35 | train] - Train Epoch: [167] [524800/1281167 (41%)]	Loss: 0.636033
[2022-04-07 09:13:03 | train] - Train Epoch: [167] [537600/1281167 (42%)]	Loss: 0.557904
[2022-04-07 09:13:32 | train] - Train Epoch: [167] [550400/1281167 (43%)]	Loss: 0.561506
[2022-04-07 09:14:01 | train] - Train Epoch: [167] [563200/1281167 (44%)]	Loss: 0.531462
[2022-04-07 09:14:28 | train] - Train Epoch: [167] [576000/1281167 (45%)]	Loss: 0.739423
[2022-04-07 09:14:57 | train] - Train Epoch: [167] [588800/1281167 (46%)]	Loss: 0.538214
[2022-04-07 09:15:25 | train] - Train Epoch: [167] [601600/1281167 (47%)]	Loss: 0.993978
[2022-04-07 09:15:53 | train] - Train Epoch: [167] [614400/1281167 (48%)]	Loss: 0.486178
[2022-04-07 09:16:23 | train] - Train Epoch: [167] [627200/1281167 (49%)]	Loss: 0.535638
[2022-04-07 09:16:51 | train] - Train Epoch: [167] [640000/1281167 (50%)]	Loss: 0.905728
[2022-04-07 09:17:19 | train] - Train Epoch: [167] [652800/1281167 (51%)]	Loss: 0.726676
[2022-04-07 09:17:48 | train] - Train Epoch: [167] [665600/1281167 (52%)]	Loss: 0.651217
[2022-04-07 09:18:16 | train] - Train Epoch: [167] [678400/1281167 (53%)]	Loss: 1.020835
[2022-04-07 09:18:45 | train] - Train Epoch: [167] [691200/1281167 (54%)]	Loss: 0.518253
[2022-04-07 09:19:12 | train] - Train Epoch: [167] [704000/1281167 (55%)]	Loss: 0.346984
[2022-04-07 09:19:40 | train] - Train Epoch: [167] [716800/1281167 (56%)]	Loss: 0.738039
[2022-04-07 09:20:07 | train] - Train Epoch: [167] [729600/1281167 (57%)]	Loss: 0.729713
[2022-04-07 09:20:35 | train] - Train Epoch: [167] [742400/1281167 (58%)]	Loss: 0.529779
[2022-04-07 09:21:02 | train] - Train Epoch: [167] [755200/1281167 (59%)]	Loss: 0.745208
[2022-04-07 09:21:30 | train] - Train Epoch: [167] [768000/1281167 (60%)]	Loss: 0.764197
[2022-04-07 09:21:57 | train] - Train Epoch: [167] [780800/1281167 (61%)]	Loss: 0.671523
[2022-04-07 09:22:25 | train] - Train Epoch: [167] [793600/1281167 (62%)]	Loss: 0.634294
[2022-04-07 09:22:53 | train] - Train Epoch: [167] [806400/1281167 (63%)]	Loss: 0.793657
[2022-04-07 09:23:19 | train] - Train Epoch: [167] [819200/1281167 (64%)]	Loss: 0.717512
[2022-04-07 09:23:48 | train] - Train Epoch: [167] [832000/1281167 (65%)]	Loss: 0.520210
[2022-04-07 09:24:15 | train] - Train Epoch: [167] [844800/1281167 (66%)]	Loss: 0.500902
[2022-04-07 09:24:43 | train] - Train Epoch: [167] [857600/1281167 (67%)]	Loss: 0.578780
[2022-04-07 09:25:10 | train] - Train Epoch: [167] [870400/1281167 (68%)]	Loss: 0.406455
[2022-04-07 09:25:37 | train] - Train Epoch: [167] [883200/1281167 (69%)]	Loss: 0.472254
[2022-04-07 09:26:04 | train] - Train Epoch: [167] [896000/1281167 (70%)]	Loss: 0.582855
[2022-04-07 09:26:32 | train] - Train Epoch: [167] [908800/1281167 (71%)]	Loss: 0.778936
[2022-04-07 09:26:59 | train] - Train Epoch: [167] [921600/1281167 (72%)]	Loss: 0.581147
[2022-04-07 09:27:26 | train] - Train Epoch: [167] [934400/1281167 (73%)]	Loss: 0.583054
[2022-04-07 09:27:54 | train] - Train Epoch: [167] [947200/1281167 (74%)]	Loss: 0.454644
[2022-04-07 09:28:21 | train] - Train Epoch: [167] [960000/1281167 (75%)]	Loss: 0.737379
[2022-04-07 09:28:49 | train] - Train Epoch: [167] [972800/1281167 (76%)]	Loss: 0.711512
[2022-04-07 09:29:16 | train] - Train Epoch: [167] [985600/1281167 (77%)]	Loss: 0.686198
[2022-04-07 09:29:43 | train] - Train Epoch: [167] [998400/1281167 (78%)]	Loss: 0.510836
[2022-04-07 09:30:10 | train] - Train Epoch: [167] [1011200/1281167 (79%)]	Loss: 0.748733
[2022-04-07 09:30:37 | train] - Train Epoch: [167] [1024000/1281167 (80%)]	Loss: 0.475105
[2022-04-07 09:31:04 | train] - Train Epoch: [167] [1036800/1281167 (81%)]	Loss: 0.598313
[2022-04-07 09:31:32 | train] - Train Epoch: [167] [1049600/1281167 (82%)]	Loss: 0.601381
[2022-04-07 09:31:59 | train] - Train Epoch: [167] [1062400/1281167 (83%)]	Loss: 0.834744
[2022-04-07 09:32:27 | train] - Train Epoch: [167] [1075200/1281167 (84%)]	Loss: 0.664417
[2022-04-07 09:32:55 | train] - Train Epoch: [167] [1088000/1281167 (85%)]	Loss: 0.661223
[2022-04-07 09:33:22 | train] - Train Epoch: [167] [1100800/1281167 (86%)]	Loss: 0.861120
[2022-04-07 09:33:50 | train] - Train Epoch: [167] [1113600/1281167 (87%)]	Loss: 0.538476
[2022-04-07 09:34:17 | train] - Train Epoch: [167] [1126400/1281167 (88%)]	Loss: 0.762590
[2022-04-07 09:34:44 | train] - Train Epoch: [167] [1139200/1281167 (89%)]	Loss: 0.627971
[2022-04-07 09:35:12 | train] - Train Epoch: [167] [1152000/1281167 (90%)]	Loss: 0.713338
[2022-04-07 09:35:39 | train] - Train Epoch: [167] [1164800/1281167 (91%)]	Loss: 0.766432
[2022-04-07 09:36:07 | train] - Train Epoch: [167] [1177600/1281167 (92%)]	Loss: 0.621058
[2022-04-07 09:36:34 | train] - Train Epoch: [167] [1190400/1281167 (93%)]	Loss: 0.798879
[2022-04-07 09:37:02 | train] - Train Epoch: [167] [1203200/1281167 (94%)]	Loss: 0.565469
[2022-04-07 09:37:30 | train] - Train Epoch: [167] [1216000/1281167 (95%)]	Loss: 0.638706
[2022-04-07 09:37:59 | train] - Train Epoch: [167] [1228800/1281167 (96%)]	Loss: 0.534039
[2022-04-07 09:38:27 | train] - Train Epoch: [167] [1241600/1281167 (97%)]	Loss: 0.634311
[2022-04-07 09:38:54 | train] - Train Epoch: [167] [1254400/1281167 (98%)]	Loss: 0.596838
[2022-04-07 09:39:22 | train] - Train Epoch: [167] [1267200/1281167 (99%)]	Loss: 0.609798
[2022-04-07 09:39:51 | train] - Train Epoch: [167] [1280000/1281167 (100%)]	Loss: 0.517755
[2022-04-07 09:39:53 | train] - Train Epoch: [167]	 Average Loss: 0.651701	 Total Acc : 84.3410	 Total Top5 Acc : 94.3270
[2022-04-07 09:39:53 | train] - -------167 epoch end-----------
========================================
-------167 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 09:41:52 | train] - 
Epoch [167] Test set: Average loss: 1.4557, Accuracy: 34908/50000 (69.7910%), Top-5 Accuracy: 88.7240%

[2022-04-07 09:41:52 | train] - save intermediate epoch [167] result


[2022-04-07 09:42:10 | train] - -------168 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 09:42:12 | train] - Train Epoch: [168] [0/1281167 (0%)]	Loss: 0.603757
[2022-04-07 09:42:38 | train] - Train Epoch: [168] [12800/1281167 (1%)]	Loss: 0.526570
[2022-04-07 09:43:05 | train] - Train Epoch: [168] [25600/1281167 (2%)]	Loss: 0.661134
[2022-04-07 09:43:33 | train] - Train Epoch: [168] [38400/1281167 (3%)]	Loss: 0.754149
[2022-04-07 09:43:59 | train] - Train Epoch: [168] [51200/1281167 (4%)]	Loss: 0.532897
[2022-04-07 09:44:26 | train] - Train Epoch: [168] [64000/1281167 (5%)]	Loss: 0.616698
[2022-04-07 09:44:53 | train] - Train Epoch: [168] [76800/1281167 (6%)]	Loss: 0.725234
[2022-04-07 09:45:20 | train] - Train Epoch: [168] [89600/1281167 (7%)]	Loss: 0.876638
[2022-04-07 09:45:47 | train] - Train Epoch: [168] [102400/1281167 (8%)]	Loss: 1.004068
[2022-04-07 09:46:15 | train] - Train Epoch: [168] [115200/1281167 (9%)]	Loss: 0.811138
[2022-04-07 09:46:42 | train] - Train Epoch: [168] [128000/1281167 (10%)]	Loss: 0.688216
[2022-04-07 09:47:09 | train] - Train Epoch: [168] [140800/1281167 (11%)]	Loss: 0.558063
[2022-04-07 09:47:36 | train] - Train Epoch: [168] [153600/1281167 (12%)]	Loss: 0.425232
[2022-04-07 09:48:04 | train] - Train Epoch: [168] [166400/1281167 (13%)]	Loss: 0.546815
[2022-04-07 09:48:31 | train] - Train Epoch: [168] [179200/1281167 (14%)]	Loss: 0.697403
[2022-04-07 09:48:59 | train] - Train Epoch: [168] [192000/1281167 (15%)]	Loss: 0.542347
[2022-04-07 09:49:26 | train] - Train Epoch: [168] [204800/1281167 (16%)]	Loss: 0.494651
[2022-04-07 09:49:53 | train] - Train Epoch: [168] [217600/1281167 (17%)]	Loss: 0.678078
[2022-04-07 09:50:21 | train] - Train Epoch: [168] [230400/1281167 (18%)]	Loss: 0.519072
[2022-04-07 09:50:48 | train] - Train Epoch: [168] [243200/1281167 (19%)]	Loss: 0.681899
[2022-04-07 09:51:15 | train] - Train Epoch: [168] [256000/1281167 (20%)]	Loss: 0.752922
[2022-04-07 09:51:43 | train] - Train Epoch: [168] [268800/1281167 (21%)]	Loss: 0.551397
[2022-04-07 09:52:10 | train] - Train Epoch: [168] [281600/1281167 (22%)]	Loss: 0.696022
[2022-04-07 09:52:37 | train] - Train Epoch: [168] [294400/1281167 (23%)]	Loss: 0.503236
[2022-04-07 09:53:04 | train] - Train Epoch: [168] [307200/1281167 (24%)]	Loss: 0.696368
[2022-04-07 09:53:32 | train] - Train Epoch: [168] [320000/1281167 (25%)]	Loss: 0.629883
[2022-04-07 09:54:00 | train] - Train Epoch: [168] [332800/1281167 (26%)]	Loss: 0.683419
[2022-04-07 09:54:27 | train] - Train Epoch: [168] [345600/1281167 (27%)]	Loss: 1.128724
[2022-04-07 09:54:53 | train] - Train Epoch: [168] [358400/1281167 (28%)]	Loss: 0.696674
[2022-04-07 09:55:22 | train] - Train Epoch: [168] [371200/1281167 (29%)]	Loss: 0.589075
[2022-04-07 09:55:49 | train] - Train Epoch: [168] [384000/1281167 (30%)]	Loss: 0.685729
[2022-04-07 09:56:16 | train] - Train Epoch: [168] [396800/1281167 (31%)]	Loss: 0.874068
[2022-04-07 09:56:43 | train] - Train Epoch: [168] [409600/1281167 (32%)]	Loss: 0.530816
[2022-04-07 09:57:10 | train] - Train Epoch: [168] [422400/1281167 (33%)]	Loss: 0.670563
[2022-04-07 09:57:38 | train] - Train Epoch: [168] [435200/1281167 (34%)]	Loss: 0.863794
[2022-04-07 09:58:06 | train] - Train Epoch: [168] [448000/1281167 (35%)]	Loss: 0.931721
[2022-04-07 09:58:32 | train] - Train Epoch: [168] [460800/1281167 (36%)]	Loss: 0.455968
[2022-04-07 09:59:00 | train] - Train Epoch: [168] [473600/1281167 (37%)]	Loss: 0.702635
[2022-04-07 09:59:27 | train] - Train Epoch: [168] [486400/1281167 (38%)]	Loss: 0.818468
[2022-04-07 09:59:53 | train] - Train Epoch: [168] [499200/1281167 (39%)]	Loss: 0.747711
[2022-04-07 10:00:20 | train] - Train Epoch: [168] [512000/1281167 (40%)]	Loss: 0.911741
[2022-04-07 10:00:46 | train] - Train Epoch: [168] [524800/1281167 (41%)]	Loss: 0.900484
[2022-04-07 10:01:14 | train] - Train Epoch: [168] [537600/1281167 (42%)]	Loss: 0.802702
[2022-04-07 10:01:40 | train] - Train Epoch: [168] [550400/1281167 (43%)]	Loss: 0.765992
[2022-04-07 10:02:07 | train] - Train Epoch: [168] [563200/1281167 (44%)]	Loss: 0.588564
[2022-04-07 10:02:32 | train] - Train Epoch: [168] [576000/1281167 (45%)]	Loss: 0.660327
[2022-04-07 10:03:00 | train] - Train Epoch: [168] [588800/1281167 (46%)]	Loss: 0.759945
[2022-04-07 10:03:26 | train] - Train Epoch: [168] [601600/1281167 (47%)]	Loss: 0.651230
[2022-04-07 10:03:54 | train] - Train Epoch: [168] [614400/1281167 (48%)]	Loss: 0.892763
[2022-04-07 10:04:22 | train] - Train Epoch: [168] [627200/1281167 (49%)]	Loss: 0.604136
[2022-04-07 10:04:50 | train] - Train Epoch: [168] [640000/1281167 (50%)]	Loss: 0.671309
[2022-04-07 10:05:18 | train] - Train Epoch: [168] [652800/1281167 (51%)]	Loss: 0.598484
[2022-04-07 10:05:46 | train] - Train Epoch: [168] [665600/1281167 (52%)]	Loss: 0.527386
[2022-04-07 10:06:14 | train] - Train Epoch: [168] [678400/1281167 (53%)]	Loss: 0.452751
[2022-04-07 10:06:42 | train] - Train Epoch: [168] [691200/1281167 (54%)]	Loss: 0.575048
[2022-04-07 10:07:10 | train] - Train Epoch: [168] [704000/1281167 (55%)]	Loss: 0.388347
[2022-04-07 10:07:38 | train] - Train Epoch: [168] [716800/1281167 (56%)]	Loss: 0.593525
[2022-04-07 10:08:06 | train] - Train Epoch: [168] [729600/1281167 (57%)]	Loss: 0.505617
[2022-04-07 10:08:34 | train] - Train Epoch: [168] [742400/1281167 (58%)]	Loss: 0.771124
[2022-04-07 10:09:01 | train] - Train Epoch: [168] [755200/1281167 (59%)]	Loss: 0.493246
[2022-04-07 10:09:28 | train] - Train Epoch: [168] [768000/1281167 (60%)]	Loss: 0.527239
[2022-04-07 10:09:57 | train] - Train Epoch: [168] [780800/1281167 (61%)]	Loss: 0.757489
[2022-04-07 10:10:25 | train] - Train Epoch: [168] [793600/1281167 (62%)]	Loss: 0.641197
[2022-04-07 10:10:51 | train] - Train Epoch: [168] [806400/1281167 (63%)]	Loss: 0.665812
[2022-04-07 10:11:18 | train] - Train Epoch: [168] [819200/1281167 (64%)]	Loss: 0.653914
[2022-04-07 10:11:45 | train] - Train Epoch: [168] [832000/1281167 (65%)]	Loss: 0.796984
[2022-04-07 10:12:11 | train] - Train Epoch: [168] [844800/1281167 (66%)]	Loss: 0.853258
[2022-04-07 10:12:37 | train] - Train Epoch: [168] [857600/1281167 (67%)]	Loss: 0.840594
[2022-04-07 10:13:04 | train] - Train Epoch: [168] [870400/1281167 (68%)]	Loss: 0.626111
[2022-04-07 10:13:31 | train] - Train Epoch: [168] [883200/1281167 (69%)]	Loss: 0.516889
[2022-04-07 10:13:58 | train] - Train Epoch: [168] [896000/1281167 (70%)]	Loss: 0.633409
[2022-04-07 10:14:26 | train] - Train Epoch: [168] [908800/1281167 (71%)]	Loss: 0.896204
[2022-04-07 10:14:53 | train] - Train Epoch: [168] [921600/1281167 (72%)]	Loss: 0.544715
[2022-04-07 10:15:19 | train] - Train Epoch: [168] [934400/1281167 (73%)]	Loss: 0.447145
[2022-04-07 10:15:46 | train] - Train Epoch: [168] [947200/1281167 (74%)]	Loss: 0.573901
[2022-04-07 10:16:12 | train] - Train Epoch: [168] [960000/1281167 (75%)]	Loss: 0.649051
[2022-04-07 10:16:38 | train] - Train Epoch: [168] [972800/1281167 (76%)]	Loss: 0.778948
[2022-04-07 10:17:04 | train] - Train Epoch: [168] [985600/1281167 (77%)]	Loss: 0.889554
[2022-04-07 10:17:31 | train] - Train Epoch: [168] [998400/1281167 (78%)]	Loss: 0.822279
[2022-04-07 10:17:58 | train] - Train Epoch: [168] [1011200/1281167 (79%)]	Loss: 0.699648
[2022-04-07 10:18:23 | train] - Train Epoch: [168] [1024000/1281167 (80%)]	Loss: 0.579536
[2022-04-07 10:18:50 | train] - Train Epoch: [168] [1036800/1281167 (81%)]	Loss: 0.627611
[2022-04-07 10:19:16 | train] - Train Epoch: [168] [1049600/1281167 (82%)]	Loss: 0.487017
[2022-04-07 10:19:43 | train] - Train Epoch: [168] [1062400/1281167 (83%)]	Loss: 0.748526
[2022-04-07 10:20:10 | train] - Train Epoch: [168] [1075200/1281167 (84%)]	Loss: 0.569429
[2022-04-07 10:20:36 | train] - Train Epoch: [168] [1088000/1281167 (85%)]	Loss: 0.496933
[2022-04-07 10:21:03 | train] - Train Epoch: [168] [1100800/1281167 (86%)]	Loss: 0.747956
[2022-04-07 10:21:29 | train] - Train Epoch: [168] [1113600/1281167 (87%)]	Loss: 0.710713
[2022-04-07 10:21:56 | train] - Train Epoch: [168] [1126400/1281167 (88%)]	Loss: 0.706426
[2022-04-07 10:22:23 | train] - Train Epoch: [168] [1139200/1281167 (89%)]	Loss: 0.689608
[2022-04-07 10:22:51 | train] - Train Epoch: [168] [1152000/1281167 (90%)]	Loss: 0.745996
[2022-04-07 10:23:18 | train] - Train Epoch: [168] [1164800/1281167 (91%)]	Loss: 0.587430
[2022-04-07 10:23:44 | train] - Train Epoch: [168] [1177600/1281167 (92%)]	Loss: 0.766043
[2022-04-07 10:24:12 | train] - Train Epoch: [168] [1190400/1281167 (93%)]	Loss: 0.665362
[2022-04-07 10:24:39 | train] - Train Epoch: [168] [1203200/1281167 (94%)]	Loss: 0.833105
[2022-04-07 10:25:07 | train] - Train Epoch: [168] [1216000/1281167 (95%)]	Loss: 0.449546
[2022-04-07 10:25:33 | train] - Train Epoch: [168] [1228800/1281167 (96%)]	Loss: 0.746356
[2022-04-07 10:26:00 | train] - Train Epoch: [168] [1241600/1281167 (97%)]	Loss: 0.781886
[2022-04-07 10:26:27 | train] - Train Epoch: [168] [1254400/1281167 (98%)]	Loss: 0.575989
[2022-04-07 10:26:54 | train] - Train Epoch: [168] [1267200/1281167 (99%)]	Loss: 0.501493
[2022-04-07 10:27:20 | train] - Train Epoch: [168] [1280000/1281167 (100%)]	Loss: 0.630550
[2022-04-07 10:27:23 | train] - Train Epoch: [168]	 Average Loss: 0.648691	 Total Acc : 84.4107	 Total Top5 Acc : 94.3459
[2022-04-07 10:27:23 | train] - -------168 epoch end-----------
========================================
-------168 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 10:29:20 | train] - 
Epoch [168] Test set: Average loss: 1.4546, Accuracy: 34906/50000 (69.7846%), Top-5 Accuracy: 88.7492%

[2022-04-07 10:29:20 | train] - save intermediate epoch [168] result


[2022-04-07 10:29:38 | train] - -------169 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 10:29:40 | train] - Train Epoch: [169] [0/1281167 (0%)]	Loss: 0.457790
[2022-04-07 10:30:07 | train] - Train Epoch: [169] [12800/1281167 (1%)]	Loss: 0.571349
[2022-04-07 10:30:36 | train] - Train Epoch: [169] [25600/1281167 (2%)]	Loss: 0.691038
[2022-04-07 10:31:04 | train] - Train Epoch: [169] [38400/1281167 (3%)]	Loss: 0.566774
[2022-04-07 10:31:30 | train] - Train Epoch: [169] [51200/1281167 (4%)]	Loss: 0.490980
[2022-04-07 10:31:58 | train] - Train Epoch: [169] [64000/1281167 (5%)]	Loss: 0.834735
[2022-04-07 10:32:25 | train] - Train Epoch: [169] [76800/1281167 (6%)]	Loss: 0.601004
[2022-04-07 10:32:53 | train] - Train Epoch: [169] [89600/1281167 (7%)]	Loss: 0.471799
[2022-04-07 10:33:21 | train] - Train Epoch: [169] [102400/1281167 (8%)]	Loss: 0.590172
[2022-04-07 10:33:49 | train] - Train Epoch: [169] [115200/1281167 (9%)]	Loss: 0.617488
[2022-04-07 10:34:17 | train] - Train Epoch: [169] [128000/1281167 (10%)]	Loss: 0.673489
[2022-04-07 10:34:44 | train] - Train Epoch: [169] [140800/1281167 (11%)]	Loss: 0.510507
[2022-04-07 10:35:10 | train] - Train Epoch: [169] [153600/1281167 (12%)]	Loss: 1.013395
[2022-04-07 10:35:37 | train] - Train Epoch: [169] [166400/1281167 (13%)]	Loss: 0.568349
[2022-04-07 10:36:04 | train] - Train Epoch: [169] [179200/1281167 (14%)]	Loss: 0.708694
[2022-04-07 10:36:31 | train] - Train Epoch: [169] [192000/1281167 (15%)]	Loss: 0.614326
[2022-04-07 10:37:00 | train] - Train Epoch: [169] [204800/1281167 (16%)]	Loss: 0.768650
[2022-04-07 10:37:27 | train] - Train Epoch: [169] [217600/1281167 (17%)]	Loss: 0.579565
[2022-04-07 10:37:56 | train] - Train Epoch: [169] [230400/1281167 (18%)]	Loss: 0.630619
[2022-04-07 10:38:23 | train] - Train Epoch: [169] [243200/1281167 (19%)]	Loss: 0.581117
[2022-04-07 10:38:50 | train] - Train Epoch: [169] [256000/1281167 (20%)]	Loss: 0.405946
[2022-04-07 10:39:18 | train] - Train Epoch: [169] [268800/1281167 (21%)]	Loss: 0.901944
[2022-04-07 10:39:46 | train] - Train Epoch: [169] [281600/1281167 (22%)]	Loss: 0.541116
[2022-04-07 10:40:14 | train] - Train Epoch: [169] [294400/1281167 (23%)]	Loss: 0.808528
[2022-04-07 10:40:42 | train] - Train Epoch: [169] [307200/1281167 (24%)]	Loss: 0.579477
[2022-04-07 10:41:09 | train] - Train Epoch: [169] [320000/1281167 (25%)]	Loss: 0.879904
[2022-04-07 10:41:36 | train] - Train Epoch: [169] [332800/1281167 (26%)]	Loss: 0.722535
[2022-04-07 10:42:04 | train] - Train Epoch: [169] [345600/1281167 (27%)]	Loss: 0.815523
[2022-04-07 10:42:31 | train] - Train Epoch: [169] [358400/1281167 (28%)]	Loss: 0.821476
[2022-04-07 10:42:59 | train] - Train Epoch: [169] [371200/1281167 (29%)]	Loss: 0.623118
[2022-04-07 10:43:27 | train] - Train Epoch: [169] [384000/1281167 (30%)]	Loss: 0.783498
[2022-04-07 10:43:54 | train] - Train Epoch: [169] [396800/1281167 (31%)]	Loss: 0.535864
[2022-04-07 10:44:22 | train] - Train Epoch: [169] [409600/1281167 (32%)]	Loss: 0.797027
[2022-04-07 10:44:49 | train] - Train Epoch: [169] [422400/1281167 (33%)]	Loss: 0.786774
[2022-04-07 10:45:15 | train] - Train Epoch: [169] [435200/1281167 (34%)]	Loss: 0.692014
[2022-04-07 10:45:42 | train] - Train Epoch: [169] [448000/1281167 (35%)]	Loss: 0.753857
[2022-04-07 10:46:10 | train] - Train Epoch: [169] [460800/1281167 (36%)]	Loss: 0.564085
[2022-04-07 10:46:38 | train] - Train Epoch: [169] [473600/1281167 (37%)]	Loss: 0.573253
[2022-04-07 10:47:06 | train] - Train Epoch: [169] [486400/1281167 (38%)]	Loss: 0.678723
[2022-04-07 10:47:33 | train] - Train Epoch: [169] [499200/1281167 (39%)]	Loss: 0.527874
[2022-04-07 10:48:01 | train] - Train Epoch: [169] [512000/1281167 (40%)]	Loss: 0.528400
[2022-04-07 10:48:28 | train] - Train Epoch: [169] [524800/1281167 (41%)]	Loss: 0.653480
[2022-04-07 10:48:56 | train] - Train Epoch: [169] [537600/1281167 (42%)]	Loss: 0.650081
[2022-04-07 10:49:23 | train] - Train Epoch: [169] [550400/1281167 (43%)]	Loss: 0.610636
[2022-04-07 10:49:50 | train] - Train Epoch: [169] [563200/1281167 (44%)]	Loss: 0.640870
[2022-04-07 10:50:18 | train] - Train Epoch: [169] [576000/1281167 (45%)]	Loss: 0.632245
[2022-04-07 10:50:46 | train] - Train Epoch: [169] [588800/1281167 (46%)]	Loss: 0.701133
[2022-04-07 10:51:13 | train] - Train Epoch: [169] [601600/1281167 (47%)]	Loss: 0.784413
[2022-04-07 10:51:41 | train] - Train Epoch: [169] [614400/1281167 (48%)]	Loss: 0.454439
[2022-04-07 10:52:08 | train] - Train Epoch: [169] [627200/1281167 (49%)]	Loss: 0.644760
[2022-04-07 10:52:35 | train] - Train Epoch: [169] [640000/1281167 (50%)]	Loss: 0.568575
[2022-04-07 10:53:03 | train] - Train Epoch: [169] [652800/1281167 (51%)]	Loss: 0.742311
[2022-04-07 10:53:30 | train] - Train Epoch: [169] [665600/1281167 (52%)]	Loss: 0.483612
[2022-04-07 10:53:58 | train] - Train Epoch: [169] [678400/1281167 (53%)]	Loss: 0.616893
[2022-04-07 10:54:25 | train] - Train Epoch: [169] [691200/1281167 (54%)]	Loss: 0.912711
[2022-04-07 10:54:53 | train] - Train Epoch: [169] [704000/1281167 (55%)]	Loss: 0.608045
[2022-04-07 10:55:21 | train] - Train Epoch: [169] [716800/1281167 (56%)]	Loss: 0.306820
[2022-04-07 10:55:48 | train] - Train Epoch: [169] [729600/1281167 (57%)]	Loss: 0.577112
[2022-04-07 10:56:17 | train] - Train Epoch: [169] [742400/1281167 (58%)]	Loss: 0.554669
[2022-04-07 10:56:44 | train] - Train Epoch: [169] [755200/1281167 (59%)]	Loss: 0.674967
[2022-04-07 10:57:12 | train] - Train Epoch: [169] [768000/1281167 (60%)]	Loss: 0.440288
[2022-04-07 10:57:40 | train] - Train Epoch: [169] [780800/1281167 (61%)]	Loss: 0.521933
[2022-04-07 10:58:07 | train] - Train Epoch: [169] [793600/1281167 (62%)]	Loss: 0.912144
[2022-04-07 10:58:34 | train] - Train Epoch: [169] [806400/1281167 (63%)]	Loss: 0.537793
[2022-04-07 10:59:02 | train] - Train Epoch: [169] [819200/1281167 (64%)]	Loss: 0.675903
[2022-04-07 10:59:29 | train] - Train Epoch: [169] [832000/1281167 (65%)]	Loss: 0.646176
[2022-04-07 10:59:56 | train] - Train Epoch: [169] [844800/1281167 (66%)]	Loss: 0.895232
[2022-04-07 11:00:23 | train] - Train Epoch: [169] [857600/1281167 (67%)]	Loss: 0.610257
[2022-04-07 11:00:50 | train] - Train Epoch: [169] [870400/1281167 (68%)]	Loss: 0.493025
[2022-04-07 11:01:16 | train] - Train Epoch: [169] [883200/1281167 (69%)]	Loss: 0.682530
[2022-04-07 11:01:44 | train] - Train Epoch: [169] [896000/1281167 (70%)]	Loss: 0.461146
[2022-04-07 11:02:12 | train] - Train Epoch: [169] [908800/1281167 (71%)]	Loss: 0.708523
[2022-04-07 11:02:39 | train] - Train Epoch: [169] [921600/1281167 (72%)]	Loss: 0.678038
[2022-04-07 11:03:06 | train] - Train Epoch: [169] [934400/1281167 (73%)]	Loss: 0.536157
[2022-04-07 11:03:33 | train] - Train Epoch: [169] [947200/1281167 (74%)]	Loss: 0.611519
[2022-04-07 11:04:00 | train] - Train Epoch: [169] [960000/1281167 (75%)]	Loss: 0.748630
[2022-04-07 11:04:27 | train] - Train Epoch: [169] [972800/1281167 (76%)]	Loss: 0.461089
[2022-04-07 11:04:54 | train] - Train Epoch: [169] [985600/1281167 (77%)]	Loss: 0.450549
[2022-04-07 11:05:21 | train] - Train Epoch: [169] [998400/1281167 (78%)]	Loss: 0.742999
[2022-04-07 11:05:49 | train] - Train Epoch: [169] [1011200/1281167 (79%)]	Loss: 0.620632
[2022-04-07 11:06:17 | train] - Train Epoch: [169] [1024000/1281167 (80%)]	Loss: 0.595497
[2022-04-07 11:06:45 | train] - Train Epoch: [169] [1036800/1281167 (81%)]	Loss: 0.614814
[2022-04-07 11:07:12 | train] - Train Epoch: [169] [1049600/1281167 (82%)]	Loss: 0.743500
[2022-04-07 11:07:39 | train] - Train Epoch: [169] [1062400/1281167 (83%)]	Loss: 0.727423
[2022-04-07 11:08:07 | train] - Train Epoch: [169] [1075200/1281167 (84%)]	Loss: 0.459419
[2022-04-07 11:08:34 | train] - Train Epoch: [169] [1088000/1281167 (85%)]	Loss: 0.537458
[2022-04-07 11:09:02 | train] - Train Epoch: [169] [1100800/1281167 (86%)]	Loss: 0.705403
[2022-04-07 11:09:30 | train] - Train Epoch: [169] [1113600/1281167 (87%)]	Loss: 0.599300
[2022-04-07 11:09:58 | train] - Train Epoch: [169] [1126400/1281167 (88%)]	Loss: 0.839980
[2022-04-07 11:10:26 | train] - Train Epoch: [169] [1139200/1281167 (89%)]	Loss: 0.661823
[2022-04-07 11:10:54 | train] - Train Epoch: [169] [1152000/1281167 (90%)]	Loss: 0.751220
[2022-04-07 11:11:21 | train] - Train Epoch: [169] [1164800/1281167 (91%)]	Loss: 0.496041
[2022-04-07 11:11:49 | train] - Train Epoch: [169] [1177600/1281167 (92%)]	Loss: 0.555346
[2022-04-07 11:12:17 | train] - Train Epoch: [169] [1190400/1281167 (93%)]	Loss: 0.395396
[2022-04-07 11:12:45 | train] - Train Epoch: [169] [1203200/1281167 (94%)]	Loss: 0.542849
[2022-04-07 11:13:13 | train] - Train Epoch: [169] [1216000/1281167 (95%)]	Loss: 0.486615
[2022-04-07 11:13:41 | train] - Train Epoch: [169] [1228800/1281167 (96%)]	Loss: 0.678364
[2022-04-07 11:14:09 | train] - Train Epoch: [169] [1241600/1281167 (97%)]	Loss: 0.657703
[2022-04-07 11:14:37 | train] - Train Epoch: [169] [1254400/1281167 (98%)]	Loss: 0.511057
[2022-04-07 11:15:05 | train] - Train Epoch: [169] [1267200/1281167 (99%)]	Loss: 0.661662
[2022-04-07 11:15:32 | train] - Train Epoch: [169] [1280000/1281167 (100%)]	Loss: 0.584158
[2022-04-07 11:15:35 | train] - Train Epoch: [169]	 Average Loss: 0.644127	 Total Acc : 84.5163	 Total Top5 Acc : 94.3966
[2022-04-07 11:15:35 | train] - -------169 epoch end-----------
========================================
-------169 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 11:17:28 | train] - 
Epoch [169] Test set: Average loss: 1.4598, Accuracy: 34922/50000 (69.8178%), Top-5 Accuracy: 88.7592%

[2022-04-07 11:17:28 | train] - save intermediate epoch [169] result


[2022-04-07 11:17:47 | train] - -------170 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 11:17:49 | train] - Train Epoch: [170] [0/1281167 (0%)]	Loss: 0.887700
[2022-04-07 11:18:15 | train] - Train Epoch: [170] [12800/1281167 (1%)]	Loss: 0.434505
[2022-04-07 11:18:41 | train] - Train Epoch: [170] [25600/1281167 (2%)]	Loss: 0.659658
[2022-04-07 11:19:08 | train] - Train Epoch: [170] [38400/1281167 (3%)]	Loss: 0.766300
[2022-04-07 11:19:35 | train] - Train Epoch: [170] [51200/1281167 (4%)]	Loss: 0.645970
[2022-04-07 11:20:01 | train] - Train Epoch: [170] [64000/1281167 (5%)]	Loss: 0.759979
[2022-04-07 11:20:28 | train] - Train Epoch: [170] [76800/1281167 (6%)]	Loss: 0.799270
[2022-04-07 11:20:54 | train] - Train Epoch: [170] [89600/1281167 (7%)]	Loss: 0.644665
[2022-04-07 11:21:21 | train] - Train Epoch: [170] [102400/1281167 (8%)]	Loss: 0.508928
[2022-04-07 11:21:47 | train] - Train Epoch: [170] [115200/1281167 (9%)]	Loss: 0.763235
[2022-04-07 11:22:13 | train] - Train Epoch: [170] [128000/1281167 (10%)]	Loss: 0.713459
[2022-04-07 11:22:40 | train] - Train Epoch: [170] [140800/1281167 (11%)]	Loss: 0.552428
[2022-04-07 11:23:06 | train] - Train Epoch: [170] [153600/1281167 (12%)]	Loss: 0.559611
[2022-04-07 11:23:32 | train] - Train Epoch: [170] [166400/1281167 (13%)]	Loss: 0.484796
[2022-04-07 11:23:59 | train] - Train Epoch: [170] [179200/1281167 (14%)]	Loss: 0.542753
[2022-04-07 11:24:26 | train] - Train Epoch: [170] [192000/1281167 (15%)]	Loss: 0.745639
[2022-04-07 11:24:54 | train] - Train Epoch: [170] [204800/1281167 (16%)]	Loss: 0.593120
[2022-04-07 11:25:20 | train] - Train Epoch: [170] [217600/1281167 (17%)]	Loss: 0.722076
[2022-04-07 11:25:47 | train] - Train Epoch: [170] [230400/1281167 (18%)]	Loss: 0.783079
[2022-04-07 11:26:15 | train] - Train Epoch: [170] [243200/1281167 (19%)]	Loss: 0.509663
[2022-04-07 11:26:42 | train] - Train Epoch: [170] [256000/1281167 (20%)]	Loss: 0.731930
[2022-04-07 11:27:09 | train] - Train Epoch: [170] [268800/1281167 (21%)]	Loss: 0.418694
[2022-04-07 11:27:36 | train] - Train Epoch: [170] [281600/1281167 (22%)]	Loss: 0.720663
[2022-04-07 11:28:03 | train] - Train Epoch: [170] [294400/1281167 (23%)]	Loss: 0.576052
[2022-04-07 11:28:30 | train] - Train Epoch: [170] [307200/1281167 (24%)]	Loss: 0.847420
[2022-04-07 11:28:57 | train] - Train Epoch: [170] [320000/1281167 (25%)]	Loss: 0.895271
[2022-04-07 11:29:25 | train] - Train Epoch: [170] [332800/1281167 (26%)]	Loss: 0.673536
[2022-04-07 11:29:52 | train] - Train Epoch: [170] [345600/1281167 (27%)]	Loss: 0.469528
[2022-04-07 11:30:19 | train] - Train Epoch: [170] [358400/1281167 (28%)]	Loss: 0.636418
[2022-04-07 11:30:46 | train] - Train Epoch: [170] [371200/1281167 (29%)]	Loss: 0.669411
[2022-04-07 11:31:13 | train] - Train Epoch: [170] [384000/1281167 (30%)]	Loss: 0.523866
[2022-04-07 11:31:40 | train] - Train Epoch: [170] [396800/1281167 (31%)]	Loss: 0.712417
[2022-04-07 11:32:07 | train] - Train Epoch: [170] [409600/1281167 (32%)]	Loss: 0.423679
[2022-04-07 11:32:33 | train] - Train Epoch: [170] [422400/1281167 (33%)]	Loss: 0.372656
[2022-04-07 11:33:00 | train] - Train Epoch: [170] [435200/1281167 (34%)]	Loss: 0.660485
[2022-04-07 11:33:28 | train] - Train Epoch: [170] [448000/1281167 (35%)]	Loss: 0.610765
[2022-04-07 11:33:55 | train] - Train Epoch: [170] [460800/1281167 (36%)]	Loss: 0.926475
[2022-04-07 11:34:23 | train] - Train Epoch: [170] [473600/1281167 (37%)]	Loss: 0.631854
[2022-04-07 11:34:50 | train] - Train Epoch: [170] [486400/1281167 (38%)]	Loss: 0.657852
[2022-04-07 11:35:17 | train] - Train Epoch: [170] [499200/1281167 (39%)]	Loss: 0.435463
[2022-04-07 11:35:44 | train] - Train Epoch: [170] [512000/1281167 (40%)]	Loss: 0.613054
[2022-04-07 11:36:12 | train] - Train Epoch: [170] [524800/1281167 (41%)]	Loss: 0.477021
[2022-04-07 11:36:39 | train] - Train Epoch: [170] [537600/1281167 (42%)]	Loss: 0.521987
[2022-04-07 11:37:07 | train] - Train Epoch: [170] [550400/1281167 (43%)]	Loss: 0.519004
[2022-04-07 11:37:34 | train] - Train Epoch: [170] [563200/1281167 (44%)]	Loss: 0.534532
[2022-04-07 11:38:01 | train] - Train Epoch: [170] [576000/1281167 (45%)]	Loss: 0.494234
[2022-04-07 11:38:28 | train] - Train Epoch: [170] [588800/1281167 (46%)]	Loss: 0.741057
[2022-04-07 11:38:55 | train] - Train Epoch: [170] [601600/1281167 (47%)]	Loss: 0.965367
[2022-04-07 11:39:22 | train] - Train Epoch: [170] [614400/1281167 (48%)]	Loss: 0.591855
[2022-04-07 11:39:49 | train] - Train Epoch: [170] [627200/1281167 (49%)]	Loss: 0.712054
[2022-04-07 11:40:16 | train] - Train Epoch: [170] [640000/1281167 (50%)]	Loss: 0.757858
[2022-04-07 11:40:44 | train] - Train Epoch: [170] [652800/1281167 (51%)]	Loss: 0.612635
[2022-04-07 11:41:11 | train] - Train Epoch: [170] [665600/1281167 (52%)]	Loss: 0.744237
[2022-04-07 11:41:39 | train] - Train Epoch: [170] [678400/1281167 (53%)]	Loss: 0.525459
[2022-04-07 11:42:05 | train] - Train Epoch: [170] [691200/1281167 (54%)]	Loss: 0.531661
[2022-04-07 11:42:32 | train] - Train Epoch: [170] [704000/1281167 (55%)]	Loss: 0.492518
[2022-04-07 11:42:59 | train] - Train Epoch: [170] [716800/1281167 (56%)]	Loss: 0.698600
[2022-04-07 11:43:25 | train] - Train Epoch: [170] [729600/1281167 (57%)]	Loss: 0.554370
[2022-04-07 11:43:53 | train] - Train Epoch: [170] [742400/1281167 (58%)]	Loss: 0.630262
[2022-04-07 11:44:20 | train] - Train Epoch: [170] [755200/1281167 (59%)]	Loss: 0.817051
[2022-04-07 11:44:48 | train] - Train Epoch: [170] [768000/1281167 (60%)]	Loss: 0.728659
[2022-04-07 11:45:16 | train] - Train Epoch: [170] [780800/1281167 (61%)]	Loss: 0.747841
[2022-04-07 11:45:43 | train] - Train Epoch: [170] [793600/1281167 (62%)]	Loss: 0.700883
[2022-04-07 11:46:11 | train] - Train Epoch: [170] [806400/1281167 (63%)]	Loss: 0.893925
[2022-04-07 11:46:38 | train] - Train Epoch: [170] [819200/1281167 (64%)]	Loss: 0.708352
[2022-04-07 11:47:06 | train] - Train Epoch: [170] [832000/1281167 (65%)]	Loss: 0.831689
[2022-04-07 11:47:33 | train] - Train Epoch: [170] [844800/1281167 (66%)]	Loss: 0.437380
[2022-04-07 11:48:01 | train] - Train Epoch: [170] [857600/1281167 (67%)]	Loss: 0.554640
[2022-04-07 11:48:28 | train] - Train Epoch: [170] [870400/1281167 (68%)]	Loss: 0.530473
[2022-04-07 11:48:56 | train] - Train Epoch: [170] [883200/1281167 (69%)]	Loss: 0.401863
[2022-04-07 11:49:23 | train] - Train Epoch: [170] [896000/1281167 (70%)]	Loss: 0.640586
[2022-04-07 11:49:51 | train] - Train Epoch: [170] [908800/1281167 (71%)]	Loss: 0.680911
[2022-04-07 11:50:18 | train] - Train Epoch: [170] [921600/1281167 (72%)]	Loss: 0.675321
[2022-04-07 11:50:45 | train] - Train Epoch: [170] [934400/1281167 (73%)]	Loss: 0.561998
[2022-04-07 11:51:12 | train] - Train Epoch: [170] [947200/1281167 (74%)]	Loss: 0.593578
[2022-04-07 11:51:39 | train] - Train Epoch: [170] [960000/1281167 (75%)]	Loss: 0.515620
[2022-04-07 11:52:07 | train] - Train Epoch: [170] [972800/1281167 (76%)]	Loss: 0.637767
[2022-04-07 11:52:33 | train] - Train Epoch: [170] [985600/1281167 (77%)]	Loss: 0.793260
[2022-04-07 11:53:00 | train] - Train Epoch: [170] [998400/1281167 (78%)]	Loss: 0.577727
[2022-04-07 11:53:27 | train] - Train Epoch: [170] [1011200/1281167 (79%)]	Loss: 0.786374
[2022-04-07 11:53:55 | train] - Train Epoch: [170] [1024000/1281167 (80%)]	Loss: 0.384884
[2022-04-07 11:54:23 | train] - Train Epoch: [170] [1036800/1281167 (81%)]	Loss: 0.363344
[2022-04-07 11:54:51 | train] - Train Epoch: [170] [1049600/1281167 (82%)]	Loss: 0.576966
[2022-04-07 11:55:18 | train] - Train Epoch: [170] [1062400/1281167 (83%)]	Loss: 0.350930
[2022-04-07 11:55:47 | train] - Train Epoch: [170] [1075200/1281167 (84%)]	Loss: 0.340341
[2022-04-07 11:56:14 | train] - Train Epoch: [170] [1088000/1281167 (85%)]	Loss: 0.515863
[2022-04-07 11:56:43 | train] - Train Epoch: [170] [1100800/1281167 (86%)]	Loss: 0.759700
[2022-04-07 11:57:11 | train] - Train Epoch: [170] [1113600/1281167 (87%)]	Loss: 0.853700
[2022-04-07 11:57:39 | train] - Train Epoch: [170] [1126400/1281167 (88%)]	Loss: 0.478419
[2022-04-07 11:58:06 | train] - Train Epoch: [170] [1139200/1281167 (89%)]	Loss: 0.479867
[2022-04-07 11:58:34 | train] - Train Epoch: [170] [1152000/1281167 (90%)]	Loss: 0.846246
[2022-04-07 11:59:02 | train] - Train Epoch: [170] [1164800/1281167 (91%)]	Loss: 0.786043
[2022-04-07 11:59:31 | train] - Train Epoch: [170] [1177600/1281167 (92%)]	Loss: 0.579235
[2022-04-07 11:59:59 | train] - Train Epoch: [170] [1190400/1281167 (93%)]	Loss: 0.877347
[2022-04-07 12:00:27 | train] - Train Epoch: [170] [1203200/1281167 (94%)]	Loss: 0.368816
[2022-04-07 12:00:55 | train] - Train Epoch: [170] [1216000/1281167 (95%)]	Loss: 0.840602
[2022-04-07 12:01:23 | train] - Train Epoch: [170] [1228800/1281167 (96%)]	Loss: 0.697291
[2022-04-07 12:01:51 | train] - Train Epoch: [170] [1241600/1281167 (97%)]	Loss: 0.548433
[2022-04-07 12:02:18 | train] - Train Epoch: [170] [1254400/1281167 (98%)]	Loss: 0.595360
[2022-04-07 12:02:46 | train] - Train Epoch: [170] [1267200/1281167 (99%)]	Loss: 0.763728
[2022-04-07 12:03:14 | train] - Train Epoch: [170] [1280000/1281167 (100%)]	Loss: 0.731251
[2022-04-07 12:03:16 | train] - Train Epoch: [170]	 Average Loss: 0.640872	 Total Acc : 84.6423	 Total Top5 Acc : 94.4137
[2022-04-07 12:03:16 | train] - -------170 epoch end-----------
========================================
-------170 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 12:05:02 | train] - 
Epoch [170] Test set: Average loss: 1.4539, Accuracy: 34881/50000 (69.7383%), Top-5 Accuracy: 88.7452%

[2022-04-07 12:05:02 | train] - save intermediate epoch [170] result


[2022-04-07 12:05:20 | train] - -------171 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 12:05:22 | train] - Train Epoch: [171] [0/1281167 (0%)]	Loss: 0.804367
[2022-04-07 12:05:47 | train] - Train Epoch: [171] [12800/1281167 (1%)]	Loss: 0.722104
[2022-04-07 12:06:12 | train] - Train Epoch: [171] [25600/1281167 (2%)]	Loss: 0.686486
[2022-04-07 12:06:37 | train] - Train Epoch: [171] [38400/1281167 (3%)]	Loss: 0.952294
[2022-04-07 12:07:02 | train] - Train Epoch: [171] [51200/1281167 (4%)]	Loss: 0.779769
[2022-04-07 12:07:28 | train] - Train Epoch: [171] [64000/1281167 (5%)]	Loss: 0.827326
[2022-04-07 12:07:54 | train] - Train Epoch: [171] [76800/1281167 (6%)]	Loss: 0.592795
[2022-04-07 12:08:20 | train] - Train Epoch: [171] [89600/1281167 (7%)]	Loss: 0.680611
[2022-04-07 12:08:46 | train] - Train Epoch: [171] [102400/1281167 (8%)]	Loss: 0.761078
[2022-04-07 12:09:12 | train] - Train Epoch: [171] [115200/1281167 (9%)]	Loss: 0.679871
[2022-04-07 12:09:37 | train] - Train Epoch: [171] [128000/1281167 (10%)]	Loss: 0.782908
[2022-04-07 12:10:02 | train] - Train Epoch: [171] [140800/1281167 (11%)]	Loss: 0.804634
[2022-04-07 12:10:28 | train] - Train Epoch: [171] [153600/1281167 (12%)]	Loss: 0.631830
[2022-04-07 12:10:54 | train] - Train Epoch: [171] [166400/1281167 (13%)]	Loss: 0.736444
[2022-04-07 12:11:19 | train] - Train Epoch: [171] [179200/1281167 (14%)]	Loss: 0.681291
[2022-04-07 12:11:45 | train] - Train Epoch: [171] [192000/1281167 (15%)]	Loss: 0.690072
[2022-04-07 12:12:12 | train] - Train Epoch: [171] [204800/1281167 (16%)]	Loss: 0.856946
[2022-04-07 12:12:38 | train] - Train Epoch: [171] [217600/1281167 (17%)]	Loss: 0.767624
[2022-04-07 12:13:04 | train] - Train Epoch: [171] [230400/1281167 (18%)]	Loss: 0.752652
[2022-04-07 12:13:29 | train] - Train Epoch: [171] [243200/1281167 (19%)]	Loss: 0.618398
[2022-04-07 12:13:55 | train] - Train Epoch: [171] [256000/1281167 (20%)]	Loss: 0.595344
[2022-04-07 12:14:21 | train] - Train Epoch: [171] [268800/1281167 (21%)]	Loss: 0.481634
[2022-04-07 12:14:47 | train] - Train Epoch: [171] [281600/1281167 (22%)]	Loss: 0.867784
[2022-04-07 12:15:13 | train] - Train Epoch: [171] [294400/1281167 (23%)]	Loss: 0.541476
[2022-04-07 12:15:40 | train] - Train Epoch: [171] [307200/1281167 (24%)]	Loss: 0.519988
[2022-04-07 12:16:06 | train] - Train Epoch: [171] [320000/1281167 (25%)]	Loss: 0.697894
[2022-04-07 12:16:32 | train] - Train Epoch: [171] [332800/1281167 (26%)]	Loss: 0.740237
[2022-04-07 12:16:57 | train] - Train Epoch: [171] [345600/1281167 (27%)]	Loss: 0.724838
[2022-04-07 12:17:22 | train] - Train Epoch: [171] [358400/1281167 (28%)]	Loss: 0.463678
[2022-04-07 12:17:46 | train] - Train Epoch: [171] [371200/1281167 (29%)]	Loss: 0.968049
[2022-04-07 12:18:12 | train] - Train Epoch: [171] [384000/1281167 (30%)]	Loss: 0.825518
[2022-04-07 12:18:37 | train] - Train Epoch: [171] [396800/1281167 (31%)]	Loss: 0.787337
[2022-04-07 12:19:02 | train] - Train Epoch: [171] [409600/1281167 (32%)]	Loss: 0.521537
[2022-04-07 12:19:27 | train] - Train Epoch: [171] [422400/1281167 (33%)]	Loss: 0.769165
[2022-04-07 12:19:52 | train] - Train Epoch: [171] [435200/1281167 (34%)]	Loss: 0.521757
[2022-04-07 12:20:17 | train] - Train Epoch: [171] [448000/1281167 (35%)]	Loss: 0.775863
[2022-04-07 12:20:42 | train] - Train Epoch: [171] [460800/1281167 (36%)]	Loss: 0.536603
[2022-04-07 12:21:07 | train] - Train Epoch: [171] [473600/1281167 (37%)]	Loss: 0.835575
[2022-04-07 12:21:32 | train] - Train Epoch: [171] [486400/1281167 (38%)]	Loss: 0.512316
[2022-04-07 12:21:56 | train] - Train Epoch: [171] [499200/1281167 (39%)]	Loss: 0.898583
[2022-04-07 12:22:22 | train] - Train Epoch: [171] [512000/1281167 (40%)]	Loss: 0.744732
[2022-04-07 12:22:47 | train] - Train Epoch: [171] [524800/1281167 (41%)]	Loss: 0.769947
[2022-04-07 12:23:12 | train] - Train Epoch: [171] [537600/1281167 (42%)]	Loss: 0.797026
[2022-04-07 12:23:36 | train] - Train Epoch: [171] [550400/1281167 (43%)]	Loss: 0.792778
[2022-04-07 12:24:01 | train] - Train Epoch: [171] [563200/1281167 (44%)]	Loss: 0.837698
[2022-04-07 12:24:26 | train] - Train Epoch: [171] [576000/1281167 (45%)]	Loss: 0.576031
[2022-04-07 12:24:52 | train] - Train Epoch: [171] [588800/1281167 (46%)]	Loss: 0.677075
[2022-04-07 12:25:16 | train] - Train Epoch: [171] [601600/1281167 (47%)]	Loss: 0.592809
[2022-04-07 12:25:41 | train] - Train Epoch: [171] [614400/1281167 (48%)]	Loss: 0.880957
[2022-04-07 12:26:06 | train] - Train Epoch: [171] [627200/1281167 (49%)]	Loss: 0.873632
[2022-04-07 12:26:31 | train] - Train Epoch: [171] [640000/1281167 (50%)]	Loss: 0.666877
[2022-04-07 12:26:56 | train] - Train Epoch: [171] [652800/1281167 (51%)]	Loss: 0.765378
[2022-04-07 12:27:21 | train] - Train Epoch: [171] [665600/1281167 (52%)]	Loss: 0.725471
[2022-04-07 12:27:45 | train] - Train Epoch: [171] [678400/1281167 (53%)]	Loss: 0.837242
[2022-04-07 12:28:10 | train] - Train Epoch: [171] [691200/1281167 (54%)]	Loss: 0.542230
[2022-04-07 12:28:36 | train] - Train Epoch: [171] [704000/1281167 (55%)]	Loss: 0.879782
[2022-04-07 12:29:01 | train] - Train Epoch: [171] [716800/1281167 (56%)]	Loss: 0.525002
[2022-04-07 12:29:25 | train] - Train Epoch: [171] [729600/1281167 (57%)]	Loss: 0.716832
[2022-04-07 12:29:51 | train] - Train Epoch: [171] [742400/1281167 (58%)]	Loss: 0.533506
[2022-04-07 12:30:15 | train] - Train Epoch: [171] [755200/1281167 (59%)]	Loss: 0.777375
[2022-04-07 12:30:40 | train] - Train Epoch: [171] [768000/1281167 (60%)]	Loss: 0.542616
[2022-04-07 12:31:05 | train] - Train Epoch: [171] [780800/1281167 (61%)]	Loss: 0.676880
[2022-04-07 12:31:29 | train] - Train Epoch: [171] [793600/1281167 (62%)]	Loss: 0.608512
[2022-04-07 12:31:54 | train] - Train Epoch: [171] [806400/1281167 (63%)]	Loss: 0.694129
[2022-04-07 12:32:19 | train] - Train Epoch: [171] [819200/1281167 (64%)]	Loss: 0.700507
[2022-04-07 12:32:45 | train] - Train Epoch: [171] [832000/1281167 (65%)]	Loss: 0.632403
[2022-04-07 12:33:09 | train] - Train Epoch: [171] [844800/1281167 (66%)]	Loss: 0.510694
[2022-04-07 12:33:34 | train] - Train Epoch: [171] [857600/1281167 (67%)]	Loss: 0.708446
[2022-04-07 12:33:59 | train] - Train Epoch: [171] [870400/1281167 (68%)]	Loss: 0.826914
[2022-04-07 12:34:24 | train] - Train Epoch: [171] [883200/1281167 (69%)]	Loss: 0.900440
[2022-04-07 12:34:48 | train] - Train Epoch: [171] [896000/1281167 (70%)]	Loss: 0.635258
[2022-04-07 12:35:13 | train] - Train Epoch: [171] [908800/1281167 (71%)]	Loss: 0.712453
[2022-04-07 12:35:38 | train] - Train Epoch: [171] [921600/1281167 (72%)]	Loss: 0.673411
[2022-04-07 12:36:03 | train] - Train Epoch: [171] [934400/1281167 (73%)]	Loss: 0.927430
[2022-04-07 12:36:28 | train] - Train Epoch: [171] [947200/1281167 (74%)]	Loss: 0.724271
[2022-04-07 12:36:53 | train] - Train Epoch: [171] [960000/1281167 (75%)]	Loss: 0.644476
[2022-04-07 12:37:18 | train] - Train Epoch: [171] [972800/1281167 (76%)]	Loss: 0.962729
[2022-04-07 12:37:43 | train] - Train Epoch: [171] [985600/1281167 (77%)]	Loss: 0.760114
[2022-04-07 12:38:07 | train] - Train Epoch: [171] [998400/1281167 (78%)]	Loss: 0.863742
[2022-04-07 12:38:32 | train] - Train Epoch: [171] [1011200/1281167 (79%)]	Loss: 0.957693
[2022-04-07 12:38:57 | train] - Train Epoch: [171] [1024000/1281167 (80%)]	Loss: 0.589082
[2022-04-07 12:39:22 | train] - Train Epoch: [171] [1036800/1281167 (81%)]	Loss: 0.884671
[2022-04-07 12:39:46 | train] - Train Epoch: [171] [1049600/1281167 (82%)]	Loss: 0.834342
[2022-04-07 12:40:11 | train] - Train Epoch: [171] [1062400/1281167 (83%)]	Loss: 0.604804
[2022-04-07 12:40:36 | train] - Train Epoch: [171] [1075200/1281167 (84%)]	Loss: 0.728170
[2022-04-07 12:41:01 | train] - Train Epoch: [171] [1088000/1281167 (85%)]	Loss: 0.593848
[2022-04-07 12:41:25 | train] - Train Epoch: [171] [1100800/1281167 (86%)]	Loss: 0.652086
[2022-04-07 12:41:51 | train] - Train Epoch: [171] [1113600/1281167 (87%)]	Loss: 0.768355
[2022-04-07 12:42:16 | train] - Train Epoch: [171] [1126400/1281167 (88%)]	Loss: 0.706650
[2022-04-07 12:42:40 | train] - Train Epoch: [171] [1139200/1281167 (89%)]	Loss: 0.561011
[2022-04-07 12:43:06 | train] - Train Epoch: [171] [1152000/1281167 (90%)]	Loss: 0.759299
[2022-04-07 12:43:31 | train] - Train Epoch: [171] [1164800/1281167 (91%)]	Loss: 0.638723
[2022-04-07 12:43:56 | train] - Train Epoch: [171] [1177600/1281167 (92%)]	Loss: 0.576601
[2022-04-07 12:44:21 | train] - Train Epoch: [171] [1190400/1281167 (93%)]	Loss: 0.720908
[2022-04-07 12:44:46 | train] - Train Epoch: [171] [1203200/1281167 (94%)]	Loss: 0.888093
[2022-04-07 12:45:11 | train] - Train Epoch: [171] [1216000/1281167 (95%)]	Loss: 0.692752
[2022-04-07 12:45:36 | train] - Train Epoch: [171] [1228800/1281167 (96%)]	Loss: 0.638924
[2022-04-07 12:46:01 | train] - Train Epoch: [171] [1241600/1281167 (97%)]	Loss: 0.568062
[2022-04-07 12:46:25 | train] - Train Epoch: [171] [1254400/1281167 (98%)]	Loss: 0.696451
[2022-04-07 12:46:50 | train] - Train Epoch: [171] [1267200/1281167 (99%)]	Loss: 0.547535
[2022-04-07 12:47:14 | train] - Train Epoch: [171] [1280000/1281167 (100%)]	Loss: 0.824661
[2022-04-07 12:47:16 | train] - Train Epoch: [171]	 Average Loss: 0.702401	 Total Acc : 83.0226	 Total Top5 Acc : 93.8095
[2022-04-07 12:47:16 | train] - -------171 epoch end-----------
========================================
-------171 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 12:49:01 | train] - 
Epoch [171] Test set: Average loss: 1.4587, Accuracy: 34891/50000 (69.7534%), Top-5 Accuracy: 88.7860%

[2022-04-07 12:49:01 | train] - save intermediate epoch [171] result


[2022-04-07 12:49:21 | train] - -------172 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 12:49:22 | train] - Train Epoch: [172] [0/1281167 (0%)]	Loss: 0.813015
[2022-04-07 12:49:45 | train] - Train Epoch: [172] [12800/1281167 (1%)]	Loss: 0.929139
[2022-04-07 12:50:09 | train] - Train Epoch: [172] [25600/1281167 (2%)]	Loss: 0.388893
[2022-04-07 12:50:33 | train] - Train Epoch: [172] [38400/1281167 (3%)]	Loss: 0.767106
[2022-04-07 12:50:56 | train] - Train Epoch: [172] [51200/1281167 (4%)]	Loss: 0.773281
[2022-04-07 12:51:20 | train] - Train Epoch: [172] [64000/1281167 (5%)]	Loss: 0.525868
[2022-04-07 12:51:44 | train] - Train Epoch: [172] [76800/1281167 (6%)]	Loss: 0.678773
[2022-04-07 12:52:08 | train] - Train Epoch: [172] [89600/1281167 (7%)]	Loss: 0.726522
[2022-04-07 12:52:32 | train] - Train Epoch: [172] [102400/1281167 (8%)]	Loss: 0.815257
[2022-04-07 12:52:57 | train] - Train Epoch: [172] [115200/1281167 (9%)]	Loss: 0.614950
[2022-04-07 12:53:20 | train] - Train Epoch: [172] [128000/1281167 (10%)]	Loss: 0.949468
[2022-04-07 12:53:43 | train] - Train Epoch: [172] [140800/1281167 (11%)]	Loss: 0.784687
[2022-04-07 12:54:07 | train] - Train Epoch: [172] [153600/1281167 (12%)]	Loss: 0.878468
[2022-04-07 12:54:31 | train] - Train Epoch: [172] [166400/1281167 (13%)]	Loss: 0.920649
[2022-04-07 12:54:54 | train] - Train Epoch: [172] [179200/1281167 (14%)]	Loss: 1.070351
[2022-04-07 12:55:18 | train] - Train Epoch: [172] [192000/1281167 (15%)]	Loss: 0.774131
[2022-04-07 12:55:41 | train] - Train Epoch: [172] [204800/1281167 (16%)]	Loss: 0.739586
[2022-04-07 12:56:05 | train] - Train Epoch: [172] [217600/1281167 (17%)]	Loss: 0.935516
[2022-04-07 12:56:30 | train] - Train Epoch: [172] [230400/1281167 (18%)]	Loss: 0.979452
[2022-04-07 12:56:53 | train] - Train Epoch: [172] [243200/1281167 (19%)]	Loss: 0.644809
[2022-04-07 12:57:17 | train] - Train Epoch: [172] [256000/1281167 (20%)]	Loss: 0.755332
[2022-04-07 12:57:41 | train] - Train Epoch: [172] [268800/1281167 (21%)]	Loss: 0.760600
[2022-04-07 12:58:06 | train] - Train Epoch: [172] [281600/1281167 (22%)]	Loss: 0.761895
[2022-04-07 12:58:29 | train] - Train Epoch: [172] [294400/1281167 (23%)]	Loss: 0.809088
[2022-04-07 12:58:53 | train] - Train Epoch: [172] [307200/1281167 (24%)]	Loss: 1.006981
[2022-04-07 12:59:17 | train] - Train Epoch: [172] [320000/1281167 (25%)]	Loss: 0.787318
[2022-04-07 12:59:40 | train] - Train Epoch: [172] [332800/1281167 (26%)]	Loss: 1.041181
[2022-04-07 13:00:04 | train] - Train Epoch: [172] [345600/1281167 (27%)]	Loss: 0.499303
[2022-04-07 13:00:28 | train] - Train Epoch: [172] [358400/1281167 (28%)]	Loss: 0.839613
[2022-04-07 13:00:51 | train] - Train Epoch: [172] [371200/1281167 (29%)]	Loss: 0.634344
[2022-04-07 13:01:16 | train] - Train Epoch: [172] [384000/1281167 (30%)]	Loss: 0.669747
[2022-04-07 13:01:40 | train] - Train Epoch: [172] [396800/1281167 (31%)]	Loss: 0.834700
[2022-04-07 13:02:03 | train] - Train Epoch: [172] [409600/1281167 (32%)]	Loss: 0.719865
[2022-04-07 13:02:26 | train] - Train Epoch: [172] [422400/1281167 (33%)]	Loss: 0.520900
[2022-04-07 13:02:50 | train] - Train Epoch: [172] [435200/1281167 (34%)]	Loss: 0.864907
[2022-04-07 13:03:13 | train] - Train Epoch: [172] [448000/1281167 (35%)]	Loss: 0.719493
[2022-04-07 13:03:37 | train] - Train Epoch: [172] [460800/1281167 (36%)]	Loss: 0.996806
[2022-04-07 13:04:01 | train] - Train Epoch: [172] [473600/1281167 (37%)]	Loss: 0.885885
[2022-04-07 13:04:26 | train] - Train Epoch: [172] [486400/1281167 (38%)]	Loss: 0.951654
[2022-04-07 13:04:50 | train] - Train Epoch: [172] [499200/1281167 (39%)]	Loss: 0.779634
[2022-04-07 13:05:13 | train] - Train Epoch: [172] [512000/1281167 (40%)]	Loss: 0.614657
[2022-04-07 13:05:37 | train] - Train Epoch: [172] [524800/1281167 (41%)]	Loss: 0.779822
[2022-04-07 13:06:00 | train] - Train Epoch: [172] [537600/1281167 (42%)]	Loss: 0.912761
[2022-04-07 13:06:23 | train] - Train Epoch: [172] [550400/1281167 (43%)]	Loss: 0.804838
[2022-04-07 13:06:47 | train] - Train Epoch: [172] [563200/1281167 (44%)]	Loss: 0.701676
[2022-04-07 13:07:11 | train] - Train Epoch: [172] [576000/1281167 (45%)]	Loss: 0.749190
[2022-04-07 13:07:34 | train] - Train Epoch: [172] [588800/1281167 (46%)]	Loss: 0.885485
[2022-04-07 13:07:58 | train] - Train Epoch: [172] [601600/1281167 (47%)]	Loss: 0.724480
[2022-04-07 13:08:21 | train] - Train Epoch: [172] [614400/1281167 (48%)]	Loss: 0.765845
[2022-04-07 13:08:45 | train] - Train Epoch: [172] [627200/1281167 (49%)]	Loss: 0.787801
[2022-04-07 13:09:08 | train] - Train Epoch: [172] [640000/1281167 (50%)]	Loss: 0.743925
[2022-04-07 13:09:30 | train] - Train Epoch: [172] [652800/1281167 (51%)]	Loss: 0.685316
[2022-04-07 13:09:54 | train] - Train Epoch: [172] [665600/1281167 (52%)]	Loss: 0.852640
[2022-04-07 13:10:17 | train] - Train Epoch: [172] [678400/1281167 (53%)]	Loss: 0.770484
[2022-04-07 13:10:40 | train] - Train Epoch: [172] [691200/1281167 (54%)]	Loss: 0.878244
[2022-04-07 13:11:03 | train] - Train Epoch: [172] [704000/1281167 (55%)]	Loss: 0.715099
[2022-04-07 13:11:28 | train] - Train Epoch: [172] [716800/1281167 (56%)]	Loss: 0.910036
[2022-04-07 13:11:51 | train] - Train Epoch: [172] [729600/1281167 (57%)]	Loss: 0.695500
[2022-04-07 13:12:15 | train] - Train Epoch: [172] [742400/1281167 (58%)]	Loss: 0.444844
[2022-04-07 13:12:37 | train] - Train Epoch: [172] [755200/1281167 (59%)]	Loss: 0.838451
[2022-04-07 13:13:02 | train] - Train Epoch: [172] [768000/1281167 (60%)]	Loss: 0.797801
[2022-04-07 13:13:24 | train] - Train Epoch: [172] [780800/1281167 (61%)]	Loss: 0.680618
[2022-04-07 13:13:47 | train] - Train Epoch: [172] [793600/1281167 (62%)]	Loss: 0.905558
[2022-04-07 13:14:11 | train] - Train Epoch: [172] [806400/1281167 (63%)]	Loss: 0.480706
[2022-04-07 13:14:34 | train] - Train Epoch: [172] [819200/1281167 (64%)]	Loss: 1.008111
[2022-04-07 13:14:58 | train] - Train Epoch: [172] [832000/1281167 (65%)]	Loss: 0.811973
[2022-04-07 13:15:21 | train] - Train Epoch: [172] [844800/1281167 (66%)]	Loss: 0.724398
[2022-04-07 13:15:44 | train] - Train Epoch: [172] [857600/1281167 (67%)]	Loss: 0.832525
[2022-04-07 13:16:07 | train] - Train Epoch: [172] [870400/1281167 (68%)]	Loss: 0.552906
[2022-04-07 13:16:31 | train] - Train Epoch: [172] [883200/1281167 (69%)]	Loss: 0.777470
[2022-04-07 13:16:54 | train] - Train Epoch: [172] [896000/1281167 (70%)]	Loss: 0.777965
[2022-04-07 13:17:17 | train] - Train Epoch: [172] [908800/1281167 (71%)]	Loss: 0.592180
[2022-04-07 13:17:40 | train] - Train Epoch: [172] [921600/1281167 (72%)]	Loss: 0.684348
[2022-04-07 13:18:03 | train] - Train Epoch: [172] [934400/1281167 (73%)]	Loss: 0.839906
[2022-04-07 13:18:26 | train] - Train Epoch: [172] [947200/1281167 (74%)]	Loss: 0.767430
[2022-04-07 13:18:49 | train] - Train Epoch: [172] [960000/1281167 (75%)]	Loss: 1.000137
[2022-04-07 13:19:13 | train] - Train Epoch: [172] [972800/1281167 (76%)]	Loss: 0.865284
[2022-04-07 13:19:36 | train] - Train Epoch: [172] [985600/1281167 (77%)]	Loss: 0.911144
[2022-04-07 13:20:00 | train] - Train Epoch: [172] [998400/1281167 (78%)]	Loss: 0.980905
[2022-04-07 13:20:22 | train] - Train Epoch: [172] [1011200/1281167 (79%)]	Loss: 0.740037
[2022-04-07 13:20:46 | train] - Train Epoch: [172] [1024000/1281167 (80%)]	Loss: 0.711708
[2022-04-07 13:21:09 | train] - Train Epoch: [172] [1036800/1281167 (81%)]	Loss: 0.998602
[2022-04-07 13:21:32 | train] - Train Epoch: [172] [1049600/1281167 (82%)]	Loss: 1.035210
[2022-04-07 13:21:56 | train] - Train Epoch: [172] [1062400/1281167 (83%)]	Loss: 0.740610
[2022-04-07 13:22:19 | train] - Train Epoch: [172] [1075200/1281167 (84%)]	Loss: 0.672665
[2022-04-07 13:22:41 | train] - Train Epoch: [172] [1088000/1281167 (85%)]	Loss: 0.534283
[2022-04-07 13:23:05 | train] - Train Epoch: [172] [1100800/1281167 (86%)]	Loss: 0.698887
[2022-04-07 13:23:28 | train] - Train Epoch: [172] [1113600/1281167 (87%)]	Loss: 0.852257
[2022-04-07 13:23:51 | train] - Train Epoch: [172] [1126400/1281167 (88%)]	Loss: 0.710884
[2022-04-07 13:24:14 | train] - Train Epoch: [172] [1139200/1281167 (89%)]	Loss: 0.587590
[2022-04-07 13:24:37 | train] - Train Epoch: [172] [1152000/1281167 (90%)]	Loss: 0.473751
[2022-04-07 13:25:00 | train] - Train Epoch: [172] [1164800/1281167 (91%)]	Loss: 0.823170
[2022-04-07 13:25:23 | train] - Train Epoch: [172] [1177600/1281167 (92%)]	Loss: 0.821752
[2022-04-07 13:25:47 | train] - Train Epoch: [172] [1190400/1281167 (93%)]	Loss: 0.629109
[2022-04-07 13:26:10 | train] - Train Epoch: [172] [1203200/1281167 (94%)]	Loss: 0.534577
[2022-04-07 13:26:33 | train] - Train Epoch: [172] [1216000/1281167 (95%)]	Loss: 0.742132
[2022-04-07 13:26:56 | train] - Train Epoch: [172] [1228800/1281167 (96%)]	Loss: 0.989846
[2022-04-07 13:27:20 | train] - Train Epoch: [172] [1241600/1281167 (97%)]	Loss: 0.538905
[2022-04-07 13:27:43 | train] - Train Epoch: [172] [1254400/1281167 (98%)]	Loss: 0.683656
[2022-04-07 13:28:05 | train] - Train Epoch: [172] [1267200/1281167 (99%)]	Loss: 0.868174
[2022-04-07 13:28:29 | train] - Train Epoch: [172] [1280000/1281167 (100%)]	Loss: 0.600974
[2022-04-07 13:28:31 | train] - Train Epoch: [172]	 Average Loss: 0.761175	 Total Acc : 81.3743	 Total Top5 Acc : 93.2340
[2022-04-07 13:28:31 | train] - -------172 epoch end-----------
========================================
-------172 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 13:30:13 | train] - 
Epoch [172] Test set: Average loss: 1.4672, Accuracy: 34908/50000 (69.7886%), Top-5 Accuracy: 88.7412%

[2022-04-07 13:30:13 | train] - save intermediate epoch [172] result


[2022-04-07 13:30:33 | train] - -------173 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 13:30:34 | train] - Train Epoch: [173] [0/1281167 (0%)]	Loss: 0.798391
[2022-04-07 13:31:00 | train] - Train Epoch: [173] [12800/1281167 (1%)]	Loss: 0.736782
[2022-04-07 13:31:27 | train] - Train Epoch: [173] [25600/1281167 (2%)]	Loss: 0.989444
[2022-04-07 13:31:52 | train] - Train Epoch: [173] [38400/1281167 (3%)]	Loss: 1.064164
[2022-04-07 13:32:18 | train] - Train Epoch: [173] [51200/1281167 (4%)]	Loss: 0.710634
[2022-04-07 13:32:44 | train] - Train Epoch: [173] [64000/1281167 (5%)]	Loss: 0.816860
[2022-04-07 13:33:11 | train] - Train Epoch: [173] [76800/1281167 (6%)]	Loss: 0.941369
[2022-04-07 13:33:37 | train] - Train Epoch: [173] [89600/1281167 (7%)]	Loss: 0.937244
[2022-04-07 13:34:03 | train] - Train Epoch: [173] [102400/1281167 (8%)]	Loss: 0.649886
[2022-04-07 13:34:29 | train] - Train Epoch: [173] [115200/1281167 (9%)]	Loss: 0.884769
[2022-04-07 13:34:54 | train] - Train Epoch: [173] [128000/1281167 (10%)]	Loss: 0.794351
[2022-04-07 13:35:20 | train] - Train Epoch: [173] [140800/1281167 (11%)]	Loss: 0.818868
[2022-04-07 13:35:46 | train] - Train Epoch: [173] [153600/1281167 (12%)]	Loss: 0.689959
[2022-04-07 13:36:12 | train] - Train Epoch: [173] [166400/1281167 (13%)]	Loss: 0.910818
[2022-04-07 13:36:38 | train] - Train Epoch: [173] [179200/1281167 (14%)]	Loss: 0.762590
[2022-04-07 13:37:05 | train] - Train Epoch: [173] [192000/1281167 (15%)]	Loss: 0.735865
[2022-04-07 13:37:30 | train] - Train Epoch: [173] [204800/1281167 (16%)]	Loss: 1.016874
[2022-04-07 13:37:56 | train] - Train Epoch: [173] [217600/1281167 (17%)]	Loss: 0.704598
[2022-04-07 13:38:23 | train] - Train Epoch: [173] [230400/1281167 (18%)]	Loss: 0.550496
[2022-04-07 13:38:50 | train] - Train Epoch: [173] [243200/1281167 (19%)]	Loss: 0.816213
[2022-04-07 13:39:16 | train] - Train Epoch: [173] [256000/1281167 (20%)]	Loss: 0.746900
[2022-04-07 13:39:43 | train] - Train Epoch: [173] [268800/1281167 (21%)]	Loss: 0.718832
[2022-04-07 13:40:09 | train] - Train Epoch: [173] [281600/1281167 (22%)]	Loss: 0.500200
[2022-04-07 13:40:35 | train] - Train Epoch: [173] [294400/1281167 (23%)]	Loss: 0.801674
[2022-04-07 13:41:02 | train] - Train Epoch: [173] [307200/1281167 (24%)]	Loss: 0.629608
[2022-04-07 13:41:29 | train] - Train Epoch: [173] [320000/1281167 (25%)]	Loss: 0.738635
[2022-04-07 13:41:56 | train] - Train Epoch: [173] [332800/1281167 (26%)]	Loss: 0.630259
[2022-04-07 13:42:23 | train] - Train Epoch: [173] [345600/1281167 (27%)]	Loss: 0.946599
[2022-04-07 13:42:49 | train] - Train Epoch: [173] [358400/1281167 (28%)]	Loss: 0.648721
[2022-04-07 13:43:16 | train] - Train Epoch: [173] [371200/1281167 (29%)]	Loss: 0.537997
[2022-04-07 13:43:43 | train] - Train Epoch: [173] [384000/1281167 (30%)]	Loss: 0.772682
[2022-04-07 13:44:10 | train] - Train Epoch: [173] [396800/1281167 (31%)]	Loss: 0.714510
[2022-04-07 13:44:37 | train] - Train Epoch: [173] [409600/1281167 (32%)]	Loss: 0.716666
[2022-04-07 13:45:04 | train] - Train Epoch: [173] [422400/1281167 (33%)]	Loss: 0.880775
[2022-04-07 13:45:30 | train] - Train Epoch: [173] [435200/1281167 (34%)]	Loss: 0.684535
[2022-04-07 13:45:57 | train] - Train Epoch: [173] [448000/1281167 (35%)]	Loss: 0.978682
[2022-04-07 13:46:24 | train] - Train Epoch: [173] [460800/1281167 (36%)]	Loss: 0.483329
[2022-04-07 13:46:51 | train] - Train Epoch: [173] [473600/1281167 (37%)]	Loss: 0.879836
[2022-04-07 13:47:18 | train] - Train Epoch: [173] [486400/1281167 (38%)]	Loss: 0.480960
[2022-04-07 13:47:45 | train] - Train Epoch: [173] [499200/1281167 (39%)]	Loss: 0.879135
[2022-04-07 13:48:12 | train] - Train Epoch: [173] [512000/1281167 (40%)]	Loss: 1.094955
[2022-04-07 13:48:39 | train] - Train Epoch: [173] [524800/1281167 (41%)]	Loss: 0.982837
[2022-04-07 13:49:06 | train] - Train Epoch: [173] [537600/1281167 (42%)]	Loss: 0.791248
[2022-04-07 13:49:34 | train] - Train Epoch: [173] [550400/1281167 (43%)]	Loss: 0.637008
[2022-04-07 13:50:01 | train] - Train Epoch: [173] [563200/1281167 (44%)]	Loss: 0.775454
[2022-04-07 13:50:27 | train] - Train Epoch: [173] [576000/1281167 (45%)]	Loss: 0.750511
[2022-04-07 13:50:55 | train] - Train Epoch: [173] [588800/1281167 (46%)]	Loss: 0.591319
[2022-04-07 13:51:23 | train] - Train Epoch: [173] [601600/1281167 (47%)]	Loss: 0.787578
[2022-04-07 13:51:51 | train] - Train Epoch: [173] [614400/1281167 (48%)]	Loss: 0.496147
[2022-04-07 13:52:17 | train] - Train Epoch: [173] [627200/1281167 (49%)]	Loss: 0.733103
[2022-04-07 13:52:45 | train] - Train Epoch: [173] [640000/1281167 (50%)]	Loss: 0.881990
[2022-04-07 13:53:14 | train] - Train Epoch: [173] [652800/1281167 (51%)]	Loss: 1.083596
[2022-04-07 13:53:42 | train] - Train Epoch: [173] [665600/1281167 (52%)]	Loss: 0.752848
[2022-04-07 13:54:10 | train] - Train Epoch: [173] [678400/1281167 (53%)]	Loss: 0.854166
[2022-04-07 13:54:38 | train] - Train Epoch: [173] [691200/1281167 (54%)]	Loss: 0.526253
[2022-04-07 13:55:05 | train] - Train Epoch: [173] [704000/1281167 (55%)]	Loss: 0.886640
[2022-04-07 13:55:33 | train] - Train Epoch: [173] [716800/1281167 (56%)]	Loss: 0.752450
[2022-04-07 13:56:02 | train] - Train Epoch: [173] [729600/1281167 (57%)]	Loss: 0.697556
[2022-04-07 13:56:30 | train] - Train Epoch: [173] [742400/1281167 (58%)]	Loss: 1.041968
[2022-04-07 13:56:58 | train] - Train Epoch: [173] [755200/1281167 (59%)]	Loss: 0.952628
[2022-04-07 13:57:25 | train] - Train Epoch: [173] [768000/1281167 (60%)]	Loss: 0.825094
[2022-04-07 13:57:53 | train] - Train Epoch: [173] [780800/1281167 (61%)]	Loss: 0.648544
[2022-04-07 13:58:21 | train] - Train Epoch: [173] [793600/1281167 (62%)]	Loss: 0.899146
[2022-04-07 13:58:48 | train] - Train Epoch: [173] [806400/1281167 (63%)]	Loss: 0.828453
[2022-04-07 13:59:15 | train] - Train Epoch: [173] [819200/1281167 (64%)]	Loss: 0.652811
[2022-04-07 13:59:43 | train] - Train Epoch: [173] [832000/1281167 (65%)]	Loss: 1.070160
[2022-04-07 14:00:10 | train] - Train Epoch: [173] [844800/1281167 (66%)]	Loss: 0.883263
[2022-04-07 14:00:37 | train] - Train Epoch: [173] [857600/1281167 (67%)]	Loss: 0.806591
[2022-04-07 14:01:05 | train] - Train Epoch: [173] [870400/1281167 (68%)]	Loss: 0.603079
[2022-04-07 14:01:33 | train] - Train Epoch: [173] [883200/1281167 (69%)]	Loss: 0.714944
[2022-04-07 14:02:00 | train] - Train Epoch: [173] [896000/1281167 (70%)]	Loss: 0.675460
[2022-04-07 14:02:28 | train] - Train Epoch: [173] [908800/1281167 (71%)]	Loss: 0.706580
[2022-04-07 14:02:55 | train] - Train Epoch: [173] [921600/1281167 (72%)]	Loss: 0.769947
[2022-04-07 14:03:22 | train] - Train Epoch: [173] [934400/1281167 (73%)]	Loss: 0.747138
[2022-04-07 14:03:49 | train] - Train Epoch: [173] [947200/1281167 (74%)]	Loss: 0.951017
[2022-04-07 14:04:18 | train] - Train Epoch: [173] [960000/1281167 (75%)]	Loss: 0.731607
[2022-04-07 14:04:45 | train] - Train Epoch: [173] [972800/1281167 (76%)]	Loss: 0.945394
[2022-04-07 14:05:13 | train] - Train Epoch: [173] [985600/1281167 (77%)]	Loss: 0.633778
[2022-04-07 14:05:41 | train] - Train Epoch: [173] [998400/1281167 (78%)]	Loss: 0.669457
[2022-04-07 14:06:09 | train] - Train Epoch: [173] [1011200/1281167 (79%)]	Loss: 0.833991
[2022-04-07 14:06:37 | train] - Train Epoch: [173] [1024000/1281167 (80%)]	Loss: 0.859284
[2022-04-07 14:07:05 | train] - Train Epoch: [173] [1036800/1281167 (81%)]	Loss: 0.594924
[2022-04-07 14:07:31 | train] - Train Epoch: [173] [1049600/1281167 (82%)]	Loss: 0.699109
[2022-04-07 14:07:59 | train] - Train Epoch: [173] [1062400/1281167 (83%)]	Loss: 1.196577
[2022-04-07 14:08:27 | train] - Train Epoch: [173] [1075200/1281167 (84%)]	Loss: 0.654899
[2022-04-07 14:08:54 | train] - Train Epoch: [173] [1088000/1281167 (85%)]	Loss: 0.773593
[2022-04-07 14:09:21 | train] - Train Epoch: [173] [1100800/1281167 (86%)]	Loss: 0.801538
[2022-04-07 14:09:50 | train] - Train Epoch: [173] [1113600/1281167 (87%)]	Loss: 0.945938
[2022-04-07 14:10:17 | train] - Train Epoch: [173] [1126400/1281167 (88%)]	Loss: 0.834191
[2022-04-07 14:10:46 | train] - Train Epoch: [173] [1139200/1281167 (89%)]	Loss: 0.691231
[2022-04-07 14:11:14 | train] - Train Epoch: [173] [1152000/1281167 (90%)]	Loss: 0.848465
[2022-04-07 14:11:42 | train] - Train Epoch: [173] [1164800/1281167 (91%)]	Loss: 0.821890
[2022-04-07 14:12:10 | train] - Train Epoch: [173] [1177600/1281167 (92%)]	Loss: 0.582445
[2022-04-07 14:12:37 | train] - Train Epoch: [173] [1190400/1281167 (93%)]	Loss: 0.979247
[2022-04-07 14:13:06 | train] - Train Epoch: [173] [1203200/1281167 (94%)]	Loss: 0.668039
[2022-04-07 14:13:34 | train] - Train Epoch: [173] [1216000/1281167 (95%)]	Loss: 0.817714
[2022-04-07 14:14:02 | train] - Train Epoch: [173] [1228800/1281167 (96%)]	Loss: 0.859650
[2022-04-07 14:14:30 | train] - Train Epoch: [173] [1241600/1281167 (97%)]	Loss: 0.760915
[2022-04-07 14:14:59 | train] - Train Epoch: [173] [1254400/1281167 (98%)]	Loss: 0.871163
[2022-04-07 14:15:28 | train] - Train Epoch: [173] [1267200/1281167 (99%)]	Loss: 0.859785
[2022-04-07 14:15:56 | train] - Train Epoch: [173] [1280000/1281167 (100%)]	Loss: 0.680036
[2022-04-07 14:15:58 | train] - Train Epoch: [173]	 Average Loss: 0.760541	 Total Acc : 81.4315	 Total Top5 Acc : 93.2274
[2022-04-07 14:15:58 | train] - -------173 epoch end-----------
========================================
-------173 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 14:17:59 | train] - 
Epoch [173] Test set: Average loss: 1.4673, Accuracy: 34900/50000 (69.7738%), Top-5 Accuracy: 88.7792%

[2022-04-07 14:17:59 | train] - save intermediate epoch [173] result


[2022-04-07 14:18:19 | train] - -------174 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 14:18:21 | train] - Train Epoch: [174] [0/1281167 (0%)]	Loss: 0.991504
[2022-04-07 14:18:48 | train] - Train Epoch: [174] [12800/1281167 (1%)]	Loss: 0.748796
[2022-04-07 14:19:15 | train] - Train Epoch: [174] [25600/1281167 (2%)]	Loss: 0.809169
[2022-04-07 14:19:43 | train] - Train Epoch: [174] [38400/1281167 (3%)]	Loss: 0.734616
[2022-04-07 14:20:11 | train] - Train Epoch: [174] [51200/1281167 (4%)]	Loss: 0.883319
[2022-04-07 14:20:39 | train] - Train Epoch: [174] [64000/1281167 (5%)]	Loss: 0.706727
[2022-04-07 14:21:06 | train] - Train Epoch: [174] [76800/1281167 (6%)]	Loss: 0.551937
[2022-04-07 14:21:35 | train] - Train Epoch: [174] [89600/1281167 (7%)]	Loss: 0.835216
[2022-04-07 14:22:03 | train] - Train Epoch: [174] [102400/1281167 (8%)]	Loss: 0.879981
[2022-04-07 14:22:33 | train] - Train Epoch: [174] [115200/1281167 (9%)]	Loss: 0.881908
[2022-04-07 14:23:00 | train] - Train Epoch: [174] [128000/1281167 (10%)]	Loss: 0.663081
[2022-04-07 14:23:29 | train] - Train Epoch: [174] [140800/1281167 (11%)]	Loss: 0.857155
[2022-04-07 14:23:56 | train] - Train Epoch: [174] [153600/1281167 (12%)]	Loss: 0.773816
[2022-04-07 14:24:23 | train] - Train Epoch: [174] [166400/1281167 (13%)]	Loss: 0.766041
[2022-04-07 14:24:50 | train] - Train Epoch: [174] [179200/1281167 (14%)]	Loss: 0.729821
[2022-04-07 14:25:17 | train] - Train Epoch: [174] [192000/1281167 (15%)]	Loss: 0.624884
[2022-04-07 14:25:44 | train] - Train Epoch: [174] [204800/1281167 (16%)]	Loss: 0.648111
[2022-04-07 14:26:11 | train] - Train Epoch: [174] [217600/1281167 (17%)]	Loss: 0.941854
[2022-04-07 14:26:39 | train] - Train Epoch: [174] [230400/1281167 (18%)]	Loss: 0.502540
[2022-04-07 14:27:06 | train] - Train Epoch: [174] [243200/1281167 (19%)]	Loss: 0.975566
[2022-04-07 14:27:34 | train] - Train Epoch: [174] [256000/1281167 (20%)]	Loss: 0.570634
[2022-04-07 14:28:01 | train] - Train Epoch: [174] [268800/1281167 (21%)]	Loss: 0.940958
[2022-04-07 14:28:29 | train] - Train Epoch: [174] [281600/1281167 (22%)]	Loss: 0.728247
[2022-04-07 14:28:55 | train] - Train Epoch: [174] [294400/1281167 (23%)]	Loss: 0.623274
[2022-04-07 14:29:23 | train] - Train Epoch: [174] [307200/1281167 (24%)]	Loss: 0.954106
[2022-04-07 14:29:50 | train] - Train Epoch: [174] [320000/1281167 (25%)]	Loss: 0.799353
[2022-04-07 14:30:17 | train] - Train Epoch: [174] [332800/1281167 (26%)]	Loss: 0.876243
[I 14:30:24.452 NotebookApp] 302 GET / (10.150.7.107) 16.880000ms
[2022-04-07 14:30:45 | train] - Train Epoch: [174] [345600/1281167 (27%)]	Loss: 0.789282
[W 14:31:00.205 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 14:31:12 | train] - Train Epoch: [174] [358400/1281167 (28%)]	Loss: 0.876969
[2022-04-07 14:31:39 | train] - Train Epoch: [174] [371200/1281167 (29%)]	Loss: 0.888624
[2022-04-07 14:32:07 | train] - Train Epoch: [174] [384000/1281167 (30%)]	Loss: 0.780727
[2022-04-07 14:32:34 | train] - Train Epoch: [174] [396800/1281167 (31%)]	Loss: 0.957052
[2022-04-07 14:33:02 | train] - Train Epoch: [174] [409600/1281167 (32%)]	Loss: 0.507979
[2022-04-07 14:33:30 | train] - Train Epoch: [174] [422400/1281167 (33%)]	Loss: 0.768198
[2022-04-07 14:33:56 | train] - Train Epoch: [174] [435200/1281167 (34%)]	Loss: 0.759568
[2022-04-07 14:34:24 | train] - Train Epoch: [174] [448000/1281167 (35%)]	Loss: 0.542430
[2022-04-07 14:34:52 | train] - Train Epoch: [174] [460800/1281167 (36%)]	Loss: 0.747853
[2022-04-07 14:35:18 | train] - Train Epoch: [174] [473600/1281167 (37%)]	Loss: 0.859975
[2022-04-07 14:35:45 | train] - Train Epoch: [174] [486400/1281167 (38%)]	Loss: 0.617846
[2022-04-07 14:36:12 | train] - Train Epoch: [174] [499200/1281167 (39%)]	Loss: 0.743027
[2022-04-07 14:36:40 | train] - Train Epoch: [174] [512000/1281167 (40%)]	Loss: 0.783606
[2022-04-07 14:37:08 | train] - Train Epoch: [174] [524800/1281167 (41%)]	Loss: 0.822073
[2022-04-07 14:37:36 | train] - Train Epoch: [174] [537600/1281167 (42%)]	Loss: 0.968304
[2022-04-07 14:38:03 | train] - Train Epoch: [174] [550400/1281167 (43%)]	Loss: 0.771449
[2022-04-07 14:38:30 | train] - Train Epoch: [174] [563200/1281167 (44%)]	Loss: 0.578895
[2022-04-07 14:38:58 | train] - Train Epoch: [174] [576000/1281167 (45%)]	Loss: 0.956187
[2022-04-07 14:39:25 | train] - Train Epoch: [174] [588800/1281167 (46%)]	Loss: 0.813171
[2022-04-07 14:39:53 | train] - Train Epoch: [174] [601600/1281167 (47%)]	Loss: 0.783728
[2022-04-07 14:40:21 | train] - Train Epoch: [174] [614400/1281167 (48%)]	Loss: 0.759678
[2022-04-07 14:40:50 | train] - Train Epoch: [174] [627200/1281167 (49%)]	Loss: 0.774570
[2022-04-07 14:41:17 | train] - Train Epoch: [174] [640000/1281167 (50%)]	Loss: 0.945127
[2022-04-07 14:41:44 | train] - Train Epoch: [174] [652800/1281167 (51%)]	Loss: 0.842309
[2022-04-07 14:42:11 | train] - Train Epoch: [174] [665600/1281167 (52%)]	Loss: 0.685844
[2022-04-07 14:42:39 | train] - Train Epoch: [174] [678400/1281167 (53%)]	Loss: 0.743778
[2022-04-07 14:43:07 | train] - Train Epoch: [174] [691200/1281167 (54%)]	Loss: 0.804887
[2022-04-07 14:43:35 | train] - Train Epoch: [174] [704000/1281167 (55%)]	Loss: 0.590197
[2022-04-07 14:44:03 | train] - Train Epoch: [174] [716800/1281167 (56%)]	Loss: 0.701872
[2022-04-07 14:44:30 | train] - Train Epoch: [174] [729600/1281167 (57%)]	Loss: 0.896106
[2022-04-07 14:44:58 | train] - Train Epoch: [174] [742400/1281167 (58%)]	Loss: 0.670359
[2022-04-07 14:45:26 | train] - Train Epoch: [174] [755200/1281167 (59%)]	Loss: 0.695229
[2022-04-07 14:45:53 | train] - Train Epoch: [174] [768000/1281167 (60%)]	Loss: 0.657358
[2022-04-07 14:46:21 | train] - Train Epoch: [174] [780800/1281167 (61%)]	Loss: 0.544045
[2022-04-07 14:46:49 | train] - Train Epoch: [174] [793600/1281167 (62%)]	Loss: 0.730672
[2022-04-07 14:47:17 | train] - Train Epoch: [174] [806400/1281167 (63%)]	Loss: 0.739465
[2022-04-07 14:47:45 | train] - Train Epoch: [174] [819200/1281167 (64%)]	Loss: 0.715038
[2022-04-07 14:48:13 | train] - Train Epoch: [174] [832000/1281167 (65%)]	Loss: 0.819962
[2022-04-07 14:48:41 | train] - Train Epoch: [174] [844800/1281167 (66%)]	Loss: 0.516039
[2022-04-07 14:49:09 | train] - Train Epoch: [174] [857600/1281167 (67%)]	Loss: 0.547001
[2022-04-07 14:49:36 | train] - Train Epoch: [174] [870400/1281167 (68%)]	Loss: 0.628064
[2022-04-07 14:50:04 | train] - Train Epoch: [174] [883200/1281167 (69%)]	Loss: 0.760008
[2022-04-07 14:50:31 | train] - Train Epoch: [174] [896000/1281167 (70%)]	Loss: 0.985935
[2022-04-07 14:50:59 | train] - Train Epoch: [174] [908800/1281167 (71%)]	Loss: 0.766227
[2022-04-07 14:51:26 | train] - Train Epoch: [174] [921600/1281167 (72%)]	Loss: 0.460100
[2022-04-07 14:51:53 | train] - Train Epoch: [174] [934400/1281167 (73%)]	Loss: 0.664451
[2022-04-07 14:52:20 | train] - Train Epoch: [174] [947200/1281167 (74%)]	Loss: 0.706840
[2022-04-07 14:52:47 | train] - Train Epoch: [174] [960000/1281167 (75%)]	Loss: 0.625058
[2022-04-07 14:53:14 | train] - Train Epoch: [174] [972800/1281167 (76%)]	Loss: 0.710238
[2022-04-07 14:53:41 | train] - Train Epoch: [174] [985600/1281167 (77%)]	Loss: 0.741534
[2022-04-07 14:54:09 | train] - Train Epoch: [174] [998400/1281167 (78%)]	Loss: 0.679568
[2022-04-07 14:54:36 | train] - Train Epoch: [174] [1011200/1281167 (79%)]	Loss: 0.684678
[2022-04-07 14:55:03 | train] - Train Epoch: [174] [1024000/1281167 (80%)]	Loss: 0.895457
[2022-04-07 14:55:31 | train] - Train Epoch: [174] [1036800/1281167 (81%)]	Loss: 0.837395
[2022-04-07 14:55:58 | train] - Train Epoch: [174] [1049600/1281167 (82%)]	Loss: 0.771073
[2022-04-07 14:56:26 | train] - Train Epoch: [174] [1062400/1281167 (83%)]	Loss: 0.845305
[2022-04-07 14:56:54 | train] - Train Epoch: [174] [1075200/1281167 (84%)]	Loss: 0.587907
[2022-04-07 14:57:21 | train] - Train Epoch: [174] [1088000/1281167 (85%)]	Loss: 0.826908
[2022-04-07 14:57:47 | train] - Train Epoch: [174] [1100800/1281167 (86%)]	Loss: 0.648412
[2022-04-07 14:58:12 | train] - Train Epoch: [174] [1113600/1281167 (87%)]	Loss: 0.935572
[2022-04-07 14:58:39 | train] - Train Epoch: [174] [1126400/1281167 (88%)]	Loss: 0.627682
[2022-04-07 14:59:06 | train] - Train Epoch: [174] [1139200/1281167 (89%)]	Loss: 0.725840
[2022-04-07 14:59:33 | train] - Train Epoch: [174] [1152000/1281167 (90%)]	Loss: 0.880299
[2022-04-07 15:00:00 | train] - Train Epoch: [174] [1164800/1281167 (91%)]	Loss: 0.624005
[2022-04-07 15:00:27 | train] - Train Epoch: [174] [1177600/1281167 (92%)]	Loss: 0.506311
[2022-04-07 15:00:54 | train] - Train Epoch: [174] [1190400/1281167 (93%)]	Loss: 0.679888
[2022-04-07 15:01:20 | train] - Train Epoch: [174] [1203200/1281167 (94%)]	Loss: 0.752291
[2022-04-07 15:01:47 | train] - Train Epoch: [174] [1216000/1281167 (95%)]	Loss: 0.771891
[2022-04-07 15:02:15 | train] - Train Epoch: [174] [1228800/1281167 (96%)]	Loss: 0.643892
[2022-04-07 15:02:41 | train] - Train Epoch: [174] [1241600/1281167 (97%)]	Loss: 0.708123
[2022-04-07 15:03:07 | train] - Train Epoch: [174] [1254400/1281167 (98%)]	Loss: 0.594551
[2022-04-07 15:03:33 | train] - Train Epoch: [174] [1267200/1281167 (99%)]	Loss: 0.651551
[2022-04-07 15:04:00 | train] - Train Epoch: [174] [1280000/1281167 (100%)]	Loss: 0.818950
[2022-04-07 15:04:02 | train] - Train Epoch: [174]	 Average Loss: 0.760446	 Total Acc : 81.4151	 Total Top5 Acc : 93.2175
[2022-04-07 15:04:02 | train] - -------174 epoch end-----------
========================================
-------174 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 15:05:57 | train] - 
Epoch [174] Test set: Average loss: 1.4604, Accuracy: 34882/50000 (69.7355%), Top-5 Accuracy: 88.7052%

[2022-04-07 15:05:57 | train] - save intermediate epoch [174] result


[2022-04-07 15:06:18 | train] - -------175 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 15:06:19 | train] - Train Epoch: [175] [0/1281167 (0%)]	Loss: 0.649888
[2022-04-07 15:06:47 | train] - Train Epoch: [175] [12800/1281167 (1%)]	Loss: 0.675789
[2022-04-07 15:07:14 | train] - Train Epoch: [175] [25600/1281167 (2%)]	Loss: 0.564912
[2022-04-07 15:07:42 | train] - Train Epoch: [175] [38400/1281167 (3%)]	Loss: 0.643834
[2022-04-07 15:08:10 | train] - Train Epoch: [175] [51200/1281167 (4%)]	Loss: 0.626990
[2022-04-07 15:08:38 | train] - Train Epoch: [175] [64000/1281167 (5%)]	Loss: 0.627771
[2022-04-07 15:09:05 | train] - Train Epoch: [175] [76800/1281167 (6%)]	Loss: 0.870195
[2022-04-07 15:09:32 | train] - Train Epoch: [175] [89600/1281167 (7%)]	Loss: 0.620870
[2022-04-07 15:10:00 | train] - Train Epoch: [175] [102400/1281167 (8%)]	Loss: 0.721625
[2022-04-07 15:10:28 | train] - Train Epoch: [175] [115200/1281167 (9%)]	Loss: 0.622613
[2022-04-07 15:10:55 | train] - Train Epoch: [175] [128000/1281167 (10%)]	Loss: 0.436827
[2022-04-07 15:11:23 | train] - Train Epoch: [175] [140800/1281167 (11%)]	Loss: 0.761908
[2022-04-07 15:11:51 | train] - Train Epoch: [175] [153600/1281167 (12%)]	Loss: 0.803439
[2022-04-07 15:12:20 | train] - Train Epoch: [175] [166400/1281167 (13%)]	Loss: 0.952735
[2022-04-07 15:12:47 | train] - Train Epoch: [175] [179200/1281167 (14%)]	Loss: 0.948126
[2022-04-07 15:13:13 | train] - Train Epoch: [175] [192000/1281167 (15%)]	Loss: 0.935336
[2022-04-07 15:13:41 | train] - Train Epoch: [175] [204800/1281167 (16%)]	Loss: 0.713787
[2022-04-07 15:14:07 | train] - Train Epoch: [175] [217600/1281167 (17%)]	Loss: 0.799014
[2022-04-07 15:14:34 | train] - Train Epoch: [175] [230400/1281167 (18%)]	Loss: 0.774489
[2022-04-07 15:15:01 | train] - Train Epoch: [175] [243200/1281167 (19%)]	Loss: 0.889156
[2022-04-07 15:15:28 | train] - Train Epoch: [175] [256000/1281167 (20%)]	Loss: 0.545295
[2022-04-07 15:15:54 | train] - Train Epoch: [175] [268800/1281167 (21%)]	Loss: 0.985809
[2022-04-07 15:16:21 | train] - Train Epoch: [175] [281600/1281167 (22%)]	Loss: 0.661989
[2022-04-07 15:16:48 | train] - Train Epoch: [175] [294400/1281167 (23%)]	Loss: 1.345439
[2022-04-07 15:17:16 | train] - Train Epoch: [175] [307200/1281167 (24%)]	Loss: 0.788476
[2022-04-07 15:17:44 | train] - Train Epoch: [175] [320000/1281167 (25%)]	Loss: 0.689034
[2022-04-07 15:18:11 | train] - Train Epoch: [175] [332800/1281167 (26%)]	Loss: 0.585609
[2022-04-07 15:18:38 | train] - Train Epoch: [175] [345600/1281167 (27%)]	Loss: 0.872070
[I 15:19:01.290 NotebookApp] Saving file at /pdh_test.ipynb
[I 15:19:01.291 NotebookApp] Saving pdh_test.ipynb
[W 15:19:01.292 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 15:19:05 | train] - Train Epoch: [175] [358400/1281167 (28%)]	Loss: 0.813242
[2022-04-07 15:19:31 | train] - Train Epoch: [175] [371200/1281167 (29%)]	Loss: 1.008943
[2022-04-07 15:19:59 | train] - Train Epoch: [175] [384000/1281167 (30%)]	Loss: 0.611611
[2022-04-07 15:20:26 | train] - Train Epoch: [175] [396800/1281167 (31%)]	Loss: 1.029009
[2022-04-07 15:20:52 | train] - Train Epoch: [175] [409600/1281167 (32%)]	Loss: 0.880483
[I 15:21:00.464 NotebookApp] Saving file at /pdh_test.ipynb
[I 15:21:00.465 NotebookApp] Saving pdh_test.ipynb
[W 15:21:00.465 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 15:21:19 | train] - Train Epoch: [175] [422400/1281167 (33%)]	Loss: 0.669090
[2022-04-07 15:21:46 | train] - Train Epoch: [175] [435200/1281167 (34%)]	Loss: 0.766302
[2022-04-07 15:22:13 | train] - Train Epoch: [175] [448000/1281167 (35%)]	Loss: 0.800202
[2022-04-07 15:22:41 | train] - Train Epoch: [175] [460800/1281167 (36%)]	Loss: 0.994186
[2022-04-07 15:23:08 | train] - Train Epoch: [175] [473600/1281167 (37%)]	Loss: 0.835387
[2022-04-07 15:23:35 | train] - Train Epoch: [175] [486400/1281167 (38%)]	Loss: 0.857810
[2022-04-07 15:24:02 | train] - Train Epoch: [175] [499200/1281167 (39%)]	Loss: 0.679967
[2022-04-07 15:24:29 | train] - Train Epoch: [175] [512000/1281167 (40%)]	Loss: 1.092325
[2022-04-07 15:24:56 | train] - Train Epoch: [175] [524800/1281167 (41%)]	Loss: 0.775020
[2022-04-07 15:25:23 | train] - Train Epoch: [175] [537600/1281167 (42%)]	Loss: 0.659923
[2022-04-07 15:25:50 | train] - Train Epoch: [175] [550400/1281167 (43%)]	Loss: 0.663746
[2022-04-07 15:26:17 | train] - Train Epoch: [175] [563200/1281167 (44%)]	Loss: 1.007223
[2022-04-07 15:26:45 | train] - Train Epoch: [175] [576000/1281167 (45%)]	Loss: 0.829869
[2022-04-07 15:27:12 | train] - Train Epoch: [175] [588800/1281167 (46%)]	Loss: 0.663707
[2022-04-07 15:27:39 | train] - Train Epoch: [175] [601600/1281167 (47%)]	Loss: 0.906569
[2022-04-07 15:28:06 | train] - Train Epoch: [175] [614400/1281167 (48%)]	Loss: 0.800417
[2022-04-07 15:28:33 | train] - Train Epoch: [175] [627200/1281167 (49%)]	Loss: 0.783059
[2022-04-07 15:29:00 | train] - Train Epoch: [175] [640000/1281167 (50%)]	Loss: 1.100287
[2022-04-07 15:29:27 | train] - Train Epoch: [175] [652800/1281167 (51%)]	Loss: 0.876552
[2022-04-07 15:29:55 | train] - Train Epoch: [175] [665600/1281167 (52%)]	Loss: 0.694045
[2022-04-07 15:30:21 | train] - Train Epoch: [175] [678400/1281167 (53%)]	Loss: 0.595130
[2022-04-07 15:30:48 | train] - Train Epoch: [175] [691200/1281167 (54%)]	Loss: 0.752736
[2022-04-07 15:31:16 | train] - Train Epoch: [175] [704000/1281167 (55%)]	Loss: 0.825969
[2022-04-07 15:31:43 | train] - Train Epoch: [175] [716800/1281167 (56%)]	Loss: 0.829383
[2022-04-07 15:32:10 | train] - Train Epoch: [175] [729600/1281167 (57%)]	Loss: 0.821454
[2022-04-07 15:32:37 | train] - Train Epoch: [175] [742400/1281167 (58%)]	Loss: 0.722493
[2022-04-07 15:33:03 | train] - Train Epoch: [175] [755200/1281167 (59%)]	Loss: 0.714508
[2022-04-07 15:33:30 | train] - Train Epoch: [175] [768000/1281167 (60%)]	Loss: 0.575854
[2022-04-07 15:33:57 | train] - Train Epoch: [175] [780800/1281167 (61%)]	Loss: 0.744994
[2022-04-07 15:34:24 | train] - Train Epoch: [175] [793600/1281167 (62%)]	Loss: 1.063285
[2022-04-07 15:34:51 | train] - Train Epoch: [175] [806400/1281167 (63%)]	Loss: 0.733025
[2022-04-07 15:35:18 | train] - Train Epoch: [175] [819200/1281167 (64%)]	Loss: 0.734771
[2022-04-07 15:35:46 | train] - Train Epoch: [175] [832000/1281167 (65%)]	Loss: 0.714446
[2022-04-07 15:36:13 | train] - Train Epoch: [175] [844800/1281167 (66%)]	Loss: 0.683235
[2022-04-07 15:36:40 | train] - Train Epoch: [175] [857600/1281167 (67%)]	Loss: 0.407100
[2022-04-07 15:37:08 | train] - Train Epoch: [175] [870400/1281167 (68%)]	Loss: 0.519853
[2022-04-07 15:37:35 | train] - Train Epoch: [175] [883200/1281167 (69%)]	Loss: 0.747062
[2022-04-07 15:38:01 | train] - Train Epoch: [175] [896000/1281167 (70%)]	Loss: 0.690366
[2022-04-07 15:38:28 | train] - Train Epoch: [175] [908800/1281167 (71%)]	Loss: 0.505263
[2022-04-07 15:38:56 | train] - Train Epoch: [175] [921600/1281167 (72%)]	Loss: 0.711483
[2022-04-07 15:39:24 | train] - Train Epoch: [175] [934400/1281167 (73%)]	Loss: 0.786482
[2022-04-07 15:39:51 | train] - Train Epoch: [175] [947200/1281167 (74%)]	Loss: 0.907011
[2022-04-07 15:40:18 | train] - Train Epoch: [175] [960000/1281167 (75%)]	Loss: 0.859322
[2022-04-07 15:40:45 | train] - Train Epoch: [175] [972800/1281167 (76%)]	Loss: 0.892785
[2022-04-07 15:41:13 | train] - Train Epoch: [175] [985600/1281167 (77%)]	Loss: 0.919329
[2022-04-07 15:41:39 | train] - Train Epoch: [175] [998400/1281167 (78%)]	Loss: 0.673178
[2022-04-07 15:42:07 | train] - Train Epoch: [175] [1011200/1281167 (79%)]	Loss: 0.686382
[2022-04-07 15:42:34 | train] - Train Epoch: [175] [1024000/1281167 (80%)]	Loss: 0.781700
[2022-04-07 15:43:02 | train] - Train Epoch: [175] [1036800/1281167 (81%)]	Loss: 0.732031
[2022-04-07 15:43:29 | train] - Train Epoch: [175] [1049600/1281167 (82%)]	Loss: 0.898154
[2022-04-07 15:43:57 | train] - Train Epoch: [175] [1062400/1281167 (83%)]	Loss: 0.578165
[2022-04-07 15:44:24 | train] - Train Epoch: [175] [1075200/1281167 (84%)]	Loss: 0.611369
[2022-04-07 15:44:52 | train] - Train Epoch: [175] [1088000/1281167 (85%)]	Loss: 0.682619
[2022-04-07 15:45:20 | train] - Train Epoch: [175] [1100800/1281167 (86%)]	Loss: 0.759344
[2022-04-07 15:45:48 | train] - Train Epoch: [175] [1113600/1281167 (87%)]	Loss: 0.649671
[2022-04-07 15:46:15 | train] - Train Epoch: [175] [1126400/1281167 (88%)]	Loss: 0.876368
[2022-04-07 15:46:43 | train] - Train Epoch: [175] [1139200/1281167 (89%)]	Loss: 0.690640
[2022-04-07 15:47:11 | train] - Train Epoch: [175] [1152000/1281167 (90%)]	Loss: 0.730362
[2022-04-07 15:47:38 | train] - Train Epoch: [175] [1164800/1281167 (91%)]	Loss: 0.582555
[2022-04-07 15:48:08 | train] - Train Epoch: [175] [1177600/1281167 (92%)]	Loss: 0.823732
[2022-04-07 15:48:35 | train] - Train Epoch: [175] [1190400/1281167 (93%)]	Loss: 0.757132
[2022-04-07 15:49:03 | train] - Train Epoch: [175] [1203200/1281167 (94%)]	Loss: 0.719244
[2022-04-07 15:49:31 | train] - Train Epoch: [175] [1216000/1281167 (95%)]	Loss: 1.101879
[2022-04-07 15:49:59 | train] - Train Epoch: [175] [1228800/1281167 (96%)]	Loss: 0.604557
[2022-04-07 15:50:28 | train] - Train Epoch: [175] [1241600/1281167 (97%)]	Loss: 0.754744
[2022-04-07 15:50:55 | train] - Train Epoch: [175] [1254400/1281167 (98%)]	Loss: 0.696481
[2022-04-07 15:51:23 | train] - Train Epoch: [175] [1267200/1281167 (99%)]	Loss: 0.897198
[2022-04-07 15:51:51 | train] - Train Epoch: [175] [1280000/1281167 (100%)]	Loss: 0.957086
[2022-04-07 15:51:53 | train] - Train Epoch: [175]	 Average Loss: 0.760011	 Total Acc : 81.4367	 Total Top5 Acc : 93.2458
[2022-04-07 15:51:53 | train] - -------175 epoch end-----------
========================================
-------175 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 15:53:49 | train] - 
Epoch [175] Test set: Average loss: 1.4661, Accuracy: 34856/50000 (69.6847%), Top-5 Accuracy: 88.6501%

[2022-04-07 15:53:49 | train] - save intermediate epoch [175] result


[2022-04-07 15:54:10 | train] - -------176 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 15:54:12 | train] - Train Epoch: [176] [0/1281167 (0%)]	Loss: 0.652531
[2022-04-07 15:54:37 | train] - Train Epoch: [176] [12800/1281167 (1%)]	Loss: 0.791835
[2022-04-07 15:55:03 | train] - Train Epoch: [176] [25600/1281167 (2%)]	Loss: 0.830585
[2022-04-07 15:55:29 | train] - Train Epoch: [176] [38400/1281167 (3%)]	Loss: 0.913461
[2022-04-07 15:55:56 | train] - Train Epoch: [176] [51200/1281167 (4%)]	Loss: 0.926452
[2022-04-07 15:56:22 | train] - Train Epoch: [176] [64000/1281167 (5%)]	Loss: 0.671297
[2022-04-07 15:56:47 | train] - Train Epoch: [176] [76800/1281167 (6%)]	Loss: 0.554343
[2022-04-07 15:57:14 | train] - Train Epoch: [176] [89600/1281167 (7%)]	Loss: 0.538616
[2022-04-07 15:57:39 | train] - Train Epoch: [176] [102400/1281167 (8%)]	Loss: 1.011146
[2022-04-07 15:58:05 | train] - Train Epoch: [176] [115200/1281167 (9%)]	Loss: 0.896785
[2022-04-07 15:58:31 | train] - Train Epoch: [176] [128000/1281167 (10%)]	Loss: 0.808008
[2022-04-07 15:58:57 | train] - Train Epoch: [176] [140800/1281167 (11%)]	Loss: 0.639895
[2022-04-07 15:59:24 | train] - Train Epoch: [176] [153600/1281167 (12%)]	Loss: 0.545244
[2022-04-07 15:59:50 | train] - Train Epoch: [176] [166400/1281167 (13%)]	Loss: 0.693666
[2022-04-07 16:00:16 | train] - Train Epoch: [176] [179200/1281167 (14%)]	Loss: 0.717491
[2022-04-07 16:00:41 | train] - Train Epoch: [176] [192000/1281167 (15%)]	Loss: 0.736110
[2022-04-07 16:01:08 | train] - Train Epoch: [176] [204800/1281167 (16%)]	Loss: 0.661792
[2022-04-07 16:01:34 | train] - Train Epoch: [176] [217600/1281167 (17%)]	Loss: 0.780523
[2022-04-07 16:02:00 | train] - Train Epoch: [176] [230400/1281167 (18%)]	Loss: 0.665932
[2022-04-07 16:02:26 | train] - Train Epoch: [176] [243200/1281167 (19%)]	Loss: 0.752618
[2022-04-07 16:02:52 | train] - Train Epoch: [176] [256000/1281167 (20%)]	Loss: 0.772551
[2022-04-07 16:03:18 | train] - Train Epoch: [176] [268800/1281167 (21%)]	Loss: 0.514335
[2022-04-07 16:03:43 | train] - Train Epoch: [176] [281600/1281167 (22%)]	Loss: 0.935410
[2022-04-07 16:04:10 | train] - Train Epoch: [176] [294400/1281167 (23%)]	Loss: 0.778817
[2022-04-07 16:04:37 | train] - Train Epoch: [176] [307200/1281167 (24%)]	Loss: 0.888799
[2022-04-07 16:05:03 | train] - Train Epoch: [176] [320000/1281167 (25%)]	Loss: 0.665955
[2022-04-07 16:05:29 | train] - Train Epoch: [176] [332800/1281167 (26%)]	Loss: 0.680829
[2022-04-07 16:05:56 | train] - Train Epoch: [176] [345600/1281167 (27%)]	Loss: 0.824568
[2022-04-07 16:06:22 | train] - Train Epoch: [176] [358400/1281167 (28%)]	Loss: 0.761732
[2022-04-07 16:06:48 | train] - Train Epoch: [176] [371200/1281167 (29%)]	Loss: 0.581859
[2022-04-07 16:07:14 | train] - Train Epoch: [176] [384000/1281167 (30%)]	Loss: 0.717153
[2022-04-07 16:07:40 | train] - Train Epoch: [176] [396800/1281167 (31%)]	Loss: 0.962502
[2022-04-07 16:08:06 | train] - Train Epoch: [176] [409600/1281167 (32%)]	Loss: 0.852045
[2022-04-07 16:08:32 | train] - Train Epoch: [176] [422400/1281167 (33%)]	Loss: 0.755574
[2022-04-07 16:08:58 | train] - Train Epoch: [176] [435200/1281167 (34%)]	Loss: 0.734914
[2022-04-07 16:09:25 | train] - Train Epoch: [176] [448000/1281167 (35%)]	Loss: 0.908672
[2022-04-07 16:09:51 | train] - Train Epoch: [176] [460800/1281167 (36%)]	Loss: 0.731670
[2022-04-07 16:10:18 | train] - Train Epoch: [176] [473600/1281167 (37%)]	Loss: 0.700158
[2022-04-07 16:10:45 | train] - Train Epoch: [176] [486400/1281167 (38%)]	Loss: 0.749362
[2022-04-07 16:11:11 | train] - Train Epoch: [176] [499200/1281167 (39%)]	Loss: 0.951672
[2022-04-07 16:11:37 | train] - Train Epoch: [176] [512000/1281167 (40%)]	Loss: 0.794212
[2022-04-07 16:12:03 | train] - Train Epoch: [176] [524800/1281167 (41%)]	Loss: 0.515803
[2022-04-07 16:12:30 | train] - Train Epoch: [176] [537600/1281167 (42%)]	Loss: 0.681799
[2022-04-07 16:12:56 | train] - Train Epoch: [176] [550400/1281167 (43%)]	Loss: 0.846247
[2022-04-07 16:13:22 | train] - Train Epoch: [176] [563200/1281167 (44%)]	Loss: 0.816347
[2022-04-07 16:13:47 | train] - Train Epoch: [176] [576000/1281167 (45%)]	Loss: 0.727594
[2022-04-07 16:14:13 | train] - Train Epoch: [176] [588800/1281167 (46%)]	Loss: 0.694416
[2022-04-07 16:14:40 | train] - Train Epoch: [176] [601600/1281167 (47%)]	Loss: 1.131488
[2022-04-07 16:15:05 | train] - Train Epoch: [176] [614400/1281167 (48%)]	Loss: 0.964813
[2022-04-07 16:15:31 | train] - Train Epoch: [176] [627200/1281167 (49%)]	Loss: 0.750352
[2022-04-07 16:15:56 | train] - Train Epoch: [176] [640000/1281167 (50%)]	Loss: 0.704286
[2022-04-07 16:16:21 | train] - Train Epoch: [176] [652800/1281167 (51%)]	Loss: 0.797200
[2022-04-07 16:16:47 | train] - Train Epoch: [176] [665600/1281167 (52%)]	Loss: 0.898895
[2022-04-07 16:17:13 | train] - Train Epoch: [176] [678400/1281167 (53%)]	Loss: 0.800738
[2022-04-07 16:17:40 | train] - Train Epoch: [176] [691200/1281167 (54%)]	Loss: 0.636043
[2022-04-07 16:18:06 | train] - Train Epoch: [176] [704000/1281167 (55%)]	Loss: 0.751357
[2022-04-07 16:18:32 | train] - Train Epoch: [176] [716800/1281167 (56%)]	Loss: 0.732813
[2022-04-07 16:18:59 | train] - Train Epoch: [176] [729600/1281167 (57%)]	Loss: 0.668408
[2022-04-07 16:19:26 | train] - Train Epoch: [176] [742400/1281167 (58%)]	Loss: 1.044200
[2022-04-07 16:19:53 | train] - Train Epoch: [176] [755200/1281167 (59%)]	Loss: 0.772406
[2022-04-07 16:20:19 | train] - Train Epoch: [176] [768000/1281167 (60%)]	Loss: 0.668787
[2022-04-07 16:20:45 | train] - Train Epoch: [176] [780800/1281167 (61%)]	Loss: 0.734072
[2022-04-07 16:21:11 | train] - Train Epoch: [176] [793600/1281167 (62%)]	Loss: 1.017572
[2022-04-07 16:21:38 | train] - Train Epoch: [176] [806400/1281167 (63%)]	Loss: 0.702801
[2022-04-07 16:22:04 | train] - Train Epoch: [176] [819200/1281167 (64%)]	Loss: 0.602311
[2022-04-07 16:22:29 | train] - Train Epoch: [176] [832000/1281167 (65%)]	Loss: 0.621197
[2022-04-07 16:22:55 | train] - Train Epoch: [176] [844800/1281167 (66%)]	Loss: 0.736015
[2022-04-07 16:23:22 | train] - Train Epoch: [176] [857600/1281167 (67%)]	Loss: 0.802341
[2022-04-07 16:23:49 | train] - Train Epoch: [176] [870400/1281167 (68%)]	Loss: 1.010084
[2022-04-07 16:24:15 | train] - Train Epoch: [176] [883200/1281167 (69%)]	Loss: 0.698820
[2022-04-07 16:24:41 | train] - Train Epoch: [176] [896000/1281167 (70%)]	Loss: 0.671627
[2022-04-07 16:25:08 | train] - Train Epoch: [176] [908800/1281167 (71%)]	Loss: 0.727565
[2022-04-07 16:25:34 | train] - Train Epoch: [176] [921600/1281167 (72%)]	Loss: 0.908513
[2022-04-07 16:26:00 | train] - Train Epoch: [176] [934400/1281167 (73%)]	Loss: 0.797246
[2022-04-07 16:26:27 | train] - Train Epoch: [176] [947200/1281167 (74%)]	Loss: 0.737893
[2022-04-07 16:26:52 | train] - Train Epoch: [176] [960000/1281167 (75%)]	Loss: 0.906272
[2022-04-07 16:27:19 | train] - Train Epoch: [176] [972800/1281167 (76%)]	Loss: 0.607738
[2022-04-07 16:27:46 | train] - Train Epoch: [176] [985600/1281167 (77%)]	Loss: 0.733428
[2022-04-07 16:28:13 | train] - Train Epoch: [176] [998400/1281167 (78%)]	Loss: 0.761218
[2022-04-07 16:28:40 | train] - Train Epoch: [176] [1011200/1281167 (79%)]	Loss: 0.748404
[2022-04-07 16:29:06 | train] - Train Epoch: [176] [1024000/1281167 (80%)]	Loss: 0.538183
[2022-04-07 16:29:34 | train] - Train Epoch: [176] [1036800/1281167 (81%)]	Loss: 0.787073
[2022-04-07 16:30:01 | train] - Train Epoch: [176] [1049600/1281167 (82%)]	Loss: 0.877612
[2022-04-07 16:30:27 | train] - Train Epoch: [176] [1062400/1281167 (83%)]	Loss: 0.670955
[2022-04-07 16:30:54 | train] - Train Epoch: [176] [1075200/1281167 (84%)]	Loss: 0.696141
[2022-04-07 16:31:20 | train] - Train Epoch: [176] [1088000/1281167 (85%)]	Loss: 0.590137
[2022-04-07 16:31:46 | train] - Train Epoch: [176] [1100800/1281167 (86%)]	Loss: 0.852793
[2022-04-07 16:32:12 | train] - Train Epoch: [176] [1113600/1281167 (87%)]	Loss: 0.909799
[2022-04-07 16:32:39 | train] - Train Epoch: [176] [1126400/1281167 (88%)]	Loss: 0.808792
[2022-04-07 16:33:06 | train] - Train Epoch: [176] [1139200/1281167 (89%)]	Loss: 0.545009
[2022-04-07 16:33:32 | train] - Train Epoch: [176] [1152000/1281167 (90%)]	Loss: 0.544156
[2022-04-07 16:33:58 | train] - Train Epoch: [176] [1164800/1281167 (91%)]	Loss: 0.744035
[2022-04-07 16:34:26 | train] - Train Epoch: [176] [1177600/1281167 (92%)]	Loss: 0.790658
[2022-04-07 16:34:52 | train] - Train Epoch: [176] [1190400/1281167 (93%)]	Loss: 0.874750
[2022-04-07 16:35:19 | train] - Train Epoch: [176] [1203200/1281167 (94%)]	Loss: 0.939038
[2022-04-07 16:35:45 | train] - Train Epoch: [176] [1216000/1281167 (95%)]	Loss: 0.725411
[2022-04-07 16:36:13 | train] - Train Epoch: [176] [1228800/1281167 (96%)]	Loss: 0.743776
[2022-04-07 16:36:40 | train] - Train Epoch: [176] [1241600/1281167 (97%)]	Loss: 0.662664
[2022-04-07 16:37:06 | train] - Train Epoch: [176] [1254400/1281167 (98%)]	Loss: 0.801403
[2022-04-07 16:37:34 | train] - Train Epoch: [176] [1267200/1281167 (99%)]	Loss: 0.687541
[2022-04-07 16:38:01 | train] - Train Epoch: [176] [1280000/1281167 (100%)]	Loss: 0.936373
[2022-04-07 16:38:03 | train] - Train Epoch: [176]	 Average Loss: 0.758386	 Total Acc : 81.4861	 Total Top5 Acc : 93.2554
[2022-04-07 16:38:03 | train] - -------176 epoch end-----------
========================================
-------176 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 16:39:57 | train] - 
Epoch [176] Test set: Average loss: 1.4524, Accuracy: 34939/50000 (69.8505%), Top-5 Accuracy: 88.7792%

[2022-04-07 16:39:57 | train] - save intermediate epoch [176] result


[2022-04-07 16:40:18 | train] - -------177 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 16:40:20 | train] - Train Epoch: [177] [0/1281167 (0%)]	Loss: 0.734562
[2022-04-07 16:40:47 | train] - Train Epoch: [177] [12800/1281167 (1%)]	Loss: 0.707923
[2022-04-07 16:41:14 | train] - Train Epoch: [177] [25600/1281167 (2%)]	Loss: 0.681745
[2022-04-07 16:41:42 | train] - Train Epoch: [177] [38400/1281167 (3%)]	Loss: 0.624961
[2022-04-07 16:42:09 | train] - Train Epoch: [177] [51200/1281167 (4%)]	Loss: 0.834649
[2022-04-07 16:42:36 | train] - Train Epoch: [177] [64000/1281167 (5%)]	Loss: 1.070815
[2022-04-07 16:43:03 | train] - Train Epoch: [177] [76800/1281167 (6%)]	Loss: 0.991195
[2022-04-07 16:43:31 | train] - Train Epoch: [177] [89600/1281167 (7%)]	Loss: 0.813882
[2022-04-07 16:43:58 | train] - Train Epoch: [177] [102400/1281167 (8%)]	Loss: 0.841209
[2022-04-07 16:44:25 | train] - Train Epoch: [177] [115200/1281167 (9%)]	Loss: 0.545576
[2022-04-07 16:44:52 | train] - Train Epoch: [177] [128000/1281167 (10%)]	Loss: 0.605835
[2022-04-07 16:45:19 | train] - Train Epoch: [177] [140800/1281167 (11%)]	Loss: 0.892977
[2022-04-07 16:45:47 | train] - Train Epoch: [177] [153600/1281167 (12%)]	Loss: 0.924940
[2022-04-07 16:46:15 | train] - Train Epoch: [177] [166400/1281167 (13%)]	Loss: 0.857460
[2022-04-07 16:46:41 | train] - Train Epoch: [177] [179200/1281167 (14%)]	Loss: 0.695280
[2022-04-07 16:47:08 | train] - Train Epoch: [177] [192000/1281167 (15%)]	Loss: 0.737308
[2022-04-07 16:47:35 | train] - Train Epoch: [177] [204800/1281167 (16%)]	Loss: 0.680285
[2022-04-07 16:48:03 | train] - Train Epoch: [177] [217600/1281167 (17%)]	Loss: 0.940704
[2022-04-07 16:48:29 | train] - Train Epoch: [177] [230400/1281167 (18%)]	Loss: 0.683635
[2022-04-07 16:48:57 | train] - Train Epoch: [177] [243200/1281167 (19%)]	Loss: 1.086310
[2022-04-07 16:49:24 | train] - Train Epoch: [177] [256000/1281167 (20%)]	Loss: 0.796408
[2022-04-07 16:49:51 | train] - Train Epoch: [177] [268800/1281167 (21%)]	Loss: 0.715716
[2022-04-07 16:50:19 | train] - Train Epoch: [177] [281600/1281167 (22%)]	Loss: 0.787655
[2022-04-07 16:50:45 | train] - Train Epoch: [177] [294400/1281167 (23%)]	Loss: 0.724607
[2022-04-07 16:51:13 | train] - Train Epoch: [177] [307200/1281167 (24%)]	Loss: 0.627110
[2022-04-07 16:51:41 | train] - Train Epoch: [177] [320000/1281167 (25%)]	Loss: 0.833842
[2022-04-07 16:52:08 | train] - Train Epoch: [177] [332800/1281167 (26%)]	Loss: 0.741734
[2022-04-07 16:52:36 | train] - Train Epoch: [177] [345600/1281167 (27%)]	Loss: 0.904843
[2022-04-07 16:53:04 | train] - Train Epoch: [177] [358400/1281167 (28%)]	Loss: 0.948832
[2022-04-07 16:53:30 | train] - Train Epoch: [177] [371200/1281167 (29%)]	Loss: 0.911260
[2022-04-07 16:53:58 | train] - Train Epoch: [177] [384000/1281167 (30%)]	Loss: 0.726119
[2022-04-07 16:54:24 | train] - Train Epoch: [177] [396800/1281167 (31%)]	Loss: 0.649186
[2022-04-07 16:54:51 | train] - Train Epoch: [177] [409600/1281167 (32%)]	Loss: 0.868660
[2022-04-07 16:55:18 | train] - Train Epoch: [177] [422400/1281167 (33%)]	Loss: 0.890425
[2022-04-07 16:55:46 | train] - Train Epoch: [177] [435200/1281167 (34%)]	Loss: 0.920856
[2022-04-07 16:56:14 | train] - Train Epoch: [177] [448000/1281167 (35%)]	Loss: 1.148757
[2022-04-07 16:56:41 | train] - Train Epoch: [177] [460800/1281167 (36%)]	Loss: 0.515875
[2022-04-07 16:57:09 | train] - Train Epoch: [177] [473600/1281167 (37%)]	Loss: 0.811670
[2022-04-07 16:57:36 | train] - Train Epoch: [177] [486400/1281167 (38%)]	Loss: 0.751527
[2022-04-07 16:58:04 | train] - Train Epoch: [177] [499200/1281167 (39%)]	Loss: 0.689533
[2022-04-07 16:58:31 | train] - Train Epoch: [177] [512000/1281167 (40%)]	Loss: 0.649038
[2022-04-07 16:58:59 | train] - Train Epoch: [177] [524800/1281167 (41%)]	Loss: 0.875980
[2022-04-07 16:59:26 | train] - Train Epoch: [177] [537600/1281167 (42%)]	Loss: 0.425413
[2022-04-07 16:59:53 | train] - Train Epoch: [177] [550400/1281167 (43%)]	Loss: 0.898335
[2022-04-07 17:00:22 | train] - Train Epoch: [177] [563200/1281167 (44%)]	Loss: 0.700322
[2022-04-07 17:00:49 | train] - Train Epoch: [177] [576000/1281167 (45%)]	Loss: 0.692693
[2022-04-07 17:01:16 | train] - Train Epoch: [177] [588800/1281167 (46%)]	Loss: 0.794748
[2022-04-07 17:01:44 | train] - Train Epoch: [177] [601600/1281167 (47%)]	Loss: 1.216195
[2022-04-07 17:02:11 | train] - Train Epoch: [177] [614400/1281167 (48%)]	Loss: 0.781965
[2022-04-07 17:02:39 | train] - Train Epoch: [177] [627200/1281167 (49%)]	Loss: 1.095147
[2022-04-07 17:03:06 | train] - Train Epoch: [177] [640000/1281167 (50%)]	Loss: 0.811089
[2022-04-07 17:03:34 | train] - Train Epoch: [177] [652800/1281167 (51%)]	Loss: 0.725599
[2022-04-07 17:04:02 | train] - Train Epoch: [177] [665600/1281167 (52%)]	Loss: 0.617047
[2022-04-07 17:04:29 | train] - Train Epoch: [177] [678400/1281167 (53%)]	Loss: 0.752199
[2022-04-07 17:04:57 | train] - Train Epoch: [177] [691200/1281167 (54%)]	Loss: 0.698614
[2022-04-07 17:05:24 | train] - Train Epoch: [177] [704000/1281167 (55%)]	Loss: 0.947849
[2022-04-07 17:05:52 | train] - Train Epoch: [177] [716800/1281167 (56%)]	Loss: 0.422588
[2022-04-07 17:06:21 | train] - Train Epoch: [177] [729600/1281167 (57%)]	Loss: 0.784111
[2022-04-07 17:06:48 | train] - Train Epoch: [177] [742400/1281167 (58%)]	Loss: 0.727261
[2022-04-07 17:07:15 | train] - Train Epoch: [177] [755200/1281167 (59%)]	Loss: 0.730073
[2022-04-07 17:07:43 | train] - Train Epoch: [177] [768000/1281167 (60%)]	Loss: 0.781994
[2022-04-07 17:08:10 | train] - Train Epoch: [177] [780800/1281167 (61%)]	Loss: 0.838127
[2022-04-07 17:08:37 | train] - Train Epoch: [177] [793600/1281167 (62%)]	Loss: 0.720504
[2022-04-07 17:09:05 | train] - Train Epoch: [177] [806400/1281167 (63%)]	Loss: 0.576940
[2022-04-07 17:09:33 | train] - Train Epoch: [177] [819200/1281167 (64%)]	Loss: 0.649497
[2022-04-07 17:10:00 | train] - Train Epoch: [177] [832000/1281167 (65%)]	Loss: 0.714312
[2022-04-07 17:10:28 | train] - Train Epoch: [177] [844800/1281167 (66%)]	Loss: 0.816304
[2022-04-07 17:10:55 | train] - Train Epoch: [177] [857600/1281167 (67%)]	Loss: 0.614536
[2022-04-07 17:11:22 | train] - Train Epoch: [177] [870400/1281167 (68%)]	Loss: 0.650347
[2022-04-07 17:11:48 | train] - Train Epoch: [177] [883200/1281167 (69%)]	Loss: 0.832011
[2022-04-07 17:12:16 | train] - Train Epoch: [177] [896000/1281167 (70%)]	Loss: 0.559480
[2022-04-07 17:12:44 | train] - Train Epoch: [177] [908800/1281167 (71%)]	Loss: 0.600958
[2022-04-07 17:13:12 | train] - Train Epoch: [177] [921600/1281167 (72%)]	Loss: 0.942407
[2022-04-07 17:13:40 | train] - Train Epoch: [177] [934400/1281167 (73%)]	Loss: 0.795453
[2022-04-07 17:14:07 | train] - Train Epoch: [177] [947200/1281167 (74%)]	Loss: 0.763278
[2022-04-07 17:14:34 | train] - Train Epoch: [177] [960000/1281167 (75%)]	Loss: 0.721699
[2022-04-07 17:15:01 | train] - Train Epoch: [177] [972800/1281167 (76%)]	Loss: 0.849978
[2022-04-07 17:15:28 | train] - Train Epoch: [177] [985600/1281167 (77%)]	Loss: 0.774923
[2022-04-07 17:15:55 | train] - Train Epoch: [177] [998400/1281167 (78%)]	Loss: 0.827656
[2022-04-07 17:16:23 | train] - Train Epoch: [177] [1011200/1281167 (79%)]	Loss: 0.880670
[2022-04-07 17:16:50 | train] - Train Epoch: [177] [1024000/1281167 (80%)]	Loss: 0.577559
[2022-04-07 17:17:17 | train] - Train Epoch: [177] [1036800/1281167 (81%)]	Loss: 0.962757
[2022-04-07 17:17:44 | train] - Train Epoch: [177] [1049600/1281167 (82%)]	Loss: 0.660583
[2022-04-07 17:18:12 | train] - Train Epoch: [177] [1062400/1281167 (83%)]	Loss: 0.726027
[2022-04-07 17:18:39 | train] - Train Epoch: [177] [1075200/1281167 (84%)]	Loss: 0.811904
[2022-04-07 17:19:07 | train] - Train Epoch: [177] [1088000/1281167 (85%)]	Loss: 0.771718
[2022-04-07 17:19:34 | train] - Train Epoch: [177] [1100800/1281167 (86%)]	Loss: 0.570923
[2022-04-07 17:20:02 | train] - Train Epoch: [177] [1113600/1281167 (87%)]	Loss: 0.756892
[2022-04-07 17:20:30 | train] - Train Epoch: [177] [1126400/1281167 (88%)]	Loss: 0.607953
[2022-04-07 17:20:57 | train] - Train Epoch: [177] [1139200/1281167 (89%)]	Loss: 0.621591
[2022-04-07 17:21:25 | train] - Train Epoch: [177] [1152000/1281167 (90%)]	Loss: 0.795257
[2022-04-07 17:21:53 | train] - Train Epoch: [177] [1164800/1281167 (91%)]	Loss: 0.749542
[2022-04-07 17:22:20 | train] - Train Epoch: [177] [1177600/1281167 (92%)]	Loss: 1.012568
[2022-04-07 17:22:49 | train] - Train Epoch: [177] [1190400/1281167 (93%)]	Loss: 1.123672
[2022-04-07 17:23:17 | train] - Train Epoch: [177] [1203200/1281167 (94%)]	Loss: 0.500566
[2022-04-07 17:23:44 | train] - Train Epoch: [177] [1216000/1281167 (95%)]	Loss: 0.896694
[2022-04-07 17:24:12 | train] - Train Epoch: [177] [1228800/1281167 (96%)]	Loss: 0.762052
[2022-04-07 17:24:40 | train] - Train Epoch: [177] [1241600/1281167 (97%)]	Loss: 0.843170
[2022-04-07 17:25:08 | train] - Train Epoch: [177] [1254400/1281167 (98%)]	Loss: 0.936516
[2022-04-07 17:25:36 | train] - Train Epoch: [177] [1267200/1281167 (99%)]	Loss: 0.907335
[2022-04-07 17:26:04 | train] - Train Epoch: [177] [1280000/1281167 (100%)]	Loss: 0.975683
[2022-04-07 17:26:06 | train] - Train Epoch: [177]	 Average Loss: 0.757887	 Total Acc : 81.4915	 Total Top5 Acc : 93.2925
[2022-04-07 17:26:06 | train] - -------177 epoch end-----------
========================================
-------177 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 17:27:59 | train] - 
Epoch [177] Test set: Average loss: 1.4529, Accuracy: 34949/50000 (69.8717%), Top-5 Accuracy: 88.7892%

[2022-04-07 17:27:59 | train] - save intermediate epoch [177] result


[2022-04-07 17:28:21 | train] - -------178 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 17:28:22 | train] - Train Epoch: [178] [0/1281167 (0%)]	Loss: 0.902096
[2022-04-07 17:28:49 | train] - Train Epoch: [178] [12800/1281167 (1%)]	Loss: 0.762891
[2022-04-07 17:29:16 | train] - Train Epoch: [178] [25600/1281167 (2%)]	Loss: 0.937015
[2022-04-07 17:29:42 | train] - Train Epoch: [178] [38400/1281167 (3%)]	Loss: 0.570201
[2022-04-07 17:30:09 | train] - Train Epoch: [178] [51200/1281167 (4%)]	Loss: 0.748860
[2022-04-07 17:30:36 | train] - Train Epoch: [178] [64000/1281167 (5%)]	Loss: 0.696025
[2022-04-07 17:31:04 | train] - Train Epoch: [178] [76800/1281167 (6%)]	Loss: 0.775087
[2022-04-07 17:31:31 | train] - Train Epoch: [178] [89600/1281167 (7%)]	Loss: 0.603118
[2022-04-07 17:31:58 | train] - Train Epoch: [178] [102400/1281167 (8%)]	Loss: 0.996053
[2022-04-07 17:32:25 | train] - Train Epoch: [178] [115200/1281167 (9%)]	Loss: 0.631251
[2022-04-07 17:32:52 | train] - Train Epoch: [178] [128000/1281167 (10%)]	Loss: 1.081088
[2022-04-07 17:33:21 | train] - Train Epoch: [178] [140800/1281167 (11%)]	Loss: 0.473586
[2022-04-07 17:33:48 | train] - Train Epoch: [178] [153600/1281167 (12%)]	Loss: 0.598521
[2022-04-07 17:34:16 | train] - Train Epoch: [178] [166400/1281167 (13%)]	Loss: 0.726941
[2022-04-07 17:34:44 | train] - Train Epoch: [178] [179200/1281167 (14%)]	Loss: 0.901908
[2022-04-07 17:35:10 | train] - Train Epoch: [178] [192000/1281167 (15%)]	Loss: 0.850940
[2022-04-07 17:35:38 | train] - Train Epoch: [178] [204800/1281167 (16%)]	Loss: 0.931042
[2022-04-07 17:36:06 | train] - Train Epoch: [178] [217600/1281167 (17%)]	Loss: 0.706098
[2022-04-07 17:36:33 | train] - Train Epoch: [178] [230400/1281167 (18%)]	Loss: 0.807482
[2022-04-07 17:37:01 | train] - Train Epoch: [178] [243200/1281167 (19%)]	Loss: 0.684778
[2022-04-07 17:37:29 | train] - Train Epoch: [178] [256000/1281167 (20%)]	Loss: 0.686657
[2022-04-07 17:37:58 | train] - Train Epoch: [178] [268800/1281167 (21%)]	Loss: 0.837390
[2022-04-07 17:38:24 | train] - Train Epoch: [178] [281600/1281167 (22%)]	Loss: 0.698212
[2022-04-07 17:38:51 | train] - Train Epoch: [178] [294400/1281167 (23%)]	Loss: 0.562855
[2022-04-07 17:39:18 | train] - Train Epoch: [178] [307200/1281167 (24%)]	Loss: 0.850322
[2022-04-07 17:39:45 | train] - Train Epoch: [178] [320000/1281167 (25%)]	Loss: 0.764892
[2022-04-07 17:40:13 | train] - Train Epoch: [178] [332800/1281167 (26%)]	Loss: 0.953590
[2022-04-07 17:40:42 | train] - Train Epoch: [178] [345600/1281167 (27%)]	Loss: 0.447529
[2022-04-07 17:41:09 | train] - Train Epoch: [178] [358400/1281167 (28%)]	Loss: 0.887491
[2022-04-07 17:41:37 | train] - Train Epoch: [178] [371200/1281167 (29%)]	Loss: 0.732569
[2022-04-07 17:42:03 | train] - Train Epoch: [178] [384000/1281167 (30%)]	Loss: 0.773302
[2022-04-07 17:42:30 | train] - Train Epoch: [178] [396800/1281167 (31%)]	Loss: 0.744421
[2022-04-07 17:42:57 | train] - Train Epoch: [178] [409600/1281167 (32%)]	Loss: 0.851006
[2022-04-07 17:43:24 | train] - Train Epoch: [178] [422400/1281167 (33%)]	Loss: 0.815480
[2022-04-07 17:43:52 | train] - Train Epoch: [178] [435200/1281167 (34%)]	Loss: 0.782925
[2022-04-07 17:44:19 | train] - Train Epoch: [178] [448000/1281167 (35%)]	Loss: 0.780113
[2022-04-07 17:44:47 | train] - Train Epoch: [178] [460800/1281167 (36%)]	Loss: 0.781418
[2022-04-07 17:45:15 | train] - Train Epoch: [178] [473600/1281167 (37%)]	Loss: 0.478117
[2022-04-07 17:45:42 | train] - Train Epoch: [178] [486400/1281167 (38%)]	Loss: 0.879963
[2022-04-07 17:46:10 | train] - Train Epoch: [178] [499200/1281167 (39%)]	Loss: 0.713973
[2022-04-07 17:46:37 | train] - Train Epoch: [178] [512000/1281167 (40%)]	Loss: 0.656244
[2022-04-07 17:47:04 | train] - Train Epoch: [178] [524800/1281167 (41%)]	Loss: 0.578471
[2022-04-07 17:47:33 | train] - Train Epoch: [178] [537600/1281167 (42%)]	Loss: 0.847081
[2022-04-07 17:48:00 | train] - Train Epoch: [178] [550400/1281167 (43%)]	Loss: 0.935312
[2022-04-07 17:48:27 | train] - Train Epoch: [178] [563200/1281167 (44%)]	Loss: 0.851644
[2022-04-07 17:48:55 | train] - Train Epoch: [178] [576000/1281167 (45%)]	Loss: 0.701201
[2022-04-07 17:49:22 | train] - Train Epoch: [178] [588800/1281167 (46%)]	Loss: 0.713965
[2022-04-07 17:49:49 | train] - Train Epoch: [178] [601600/1281167 (47%)]	Loss: 0.758330
[2022-04-07 17:50:16 | train] - Train Epoch: [178] [614400/1281167 (48%)]	Loss: 0.911419
[2022-04-07 17:50:44 | train] - Train Epoch: [178] [627200/1281167 (49%)]	Loss: 0.750135
[2022-04-07 17:51:11 | train] - Train Epoch: [178] [640000/1281167 (50%)]	Loss: 0.682658
[2022-04-07 17:51:39 | train] - Train Epoch: [178] [652800/1281167 (51%)]	Loss: 0.993736
[2022-04-07 17:52:06 | train] - Train Epoch: [178] [665600/1281167 (52%)]	Loss: 0.776347
[2022-04-07 17:52:34 | train] - Train Epoch: [178] [678400/1281167 (53%)]	Loss: 0.622661
[2022-04-07 17:53:02 | train] - Train Epoch: [178] [691200/1281167 (54%)]	Loss: 0.702331
[2022-04-07 17:53:29 | train] - Train Epoch: [178] [704000/1281167 (55%)]	Loss: 0.732734
[2022-04-07 17:53:57 | train] - Train Epoch: [178] [716800/1281167 (56%)]	Loss: 0.578364
[2022-04-07 17:54:25 | train] - Train Epoch: [178] [729600/1281167 (57%)]	Loss: 0.705032
[2022-04-07 17:54:52 | train] - Train Epoch: [178] [742400/1281167 (58%)]	Loss: 0.624537
[2022-04-07 17:55:19 | train] - Train Epoch: [178] [755200/1281167 (59%)]	Loss: 0.827357
[2022-04-07 17:55:47 | train] - Train Epoch: [178] [768000/1281167 (60%)]	Loss: 0.585752
[2022-04-07 17:56:14 | train] - Train Epoch: [178] [780800/1281167 (61%)]	Loss: 0.813207
[2022-04-07 17:56:42 | train] - Train Epoch: [178] [793600/1281167 (62%)]	Loss: 0.779970
[2022-04-07 17:57:08 | train] - Train Epoch: [178] [806400/1281167 (63%)]	Loss: 0.793106
[2022-04-07 17:57:37 | train] - Train Epoch: [178] [819200/1281167 (64%)]	Loss: 0.476970
[2022-04-07 17:58:05 | train] - Train Epoch: [178] [832000/1281167 (65%)]	Loss: 0.589001
[2022-04-07 17:58:33 | train] - Train Epoch: [178] [844800/1281167 (66%)]	Loss: 1.005041
[2022-04-07 17:59:00 | train] - Train Epoch: [178] [857600/1281167 (67%)]	Loss: 0.870122
[2022-04-07 17:59:28 | train] - Train Epoch: [178] [870400/1281167 (68%)]	Loss: 0.671615
[2022-04-07 17:59:55 | train] - Train Epoch: [178] [883200/1281167 (69%)]	Loss: 0.698559
[2022-04-07 18:00:23 | train] - Train Epoch: [178] [896000/1281167 (70%)]	Loss: 0.667187
[2022-04-07 18:00:51 | train] - Train Epoch: [178] [908800/1281167 (71%)]	Loss: 0.690911
[2022-04-07 18:01:19 | train] - Train Epoch: [178] [921600/1281167 (72%)]	Loss: 0.739264
[2022-04-07 18:01:45 | train] - Train Epoch: [178] [934400/1281167 (73%)]	Loss: 0.809662
[2022-04-07 18:02:12 | train] - Train Epoch: [178] [947200/1281167 (74%)]	Loss: 0.887333
[2022-04-07 18:02:40 | train] - Train Epoch: [178] [960000/1281167 (75%)]	Loss: 0.919204
[2022-04-07 18:03:08 | train] - Train Epoch: [178] [972800/1281167 (76%)]	Loss: 1.017689
[2022-04-07 18:03:36 | train] - Train Epoch: [178] [985600/1281167 (77%)]	Loss: 0.879685
[2022-04-07 18:04:04 | train] - Train Epoch: [178] [998400/1281167 (78%)]	Loss: 0.733867
[2022-04-07 18:04:32 | train] - Train Epoch: [178] [1011200/1281167 (79%)]	Loss: 0.865292
[2022-04-07 18:04:59 | train] - Train Epoch: [178] [1024000/1281167 (80%)]	Loss: 0.846732
[2022-04-07 18:05:26 | train] - Train Epoch: [178] [1036800/1281167 (81%)]	Loss: 0.819429
[2022-04-07 18:05:53 | train] - Train Epoch: [178] [1049600/1281167 (82%)]	Loss: 0.989854
[2022-04-07 18:06:21 | train] - Train Epoch: [178] [1062400/1281167 (83%)]	Loss: 0.769446
[2022-04-07 18:06:49 | train] - Train Epoch: [178] [1075200/1281167 (84%)]	Loss: 0.736553
[2022-04-07 18:07:17 | train] - Train Epoch: [178] [1088000/1281167 (85%)]	Loss: 0.679257
[2022-04-07 18:07:44 | train] - Train Epoch: [178] [1100800/1281167 (86%)]	Loss: 0.691335
[2022-04-07 18:08:12 | train] - Train Epoch: [178] [1113600/1281167 (87%)]	Loss: 0.756052
[2022-04-07 18:08:40 | train] - Train Epoch: [178] [1126400/1281167 (88%)]	Loss: 0.803219
[2022-04-07 18:09:08 | train] - Train Epoch: [178] [1139200/1281167 (89%)]	Loss: 0.558962
[2022-04-07 18:09:36 | train] - Train Epoch: [178] [1152000/1281167 (90%)]	Loss: 0.500041
[2022-04-07 18:10:04 | train] - Train Epoch: [178] [1164800/1281167 (91%)]	Loss: 0.601696
[2022-04-07 18:10:32 | train] - Train Epoch: [178] [1177600/1281167 (92%)]	Loss: 0.915815
[2022-04-07 18:11:00 | train] - Train Epoch: [178] [1190400/1281167 (93%)]	Loss: 0.650936
[2022-04-07 18:11:28 | train] - Train Epoch: [178] [1203200/1281167 (94%)]	Loss: 0.734993
[2022-04-07 18:11:57 | train] - Train Epoch: [178] [1216000/1281167 (95%)]	Loss: 0.697534
[2022-04-07 18:12:26 | train] - Train Epoch: [178] [1228800/1281167 (96%)]	Loss: 0.756415
[2022-04-07 18:12:55 | train] - Train Epoch: [178] [1241600/1281167 (97%)]	Loss: 0.852810
[2022-04-07 18:13:24 | train] - Train Epoch: [178] [1254400/1281167 (98%)]	Loss: 0.753668
[2022-04-07 18:13:52 | train] - Train Epoch: [178] [1267200/1281167 (99%)]	Loss: 0.943339
[2022-04-07 18:14:21 | train] - Train Epoch: [178] [1280000/1281167 (100%)]	Loss: 0.662114
[2022-04-07 18:14:23 | train] - Train Epoch: [178]	 Average Loss: 0.759322	 Total Acc : 81.4785	 Total Top5 Acc : 93.2180
[2022-04-07 18:14:23 | train] - -------178 epoch end-----------
========================================
-------178 epoch end  -----------

----- test and print accuracy ------------------
[I 18:15:01.657 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:15:01.663 NotebookApp] Saving pdh_test.ipynb
[W 18:15:01.667 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:16:23 | train] - 
Epoch [178] Test set: Average loss: 1.4571, Accuracy: 34898/50000 (69.7710%), Top-5 Accuracy: 88.7432%

[2022-04-07 18:16:24 | train] - save intermediate epoch [178] result


[2022-04-07 18:16:45 | train] - -------179 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 18:16:46 | train] - Train Epoch: [179] [0/1281167 (0%)]	Loss: 1.031265
[I 18:17:01.580 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:17:01.581 NotebookApp] Saving pdh_test.ipynb
[W 18:17:01.581 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:17:15 | train] - Train Epoch: [179] [12800/1281167 (1%)]	Loss: 0.779296
[2022-04-07 18:17:42 | train] - Train Epoch: [179] [25600/1281167 (2%)]	Loss: 0.450871
[2022-04-07 18:18:09 | train] - Train Epoch: [179] [38400/1281167 (3%)]	Loss: 0.848513
[2022-04-07 18:18:37 | train] - Train Epoch: [179] [51200/1281167 (4%)]	Loss: 0.745281
[I 18:19:00.768 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:19:00.769 NotebookApp] Saving pdh_test.ipynb
[W 18:19:00.770 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:19:03 | train] - Train Epoch: [179] [64000/1281167 (5%)]	Loss: 0.746261
[2022-04-07 18:19:30 | train] - Train Epoch: [179] [76800/1281167 (6%)]	Loss: 0.688423
[2022-04-07 18:19:58 | train] - Train Epoch: [179] [89600/1281167 (7%)]	Loss: 0.944124
[2022-04-07 18:20:25 | train] - Train Epoch: [179] [102400/1281167 (8%)]	Loss: 0.787710
[2022-04-07 18:20:52 | train] - Train Epoch: [179] [115200/1281167 (9%)]	Loss: 0.684876
[I 18:21:01.576 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:21:01.577 NotebookApp] Saving pdh_test.ipynb
[W 18:21:01.577 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:21:20 | train] - Train Epoch: [179] [128000/1281167 (10%)]	Loss: 0.890573
[2022-04-07 18:21:47 | train] - Train Epoch: [179] [140800/1281167 (11%)]	Loss: 0.839941
[2022-04-07 18:22:14 | train] - Train Epoch: [179] [153600/1281167 (12%)]	Loss: 1.004699
[2022-04-07 18:22:42 | train] - Train Epoch: [179] [166400/1281167 (13%)]	Loss: 0.603251
[2022-04-07 18:23:10 | train] - Train Epoch: [179] [179200/1281167 (14%)]	Loss: 0.751271
[2022-04-07 18:23:38 | train] - Train Epoch: [179] [192000/1281167 (15%)]	Loss: 0.643911
[2022-04-07 18:24:04 | train] - Train Epoch: [179] [204800/1281167 (16%)]	Loss: 0.578589
[2022-04-07 18:24:31 | train] - Train Epoch: [179] [217600/1281167 (17%)]	Loss: 0.829822
[2022-04-07 18:24:58 | train] - Train Epoch: [179] [230400/1281167 (18%)]	Loss: 0.659601
[2022-04-07 18:25:27 | train] - Train Epoch: [179] [243200/1281167 (19%)]	Loss: 0.675674
[2022-04-07 18:25:55 | train] - Train Epoch: [179] [256000/1281167 (20%)]	Loss: 0.644609
[2022-04-07 18:26:23 | train] - Train Epoch: [179] [268800/1281167 (21%)]	Loss: 0.486365
[2022-04-07 18:26:50 | train] - Train Epoch: [179] [281600/1281167 (22%)]	Loss: 0.890034
[2022-04-07 18:27:18 | train] - Train Epoch: [179] [294400/1281167 (23%)]	Loss: 0.845235
[2022-04-07 18:27:45 | train] - Train Epoch: [179] [307200/1281167 (24%)]	Loss: 1.185047
[2022-04-07 18:28:13 | train] - Train Epoch: [179] [320000/1281167 (25%)]	Loss: 0.697914
[2022-04-07 18:28:41 | train] - Train Epoch: [179] [332800/1281167 (26%)]	Loss: 0.650205
[2022-04-07 18:29:09 | train] - Train Epoch: [179] [345600/1281167 (27%)]	Loss: 0.668397
[2022-04-07 18:29:37 | train] - Train Epoch: [179] [358400/1281167 (28%)]	Loss: 0.615930
[2022-04-07 18:30:05 | train] - Train Epoch: [179] [371200/1281167 (29%)]	Loss: 0.933872
[2022-04-07 18:30:33 | train] - Train Epoch: [179] [384000/1281167 (30%)]	Loss: 0.689757
[2022-04-07 18:31:00 | train] - Train Epoch: [179] [396800/1281167 (31%)]	Loss: 0.535392
[2022-04-07 18:31:28 | train] - Train Epoch: [179] [409600/1281167 (32%)]	Loss: 0.573106
[2022-04-07 18:31:57 | train] - Train Epoch: [179] [422400/1281167 (33%)]	Loss: 0.826702
[2022-04-07 18:32:24 | train] - Train Epoch: [179] [435200/1281167 (34%)]	Loss: 0.837258
[2022-04-07 18:32:52 | train] - Train Epoch: [179] [448000/1281167 (35%)]	Loss: 0.839685
[2022-04-07 18:33:19 | train] - Train Epoch: [179] [460800/1281167 (36%)]	Loss: 0.837431
[2022-04-07 18:33:46 | train] - Train Epoch: [179] [473600/1281167 (37%)]	Loss: 0.640638
[2022-04-07 18:34:13 | train] - Train Epoch: [179] [486400/1281167 (38%)]	Loss: 0.986145
[2022-04-07 18:34:41 | train] - Train Epoch: [179] [499200/1281167 (39%)]	Loss: 0.749260
[I 18:35:01.627 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:35:01.630 NotebookApp] Saving pdh_test.ipynb
[W 18:35:01.630 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:35:08 | train] - Train Epoch: [179] [512000/1281167 (40%)]	Loss: 0.821595
[2022-04-07 18:35:36 | train] - Train Epoch: [179] [524800/1281167 (41%)]	Loss: 0.786331
[2022-04-07 18:36:03 | train] - Train Epoch: [179] [537600/1281167 (42%)]	Loss: 0.784057
[2022-04-07 18:36:31 | train] - Train Epoch: [179] [550400/1281167 (43%)]	Loss: 0.802700
[2022-04-07 18:36:58 | train] - Train Epoch: [179] [563200/1281167 (44%)]	Loss: 0.512770
[I 18:37:01.592 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:37:01.593 NotebookApp] Saving pdh_test.ipynb
[W 18:37:01.594 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 18:37:27 | train] - Train Epoch: [179] [576000/1281167 (45%)]	Loss: 0.692132
[2022-04-07 18:37:54 | train] - Train Epoch: [179] [588800/1281167 (46%)]	Loss: 0.790802
[2022-04-07 18:38:22 | train] - Train Epoch: [179] [601600/1281167 (47%)]	Loss: 0.956167
[2022-04-07 18:38:49 | train] - Train Epoch: [179] [614400/1281167 (48%)]	Loss: 0.728401
[I 18:39:00.783 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:39:00.784 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 18:39:16 | train] - Train Epoch: [179] [627200/1281167 (49%)]	Loss: 0.733895
[2022-04-07 18:39:43 | train] - Train Epoch: [179] [640000/1281167 (50%)]	Loss: 0.774462
[2022-04-07 18:40:11 | train] - Train Epoch: [179] [652800/1281167 (51%)]	Loss: 0.674364
[2022-04-07 18:40:38 | train] - Train Epoch: [179] [665600/1281167 (52%)]	Loss: 0.755298
[I 18:41:00.798 NotebookApp] Saving file at /pdh_test.ipynb
[I 18:41:00.799 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 18:41:05 | train] - Train Epoch: [179] [678400/1281167 (53%)]	Loss: 0.680175
[2022-04-07 18:41:33 | train] - Train Epoch: [179] [691200/1281167 (54%)]	Loss: 0.478812
[2022-04-07 18:42:00 | train] - Train Epoch: [179] [704000/1281167 (55%)]	Loss: 0.617463
[2022-04-07 18:42:27 | train] - Train Epoch: [179] [716800/1281167 (56%)]	Loss: 0.659068
[2022-04-07 18:42:55 | train] - Train Epoch: [179] [729600/1281167 (57%)]	Loss: 0.738518
[2022-04-07 18:43:24 | train] - Train Epoch: [179] [742400/1281167 (58%)]	Loss: 0.594622
[2022-04-07 18:43:50 | train] - Train Epoch: [179] [755200/1281167 (59%)]	Loss: 0.565393
[2022-04-07 18:44:18 | train] - Train Epoch: [179] [768000/1281167 (60%)]	Loss: 0.781575
[2022-04-07 18:44:46 | train] - Train Epoch: [179] [780800/1281167 (61%)]	Loss: 0.696518
[2022-04-07 18:45:13 | train] - Train Epoch: [179] [793600/1281167 (62%)]	Loss: 0.739853
[2022-04-07 18:45:41 | train] - Train Epoch: [179] [806400/1281167 (63%)]	Loss: 0.701933
[2022-04-07 18:46:09 | train] - Train Epoch: [179] [819200/1281167 (64%)]	Loss: 0.991566
[2022-04-07 18:46:38 | train] - Train Epoch: [179] [832000/1281167 (65%)]	Loss: 0.722677
[2022-04-07 18:47:05 | train] - Train Epoch: [179] [844800/1281167 (66%)]	Loss: 0.762874
[2022-04-07 18:47:33 | train] - Train Epoch: [179] [857600/1281167 (67%)]	Loss: 0.964359
[2022-04-07 18:48:00 | train] - Train Epoch: [179] [870400/1281167 (68%)]	Loss: 0.742831
[2022-04-07 18:48:28 | train] - Train Epoch: [179] [883200/1281167 (69%)]	Loss: 0.689217
[2022-04-07 18:48:56 | train] - Train Epoch: [179] [896000/1281167 (70%)]	Loss: 0.780290
[2022-04-07 18:49:24 | train] - Train Epoch: [179] [908800/1281167 (71%)]	Loss: 0.599716
[2022-04-07 18:49:53 | train] - Train Epoch: [179] [921600/1281167 (72%)]	Loss: 0.577155
[2022-04-07 18:50:21 | train] - Train Epoch: [179] [934400/1281167 (73%)]	Loss: 0.802795
[2022-04-07 18:50:50 | train] - Train Epoch: [179] [947200/1281167 (74%)]	Loss: 0.613579
[2022-04-07 18:51:18 | train] - Train Epoch: [179] [960000/1281167 (75%)]	Loss: 0.659465
[2022-04-07 18:51:46 | train] - Train Epoch: [179] [972800/1281167 (76%)]	Loss: 0.499118
[2022-04-07 18:52:15 | train] - Train Epoch: [179] [985600/1281167 (77%)]	Loss: 0.985973
[2022-04-07 18:52:43 | train] - Train Epoch: [179] [998400/1281167 (78%)]	Loss: 0.553202
[2022-04-07 18:53:10 | train] - Train Epoch: [179] [1011200/1281167 (79%)]	Loss: 0.772786
[2022-04-07 18:53:39 | train] - Train Epoch: [179] [1024000/1281167 (80%)]	Loss: 1.126768
[2022-04-07 18:54:06 | train] - Train Epoch: [179] [1036800/1281167 (81%)]	Loss: 0.694367
[2022-04-07 18:54:32 | train] - Train Epoch: [179] [1049600/1281167 (82%)]	Loss: 0.714562
[2022-04-07 18:54:59 | train] - Train Epoch: [179] [1062400/1281167 (83%)]	Loss: 0.950384
[2022-04-07 18:55:27 | train] - Train Epoch: [179] [1075200/1281167 (84%)]	Loss: 0.613712
[2022-04-07 18:55:55 | train] - Train Epoch: [179] [1088000/1281167 (85%)]	Loss: 0.611070
[2022-04-07 18:56:22 | train] - Train Epoch: [179] [1100800/1281167 (86%)]	Loss: 0.712397
[2022-04-07 18:56:50 | train] - Train Epoch: [179] [1113600/1281167 (87%)]	Loss: 0.632262
[2022-04-07 18:57:17 | train] - Train Epoch: [179] [1126400/1281167 (88%)]	Loss: 1.139592
[2022-04-07 18:57:45 | train] - Train Epoch: [179] [1139200/1281167 (89%)]	Loss: 0.584233
[2022-04-07 18:58:13 | train] - Train Epoch: [179] [1152000/1281167 (90%)]	Loss: 0.858202
[2022-04-07 18:58:41 | train] - Train Epoch: [179] [1164800/1281167 (91%)]	Loss: 0.957337
[2022-04-07 18:59:08 | train] - Train Epoch: [179] [1177600/1281167 (92%)]	Loss: 0.577434
[2022-04-07 18:59:37 | train] - Train Epoch: [179] [1190400/1281167 (93%)]	Loss: 0.821411
[2022-04-07 19:00:05 | train] - Train Epoch: [179] [1203200/1281167 (94%)]	Loss: 0.984293
[2022-04-07 19:00:33 | train] - Train Epoch: [179] [1216000/1281167 (95%)]	Loss: 0.624572
[2022-04-07 19:01:02 | train] - Train Epoch: [179] [1228800/1281167 (96%)]	Loss: 0.788527
[2022-04-07 19:01:31 | train] - Train Epoch: [179] [1241600/1281167 (97%)]	Loss: 0.551106
[2022-04-07 19:02:00 | train] - Train Epoch: [179] [1254400/1281167 (98%)]	Loss: 0.993556
[2022-04-07 19:02:29 | train] - Train Epoch: [179] [1267200/1281167 (99%)]	Loss: 0.935337
[2022-04-07 19:02:57 | train] - Train Epoch: [179] [1280000/1281167 (100%)]	Loss: 0.810753
[2022-04-07 19:02:59 | train] - Train Epoch: [179]	 Average Loss: 0.758987	 Total Acc : 81.4053	 Total Top5 Acc : 93.2426
[2022-04-07 19:02:59 | train] - -------179 epoch end-----------
========================================
-------179 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 19:04:53 | train] - 
Epoch [179] Test set: Average loss: 1.4583, Accuracy: 34930/50000 (69.8314%), Top-5 Accuracy: 88.8731%

[2022-04-07 19:04:53 | train] - save intermediate epoch [179] result


[2022-04-07 19:05:15 | train] - -------180 epoch start-----------
[2022-04-07 19:05:15 | train] - -------- logging 180 batch layer input tensor ------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
batch_grad_output shape : torch.Size([128, 64, 112, 112])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 64, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 56, 56])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 128, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 28, 28])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
[2022-04-07 19:05:44 | train] - -------- logging end 180 --------------------
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 256, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1024, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 14, 14])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 512, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 2048, 7, 7])
batch_grad_output tuples shape : [128]
batch_grad_output shape : torch.Size([128, 1000])
batch_grad_output tuples shape : [128]
[2022-04-07 19:05:46 | train] - Train Epoch: [180] [0/1281167 (0%)]	Loss: 0.678300
[2022-04-07 19:06:13 | train] - Train Epoch: [180] [12800/1281167 (1%)]	Loss: 0.791886
[2022-04-07 19:06:41 | train] - Train Epoch: [180] [25600/1281167 (2%)]	Loss: 0.594363
[2022-04-07 19:07:08 | train] - Train Epoch: [180] [38400/1281167 (3%)]	Loss: 0.776042
[2022-04-07 19:07:36 | train] - Train Epoch: [180] [51200/1281167 (4%)]	Loss: 1.031159
[2022-04-07 19:08:03 | train] - Train Epoch: [180] [64000/1281167 (5%)]	Loss: 0.891906
[2022-04-07 19:08:31 | train] - Train Epoch: [180] [76800/1281167 (6%)]	Loss: 0.396314
[2022-04-07 19:08:58 | train] - Train Epoch: [180] [89600/1281167 (7%)]	Loss: 1.073182
[2022-04-07 19:09:25 | train] - Train Epoch: [180] [102400/1281167 (8%)]	Loss: 0.826973
[2022-04-07 19:09:52 | train] - Train Epoch: [180] [115200/1281167 (9%)]	Loss: 0.647664
[2022-04-07 19:10:19 | train] - Train Epoch: [180] [128000/1281167 (10%)]	Loss: 0.660375
[2022-04-07 19:10:47 | train] - Train Epoch: [180] [140800/1281167 (11%)]	Loss: 0.764777
[2022-04-07 19:11:13 | train] - Train Epoch: [180] [153600/1281167 (12%)]	Loss: 0.692187
[2022-04-07 19:11:41 | train] - Train Epoch: [180] [166400/1281167 (13%)]	Loss: 0.852219
[2022-04-07 19:12:08 | train] - Train Epoch: [180] [179200/1281167 (14%)]	Loss: 0.687972
[2022-04-07 19:12:35 | train] - Train Epoch: [180] [192000/1281167 (15%)]	Loss: 0.700619
[2022-04-07 19:13:03 | train] - Train Epoch: [180] [204800/1281167 (16%)]	Loss: 0.753713
[2022-04-07 19:13:30 | train] - Train Epoch: [180] [217600/1281167 (17%)]	Loss: 0.818606
[2022-04-07 19:13:57 | train] - Train Epoch: [180] [230400/1281167 (18%)]	Loss: 0.818337
[2022-04-07 19:14:24 | train] - Train Epoch: [180] [243200/1281167 (19%)]	Loss: 0.909800
[2022-04-07 19:14:52 | train] - Train Epoch: [180] [256000/1281167 (20%)]	Loss: 0.757284
[2022-04-07 19:15:19 | train] - Train Epoch: [180] [268800/1281167 (21%)]	Loss: 0.734323
[2022-04-07 19:15:47 | train] - Train Epoch: [180] [281600/1281167 (22%)]	Loss: 0.944028
[2022-04-07 19:16:15 | train] - Train Epoch: [180] [294400/1281167 (23%)]	Loss: 0.975520
[2022-04-07 19:16:42 | train] - Train Epoch: [180] [307200/1281167 (24%)]	Loss: 0.707504
[I 19:17:01.699 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:17:01.700 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:17:10 | train] - Train Epoch: [180] [320000/1281167 (25%)]	Loss: 0.741007
[2022-04-07 19:17:38 | train] - Train Epoch: [180] [332800/1281167 (26%)]	Loss: 0.780702
[2022-04-07 19:18:05 | train] - Train Epoch: [180] [345600/1281167 (27%)]	Loss: 0.584615
[2022-04-07 19:18:33 | train] - Train Epoch: [180] [358400/1281167 (28%)]	Loss: 0.572138
[2022-04-07 19:19:01 | train] - Train Epoch: [180] [371200/1281167 (29%)]	Loss: 0.757305
[2022-04-07 19:19:30 | train] - Train Epoch: [180] [384000/1281167 (30%)]	Loss: 0.657269
[2022-04-07 19:19:57 | train] - Train Epoch: [180] [396800/1281167 (31%)]	Loss: 0.912986
[2022-04-07 19:20:26 | train] - Train Epoch: [180] [409600/1281167 (32%)]	Loss: 0.873837
[2022-04-07 19:20:53 | train] - Train Epoch: [180] [422400/1281167 (33%)]	Loss: 1.238514
[2022-04-07 19:21:21 | train] - Train Epoch: [180] [435200/1281167 (34%)]	Loss: 0.841483
[2022-04-07 19:21:49 | train] - Train Epoch: [180] [448000/1281167 (35%)]	Loss: 0.775464
[2022-04-07 19:22:17 | train] - Train Epoch: [180] [460800/1281167 (36%)]	Loss: 0.892819
[2022-04-07 19:22:46 | train] - Train Epoch: [180] [473600/1281167 (37%)]	Loss: 0.819754
[2022-04-07 19:23:14 | train] - Train Epoch: [180] [486400/1281167 (38%)]	Loss: 0.477413
[2022-04-07 19:23:42 | train] - Train Epoch: [180] [499200/1281167 (39%)]	Loss: 0.975932
[2022-04-07 19:24:09 | train] - Train Epoch: [180] [512000/1281167 (40%)]	Loss: 0.782273
[2022-04-07 19:24:37 | train] - Train Epoch: [180] [524800/1281167 (41%)]	Loss: 0.810436
[I 19:25:00.884 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:25:00.885 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:25:05 | train] - Train Epoch: [180] [537600/1281167 (42%)]	Loss: 0.715142
[2022-04-07 19:25:33 | train] - Train Epoch: [180] [550400/1281167 (43%)]	Loss: 0.446591
[2022-04-07 19:26:01 | train] - Train Epoch: [180] [563200/1281167 (44%)]	Loss: 0.946230
[2022-04-07 19:26:29 | train] - Train Epoch: [180] [576000/1281167 (45%)]	Loss: 0.622210
[2022-04-07 19:26:57 | train] - Train Epoch: [180] [588800/1281167 (46%)]	Loss: 0.783005
[I 19:27:00.871 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:27:00.872 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:27:25 | train] - Train Epoch: [180] [601600/1281167 (47%)]	Loss: 0.819902
[2022-04-07 19:27:52 | train] - Train Epoch: [180] [614400/1281167 (48%)]	Loss: 0.680791
[2022-04-07 19:28:20 | train] - Train Epoch: [180] [627200/1281167 (49%)]	Loss: 0.904184
[2022-04-07 19:28:49 | train] - Train Epoch: [180] [640000/1281167 (50%)]	Loss: 0.985877
[I 19:29:01.695 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:29:01.696 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:29:17 | train] - Train Epoch: [180] [652800/1281167 (51%)]	Loss: 0.770984
[2022-04-07 19:29:44 | train] - Train Epoch: [180] [665600/1281167 (52%)]	Loss: 0.854251
[2022-04-07 19:30:12 | train] - Train Epoch: [180] [678400/1281167 (53%)]	Loss: 0.709307
[2022-04-07 19:30:40 | train] - Train Epoch: [180] [691200/1281167 (54%)]	Loss: 0.581606
[2022-04-07 19:31:09 | train] - Train Epoch: [180] [704000/1281167 (55%)]	Loss: 0.627479
[2022-04-07 19:31:36 | train] - Train Epoch: [180] [716800/1281167 (56%)]	Loss: 0.850870
[2022-04-07 19:32:04 | train] - Train Epoch: [180] [729600/1281167 (57%)]	Loss: 1.023403
[2022-04-07 19:32:31 | train] - Train Epoch: [180] [742400/1281167 (58%)]	Loss: 0.670383
[2022-04-07 19:32:59 | train] - Train Epoch: [180] [755200/1281167 (59%)]	Loss: 0.847878
[2022-04-07 19:33:27 | train] - Train Epoch: [180] [768000/1281167 (60%)]	Loss: 0.709954
[2022-04-07 19:33:56 | train] - Train Epoch: [180] [780800/1281167 (61%)]	Loss: 0.943171
[2022-04-07 19:34:23 | train] - Train Epoch: [180] [793600/1281167 (62%)]	Loss: 0.869319
[2022-04-07 19:34:50 | train] - Train Epoch: [180] [806400/1281167 (63%)]	Loss: 1.062538
[2022-04-07 19:35:17 | train] - Train Epoch: [180] [819200/1281167 (64%)]	Loss: 0.448365
[2022-04-07 19:35:46 | train] - Train Epoch: [180] [832000/1281167 (65%)]	Loss: 0.715042
[2022-04-07 19:36:13 | train] - Train Epoch: [180] [844800/1281167 (66%)]	Loss: 0.763868
[2022-04-07 19:36:42 | train] - Train Epoch: [180] [857600/1281167 (67%)]	Loss: 1.111915
[2022-04-07 19:37:09 | train] - Train Epoch: [180] [870400/1281167 (68%)]	Loss: 0.936062
[2022-04-07 19:37:38 | train] - Train Epoch: [180] [883200/1281167 (69%)]	Loss: 0.855679
[2022-04-07 19:38:05 | train] - Train Epoch: [180] [896000/1281167 (70%)]	Loss: 0.651922
[2022-04-07 19:38:32 | train] - Train Epoch: [180] [908800/1281167 (71%)]	Loss: 0.826652
[2022-04-07 19:39:00 | train] - Train Epoch: [180] [921600/1281167 (72%)]	Loss: 0.624515
[2022-04-07 19:39:28 | train] - Train Epoch: [180] [934400/1281167 (73%)]	Loss: 0.704085
[2022-04-07 19:39:55 | train] - Train Epoch: [180] [947200/1281167 (74%)]	Loss: 0.782960
[2022-04-07 19:40:24 | train] - Train Epoch: [180] [960000/1281167 (75%)]	Loss: 0.784168
[2022-04-07 19:40:52 | train] - Train Epoch: [180] [972800/1281167 (76%)]	Loss: 0.664184
[2022-04-07 19:41:19 | train] - Train Epoch: [180] [985600/1281167 (77%)]	Loss: 0.534662
[2022-04-07 19:41:48 | train] - Train Epoch: [180] [998400/1281167 (78%)]	Loss: 0.666716
[2022-04-07 19:42:16 | train] - Train Epoch: [180] [1011200/1281167 (79%)]	Loss: 0.746058
[2022-04-07 19:42:44 | train] - Train Epoch: [180] [1024000/1281167 (80%)]	Loss: 0.750282
[I 19:43:00.913 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:43:00.914 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:43:13 | train] - Train Epoch: [180] [1036800/1281167 (81%)]	Loss: 0.745461
[2022-04-07 19:43:41 | train] - Train Epoch: [180] [1049600/1281167 (82%)]	Loss: 0.681960
[2022-04-07 19:44:09 | train] - Train Epoch: [180] [1062400/1281167 (83%)]	Loss: 0.591161
[2022-04-07 19:44:36 | train] - Train Epoch: [180] [1075200/1281167 (84%)]	Loss: 0.520592
[I 19:45:01.710 NotebookApp] Saving file at /pdh_test.ipynb
[I 19:45:01.711 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 19:45:04 | train] - Train Epoch: [180] [1088000/1281167 (85%)]	Loss: 0.728826
[2022-04-07 19:45:32 | train] - Train Epoch: [180] [1100800/1281167 (86%)]	Loss: 0.757581
[2022-04-07 19:46:00 | train] - Train Epoch: [180] [1113600/1281167 (87%)]	Loss: 0.698574
[2022-04-07 19:46:28 | train] - Train Epoch: [180] [1126400/1281167 (88%)]	Loss: 0.769446
[2022-04-07 19:46:56 | train] - Train Epoch: [180] [1139200/1281167 (89%)]	Loss: 0.871022
[2022-04-07 19:47:23 | train] - Train Epoch: [180] [1152000/1281167 (90%)]	Loss: 0.845299
[2022-04-07 19:47:52 | train] - Train Epoch: [180] [1164800/1281167 (91%)]	Loss: 0.607728
[2022-04-07 19:48:20 | train] - Train Epoch: [180] [1177600/1281167 (92%)]	Loss: 0.654490
[2022-04-07 19:48:47 | train] - Train Epoch: [180] [1190400/1281167 (93%)]	Loss: 0.548957
[2022-04-07 19:49:16 | train] - Train Epoch: [180] [1203200/1281167 (94%)]	Loss: 0.617549
[2022-04-07 19:49:45 | train] - Train Epoch: [180] [1216000/1281167 (95%)]	Loss: 0.594095
[2022-04-07 19:50:13 | train] - Train Epoch: [180] [1228800/1281167 (96%)]	Loss: 0.727438
[2022-04-07 19:50:41 | train] - Train Epoch: [180] [1241600/1281167 (97%)]	Loss: 0.744304
[2022-04-07 19:51:09 | train] - Train Epoch: [180] [1254400/1281167 (98%)]	Loss: 0.612272
[2022-04-07 19:51:39 | train] - Train Epoch: [180] [1267200/1281167 (99%)]	Loss: 0.594915
[2022-04-07 19:52:07 | train] - Train Epoch: [180] [1280000/1281167 (100%)]	Loss: 0.502579
[2022-04-07 19:52:09 | train] - Train Epoch: [180]	 Average Loss: 0.759689	 Total Acc : 81.4486	 Total Top5 Acc : 93.2340
[2022-04-07 19:52:09 | train] - -------180 epoch end-----------
========================================
-------180 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 19:54:04 | train] - 
Epoch [180] Test set: Average loss: 1.4572, Accuracy: 34868/50000 (69.7087%), Top-5 Accuracy: 88.7432%

[2022-04-07 19:54:04 | train] - save intermediate epoch [180] result


[2022-04-07 19:54:26 | train] - -------181 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 19:54:28 | train] - Train Epoch: [181] [0/1281167 (0%)]	Loss: 0.677231
[2022-04-07 19:54:54 | train] - Train Epoch: [181] [12800/1281167 (1%)]	Loss: 0.602124
[2022-04-07 19:55:22 | train] - Train Epoch: [181] [25600/1281167 (2%)]	Loss: 0.792919
[2022-04-07 19:55:49 | train] - Train Epoch: [181] [38400/1281167 (3%)]	Loss: 0.731180
[2022-04-07 19:56:15 | train] - Train Epoch: [181] [51200/1281167 (4%)]	Loss: 0.562939
[2022-04-07 19:56:43 | train] - Train Epoch: [181] [64000/1281167 (5%)]	Loss: 0.789611
[2022-04-07 19:57:09 | train] - Train Epoch: [181] [76800/1281167 (6%)]	Loss: 0.987660
[2022-04-07 19:57:37 | train] - Train Epoch: [181] [89600/1281167 (7%)]	Loss: 0.732043
[2022-04-07 19:58:05 | train] - Train Epoch: [181] [102400/1281167 (8%)]	Loss: 0.811959
[2022-04-07 19:58:32 | train] - Train Epoch: [181] [115200/1281167 (9%)]	Loss: 0.805159
[2022-04-07 19:58:58 | train] - Train Epoch: [181] [128000/1281167 (10%)]	Loss: 0.776254
[2022-04-07 19:59:26 | train] - Train Epoch: [181] [140800/1281167 (11%)]	Loss: 0.781801
[2022-04-07 19:59:53 | train] - Train Epoch: [181] [153600/1281167 (12%)]	Loss: 0.918994
[2022-04-07 20:00:21 | train] - Train Epoch: [181] [166400/1281167 (13%)]	Loss: 0.950839
[2022-04-07 20:00:48 | train] - Train Epoch: [181] [179200/1281167 (14%)]	Loss: 0.777837
[2022-04-07 20:01:14 | train] - Train Epoch: [181] [192000/1281167 (15%)]	Loss: 0.885472
[2022-04-07 20:01:41 | train] - Train Epoch: [181] [204800/1281167 (16%)]	Loss: 0.912086
[2022-04-07 20:02:08 | train] - Train Epoch: [181] [217600/1281167 (17%)]	Loss: 0.612281
[2022-04-07 20:02:35 | train] - Train Epoch: [181] [230400/1281167 (18%)]	Loss: 0.722194
[2022-04-07 20:03:03 | train] - Train Epoch: [181] [243200/1281167 (19%)]	Loss: 0.718037
[2022-04-07 20:03:31 | train] - Train Epoch: [181] [256000/1281167 (20%)]	Loss: 0.934137
[2022-04-07 20:03:58 | train] - Train Epoch: [181] [268800/1281167 (21%)]	Loss: 0.726047
[2022-04-07 20:04:26 | train] - Train Epoch: [181] [281600/1281167 (22%)]	Loss: 0.814046
[2022-04-07 20:04:53 | train] - Train Epoch: [181] [294400/1281167 (23%)]	Loss: 0.700942
[2022-04-07 20:05:21 | train] - Train Epoch: [181] [307200/1281167 (24%)]	Loss: 0.730079
[2022-04-07 20:05:48 | train] - Train Epoch: [181] [320000/1281167 (25%)]	Loss: 0.709545
[2022-04-07 20:06:17 | train] - Train Epoch: [181] [332800/1281167 (26%)]	Loss: 0.772279
[2022-04-07 20:06:44 | train] - Train Epoch: [181] [345600/1281167 (27%)]	Loss: 0.626666
[2022-04-07 20:07:11 | train] - Train Epoch: [181] [358400/1281167 (28%)]	Loss: 0.808403
[2022-04-07 20:07:40 | train] - Train Epoch: [181] [371200/1281167 (29%)]	Loss: 0.870148
[2022-04-07 20:08:07 | train] - Train Epoch: [181] [384000/1281167 (30%)]	Loss: 0.761126
[2022-04-07 20:08:35 | train] - Train Epoch: [181] [396800/1281167 (31%)]	Loss: 0.695358
[2022-04-07 20:09:03 | train] - Train Epoch: [181] [409600/1281167 (32%)]	Loss: 0.898863
[2022-04-07 20:09:30 | train] - Train Epoch: [181] [422400/1281167 (33%)]	Loss: 1.067058
[2022-04-07 20:09:57 | train] - Train Epoch: [181] [435200/1281167 (34%)]	Loss: 0.701657
[2022-04-07 20:10:24 | train] - Train Epoch: [181] [448000/1281167 (35%)]	Loss: 0.686306
[2022-04-07 20:10:51 | train] - Train Epoch: [181] [460800/1281167 (36%)]	Loss: 0.848678
[2022-04-07 20:11:18 | train] - Train Epoch: [181] [473600/1281167 (37%)]	Loss: 0.767425
[2022-04-07 20:11:45 | train] - Train Epoch: [181] [486400/1281167 (38%)]	Loss: 0.955145
[2022-04-07 20:12:12 | train] - Train Epoch: [181] [499200/1281167 (39%)]	Loss: 0.663615
[2022-04-07 20:12:40 | train] - Train Epoch: [181] [512000/1281167 (40%)]	Loss: 0.736337
[2022-04-07 20:13:08 | train] - Train Epoch: [181] [524800/1281167 (41%)]	Loss: 0.902097
[2022-04-07 20:13:35 | train] - Train Epoch: [181] [537600/1281167 (42%)]	Loss: 0.801162
[2022-04-07 20:14:02 | train] - Train Epoch: [181] [550400/1281167 (43%)]	Loss: 0.694319
[2022-04-07 20:14:29 | train] - Train Epoch: [181] [563200/1281167 (44%)]	Loss: 0.768178
[2022-04-07 20:14:57 | train] - Train Epoch: [181] [576000/1281167 (45%)]	Loss: 0.768815
[2022-04-07 20:15:24 | train] - Train Epoch: [181] [588800/1281167 (46%)]	Loss: 0.657347
[2022-04-07 20:15:52 | train] - Train Epoch: [181] [601600/1281167 (47%)]	Loss: 0.806603
[2022-04-07 20:16:20 | train] - Train Epoch: [181] [614400/1281167 (48%)]	Loss: 0.477287
[2022-04-07 20:16:46 | train] - Train Epoch: [181] [627200/1281167 (49%)]	Loss: 0.660059
[2022-04-07 20:17:14 | train] - Train Epoch: [181] [640000/1281167 (50%)]	Loss: 0.744951
[2022-04-07 20:17:41 | train] - Train Epoch: [181] [652800/1281167 (51%)]	Loss: 0.531088
[2022-04-07 20:18:08 | train] - Train Epoch: [181] [665600/1281167 (52%)]	Loss: 0.682348
[2022-04-07 20:18:35 | train] - Train Epoch: [181] [678400/1281167 (53%)]	Loss: 0.677202
[2022-04-07 20:19:02 | train] - Train Epoch: [181] [691200/1281167 (54%)]	Loss: 0.821395
[2022-04-07 20:19:29 | train] - Train Epoch: [181] [704000/1281167 (55%)]	Loss: 0.669451
[2022-04-07 20:19:57 | train] - Train Epoch: [181] [716800/1281167 (56%)]	Loss: 0.698769
[2022-04-07 20:20:24 | train] - Train Epoch: [181] [729600/1281167 (57%)]	Loss: 0.849450
[2022-04-07 20:20:52 | train] - Train Epoch: [181] [742400/1281167 (58%)]	Loss: 1.005296
[2022-04-07 20:21:18 | train] - Train Epoch: [181] [755200/1281167 (59%)]	Loss: 0.937921
[2022-04-07 20:21:46 | train] - Train Epoch: [181] [768000/1281167 (60%)]	Loss: 0.851775
[2022-04-07 20:22:13 | train] - Train Epoch: [181] [780800/1281167 (61%)]	Loss: 0.579294
[2022-04-07 20:22:40 | train] - Train Epoch: [181] [793600/1281167 (62%)]	Loss: 0.756345
[2022-04-07 20:23:08 | train] - Train Epoch: [181] [806400/1281167 (63%)]	Loss: 0.800398
[2022-04-07 20:23:35 | train] - Train Epoch: [181] [819200/1281167 (64%)]	Loss: 0.882801
[2022-04-07 20:24:01 | train] - Train Epoch: [181] [832000/1281167 (65%)]	Loss: 0.629315
[2022-04-07 20:24:28 | train] - Train Epoch: [181] [844800/1281167 (66%)]	Loss: 0.728831
[2022-04-07 20:24:56 | train] - Train Epoch: [181] [857600/1281167 (67%)]	Loss: 0.755502
[I 20:25:01.806 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:25:01.807 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 20:25:24 | train] - Train Epoch: [181] [870400/1281167 (68%)]	Loss: 0.678387
[2022-04-07 20:25:50 | train] - Train Epoch: [181] [883200/1281167 (69%)]	Loss: 0.523184
[2022-04-07 20:26:17 | train] - Train Epoch: [181] [896000/1281167 (70%)]	Loss: 0.666442
[2022-04-07 20:26:45 | train] - Train Epoch: [181] [908800/1281167 (71%)]	Loss: 0.844256
[2022-04-07 20:27:12 | train] - Train Epoch: [181] [921600/1281167 (72%)]	Loss: 0.764318
[2022-04-07 20:27:40 | train] - Train Epoch: [181] [934400/1281167 (73%)]	Loss: 0.869653
[2022-04-07 20:28:08 | train] - Train Epoch: [181] [947200/1281167 (74%)]	Loss: 0.884418
[2022-04-07 20:28:35 | train] - Train Epoch: [181] [960000/1281167 (75%)]	Loss: 0.902587
[2022-04-07 20:29:02 | train] - Train Epoch: [181] [972800/1281167 (76%)]	Loss: 0.582570
[2022-04-07 20:29:30 | train] - Train Epoch: [181] [985600/1281167 (77%)]	Loss: 0.669749
[2022-04-07 20:29:59 | train] - Train Epoch: [181] [998400/1281167 (78%)]	Loss: 0.786921
[2022-04-07 20:30:26 | train] - Train Epoch: [181] [1011200/1281167 (79%)]	Loss: 0.587693
[2022-04-07 20:30:54 | train] - Train Epoch: [181] [1024000/1281167 (80%)]	Loss: 0.812978
[I 20:31:00.976 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:31:00.976 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 20:31:23 | train] - Train Epoch: [181] [1036800/1281167 (81%)]	Loss: 0.885965
[2022-04-07 20:31:51 | train] - Train Epoch: [181] [1049600/1281167 (82%)]	Loss: 0.587747
[2022-04-07 20:32:18 | train] - Train Epoch: [181] [1062400/1281167 (83%)]	Loss: 0.670974
[2022-04-07 20:32:46 | train] - Train Epoch: [181] [1075200/1281167 (84%)]	Loss: 0.563312
[I 20:33:00.982 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:33:00.983 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 20:33:14 | train] - Train Epoch: [181] [1088000/1281167 (85%)]	Loss: 0.418654
[2022-04-07 20:33:40 | train] - Train Epoch: [181] [1100800/1281167 (86%)]	Loss: 0.647596
[2022-04-07 20:34:09 | train] - Train Epoch: [181] [1113600/1281167 (87%)]	Loss: 0.674905
[2022-04-07 20:34:36 | train] - Train Epoch: [181] [1126400/1281167 (88%)]	Loss: 0.720837
[I 20:35:00.981 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:35:00.982 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 20:35:03 | train] - Train Epoch: [181] [1139200/1281167 (89%)]	Loss: 0.677343
[2022-04-07 20:35:31 | train] - Train Epoch: [181] [1152000/1281167 (90%)]	Loss: 0.833162
[2022-04-07 20:36:01 | train] - Train Epoch: [181] [1164800/1281167 (91%)]	Loss: 0.577986
[2022-04-07 20:36:30 | train] - Train Epoch: [181] [1177600/1281167 (92%)]	Loss: 0.722452
[2022-04-07 20:37:00 | train] - Train Epoch: [181] [1190400/1281167 (93%)]	Loss: 0.588710
[I 20:37:01.003 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:37:01.004 NotebookApp] Saving pdh_test.ipynb
[2022-04-07 20:37:29 | train] - Train Epoch: [181] [1203200/1281167 (94%)]	Loss: 0.680783
[2022-04-07 20:37:57 | train] - Train Epoch: [181] [1216000/1281167 (95%)]	Loss: 0.746029
[I 20:38:12.776 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:38:12.777 NotebookApp] Saving pdh_test.ipynb
[I 20:38:13.137 NotebookApp] Saving file at /pdh_test.ipynb
[I 20:38:13.138 NotebookApp] Saving pdh_test.ipynb
[I 20:38:14.308 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:f455c992266f456c82d34c7be4b33e81
[2022-04-07 20:38:26 | train] - Train Epoch: [181] [1228800/1281167 (96%)]	Loss: 0.835032
[2022-04-07 20:38:55 | train] - Train Epoch: [181] [1241600/1281167 (97%)]	Loss: 0.560572
[2022-04-07 20:39:24 | train] - Train Epoch: [181] [1254400/1281167 (98%)]	Loss: 0.637043
[2022-04-07 20:39:53 | train] - Train Epoch: [181] [1267200/1281167 (99%)]	Loss: 1.125159
[2022-04-07 20:40:20 | train] - Train Epoch: [181] [1280000/1281167 (100%)]	Loss: 0.850027
[2022-04-07 20:40:23 | train] - Train Epoch: [181]	 Average Loss: 0.757575	 Total Acc : 81.5118	 Total Top5 Acc : 93.2552
[2022-04-07 20:40:23 | train] - -------181 epoch end-----------
========================================
-------181 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 20:42:15 | train] - 
Epoch [181] Test set: Average loss: 1.4607, Accuracy: 34889/50000 (69.7518%), Top-5 Accuracy: 88.7692%

[2022-04-07 20:42:15 | train] - save intermediate epoch [181] result


[2022-04-07 20:42:38 | train] - -------182 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 20:42:40 | train] - Train Epoch: [182] [0/1281167 (0%)]	Loss: 0.673063
[2022-04-07 20:43:07 | train] - Train Epoch: [182] [12800/1281167 (1%)]	Loss: 0.817346
[2022-04-07 20:43:33 | train] - Train Epoch: [182] [25600/1281167 (2%)]	Loss: 1.130219
[2022-04-07 20:44:01 | train] - Train Epoch: [182] [38400/1281167 (3%)]	Loss: 0.850460
[2022-04-07 20:44:28 | train] - Train Epoch: [182] [51200/1281167 (4%)]	Loss: 0.857915
[2022-04-07 20:44:54 | train] - Train Epoch: [182] [64000/1281167 (5%)]	Loss: 0.789168
[2022-04-07 20:45:21 | train] - Train Epoch: [182] [76800/1281167 (6%)]	Loss: 0.873536
[2022-04-07 20:45:49 | train] - Train Epoch: [182] [89600/1281167 (7%)]	Loss: 0.901963
[2022-04-07 20:46:15 | train] - Train Epoch: [182] [102400/1281167 (8%)]	Loss: 0.730194
[2022-04-07 20:46:42 | train] - Train Epoch: [182] [115200/1281167 (9%)]	Loss: 0.810797
[2022-04-07 20:47:09 | train] - Train Epoch: [182] [128000/1281167 (10%)]	Loss: 0.643359
[2022-04-07 20:47:36 | train] - Train Epoch: [182] [140800/1281167 (11%)]	Loss: 1.078649
[2022-04-07 20:48:03 | train] - Train Epoch: [182] [153600/1281167 (12%)]	Loss: 0.433996
[2022-04-07 20:48:29 | train] - Train Epoch: [182] [166400/1281167 (13%)]	Loss: 0.833657
[2022-04-07 20:48:57 | train] - Train Epoch: [182] [179200/1281167 (14%)]	Loss: 0.747133
[2022-04-07 20:49:23 | train] - Train Epoch: [182] [192000/1281167 (15%)]	Loss: 0.603498
[2022-04-07 20:49:50 | train] - Train Epoch: [182] [204800/1281167 (16%)]	Loss: 0.584960
[2022-04-07 20:50:16 | train] - Train Epoch: [182] [217600/1281167 (17%)]	Loss: 0.835679
[2022-04-07 20:50:43 | train] - Train Epoch: [182] [230400/1281167 (18%)]	Loss: 0.766341
[2022-04-07 20:51:10 | train] - Train Epoch: [182] [243200/1281167 (19%)]	Loss: 0.442208
[2022-04-07 20:51:36 | train] - Train Epoch: [182] [256000/1281167 (20%)]	Loss: 0.595074
[2022-04-07 20:52:03 | train] - Train Epoch: [182] [268800/1281167 (21%)]	Loss: 0.856091
[2022-04-07 20:52:30 | train] - Train Epoch: [182] [281600/1281167 (22%)]	Loss: 0.770828
[2022-04-07 20:52:57 | train] - Train Epoch: [182] [294400/1281167 (23%)]	Loss: 0.878788
[2022-04-07 20:53:24 | train] - Train Epoch: [182] [307200/1281167 (24%)]	Loss: 0.551318
[2022-04-07 20:53:52 | train] - Train Epoch: [182] [320000/1281167 (25%)]	Loss: 0.678885
[2022-04-07 20:54:18 | train] - Train Epoch: [182] [332800/1281167 (26%)]	Loss: 0.654859
[2022-04-07 20:54:45 | train] - Train Epoch: [182] [345600/1281167 (27%)]	Loss: 0.854154
[2022-04-07 20:55:12 | train] - Train Epoch: [182] [358400/1281167 (28%)]	Loss: 0.557917
[2022-04-07 20:55:39 | train] - Train Epoch: [182] [371200/1281167 (29%)]	Loss: 0.607028
[2022-04-07 20:56:06 | train] - Train Epoch: [182] [384000/1281167 (30%)]	Loss: 0.671338
[2022-04-07 20:56:34 | train] - Train Epoch: [182] [396800/1281167 (31%)]	Loss: 0.824367
[2022-04-07 20:57:02 | train] - Train Epoch: [182] [409600/1281167 (32%)]	Loss: 0.795127
[2022-04-07 20:57:29 | train] - Train Epoch: [182] [422400/1281167 (33%)]	Loss: 0.963069
[2022-04-07 20:57:57 | train] - Train Epoch: [182] [435200/1281167 (34%)]	Loss: 0.764070
[2022-04-07 20:58:25 | train] - Train Epoch: [182] [448000/1281167 (35%)]	Loss: 0.913708
[2022-04-07 20:58:52 | train] - Train Epoch: [182] [460800/1281167 (36%)]	Loss: 0.701951
[2022-04-07 20:59:19 | train] - Train Epoch: [182] [473600/1281167 (37%)]	Loss: 0.418290
[2022-04-07 20:59:46 | train] - Train Epoch: [182] [486400/1281167 (38%)]	Loss: 0.641277
[2022-04-07 21:00:14 | train] - Train Epoch: [182] [499200/1281167 (39%)]	Loss: 0.635684
[2022-04-07 21:00:40 | train] - Train Epoch: [182] [512000/1281167 (40%)]	Loss: 0.947468
[2022-04-07 21:01:08 | train] - Train Epoch: [182] [524800/1281167 (41%)]	Loss: 1.043319
[2022-04-07 21:01:35 | train] - Train Epoch: [182] [537600/1281167 (42%)]	Loss: 0.712841
[2022-04-07 21:02:03 | train] - Train Epoch: [182] [550400/1281167 (43%)]	Loss: 0.713577
[2022-04-07 21:02:30 | train] - Train Epoch: [182] [563200/1281167 (44%)]	Loss: 0.797489
[2022-04-07 21:02:56 | train] - Train Epoch: [182] [576000/1281167 (45%)]	Loss: 0.735257
[2022-04-07 21:03:22 | train] - Train Epoch: [182] [588800/1281167 (46%)]	Loss: 0.688571
[2022-04-07 21:03:50 | train] - Train Epoch: [182] [601600/1281167 (47%)]	Loss: 0.838995
[2022-04-07 21:04:17 | train] - Train Epoch: [182] [614400/1281167 (48%)]	Loss: 0.810338
[2022-04-07 21:04:45 | train] - Train Epoch: [182] [627200/1281167 (49%)]	Loss: 0.681935
[2022-04-07 21:05:12 | train] - Train Epoch: [182] [640000/1281167 (50%)]	Loss: 0.925828
[2022-04-07 21:05:39 | train] - Train Epoch: [182] [652800/1281167 (51%)]	Loss: 0.787203
[2022-04-07 21:06:06 | train] - Train Epoch: [182] [665600/1281167 (52%)]	Loss: 0.632364
[2022-04-07 21:06:33 | train] - Train Epoch: [182] [678400/1281167 (53%)]	Loss: 0.775644
[2022-04-07 21:07:00 | train] - Train Epoch: [182] [691200/1281167 (54%)]	Loss: 1.041002
[2022-04-07 21:07:27 | train] - Train Epoch: [182] [704000/1281167 (55%)]	Loss: 1.154714
[2022-04-07 21:07:55 | train] - Train Epoch: [182] [716800/1281167 (56%)]	Loss: 0.846833
[2022-04-07 21:08:24 | train] - Train Epoch: [182] [729600/1281167 (57%)]	Loss: 1.086041
[2022-04-07 21:08:52 | train] - Train Epoch: [182] [742400/1281167 (58%)]	Loss: 0.870728
[2022-04-07 21:09:18 | train] - Train Epoch: [182] [755200/1281167 (59%)]	Loss: 0.793394
[2022-04-07 21:09:45 | train] - Train Epoch: [182] [768000/1281167 (60%)]	Loss: 0.776746
[2022-04-07 21:10:12 | train] - Train Epoch: [182] [780800/1281167 (61%)]	Loss: 0.804135
[2022-04-07 21:10:39 | train] - Train Epoch: [182] [793600/1281167 (62%)]	Loss: 0.732028
[W 21:10:48.841 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 21:11:06 | train] - Train Epoch: [182] [806400/1281167 (63%)]	Loss: 0.764519
[I 21:11:21.068 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:a75ab5a60b4642f79571db17fa547ce6
[I 21:11:22.963 NotebookApp] Kernel restarted: 70aafaca-033a-4a2c-a6f9-8d60068e7fa8
[I 21:11:23.005 NotebookApp] Restoring connection for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:a75ab5a60b4642f79571db17fa547ce6
[W 21:11:27.517 NotebookApp] Nudge: attempt 10 on kernel 70aafaca-033a-4a2c-a6f9-8d60068e7fa8
[I 21:11:28.294 NotebookApp] Replaying 3 buffered messages
[2022-04-07 21:11:32 | train] - Train Epoch: [182] [819200/1281167 (64%)]	Loss: 0.758478
[2022-04-07 21:11:59 | train] - Train Epoch: [182] [832000/1281167 (65%)]	Loss: 0.684255
[2022-04-07 21:12:27 | train] - Train Epoch: [182] [844800/1281167 (66%)]	Loss: 0.874279
[I 21:12:49.061 NotebookApp] Saving file at /pdh_test.ipynb
[I 21:12:49.062 NotebookApp] Saving pdh_test.ipynb
[W 21:12:49.062 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 21:12:55 | train] - Train Epoch: [182] [857600/1281167 (67%)]	Loss: 0.561588
[2022-04-07 21:13:23 | train] - Train Epoch: [182] [870400/1281167 (68%)]	Loss: 0.817937
[2022-04-07 21:13:52 | train] - Train Epoch: [182] [883200/1281167 (69%)]	Loss: 0.892009
[2022-04-07 21:14:20 | train] - Train Epoch: [182] [896000/1281167 (70%)]	Loss: 0.869485
[2022-04-07 21:14:47 | train] - Train Epoch: [182] [908800/1281167 (71%)]	Loss: 0.770104
[I 21:14:49.873 NotebookApp] Saving file at /pdh_test.ipynb
[I 21:14:49.874 NotebookApp] Saving pdh_test.ipynb
[W 21:14:49.874 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 21:15:14 | train] - Train Epoch: [182] [921600/1281167 (72%)]	Loss: 0.730345
[2022-04-07 21:15:41 | train] - Train Epoch: [182] [934400/1281167 (73%)]	Loss: 0.722677
[2022-04-07 21:16:09 | train] - Train Epoch: [182] [947200/1281167 (74%)]	Loss: 0.701745
[2022-04-07 21:16:37 | train] - Train Epoch: [182] [960000/1281167 (75%)]	Loss: 0.868738
[2022-04-07 21:17:04 | train] - Train Epoch: [182] [972800/1281167 (76%)]	Loss: 0.995713
[2022-04-07 21:17:32 | train] - Train Epoch: [182] [985600/1281167 (77%)]	Loss: 0.707615
[2022-04-07 21:17:59 | train] - Train Epoch: [182] [998400/1281167 (78%)]	Loss: 0.718049
[2022-04-07 21:18:27 | train] - Train Epoch: [182] [1011200/1281167 (79%)]	Loss: 0.909250
[I 21:18:49.076 NotebookApp] Saving file at /pdh_test.ipynb
[I 21:18:49.076 NotebookApp] Saving pdh_test.ipynb
[W 21:18:49.077 NotebookApp] Notebook pdh_test.ipynb is not trusted
[2022-04-07 21:18:55 | train] - Train Epoch: [182] [1024000/1281167 (80%)]	Loss: 0.872550
[2022-04-07 21:19:23 | train] - Train Epoch: [182] [1036800/1281167 (81%)]	Loss: 0.694830
[2022-04-07 21:19:51 | train] - Train Epoch: [182] [1049600/1281167 (82%)]	Loss: 0.873087
[2022-04-07 21:20:19 | train] - Train Epoch: [182] [1062400/1281167 (83%)]	Loss: 0.691788
[2022-04-07 21:20:47 | train] - Train Epoch: [182] [1075200/1281167 (84%)]	Loss: 0.659335
[2022-04-07 21:21:15 | train] - Train Epoch: [182] [1088000/1281167 (85%)]	Loss: 0.635413
[2022-04-07 21:21:43 | train] - Train Epoch: [182] [1100800/1281167 (86%)]	Loss: 0.789105
[2022-04-07 21:22:11 | train] - Train Epoch: [182] [1113600/1281167 (87%)]	Loss: 0.836047
[2022-04-07 21:22:39 | train] - Train Epoch: [182] [1126400/1281167 (88%)]	Loss: 0.740095
[2022-04-07 21:23:07 | train] - Train Epoch: [182] [1139200/1281167 (89%)]	Loss: 0.901115
[2022-04-07 21:23:36 | train] - Train Epoch: [182] [1152000/1281167 (90%)]	Loss: 0.985721
[2022-04-07 21:24:03 | train] - Train Epoch: [182] [1164800/1281167 (91%)]	Loss: 0.837872
[2022-04-07 21:24:31 | train] - Train Epoch: [182] [1177600/1281167 (92%)]	Loss: 0.882499
[2022-04-07 21:24:58 | train] - Train Epoch: [182] [1190400/1281167 (93%)]	Loss: 0.855966
[2022-04-07 21:25:25 | train] - Train Epoch: [182] [1203200/1281167 (94%)]	Loss: 0.906608
[2022-04-07 21:25:53 | train] - Train Epoch: [182] [1216000/1281167 (95%)]	Loss: 0.855995
[2022-04-07 21:26:21 | train] - Train Epoch: [182] [1228800/1281167 (96%)]	Loss: 0.808523
[2022-04-07 21:26:49 | train] - Train Epoch: [182] [1241600/1281167 (97%)]	Loss: 0.954504
[2022-04-07 21:27:18 | train] - Train Epoch: [182] [1254400/1281167 (98%)]	Loss: 0.765150
[2022-04-07 21:27:45 | train] - Train Epoch: [182] [1267200/1281167 (99%)]	Loss: 0.910762
[2022-04-07 21:28:13 | train] - Train Epoch: [182] [1280000/1281167 (100%)]	Loss: 0.893527
[2022-04-07 21:28:15 | train] - Train Epoch: [182]	 Average Loss: 0.758299	 Total Acc : 81.4819	 Total Top5 Acc : 93.2722
[2022-04-07 21:28:15 | train] - -------182 epoch end-----------
========================================
-------182 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 21:30:13 | train] - 
Epoch [182] Test set: Average loss: 1.4629, Accuracy: 34833/50000 (69.6411%), Top-5 Accuracy: 88.7032%

[2022-04-07 21:30:13 | train] - save intermediate epoch [182] result


[2022-04-07 21:30:36 | train] - -------183 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 21:30:38 | train] - Train Epoch: [183] [0/1281167 (0%)]	Loss: 0.969088
[2022-04-07 21:31:05 | train] - Train Epoch: [183] [12800/1281167 (1%)]	Loss: 0.778994
[2022-04-07 21:31:31 | train] - Train Epoch: [183] [25600/1281167 (2%)]	Loss: 0.736735
[2022-04-07 21:31:58 | train] - Train Epoch: [183] [38400/1281167 (3%)]	Loss: 0.723170
[2022-04-07 21:32:25 | train] - Train Epoch: [183] [51200/1281167 (4%)]	Loss: 0.828133
[2022-04-07 21:32:51 | train] - Train Epoch: [183] [64000/1281167 (5%)]	Loss: 0.667669
[2022-04-07 21:33:19 | train] - Train Epoch: [183] [76800/1281167 (6%)]	Loss: 0.530716
[2022-04-07 21:33:46 | train] - Train Epoch: [183] [89600/1281167 (7%)]	Loss: 0.928041
[2022-04-07 21:34:14 | train] - Train Epoch: [183] [102400/1281167 (8%)]	Loss: 0.567087
[2022-04-07 21:34:41 | train] - Train Epoch: [183] [115200/1281167 (9%)]	Loss: 0.646654
[2022-04-07 21:35:07 | train] - Train Epoch: [183] [128000/1281167 (10%)]	Loss: 0.881370
[2022-04-07 21:35:34 | train] - Train Epoch: [183] [140800/1281167 (11%)]	Loss: 0.820373
[2022-04-07 21:36:01 | train] - Train Epoch: [183] [153600/1281167 (12%)]	Loss: 0.517890
[2022-04-07 21:36:28 | train] - Train Epoch: [183] [166400/1281167 (13%)]	Loss: 0.637091
[2022-04-07 21:36:56 | train] - Train Epoch: [183] [179200/1281167 (14%)]	Loss: 0.853663
[2022-04-07 21:37:22 | train] - Train Epoch: [183] [192000/1281167 (15%)]	Loss: 0.859433
[2022-04-07 21:37:50 | train] - Train Epoch: [183] [204800/1281167 (16%)]	Loss: 0.723752
[2022-04-07 21:38:18 | train] - Train Epoch: [183] [217600/1281167 (17%)]	Loss: 0.652207
[2022-04-07 21:38:44 | train] - Train Epoch: [183] [230400/1281167 (18%)]	Loss: 0.728847
[2022-04-07 21:39:13 | train] - Train Epoch: [183] [243200/1281167 (19%)]	Loss: 0.500027
[2022-04-07 21:39:41 | train] - Train Epoch: [183] [256000/1281167 (20%)]	Loss: 0.801674
[2022-04-07 21:40:07 | train] - Train Epoch: [183] [268800/1281167 (21%)]	Loss: 0.779612
[2022-04-07 21:40:34 | train] - Train Epoch: [183] [281600/1281167 (22%)]	Loss: 0.780209
[2022-04-07 21:41:01 | train] - Train Epoch: [183] [294400/1281167 (23%)]	Loss: 0.709315
[2022-04-07 21:41:28 | train] - Train Epoch: [183] [307200/1281167 (24%)]	Loss: 0.648868
[2022-04-07 21:41:55 | train] - Train Epoch: [183] [320000/1281167 (25%)]	Loss: 0.656719
[2022-04-07 21:42:22 | train] - Train Epoch: [183] [332800/1281167 (26%)]	Loss: 0.804026
[2022-04-07 21:42:48 | train] - Train Epoch: [183] [345600/1281167 (27%)]	Loss: 0.658486
[2022-04-07 21:43:15 | train] - Train Epoch: [183] [358400/1281167 (28%)]	Loss: 0.821389
[2022-04-07 21:43:42 | train] - Train Epoch: [183] [371200/1281167 (29%)]	Loss: 0.959115
[2022-04-07 21:44:09 | train] - Train Epoch: [183] [384000/1281167 (30%)]	Loss: 0.854642
[2022-04-07 21:44:37 | train] - Train Epoch: [183] [396800/1281167 (31%)]	Loss: 0.763291
[2022-04-07 21:45:03 | train] - Train Epoch: [183] [409600/1281167 (32%)]	Loss: 0.702501
[2022-04-07 21:45:31 | train] - Train Epoch: [183] [422400/1281167 (33%)]	Loss: 0.718344
[2022-04-07 21:45:58 | train] - Train Epoch: [183] [435200/1281167 (34%)]	Loss: 0.714806
[2022-04-07 21:46:25 | train] - Train Epoch: [183] [448000/1281167 (35%)]	Loss: 0.813946
[2022-04-07 21:46:53 | train] - Train Epoch: [183] [460800/1281167 (36%)]	Loss: 0.571378
[2022-04-07 21:47:20 | train] - Train Epoch: [183] [473600/1281167 (37%)]	Loss: 0.472379
[2022-04-07 21:47:47 | train] - Train Epoch: [183] [486400/1281167 (38%)]	Loss: 0.621167
[2022-04-07 21:48:14 | train] - Train Epoch: [183] [499200/1281167 (39%)]	Loss: 0.717214
[2022-04-07 21:48:41 | train] - Train Epoch: [183] [512000/1281167 (40%)]	Loss: 0.638120
[2022-04-07 21:49:09 | train] - Train Epoch: [183] [524800/1281167 (41%)]	Loss: 0.741569
[2022-04-07 21:49:36 | train] - Train Epoch: [183] [537600/1281167 (42%)]	Loss: 0.891629
[2022-04-07 21:50:03 | train] - Train Epoch: [183] [550400/1281167 (43%)]	Loss: 0.743565
[2022-04-07 21:50:30 | train] - Train Epoch: [183] [563200/1281167 (44%)]	Loss: 0.559600
[2022-04-07 21:50:57 | train] - Train Epoch: [183] [576000/1281167 (45%)]	Loss: 0.857241
[2022-04-07 21:51:24 | train] - Train Epoch: [183] [588800/1281167 (46%)]	Loss: 0.961199
[2022-04-07 21:51:52 | train] - Train Epoch: [183] [601600/1281167 (47%)]	Loss: 0.796062
[2022-04-07 21:52:19 | train] - Train Epoch: [183] [614400/1281167 (48%)]	Loss: 0.742720
[2022-04-07 21:52:46 | train] - Train Epoch: [183] [627200/1281167 (49%)]	Loss: 0.518018
[2022-04-07 21:53:13 | train] - Train Epoch: [183] [640000/1281167 (50%)]	Loss: 1.054479
[2022-04-07 21:53:40 | train] - Train Epoch: [183] [652800/1281167 (51%)]	Loss: 0.653953
[2022-04-07 21:54:07 | train] - Train Epoch: [183] [665600/1281167 (52%)]	Loss: 0.681057
[2022-04-07 21:54:35 | train] - Train Epoch: [183] [678400/1281167 (53%)]	Loss: 0.736931
[2022-04-07 21:55:02 | train] - Train Epoch: [183] [691200/1281167 (54%)]	Loss: 0.676863
[2022-04-07 21:55:28 | train] - Train Epoch: [183] [704000/1281167 (55%)]	Loss: 0.891726
[2022-04-07 21:55:55 | train] - Train Epoch: [183] [716800/1281167 (56%)]	Loss: 0.575371
[2022-04-07 21:56:22 | train] - Train Epoch: [183] [729600/1281167 (57%)]	Loss: 0.855574
[2022-04-07 21:56:50 | train] - Train Epoch: [183] [742400/1281167 (58%)]	Loss: 0.831191
[2022-04-07 21:57:17 | train] - Train Epoch: [183] [755200/1281167 (59%)]	Loss: 1.069311
[2022-04-07 21:57:45 | train] - Train Epoch: [183] [768000/1281167 (60%)]	Loss: 0.679247
[2022-04-07 21:58:12 | train] - Train Epoch: [183] [780800/1281167 (61%)]	Loss: 0.846256
[2022-04-07 21:58:39 | train] - Train Epoch: [183] [793600/1281167 (62%)]	Loss: 0.731657
[2022-04-07 21:59:07 | train] - Train Epoch: [183] [806400/1281167 (63%)]	Loss: 1.004444
[2022-04-07 21:59:35 | train] - Train Epoch: [183] [819200/1281167 (64%)]	Loss: 0.608316
[2022-04-07 22:00:02 | train] - Train Epoch: [183] [832000/1281167 (65%)]	Loss: 1.083571
[2022-04-07 22:00:29 | train] - Train Epoch: [183] [844800/1281167 (66%)]	Loss: 0.758865
[2022-04-07 22:00:57 | train] - Train Epoch: [183] [857600/1281167 (67%)]	Loss: 1.122908
[2022-04-07 22:01:24 | train] - Train Epoch: [183] [870400/1281167 (68%)]	Loss: 0.644534
[2022-04-07 22:01:51 | train] - Train Epoch: [183] [883200/1281167 (69%)]	Loss: 0.824767
[2022-04-07 22:02:18 | train] - Train Epoch: [183] [896000/1281167 (70%)]	Loss: 0.851332
[2022-04-07 22:02:45 | train] - Train Epoch: [183] [908800/1281167 (71%)]	Loss: 0.822511
[2022-04-07 22:03:13 | train] - Train Epoch: [183] [921600/1281167 (72%)]	Loss: 0.420167
[2022-04-07 22:03:40 | train] - Train Epoch: [183] [934400/1281167 (73%)]	Loss: 0.789376
[2022-04-07 22:04:07 | train] - Train Epoch: [183] [947200/1281167 (74%)]	Loss: 0.810612
[2022-04-07 22:04:35 | train] - Train Epoch: [183] [960000/1281167 (75%)]	Loss: 0.758121
[2022-04-07 22:05:03 | train] - Train Epoch: [183] [972800/1281167 (76%)]	Loss: 0.677106
[2022-04-07 22:05:31 | train] - Train Epoch: [183] [985600/1281167 (77%)]	Loss: 0.551383
[2022-04-07 22:05:58 | train] - Train Epoch: [183] [998400/1281167 (78%)]	Loss: 0.888507
[2022-04-07 22:06:26 | train] - Train Epoch: [183] [1011200/1281167 (79%)]	Loss: 0.717482
[2022-04-07 22:06:53 | train] - Train Epoch: [183] [1024000/1281167 (80%)]	Loss: 0.907288
[2022-04-07 22:07:21 | train] - Train Epoch: [183] [1036800/1281167 (81%)]	Loss: 0.599234
[2022-04-07 22:07:49 | train] - Train Epoch: [183] [1049600/1281167 (82%)]	Loss: 0.800603
[2022-04-07 22:08:16 | train] - Train Epoch: [183] [1062400/1281167 (83%)]	Loss: 1.066817
[2022-04-07 22:08:44 | train] - Train Epoch: [183] [1075200/1281167 (84%)]	Loss: 0.575454
[2022-04-07 22:09:11 | train] - Train Epoch: [183] [1088000/1281167 (85%)]	Loss: 0.708644
[2022-04-07 22:09:39 | train] - Train Epoch: [183] [1100800/1281167 (86%)]	Loss: 0.747620
[2022-04-07 22:10:06 | train] - Train Epoch: [183] [1113600/1281167 (87%)]	Loss: 0.868772
[2022-04-07 22:10:33 | train] - Train Epoch: [183] [1126400/1281167 (88%)]	Loss: 0.713206
[2022-04-07 22:11:01 | train] - Train Epoch: [183] [1139200/1281167 (89%)]	Loss: 0.684094
[2022-04-07 22:11:29 | train] - Train Epoch: [183] [1152000/1281167 (90%)]	Loss: 0.643056
[2022-04-07 22:11:57 | train] - Train Epoch: [183] [1164800/1281167 (91%)]	Loss: 0.859782
[I 22:11:58.952 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:a75ab5a60b4642f79571db17fa547ce6
[2022-04-07 22:12:25 | train] - Train Epoch: [183] [1177600/1281167 (92%)]	Loss: 0.545609
[2022-04-07 22:12:52 | train] - Train Epoch: [183] [1190400/1281167 (93%)]	Loss: 0.794817
[2022-04-07 22:13:20 | train] - Train Epoch: [183] [1203200/1281167 (94%)]	Loss: 0.692673
[2022-04-07 22:13:48 | train] - Train Epoch: [183] [1216000/1281167 (95%)]	Loss: 0.981563
[2022-04-07 22:14:17 | train] - Train Epoch: [183] [1228800/1281167 (96%)]	Loss: 0.917386
[2022-04-07 22:14:45 | train] - Train Epoch: [183] [1241600/1281167 (97%)]	Loss: 0.602509
[2022-04-07 22:15:13 | train] - Train Epoch: [183] [1254400/1281167 (98%)]	Loss: 0.813120
[2022-04-07 22:15:41 | train] - Train Epoch: [183] [1267200/1281167 (99%)]	Loss: 0.778971
[2022-04-07 22:16:08 | train] - Train Epoch: [183] [1280000/1281167 (100%)]	Loss: 0.656046
[2022-04-07 22:16:11 | train] - Train Epoch: [183]	 Average Loss: 0.757842	 Total Acc : 81.4422	 Total Top5 Acc : 93.2652
[2022-04-07 22:16:11 | train] - -------183 epoch end-----------
========================================
-------183 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 22:18:11 | train] - 
Epoch [183] Test set: Average loss: 1.4541, Accuracy: 34845/50000 (69.6639%), Top-5 Accuracy: 88.7552%

[2022-04-07 22:18:11 | train] - save intermediate epoch [183] result


[2022-04-07 22:18:34 | train] - -------184 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 22:18:36 | train] - Train Epoch: [184] [0/1281167 (0%)]	Loss: 0.762650
[2022-04-07 22:19:03 | train] - Train Epoch: [184] [12800/1281167 (1%)]	Loss: 0.813537
[2022-04-07 22:19:30 | train] - Train Epoch: [184] [25600/1281167 (2%)]	Loss: 0.880723
[2022-04-07 22:19:58 | train] - Train Epoch: [184] [38400/1281167 (3%)]	Loss: 0.765925
[2022-04-07 22:20:25 | train] - Train Epoch: [184] [51200/1281167 (4%)]	Loss: 1.065033
[2022-04-07 22:20:52 | train] - Train Epoch: [184] [64000/1281167 (5%)]	Loss: 0.623831
[2022-04-07 22:21:20 | train] - Train Epoch: [184] [76800/1281167 (6%)]	Loss: 0.698065
[2022-04-07 22:21:47 | train] - Train Epoch: [184] [89600/1281167 (7%)]	Loss: 0.856658
[2022-04-07 22:22:14 | train] - Train Epoch: [184] [102400/1281167 (8%)]	Loss: 0.658187
[2022-04-07 22:22:41 | train] - Train Epoch: [184] [115200/1281167 (9%)]	Loss: 0.873594
[2022-04-07 22:23:08 | train] - Train Epoch: [184] [128000/1281167 (10%)]	Loss: 0.805593
[2022-04-07 22:23:35 | train] - Train Epoch: [184] [140800/1281167 (11%)]	Loss: 0.611072
[2022-04-07 22:24:02 | train] - Train Epoch: [184] [153600/1281167 (12%)]	Loss: 0.657152
[2022-04-07 22:24:29 | train] - Train Epoch: [184] [166400/1281167 (13%)]	Loss: 0.927746
[2022-04-07 22:24:57 | train] - Train Epoch: [184] [179200/1281167 (14%)]	Loss: 0.855080
[2022-04-07 22:25:25 | train] - Train Epoch: [184] [192000/1281167 (15%)]	Loss: 0.626604
[2022-04-07 22:25:52 | train] - Train Epoch: [184] [204800/1281167 (16%)]	Loss: 0.867795
[2022-04-07 22:26:19 | train] - Train Epoch: [184] [217600/1281167 (17%)]	Loss: 0.751612
[2022-04-07 22:26:47 | train] - Train Epoch: [184] [230400/1281167 (18%)]	Loss: 0.884235
[2022-04-07 22:27:14 | train] - Train Epoch: [184] [243200/1281167 (19%)]	Loss: 0.811823
[2022-04-07 22:27:41 | train] - Train Epoch: [184] [256000/1281167 (20%)]	Loss: 0.633347
[2022-04-07 22:28:08 | train] - Train Epoch: [184] [268800/1281167 (21%)]	Loss: 0.878213
[2022-04-07 22:28:35 | train] - Train Epoch: [184] [281600/1281167 (22%)]	Loss: 0.638454
[2022-04-07 22:29:03 | train] - Train Epoch: [184] [294400/1281167 (23%)]	Loss: 0.583416
[2022-04-07 22:29:31 | train] - Train Epoch: [184] [307200/1281167 (24%)]	Loss: 0.907241
[2022-04-07 22:29:58 | train] - Train Epoch: [184] [320000/1281167 (25%)]	Loss: 0.637536
[2022-04-07 22:30:26 | train] - Train Epoch: [184] [332800/1281167 (26%)]	Loss: 0.840548
[2022-04-07 22:30:53 | train] - Train Epoch: [184] [345600/1281167 (27%)]	Loss: 0.841877
[2022-04-07 22:31:21 | train] - Train Epoch: [184] [358400/1281167 (28%)]	Loss: 0.705100
[2022-04-07 22:31:49 | train] - Train Epoch: [184] [371200/1281167 (29%)]	Loss: 0.527718
[2022-04-07 22:32:16 | train] - Train Epoch: [184] [384000/1281167 (30%)]	Loss: 0.729669
[2022-04-07 22:32:43 | train] - Train Epoch: [184] [396800/1281167 (31%)]	Loss: 0.659215
[2022-04-07 22:33:10 | train] - Train Epoch: [184] [409600/1281167 (32%)]	Loss: 0.636789
[2022-04-07 22:33:38 | train] - Train Epoch: [184] [422400/1281167 (33%)]	Loss: 0.471677
[2022-04-07 22:34:06 | train] - Train Epoch: [184] [435200/1281167 (34%)]	Loss: 0.936687
[2022-04-07 22:34:33 | train] - Train Epoch: [184] [448000/1281167 (35%)]	Loss: 1.009026
[2022-04-07 22:35:01 | train] - Train Epoch: [184] [460800/1281167 (36%)]	Loss: 0.854947
[2022-04-07 22:35:29 | train] - Train Epoch: [184] [473600/1281167 (37%)]	Loss: 0.540095
[2022-04-07 22:35:56 | train] - Train Epoch: [184] [486400/1281167 (38%)]	Loss: 1.032248
[2022-04-07 22:36:25 | train] - Train Epoch: [184] [499200/1281167 (39%)]	Loss: 0.669004
[2022-04-07 22:36:52 | train] - Train Epoch: [184] [512000/1281167 (40%)]	Loss: 0.955247
[2022-04-07 22:37:20 | train] - Train Epoch: [184] [524800/1281167 (41%)]	Loss: 0.671453
[2022-04-07 22:37:46 | train] - Train Epoch: [184] [537600/1281167 (42%)]	Loss: 1.026091
[2022-04-07 22:38:14 | train] - Train Epoch: [184] [550400/1281167 (43%)]	Loss: 0.966733
[2022-04-07 22:38:42 | train] - Train Epoch: [184] [563200/1281167 (44%)]	Loss: 0.966772
[2022-04-07 22:39:11 | train] - Train Epoch: [184] [576000/1281167 (45%)]	Loss: 0.703625
[2022-04-07 22:39:39 | train] - Train Epoch: [184] [588800/1281167 (46%)]	Loss: 0.584569
[2022-04-07 22:40:07 | train] - Train Epoch: [184] [601600/1281167 (47%)]	Loss: 0.616458
[2022-04-07 22:40:35 | train] - Train Epoch: [184] [614400/1281167 (48%)]	Loss: 0.689790
[2022-04-07 22:41:03 | train] - Train Epoch: [184] [627200/1281167 (49%)]	Loss: 0.632292
[2022-04-07 22:41:31 | train] - Train Epoch: [184] [640000/1281167 (50%)]	Loss: 0.952352
[2022-04-07 22:41:58 | train] - Train Epoch: [184] [652800/1281167 (51%)]	Loss: 0.577261
[2022-04-07 22:42:26 | train] - Train Epoch: [184] [665600/1281167 (52%)]	Loss: 0.853157
[2022-04-07 22:42:54 | train] - Train Epoch: [184] [678400/1281167 (53%)]	Loss: 0.628944
[2022-04-07 22:43:21 | train] - Train Epoch: [184] [691200/1281167 (54%)]	Loss: 0.989955
[2022-04-07 22:43:49 | train] - Train Epoch: [184] [704000/1281167 (55%)]	Loss: 0.725371
[2022-04-07 22:44:17 | train] - Train Epoch: [184] [716800/1281167 (56%)]	Loss: 0.880211
[2022-04-07 22:44:45 | train] - Train Epoch: [184] [729600/1281167 (57%)]	Loss: 0.876669
[2022-04-07 22:45:14 | train] - Train Epoch: [184] [742400/1281167 (58%)]	Loss: 0.682562
[2022-04-07 22:45:42 | train] - Train Epoch: [184] [755200/1281167 (59%)]	Loss: 0.749948
[2022-04-07 22:46:09 | train] - Train Epoch: [184] [768000/1281167 (60%)]	Loss: 0.757856
[2022-04-07 22:46:37 | train] - Train Epoch: [184] [780800/1281167 (61%)]	Loss: 0.611009
[2022-04-07 22:47:05 | train] - Train Epoch: [184] [793600/1281167 (62%)]	Loss: 0.749404
[2022-04-07 22:47:33 | train] - Train Epoch: [184] [806400/1281167 (63%)]	Loss: 1.077475
[2022-04-07 22:48:01 | train] - Train Epoch: [184] [819200/1281167 (64%)]	Loss: 0.680871
[2022-04-07 22:48:28 | train] - Train Epoch: [184] [832000/1281167 (65%)]	Loss: 0.599010
[2022-04-07 22:48:55 | train] - Train Epoch: [184] [844800/1281167 (66%)]	Loss: 0.725841
[2022-04-07 22:49:23 | train] - Train Epoch: [184] [857600/1281167 (67%)]	Loss: 1.051811
[2022-04-07 22:49:51 | train] - Train Epoch: [184] [870400/1281167 (68%)]	Loss: 0.863156
[2022-04-07 22:50:19 | train] - Train Epoch: [184] [883200/1281167 (69%)]	Loss: 0.768870
[2022-04-07 22:50:46 | train] - Train Epoch: [184] [896000/1281167 (70%)]	Loss: 0.881595
[2022-04-07 22:51:14 | train] - Train Epoch: [184] [908800/1281167 (71%)]	Loss: 0.860447
[2022-04-07 22:51:41 | train] - Train Epoch: [184] [921600/1281167 (72%)]	Loss: 0.924804
[2022-04-07 22:52:09 | train] - Train Epoch: [184] [934400/1281167 (73%)]	Loss: 0.900616
[2022-04-07 22:52:36 | train] - Train Epoch: [184] [947200/1281167 (74%)]	Loss: 0.713569
[2022-04-07 22:53:04 | train] - Train Epoch: [184] [960000/1281167 (75%)]	Loss: 0.565739
[2022-04-07 22:53:32 | train] - Train Epoch: [184] [972800/1281167 (76%)]	Loss: 0.705061
[2022-04-07 22:54:00 | train] - Train Epoch: [184] [985600/1281167 (77%)]	Loss: 0.631234
[2022-04-07 22:54:27 | train] - Train Epoch: [184] [998400/1281167 (78%)]	Loss: 0.595091
[2022-04-07 22:54:54 | train] - Train Epoch: [184] [1011200/1281167 (79%)]	Loss: 0.532717
[2022-04-07 22:55:22 | train] - Train Epoch: [184] [1024000/1281167 (80%)]	Loss: 1.003514
[2022-04-07 22:55:50 | train] - Train Epoch: [184] [1036800/1281167 (81%)]	Loss: 0.868437
[2022-04-07 22:56:18 | train] - Train Epoch: [184] [1049600/1281167 (82%)]	Loss: 0.710004
[2022-04-07 22:56:46 | train] - Train Epoch: [184] [1062400/1281167 (83%)]	Loss: 0.707459
[2022-04-07 22:57:14 | train] - Train Epoch: [184] [1075200/1281167 (84%)]	Loss: 0.741972
[2022-04-07 22:57:43 | train] - Train Epoch: [184] [1088000/1281167 (85%)]	Loss: 1.069424
[2022-04-07 22:58:11 | train] - Train Epoch: [184] [1100800/1281167 (86%)]	Loss: 0.699194
[2022-04-07 22:58:40 | train] - Train Epoch: [184] [1113600/1281167 (87%)]	Loss: 1.065338
[2022-04-07 22:59:08 | train] - Train Epoch: [184] [1126400/1281167 (88%)]	Loss: 0.666194
[2022-04-07 22:59:36 | train] - Train Epoch: [184] [1139200/1281167 (89%)]	Loss: 0.796264
[2022-04-07 23:00:05 | train] - Train Epoch: [184] [1152000/1281167 (90%)]	Loss: 0.989871
[2022-04-07 23:00:33 | train] - Train Epoch: [184] [1164800/1281167 (91%)]	Loss: 0.780437
[2022-04-07 23:01:02 | train] - Train Epoch: [184] [1177600/1281167 (92%)]	Loss: 0.658460
[2022-04-07 23:01:31 | train] - Train Epoch: [184] [1190400/1281167 (93%)]	Loss: 0.855614
[2022-04-07 23:01:59 | train] - Train Epoch: [184] [1203200/1281167 (94%)]	Loss: 0.600071
[2022-04-07 23:02:28 | train] - Train Epoch: [184] [1216000/1281167 (95%)]	Loss: 0.842411
[2022-04-07 23:02:57 | train] - Train Epoch: [184] [1228800/1281167 (96%)]	Loss: 0.702697
[2022-04-07 23:03:26 | train] - Train Epoch: [184] [1241600/1281167 (97%)]	Loss: 0.819257
[2022-04-07 23:03:54 | train] - Train Epoch: [184] [1254400/1281167 (98%)]	Loss: 0.772194
[2022-04-07 23:04:23 | train] - Train Epoch: [184] [1267200/1281167 (99%)]	Loss: 0.761187
[2022-04-07 23:04:51 | train] - Train Epoch: [184] [1280000/1281167 (100%)]	Loss: 0.583245
[2022-04-07 23:04:53 | train] - Train Epoch: [184]	 Average Loss: 0.755653	 Total Acc : 81.5541	 Total Top5 Acc : 93.2703
[2022-04-07 23:04:53 | train] - -------184 epoch end-----------
========================================
-------184 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 23:06:49 | train] - 
Epoch [184] Test set: Average loss: 1.4569, Accuracy: 34914/50000 (69.8006%), Top-5 Accuracy: 88.8251%

[2022-04-07 23:06:49 | train] - save intermediate epoch [184] result


[2022-04-07 23:07:13 | train] - -------185 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 23:07:14 | train] - Train Epoch: [185] [0/1281167 (0%)]	Loss: 0.701362
[2022-04-07 23:07:41 | train] - Train Epoch: [185] [12800/1281167 (1%)]	Loss: 0.650129
[2022-04-07 23:08:09 | train] - Train Epoch: [185] [25600/1281167 (2%)]	Loss: 0.618805
[2022-04-07 23:08:37 | train] - Train Epoch: [185] [38400/1281167 (3%)]	Loss: 0.687889
[2022-04-07 23:09:05 | train] - Train Epoch: [185] [51200/1281167 (4%)]	Loss: 0.553250
[2022-04-07 23:09:32 | train] - Train Epoch: [185] [64000/1281167 (5%)]	Loss: 0.664153
[2022-04-07 23:09:59 | train] - Train Epoch: [185] [76800/1281167 (6%)]	Loss: 0.814057
[2022-04-07 23:10:27 | train] - Train Epoch: [185] [89600/1281167 (7%)]	Loss: 1.092127
[2022-04-07 23:10:55 | train] - Train Epoch: [185] [102400/1281167 (8%)]	Loss: 0.610414
[2022-04-07 23:11:22 | train] - Train Epoch: [185] [115200/1281167 (9%)]	Loss: 0.629362
[2022-04-07 23:11:50 | train] - Train Epoch: [185] [128000/1281167 (10%)]	Loss: 0.661901
[2022-04-07 23:12:17 | train] - Train Epoch: [185] [140800/1281167 (11%)]	Loss: 0.785475
[2022-04-07 23:12:45 | train] - Train Epoch: [185] [153600/1281167 (12%)]	Loss: 0.664302
[2022-04-07 23:13:12 | train] - Train Epoch: [185] [166400/1281167 (13%)]	Loss: 1.258281
[2022-04-07 23:13:40 | train] - Train Epoch: [185] [179200/1281167 (14%)]	Loss: 0.798442
[2022-04-07 23:14:06 | train] - Train Epoch: [185] [192000/1281167 (15%)]	Loss: 0.716704
[2022-04-07 23:14:33 | train] - Train Epoch: [185] [204800/1281167 (16%)]	Loss: 0.705662
[2022-04-07 23:15:01 | train] - Train Epoch: [185] [217600/1281167 (17%)]	Loss: 0.667873
[2022-04-07 23:15:28 | train] - Train Epoch: [185] [230400/1281167 (18%)]	Loss: 0.664730
[2022-04-07 23:15:55 | train] - Train Epoch: [185] [243200/1281167 (19%)]	Loss: 0.657026
[2022-04-07 23:16:24 | train] - Train Epoch: [185] [256000/1281167 (20%)]	Loss: 0.808910
[2022-04-07 23:16:51 | train] - Train Epoch: [185] [268800/1281167 (21%)]	Loss: 1.140664
[2022-04-07 23:17:19 | train] - Train Epoch: [185] [281600/1281167 (22%)]	Loss: 0.961549
[2022-04-07 23:17:46 | train] - Train Epoch: [185] [294400/1281167 (23%)]	Loss: 0.587048
[2022-04-07 23:18:14 | train] - Train Epoch: [185] [307200/1281167 (24%)]	Loss: 1.031745
[2022-04-07 23:18:41 | train] - Train Epoch: [185] [320000/1281167 (25%)]	Loss: 0.473246
[2022-04-07 23:19:10 | train] - Train Epoch: [185] [332800/1281167 (26%)]	Loss: 0.825228
[2022-04-07 23:19:36 | train] - Train Epoch: [185] [345600/1281167 (27%)]	Loss: 0.720775
[2022-04-07 23:20:04 | train] - Train Epoch: [185] [358400/1281167 (28%)]	Loss: 0.653534
[2022-04-07 23:20:30 | train] - Train Epoch: [185] [371200/1281167 (29%)]	Loss: 0.889706
[2022-04-07 23:20:58 | train] - Train Epoch: [185] [384000/1281167 (30%)]	Loss: 1.061373
[2022-04-07 23:21:26 | train] - Train Epoch: [185] [396800/1281167 (31%)]	Loss: 0.572977
[2022-04-07 23:21:53 | train] - Train Epoch: [185] [409600/1281167 (32%)]	Loss: 0.964116
[2022-04-07 23:22:20 | train] - Train Epoch: [185] [422400/1281167 (33%)]	Loss: 0.843753
[2022-04-07 23:22:47 | train] - Train Epoch: [185] [435200/1281167 (34%)]	Loss: 0.520278
[2022-04-07 23:23:15 | train] - Train Epoch: [185] [448000/1281167 (35%)]	Loss: 0.592383
[2022-04-07 23:23:41 | train] - Train Epoch: [185] [460800/1281167 (36%)]	Loss: 0.756581
[2022-04-07 23:24:09 | train] - Train Epoch: [185] [473600/1281167 (37%)]	Loss: 0.877629
[2022-04-07 23:24:36 | train] - Train Epoch: [185] [486400/1281167 (38%)]	Loss: 0.567432
[2022-04-07 23:25:03 | train] - Train Epoch: [185] [499200/1281167 (39%)]	Loss: 0.623629
[2022-04-07 23:25:31 | train] - Train Epoch: [185] [512000/1281167 (40%)]	Loss: 0.734700
[2022-04-07 23:25:58 | train] - Train Epoch: [185] [524800/1281167 (41%)]	Loss: 0.775576
[2022-04-07 23:26:25 | train] - Train Epoch: [185] [537600/1281167 (42%)]	Loss: 0.608061
[2022-04-07 23:26:54 | train] - Train Epoch: [185] [550400/1281167 (43%)]	Loss: 0.632060
[2022-04-07 23:27:22 | train] - Train Epoch: [185] [563200/1281167 (44%)]	Loss: 0.886980
[2022-04-07 23:27:49 | train] - Train Epoch: [185] [576000/1281167 (45%)]	Loss: 0.590449
[2022-04-07 23:28:17 | train] - Train Epoch: [185] [588800/1281167 (46%)]	Loss: 0.552667
[2022-04-07 23:28:44 | train] - Train Epoch: [185] [601600/1281167 (47%)]	Loss: 1.005446
[2022-04-07 23:29:11 | train] - Train Epoch: [185] [614400/1281167 (48%)]	Loss: 0.831065
[2022-04-07 23:29:38 | train] - Train Epoch: [185] [627200/1281167 (49%)]	Loss: 0.650091
[2022-04-07 23:30:06 | train] - Train Epoch: [185] [640000/1281167 (50%)]	Loss: 0.659921
[2022-04-07 23:30:33 | train] - Train Epoch: [185] [652800/1281167 (51%)]	Loss: 0.535025
[2022-04-07 23:31:00 | train] - Train Epoch: [185] [665600/1281167 (52%)]	Loss: 1.020695
[2022-04-07 23:31:28 | train] - Train Epoch: [185] [678400/1281167 (53%)]	Loss: 0.716188
[2022-04-07 23:31:56 | train] - Train Epoch: [185] [691200/1281167 (54%)]	Loss: 0.709641
[2022-04-07 23:32:23 | train] - Train Epoch: [185] [704000/1281167 (55%)]	Loss: 0.923646
[2022-04-07 23:32:51 | train] - Train Epoch: [185] [716800/1281167 (56%)]	Loss: 0.729057
[2022-04-07 23:33:18 | train] - Train Epoch: [185] [729600/1281167 (57%)]	Loss: 0.700205
[2022-04-07 23:33:45 | train] - Train Epoch: [185] [742400/1281167 (58%)]	Loss: 0.776409
[2022-04-07 23:34:13 | train] - Train Epoch: [185] [755200/1281167 (59%)]	Loss: 0.872656
[2022-04-07 23:34:41 | train] - Train Epoch: [185] [768000/1281167 (60%)]	Loss: 0.653084
[2022-04-07 23:35:09 | train] - Train Epoch: [185] [780800/1281167 (61%)]	Loss: 1.385433
[2022-04-07 23:35:37 | train] - Train Epoch: [185] [793600/1281167 (62%)]	Loss: 0.949444
[2022-04-07 23:36:04 | train] - Train Epoch: [185] [806400/1281167 (63%)]	Loss: 0.529241
[2022-04-07 23:36:33 | train] - Train Epoch: [185] [819200/1281167 (64%)]	Loss: 0.886818
[2022-04-07 23:37:00 | train] - Train Epoch: [185] [832000/1281167 (65%)]	Loss: 0.859472
[2022-04-07 23:37:28 | train] - Train Epoch: [185] [844800/1281167 (66%)]	Loss: 0.510151
[2022-04-07 23:37:56 | train] - Train Epoch: [185] [857600/1281167 (67%)]	Loss: 0.705554
[2022-04-07 23:38:24 | train] - Train Epoch: [185] [870400/1281167 (68%)]	Loss: 0.812557
[2022-04-07 23:38:52 | train] - Train Epoch: [185] [883200/1281167 (69%)]	Loss: 0.753122
[2022-04-07 23:39:20 | train] - Train Epoch: [185] [896000/1281167 (70%)]	Loss: 0.562478
[2022-04-07 23:39:48 | train] - Train Epoch: [185] [908800/1281167 (71%)]	Loss: 0.629264
[2022-04-07 23:40:16 | train] - Train Epoch: [185] [921600/1281167 (72%)]	Loss: 1.039541
[2022-04-07 23:40:44 | train] - Train Epoch: [185] [934400/1281167 (73%)]	Loss: 0.987775
[2022-04-07 23:41:12 | train] - Train Epoch: [185] [947200/1281167 (74%)]	Loss: 0.540269
[2022-04-07 23:41:40 | train] - Train Epoch: [185] [960000/1281167 (75%)]	Loss: 0.814806
[2022-04-07 23:42:08 | train] - Train Epoch: [185] [972800/1281167 (76%)]	Loss: 0.965858
[2022-04-07 23:42:37 | train] - Train Epoch: [185] [985600/1281167 (77%)]	Loss: 0.888231
[2022-04-07 23:43:04 | train] - Train Epoch: [185] [998400/1281167 (78%)]	Loss: 0.812946
[2022-04-07 23:43:32 | train] - Train Epoch: [185] [1011200/1281167 (79%)]	Loss: 0.468347
[2022-04-07 23:44:01 | train] - Train Epoch: [185] [1024000/1281167 (80%)]	Loss: 0.790235
[2022-04-07 23:44:29 | train] - Train Epoch: [185] [1036800/1281167 (81%)]	Loss: 0.985627
[2022-04-07 23:44:57 | train] - Train Epoch: [185] [1049600/1281167 (82%)]	Loss: 0.770818
[2022-04-07 23:45:25 | train] - Train Epoch: [185] [1062400/1281167 (83%)]	Loss: 0.860955
[2022-04-07 23:45:54 | train] - Train Epoch: [185] [1075200/1281167 (84%)]	Loss: 0.607325
[2022-04-07 23:46:22 | train] - Train Epoch: [185] [1088000/1281167 (85%)]	Loss: 0.598313
[2022-04-07 23:46:50 | train] - Train Epoch: [185] [1100800/1281167 (86%)]	Loss: 0.373588
[2022-04-07 23:47:18 | train] - Train Epoch: [185] [1113600/1281167 (87%)]	Loss: 0.745700
[2022-04-07 23:47:47 | train] - Train Epoch: [185] [1126400/1281167 (88%)]	Loss: 0.614929
[2022-04-07 23:48:15 | train] - Train Epoch: [185] [1139200/1281167 (89%)]	Loss: 0.766886
[2022-04-07 23:48:43 | train] - Train Epoch: [185] [1152000/1281167 (90%)]	Loss: 0.902853
[2022-04-07 23:49:12 | train] - Train Epoch: [185] [1164800/1281167 (91%)]	Loss: 0.979869
[2022-04-07 23:49:39 | train] - Train Epoch: [185] [1177600/1281167 (92%)]	Loss: 0.925906
[2022-04-07 23:50:07 | train] - Train Epoch: [185] [1190400/1281167 (93%)]	Loss: 0.727064
[2022-04-07 23:50:35 | train] - Train Epoch: [185] [1203200/1281167 (94%)]	Loss: 0.736740
[2022-04-07 23:51:04 | train] - Train Epoch: [185] [1216000/1281167 (95%)]	Loss: 0.859643
[2022-04-07 23:51:32 | train] - Train Epoch: [185] [1228800/1281167 (96%)]	Loss: 0.875998
[2022-04-07 23:52:01 | train] - Train Epoch: [185] [1241600/1281167 (97%)]	Loss: 0.825003
[2022-04-07 23:52:29 | train] - Train Epoch: [185] [1254400/1281167 (98%)]	Loss: 0.656345
[2022-04-07 23:52:58 | train] - Train Epoch: [185] [1267200/1281167 (99%)]	Loss: 0.581203
[2022-04-07 23:53:27 | train] - Train Epoch: [185] [1280000/1281167 (100%)]	Loss: 0.725965
[2022-04-07 23:53:30 | train] - Train Epoch: [185]	 Average Loss: 0.756769	 Total Acc : 81.5266	 Total Top5 Acc : 93.2508
[2022-04-07 23:53:30 | train] - -------185 epoch end-----------
========================================
-------185 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-07 23:55:26 | train] - 
Epoch [185] Test set: Average loss: 1.4574, Accuracy: 34945/50000 (69.8637%), Top-5 Accuracy: 88.7612%

[2022-04-07 23:55:26 | train] - save intermediate epoch [185] result


[2022-04-07 23:55:50 | train] - -------186 epoch start-----------
========================================
----- test end -------------------------


[2022-04-07 23:55:52 | train] - Train Epoch: [186] [0/1281167 (0%)]	Loss: 0.684763
[2022-04-07 23:56:18 | train] - Train Epoch: [186] [12800/1281167 (1%)]	Loss: 0.651886
[2022-04-07 23:56:45 | train] - Train Epoch: [186] [25600/1281167 (2%)]	Loss: 0.673144
[2022-04-07 23:57:11 | train] - Train Epoch: [186] [38400/1281167 (3%)]	Loss: 0.856652
[2022-04-07 23:57:37 | train] - Train Epoch: [186] [51200/1281167 (4%)]	Loss: 0.610185
[2022-04-07 23:58:04 | train] - Train Epoch: [186] [64000/1281167 (5%)]	Loss: 0.603858
[2022-04-07 23:58:30 | train] - Train Epoch: [186] [76800/1281167 (6%)]	Loss: 0.625230
[2022-04-07 23:58:56 | train] - Train Epoch: [186] [89600/1281167 (7%)]	Loss: 0.718360
[2022-04-07 23:59:23 | train] - Train Epoch: [186] [102400/1281167 (8%)]	Loss: 0.979315
[2022-04-07 23:59:49 | train] - Train Epoch: [186] [115200/1281167 (9%)]	Loss: 0.894681
[2022-04-08 00:00:14 | train] - Train Epoch: [186] [128000/1281167 (10%)]	Loss: 0.688658
[2022-04-08 00:00:40 | train] - Train Epoch: [186] [140800/1281167 (11%)]	Loss: 0.830141
[2022-04-08 00:01:07 | train] - Train Epoch: [186] [153600/1281167 (12%)]	Loss: 0.762481
[2022-04-08 00:01:34 | train] - Train Epoch: [186] [166400/1281167 (13%)]	Loss: 0.785555
[2022-04-08 00:02:00 | train] - Train Epoch: [186] [179200/1281167 (14%)]	Loss: 0.760644
[2022-04-08 00:02:26 | train] - Train Epoch: [186] [192000/1281167 (15%)]	Loss: 0.720905
[2022-04-08 00:02:51 | train] - Train Epoch: [186] [204800/1281167 (16%)]	Loss: 0.492439
[2022-04-08 00:03:17 | train] - Train Epoch: [186] [217600/1281167 (17%)]	Loss: 1.195499
[2022-04-08 00:03:44 | train] - Train Epoch: [186] [230400/1281167 (18%)]	Loss: 0.613919
[2022-04-08 00:04:10 | train] - Train Epoch: [186] [243200/1281167 (19%)]	Loss: 0.889021
[2022-04-08 00:04:35 | train] - Train Epoch: [186] [256000/1281167 (20%)]	Loss: 0.671527
[2022-04-08 00:05:02 | train] - Train Epoch: [186] [268800/1281167 (21%)]	Loss: 0.970705
[2022-04-08 00:05:28 | train] - Train Epoch: [186] [281600/1281167 (22%)]	Loss: 0.768909
[2022-04-08 00:05:55 | train] - Train Epoch: [186] [294400/1281167 (23%)]	Loss: 0.806558
[2022-04-08 00:06:21 | train] - Train Epoch: [186] [307200/1281167 (24%)]	Loss: 0.819239
[2022-04-08 00:06:47 | train] - Train Epoch: [186] [320000/1281167 (25%)]	Loss: 1.091423
[2022-04-08 00:07:14 | train] - Train Epoch: [186] [332800/1281167 (26%)]	Loss: 0.641554
[2022-04-08 00:07:40 | train] - Train Epoch: [186] [345600/1281167 (27%)]	Loss: 0.818846
[2022-04-08 00:08:07 | train] - Train Epoch: [186] [358400/1281167 (28%)]	Loss: 0.671091
[2022-04-08 00:08:34 | train] - Train Epoch: [186] [371200/1281167 (29%)]	Loss: 0.826175
[2022-04-08 00:09:00 | train] - Train Epoch: [186] [384000/1281167 (30%)]	Loss: 0.654213
[2022-04-08 00:09:27 | train] - Train Epoch: [186] [396800/1281167 (31%)]	Loss: 0.762784
[2022-04-08 00:09:53 | train] - Train Epoch: [186] [409600/1281167 (32%)]	Loss: 0.791462
[2022-04-08 00:10:19 | train] - Train Epoch: [186] [422400/1281167 (33%)]	Loss: 0.640602
[2022-04-08 00:10:46 | train] - Train Epoch: [186] [435200/1281167 (34%)]	Loss: 0.668557
[2022-04-08 00:11:11 | train] - Train Epoch: [186] [448000/1281167 (35%)]	Loss: 1.105728
[2022-04-08 00:11:38 | train] - Train Epoch: [186] [460800/1281167 (36%)]	Loss: 1.005232
[2022-04-08 00:12:05 | train] - Train Epoch: [186] [473600/1281167 (37%)]	Loss: 0.768292
[2022-04-08 00:12:32 | train] - Train Epoch: [186] [486400/1281167 (38%)]	Loss: 1.141319
[2022-04-08 00:12:58 | train] - Train Epoch: [186] [499200/1281167 (39%)]	Loss: 0.674266
[2022-04-08 00:13:24 | train] - Train Epoch: [186] [512000/1281167 (40%)]	Loss: 0.873046
[2022-04-08 00:13:51 | train] - Train Epoch: [186] [524800/1281167 (41%)]	Loss: 0.634462
[2022-04-08 00:14:17 | train] - Train Epoch: [186] [537600/1281167 (42%)]	Loss: 0.775360
[2022-04-08 00:14:44 | train] - Train Epoch: [186] [550400/1281167 (43%)]	Loss: 0.796427
[2022-04-08 00:15:10 | train] - Train Epoch: [186] [563200/1281167 (44%)]	Loss: 0.732429
[2022-04-08 00:15:37 | train] - Train Epoch: [186] [576000/1281167 (45%)]	Loss: 0.668943
[2022-04-08 00:16:03 | train] - Train Epoch: [186] [588800/1281167 (46%)]	Loss: 1.121197
[2022-04-08 00:16:30 | train] - Train Epoch: [186] [601600/1281167 (47%)]	Loss: 0.562524
[2022-04-08 00:16:56 | train] - Train Epoch: [186] [614400/1281167 (48%)]	Loss: 0.781777
[2022-04-08 00:17:23 | train] - Train Epoch: [186] [627200/1281167 (49%)]	Loss: 0.756614
[2022-04-08 00:17:49 | train] - Train Epoch: [186] [640000/1281167 (50%)]	Loss: 0.771863
[2022-04-08 00:18:16 | train] - Train Epoch: [186] [652800/1281167 (51%)]	Loss: 0.990347
[2022-04-08 00:18:42 | train] - Train Epoch: [186] [665600/1281167 (52%)]	Loss: 0.860296
[2022-04-08 00:19:08 | train] - Train Epoch: [186] [678400/1281167 (53%)]	Loss: 0.731866
[2022-04-08 00:19:35 | train] - Train Epoch: [186] [691200/1281167 (54%)]	Loss: 0.724479
[2022-04-08 00:20:01 | train] - Train Epoch: [186] [704000/1281167 (55%)]	Loss: 0.599224
[2022-04-08 00:20:27 | train] - Train Epoch: [186] [716800/1281167 (56%)]	Loss: 0.869681
[2022-04-08 00:20:54 | train] - Train Epoch: [186] [729600/1281167 (57%)]	Loss: 0.744037
[2022-04-08 00:21:21 | train] - Train Epoch: [186] [742400/1281167 (58%)]	Loss: 0.675030
[2022-04-08 00:21:48 | train] - Train Epoch: [186] [755200/1281167 (59%)]	Loss: 0.756167
[2022-04-08 00:22:14 | train] - Train Epoch: [186] [768000/1281167 (60%)]	Loss: 0.653061
[2022-04-08 00:22:41 | train] - Train Epoch: [186] [780800/1281167 (61%)]	Loss: 0.662444
[2022-04-08 00:23:08 | train] - Train Epoch: [186] [793600/1281167 (62%)]	Loss: 0.725173
[2022-04-08 00:23:35 | train] - Train Epoch: [186] [806400/1281167 (63%)]	Loss: 0.744551
[2022-04-08 00:24:01 | train] - Train Epoch: [186] [819200/1281167 (64%)]	Loss: 0.712868
[2022-04-08 00:24:28 | train] - Train Epoch: [186] [832000/1281167 (65%)]	Loss: 0.672380
[2022-04-08 00:24:55 | train] - Train Epoch: [186] [844800/1281167 (66%)]	Loss: 0.622321
[2022-04-08 00:25:22 | train] - Train Epoch: [186] [857600/1281167 (67%)]	Loss: 0.674617
[2022-04-08 00:25:49 | train] - Train Epoch: [186] [870400/1281167 (68%)]	Loss: 0.846900
[2022-04-08 00:26:15 | train] - Train Epoch: [186] [883200/1281167 (69%)]	Loss: 0.844757
[2022-04-08 00:26:41 | train] - Train Epoch: [186] [896000/1281167 (70%)]	Loss: 0.781754
[2022-04-08 00:27:08 | train] - Train Epoch: [186] [908800/1281167 (71%)]	Loss: 0.699487
[2022-04-08 00:27:35 | train] - Train Epoch: [186] [921600/1281167 (72%)]	Loss: 0.786408
[2022-04-08 00:28:02 | train] - Train Epoch: [186] [934400/1281167 (73%)]	Loss: 0.917906
[2022-04-08 00:28:28 | train] - Train Epoch: [186] [947200/1281167 (74%)]	Loss: 0.603803
[2022-04-08 00:28:55 | train] - Train Epoch: [186] [960000/1281167 (75%)]	Loss: 0.516315
[2022-04-08 00:29:23 | train] - Train Epoch: [186] [972800/1281167 (76%)]	Loss: 0.697182
[2022-04-08 00:29:49 | train] - Train Epoch: [186] [985600/1281167 (77%)]	Loss: 0.694368
[2022-04-08 00:30:16 | train] - Train Epoch: [186] [998400/1281167 (78%)]	Loss: 0.783433
[2022-04-08 00:30:43 | train] - Train Epoch: [186] [1011200/1281167 (79%)]	Loss: 0.753608
[2022-04-08 00:31:09 | train] - Train Epoch: [186] [1024000/1281167 (80%)]	Loss: 0.738301
[2022-04-08 00:31:36 | train] - Train Epoch: [186] [1036800/1281167 (81%)]	Loss: 0.615682
[2022-04-08 00:32:02 | train] - Train Epoch: [186] [1049600/1281167 (82%)]	Loss: 0.598580
[2022-04-08 00:32:29 | train] - Train Epoch: [186] [1062400/1281167 (83%)]	Loss: 0.803618
[2022-04-08 00:32:56 | train] - Train Epoch: [186] [1075200/1281167 (84%)]	Loss: 0.699290
[2022-04-08 00:33:24 | train] - Train Epoch: [186] [1088000/1281167 (85%)]	Loss: 0.558148
[2022-04-08 00:33:51 | train] - Train Epoch: [186] [1100800/1281167 (86%)]	Loss: 0.771772
[2022-04-08 00:34:19 | train] - Train Epoch: [186] [1113600/1281167 (87%)]	Loss: 1.037035
[2022-04-08 00:34:46 | train] - Train Epoch: [186] [1126400/1281167 (88%)]	Loss: 0.698618
[2022-04-08 00:35:14 | train] - Train Epoch: [186] [1139200/1281167 (89%)]	Loss: 0.755154
[2022-04-08 00:35:41 | train] - Train Epoch: [186] [1152000/1281167 (90%)]	Loss: 0.777320
[2022-04-08 00:36:08 | train] - Train Epoch: [186] [1164800/1281167 (91%)]	Loss: 0.654288
[2022-04-08 00:36:35 | train] - Train Epoch: [186] [1177600/1281167 (92%)]	Loss: 1.165027
[2022-04-08 00:37:02 | train] - Train Epoch: [186] [1190400/1281167 (93%)]	Loss: 0.644348
[2022-04-08 00:37:30 | train] - Train Epoch: [186] [1203200/1281167 (94%)]	Loss: 0.870942
[2022-04-08 00:37:57 | train] - Train Epoch: [186] [1216000/1281167 (95%)]	Loss: 0.742916
[2022-04-08 00:38:25 | train] - Train Epoch: [186] [1228800/1281167 (96%)]	Loss: 0.672971
[2022-04-08 00:38:53 | train] - Train Epoch: [186] [1241600/1281167 (97%)]	Loss: 0.670820
[2022-04-08 00:39:20 | train] - Train Epoch: [186] [1254400/1281167 (98%)]	Loss: 0.478866
[2022-04-08 00:39:47 | train] - Train Epoch: [186] [1267200/1281167 (99%)]	Loss: 0.706012
[2022-04-08 00:40:14 | train] - Train Epoch: [186] [1280000/1281167 (100%)]	Loss: 0.622720
[2022-04-08 00:40:16 | train] - Train Epoch: [186]	 Average Loss: 0.756011	 Total Acc : 81.5263	 Total Top5 Acc : 93.2789
[2022-04-08 00:40:16 | train] - -------186 epoch end-----------
========================================
-------186 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 00:42:02 | train] - 
Epoch [186] Test set: Average loss: 1.4615, Accuracy: 34977/50000 (69.9253%), Top-5 Accuracy: 88.8799%

[2022-04-08 00:42:02 | train] - save intermediate epoch [186] result


[2022-04-08 00:42:26 | train] - logging best performance 186 epoch
[2022-04-08 00:42:27 | train] - -------187 epoch start-----------
========================================
----- test end -------------------------


logging best performance 186 epoch
[2022-04-08 00:42:29 | train] - Train Epoch: [187] [0/1281167 (0%)]	Loss: 0.770577
[2022-04-08 00:42:56 | train] - Train Epoch: [187] [12800/1281167 (1%)]	Loss: 0.924119
[2022-04-08 00:43:22 | train] - Train Epoch: [187] [25600/1281167 (2%)]	Loss: 0.754147
[2022-04-08 00:43:49 | train] - Train Epoch: [187] [38400/1281167 (3%)]	Loss: 0.650356
[2022-04-08 00:44:17 | train] - Train Epoch: [187] [51200/1281167 (4%)]	Loss: 0.638068
[2022-04-08 00:44:44 | train] - Train Epoch: [187] [64000/1281167 (5%)]	Loss: 0.618123
[2022-04-08 00:45:11 | train] - Train Epoch: [187] [76800/1281167 (6%)]	Loss: 0.672264
[2022-04-08 00:45:39 | train] - Train Epoch: [187] [89600/1281167 (7%)]	Loss: 0.727785
[2022-04-08 00:46:06 | train] - Train Epoch: [187] [102400/1281167 (8%)]	Loss: 0.500670
[2022-04-08 00:46:33 | train] - Train Epoch: [187] [115200/1281167 (9%)]	Loss: 0.864826
[2022-04-08 00:47:01 | train] - Train Epoch: [187] [128000/1281167 (10%)]	Loss: 0.679524
[2022-04-08 00:47:28 | train] - Train Epoch: [187] [140800/1281167 (11%)]	Loss: 0.838003
[2022-04-08 00:47:56 | train] - Train Epoch: [187] [153600/1281167 (12%)]	Loss: 0.871349
[2022-04-08 00:48:24 | train] - Train Epoch: [187] [166400/1281167 (13%)]	Loss: 0.805625
[2022-04-08 00:48:52 | train] - Train Epoch: [187] [179200/1281167 (14%)]	Loss: 0.719233
[2022-04-08 00:49:20 | train] - Train Epoch: [187] [192000/1281167 (15%)]	Loss: 0.786363
[2022-04-08 00:49:48 | train] - Train Epoch: [187] [204800/1281167 (16%)]	Loss: 0.714935
[2022-04-08 00:50:15 | train] - Train Epoch: [187] [217600/1281167 (17%)]	Loss: 0.701397
[2022-04-08 00:50:42 | train] - Train Epoch: [187] [230400/1281167 (18%)]	Loss: 0.488830
[2022-04-08 00:51:10 | train] - Train Epoch: [187] [243200/1281167 (19%)]	Loss: 0.826433
[2022-04-08 00:51:36 | train] - Train Epoch: [187] [256000/1281167 (20%)]	Loss: 0.817527
[2022-04-08 00:52:04 | train] - Train Epoch: [187] [268800/1281167 (21%)]	Loss: 0.795991
[2022-04-08 00:52:31 | train] - Train Epoch: [187] [281600/1281167 (22%)]	Loss: 0.893861
[2022-04-08 00:52:59 | train] - Train Epoch: [187] [294400/1281167 (23%)]	Loss: 0.721167
[2022-04-08 00:53:27 | train] - Train Epoch: [187] [307200/1281167 (24%)]	Loss: 0.776879
[2022-04-08 00:53:54 | train] - Train Epoch: [187] [320000/1281167 (25%)]	Loss: 0.499930
[2022-04-08 00:54:21 | train] - Train Epoch: [187] [332800/1281167 (26%)]	Loss: 0.823512
[2022-04-08 00:54:48 | train] - Train Epoch: [187] [345600/1281167 (27%)]	Loss: 1.018003
[2022-04-08 00:55:16 | train] - Train Epoch: [187] [358400/1281167 (28%)]	Loss: 0.767644
[2022-04-08 00:55:44 | train] - Train Epoch: [187] [371200/1281167 (29%)]	Loss: 0.565129
[2022-04-08 00:56:12 | train] - Train Epoch: [187] [384000/1281167 (30%)]	Loss: 0.831977
[2022-04-08 00:56:40 | train] - Train Epoch: [187] [396800/1281167 (31%)]	Loss: 0.568923
[2022-04-08 00:57:07 | train] - Train Epoch: [187] [409600/1281167 (32%)]	Loss: 0.743606
[2022-04-08 00:57:34 | train] - Train Epoch: [187] [422400/1281167 (33%)]	Loss: 0.761454
[2022-04-08 00:58:01 | train] - Train Epoch: [187] [435200/1281167 (34%)]	Loss: 0.640615
[2022-04-08 00:58:29 | train] - Train Epoch: [187] [448000/1281167 (35%)]	Loss: 0.962395
[2022-04-08 00:58:57 | train] - Train Epoch: [187] [460800/1281167 (36%)]	Loss: 0.678353
[2022-04-08 00:59:24 | train] - Train Epoch: [187] [473600/1281167 (37%)]	Loss: 1.159687
[2022-04-08 00:59:51 | train] - Train Epoch: [187] [486400/1281167 (38%)]	Loss: 0.690588
[2022-04-08 01:00:19 | train] - Train Epoch: [187] [499200/1281167 (39%)]	Loss: 0.755082
[2022-04-08 01:00:47 | train] - Train Epoch: [187] [512000/1281167 (40%)]	Loss: 0.862160
[2022-04-08 01:01:14 | train] - Train Epoch: [187] [524800/1281167 (41%)]	Loss: 0.754899
[2022-04-08 01:01:41 | train] - Train Epoch: [187] [537600/1281167 (42%)]	Loss: 0.750339
[2022-04-08 01:02:08 | train] - Train Epoch: [187] [550400/1281167 (43%)]	Loss: 0.641416
[2022-04-08 01:02:35 | train] - Train Epoch: [187] [563200/1281167 (44%)]	Loss: 0.673951
[2022-04-08 01:03:02 | train] - Train Epoch: [187] [576000/1281167 (45%)]	Loss: 1.046577
[2022-04-08 01:03:29 | train] - Train Epoch: [187] [588800/1281167 (46%)]	Loss: 0.826259
[2022-04-08 01:03:56 | train] - Train Epoch: [187] [601600/1281167 (47%)]	Loss: 0.912837
[2022-04-08 01:04:23 | train] - Train Epoch: [187] [614400/1281167 (48%)]	Loss: 0.730437
[2022-04-08 01:04:51 | train] - Train Epoch: [187] [627200/1281167 (49%)]	Loss: 0.678521
[2022-04-08 01:05:18 | train] - Train Epoch: [187] [640000/1281167 (50%)]	Loss: 0.908860
[2022-04-08 01:05:45 | train] - Train Epoch: [187] [652800/1281167 (51%)]	Loss: 0.524136
[2022-04-08 01:06:12 | train] - Train Epoch: [187] [665600/1281167 (52%)]	Loss: 0.784894
[2022-04-08 01:06:39 | train] - Train Epoch: [187] [678400/1281167 (53%)]	Loss: 0.693014
[2022-04-08 01:07:07 | train] - Train Epoch: [187] [691200/1281167 (54%)]	Loss: 0.706999
[2022-04-08 01:07:35 | train] - Train Epoch: [187] [704000/1281167 (55%)]	Loss: 0.686272
[2022-04-08 01:08:03 | train] - Train Epoch: [187] [716800/1281167 (56%)]	Loss: 0.827403
[2022-04-08 01:08:31 | train] - Train Epoch: [187] [729600/1281167 (57%)]	Loss: 0.502344
[2022-04-08 01:08:59 | train] - Train Epoch: [187] [742400/1281167 (58%)]	Loss: 0.667802
[2022-04-08 01:09:26 | train] - Train Epoch: [187] [755200/1281167 (59%)]	Loss: 0.807603
[2022-04-08 01:09:53 | train] - Train Epoch: [187] [768000/1281167 (60%)]	Loss: 0.528878
[2022-04-08 01:10:21 | train] - Train Epoch: [187] [780800/1281167 (61%)]	Loss: 0.764009
[2022-04-08 01:10:48 | train] - Train Epoch: [187] [793600/1281167 (62%)]	Loss: 0.939579
[2022-04-08 01:11:17 | train] - Train Epoch: [187] [806400/1281167 (63%)]	Loss: 1.062315
[2022-04-08 01:11:44 | train] - Train Epoch: [187] [819200/1281167 (64%)]	Loss: 0.879974
[2022-04-08 01:12:11 | train] - Train Epoch: [187] [832000/1281167 (65%)]	Loss: 0.630784
[2022-04-08 01:12:39 | train] - Train Epoch: [187] [844800/1281167 (66%)]	Loss: 0.470209
[2022-04-08 01:13:07 | train] - Train Epoch: [187] [857600/1281167 (67%)]	Loss: 0.822575
[2022-04-08 01:13:34 | train] - Train Epoch: [187] [870400/1281167 (68%)]	Loss: 0.741708
[2022-04-08 01:14:01 | train] - Train Epoch: [187] [883200/1281167 (69%)]	Loss: 0.740527
[2022-04-08 01:14:28 | train] - Train Epoch: [187] [896000/1281167 (70%)]	Loss: 0.762242
[2022-04-08 01:14:56 | train] - Train Epoch: [187] [908800/1281167 (71%)]	Loss: 1.012012
[2022-04-08 01:15:24 | train] - Train Epoch: [187] [921600/1281167 (72%)]	Loss: 0.699820
[2022-04-08 01:15:51 | train] - Train Epoch: [187] [934400/1281167 (73%)]	Loss: 0.763573
[2022-04-08 01:16:18 | train] - Train Epoch: [187] [947200/1281167 (74%)]	Loss: 1.174608
[2022-04-08 01:16:47 | train] - Train Epoch: [187] [960000/1281167 (75%)]	Loss: 0.696805
[2022-04-08 01:17:16 | train] - Train Epoch: [187] [972800/1281167 (76%)]	Loss: 0.550236
[2022-04-08 01:17:43 | train] - Train Epoch: [187] [985600/1281167 (77%)]	Loss: 0.644162
[2022-04-08 01:18:11 | train] - Train Epoch: [187] [998400/1281167 (78%)]	Loss: 0.588261
[2022-04-08 01:18:39 | train] - Train Epoch: [187] [1011200/1281167 (79%)]	Loss: 0.898965
[2022-04-08 01:19:06 | train] - Train Epoch: [187] [1024000/1281167 (80%)]	Loss: 0.804625
[2022-04-08 01:19:33 | train] - Train Epoch: [187] [1036800/1281167 (81%)]	Loss: 1.003657
[2022-04-08 01:20:01 | train] - Train Epoch: [187] [1049600/1281167 (82%)]	Loss: 0.701568
[2022-04-08 01:20:29 | train] - Train Epoch: [187] [1062400/1281167 (83%)]	Loss: 0.655047
[2022-04-08 01:20:56 | train] - Train Epoch: [187] [1075200/1281167 (84%)]	Loss: 0.795584
[2022-04-08 01:21:23 | train] - Train Epoch: [187] [1088000/1281167 (85%)]	Loss: 0.665179
[2022-04-08 01:21:51 | train] - Train Epoch: [187] [1100800/1281167 (86%)]	Loss: 0.794919
[2022-04-08 01:22:19 | train] - Train Epoch: [187] [1113600/1281167 (87%)]	Loss: 0.431429
[2022-04-08 01:22:47 | train] - Train Epoch: [187] [1126400/1281167 (88%)]	Loss: 1.009885
[2022-04-08 01:23:15 | train] - Train Epoch: [187] [1139200/1281167 (89%)]	Loss: 0.757403
[2022-04-08 01:23:44 | train] - Train Epoch: [187] [1152000/1281167 (90%)]	Loss: 0.997995
[2022-04-08 01:24:12 | train] - Train Epoch: [187] [1164800/1281167 (91%)]	Loss: 0.551485
[2022-04-08 01:24:41 | train] - Train Epoch: [187] [1177600/1281167 (92%)]	Loss: 1.045242
[2022-04-08 01:25:08 | train] - Train Epoch: [187] [1190400/1281167 (93%)]	Loss: 0.858657
[2022-04-08 01:25:37 | train] - Train Epoch: [187] [1203200/1281167 (94%)]	Loss: 0.974052
[2022-04-08 01:26:05 | train] - Train Epoch: [187] [1216000/1281167 (95%)]	Loss: 0.616117
[2022-04-08 01:26:34 | train] - Train Epoch: [187] [1228800/1281167 (96%)]	Loss: 0.819265
[2022-04-08 01:27:01 | train] - Train Epoch: [187] [1241600/1281167 (97%)]	Loss: 0.913951
[2022-04-08 01:27:30 | train] - Train Epoch: [187] [1254400/1281167 (98%)]	Loss: 0.556628
[2022-04-08 01:27:59 | train] - Train Epoch: [187] [1267200/1281167 (99%)]	Loss: 0.798845
[2022-04-08 01:28:27 | train] - Train Epoch: [187] [1280000/1281167 (100%)]	Loss: 0.707988
[2022-04-08 01:28:30 | train] - Train Epoch: [187]	 Average Loss: 0.757859	 Total Acc : 81.5119	 Total Top5 Acc : 93.2541
[2022-04-08 01:28:30 | train] - -------187 epoch end-----------
========================================
-------187 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 01:30:24 | train] - 
Epoch [187] Test set: Average loss: 1.4614, Accuracy: 34866/50000 (69.7047%), Top-5 Accuracy: 88.8311%

[2022-04-08 01:30:24 | train] - save intermediate epoch [187] result


[2022-04-08 01:30:49 | train] - -------188 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 01:30:50 | train] - Train Epoch: [188] [0/1281167 (0%)]	Loss: 0.857908
[2022-04-08 01:31:17 | train] - Train Epoch: [188] [12800/1281167 (1%)]	Loss: 0.586421
[2022-04-08 01:31:45 | train] - Train Epoch: [188] [25600/1281167 (2%)]	Loss: 0.726545
[2022-04-08 01:32:12 | train] - Train Epoch: [188] [38400/1281167 (3%)]	Loss: 0.814205
[2022-04-08 01:32:39 | train] - Train Epoch: [188] [51200/1281167 (4%)]	Loss: 0.637722
[2022-04-08 01:33:05 | train] - Train Epoch: [188] [64000/1281167 (5%)]	Loss: 0.723407
[2022-04-08 01:33:32 | train] - Train Epoch: [188] [76800/1281167 (6%)]	Loss: 0.877986
[2022-04-08 01:33:59 | train] - Train Epoch: [188] [89600/1281167 (7%)]	Loss: 0.645302
[2022-04-08 01:34:27 | train] - Train Epoch: [188] [102400/1281167 (8%)]	Loss: 0.660047
[2022-04-08 01:34:54 | train] - Train Epoch: [188] [115200/1281167 (9%)]	Loss: 0.700883
[2022-04-08 01:35:21 | train] - Train Epoch: [188] [128000/1281167 (10%)]	Loss: 0.664029
[2022-04-08 01:35:48 | train] - Train Epoch: [188] [140800/1281167 (11%)]	Loss: 0.732819
[2022-04-08 01:36:15 | train] - Train Epoch: [188] [153600/1281167 (12%)]	Loss: 0.749119
[2022-04-08 01:36:41 | train] - Train Epoch: [188] [166400/1281167 (13%)]	Loss: 0.705363
[2022-04-08 01:37:09 | train] - Train Epoch: [188] [179200/1281167 (14%)]	Loss: 0.690054
[2022-04-08 01:37:36 | train] - Train Epoch: [188] [192000/1281167 (15%)]	Loss: 0.920374
[2022-04-08 01:38:04 | train] - Train Epoch: [188] [204800/1281167 (16%)]	Loss: 1.078354
[2022-04-08 01:38:30 | train] - Train Epoch: [188] [217600/1281167 (17%)]	Loss: 0.451635
[2022-04-08 01:38:58 | train] - Train Epoch: [188] [230400/1281167 (18%)]	Loss: 0.590264
[2022-04-08 01:39:25 | train] - Train Epoch: [188] [243200/1281167 (19%)]	Loss: 0.759380
[2022-04-08 01:39:52 | train] - Train Epoch: [188] [256000/1281167 (20%)]	Loss: 1.001549
[2022-04-08 01:40:20 | train] - Train Epoch: [188] [268800/1281167 (21%)]	Loss: 0.735696
[2022-04-08 01:40:47 | train] - Train Epoch: [188] [281600/1281167 (22%)]	Loss: 0.877761
[2022-04-08 01:41:15 | train] - Train Epoch: [188] [294400/1281167 (23%)]	Loss: 0.697574
[2022-04-08 01:41:43 | train] - Train Epoch: [188] [307200/1281167 (24%)]	Loss: 0.811006
[2022-04-08 01:42:10 | train] - Train Epoch: [188] [320000/1281167 (25%)]	Loss: 0.698535
[2022-04-08 01:42:37 | train] - Train Epoch: [188] [332800/1281167 (26%)]	Loss: 1.038836
[2022-04-08 01:43:05 | train] - Train Epoch: [188] [345600/1281167 (27%)]	Loss: 0.869162
[2022-04-08 01:43:31 | train] - Train Epoch: [188] [358400/1281167 (28%)]	Loss: 0.620446
[2022-04-08 01:43:59 | train] - Train Epoch: [188] [371200/1281167 (29%)]	Loss: 0.824820
[2022-04-08 01:44:26 | train] - Train Epoch: [188] [384000/1281167 (30%)]	Loss: 0.702803
[2022-04-08 01:44:54 | train] - Train Epoch: [188] [396800/1281167 (31%)]	Loss: 0.787232
[2022-04-08 01:45:21 | train] - Train Epoch: [188] [409600/1281167 (32%)]	Loss: 0.687592
[2022-04-08 01:45:48 | train] - Train Epoch: [188] [422400/1281167 (33%)]	Loss: 0.528433
[2022-04-08 01:46:15 | train] - Train Epoch: [188] [435200/1281167 (34%)]	Loss: 0.574846
[2022-04-08 01:46:42 | train] - Train Epoch: [188] [448000/1281167 (35%)]	Loss: 0.714017
[2022-04-08 01:47:09 | train] - Train Epoch: [188] [460800/1281167 (36%)]	Loss: 0.516250
[2022-04-08 01:47:37 | train] - Train Epoch: [188] [473600/1281167 (37%)]	Loss: 0.654434
[2022-04-08 01:48:05 | train] - Train Epoch: [188] [486400/1281167 (38%)]	Loss: 0.881668
[2022-04-08 01:48:33 | train] - Train Epoch: [188] [499200/1281167 (39%)]	Loss: 0.761267
[2022-04-08 01:49:00 | train] - Train Epoch: [188] [512000/1281167 (40%)]	Loss: 0.655813
[2022-04-08 01:49:27 | train] - Train Epoch: [188] [524800/1281167 (41%)]	Loss: 0.743148
[2022-04-08 01:49:54 | train] - Train Epoch: [188] [537600/1281167 (42%)]	Loss: 0.694066
[2022-04-08 01:50:22 | train] - Train Epoch: [188] [550400/1281167 (43%)]	Loss: 1.055944
[2022-04-08 01:50:51 | train] - Train Epoch: [188] [563200/1281167 (44%)]	Loss: 0.849738
[2022-04-08 01:51:19 | train] - Train Epoch: [188] [576000/1281167 (45%)]	Loss: 0.663737
[2022-04-08 01:51:46 | train] - Train Epoch: [188] [588800/1281167 (46%)]	Loss: 0.883243
[2022-04-08 01:52:13 | train] - Train Epoch: [188] [601600/1281167 (47%)]	Loss: 0.994993
[2022-04-08 01:52:40 | train] - Train Epoch: [188] [614400/1281167 (48%)]	Loss: 0.802011
[2022-04-08 01:53:08 | train] - Train Epoch: [188] [627200/1281167 (49%)]	Loss: 0.585785
[2022-04-08 01:53:36 | train] - Train Epoch: [188] [640000/1281167 (50%)]	Loss: 0.746351
[2022-04-08 01:54:04 | train] - Train Epoch: [188] [652800/1281167 (51%)]	Loss: 0.880161
[2022-04-08 01:54:32 | train] - Train Epoch: [188] [665600/1281167 (52%)]	Loss: 0.678627
[2022-04-08 01:54:59 | train] - Train Epoch: [188] [678400/1281167 (53%)]	Loss: 0.618440
[2022-04-08 01:55:27 | train] - Train Epoch: [188] [691200/1281167 (54%)]	Loss: 0.793887
[2022-04-08 01:55:55 | train] - Train Epoch: [188] [704000/1281167 (55%)]	Loss: 0.617198
[2022-04-08 01:56:23 | train] - Train Epoch: [188] [716800/1281167 (56%)]	Loss: 0.685567
[2022-04-08 01:56:50 | train] - Train Epoch: [188] [729600/1281167 (57%)]	Loss: 0.863792
[2022-04-08 01:57:19 | train] - Train Epoch: [188] [742400/1281167 (58%)]	Loss: 0.874166
[2022-04-08 01:57:47 | train] - Train Epoch: [188] [755200/1281167 (59%)]	Loss: 0.817222
[2022-04-08 01:58:14 | train] - Train Epoch: [188] [768000/1281167 (60%)]	Loss: 0.716834
[2022-04-08 01:58:42 | train] - Train Epoch: [188] [780800/1281167 (61%)]	Loss: 0.742262
[2022-04-08 01:59:09 | train] - Train Epoch: [188] [793600/1281167 (62%)]	Loss: 0.838393
[2022-04-08 01:59:37 | train] - Train Epoch: [188] [806400/1281167 (63%)]	Loss: 0.677895
[2022-04-08 02:00:04 | train] - Train Epoch: [188] [819200/1281167 (64%)]	Loss: 0.838197
[2022-04-08 02:00:31 | train] - Train Epoch: [188] [832000/1281167 (65%)]	Loss: 0.825341
[2022-04-08 02:00:59 | train] - Train Epoch: [188] [844800/1281167 (66%)]	Loss: 1.024324
[2022-04-08 02:01:26 | train] - Train Epoch: [188] [857600/1281167 (67%)]	Loss: 0.799385
[2022-04-08 02:01:53 | train] - Train Epoch: [188] [870400/1281167 (68%)]	Loss: 0.743554
[2022-04-08 02:02:20 | train] - Train Epoch: [188] [883200/1281167 (69%)]	Loss: 0.721670
[2022-04-08 02:02:48 | train] - Train Epoch: [188] [896000/1281167 (70%)]	Loss: 0.695780
[2022-04-08 02:03:16 | train] - Train Epoch: [188] [908800/1281167 (71%)]	Loss: 0.509111
[2022-04-08 02:03:42 | train] - Train Epoch: [188] [921600/1281167 (72%)]	Loss: 0.673233
[2022-04-08 02:04:10 | train] - Train Epoch: [188] [934400/1281167 (73%)]	Loss: 0.916417
[2022-04-08 02:04:37 | train] - Train Epoch: [188] [947200/1281167 (74%)]	Loss: 0.822307
[2022-04-08 02:05:05 | train] - Train Epoch: [188] [960000/1281167 (75%)]	Loss: 0.823918
[2022-04-08 02:05:32 | train] - Train Epoch: [188] [972800/1281167 (76%)]	Loss: 0.977254
[2022-04-08 02:05:59 | train] - Train Epoch: [188] [985600/1281167 (77%)]	Loss: 0.611216
[2022-04-08 02:06:26 | train] - Train Epoch: [188] [998400/1281167 (78%)]	Loss: 0.863952
[2022-04-08 02:06:53 | train] - Train Epoch: [188] [1011200/1281167 (79%)]	Loss: 0.602061
[2022-04-08 02:07:21 | train] - Train Epoch: [188] [1024000/1281167 (80%)]	Loss: 0.782974
[2022-04-08 02:07:49 | train] - Train Epoch: [188] [1036800/1281167 (81%)]	Loss: 0.687198
[2022-04-08 02:08:16 | train] - Train Epoch: [188] [1049600/1281167 (82%)]	Loss: 0.739464
[2022-04-08 02:08:44 | train] - Train Epoch: [188] [1062400/1281167 (83%)]	Loss: 0.866444
[2022-04-08 02:09:11 | train] - Train Epoch: [188] [1075200/1281167 (84%)]	Loss: 0.689919
[2022-04-08 02:09:39 | train] - Train Epoch: [188] [1088000/1281167 (85%)]	Loss: 0.601231
[2022-04-08 02:10:07 | train] - Train Epoch: [188] [1100800/1281167 (86%)]	Loss: 0.628115
[2022-04-08 02:10:35 | train] - Train Epoch: [188] [1113600/1281167 (87%)]	Loss: 0.808556
[2022-04-08 02:11:02 | train] - Train Epoch: [188] [1126400/1281167 (88%)]	Loss: 0.741792
[2022-04-08 02:11:30 | train] - Train Epoch: [188] [1139200/1281167 (89%)]	Loss: 0.392586
[2022-04-08 02:11:58 | train] - Train Epoch: [188] [1152000/1281167 (90%)]	Loss: 0.764958
[2022-04-08 02:12:26 | train] - Train Epoch: [188] [1164800/1281167 (91%)]	Loss: 0.648583
[2022-04-08 02:12:54 | train] - Train Epoch: [188] [1177600/1281167 (92%)]	Loss: 0.611250
[2022-04-08 02:13:22 | train] - Train Epoch: [188] [1190400/1281167 (93%)]	Loss: 0.788726
[2022-04-08 02:13:50 | train] - Train Epoch: [188] [1203200/1281167 (94%)]	Loss: 0.736908
[2022-04-08 02:14:18 | train] - Train Epoch: [188] [1216000/1281167 (95%)]	Loss: 0.638066
[2022-04-08 02:14:46 | train] - Train Epoch: [188] [1228800/1281167 (96%)]	Loss: 0.762066
[2022-04-08 02:15:14 | train] - Train Epoch: [188] [1241600/1281167 (97%)]	Loss: 0.773052
[2022-04-08 02:15:41 | train] - Train Epoch: [188] [1254400/1281167 (98%)]	Loss: 0.604494
[2022-04-08 02:16:09 | train] - Train Epoch: [188] [1267200/1281167 (99%)]	Loss: 0.956402
[2022-04-08 02:16:37 | train] - Train Epoch: [188] [1280000/1281167 (100%)]	Loss: 0.865263
[2022-04-08 02:16:39 | train] - Train Epoch: [188]	 Average Loss: 0.758005	 Total Acc : 81.5179	 Total Top5 Acc : 93.2542
[2022-04-08 02:16:39 | train] - -------188 epoch end-----------
========================================
-------188 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 02:18:32 | train] - 
Epoch [188] Test set: Average loss: 1.4591, Accuracy: 34869/50000 (69.7107%), Top-5 Accuracy: 88.7372%

[2022-04-08 02:18:32 | train] - save intermediate epoch [188] result


[2022-04-08 02:18:57 | train] - -------189 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 02:18:59 | train] - Train Epoch: [189] [0/1281167 (0%)]	Loss: 0.971363
[2022-04-08 02:19:26 | train] - Train Epoch: [189] [12800/1281167 (1%)]	Loss: 0.732244
[2022-04-08 02:19:53 | train] - Train Epoch: [189] [25600/1281167 (2%)]	Loss: 0.856059
[2022-04-08 02:20:20 | train] - Train Epoch: [189] [38400/1281167 (3%)]	Loss: 0.537313
[2022-04-08 02:20:47 | train] - Train Epoch: [189] [51200/1281167 (4%)]	Loss: 0.676322
[2022-04-08 02:21:14 | train] - Train Epoch: [189] [64000/1281167 (5%)]	Loss: 0.536983
[2022-04-08 02:21:41 | train] - Train Epoch: [189] [76800/1281167 (6%)]	Loss: 0.865484
[2022-04-08 02:22:08 | train] - Train Epoch: [189] [89600/1281167 (7%)]	Loss: 0.914416
[2022-04-08 02:22:35 | train] - Train Epoch: [189] [102400/1281167 (8%)]	Loss: 0.818406
[2022-04-08 02:23:02 | train] - Train Epoch: [189] [115200/1281167 (9%)]	Loss: 1.145219
[2022-04-08 02:23:29 | train] - Train Epoch: [189] [128000/1281167 (10%)]	Loss: 0.711747
[2022-04-08 02:23:55 | train] - Train Epoch: [189] [140800/1281167 (11%)]	Loss: 0.743352
[2022-04-08 02:24:23 | train] - Train Epoch: [189] [153600/1281167 (12%)]	Loss: 0.718022
[2022-04-08 02:24:50 | train] - Train Epoch: [189] [166400/1281167 (13%)]	Loss: 0.690447
[2022-04-08 02:25:18 | train] - Train Epoch: [189] [179200/1281167 (14%)]	Loss: 0.758274
[2022-04-08 02:25:45 | train] - Train Epoch: [189] [192000/1281167 (15%)]	Loss: 0.873441
[2022-04-08 02:26:12 | train] - Train Epoch: [189] [204800/1281167 (16%)]	Loss: 0.680153
[2022-04-08 02:26:39 | train] - Train Epoch: [189] [217600/1281167 (17%)]	Loss: 0.611289
[2022-04-08 02:27:07 | train] - Train Epoch: [189] [230400/1281167 (18%)]	Loss: 0.689249
[2022-04-08 02:27:35 | train] - Train Epoch: [189] [243200/1281167 (19%)]	Loss: 0.743662
[2022-04-08 02:28:02 | train] - Train Epoch: [189] [256000/1281167 (20%)]	Loss: 0.908073
[2022-04-08 02:28:30 | train] - Train Epoch: [189] [268800/1281167 (21%)]	Loss: 0.706060
[2022-04-08 02:28:58 | train] - Train Epoch: [189] [281600/1281167 (22%)]	Loss: 0.970985
[2022-04-08 02:29:25 | train] - Train Epoch: [189] [294400/1281167 (23%)]	Loss: 0.731830
[2022-04-08 02:29:53 | train] - Train Epoch: [189] [307200/1281167 (24%)]	Loss: 0.882065
[2022-04-08 02:30:20 | train] - Train Epoch: [189] [320000/1281167 (25%)]	Loss: 0.873146
[2022-04-08 02:30:48 | train] - Train Epoch: [189] [332800/1281167 (26%)]	Loss: 0.824581
[2022-04-08 02:31:15 | train] - Train Epoch: [189] [345600/1281167 (27%)]	Loss: 0.690195
[2022-04-08 02:31:42 | train] - Train Epoch: [189] [358400/1281167 (28%)]	Loss: 0.966869
[2022-04-08 02:32:10 | train] - Train Epoch: [189] [371200/1281167 (29%)]	Loss: 0.725120
[2022-04-08 02:32:38 | train] - Train Epoch: [189] [384000/1281167 (30%)]	Loss: 0.661397
[2022-04-08 02:33:05 | train] - Train Epoch: [189] [396800/1281167 (31%)]	Loss: 0.829509
[2022-04-08 02:33:33 | train] - Train Epoch: [189] [409600/1281167 (32%)]	Loss: 0.836516
[2022-04-08 02:34:00 | train] - Train Epoch: [189] [422400/1281167 (33%)]	Loss: 0.796436
[2022-04-08 02:34:27 | train] - Train Epoch: [189] [435200/1281167 (34%)]	Loss: 0.715060
[2022-04-08 02:34:55 | train] - Train Epoch: [189] [448000/1281167 (35%)]	Loss: 1.046294
[2022-04-08 02:35:23 | train] - Train Epoch: [189] [460800/1281167 (36%)]	Loss: 0.848083
[2022-04-08 02:35:51 | train] - Train Epoch: [189] [473600/1281167 (37%)]	Loss: 0.633854
[2022-04-08 02:36:17 | train] - Train Epoch: [189] [486400/1281167 (38%)]	Loss: 0.732277
[2022-04-08 02:36:45 | train] - Train Epoch: [189] [499200/1281167 (39%)]	Loss: 0.932560
[2022-04-08 02:37:12 | train] - Train Epoch: [189] [512000/1281167 (40%)]	Loss: 0.900251
[2022-04-08 02:37:39 | train] - Train Epoch: [189] [524800/1281167 (41%)]	Loss: 0.605959
[2022-04-08 02:38:07 | train] - Train Epoch: [189] [537600/1281167 (42%)]	Loss: 0.659692
[2022-04-08 02:38:34 | train] - Train Epoch: [189] [550400/1281167 (43%)]	Loss: 0.959652
[2022-04-08 02:39:02 | train] - Train Epoch: [189] [563200/1281167 (44%)]	Loss: 0.727574
[2022-04-08 02:39:30 | train] - Train Epoch: [189] [576000/1281167 (45%)]	Loss: 0.660654
[2022-04-08 02:39:58 | train] - Train Epoch: [189] [588800/1281167 (46%)]	Loss: 0.799825
[2022-04-08 02:40:25 | train] - Train Epoch: [189] [601600/1281167 (47%)]	Loss: 0.957835
[2022-04-08 02:40:52 | train] - Train Epoch: [189] [614400/1281167 (48%)]	Loss: 0.786787
[2022-04-08 02:41:20 | train] - Train Epoch: [189] [627200/1281167 (49%)]	Loss: 0.903181
[2022-04-08 02:41:47 | train] - Train Epoch: [189] [640000/1281167 (50%)]	Loss: 0.803441
[2022-04-08 02:42:14 | train] - Train Epoch: [189] [652800/1281167 (51%)]	Loss: 0.449195
[2022-04-08 02:42:42 | train] - Train Epoch: [189] [665600/1281167 (52%)]	Loss: 0.497682
[2022-04-08 02:43:10 | train] - Train Epoch: [189] [678400/1281167 (53%)]	Loss: 0.734227
[2022-04-08 02:43:38 | train] - Train Epoch: [189] [691200/1281167 (54%)]	Loss: 0.606513
[2022-04-08 02:44:05 | train] - Train Epoch: [189] [704000/1281167 (55%)]	Loss: 0.486219
[2022-04-08 02:44:33 | train] - Train Epoch: [189] [716800/1281167 (56%)]	Loss: 0.667018
[2022-04-08 02:45:00 | train] - Train Epoch: [189] [729600/1281167 (57%)]	Loss: 0.525645
[2022-04-08 02:45:27 | train] - Train Epoch: [189] [742400/1281167 (58%)]	Loss: 1.156917
[2022-04-08 02:45:54 | train] - Train Epoch: [189] [755200/1281167 (59%)]	Loss: 0.690406
[2022-04-08 02:46:22 | train] - Train Epoch: [189] [768000/1281167 (60%)]	Loss: 0.663830
[2022-04-08 02:46:50 | train] - Train Epoch: [189] [780800/1281167 (61%)]	Loss: 0.844059
[2022-04-08 02:47:17 | train] - Train Epoch: [189] [793600/1281167 (62%)]	Loss: 0.607469
[2022-04-08 02:47:45 | train] - Train Epoch: [189] [806400/1281167 (63%)]	Loss: 0.934958
[2022-04-08 02:48:13 | train] - Train Epoch: [189] [819200/1281167 (64%)]	Loss: 0.976412
[2022-04-08 02:48:40 | train] - Train Epoch: [189] [832000/1281167 (65%)]	Loss: 0.785962
[2022-04-08 02:49:07 | train] - Train Epoch: [189] [844800/1281167 (66%)]	Loss: 0.533593
[2022-04-08 02:49:34 | train] - Train Epoch: [189] [857600/1281167 (67%)]	Loss: 0.464191
[2022-04-08 02:50:01 | train] - Train Epoch: [189] [870400/1281167 (68%)]	Loss: 0.777845
[2022-04-08 02:50:27 | train] - Train Epoch: [189] [883200/1281167 (69%)]	Loss: 0.654512
[2022-04-08 02:50:53 | train] - Train Epoch: [189] [896000/1281167 (70%)]	Loss: 0.831651
[2022-04-08 02:51:19 | train] - Train Epoch: [189] [908800/1281167 (71%)]	Loss: 0.841540
[2022-04-08 02:51:46 | train] - Train Epoch: [189] [921600/1281167 (72%)]	Loss: 0.753874
[2022-04-08 02:52:12 | train] - Train Epoch: [189] [934400/1281167 (73%)]	Loss: 0.822884
[2022-04-08 02:52:38 | train] - Train Epoch: [189] [947200/1281167 (74%)]	Loss: 0.994285
[2022-04-08 02:53:05 | train] - Train Epoch: [189] [960000/1281167 (75%)]	Loss: 0.839976
[2022-04-08 02:53:31 | train] - Train Epoch: [189] [972800/1281167 (76%)]	Loss: 0.758269
[2022-04-08 02:53:58 | train] - Train Epoch: [189] [985600/1281167 (77%)]	Loss: 0.720373
[2022-04-08 02:54:24 | train] - Train Epoch: [189] [998400/1281167 (78%)]	Loss: 0.797013
[2022-04-08 02:54:51 | train] - Train Epoch: [189] [1011200/1281167 (79%)]	Loss: 0.833008
[2022-04-08 02:55:18 | train] - Train Epoch: [189] [1024000/1281167 (80%)]	Loss: 0.807847
[2022-04-08 02:55:45 | train] - Train Epoch: [189] [1036800/1281167 (81%)]	Loss: 0.684555
[2022-04-08 02:56:12 | train] - Train Epoch: [189] [1049600/1281167 (82%)]	Loss: 1.100197
[2022-04-08 02:56:39 | train] - Train Epoch: [189] [1062400/1281167 (83%)]	Loss: 0.884455
[2022-04-08 02:57:05 | train] - Train Epoch: [189] [1075200/1281167 (84%)]	Loss: 0.788723
[2022-04-08 02:57:31 | train] - Train Epoch: [189] [1088000/1281167 (85%)]	Loss: 0.871416
[2022-04-08 02:57:58 | train] - Train Epoch: [189] [1100800/1281167 (86%)]	Loss: 0.598316
[2022-04-08 02:58:24 | train] - Train Epoch: [189] [1113600/1281167 (87%)]	Loss: 0.794908
[2022-04-08 02:58:51 | train] - Train Epoch: [189] [1126400/1281167 (88%)]	Loss: 0.669792
[2022-04-08 02:59:18 | train] - Train Epoch: [189] [1139200/1281167 (89%)]	Loss: 0.628085
[2022-04-08 02:59:45 | train] - Train Epoch: [189] [1152000/1281167 (90%)]	Loss: 0.719401
[2022-04-08 03:00:11 | train] - Train Epoch: [189] [1164800/1281167 (91%)]	Loss: 0.612204
[2022-04-08 03:00:39 | train] - Train Epoch: [189] [1177600/1281167 (92%)]	Loss: 0.671341
[2022-04-08 03:01:05 | train] - Train Epoch: [189] [1190400/1281167 (93%)]	Loss: 0.726685
[2022-04-08 03:01:32 | train] - Train Epoch: [189] [1203200/1281167 (94%)]	Loss: 0.890004
[2022-04-08 03:01:59 | train] - Train Epoch: [189] [1216000/1281167 (95%)]	Loss: 1.091232
[2022-04-08 03:02:25 | train] - Train Epoch: [189] [1228800/1281167 (96%)]	Loss: 0.545765
[2022-04-08 03:02:53 | train] - Train Epoch: [189] [1241600/1281167 (97%)]	Loss: 0.814743
[2022-04-08 03:03:20 | train] - Train Epoch: [189] [1254400/1281167 (98%)]	Loss: 0.688301
[2022-04-08 03:03:46 | train] - Train Epoch: [189] [1267200/1281167 (99%)]	Loss: 0.686603
[2022-04-08 03:04:13 | train] - Train Epoch: [189] [1280000/1281167 (100%)]	Loss: 0.824522
[2022-04-08 03:04:15 | train] - Train Epoch: [189]	 Average Loss: 0.757046	 Total Acc : 81.5547	 Total Top5 Acc : 93.2665
[2022-04-08 03:04:15 | train] - -------189 epoch end-----------
========================================
-------189 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 03:05:59 | train] - 
Epoch [189] Test set: Average loss: 1.4621, Accuracy: 34858/50000 (69.6899%), Top-5 Accuracy: 88.7152%

[2022-04-08 03:05:59 | train] - save intermediate epoch [189] result


[2022-04-08 03:06:25 | train] - -------190 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 03:06:26 | train] - Train Epoch: [190] [0/1281167 (0%)]	Loss: 0.891314
[2022-04-08 03:06:51 | train] - Train Epoch: [190] [12800/1281167 (1%)]	Loss: 0.770434
[2022-04-08 03:07:16 | train] - Train Epoch: [190] [25600/1281167 (2%)]	Loss: 0.846156
[2022-04-08 03:07:41 | train] - Train Epoch: [190] [38400/1281167 (3%)]	Loss: 0.684743
[2022-04-08 03:08:06 | train] - Train Epoch: [190] [51200/1281167 (4%)]	Loss: 0.743356
[2022-04-08 03:08:31 | train] - Train Epoch: [190] [64000/1281167 (5%)]	Loss: 0.712173
[2022-04-08 03:08:56 | train] - Train Epoch: [190] [76800/1281167 (6%)]	Loss: 0.713757
[2022-04-08 03:09:20 | train] - Train Epoch: [190] [89600/1281167 (7%)]	Loss: 0.634071
[2022-04-08 03:09:45 | train] - Train Epoch: [190] [102400/1281167 (8%)]	Loss: 0.886554
[2022-04-08 03:10:09 | train] - Train Epoch: [190] [115200/1281167 (9%)]	Loss: 0.717005
[2022-04-08 03:10:34 | train] - Train Epoch: [190] [128000/1281167 (10%)]	Loss: 0.684936
[2022-04-08 03:10:59 | train] - Train Epoch: [190] [140800/1281167 (11%)]	Loss: 0.600080
[2022-04-08 03:11:24 | train] - Train Epoch: [190] [153600/1281167 (12%)]	Loss: 0.570738
[2022-04-08 03:11:48 | train] - Train Epoch: [190] [166400/1281167 (13%)]	Loss: 0.744456
[2022-04-08 03:12:12 | train] - Train Epoch: [190] [179200/1281167 (14%)]	Loss: 0.800293
[2022-04-08 03:12:37 | train] - Train Epoch: [190] [192000/1281167 (15%)]	Loss: 0.673147
[2022-04-08 03:13:02 | train] - Train Epoch: [190] [204800/1281167 (16%)]	Loss: 0.656442
[2022-04-08 03:13:26 | train] - Train Epoch: [190] [217600/1281167 (17%)]	Loss: 0.941974
[2022-04-08 03:13:51 | train] - Train Epoch: [190] [230400/1281167 (18%)]	Loss: 0.665774
[2022-04-08 03:14:15 | train] - Train Epoch: [190] [243200/1281167 (19%)]	Loss: 0.609687
[2022-04-08 03:14:40 | train] - Train Epoch: [190] [256000/1281167 (20%)]	Loss: 1.011109
[2022-04-08 03:15:05 | train] - Train Epoch: [190] [268800/1281167 (21%)]	Loss: 0.728274
[2022-04-08 03:15:30 | train] - Train Epoch: [190] [281600/1281167 (22%)]	Loss: 0.707025
[2022-04-08 03:15:55 | train] - Train Epoch: [190] [294400/1281167 (23%)]	Loss: 0.608008
[2022-04-08 03:16:19 | train] - Train Epoch: [190] [307200/1281167 (24%)]	Loss: 0.586354
[2022-04-08 03:16:43 | train] - Train Epoch: [190] [320000/1281167 (25%)]	Loss: 0.602217
[2022-04-08 03:17:08 | train] - Train Epoch: [190] [332800/1281167 (26%)]	Loss: 0.795079
[2022-04-08 03:17:33 | train] - Train Epoch: [190] [345600/1281167 (27%)]	Loss: 0.686076
[2022-04-08 03:17:58 | train] - Train Epoch: [190] [358400/1281167 (28%)]	Loss: 1.009948
[2022-04-08 03:18:22 | train] - Train Epoch: [190] [371200/1281167 (29%)]	Loss: 0.791834
[2022-04-08 03:18:47 | train] - Train Epoch: [190] [384000/1281167 (30%)]	Loss: 0.619539
[2022-04-08 03:19:12 | train] - Train Epoch: [190] [396800/1281167 (31%)]	Loss: 0.614419
[2022-04-08 03:19:37 | train] - Train Epoch: [190] [409600/1281167 (32%)]	Loss: 0.932528
[2022-04-08 03:20:01 | train] - Train Epoch: [190] [422400/1281167 (33%)]	Loss: 0.580593
[2022-04-08 03:20:26 | train] - Train Epoch: [190] [435200/1281167 (34%)]	Loss: 0.817873
[2022-04-08 03:20:50 | train] - Train Epoch: [190] [448000/1281167 (35%)]	Loss: 0.724346
[2022-04-08 03:21:14 | train] - Train Epoch: [190] [460800/1281167 (36%)]	Loss: 0.438163
[2022-04-08 03:21:39 | train] - Train Epoch: [190] [473600/1281167 (37%)]	Loss: 0.887756
[2022-04-08 03:22:03 | train] - Train Epoch: [190] [486400/1281167 (38%)]	Loss: 0.902981
[2022-04-08 03:22:28 | train] - Train Epoch: [190] [499200/1281167 (39%)]	Loss: 0.564550
[2022-04-08 03:22:52 | train] - Train Epoch: [190] [512000/1281167 (40%)]	Loss: 0.737468
[2022-04-08 03:23:16 | train] - Train Epoch: [190] [524800/1281167 (41%)]	Loss: 0.696530
[2022-04-08 03:23:41 | train] - Train Epoch: [190] [537600/1281167 (42%)]	Loss: 0.867240
[2022-04-08 03:24:06 | train] - Train Epoch: [190] [550400/1281167 (43%)]	Loss: 0.773959
[2022-04-08 03:24:31 | train] - Train Epoch: [190] [563200/1281167 (44%)]	Loss: 0.683409
[2022-04-08 03:24:56 | train] - Train Epoch: [190] [576000/1281167 (45%)]	Loss: 0.530874
[2022-04-08 03:25:21 | train] - Train Epoch: [190] [588800/1281167 (46%)]	Loss: 0.674802
[2022-04-08 03:25:46 | train] - Train Epoch: [190] [601600/1281167 (47%)]	Loss: 0.626866
[2022-04-08 03:26:11 | train] - Train Epoch: [190] [614400/1281167 (48%)]	Loss: 0.925826
[2022-04-08 03:26:36 | train] - Train Epoch: [190] [627200/1281167 (49%)]	Loss: 0.688865
[2022-04-08 03:27:00 | train] - Train Epoch: [190] [640000/1281167 (50%)]	Loss: 0.506446
[2022-04-08 03:27:25 | train] - Train Epoch: [190] [652800/1281167 (51%)]	Loss: 0.691847
[2022-04-08 03:27:50 | train] - Train Epoch: [190] [665600/1281167 (52%)]	Loss: 0.784343
[2022-04-08 03:28:14 | train] - Train Epoch: [190] [678400/1281167 (53%)]	Loss: 0.500450
[2022-04-08 03:28:38 | train] - Train Epoch: [190] [691200/1281167 (54%)]	Loss: 0.759191
[2022-04-08 03:29:02 | train] - Train Epoch: [190] [704000/1281167 (55%)]	Loss: 0.727419
[2022-04-08 03:29:27 | train] - Train Epoch: [190] [716800/1281167 (56%)]	Loss: 0.809216
[2022-04-08 03:29:52 | train] - Train Epoch: [190] [729600/1281167 (57%)]	Loss: 0.747116
[2022-04-08 03:30:16 | train] - Train Epoch: [190] [742400/1281167 (58%)]	Loss: 0.691398
[2022-04-08 03:30:41 | train] - Train Epoch: [190] [755200/1281167 (59%)]	Loss: 0.768872
[2022-04-08 03:31:05 | train] - Train Epoch: [190] [768000/1281167 (60%)]	Loss: 0.691477
[2022-04-08 03:31:31 | train] - Train Epoch: [190] [780800/1281167 (61%)]	Loss: 0.773213
[2022-04-08 03:31:55 | train] - Train Epoch: [190] [793600/1281167 (62%)]	Loss: 0.689962
[2022-04-08 03:32:19 | train] - Train Epoch: [190] [806400/1281167 (63%)]	Loss: 0.600841
[2022-04-08 03:32:44 | train] - Train Epoch: [190] [819200/1281167 (64%)]	Loss: 0.862796
[2022-04-08 03:33:08 | train] - Train Epoch: [190] [832000/1281167 (65%)]	Loss: 0.662502
[2022-04-08 03:33:33 | train] - Train Epoch: [190] [844800/1281167 (66%)]	Loss: 0.466276
[2022-04-08 03:33:57 | train] - Train Epoch: [190] [857600/1281167 (67%)]	Loss: 0.785066
[2022-04-08 03:34:22 | train] - Train Epoch: [190] [870400/1281167 (68%)]	Loss: 0.650218
[2022-04-08 03:34:47 | train] - Train Epoch: [190] [883200/1281167 (69%)]	Loss: 0.722038
[2022-04-08 03:35:11 | train] - Train Epoch: [190] [896000/1281167 (70%)]	Loss: 0.689193
[2022-04-08 03:35:35 | train] - Train Epoch: [190] [908800/1281167 (71%)]	Loss: 0.678784
[2022-04-08 03:36:01 | train] - Train Epoch: [190] [921600/1281167 (72%)]	Loss: 0.652808
[2022-04-08 03:36:25 | train] - Train Epoch: [190] [934400/1281167 (73%)]	Loss: 0.699301
[2022-04-08 03:36:50 | train] - Train Epoch: [190] [947200/1281167 (74%)]	Loss: 0.516575
[2022-04-08 03:37:15 | train] - Train Epoch: [190] [960000/1281167 (75%)]	Loss: 0.755798
[2022-04-08 03:37:39 | train] - Train Epoch: [190] [972800/1281167 (76%)]	Loss: 0.621744
[2022-04-08 03:38:03 | train] - Train Epoch: [190] [985600/1281167 (77%)]	Loss: 0.698533
[2022-04-08 03:38:27 | train] - Train Epoch: [190] [998400/1281167 (78%)]	Loss: 0.571242
[2022-04-08 03:38:52 | train] - Train Epoch: [190] [1011200/1281167 (79%)]	Loss: 0.544887
[2022-04-08 03:39:17 | train] - Train Epoch: [190] [1024000/1281167 (80%)]	Loss: 0.867801
[2022-04-08 03:39:42 | train] - Train Epoch: [190] [1036800/1281167 (81%)]	Loss: 0.760233
[2022-04-08 03:40:07 | train] - Train Epoch: [190] [1049600/1281167 (82%)]	Loss: 0.854622
[2022-04-08 03:40:31 | train] - Train Epoch: [190] [1062400/1281167 (83%)]	Loss: 0.730213
[2022-04-08 03:40:56 | train] - Train Epoch: [190] [1075200/1281167 (84%)]	Loss: 0.574527
[2022-04-08 03:41:21 | train] - Train Epoch: [190] [1088000/1281167 (85%)]	Loss: 0.679148
[2022-04-08 03:41:46 | train] - Train Epoch: [190] [1100800/1281167 (86%)]	Loss: 0.837314
[2022-04-08 03:42:11 | train] - Train Epoch: [190] [1113600/1281167 (87%)]	Loss: 0.822315
[2022-04-08 03:42:35 | train] - Train Epoch: [190] [1126400/1281167 (88%)]	Loss: 0.865306
[2022-04-08 03:43:00 | train] - Train Epoch: [190] [1139200/1281167 (89%)]	Loss: 0.730146
[2022-04-08 03:43:25 | train] - Train Epoch: [190] [1152000/1281167 (90%)]	Loss: 0.744701
[2022-04-08 03:43:49 | train] - Train Epoch: [190] [1164800/1281167 (91%)]	Loss: 0.614759
[2022-04-08 03:44:14 | train] - Train Epoch: [190] [1177600/1281167 (92%)]	Loss: 0.607271
[2022-04-08 03:44:39 | train] - Train Epoch: [190] [1190400/1281167 (93%)]	Loss: 0.557111
[2022-04-08 03:45:04 | train] - Train Epoch: [190] [1203200/1281167 (94%)]	Loss: 0.725264
[2022-04-08 03:45:29 | train] - Train Epoch: [190] [1216000/1281167 (95%)]	Loss: 0.640756
[2022-04-08 03:45:54 | train] - Train Epoch: [190] [1228800/1281167 (96%)]	Loss: 0.989551
[2022-04-08 03:46:18 | train] - Train Epoch: [190] [1241600/1281167 (97%)]	Loss: 0.657596
[2022-04-08 03:46:43 | train] - Train Epoch: [190] [1254400/1281167 (98%)]	Loss: 0.800054
[2022-04-08 03:47:07 | train] - Train Epoch: [190] [1267200/1281167 (99%)]	Loss: 0.685697
[2022-04-08 03:47:32 | train] - Train Epoch: [190] [1280000/1281167 (100%)]	Loss: 0.534523
[2022-04-08 03:47:34 | train] - Train Epoch: [190]	 Average Loss: 0.757202	 Total Acc : 81.5228	 Total Top5 Acc : 93.2700
[2022-04-08 03:47:34 | train] - -------190 epoch end-----------
========================================
-------190 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 03:49:18 | train] - 
Epoch [190] Test set: Average loss: 1.4630, Accuracy: 34876/50000 (69.7247%), Top-5 Accuracy: 88.7288%

[2022-04-08 03:49:18 | train] - save intermediate epoch [190] result


[2022-04-08 03:49:45 | train] - -------191 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 03:49:46 | train] - Train Epoch: [191] [0/1281167 (0%)]	Loss: 0.498166
[2022-04-08 03:50:10 | train] - Train Epoch: [191] [12800/1281167 (1%)]	Loss: 0.731305
[2022-04-08 03:50:33 | train] - Train Epoch: [191] [25600/1281167 (2%)]	Loss: 0.681546
[2022-04-08 03:50:56 | train] - Train Epoch: [191] [38400/1281167 (3%)]	Loss: 0.773257
[2022-04-08 03:51:19 | train] - Train Epoch: [191] [51200/1281167 (4%)]	Loss: 0.664480
[2022-04-08 03:51:42 | train] - Train Epoch: [191] [64000/1281167 (5%)]	Loss: 0.743529
[2022-04-08 03:52:05 | train] - Train Epoch: [191] [76800/1281167 (6%)]	Loss: 0.493280
[2022-04-08 03:52:27 | train] - Train Epoch: [191] [89600/1281167 (7%)]	Loss: 0.824737
[2022-04-08 03:52:50 | train] - Train Epoch: [191] [102400/1281167 (8%)]	Loss: 0.666610
[2022-04-08 03:53:14 | train] - Train Epoch: [191] [115200/1281167 (9%)]	Loss: 0.757558
[2022-04-08 03:53:37 | train] - Train Epoch: [191] [128000/1281167 (10%)]	Loss: 0.629971
[2022-04-08 03:54:00 | train] - Train Epoch: [191] [140800/1281167 (11%)]	Loss: 0.752574
[2022-04-08 03:54:23 | train] - Train Epoch: [191] [153600/1281167 (12%)]	Loss: 0.923202
[2022-04-08 03:54:46 | train] - Train Epoch: [191] [166400/1281167 (13%)]	Loss: 0.580803
[2022-04-08 03:55:10 | train] - Train Epoch: [191] [179200/1281167 (14%)]	Loss: 0.892429
[2022-04-08 03:55:33 | train] - Train Epoch: [191] [192000/1281167 (15%)]	Loss: 0.881460
[2022-04-08 03:55:56 | train] - Train Epoch: [191] [204800/1281167 (16%)]	Loss: 0.566244
[2022-04-08 03:56:19 | train] - Train Epoch: [191] [217600/1281167 (17%)]	Loss: 0.635498
[2022-04-08 03:56:41 | train] - Train Epoch: [191] [230400/1281167 (18%)]	Loss: 1.062772
[2022-04-08 03:57:04 | train] - Train Epoch: [191] [243200/1281167 (19%)]	Loss: 1.003218
[2022-04-08 03:57:27 | train] - Train Epoch: [191] [256000/1281167 (20%)]	Loss: 0.642825
[2022-04-08 03:57:50 | train] - Train Epoch: [191] [268800/1281167 (21%)]	Loss: 0.888952
[2022-04-08 03:58:14 | train] - Train Epoch: [191] [281600/1281167 (22%)]	Loss: 0.779003
[2022-04-08 03:58:37 | train] - Train Epoch: [191] [294400/1281167 (23%)]	Loss: 0.735803
[2022-04-08 03:59:00 | train] - Train Epoch: [191] [307200/1281167 (24%)]	Loss: 0.647025
[2022-04-08 03:59:24 | train] - Train Epoch: [191] [320000/1281167 (25%)]	Loss: 0.667493
[2022-04-08 03:59:48 | train] - Train Epoch: [191] [332800/1281167 (26%)]	Loss: 0.715450
[2022-04-08 04:00:12 | train] - Train Epoch: [191] [345600/1281167 (27%)]	Loss: 0.864817
[2022-04-08 04:00:34 | train] - Train Epoch: [191] [358400/1281167 (28%)]	Loss: 0.593476
[2022-04-08 04:00:58 | train] - Train Epoch: [191] [371200/1281167 (29%)]	Loss: 0.762700
[2022-04-08 04:01:21 | train] - Train Epoch: [191] [384000/1281167 (30%)]	Loss: 0.835360
[2022-04-08 04:01:44 | train] - Train Epoch: [191] [396800/1281167 (31%)]	Loss: 0.707099
[2022-04-08 04:02:07 | train] - Train Epoch: [191] [409600/1281167 (32%)]	Loss: 0.620585
[2022-04-08 04:02:30 | train] - Train Epoch: [191] [422400/1281167 (33%)]	Loss: 0.725929
[2022-04-08 04:02:54 | train] - Train Epoch: [191] [435200/1281167 (34%)]	Loss: 0.631400
[2022-04-08 04:03:17 | train] - Train Epoch: [191] [448000/1281167 (35%)]	Loss: 0.703005
[2022-04-08 04:03:40 | train] - Train Epoch: [191] [460800/1281167 (36%)]	Loss: 0.612288
[2022-04-08 04:04:03 | train] - Train Epoch: [191] [473600/1281167 (37%)]	Loss: 0.857402
[2022-04-08 04:04:27 | train] - Train Epoch: [191] [486400/1281167 (38%)]	Loss: 0.949875
[2022-04-08 04:04:50 | train] - Train Epoch: [191] [499200/1281167 (39%)]	Loss: 0.900743
[2022-04-08 04:05:13 | train] - Train Epoch: [191] [512000/1281167 (40%)]	Loss: 0.730629
[2022-04-08 04:05:36 | train] - Train Epoch: [191] [524800/1281167 (41%)]	Loss: 0.910902
[2022-04-08 04:05:59 | train] - Train Epoch: [191] [537600/1281167 (42%)]	Loss: 0.795908
[2022-04-08 04:06:22 | train] - Train Epoch: [191] [550400/1281167 (43%)]	Loss: 1.057782
[2022-04-08 04:06:45 | train] - Train Epoch: [191] [563200/1281167 (44%)]	Loss: 0.619798
[2022-04-08 04:07:08 | train] - Train Epoch: [191] [576000/1281167 (45%)]	Loss: 0.575996
[2022-04-08 04:07:31 | train] - Train Epoch: [191] [588800/1281167 (46%)]	Loss: 0.664022
[2022-04-08 04:07:54 | train] - Train Epoch: [191] [601600/1281167 (47%)]	Loss: 0.732793
[2022-04-08 04:08:17 | train] - Train Epoch: [191] [614400/1281167 (48%)]	Loss: 0.988577
[2022-04-08 04:08:40 | train] - Train Epoch: [191] [627200/1281167 (49%)]	Loss: 0.633651
[2022-04-08 04:09:03 | train] - Train Epoch: [191] [640000/1281167 (50%)]	Loss: 0.783284
[2022-04-08 04:09:26 | train] - Train Epoch: [191] [652800/1281167 (51%)]	Loss: 0.865202
[2022-04-08 04:09:49 | train] - Train Epoch: [191] [665600/1281167 (52%)]	Loss: 0.792342
[2022-04-08 04:10:12 | train] - Train Epoch: [191] [678400/1281167 (53%)]	Loss: 0.707361
[2022-04-08 04:10:36 | train] - Train Epoch: [191] [691200/1281167 (54%)]	Loss: 0.884700
[2022-04-08 04:10:58 | train] - Train Epoch: [191] [704000/1281167 (55%)]	Loss: 0.737862
[2022-04-08 04:11:21 | train] - Train Epoch: [191] [716800/1281167 (56%)]	Loss: 0.942759
[2022-04-08 04:11:45 | train] - Train Epoch: [191] [729600/1281167 (57%)]	Loss: 0.634457
[2022-04-08 04:12:08 | train] - Train Epoch: [191] [742400/1281167 (58%)]	Loss: 0.669714
[2022-04-08 04:12:31 | train] - Train Epoch: [191] [755200/1281167 (59%)]	Loss: 0.553672
[2022-04-08 04:12:55 | train] - Train Epoch: [191] [768000/1281167 (60%)]	Loss: 0.567366
[2022-04-08 04:13:18 | train] - Train Epoch: [191] [780800/1281167 (61%)]	Loss: 0.709787
[2022-04-08 04:13:41 | train] - Train Epoch: [191] [793600/1281167 (62%)]	Loss: 0.701961
[2022-04-08 04:14:05 | train] - Train Epoch: [191] [806400/1281167 (63%)]	Loss: 0.851736
[2022-04-08 04:14:28 | train] - Train Epoch: [191] [819200/1281167 (64%)]	Loss: 0.736205
[2022-04-08 04:14:51 | train] - Train Epoch: [191] [832000/1281167 (65%)]	Loss: 1.099247
[2022-04-08 04:15:14 | train] - Train Epoch: [191] [844800/1281167 (66%)]	Loss: 0.863421
[2022-04-08 04:15:37 | train] - Train Epoch: [191] [857600/1281167 (67%)]	Loss: 0.769932
[2022-04-08 04:16:01 | train] - Train Epoch: [191] [870400/1281167 (68%)]	Loss: 0.896613
[2022-04-08 04:16:24 | train] - Train Epoch: [191] [883200/1281167 (69%)]	Loss: 0.900688
[2022-04-08 04:16:48 | train] - Train Epoch: [191] [896000/1281167 (70%)]	Loss: 0.683469
[2022-04-08 04:17:11 | train] - Train Epoch: [191] [908800/1281167 (71%)]	Loss: 0.887649
[2022-04-08 04:17:35 | train] - Train Epoch: [191] [921600/1281167 (72%)]	Loss: 1.062724
[2022-04-08 04:17:58 | train] - Train Epoch: [191] [934400/1281167 (73%)]	Loss: 0.766750
[2022-04-08 04:18:21 | train] - Train Epoch: [191] [947200/1281167 (74%)]	Loss: 0.591215
[2022-04-08 04:18:45 | train] - Train Epoch: [191] [960000/1281167 (75%)]	Loss: 0.712271
[2022-04-08 04:19:08 | train] - Train Epoch: [191] [972800/1281167 (76%)]	Loss: 0.864065
[2022-04-08 04:19:31 | train] - Train Epoch: [191] [985600/1281167 (77%)]	Loss: 0.749736
[2022-04-08 04:19:54 | train] - Train Epoch: [191] [998400/1281167 (78%)]	Loss: 0.784022
[2022-04-08 04:20:17 | train] - Train Epoch: [191] [1011200/1281167 (79%)]	Loss: 0.858457
[2022-04-08 04:20:41 | train] - Train Epoch: [191] [1024000/1281167 (80%)]	Loss: 0.754554
[2022-04-08 04:21:04 | train] - Train Epoch: [191] [1036800/1281167 (81%)]	Loss: 0.844234
[2022-04-08 04:21:27 | train] - Train Epoch: [191] [1049600/1281167 (82%)]	Loss: 0.532409
[2022-04-08 04:21:50 | train] - Train Epoch: [191] [1062400/1281167 (83%)]	Loss: 0.873983
[2022-04-08 04:22:13 | train] - Train Epoch: [191] [1075200/1281167 (84%)]	Loss: 0.981835
[2022-04-08 04:22:36 | train] - Train Epoch: [191] [1088000/1281167 (85%)]	Loss: 0.785592
[2022-04-08 04:22:59 | train] - Train Epoch: [191] [1100800/1281167 (86%)]	Loss: 0.609404
[2022-04-08 04:23:21 | train] - Train Epoch: [191] [1113600/1281167 (87%)]	Loss: 0.643962
[2022-04-08 04:23:44 | train] - Train Epoch: [191] [1126400/1281167 (88%)]	Loss: 0.797047
[2022-04-08 04:24:07 | train] - Train Epoch: [191] [1139200/1281167 (89%)]	Loss: 0.753797
[2022-04-08 04:24:31 | train] - Train Epoch: [191] [1152000/1281167 (90%)]	Loss: 0.797486
[2022-04-08 04:24:54 | train] - Train Epoch: [191] [1164800/1281167 (91%)]	Loss: 0.896659
[2022-04-08 04:25:17 | train] - Train Epoch: [191] [1177600/1281167 (92%)]	Loss: 0.980134
[2022-04-08 04:25:40 | train] - Train Epoch: [191] [1190400/1281167 (93%)]	Loss: 0.736181
[2022-04-08 04:26:03 | train] - Train Epoch: [191] [1203200/1281167 (94%)]	Loss: 0.744443
[2022-04-08 04:26:26 | train] - Train Epoch: [191] [1216000/1281167 (95%)]	Loss: 0.934825
[2022-04-08 04:26:49 | train] - Train Epoch: [191] [1228800/1281167 (96%)]	Loss: 0.907933
[2022-04-08 04:27:13 | train] - Train Epoch: [191] [1241600/1281167 (97%)]	Loss: 0.843593
[2022-04-08 04:27:37 | train] - Train Epoch: [191] [1254400/1281167 (98%)]	Loss: 0.779720
[2022-04-08 04:28:01 | train] - Train Epoch: [191] [1267200/1281167 (99%)]	Loss: 0.696677
[2022-04-08 04:28:24 | train] - Train Epoch: [191] [1280000/1281167 (100%)]	Loss: 1.071893
[2022-04-08 04:28:26 | train] - Train Epoch: [191]	 Average Loss: 0.757760	 Total Acc : 81.4795	 Total Top5 Acc : 93.2557
[2022-04-08 04:28:26 | train] - -------191 epoch end-----------
========================================
-------191 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 04:30:05 | train] - 
Epoch [191] Test set: Average loss: 1.4558, Accuracy: 34882/50000 (69.7379%), Top-5 Accuracy: 88.8091%

[2022-04-08 04:30:05 | train] - save intermediate epoch [191] result


[2022-04-08 04:30:32 | train] - -------192 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 04:30:33 | train] - Train Epoch: [192] [0/1281167 (0%)]	Loss: 0.896235
[2022-04-08 04:30:59 | train] - Train Epoch: [192] [12800/1281167 (1%)]	Loss: 0.758232
[2022-04-08 04:31:24 | train] - Train Epoch: [192] [25600/1281167 (2%)]	Loss: 0.843218
[2022-04-08 04:31:49 | train] - Train Epoch: [192] [38400/1281167 (3%)]	Loss: 0.640460
[2022-04-08 04:32:14 | train] - Train Epoch: [192] [51200/1281167 (4%)]	Loss: 1.000762
[2022-04-08 04:32:40 | train] - Train Epoch: [192] [64000/1281167 (5%)]	Loss: 0.847372
[2022-04-08 04:33:03 | train] - Train Epoch: [192] [76800/1281167 (6%)]	Loss: 0.695042
[2022-04-08 04:33:28 | train] - Train Epoch: [192] [89600/1281167 (7%)]	Loss: 0.799738
[2022-04-08 04:33:52 | train] - Train Epoch: [192] [102400/1281167 (8%)]	Loss: 0.936969
[2022-04-08 04:34:16 | train] - Train Epoch: [192] [115200/1281167 (9%)]	Loss: 0.842405
[2022-04-08 04:34:41 | train] - Train Epoch: [192] [128000/1281167 (10%)]	Loss: 0.776614
[2022-04-08 04:35:05 | train] - Train Epoch: [192] [140800/1281167 (11%)]	Loss: 0.737502
[2022-04-08 04:35:30 | train] - Train Epoch: [192] [153600/1281167 (12%)]	Loss: 0.770740
[2022-04-08 04:35:54 | train] - Train Epoch: [192] [166400/1281167 (13%)]	Loss: 0.691210
[2022-04-08 04:36:17 | train] - Train Epoch: [192] [179200/1281167 (14%)]	Loss: 0.893147
[2022-04-08 04:36:42 | train] - Train Epoch: [192] [192000/1281167 (15%)]	Loss: 0.793883
[2022-04-08 04:37:07 | train] - Train Epoch: [192] [204800/1281167 (16%)]	Loss: 1.046846
[2022-04-08 04:37:31 | train] - Train Epoch: [192] [217600/1281167 (17%)]	Loss: 0.668661
[2022-04-08 04:37:56 | train] - Train Epoch: [192] [230400/1281167 (18%)]	Loss: 0.772630
[2022-04-08 04:38:19 | train] - Train Epoch: [192] [243200/1281167 (19%)]	Loss: 0.752746
[2022-04-08 04:38:44 | train] - Train Epoch: [192] [256000/1281167 (20%)]	Loss: 0.900724
[2022-04-08 04:39:07 | train] - Train Epoch: [192] [268800/1281167 (21%)]	Loss: 0.822863
[2022-04-08 04:39:31 | train] - Train Epoch: [192] [281600/1281167 (22%)]	Loss: 0.808919
[2022-04-08 04:39:55 | train] - Train Epoch: [192] [294400/1281167 (23%)]	Loss: 0.832474
[2022-04-08 04:40:20 | train] - Train Epoch: [192] [307200/1281167 (24%)]	Loss: 0.701037
[2022-04-08 04:40:43 | train] - Train Epoch: [192] [320000/1281167 (25%)]	Loss: 0.734152
[2022-04-08 04:41:08 | train] - Train Epoch: [192] [332800/1281167 (26%)]	Loss: 0.871113
[2022-04-08 04:41:32 | train] - Train Epoch: [192] [345600/1281167 (27%)]	Loss: 0.708635
[2022-04-08 04:41:57 | train] - Train Epoch: [192] [358400/1281167 (28%)]	Loss: 0.571074
[2022-04-08 04:42:21 | train] - Train Epoch: [192] [371200/1281167 (29%)]	Loss: 0.794379
[2022-04-08 04:42:45 | train] - Train Epoch: [192] [384000/1281167 (30%)]	Loss: 1.032659
[2022-04-08 04:43:09 | train] - Train Epoch: [192] [396800/1281167 (31%)]	Loss: 0.818005
[2022-04-08 04:43:33 | train] - Train Epoch: [192] [409600/1281167 (32%)]	Loss: 0.597427
[2022-04-08 04:43:57 | train] - Train Epoch: [192] [422400/1281167 (33%)]	Loss: 0.846939
[2022-04-08 04:44:21 | train] - Train Epoch: [192] [435200/1281167 (34%)]	Loss: 0.806516
[2022-04-08 04:44:46 | train] - Train Epoch: [192] [448000/1281167 (35%)]	Loss: 0.678997
[2022-04-08 04:45:10 | train] - Train Epoch: [192] [460800/1281167 (36%)]	Loss: 0.736142
[2022-04-08 04:45:34 | train] - Train Epoch: [192] [473600/1281167 (37%)]	Loss: 0.884665
[2022-04-08 04:45:59 | train] - Train Epoch: [192] [486400/1281167 (38%)]	Loss: 0.782530
[2022-04-08 04:46:23 | train] - Train Epoch: [192] [499200/1281167 (39%)]	Loss: 0.877075
[2022-04-08 04:46:47 | train] - Train Epoch: [192] [512000/1281167 (40%)]	Loss: 0.914486
[2022-04-08 04:47:11 | train] - Train Epoch: [192] [524800/1281167 (41%)]	Loss: 0.912652
[2022-04-08 04:47:35 | train] - Train Epoch: [192] [537600/1281167 (42%)]	Loss: 0.627775
[2022-04-08 04:47:59 | train] - Train Epoch: [192] [550400/1281167 (43%)]	Loss: 0.718941
[2022-04-08 04:48:24 | train] - Train Epoch: [192] [563200/1281167 (44%)]	Loss: 0.589707
[2022-04-08 04:48:48 | train] - Train Epoch: [192] [576000/1281167 (45%)]	Loss: 0.830866
[2022-04-08 04:49:13 | train] - Train Epoch: [192] [588800/1281167 (46%)]	Loss: 0.605339
[2022-04-08 04:49:37 | train] - Train Epoch: [192] [601600/1281167 (47%)]	Loss: 1.024794
[2022-04-08 04:50:01 | train] - Train Epoch: [192] [614400/1281167 (48%)]	Loss: 0.889547
[2022-04-08 04:50:25 | train] - Train Epoch: [192] [627200/1281167 (49%)]	Loss: 0.890647
[2022-04-08 04:50:50 | train] - Train Epoch: [192] [640000/1281167 (50%)]	Loss: 0.737969
[2022-04-08 04:51:14 | train] - Train Epoch: [192] [652800/1281167 (51%)]	Loss: 0.744503
[2022-04-08 04:51:38 | train] - Train Epoch: [192] [665600/1281167 (52%)]	Loss: 0.863195
[2022-04-08 04:52:02 | train] - Train Epoch: [192] [678400/1281167 (53%)]	Loss: 0.672132
[2022-04-08 04:52:26 | train] - Train Epoch: [192] [691200/1281167 (54%)]	Loss: 0.838586
[2022-04-08 04:52:50 | train] - Train Epoch: [192] [704000/1281167 (55%)]	Loss: 0.699931
[2022-04-08 04:53:14 | train] - Train Epoch: [192] [716800/1281167 (56%)]	Loss: 0.914963
[2022-04-08 04:53:39 | train] - Train Epoch: [192] [729600/1281167 (57%)]	Loss: 0.967812
[2022-04-08 04:54:03 | train] - Train Epoch: [192] [742400/1281167 (58%)]	Loss: 0.700470
[2022-04-08 04:54:28 | train] - Train Epoch: [192] [755200/1281167 (59%)]	Loss: 1.061991
[2022-04-08 04:54:52 | train] - Train Epoch: [192] [768000/1281167 (60%)]	Loss: 1.125147
[2022-04-08 04:55:16 | train] - Train Epoch: [192] [780800/1281167 (61%)]	Loss: 0.599852
[2022-04-08 04:55:40 | train] - Train Epoch: [192] [793600/1281167 (62%)]	Loss: 0.819166
[2022-04-08 04:56:04 | train] - Train Epoch: [192] [806400/1281167 (63%)]	Loss: 0.914474
[2022-04-08 04:56:29 | train] - Train Epoch: [192] [819200/1281167 (64%)]	Loss: 0.983515
[2022-04-08 04:56:52 | train] - Train Epoch: [192] [832000/1281167 (65%)]	Loss: 0.861996
[2022-04-08 04:57:16 | train] - Train Epoch: [192] [844800/1281167 (66%)]	Loss: 0.767719
[2022-04-08 04:57:40 | train] - Train Epoch: [192] [857600/1281167 (67%)]	Loss: 0.755809
[2022-04-08 04:58:03 | train] - Train Epoch: [192] [870400/1281167 (68%)]	Loss: 0.684802
[2022-04-08 04:58:27 | train] - Train Epoch: [192] [883200/1281167 (69%)]	Loss: 1.009035
[2022-04-08 04:58:51 | train] - Train Epoch: [192] [896000/1281167 (70%)]	Loss: 0.880906
[2022-04-08 04:59:14 | train] - Train Epoch: [192] [908800/1281167 (71%)]	Loss: 0.696600
[2022-04-08 04:59:37 | train] - Train Epoch: [192] [921600/1281167 (72%)]	Loss: 0.912977
[2022-04-08 05:00:01 | train] - Train Epoch: [192] [934400/1281167 (73%)]	Loss: 1.304759
[2022-04-08 05:00:24 | train] - Train Epoch: [192] [947200/1281167 (74%)]	Loss: 0.760813
[2022-04-08 05:00:47 | train] - Train Epoch: [192] [960000/1281167 (75%)]	Loss: 0.808197
[2022-04-08 05:01:10 | train] - Train Epoch: [192] [972800/1281167 (76%)]	Loss: 0.918580
[2022-04-08 05:01:35 | train] - Train Epoch: [192] [985600/1281167 (77%)]	Loss: 0.748176
[2022-04-08 05:01:58 | train] - Train Epoch: [192] [998400/1281167 (78%)]	Loss: 0.996199
[2022-04-08 05:02:22 | train] - Train Epoch: [192] [1011200/1281167 (79%)]	Loss: 0.729886
[2022-04-08 05:02:45 | train] - Train Epoch: [192] [1024000/1281167 (80%)]	Loss: 0.952659
[2022-04-08 05:03:08 | train] - Train Epoch: [192] [1036800/1281167 (81%)]	Loss: 0.754603
[2022-04-08 05:03:32 | train] - Train Epoch: [192] [1049600/1281167 (82%)]	Loss: 0.483219
[2022-04-08 05:03:55 | train] - Train Epoch: [192] [1062400/1281167 (83%)]	Loss: 0.574355
[2022-04-08 05:04:19 | train] - Train Epoch: [192] [1075200/1281167 (84%)]	Loss: 0.882501
[2022-04-08 05:04:43 | train] - Train Epoch: [192] [1088000/1281167 (85%)]	Loss: 0.891982
[2022-04-08 05:05:06 | train] - Train Epoch: [192] [1100800/1281167 (86%)]	Loss: 0.830977
[2022-04-08 05:05:29 | train] - Train Epoch: [192] [1113600/1281167 (87%)]	Loss: 1.029733
[2022-04-08 05:05:53 | train] - Train Epoch: [192] [1126400/1281167 (88%)]	Loss: 0.705993
[2022-04-08 05:06:16 | train] - Train Epoch: [192] [1139200/1281167 (89%)]	Loss: 0.626413
[2022-04-08 05:06:40 | train] - Train Epoch: [192] [1152000/1281167 (90%)]	Loss: 0.850119
[2022-04-08 05:07:03 | train] - Train Epoch: [192] [1164800/1281167 (91%)]	Loss: 0.531160
[2022-04-08 05:07:27 | train] - Train Epoch: [192] [1177600/1281167 (92%)]	Loss: 0.657485
[2022-04-08 05:07:50 | train] - Train Epoch: [192] [1190400/1281167 (93%)]	Loss: 0.759204
[2022-04-08 05:08:13 | train] - Train Epoch: [192] [1203200/1281167 (94%)]	Loss: 0.684951
[2022-04-08 05:08:36 | train] - Train Epoch: [192] [1216000/1281167 (95%)]	Loss: 0.686871
[2022-04-08 05:09:00 | train] - Train Epoch: [192] [1228800/1281167 (96%)]	Loss: 0.924742
[2022-04-08 05:09:24 | train] - Train Epoch: [192] [1241600/1281167 (97%)]	Loss: 0.818180
[2022-04-08 05:09:47 | train] - Train Epoch: [192] [1254400/1281167 (98%)]	Loss: 0.912685
[2022-04-08 05:10:11 | train] - Train Epoch: [192] [1267200/1281167 (99%)]	Loss: 0.596840
[2022-04-08 05:10:34 | train] - Train Epoch: [192] [1280000/1281167 (100%)]	Loss: 0.713962
[2022-04-08 05:10:36 | train] - Train Epoch: [192]	 Average Loss: 0.756684	 Total Acc : 81.5285	 Total Top5 Acc : 93.2538
[2022-04-08 05:10:36 | train] - -------192 epoch end-----------
========================================
-------192 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 05:12:17 | train] - 
Epoch [192] Test set: Average loss: 1.4600, Accuracy: 34864/50000 (69.6995%), Top-5 Accuracy: 88.7340%

[2022-04-08 05:12:17 | train] - save intermediate epoch [192] result


[2022-04-08 05:12:44 | train] - -------193 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 05:12:45 | train] - Train Epoch: [193] [0/1281167 (0%)]	Loss: 0.608319
[2022-04-08 05:13:08 | train] - Train Epoch: [193] [12800/1281167 (1%)]	Loss: 0.908667
[2022-04-08 05:13:31 | train] - Train Epoch: [193] [25600/1281167 (2%)]	Loss: 0.879798
[2022-04-08 05:13:55 | train] - Train Epoch: [193] [38400/1281167 (3%)]	Loss: 0.767187
[2022-04-08 05:14:18 | train] - Train Epoch: [193] [51200/1281167 (4%)]	Loss: 0.759973
[2022-04-08 05:14:42 | train] - Train Epoch: [193] [64000/1281167 (5%)]	Loss: 1.068503
[2022-04-08 05:15:05 | train] - Train Epoch: [193] [76800/1281167 (6%)]	Loss: 0.785615
[2022-04-08 05:15:29 | train] - Train Epoch: [193] [89600/1281167 (7%)]	Loss: 1.005253
[2022-04-08 05:15:53 | train] - Train Epoch: [193] [102400/1281167 (8%)]	Loss: 0.608427
[2022-04-08 05:16:16 | train] - Train Epoch: [193] [115200/1281167 (9%)]	Loss: 0.655280
[2022-04-08 05:16:40 | train] - Train Epoch: [193] [128000/1281167 (10%)]	Loss: 0.629200
[2022-04-08 05:17:03 | train] - Train Epoch: [193] [140800/1281167 (11%)]	Loss: 0.774535
[2022-04-08 05:17:26 | train] - Train Epoch: [193] [153600/1281167 (12%)]	Loss: 0.734309
[2022-04-08 05:17:50 | train] - Train Epoch: [193] [166400/1281167 (13%)]	Loss: 0.474996
[2022-04-08 05:18:14 | train] - Train Epoch: [193] [179200/1281167 (14%)]	Loss: 0.795707
[2022-04-08 05:18:37 | train] - Train Epoch: [193] [192000/1281167 (15%)]	Loss: 0.733567
[2022-04-08 05:19:01 | train] - Train Epoch: [193] [204800/1281167 (16%)]	Loss: 0.808199
[2022-04-08 05:19:24 | train] - Train Epoch: [193] [217600/1281167 (17%)]	Loss: 0.792483
[2022-04-08 05:19:47 | train] - Train Epoch: [193] [230400/1281167 (18%)]	Loss: 0.590672
[2022-04-08 05:20:11 | train] - Train Epoch: [193] [243200/1281167 (19%)]	Loss: 0.806184
[2022-04-08 05:20:35 | train] - Train Epoch: [193] [256000/1281167 (20%)]	Loss: 0.911704
[2022-04-08 05:20:58 | train] - Train Epoch: [193] [268800/1281167 (21%)]	Loss: 0.690792
[2022-04-08 05:21:22 | train] - Train Epoch: [193] [281600/1281167 (22%)]	Loss: 0.693983
[2022-04-08 05:21:46 | train] - Train Epoch: [193] [294400/1281167 (23%)]	Loss: 0.861283
[2022-04-08 05:22:09 | train] - Train Epoch: [193] [307200/1281167 (24%)]	Loss: 0.716825
[2022-04-08 05:22:33 | train] - Train Epoch: [193] [320000/1281167 (25%)]	Loss: 0.707355
[2022-04-08 05:22:57 | train] - Train Epoch: [193] [332800/1281167 (26%)]	Loss: 0.689692
[2022-04-08 05:23:20 | train] - Train Epoch: [193] [345600/1281167 (27%)]	Loss: 0.814724
[2022-04-08 05:23:44 | train] - Train Epoch: [193] [358400/1281167 (28%)]	Loss: 0.756283
[2022-04-08 05:24:08 | train] - Train Epoch: [193] [371200/1281167 (29%)]	Loss: 0.846255
[2022-04-08 05:24:31 | train] - Train Epoch: [193] [384000/1281167 (30%)]	Loss: 0.699537
[2022-04-08 05:24:54 | train] - Train Epoch: [193] [396800/1281167 (31%)]	Loss: 0.919595
[2022-04-08 05:25:17 | train] - Train Epoch: [193] [409600/1281167 (32%)]	Loss: 0.925783
[2022-04-08 05:25:41 | train] - Train Epoch: [193] [422400/1281167 (33%)]	Loss: 0.691182
[2022-04-08 05:26:04 | train] - Train Epoch: [193] [435200/1281167 (34%)]	Loss: 0.809955
[2022-04-08 05:26:27 | train] - Train Epoch: [193] [448000/1281167 (35%)]	Loss: 0.806737
[2022-04-08 05:26:51 | train] - Train Epoch: [193] [460800/1281167 (36%)]	Loss: 0.750736
[2022-04-08 05:27:14 | train] - Train Epoch: [193] [473600/1281167 (37%)]	Loss: 0.634680
[2022-04-08 05:27:38 | train] - Train Epoch: [193] [486400/1281167 (38%)]	Loss: 0.728349
[2022-04-08 05:28:02 | train] - Train Epoch: [193] [499200/1281167 (39%)]	Loss: 0.814774
[2022-04-08 05:28:25 | train] - Train Epoch: [193] [512000/1281167 (40%)]	Loss: 0.742546
[2022-04-08 05:28:49 | train] - Train Epoch: [193] [524800/1281167 (41%)]	Loss: 0.568149
[2022-04-08 05:29:12 | train] - Train Epoch: [193] [537600/1281167 (42%)]	Loss: 0.727202
[2022-04-08 05:29:36 | train] - Train Epoch: [193] [550400/1281167 (43%)]	Loss: 0.601739
[2022-04-08 05:29:59 | train] - Train Epoch: [193] [563200/1281167 (44%)]	Loss: 0.629184
[2022-04-08 05:30:22 | train] - Train Epoch: [193] [576000/1281167 (45%)]	Loss: 0.779502
[2022-04-08 05:30:46 | train] - Train Epoch: [193] [588800/1281167 (46%)]	Loss: 0.915002
[2022-04-08 05:31:10 | train] - Train Epoch: [193] [601600/1281167 (47%)]	Loss: 0.762795
[2022-04-08 05:31:33 | train] - Train Epoch: [193] [614400/1281167 (48%)]	Loss: 0.888510
[2022-04-08 05:31:57 | train] - Train Epoch: [193] [627200/1281167 (49%)]	Loss: 0.611247
[2022-04-08 05:32:20 | train] - Train Epoch: [193] [640000/1281167 (50%)]	Loss: 0.685215
[2022-04-08 05:32:44 | train] - Train Epoch: [193] [652800/1281167 (51%)]	Loss: 0.796950
[2022-04-08 05:33:08 | train] - Train Epoch: [193] [665600/1281167 (52%)]	Loss: 0.608794
[2022-04-08 05:33:31 | train] - Train Epoch: [193] [678400/1281167 (53%)]	Loss: 0.893462
[2022-04-08 05:33:55 | train] - Train Epoch: [193] [691200/1281167 (54%)]	Loss: 0.784632
[2022-04-08 05:34:18 | train] - Train Epoch: [193] [704000/1281167 (55%)]	Loss: 0.717378
[2022-04-08 05:34:42 | train] - Train Epoch: [193] [716800/1281167 (56%)]	Loss: 0.790807
[2022-04-08 05:35:05 | train] - Train Epoch: [193] [729600/1281167 (57%)]	Loss: 0.989145
[2022-04-08 05:35:28 | train] - Train Epoch: [193] [742400/1281167 (58%)]	Loss: 0.612744
[2022-04-08 05:35:52 | train] - Train Epoch: [193] [755200/1281167 (59%)]	Loss: 1.022372
[2022-04-08 05:36:15 | train] - Train Epoch: [193] [768000/1281167 (60%)]	Loss: 1.130876
[2022-04-08 05:36:38 | train] - Train Epoch: [193] [780800/1281167 (61%)]	Loss: 0.724089
[2022-04-08 05:37:01 | train] - Train Epoch: [193] [793600/1281167 (62%)]	Loss: 0.801354
[2022-04-08 05:37:25 | train] - Train Epoch: [193] [806400/1281167 (63%)]	Loss: 0.863222
[2022-04-08 05:37:48 | train] - Train Epoch: [193] [819200/1281167 (64%)]	Loss: 0.683361
[2022-04-08 05:38:11 | train] - Train Epoch: [193] [832000/1281167 (65%)]	Loss: 0.680249
[2022-04-08 05:38:35 | train] - Train Epoch: [193] [844800/1281167 (66%)]	Loss: 0.699519
[2022-04-08 05:38:59 | train] - Train Epoch: [193] [857600/1281167 (67%)]	Loss: 0.821339
[2022-04-08 05:39:22 | train] - Train Epoch: [193] [870400/1281167 (68%)]	Loss: 0.752583
[2022-04-08 05:39:45 | train] - Train Epoch: [193] [883200/1281167 (69%)]	Loss: 0.808011
[2022-04-08 05:40:09 | train] - Train Epoch: [193] [896000/1281167 (70%)]	Loss: 0.924292
[2022-04-08 05:40:31 | train] - Train Epoch: [193] [908800/1281167 (71%)]	Loss: 0.724972
[2022-04-08 05:40:55 | train] - Train Epoch: [193] [921600/1281167 (72%)]	Loss: 0.897545
[2022-04-08 05:41:18 | train] - Train Epoch: [193] [934400/1281167 (73%)]	Loss: 0.673344
[2022-04-08 05:41:43 | train] - Train Epoch: [193] [947200/1281167 (74%)]	Loss: 0.818023
[2022-04-08 05:42:06 | train] - Train Epoch: [193] [960000/1281167 (75%)]	Loss: 0.601264
[2022-04-08 05:42:29 | train] - Train Epoch: [193] [972800/1281167 (76%)]	Loss: 0.955603
[2022-04-08 05:42:52 | train] - Train Epoch: [193] [985600/1281167 (77%)]	Loss: 0.617608
[2022-04-08 05:43:15 | train] - Train Epoch: [193] [998400/1281167 (78%)]	Loss: 0.636724
[2022-04-08 05:43:38 | train] - Train Epoch: [193] [1011200/1281167 (79%)]	Loss: 0.901420
[2022-04-08 05:44:01 | train] - Train Epoch: [193] [1024000/1281167 (80%)]	Loss: 0.827944
[2022-04-08 05:44:24 | train] - Train Epoch: [193] [1036800/1281167 (81%)]	Loss: 0.710882
[2022-04-08 05:44:47 | train] - Train Epoch: [193] [1049600/1281167 (82%)]	Loss: 0.996058
[2022-04-08 05:45:11 | train] - Train Epoch: [193] [1062400/1281167 (83%)]	Loss: 0.617167
[2022-04-08 05:45:34 | train] - Train Epoch: [193] [1075200/1281167 (84%)]	Loss: 0.801241
[2022-04-08 05:45:57 | train] - Train Epoch: [193] [1088000/1281167 (85%)]	Loss: 0.713805
[2022-04-08 05:46:21 | train] - Train Epoch: [193] [1100800/1281167 (86%)]	Loss: 0.819948
[2022-04-08 05:46:44 | train] - Train Epoch: [193] [1113600/1281167 (87%)]	Loss: 0.775517
[2022-04-08 05:47:07 | train] - Train Epoch: [193] [1126400/1281167 (88%)]	Loss: 0.872169
[2022-04-08 05:47:30 | train] - Train Epoch: [193] [1139200/1281167 (89%)]	Loss: 0.794770
[2022-04-08 05:47:53 | train] - Train Epoch: [193] [1152000/1281167 (90%)]	Loss: 0.929783
[2022-04-08 05:48:16 | train] - Train Epoch: [193] [1164800/1281167 (91%)]	Loss: 0.740388
[2022-04-08 05:48:39 | train] - Train Epoch: [193] [1177600/1281167 (92%)]	Loss: 0.771638
[2022-04-08 05:49:03 | train] - Train Epoch: [193] [1190400/1281167 (93%)]	Loss: 0.566650
[2022-04-08 05:49:26 | train] - Train Epoch: [193] [1203200/1281167 (94%)]	Loss: 0.602493
[2022-04-08 05:49:49 | train] - Train Epoch: [193] [1216000/1281167 (95%)]	Loss: 0.762899
[2022-04-08 05:50:12 | train] - Train Epoch: [193] [1228800/1281167 (96%)]	Loss: 0.823926
[2022-04-08 05:50:36 | train] - Train Epoch: [193] [1241600/1281167 (97%)]	Loss: 0.930643
[2022-04-08 05:50:59 | train] - Train Epoch: [193] [1254400/1281167 (98%)]	Loss: 0.817185
[2022-04-08 05:51:22 | train] - Train Epoch: [193] [1267200/1281167 (99%)]	Loss: 0.845318
[2022-04-08 05:51:45 | train] - Train Epoch: [193] [1280000/1281167 (100%)]	Loss: 0.926040
[2022-04-08 05:51:47 | train] - Train Epoch: [193]	 Average Loss: 0.754130	 Total Acc : 81.6224	 Total Top5 Acc : 93.2843
[2022-04-08 05:51:47 | train] - -------193 epoch end-----------
========================================
-------193 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 05:53:27 | train] - 
Epoch [193] Test set: Average loss: 1.4570, Accuracy: 34943/50000 (69.8573%), Top-5 Accuracy: 88.7520%

[2022-04-08 05:53:27 | train] - save intermediate epoch [193] result


[2022-04-08 05:53:54 | train] - -------194 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 05:53:55 | train] - Train Epoch: [194] [0/1281167 (0%)]	Loss: 0.923394
[2022-04-08 05:54:18 | train] - Train Epoch: [194] [12800/1281167 (1%)]	Loss: 0.643005
[2022-04-08 05:54:42 | train] - Train Epoch: [194] [25600/1281167 (2%)]	Loss: 0.740252
[2022-04-08 05:55:05 | train] - Train Epoch: [194] [38400/1281167 (3%)]	Loss: 0.468253
[2022-04-08 05:55:28 | train] - Train Epoch: [194] [51200/1281167 (4%)]	Loss: 0.762277
[2022-04-08 05:55:52 | train] - Train Epoch: [194] [64000/1281167 (5%)]	Loss: 0.808135
[2022-04-08 05:56:15 | train] - Train Epoch: [194] [76800/1281167 (6%)]	Loss: 0.743536
[2022-04-08 05:56:38 | train] - Train Epoch: [194] [89600/1281167 (7%)]	Loss: 0.835493
[2022-04-08 05:57:01 | train] - Train Epoch: [194] [102400/1281167 (8%)]	Loss: 0.712751
[2022-04-08 05:57:25 | train] - Train Epoch: [194] [115200/1281167 (9%)]	Loss: 0.666865
[2022-04-08 05:57:48 | train] - Train Epoch: [194] [128000/1281167 (10%)]	Loss: 0.720289
[2022-04-08 05:58:11 | train] - Train Epoch: [194] [140800/1281167 (11%)]	Loss: 0.920337
[2022-04-08 05:58:34 | train] - Train Epoch: [194] [153600/1281167 (12%)]	Loss: 0.779069
[2022-04-08 05:58:57 | train] - Train Epoch: [194] [166400/1281167 (13%)]	Loss: 0.809400
[2022-04-08 05:59:20 | train] - Train Epoch: [194] [179200/1281167 (14%)]	Loss: 0.712756
[2022-04-08 05:59:43 | train] - Train Epoch: [194] [192000/1281167 (15%)]	Loss: 0.545271
[2022-04-08 06:00:07 | train] - Train Epoch: [194] [204800/1281167 (16%)]	Loss: 0.754597
[2022-04-08 06:00:29 | train] - Train Epoch: [194] [217600/1281167 (17%)]	Loss: 0.724050
[2022-04-08 06:00:52 | train] - Train Epoch: [194] [230400/1281167 (18%)]	Loss: 0.783090
[2022-04-08 06:01:16 | train] - Train Epoch: [194] [243200/1281167 (19%)]	Loss: 0.595212
[2022-04-08 06:01:39 | train] - Train Epoch: [194] [256000/1281167 (20%)]	Loss: 0.811374
[2022-04-08 06:02:02 | train] - Train Epoch: [194] [268800/1281167 (21%)]	Loss: 0.726510
[2022-04-08 06:02:26 | train] - Train Epoch: [194] [281600/1281167 (22%)]	Loss: 0.673917
[2022-04-08 06:02:49 | train] - Train Epoch: [194] [294400/1281167 (23%)]	Loss: 0.752477
[2022-04-08 06:03:12 | train] - Train Epoch: [194] [307200/1281167 (24%)]	Loss: 0.772318
[2022-04-08 06:03:35 | train] - Train Epoch: [194] [320000/1281167 (25%)]	Loss: 0.762582
[2022-04-08 06:03:58 | train] - Train Epoch: [194] [332800/1281167 (26%)]	Loss: 0.776037
[2022-04-08 06:04:22 | train] - Train Epoch: [194] [345600/1281167 (27%)]	Loss: 0.716001
[2022-04-08 06:04:45 | train] - Train Epoch: [194] [358400/1281167 (28%)]	Loss: 0.694782
[2022-04-08 06:05:08 | train] - Train Epoch: [194] [371200/1281167 (29%)]	Loss: 0.648086
[2022-04-08 06:05:32 | train] - Train Epoch: [194] [384000/1281167 (30%)]	Loss: 0.540304
[2022-04-08 06:05:55 | train] - Train Epoch: [194] [396800/1281167 (31%)]	Loss: 0.748970
[2022-04-08 06:06:18 | train] - Train Epoch: [194] [409600/1281167 (32%)]	Loss: 0.729300
[2022-04-08 06:06:41 | train] - Train Epoch: [194] [422400/1281167 (33%)]	Loss: 0.961929
[2022-04-08 06:07:04 | train] - Train Epoch: [194] [435200/1281167 (34%)]	Loss: 0.725140
[2022-04-08 06:07:27 | train] - Train Epoch: [194] [448000/1281167 (35%)]	Loss: 0.495817
[2022-04-08 06:07:50 | train] - Train Epoch: [194] [460800/1281167 (36%)]	Loss: 0.798286
[2022-04-08 06:08:13 | train] - Train Epoch: [194] [473600/1281167 (37%)]	Loss: 0.922891
[2022-04-08 06:08:36 | train] - Train Epoch: [194] [486400/1281167 (38%)]	Loss: 0.774305
[2022-04-08 06:09:00 | train] - Train Epoch: [194] [499200/1281167 (39%)]	Loss: 0.698323
[2022-04-08 06:09:23 | train] - Train Epoch: [194] [512000/1281167 (40%)]	Loss: 0.556682
[2022-04-08 06:09:46 | train] - Train Epoch: [194] [524800/1281167 (41%)]	Loss: 0.851253
[2022-04-08 06:10:09 | train] - Train Epoch: [194] [537600/1281167 (42%)]	Loss: 0.571786
[2022-04-08 06:10:32 | train] - Train Epoch: [194] [550400/1281167 (43%)]	Loss: 0.554699
[2022-04-08 06:10:55 | train] - Train Epoch: [194] [563200/1281167 (44%)]	Loss: 0.815416
[2022-04-08 06:11:18 | train] - Train Epoch: [194] [576000/1281167 (45%)]	Loss: 0.519267
[2022-04-08 06:11:41 | train] - Train Epoch: [194] [588800/1281167 (46%)]	Loss: 0.781769
[2022-04-08 06:12:04 | train] - Train Epoch: [194] [601600/1281167 (47%)]	Loss: 0.654093
[2022-04-08 06:12:28 | train] - Train Epoch: [194] [614400/1281167 (48%)]	Loss: 0.695336
[2022-04-08 06:12:51 | train] - Train Epoch: [194] [627200/1281167 (49%)]	Loss: 0.919322
[2022-04-08 06:13:14 | train] - Train Epoch: [194] [640000/1281167 (50%)]	Loss: 0.813406
[2022-04-08 06:13:37 | train] - Train Epoch: [194] [652800/1281167 (51%)]	Loss: 0.958730
[2022-04-08 06:14:01 | train] - Train Epoch: [194] [665600/1281167 (52%)]	Loss: 0.825821
[2022-04-08 06:14:24 | train] - Train Epoch: [194] [678400/1281167 (53%)]	Loss: 0.816918
[2022-04-08 06:14:47 | train] - Train Epoch: [194] [691200/1281167 (54%)]	Loss: 0.583111
[2022-04-08 06:15:10 | train] - Train Epoch: [194] [704000/1281167 (55%)]	Loss: 0.625098
[2022-04-08 06:15:33 | train] - Train Epoch: [194] [716800/1281167 (56%)]	Loss: 0.812662
[2022-04-08 06:15:56 | train] - Train Epoch: [194] [729600/1281167 (57%)]	Loss: 0.783483
[2022-04-08 06:16:19 | train] - Train Epoch: [194] [742400/1281167 (58%)]	Loss: 0.791523
[2022-04-08 06:16:43 | train] - Train Epoch: [194] [755200/1281167 (59%)]	Loss: 0.690678
[2022-04-08 06:17:06 | train] - Train Epoch: [194] [768000/1281167 (60%)]	Loss: 0.982560
[2022-04-08 06:17:29 | train] - Train Epoch: [194] [780800/1281167 (61%)]	Loss: 0.634687
[2022-04-08 06:17:52 | train] - Train Epoch: [194] [793600/1281167 (62%)]	Loss: 0.987242
[2022-04-08 06:18:15 | train] - Train Epoch: [194] [806400/1281167 (63%)]	Loss: 0.877452
[2022-04-08 06:18:38 | train] - Train Epoch: [194] [819200/1281167 (64%)]	Loss: 0.814996
[2022-04-08 06:19:01 | train] - Train Epoch: [194] [832000/1281167 (65%)]	Loss: 0.984635
[2022-04-08 06:19:24 | train] - Train Epoch: [194] [844800/1281167 (66%)]	Loss: 0.713986
[2022-04-08 06:19:47 | train] - Train Epoch: [194] [857600/1281167 (67%)]	Loss: 0.659016
[2022-04-08 06:20:11 | train] - Train Epoch: [194] [870400/1281167 (68%)]	Loss: 0.622666
[2022-04-08 06:20:34 | train] - Train Epoch: [194] [883200/1281167 (69%)]	Loss: 0.503997
[2022-04-08 06:20:58 | train] - Train Epoch: [194] [896000/1281167 (70%)]	Loss: 0.539137
[2022-04-08 06:21:21 | train] - Train Epoch: [194] [908800/1281167 (71%)]	Loss: 0.802160
[2022-04-08 06:21:44 | train] - Train Epoch: [194] [921600/1281167 (72%)]	Loss: 1.068362
[2022-04-08 06:22:07 | train] - Train Epoch: [194] [934400/1281167 (73%)]	Loss: 0.735656
[2022-04-08 06:22:30 | train] - Train Epoch: [194] [947200/1281167 (74%)]	Loss: 0.670846
[2022-04-08 06:22:54 | train] - Train Epoch: [194] [960000/1281167 (75%)]	Loss: 0.861716
[2022-04-08 06:23:16 | train] - Train Epoch: [194] [972800/1281167 (76%)]	Loss: 0.671147
[2022-04-08 06:23:40 | train] - Train Epoch: [194] [985600/1281167 (77%)]	Loss: 0.853190
[2022-04-08 06:24:03 | train] - Train Epoch: [194] [998400/1281167 (78%)]	Loss: 1.019573
[2022-04-08 06:24:26 | train] - Train Epoch: [194] [1011200/1281167 (79%)]	Loss: 0.782850
[2022-04-08 06:24:50 | train] - Train Epoch: [194] [1024000/1281167 (80%)]	Loss: 0.663394
[2022-04-08 06:25:12 | train] - Train Epoch: [194] [1036800/1281167 (81%)]	Loss: 0.842359
[2022-04-08 06:25:35 | train] - Train Epoch: [194] [1049600/1281167 (82%)]	Loss: 0.474332
[2022-04-08 06:25:58 | train] - Train Epoch: [194] [1062400/1281167 (83%)]	Loss: 0.882296
[2022-04-08 06:26:22 | train] - Train Epoch: [194] [1075200/1281167 (84%)]	Loss: 0.665716
[2022-04-08 06:26:45 | train] - Train Epoch: [194] [1088000/1281167 (85%)]	Loss: 0.700658
[2022-04-08 06:27:08 | train] - Train Epoch: [194] [1100800/1281167 (86%)]	Loss: 0.959897
[2022-04-08 06:27:31 | train] - Train Epoch: [194] [1113600/1281167 (87%)]	Loss: 0.631336
[2022-04-08 06:27:54 | train] - Train Epoch: [194] [1126400/1281167 (88%)]	Loss: 1.051513
[2022-04-08 06:28:16 | train] - Train Epoch: [194] [1139200/1281167 (89%)]	Loss: 0.822641
[2022-04-08 06:28:39 | train] - Train Epoch: [194] [1152000/1281167 (90%)]	Loss: 0.424451
[2022-04-08 06:29:02 | train] - Train Epoch: [194] [1164800/1281167 (91%)]	Loss: 0.674798
[2022-04-08 06:29:25 | train] - Train Epoch: [194] [1177600/1281167 (92%)]	Loss: 0.645843
[2022-04-08 06:29:48 | train] - Train Epoch: [194] [1190400/1281167 (93%)]	Loss: 0.949146
[2022-04-08 06:30:11 | train] - Train Epoch: [194] [1203200/1281167 (94%)]	Loss: 0.842925
[2022-04-08 06:30:35 | train] - Train Epoch: [194] [1216000/1281167 (95%)]	Loss: 0.772914
[2022-04-08 06:30:58 | train] - Train Epoch: [194] [1228800/1281167 (96%)]	Loss: 0.790573
[2022-04-08 06:31:21 | train] - Train Epoch: [194] [1241600/1281167 (97%)]	Loss: 0.822772
[2022-04-08 06:31:44 | train] - Train Epoch: [194] [1254400/1281167 (98%)]	Loss: 0.869537
[2022-04-08 06:32:07 | train] - Train Epoch: [194] [1267200/1281167 (99%)]	Loss: 0.800991
[2022-04-08 06:32:30 | train] - Train Epoch: [194] [1280000/1281167 (100%)]	Loss: 0.638724
[2022-04-08 06:32:32 | train] - Train Epoch: [194]	 Average Loss: 0.755433	 Total Acc : 81.5417	 Total Top5 Acc : 93.3087
[2022-04-08 06:32:32 | train] - -------194 epoch end-----------
========================================
-------194 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 06:34:11 | train] - 
Epoch [194] Test set: Average loss: 1.4630, Accuracy: 34849/50000 (69.6707%), Top-5 Accuracy: 88.7212%

[2022-04-08 06:34:11 | train] - save intermediate epoch [194] result


[2022-04-08 06:34:38 | train] - -------195 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 06:34:40 | train] - Train Epoch: [195] [0/1281167 (0%)]	Loss: 0.653023
[2022-04-08 06:35:03 | train] - Train Epoch: [195] [12800/1281167 (1%)]	Loss: 0.762098
[2022-04-08 06:35:25 | train] - Train Epoch: [195] [25600/1281167 (2%)]	Loss: 0.540504
[2022-04-08 06:35:48 | train] - Train Epoch: [195] [38400/1281167 (3%)]	Loss: 0.578198
[2022-04-08 06:36:11 | train] - Train Epoch: [195] [51200/1281167 (4%)]	Loss: 0.949242
[2022-04-08 06:36:34 | train] - Train Epoch: [195] [64000/1281167 (5%)]	Loss: 0.717748
[2022-04-08 06:36:56 | train] - Train Epoch: [195] [76800/1281167 (6%)]	Loss: 0.746129
[2022-04-08 06:37:19 | train] - Train Epoch: [195] [89600/1281167 (7%)]	Loss: 0.738604
[2022-04-08 06:37:42 | train] - Train Epoch: [195] [102400/1281167 (8%)]	Loss: 0.489995
[2022-04-08 06:38:05 | train] - Train Epoch: [195] [115200/1281167 (9%)]	Loss: 0.902062
[2022-04-08 06:38:27 | train] - Train Epoch: [195] [128000/1281167 (10%)]	Loss: 0.860977
[2022-04-08 06:38:50 | train] - Train Epoch: [195] [140800/1281167 (11%)]	Loss: 0.983413
[2022-04-08 06:39:13 | train] - Train Epoch: [195] [153600/1281167 (12%)]	Loss: 0.907069
[2022-04-08 06:39:36 | train] - Train Epoch: [195] [166400/1281167 (13%)]	Loss: 0.621286
[2022-04-08 06:39:58 | train] - Train Epoch: [195] [179200/1281167 (14%)]	Loss: 0.621743
[2022-04-08 06:40:21 | train] - Train Epoch: [195] [192000/1281167 (15%)]	Loss: 1.027157
[2022-04-08 06:40:44 | train] - Train Epoch: [195] [204800/1281167 (16%)]	Loss: 0.732285
[2022-04-08 06:41:07 | train] - Train Epoch: [195] [217600/1281167 (17%)]	Loss: 0.911660
[2022-04-08 06:41:30 | train] - Train Epoch: [195] [230400/1281167 (18%)]	Loss: 1.037543
[2022-04-08 06:41:53 | train] - Train Epoch: [195] [243200/1281167 (19%)]	Loss: 0.848330
[2022-04-08 06:42:16 | train] - Train Epoch: [195] [256000/1281167 (20%)]	Loss: 1.072375
[2022-04-08 06:42:38 | train] - Train Epoch: [195] [268800/1281167 (21%)]	Loss: 0.828150
[2022-04-08 06:43:01 | train] - Train Epoch: [195] [281600/1281167 (22%)]	Loss: 0.602597
[2022-04-08 06:43:24 | train] - Train Epoch: [195] [294400/1281167 (23%)]	Loss: 0.723185
[2022-04-08 06:43:47 | train] - Train Epoch: [195] [307200/1281167 (24%)]	Loss: 0.862474
[2022-04-08 06:44:10 | train] - Train Epoch: [195] [320000/1281167 (25%)]	Loss: 0.689544
[2022-04-08 06:44:32 | train] - Train Epoch: [195] [332800/1281167 (26%)]	Loss: 0.872551
[2022-04-08 06:44:55 | train] - Train Epoch: [195] [345600/1281167 (27%)]	Loss: 0.821702
[2022-04-08 06:45:18 | train] - Train Epoch: [195] [358400/1281167 (28%)]	Loss: 0.945366
[2022-04-08 06:45:40 | train] - Train Epoch: [195] [371200/1281167 (29%)]	Loss: 0.711550
[2022-04-08 06:46:03 | train] - Train Epoch: [195] [384000/1281167 (30%)]	Loss: 0.745667
[2022-04-08 06:46:26 | train] - Train Epoch: [195] [396800/1281167 (31%)]	Loss: 0.983091
[2022-04-08 06:46:49 | train] - Train Epoch: [195] [409600/1281167 (32%)]	Loss: 0.925458
[2022-04-08 06:47:11 | train] - Train Epoch: [195] [422400/1281167 (33%)]	Loss: 0.763670
[2022-04-08 06:47:34 | train] - Train Epoch: [195] [435200/1281167 (34%)]	Loss: 0.489670
[2022-04-08 06:47:57 | train] - Train Epoch: [195] [448000/1281167 (35%)]	Loss: 0.711567
[2022-04-08 06:48:19 | train] - Train Epoch: [195] [460800/1281167 (36%)]	Loss: 0.642277
[2022-04-08 06:48:42 | train] - Train Epoch: [195] [473600/1281167 (37%)]	Loss: 0.550599
[2022-04-08 06:49:05 | train] - Train Epoch: [195] [486400/1281167 (38%)]	Loss: 0.881383
[2022-04-08 06:49:28 | train] - Train Epoch: [195] [499200/1281167 (39%)]	Loss: 0.556185
[2022-04-08 06:49:51 | train] - Train Epoch: [195] [512000/1281167 (40%)]	Loss: 0.808011
[2022-04-08 06:50:14 | train] - Train Epoch: [195] [524800/1281167 (41%)]	Loss: 0.994883
[2022-04-08 06:50:36 | train] - Train Epoch: [195] [537600/1281167 (42%)]	Loss: 0.800396
[2022-04-08 06:50:59 | train] - Train Epoch: [195] [550400/1281167 (43%)]	Loss: 0.921803
[2022-04-08 06:51:21 | train] - Train Epoch: [195] [563200/1281167 (44%)]	Loss: 0.717679
[2022-04-08 06:51:44 | train] - Train Epoch: [195] [576000/1281167 (45%)]	Loss: 0.540971
[2022-04-08 06:52:07 | train] - Train Epoch: [195] [588800/1281167 (46%)]	Loss: 0.509363
[2022-04-08 06:52:30 | train] - Train Epoch: [195] [601600/1281167 (47%)]	Loss: 0.918044
[2022-04-08 06:52:52 | train] - Train Epoch: [195] [614400/1281167 (48%)]	Loss: 0.748329
[2022-04-08 06:53:15 | train] - Train Epoch: [195] [627200/1281167 (49%)]	Loss: 0.852928
[2022-04-08 06:53:37 | train] - Train Epoch: [195] [640000/1281167 (50%)]	Loss: 0.897506
[2022-04-08 06:54:00 | train] - Train Epoch: [195] [652800/1281167 (51%)]	Loss: 0.705175
[2022-04-08 06:54:23 | train] - Train Epoch: [195] [665600/1281167 (52%)]	Loss: 0.703403
[2022-04-08 06:54:45 | train] - Train Epoch: [195] [678400/1281167 (53%)]	Loss: 0.951954
[2022-04-08 06:55:08 | train] - Train Epoch: [195] [691200/1281167 (54%)]	Loss: 0.504043
[2022-04-08 06:55:31 | train] - Train Epoch: [195] [704000/1281167 (55%)]	Loss: 0.610956
[2022-04-08 06:55:53 | train] - Train Epoch: [195] [716800/1281167 (56%)]	Loss: 0.690835
[2022-04-08 06:56:16 | train] - Train Epoch: [195] [729600/1281167 (57%)]	Loss: 1.056837
[2022-04-08 06:56:39 | train] - Train Epoch: [195] [742400/1281167 (58%)]	Loss: 0.700263
[2022-04-08 06:57:02 | train] - Train Epoch: [195] [755200/1281167 (59%)]	Loss: 0.695258
[2022-04-08 06:57:24 | train] - Train Epoch: [195] [768000/1281167 (60%)]	Loss: 0.916960
[2022-04-08 06:57:47 | train] - Train Epoch: [195] [780800/1281167 (61%)]	Loss: 0.608288
[2022-04-08 06:58:10 | train] - Train Epoch: [195] [793600/1281167 (62%)]	Loss: 0.644735
[2022-04-08 06:58:32 | train] - Train Epoch: [195] [806400/1281167 (63%)]	Loss: 0.890584
[2022-04-08 06:58:54 | train] - Train Epoch: [195] [819200/1281167 (64%)]	Loss: 0.868611
[2022-04-08 06:59:17 | train] - Train Epoch: [195] [832000/1281167 (65%)]	Loss: 0.742920
[2022-04-08 06:59:40 | train] - Train Epoch: [195] [844800/1281167 (66%)]	Loss: 0.696348
[2022-04-08 07:00:03 | train] - Train Epoch: [195] [857600/1281167 (67%)]	Loss: 0.871209
[2022-04-08 07:00:25 | train] - Train Epoch: [195] [870400/1281167 (68%)]	Loss: 0.642285
[2022-04-08 07:00:48 | train] - Train Epoch: [195] [883200/1281167 (69%)]	Loss: 0.658133
[2022-04-08 07:01:11 | train] - Train Epoch: [195] [896000/1281167 (70%)]	Loss: 0.700128
[2022-04-08 07:01:33 | train] - Train Epoch: [195] [908800/1281167 (71%)]	Loss: 0.814086
[2022-04-08 07:01:56 | train] - Train Epoch: [195] [921600/1281167 (72%)]	Loss: 0.772989
[2022-04-08 07:02:18 | train] - Train Epoch: [195] [934400/1281167 (73%)]	Loss: 0.740926
[2022-04-08 07:02:41 | train] - Train Epoch: [195] [947200/1281167 (74%)]	Loss: 0.882461
[2022-04-08 07:03:03 | train] - Train Epoch: [195] [960000/1281167 (75%)]	Loss: 0.583999
[2022-04-08 07:03:26 | train] - Train Epoch: [195] [972800/1281167 (76%)]	Loss: 0.663161
[2022-04-08 07:03:49 | train] - Train Epoch: [195] [985600/1281167 (77%)]	Loss: 0.849838
[2022-04-08 07:04:12 | train] - Train Epoch: [195] [998400/1281167 (78%)]	Loss: 0.804868
[2022-04-08 07:04:35 | train] - Train Epoch: [195] [1011200/1281167 (79%)]	Loss: 1.040909
[2022-04-08 07:04:57 | train] - Train Epoch: [195] [1024000/1281167 (80%)]	Loss: 0.899288
[2022-04-08 07:05:20 | train] - Train Epoch: [195] [1036800/1281167 (81%)]	Loss: 0.938579
[2022-04-08 07:05:43 | train] - Train Epoch: [195] [1049600/1281167 (82%)]	Loss: 0.935457
[2022-04-08 07:06:06 | train] - Train Epoch: [195] [1062400/1281167 (83%)]	Loss: 0.933704
[2022-04-08 07:06:29 | train] - Train Epoch: [195] [1075200/1281167 (84%)]	Loss: 0.760021
[2022-04-08 07:06:51 | train] - Train Epoch: [195] [1088000/1281167 (85%)]	Loss: 0.716538
[2022-04-08 07:07:14 | train] - Train Epoch: [195] [1100800/1281167 (86%)]	Loss: 0.785868
[2022-04-08 07:07:37 | train] - Train Epoch: [195] [1113600/1281167 (87%)]	Loss: 0.751259
[2022-04-08 07:08:00 | train] - Train Epoch: [195] [1126400/1281167 (88%)]	Loss: 0.932614
[2022-04-08 07:08:23 | train] - Train Epoch: [195] [1139200/1281167 (89%)]	Loss: 0.727585
[2022-04-08 07:08:46 | train] - Train Epoch: [195] [1152000/1281167 (90%)]	Loss: 0.826212
[2022-04-08 07:09:08 | train] - Train Epoch: [195] [1164800/1281167 (91%)]	Loss: 0.610321
[2022-04-08 07:09:32 | train] - Train Epoch: [195] [1177600/1281167 (92%)]	Loss: 0.946560
[2022-04-08 07:09:54 | train] - Train Epoch: [195] [1190400/1281167 (93%)]	Loss: 0.654957
[2022-04-08 07:10:18 | train] - Train Epoch: [195] [1203200/1281167 (94%)]	Loss: 0.880869
[2022-04-08 07:10:40 | train] - Train Epoch: [195] [1216000/1281167 (95%)]	Loss: 0.836390
[2022-04-08 07:11:04 | train] - Train Epoch: [195] [1228800/1281167 (96%)]	Loss: 0.707615
[2022-04-08 07:11:26 | train] - Train Epoch: [195] [1241600/1281167 (97%)]	Loss: 0.783867
[2022-04-08 07:11:49 | train] - Train Epoch: [195] [1254400/1281167 (98%)]	Loss: 0.609796
[2022-04-08 07:12:12 | train] - Train Epoch: [195] [1267200/1281167 (99%)]	Loss: 0.396148
[2022-04-08 07:12:35 | train] - Train Epoch: [195] [1280000/1281167 (100%)]	Loss: 0.685502
[2022-04-08 07:12:37 | train] - Train Epoch: [195]	 Average Loss: 0.756036	 Total Acc : 81.5151	 Total Top5 Acc : 93.2824
[2022-04-08 07:12:37 | train] - -------195 epoch end-----------
========================================
-------195 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 07:14:14 | train] - 
Epoch [195] Test set: Average loss: 1.4658, Accuracy: 34881/50000 (69.7335%), Top-5 Accuracy: 88.7200%

[2022-04-08 07:14:14 | train] - save intermediate epoch [195] result


[2022-04-08 07:14:42 | train] - -------196 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 07:14:44 | train] - Train Epoch: [196] [0/1281167 (0%)]	Loss: 0.810865
[2022-04-08 07:15:07 | train] - Train Epoch: [196] [12800/1281167 (1%)]	Loss: 0.650249
[2022-04-08 07:15:29 | train] - Train Epoch: [196] [25600/1281167 (2%)]	Loss: 0.753827
[2022-04-08 07:15:53 | train] - Train Epoch: [196] [38400/1281167 (3%)]	Loss: 0.557723
[2022-04-08 07:16:16 | train] - Train Epoch: [196] [51200/1281167 (4%)]	Loss: 0.483186
[2022-04-08 07:16:39 | train] - Train Epoch: [196] [64000/1281167 (5%)]	Loss: 0.945711
[2022-04-08 07:17:03 | train] - Train Epoch: [196] [76800/1281167 (6%)]	Loss: 0.793805
[2022-04-08 07:17:25 | train] - Train Epoch: [196] [89600/1281167 (7%)]	Loss: 0.774896
[2022-04-08 07:17:48 | train] - Train Epoch: [196] [102400/1281167 (8%)]	Loss: 0.742869
[2022-04-08 07:18:12 | train] - Train Epoch: [196] [115200/1281167 (9%)]	Loss: 1.112719
[2022-04-08 07:18:35 | train] - Train Epoch: [196] [128000/1281167 (10%)]	Loss: 0.562953
[2022-04-08 07:18:58 | train] - Train Epoch: [196] [140800/1281167 (11%)]	Loss: 0.995778
[2022-04-08 07:19:21 | train] - Train Epoch: [196] [153600/1281167 (12%)]	Loss: 0.747212
[2022-04-08 07:19:44 | train] - Train Epoch: [196] [166400/1281167 (13%)]	Loss: 0.788403
[2022-04-08 07:20:07 | train] - Train Epoch: [196] [179200/1281167 (14%)]	Loss: 0.754437
[2022-04-08 07:20:30 | train] - Train Epoch: [196] [192000/1281167 (15%)]	Loss: 0.806569
[2022-04-08 07:20:53 | train] - Train Epoch: [196] [204800/1281167 (16%)]	Loss: 0.596728
[2022-04-08 07:21:16 | train] - Train Epoch: [196] [217600/1281167 (17%)]	Loss: 0.631265
[2022-04-08 07:21:39 | train] - Train Epoch: [196] [230400/1281167 (18%)]	Loss: 0.620735
[2022-04-08 07:22:02 | train] - Train Epoch: [196] [243200/1281167 (19%)]	Loss: 0.650160
[2022-04-08 07:22:25 | train] - Train Epoch: [196] [256000/1281167 (20%)]	Loss: 0.678347
[2022-04-08 07:22:48 | train] - Train Epoch: [196] [268800/1281167 (21%)]	Loss: 0.631483
[2022-04-08 07:23:11 | train] - Train Epoch: [196] [281600/1281167 (22%)]	Loss: 0.618179
[2022-04-08 07:23:35 | train] - Train Epoch: [196] [294400/1281167 (23%)]	Loss: 0.675165
[2022-04-08 07:23:57 | train] - Train Epoch: [196] [307200/1281167 (24%)]	Loss: 0.652635
[2022-04-08 07:24:21 | train] - Train Epoch: [196] [320000/1281167 (25%)]	Loss: 0.711017
[2022-04-08 07:24:44 | train] - Train Epoch: [196] [332800/1281167 (26%)]	Loss: 0.546316
[2022-04-08 07:25:07 | train] - Train Epoch: [196] [345600/1281167 (27%)]	Loss: 0.978779
[2022-04-08 07:25:31 | train] - Train Epoch: [196] [358400/1281167 (28%)]	Loss: 1.026823
[2022-04-08 07:25:54 | train] - Train Epoch: [196] [371200/1281167 (29%)]	Loss: 0.794870
[2022-04-08 07:26:18 | train] - Train Epoch: [196] [384000/1281167 (30%)]	Loss: 0.869569
[2022-04-08 07:26:41 | train] - Train Epoch: [196] [396800/1281167 (31%)]	Loss: 0.761339
[2022-04-08 07:27:04 | train] - Train Epoch: [196] [409600/1281167 (32%)]	Loss: 0.649188
[2022-04-08 07:27:27 | train] - Train Epoch: [196] [422400/1281167 (33%)]	Loss: 0.516565
[2022-04-08 07:27:50 | train] - Train Epoch: [196] [435200/1281167 (34%)]	Loss: 1.080211
[2022-04-08 07:28:13 | train] - Train Epoch: [196] [448000/1281167 (35%)]	Loss: 0.836599
[2022-04-08 07:28:36 | train] - Train Epoch: [196] [460800/1281167 (36%)]	Loss: 0.745847
[2022-04-08 07:28:59 | train] - Train Epoch: [196] [473600/1281167 (37%)]	Loss: 0.685011
[2022-04-08 07:29:22 | train] - Train Epoch: [196] [486400/1281167 (38%)]	Loss: 0.740918
[2022-04-08 07:29:45 | train] - Train Epoch: [196] [499200/1281167 (39%)]	Loss: 0.893051
[2022-04-08 07:30:08 | train] - Train Epoch: [196] [512000/1281167 (40%)]	Loss: 0.668501
[2022-04-08 07:30:30 | train] - Train Epoch: [196] [524800/1281167 (41%)]	Loss: 0.995010
[2022-04-08 07:30:54 | train] - Train Epoch: [196] [537600/1281167 (42%)]	Loss: 0.937409
[2022-04-08 07:31:17 | train] - Train Epoch: [196] [550400/1281167 (43%)]	Loss: 0.809620
[2022-04-08 07:31:40 | train] - Train Epoch: [196] [563200/1281167 (44%)]	Loss: 0.651723
[2022-04-08 07:32:03 | train] - Train Epoch: [196] [576000/1281167 (45%)]	Loss: 0.525401
[2022-04-08 07:32:26 | train] - Train Epoch: [196] [588800/1281167 (46%)]	Loss: 0.534103
[2022-04-08 07:32:50 | train] - Train Epoch: [196] [601600/1281167 (47%)]	Loss: 0.728680
[2022-04-08 07:33:12 | train] - Train Epoch: [196] [614400/1281167 (48%)]	Loss: 0.766733
[2022-04-08 07:33:36 | train] - Train Epoch: [196] [627200/1281167 (49%)]	Loss: 0.810041
[2022-04-08 07:33:59 | train] - Train Epoch: [196] [640000/1281167 (50%)]	Loss: 0.626925
[2022-04-08 07:34:23 | train] - Train Epoch: [196] [652800/1281167 (51%)]	Loss: 0.846369
[2022-04-08 07:34:46 | train] - Train Epoch: [196] [665600/1281167 (52%)]	Loss: 1.138585
[2022-04-08 07:35:09 | train] - Train Epoch: [196] [678400/1281167 (53%)]	Loss: 0.825988
[2022-04-08 07:35:32 | train] - Train Epoch: [196] [691200/1281167 (54%)]	Loss: 0.777897
[2022-04-08 07:35:55 | train] - Train Epoch: [196] [704000/1281167 (55%)]	Loss: 0.848926
[2022-04-08 07:36:18 | train] - Train Epoch: [196] [716800/1281167 (56%)]	Loss: 0.635279
[2022-04-08 07:36:41 | train] - Train Epoch: [196] [729600/1281167 (57%)]	Loss: 0.866619
[2022-04-08 07:37:04 | train] - Train Epoch: [196] [742400/1281167 (58%)]	Loss: 0.970517
[2022-04-08 07:37:27 | train] - Train Epoch: [196] [755200/1281167 (59%)]	Loss: 0.662249
[2022-04-08 07:37:50 | train] - Train Epoch: [196] [768000/1281167 (60%)]	Loss: 0.735835
[2022-04-08 07:38:13 | train] - Train Epoch: [196] [780800/1281167 (61%)]	Loss: 1.098888
[2022-04-08 07:38:35 | train] - Train Epoch: [196] [793600/1281167 (62%)]	Loss: 0.963183
[2022-04-08 07:38:58 | train] - Train Epoch: [196] [806400/1281167 (63%)]	Loss: 0.609788
[2022-04-08 07:39:22 | train] - Train Epoch: [196] [819200/1281167 (64%)]	Loss: 0.929763
[2022-04-08 07:39:44 | train] - Train Epoch: [196] [832000/1281167 (65%)]	Loss: 0.747634
[2022-04-08 07:40:08 | train] - Train Epoch: [196] [844800/1281167 (66%)]	Loss: 0.742462
[2022-04-08 07:40:31 | train] - Train Epoch: [196] [857600/1281167 (67%)]	Loss: 0.506919
[2022-04-08 07:40:54 | train] - Train Epoch: [196] [870400/1281167 (68%)]	Loss: 0.687043
[2022-04-08 07:41:17 | train] - Train Epoch: [196] [883200/1281167 (69%)]	Loss: 0.683382
[2022-04-08 07:41:40 | train] - Train Epoch: [196] [896000/1281167 (70%)]	Loss: 0.885386
[2022-04-08 07:42:03 | train] - Train Epoch: [196] [908800/1281167 (71%)]	Loss: 0.909886
[2022-04-08 07:42:26 | train] - Train Epoch: [196] [921600/1281167 (72%)]	Loss: 0.808259
[2022-04-08 07:42:49 | train] - Train Epoch: [196] [934400/1281167 (73%)]	Loss: 0.811613
[2022-04-08 07:43:12 | train] - Train Epoch: [196] [947200/1281167 (74%)]	Loss: 0.627536
[2022-04-08 07:43:35 | train] - Train Epoch: [196] [960000/1281167 (75%)]	Loss: 0.891303
[2022-04-08 07:43:58 | train] - Train Epoch: [196] [972800/1281167 (76%)]	Loss: 1.006917
[2022-04-08 07:44:21 | train] - Train Epoch: [196] [985600/1281167 (77%)]	Loss: 1.113443
[2022-04-08 07:44:44 | train] - Train Epoch: [196] [998400/1281167 (78%)]	Loss: 0.831568
[2022-04-08 07:45:08 | train] - Train Epoch: [196] [1011200/1281167 (79%)]	Loss: 0.758443
[2022-04-08 07:45:31 | train] - Train Epoch: [196] [1024000/1281167 (80%)]	Loss: 0.663137
[2022-04-08 07:45:54 | train] - Train Epoch: [196] [1036800/1281167 (81%)]	Loss: 1.085930
[2022-04-08 07:46:17 | train] - Train Epoch: [196] [1049600/1281167 (82%)]	Loss: 0.914107
[2022-04-08 07:46:40 | train] - Train Epoch: [196] [1062400/1281167 (83%)]	Loss: 1.019735
[2022-04-08 07:47:04 | train] - Train Epoch: [196] [1075200/1281167 (84%)]	Loss: 0.671337
[2022-04-08 07:47:26 | train] - Train Epoch: [196] [1088000/1281167 (85%)]	Loss: 0.826413
[2022-04-08 07:47:49 | train] - Train Epoch: [196] [1100800/1281167 (86%)]	Loss: 0.893948
[2022-04-08 07:48:13 | train] - Train Epoch: [196] [1113600/1281167 (87%)]	Loss: 0.776381
[2022-04-08 07:48:35 | train] - Train Epoch: [196] [1126400/1281167 (88%)]	Loss: 0.820493
[2022-04-08 07:48:58 | train] - Train Epoch: [196] [1139200/1281167 (89%)]	Loss: 0.879915
[2022-04-08 07:49:21 | train] - Train Epoch: [196] [1152000/1281167 (90%)]	Loss: 0.713307
[2022-04-08 07:49:44 | train] - Train Epoch: [196] [1164800/1281167 (91%)]	Loss: 0.648026
[2022-04-08 07:50:08 | train] - Train Epoch: [196] [1177600/1281167 (92%)]	Loss: 0.581103
[2022-04-08 07:50:31 | train] - Train Epoch: [196] [1190400/1281167 (93%)]	Loss: 0.937149
[2022-04-08 07:50:54 | train] - Train Epoch: [196] [1203200/1281167 (94%)]	Loss: 0.584390
[2022-04-08 07:51:18 | train] - Train Epoch: [196] [1216000/1281167 (95%)]	Loss: 0.628664
[2022-04-08 07:51:40 | train] - Train Epoch: [196] [1228800/1281167 (96%)]	Loss: 0.796181
[2022-04-08 07:52:03 | train] - Train Epoch: [196] [1241600/1281167 (97%)]	Loss: 0.794277
[2022-04-08 07:52:26 | train] - Train Epoch: [196] [1254400/1281167 (98%)]	Loss: 0.660737
[2022-04-08 07:52:50 | train] - Train Epoch: [196] [1267200/1281167 (99%)]	Loss: 0.769349
[2022-04-08 07:53:14 | train] - Train Epoch: [196] [1280000/1281167 (100%)]	Loss: 0.544300
[2022-04-08 07:53:16 | train] - Train Epoch: [196]	 Average Loss: 0.755817	 Total Acc : 81.5487	 Total Top5 Acc : 93.2631
[2022-04-08 07:53:16 | train] - -------196 epoch end-----------
========================================
-------196 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 07:54:56 | train] - 
Epoch [196] Test set: Average loss: 1.4563, Accuracy: 34844/50000 (69.6607%), Top-5 Accuracy: 88.7500%

[2022-04-08 07:54:56 | train] - save intermediate epoch [196] result


[2022-04-08 07:55:24 | train] - -------197 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 07:55:26 | train] - Train Epoch: [197] [0/1281167 (0%)]	Loss: 0.683648
[2022-04-08 07:55:49 | train] - Train Epoch: [197] [12800/1281167 (1%)]	Loss: 0.656138
[2022-04-08 07:56:12 | train] - Train Epoch: [197] [25600/1281167 (2%)]	Loss: 0.846448
[2022-04-08 07:56:35 | train] - Train Epoch: [197] [38400/1281167 (3%)]	Loss: 1.003791
[2022-04-08 07:56:59 | train] - Train Epoch: [197] [51200/1281167 (4%)]	Loss: 0.920551
[2022-04-08 07:57:23 | train] - Train Epoch: [197] [64000/1281167 (5%)]	Loss: 0.615168
[2022-04-08 07:57:46 | train] - Train Epoch: [197] [76800/1281167 (6%)]	Loss: 0.852101
[2022-04-08 07:58:08 | train] - Train Epoch: [197] [89600/1281167 (7%)]	Loss: 0.495598
[2022-04-08 07:58:32 | train] - Train Epoch: [197] [102400/1281167 (8%)]	Loss: 0.477700
[2022-04-08 07:58:55 | train] - Train Epoch: [197] [115200/1281167 (9%)]	Loss: 0.861046
[2022-04-08 07:59:19 | train] - Train Epoch: [197] [128000/1281167 (10%)]	Loss: 0.637267
[2022-04-08 07:59:41 | train] - Train Epoch: [197] [140800/1281167 (11%)]	Loss: 0.671449
[2022-04-08 08:00:04 | train] - Train Epoch: [197] [153600/1281167 (12%)]	Loss: 0.540149
[2022-04-08 08:00:28 | train] - Train Epoch: [197] [166400/1281167 (13%)]	Loss: 0.852588
[2022-04-08 08:00:51 | train] - Train Epoch: [197] [179200/1281167 (14%)]	Loss: 0.726459
[2022-04-08 08:01:14 | train] - Train Epoch: [197] [192000/1281167 (15%)]	Loss: 0.649671
[2022-04-08 08:01:37 | train] - Train Epoch: [197] [204800/1281167 (16%)]	Loss: 0.804494
[2022-04-08 08:02:00 | train] - Train Epoch: [197] [217600/1281167 (17%)]	Loss: 1.056699
[2022-04-08 08:02:23 | train] - Train Epoch: [197] [230400/1281167 (18%)]	Loss: 0.731103
[2022-04-08 08:02:47 | train] - Train Epoch: [197] [243200/1281167 (19%)]	Loss: 0.631187
[2022-04-08 08:03:10 | train] - Train Epoch: [197] [256000/1281167 (20%)]	Loss: 0.928909
[2022-04-08 08:03:33 | train] - Train Epoch: [197] [268800/1281167 (21%)]	Loss: 0.977688
[2022-04-08 08:03:56 | train] - Train Epoch: [197] [281600/1281167 (22%)]	Loss: 0.687776
[2022-04-08 08:04:20 | train] - Train Epoch: [197] [294400/1281167 (23%)]	Loss: 0.428654
[2022-04-08 08:04:43 | train] - Train Epoch: [197] [307200/1281167 (24%)]	Loss: 0.870256
[2022-04-08 08:05:06 | train] - Train Epoch: [197] [320000/1281167 (25%)]	Loss: 0.837822
[2022-04-08 08:05:29 | train] - Train Epoch: [197] [332800/1281167 (26%)]	Loss: 0.820001
[2022-04-08 08:05:51 | train] - Train Epoch: [197] [345600/1281167 (27%)]	Loss: 0.721053
[2022-04-08 08:06:15 | train] - Train Epoch: [197] [358400/1281167 (28%)]	Loss: 0.694077
[2022-04-08 08:06:37 | train] - Train Epoch: [197] [371200/1281167 (29%)]	Loss: 0.656646
[2022-04-08 08:07:00 | train] - Train Epoch: [197] [384000/1281167 (30%)]	Loss: 0.795431
[2022-04-08 08:07:24 | train] - Train Epoch: [197] [396800/1281167 (31%)]	Loss: 0.571897
[2022-04-08 08:07:47 | train] - Train Epoch: [197] [409600/1281167 (32%)]	Loss: 0.776832
[2022-04-08 08:08:10 | train] - Train Epoch: [197] [422400/1281167 (33%)]	Loss: 0.809454
[2022-04-08 08:08:33 | train] - Train Epoch: [197] [435200/1281167 (34%)]	Loss: 0.829298
[2022-04-08 08:08:56 | train] - Train Epoch: [197] [448000/1281167 (35%)]	Loss: 0.636923
[2022-04-08 08:09:19 | train] - Train Epoch: [197] [460800/1281167 (36%)]	Loss: 0.781497
[2022-04-08 08:09:42 | train] - Train Epoch: [197] [473600/1281167 (37%)]	Loss: 0.571978
[2022-04-08 08:10:06 | train] - Train Epoch: [197] [486400/1281167 (38%)]	Loss: 0.740740
[2022-04-08 08:10:29 | train] - Train Epoch: [197] [499200/1281167 (39%)]	Loss: 0.681527
[2022-04-08 08:10:51 | train] - Train Epoch: [197] [512000/1281167 (40%)]	Loss: 0.849543
[2022-04-08 08:11:14 | train] - Train Epoch: [197] [524800/1281167 (41%)]	Loss: 0.874542
[2022-04-08 08:11:37 | train] - Train Epoch: [197] [537600/1281167 (42%)]	Loss: 0.878628
[2022-04-08 08:12:00 | train] - Train Epoch: [197] [550400/1281167 (43%)]	Loss: 0.758662
[2022-04-08 08:12:23 | train] - Train Epoch: [197] [563200/1281167 (44%)]	Loss: 0.887182
[2022-04-08 08:12:46 | train] - Train Epoch: [197] [576000/1281167 (45%)]	Loss: 0.949762
[2022-04-08 08:13:09 | train] - Train Epoch: [197] [588800/1281167 (46%)]	Loss: 0.653205
[2022-04-08 08:13:32 | train] - Train Epoch: [197] [601600/1281167 (47%)]	Loss: 0.720462
[2022-04-08 08:13:55 | train] - Train Epoch: [197] [614400/1281167 (48%)]	Loss: 1.095258
[2022-04-08 08:14:18 | train] - Train Epoch: [197] [627200/1281167 (49%)]	Loss: 0.713786
[2022-04-08 08:14:41 | train] - Train Epoch: [197] [640000/1281167 (50%)]	Loss: 0.923615
[2022-04-08 08:15:04 | train] - Train Epoch: [197] [652800/1281167 (51%)]	Loss: 0.625358
[2022-04-08 08:15:27 | train] - Train Epoch: [197] [665600/1281167 (52%)]	Loss: 0.880234
[2022-04-08 08:15:50 | train] - Train Epoch: [197] [678400/1281167 (53%)]	Loss: 0.769891
[2022-04-08 08:16:13 | train] - Train Epoch: [197] [691200/1281167 (54%)]	Loss: 0.663429
[2022-04-08 08:16:36 | train] - Train Epoch: [197] [704000/1281167 (55%)]	Loss: 0.708670
[2022-04-08 08:17:00 | train] - Train Epoch: [197] [716800/1281167 (56%)]	Loss: 0.858155
[2022-04-08 08:17:22 | train] - Train Epoch: [197] [729600/1281167 (57%)]	Loss: 0.501256
[2022-04-08 08:17:46 | train] - Train Epoch: [197] [742400/1281167 (58%)]	Loss: 0.656620
[2022-04-08 08:18:09 | train] - Train Epoch: [197] [755200/1281167 (59%)]	Loss: 0.781958
[2022-04-08 08:18:32 | train] - Train Epoch: [197] [768000/1281167 (60%)]	Loss: 0.806768
[2022-04-08 08:18:55 | train] - Train Epoch: [197] [780800/1281167 (61%)]	Loss: 0.699519
[2022-04-08 08:19:18 | train] - Train Epoch: [197] [793600/1281167 (62%)]	Loss: 1.300120
[2022-04-08 08:19:41 | train] - Train Epoch: [197] [806400/1281167 (63%)]	Loss: 0.895221
[2022-04-08 08:20:04 | train] - Train Epoch: [197] [819200/1281167 (64%)]	Loss: 0.828232
[2022-04-08 08:20:27 | train] - Train Epoch: [197] [832000/1281167 (65%)]	Loss: 0.960856
[2022-04-08 08:20:50 | train] - Train Epoch: [197] [844800/1281167 (66%)]	Loss: 0.756875
[2022-04-08 08:21:13 | train] - Train Epoch: [197] [857600/1281167 (67%)]	Loss: 0.759629
[2022-04-08 08:21:36 | train] - Train Epoch: [197] [870400/1281167 (68%)]	Loss: 0.729181
[2022-04-08 08:22:00 | train] - Train Epoch: [197] [883200/1281167 (69%)]	Loss: 0.789919
[2022-04-08 08:22:24 | train] - Train Epoch: [197] [896000/1281167 (70%)]	Loss: 1.039719
[2022-04-08 08:22:46 | train] - Train Epoch: [197] [908800/1281167 (71%)]	Loss: 0.689403
[2022-04-08 08:23:09 | train] - Train Epoch: [197] [921600/1281167 (72%)]	Loss: 0.586868
[2022-04-08 08:23:32 | train] - Train Epoch: [197] [934400/1281167 (73%)]	Loss: 0.720792
[2022-04-08 08:23:55 | train] - Train Epoch: [197] [947200/1281167 (74%)]	Loss: 0.833851
[2022-04-08 08:24:18 | train] - Train Epoch: [197] [960000/1281167 (75%)]	Loss: 0.856738
[2022-04-08 08:24:41 | train] - Train Epoch: [197] [972800/1281167 (76%)]	Loss: 0.773788
[2022-04-08 08:25:05 | train] - Train Epoch: [197] [985600/1281167 (77%)]	Loss: 0.710445
[2022-04-08 08:25:28 | train] - Train Epoch: [197] [998400/1281167 (78%)]	Loss: 0.799538
[2022-04-08 08:25:51 | train] - Train Epoch: [197] [1011200/1281167 (79%)]	Loss: 0.748942
[2022-04-08 08:26:14 | train] - Train Epoch: [197] [1024000/1281167 (80%)]	Loss: 0.828677
[2022-04-08 08:26:37 | train] - Train Epoch: [197] [1036800/1281167 (81%)]	Loss: 0.971334
[2022-04-08 08:27:00 | train] - Train Epoch: [197] [1049600/1281167 (82%)]	Loss: 0.683028
[2022-04-08 08:27:22 | train] - Train Epoch: [197] [1062400/1281167 (83%)]	Loss: 0.870347
[2022-04-08 08:27:46 | train] - Train Epoch: [197] [1075200/1281167 (84%)]	Loss: 0.730259
[2022-04-08 08:28:08 | train] - Train Epoch: [197] [1088000/1281167 (85%)]	Loss: 0.768474
[2022-04-08 08:28:32 | train] - Train Epoch: [197] [1100800/1281167 (86%)]	Loss: 0.777828
[2022-04-08 08:28:54 | train] - Train Epoch: [197] [1113600/1281167 (87%)]	Loss: 0.792925
[2022-04-08 08:29:17 | train] - Train Epoch: [197] [1126400/1281167 (88%)]	Loss: 0.770465
[2022-04-08 08:29:40 | train] - Train Epoch: [197] [1139200/1281167 (89%)]	Loss: 0.840589
[2022-04-08 08:30:03 | train] - Train Epoch: [197] [1152000/1281167 (90%)]	Loss: 0.667454
[2022-04-08 08:30:27 | train] - Train Epoch: [197] [1164800/1281167 (91%)]	Loss: 0.618317
[2022-04-08 08:30:50 | train] - Train Epoch: [197] [1177600/1281167 (92%)]	Loss: 0.647867
[2022-04-08 08:31:13 | train] - Train Epoch: [197] [1190400/1281167 (93%)]	Loss: 0.804339
[2022-04-08 08:31:36 | train] - Train Epoch: [197] [1203200/1281167 (94%)]	Loss: 0.960455
[2022-04-08 08:31:58 | train] - Train Epoch: [197] [1216000/1281167 (95%)]	Loss: 0.619149
[2022-04-08 08:32:21 | train] - Train Epoch: [197] [1228800/1281167 (96%)]	Loss: 0.718476
[2022-04-08 08:32:44 | train] - Train Epoch: [197] [1241600/1281167 (97%)]	Loss: 0.715036
[2022-04-08 08:33:08 | train] - Train Epoch: [197] [1254400/1281167 (98%)]	Loss: 0.987181
[2022-04-08 08:33:30 | train] - Train Epoch: [197] [1267200/1281167 (99%)]	Loss: 0.781073
[2022-04-08 08:33:54 | train] - Train Epoch: [197] [1280000/1281167 (100%)]	Loss: 0.809107
[2022-04-08 08:33:56 | train] - Train Epoch: [197]	 Average Loss: 0.754698	 Total Acc : 81.5813	 Total Top5 Acc : 93.3135
[2022-04-08 08:33:56 | train] - -------197 epoch end-----------
========================================
-------197 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 08:35:34 | train] - 
Epoch [197] Test set: Average loss: 1.4619, Accuracy: 34820/50000 (69.6116%), Top-5 Accuracy: 88.7552%

[2022-04-08 08:35:34 | train] - save intermediate epoch [197] result


[2022-04-08 08:36:02 | train] - -------198 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 08:36:04 | train] - Train Epoch: [198] [0/1281167 (0%)]	Loss: 0.676290
[2022-04-08 08:36:27 | train] - Train Epoch: [198] [12800/1281167 (1%)]	Loss: 0.939713
[2022-04-08 08:36:50 | train] - Train Epoch: [198] [25600/1281167 (2%)]	Loss: 0.732545
[2022-04-08 08:37:13 | train] - Train Epoch: [198] [38400/1281167 (3%)]	Loss: 0.710433
[2022-04-08 08:37:36 | train] - Train Epoch: [198] [51200/1281167 (4%)]	Loss: 1.036121
[2022-04-08 08:38:00 | train] - Train Epoch: [198] [64000/1281167 (5%)]	Loss: 0.886197
[2022-04-08 08:38:22 | train] - Train Epoch: [198] [76800/1281167 (6%)]	Loss: 1.026039
[2022-04-08 08:38:46 | train] - Train Epoch: [198] [89600/1281167 (7%)]	Loss: 0.916843
[2022-04-08 08:39:09 | train] - Train Epoch: [198] [102400/1281167 (8%)]	Loss: 0.883813
[2022-04-08 08:39:32 | train] - Train Epoch: [198] [115200/1281167 (9%)]	Loss: 0.929046
[2022-04-08 08:39:55 | train] - Train Epoch: [198] [128000/1281167 (10%)]	Loss: 0.824270
[2022-04-08 08:40:18 | train] - Train Epoch: [198] [140800/1281167 (11%)]	Loss: 0.663568
[2022-04-08 08:40:41 | train] - Train Epoch: [198] [153600/1281167 (12%)]	Loss: 0.527595
[2022-04-08 08:41:05 | train] - Train Epoch: [198] [166400/1281167 (13%)]	Loss: 0.597832
[2022-04-08 08:41:28 | train] - Train Epoch: [198] [179200/1281167 (14%)]	Loss: 0.882201
[2022-04-08 08:41:51 | train] - Train Epoch: [198] [192000/1281167 (15%)]	Loss: 0.552132
[2022-04-08 08:42:14 | train] - Train Epoch: [198] [204800/1281167 (16%)]	Loss: 0.794549
[2022-04-08 08:42:38 | train] - Train Epoch: [198] [217600/1281167 (17%)]	Loss: 0.676752
[2022-04-08 08:43:02 | train] - Train Epoch: [198] [230400/1281167 (18%)]	Loss: 0.751888
[2022-04-08 08:43:25 | train] - Train Epoch: [198] [243200/1281167 (19%)]	Loss: 0.787864
[2022-04-08 08:43:48 | train] - Train Epoch: [198] [256000/1281167 (20%)]	Loss: 0.664928
[2022-04-08 08:44:12 | train] - Train Epoch: [198] [268800/1281167 (21%)]	Loss: 0.520180
[2022-04-08 08:44:35 | train] - Train Epoch: [198] [281600/1281167 (22%)]	Loss: 0.905830
[2022-04-08 08:44:58 | train] - Train Epoch: [198] [294400/1281167 (23%)]	Loss: 1.140465
[2022-04-08 08:45:21 | train] - Train Epoch: [198] [307200/1281167 (24%)]	Loss: 0.670460
[2022-04-08 08:45:44 | train] - Train Epoch: [198] [320000/1281167 (25%)]	Loss: 0.655492
[2022-04-08 08:46:07 | train] - Train Epoch: [198] [332800/1281167 (26%)]	Loss: 0.995343
[2022-04-08 08:46:31 | train] - Train Epoch: [198] [345600/1281167 (27%)]	Loss: 0.608277
[2022-04-08 08:46:54 | train] - Train Epoch: [198] [358400/1281167 (28%)]	Loss: 1.030646
[2022-04-08 08:47:17 | train] - Train Epoch: [198] [371200/1281167 (29%)]	Loss: 0.818851
[2022-04-08 08:47:40 | train] - Train Epoch: [198] [384000/1281167 (30%)]	Loss: 0.774514
[2022-04-08 08:48:03 | train] - Train Epoch: [198] [396800/1281167 (31%)]	Loss: 0.723500
[2022-04-08 08:48:27 | train] - Train Epoch: [198] [409600/1281167 (32%)]	Loss: 0.803026
[2022-04-08 08:48:50 | train] - Train Epoch: [198] [422400/1281167 (33%)]	Loss: 0.821737
[2022-04-08 08:49:13 | train] - Train Epoch: [198] [435200/1281167 (34%)]	Loss: 0.635579
[2022-04-08 08:49:36 | train] - Train Epoch: [198] [448000/1281167 (35%)]	Loss: 0.820705
[2022-04-08 08:49:59 | train] - Train Epoch: [198] [460800/1281167 (36%)]	Loss: 0.531647
[2022-04-08 08:50:22 | train] - Train Epoch: [198] [473600/1281167 (37%)]	Loss: 0.457168
[2022-04-08 08:50:46 | train] - Train Epoch: [198] [486400/1281167 (38%)]	Loss: 0.549088
[2022-04-08 08:51:09 | train] - Train Epoch: [198] [499200/1281167 (39%)]	Loss: 0.913898
[2022-04-08 08:51:33 | train] - Train Epoch: [198] [512000/1281167 (40%)]	Loss: 0.708421
[2022-04-08 08:51:56 | train] - Train Epoch: [198] [524800/1281167 (41%)]	Loss: 0.691069
[2022-04-08 08:52:19 | train] - Train Epoch: [198] [537600/1281167 (42%)]	Loss: 0.965520
[2022-04-08 08:52:43 | train] - Train Epoch: [198] [550400/1281167 (43%)]	Loss: 1.165455
[2022-04-08 08:53:06 | train] - Train Epoch: [198] [563200/1281167 (44%)]	Loss: 0.858155
[2022-04-08 08:53:30 | train] - Train Epoch: [198] [576000/1281167 (45%)]	Loss: 0.861508
[2022-04-08 08:53:54 | train] - Train Epoch: [198] [588800/1281167 (46%)]	Loss: 0.997746
[2022-04-08 08:54:17 | train] - Train Epoch: [198] [601600/1281167 (47%)]	Loss: 0.641761
[2022-04-08 08:54:39 | train] - Train Epoch: [198] [614400/1281167 (48%)]	Loss: 0.914211
[2022-04-08 08:55:03 | train] - Train Epoch: [198] [627200/1281167 (49%)]	Loss: 0.579782
[2022-04-08 08:55:26 | train] - Train Epoch: [198] [640000/1281167 (50%)]	Loss: 0.657230
[2022-04-08 08:55:49 | train] - Train Epoch: [198] [652800/1281167 (51%)]	Loss: 0.739812
[2022-04-08 08:56:12 | train] - Train Epoch: [198] [665600/1281167 (52%)]	Loss: 0.814282
[2022-04-08 08:56:35 | train] - Train Epoch: [198] [678400/1281167 (53%)]	Loss: 0.745689
[2022-04-08 08:56:59 | train] - Train Epoch: [198] [691200/1281167 (54%)]	Loss: 0.895944
[2022-04-08 08:57:22 | train] - Train Epoch: [198] [704000/1281167 (55%)]	Loss: 0.551700
[2022-04-08 08:57:44 | train] - Train Epoch: [198] [716800/1281167 (56%)]	Loss: 0.771971
[2022-04-08 08:58:08 | train] - Train Epoch: [198] [729600/1281167 (57%)]	Loss: 0.941285
[2022-04-08 08:58:30 | train] - Train Epoch: [198] [742400/1281167 (58%)]	Loss: 0.802276
[2022-04-08 08:58:54 | train] - Train Epoch: [198] [755200/1281167 (59%)]	Loss: 0.541075
[2022-04-08 08:59:18 | train] - Train Epoch: [198] [768000/1281167 (60%)]	Loss: 0.815912
[2022-04-08 08:59:42 | train] - Train Epoch: [198] [780800/1281167 (61%)]	Loss: 0.792473
[2022-04-08 09:00:05 | train] - Train Epoch: [198] [793600/1281167 (62%)]	Loss: 0.785699
[2022-04-08 09:00:28 | train] - Train Epoch: [198] [806400/1281167 (63%)]	Loss: 0.848338
[2022-04-08 09:00:52 | train] - Train Epoch: [198] [819200/1281167 (64%)]	Loss: 0.806090
[2022-04-08 09:01:15 | train] - Train Epoch: [198] [832000/1281167 (65%)]	Loss: 0.789894
[2022-04-08 09:01:38 | train] - Train Epoch: [198] [844800/1281167 (66%)]	Loss: 0.748322
[2022-04-08 09:02:02 | train] - Train Epoch: [198] [857600/1281167 (67%)]	Loss: 0.572772
[2022-04-08 09:02:24 | train] - Train Epoch: [198] [870400/1281167 (68%)]	Loss: 0.880404
[2022-04-08 09:02:47 | train] - Train Epoch: [198] [883200/1281167 (69%)]	Loss: 0.515005
[2022-04-08 09:03:10 | train] - Train Epoch: [198] [896000/1281167 (70%)]	Loss: 0.609216
[2022-04-08 09:03:33 | train] - Train Epoch: [198] [908800/1281167 (71%)]	Loss: 0.862731
[2022-04-08 09:03:57 | train] - Train Epoch: [198] [921600/1281167 (72%)]	Loss: 0.832350
[2022-04-08 09:04:20 | train] - Train Epoch: [198] [934400/1281167 (73%)]	Loss: 0.638731
[2022-04-08 09:04:42 | train] - Train Epoch: [198] [947200/1281167 (74%)]	Loss: 0.994202
[2022-04-08 09:05:05 | train] - Train Epoch: [198] [960000/1281167 (75%)]	Loss: 0.917440
[2022-04-08 09:05:28 | train] - Train Epoch: [198] [972800/1281167 (76%)]	Loss: 0.612204
[2022-04-08 09:05:52 | train] - Train Epoch: [198] [985600/1281167 (77%)]	Loss: 0.842253
[2022-04-08 09:06:15 | train] - Train Epoch: [198] [998400/1281167 (78%)]	Loss: 0.842292
[2022-04-08 09:06:38 | train] - Train Epoch: [198] [1011200/1281167 (79%)]	Loss: 0.588694
[2022-04-08 09:07:01 | train] - Train Epoch: [198] [1024000/1281167 (80%)]	Loss: 0.632282
[2022-04-08 09:07:24 | train] - Train Epoch: [198] [1036800/1281167 (81%)]	Loss: 0.731999
[2022-04-08 09:07:47 | train] - Train Epoch: [198] [1049600/1281167 (82%)]	Loss: 0.918037
[2022-04-08 09:08:10 | train] - Train Epoch: [198] [1062400/1281167 (83%)]	Loss: 0.426282
[2022-04-08 09:08:33 | train] - Train Epoch: [198] [1075200/1281167 (84%)]	Loss: 0.744181
[2022-04-08 09:08:56 | train] - Train Epoch: [198] [1088000/1281167 (85%)]	Loss: 0.889109
[2022-04-08 09:09:19 | train] - Train Epoch: [198] [1100800/1281167 (86%)]	Loss: 0.813265
[2022-04-08 09:09:42 | train] - Train Epoch: [198] [1113600/1281167 (87%)]	Loss: 0.617876
[2022-04-08 09:10:04 | train] - Train Epoch: [198] [1126400/1281167 (88%)]	Loss: 0.603916
[2022-04-08 09:10:27 | train] - Train Epoch: [198] [1139200/1281167 (89%)]	Loss: 0.707556
[2022-04-08 09:10:51 | train] - Train Epoch: [198] [1152000/1281167 (90%)]	Loss: 0.577514
[2022-04-08 09:11:14 | train] - Train Epoch: [198] [1164800/1281167 (91%)]	Loss: 0.646817
[2022-04-08 09:11:36 | train] - Train Epoch: [198] [1177600/1281167 (92%)]	Loss: 0.765556
[2022-04-08 09:11:59 | train] - Train Epoch: [198] [1190400/1281167 (93%)]	Loss: 0.583803
[2022-04-08 09:12:22 | train] - Train Epoch: [198] [1203200/1281167 (94%)]	Loss: 0.481359
[2022-04-08 09:12:46 | train] - Train Epoch: [198] [1216000/1281167 (95%)]	Loss: 0.746704
[2022-04-08 09:13:08 | train] - Train Epoch: [198] [1228800/1281167 (96%)]	Loss: 0.936270
[2022-04-08 09:13:31 | train] - Train Epoch: [198] [1241600/1281167 (97%)]	Loss: 0.700879
[2022-04-08 09:13:54 | train] - Train Epoch: [198] [1254400/1281167 (98%)]	Loss: 0.752920
[2022-04-08 09:14:18 | train] - Train Epoch: [198] [1267200/1281167 (99%)]	Loss: 0.797653
[2022-04-08 09:14:41 | train] - Train Epoch: [198] [1280000/1281167 (100%)]	Loss: 0.953364
[2022-04-08 09:14:43 | train] - Train Epoch: [198]	 Average Loss: 0.754216	 Total Acc : 81.6166	 Total Top5 Acc : 93.2868
[2022-04-08 09:14:43 | train] - -------198 epoch end-----------
========================================
-------198 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 09:16:21 | train] - 
Epoch [198] Test set: Average loss: 1.4519, Accuracy: 34892/50000 (69.7554%), Top-5 Accuracy: 88.8024%

[2022-04-08 09:16:21 | train] - save intermediate epoch [198] result


[2022-04-08 09:16:49 | train] - -------199 epoch start-----------
========================================
----- test end -------------------------


[2022-04-08 09:16:50 | train] - Train Epoch: [199] [0/1281167 (0%)]	Loss: 0.597283
[2022-04-08 09:17:13 | train] - Train Epoch: [199] [12800/1281167 (1%)]	Loss: 0.879270
[2022-04-08 09:17:36 | train] - Train Epoch: [199] [25600/1281167 (2%)]	Loss: 0.572670
[2022-04-08 09:18:00 | train] - Train Epoch: [199] [38400/1281167 (3%)]	Loss: 0.693674
[2022-04-08 09:18:23 | train] - Train Epoch: [199] [51200/1281167 (4%)]	Loss: 0.588393
[2022-04-08 09:18:46 | train] - Train Epoch: [199] [64000/1281167 (5%)]	Loss: 0.832679
[2022-04-08 09:19:09 | train] - Train Epoch: [199] [76800/1281167 (6%)]	Loss: 0.573382
[2022-04-08 09:19:32 | train] - Train Epoch: [199] [89600/1281167 (7%)]	Loss: 0.616746
[2022-04-08 09:19:56 | train] - Train Epoch: [199] [102400/1281167 (8%)]	Loss: 0.665225
[2022-04-08 09:20:20 | train] - Train Epoch: [199] [115200/1281167 (9%)]	Loss: 0.718869
[2022-04-08 09:20:42 | train] - Train Epoch: [199] [128000/1281167 (10%)]	Loss: 0.659531
[2022-04-08 09:21:05 | train] - Train Epoch: [199] [140800/1281167 (11%)]	Loss: 0.861748
[2022-04-08 09:21:28 | train] - Train Epoch: [199] [153600/1281167 (12%)]	Loss: 0.866831
[2022-04-08 09:21:51 | train] - Train Epoch: [199] [166400/1281167 (13%)]	Loss: 0.859436
[2022-04-08 09:22:15 | train] - Train Epoch: [199] [179200/1281167 (14%)]	Loss: 1.016652
[2022-04-08 09:22:38 | train] - Train Epoch: [199] [192000/1281167 (15%)]	Loss: 0.679978
[2022-04-08 09:23:00 | train] - Train Epoch: [199] [204800/1281167 (16%)]	Loss: 0.780704
[2022-04-08 09:23:24 | train] - Train Epoch: [199] [217600/1281167 (17%)]	Loss: 0.772328
[2022-04-08 09:23:47 | train] - Train Epoch: [199] [230400/1281167 (18%)]	Loss: 0.900670
[2022-04-08 09:24:10 | train] - Train Epoch: [199] [243200/1281167 (19%)]	Loss: 0.714021
[2022-04-08 09:24:33 | train] - Train Epoch: [199] [256000/1281167 (20%)]	Loss: 0.773050
[2022-04-08 09:24:56 | train] - Train Epoch: [199] [268800/1281167 (21%)]	Loss: 0.812903
[2022-04-08 09:25:19 | train] - Train Epoch: [199] [281600/1281167 (22%)]	Loss: 0.669282
[2022-04-08 09:25:42 | train] - Train Epoch: [199] [294400/1281167 (23%)]	Loss: 0.712326
[2022-04-08 09:26:05 | train] - Train Epoch: [199] [307200/1281167 (24%)]	Loss: 0.678562
[2022-04-08 09:26:28 | train] - Train Epoch: [199] [320000/1281167 (25%)]	Loss: 0.861814
[2022-04-08 09:26:52 | train] - Train Epoch: [199] [332800/1281167 (26%)]	Loss: 0.637189
[2022-04-08 09:27:14 | train] - Train Epoch: [199] [345600/1281167 (27%)]	Loss: 0.813495
[2022-04-08 09:27:37 | train] - Train Epoch: [199] [358400/1281167 (28%)]	Loss: 0.839644
[2022-04-08 09:28:00 | train] - Train Epoch: [199] [371200/1281167 (29%)]	Loss: 0.752887
[2022-04-08 09:28:23 | train] - Train Epoch: [199] [384000/1281167 (30%)]	Loss: 0.772924
[2022-04-08 09:28:46 | train] - Train Epoch: [199] [396800/1281167 (31%)]	Loss: 0.605282
[2022-04-08 09:29:09 | train] - Train Epoch: [199] [409600/1281167 (32%)]	Loss: 1.015517
[2022-04-08 09:29:33 | train] - Train Epoch: [199] [422400/1281167 (33%)]	Loss: 0.925173
[2022-04-08 09:29:55 | train] - Train Epoch: [199] [435200/1281167 (34%)]	Loss: 1.017890
[2022-04-08 09:30:18 | train] - Train Epoch: [199] [448000/1281167 (35%)]	Loss: 0.732791
[2022-04-08 09:30:41 | train] - Train Epoch: [199] [460800/1281167 (36%)]	Loss: 0.553481
[2022-04-08 09:31:04 | train] - Train Epoch: [199] [473600/1281167 (37%)]	Loss: 0.932103
[2022-04-08 09:31:27 | train] - Train Epoch: [199] [486400/1281167 (38%)]	Loss: 0.707182
[2022-04-08 09:31:50 | train] - Train Epoch: [199] [499200/1281167 (39%)]	Loss: 0.842235
[2022-04-08 09:32:14 | train] - Train Epoch: [199] [512000/1281167 (40%)]	Loss: 1.083690
[2022-04-08 09:32:37 | train] - Train Epoch: [199] [524800/1281167 (41%)]	Loss: 0.674626
[2022-04-08 09:33:00 | train] - Train Epoch: [199] [537600/1281167 (42%)]	Loss: 0.904919
[2022-04-08 09:33:23 | train] - Train Epoch: [199] [550400/1281167 (43%)]	Loss: 0.704101
[2022-04-08 09:33:46 | train] - Train Epoch: [199] [563200/1281167 (44%)]	Loss: 0.791811
[2022-04-08 09:34:09 | train] - Train Epoch: [199] [576000/1281167 (45%)]	Loss: 0.564078
[2022-04-08 09:34:32 | train] - Train Epoch: [199] [588800/1281167 (46%)]	Loss: 0.856604
[2022-04-08 09:34:55 | train] - Train Epoch: [199] [601600/1281167 (47%)]	Loss: 0.901359
[2022-04-08 09:35:18 | train] - Train Epoch: [199] [614400/1281167 (48%)]	Loss: 0.858782
[2022-04-08 09:35:41 | train] - Train Epoch: [199] [627200/1281167 (49%)]	Loss: 0.979772
[2022-04-08 09:36:04 | train] - Train Epoch: [199] [640000/1281167 (50%)]	Loss: 0.855574
[2022-04-08 09:36:28 | train] - Train Epoch: [199] [652800/1281167 (51%)]	Loss: 0.941043
[2022-04-08 09:36:51 | train] - Train Epoch: [199] [665600/1281167 (52%)]	Loss: 0.681289
[2022-04-08 09:37:14 | train] - Train Epoch: [199] [678400/1281167 (53%)]	Loss: 0.836932
[2022-04-08 09:37:37 | train] - Train Epoch: [199] [691200/1281167 (54%)]	Loss: 0.879799
[2022-04-08 09:38:00 | train] - Train Epoch: [199] [704000/1281167 (55%)]	Loss: 0.923171
[2022-04-08 09:38:22 | train] - Train Epoch: [199] [716800/1281167 (56%)]	Loss: 0.686192
[2022-04-08 09:38:46 | train] - Train Epoch: [199] [729600/1281167 (57%)]	Loss: 0.632187
[2022-04-08 09:39:09 | train] - Train Epoch: [199] [742400/1281167 (58%)]	Loss: 0.786484
[2022-04-08 09:39:32 | train] - Train Epoch: [199] [755200/1281167 (59%)]	Loss: 0.644200
[2022-04-08 09:39:55 | train] - Train Epoch: [199] [768000/1281167 (60%)]	Loss: 0.762155
[2022-04-08 09:40:18 | train] - Train Epoch: [199] [780800/1281167 (61%)]	Loss: 0.683501
[2022-04-08 09:40:42 | train] - Train Epoch: [199] [793600/1281167 (62%)]	Loss: 0.740464
[2022-04-08 09:41:05 | train] - Train Epoch: [199] [806400/1281167 (63%)]	Loss: 0.796714
[2022-04-08 09:41:28 | train] - Train Epoch: [199] [819200/1281167 (64%)]	Loss: 0.796091
[2022-04-08 09:41:50 | train] - Train Epoch: [199] [832000/1281167 (65%)]	Loss: 0.683002
[2022-04-08 09:42:14 | train] - Train Epoch: [199] [844800/1281167 (66%)]	Loss: 0.757869
[2022-04-08 09:42:37 | train] - Train Epoch: [199] [857600/1281167 (67%)]	Loss: 0.669175
[2022-04-08 09:42:59 | train] - Train Epoch: [199] [870400/1281167 (68%)]	Loss: 0.713181
[2022-04-08 09:43:22 | train] - Train Epoch: [199] [883200/1281167 (69%)]	Loss: 0.599872
[2022-04-08 09:43:45 | train] - Train Epoch: [199] [896000/1281167 (70%)]	Loss: 0.667669
[2022-04-08 09:44:09 | train] - Train Epoch: [199] [908800/1281167 (71%)]	Loss: 0.677303
[2022-04-08 09:44:32 | train] - Train Epoch: [199] [921600/1281167 (72%)]	Loss: 0.677163
[2022-04-08 09:44:54 | train] - Train Epoch: [199] [934400/1281167 (73%)]	Loss: 0.694741
[2022-04-08 09:45:17 | train] - Train Epoch: [199] [947200/1281167 (74%)]	Loss: 0.479747
[2022-04-08 09:45:40 | train] - Train Epoch: [199] [960000/1281167 (75%)]	Loss: 0.721599
[2022-04-08 09:46:03 | train] - Train Epoch: [199] [972800/1281167 (76%)]	Loss: 0.587470
[2022-04-08 09:46:26 | train] - Train Epoch: [199] [985600/1281167 (77%)]	Loss: 0.591439
[2022-04-08 09:46:49 | train] - Train Epoch: [199] [998400/1281167 (78%)]	Loss: 0.676093
[2022-04-08 09:47:12 | train] - Train Epoch: [199] [1011200/1281167 (79%)]	Loss: 0.911489
[2022-04-08 09:47:35 | train] - Train Epoch: [199] [1024000/1281167 (80%)]	Loss: 0.702231
[2022-04-08 09:47:58 | train] - Train Epoch: [199] [1036800/1281167 (81%)]	Loss: 0.824377
[2022-04-08 09:48:21 | train] - Train Epoch: [199] [1049600/1281167 (82%)]	Loss: 0.780012
[2022-04-08 09:48:44 | train] - Train Epoch: [199] [1062400/1281167 (83%)]	Loss: 0.640387
[2022-04-08 09:49:07 | train] - Train Epoch: [199] [1075200/1281167 (84%)]	Loss: 0.852008
[2022-04-08 09:49:30 | train] - Train Epoch: [199] [1088000/1281167 (85%)]	Loss: 0.786871
[2022-04-08 09:49:53 | train] - Train Epoch: [199] [1100800/1281167 (86%)]	Loss: 0.838557
[2022-04-08 09:50:16 | train] - Train Epoch: [199] [1113600/1281167 (87%)]	Loss: 0.738577
[2022-04-08 09:50:40 | train] - Train Epoch: [199] [1126400/1281167 (88%)]	Loss: 0.666035
[2022-04-08 09:51:03 | train] - Train Epoch: [199] [1139200/1281167 (89%)]	Loss: 0.905880
[2022-04-08 09:51:26 | train] - Train Epoch: [199] [1152000/1281167 (90%)]	Loss: 0.852175
[2022-04-08 09:51:49 | train] - Train Epoch: [199] [1164800/1281167 (91%)]	Loss: 0.854611
[2022-04-08 09:52:12 | train] - Train Epoch: [199] [1177600/1281167 (92%)]	Loss: 0.730480
[2022-04-08 09:52:35 | train] - Train Epoch: [199] [1190400/1281167 (93%)]	Loss: 0.791299
[2022-04-08 09:52:58 | train] - Train Epoch: [199] [1203200/1281167 (94%)]	Loss: 0.677243
[2022-04-08 09:53:21 | train] - Train Epoch: [199] [1216000/1281167 (95%)]	Loss: 0.733654
[2022-04-08 09:53:44 | train] - Train Epoch: [199] [1228800/1281167 (96%)]	Loss: 0.837555
[2022-04-08 09:54:08 | train] - Train Epoch: [199] [1241600/1281167 (97%)]	Loss: 0.827876
[2022-04-08 09:54:30 | train] - Train Epoch: [199] [1254400/1281167 (98%)]	Loss: 0.959572
[2022-04-08 09:54:53 | train] - Train Epoch: [199] [1267200/1281167 (99%)]	Loss: 0.704525
[2022-04-08 09:55:16 | train] - Train Epoch: [199] [1280000/1281167 (100%)]	Loss: 0.639005
[2022-04-08 09:55:18 | train] - Train Epoch: [199]	 Average Loss: 0.754611	 Total Acc : 81.5787	 Total Top5 Acc : 93.3006
[2022-04-08 09:55:18 | train] - -------199 epoch end-----------
========================================
-------199 epoch end  -----------

----- test and print accuracy ------------------
[2022-04-08 09:56:55 | train] - 
Epoch [199] Test set: Average loss: 1.4517, Accuracy: 34860/50000 (69.6927%), Top-5 Accuracy: 88.8043%

[2022-04-08 09:56:55 | train] - save intermediate epoch [199] result


========================================
----- test end -------------------------


[I 15:54:31.353 NotebookApp] 302 GET / (10.150.7.107) 15.330000ms
[W 15:54:36.129 NotebookApp] Notebook Untitled.ipynb is not trusted
[I 15:54:59.831 NotebookApp] 302 GET / (10.150.7.107) 0.770000ms
[W 15:55:05.809 NotebookApp] Notebook Untitled.ipynb is not trusted
[W 16:00:02.558 NotebookApp] Notebook Untitled.ipynb is not trusted
[W 16:00:07.806 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 16:00:36.240 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:00:36.241 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:00:36.242 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:02:07.992 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:02:07.993 NotebookApp] Saving pdh_test.ipynb
[W 16:02:07.993 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 16:04:36.239 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:04:36.240 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:04:36.240 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[W 16:04:52.862 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:06:09.004 NotebookApp] Saving file at /pdh_test.ipynb
[I 16:06:09.005 NotebookApp] Saving pdh_test.ipynb
[W 16:06:09.005 NotebookApp] Notebook pdh_test.ipynb is not trusted
[W 16:06:38.447 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:06:53.025 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:06:53.026 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:06:53.026 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:08:53.016 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:08:53.017 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:08:53.017 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:10:53.019 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:10:53.019 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:10:53.020 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:12:53.018 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:12:53.019 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:12:53.019 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:14:53.026 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:14:53.027 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:14:53.027 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:16:53.038 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:16:53.039 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:16:53.047 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:20:53.039 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:20:53.040 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:20:53.040 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:26:53.056 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:26:53.056 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:26:53.057 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:28:53.044 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:28:53.045 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:28:53.045 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:38:53.089 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:38:53.090 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:38:53.090 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:40:53.068 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:40:53.068 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:40:53.068 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:42:53.079 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:42:53.079 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:42:53.079 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:44:53.073 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:44:53.074 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:44:53.074 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:46:53.079 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:46:53.080 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:46:53.080 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:48:53.081 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:48:53.082 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:48:53.082 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:50:53.084 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:50:53.085 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:50:53.085 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:52:53.093 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:52:53.094 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:52:53.094 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:54:53.091 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:54:53.092 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:54:53.092 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:56:53.107 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:56:53.108 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:56:53.108 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 16:58:53.100 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 16:58:53.101 NotebookApp] Saving imagenet_resnet50.ipynb
[W 16:58:53.101 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:00:53.102 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:00:53.103 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:00:53.103 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:04:53.108 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:04:53.109 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:04:53.109 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:06:53.108 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:06:53.109 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:06:53.109 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:08:53.122 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:08:53.123 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:08:53.123 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:10:53.112 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:10:53.112 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:10:53.113 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:12:53.149 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:12:53.150 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:12:53.150 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:14:53.128 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:14:53.129 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:14:53.129 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:16:53.139 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:16:53.140 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:16:53.140 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:18:53.143 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:18:53.144 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:18:53.144 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:20:53.143 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:20:53.144 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:20:53.144 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:22:53.149 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:22:53.150 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:22:53.150 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:24:53.151 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:24:53.152 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:24:53.152 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:26:53.139 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:26:53.139 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:26:53.140 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:28:53.156 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:28:53.157 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:28:53.158 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:30:53.157 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:30:53.158 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:30:53.158 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:32:53.153 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:32:53.154 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:32:53.154 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:34:53.174 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:34:53.175 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:34:53.175 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:36:53.169 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:36:53.170 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:36:53.178 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:38:53.166 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:38:53.166 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:38:53.167 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:40:10.529 NotebookApp] Kernel restarted: d6795a48-6c4e-4456-8ce6-0d102073ec65
[I 17:40:53.178 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:40:53.179 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:40:53.180 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:42:53.188 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:42:53.189 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:42:53.189 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:44:53.172 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:44:53.172 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:44:53.172 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:50:53.395 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:50:53.396 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:50:53.397 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:52:53.185 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:52:53.185 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:52:53.186 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:54:53.194 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:54:53.195 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:54:53.195 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:00:53.233 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:00:53.234 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:00:53.234 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:02:53.218 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:02:53.219 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:02:53.220 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:04:53.207 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:04:53.207 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:04:53.208 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:06:53.225 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:06:53.225 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:06:53.226 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:08:53.216 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:08:53.217 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:08:53.217 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:10:53.220 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:10:53.221 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:10:53.221 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:12:53.223 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:12:53.224 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:12:53.224 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:14:53.231 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:14:53.231 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:14:53.232 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:16:53.230 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:16:53.231 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:16:53.232 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:18:53.235 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:18:53.235 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:18:53.236 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:22:53.248 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:22:53.249 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:22:53.249 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:24:53.246 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:24:53.247 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:24:53.248 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:26:53.243 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:26:53.243 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:26:53.244 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:28:53.254 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:28:53.254 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:28:53.255 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:30:53.267 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:30:53.268 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:30:53.268 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:32:53.253 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:32:53.254 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:32:53.254 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:34:53.265 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:34:53.266 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:34:53.266 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:36:53.263 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:36:53.264 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:36:53.264 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:38:53.266 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:38:53.267 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:38:53.268 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:40:53.272 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:40:53.272 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:40:53.273 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:42:53.284 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:42:53.285 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:42:53.286 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:44:12.056 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:44:12.057 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:44:12.058 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:44:53.271 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:44:53.272 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:44:53.272 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:46:53.293 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:46:53.294 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:46:53.294 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:48:53.286 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:48:53.286 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:48:53.287 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:50:44.563 NotebookApp] Kernel interrupted: d6795a48-6c4e-4456-8ce6-0d102073ec65
[I 18:50:53.288 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:50:53.288 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:50:53.289 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:52:53.292 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:52:53.293 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:52:53.294 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:54:53.299 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:54:53.299 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:54:53.300 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:55:40.781 NotebookApp] Kernel interrupted: d6795a48-6c4e-4456-8ce6-0d102073ec65
[I 18:56:53.311 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:56:53.312 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:56:53.312 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:58:53.317 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:58:53.317 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:58:53.318 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:00:53.316 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:00:53.317 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:00:53.318 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:02:53.345 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:02:53.346 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:02:53.347 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:04:53.348 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:04:53.349 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:04:53.350 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:06:53.353 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:06:53.354 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:06:53.355 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:08:53.366 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:08:53.366 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:08:53.367 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:10:53.381 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:10:53.382 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:10:53.383 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:12:53.390 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:12:53.391 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:12:53.392 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:14:54.380 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:14:54.381 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:14:54.382 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:32:53.482 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:32:53.483 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:32:53.483 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[W 20:32:03.944 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:41:51.065 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:a6af177adfbe4f4eb395d32534c2fa49
[I 03:20:02.408 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:8c774da21ea84d58b7e20f69d8f6b7f6
[W 03:20:02.862 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:12:29.750 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:061068dd86c343e0acb399f84eb97952
[I 18:23:21.466 NotebookApp] 302 GET / (10.150.7.107) 1.080000ms
[W 18:23:26.331 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:46:01.484 NotebookApp] Kernel interrupted: d6795a48-6c4e-4456-8ce6-0d102073ec65
[I 18:47:27.141 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:47:27.143 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:47:27.144 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:49:27.986 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:49:27.987 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:49:27.988 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:51:27.996 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:51:27.997 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:51:27.998 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:53:28.000 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:53:28.001 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:53:28.002 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:55:28.020 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:55:28.021 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:55:28.021 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:57:28.017 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:57:28.018 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:57:28.019 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:59:28.351 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:59:28.352 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:59:28.352 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:01:28.064 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:01:28.065 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:01:28.066 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:03:28.043 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:03:28.044 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:03:28.045 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:11:27.085 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:11:27.086 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:11:27.086 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:13:27.085 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:13:27.086 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:13:27.086 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:15:27.434 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:15:27.435 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:15:27.436 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:17:27.450 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:17:27.452 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:17:27.453 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:19:27.132 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:19:27.133 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:19:27.134 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:21:27.126 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:21:27.127 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:21:27.128 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:27:27.031 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:27:27.032 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:27:27.033 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:29:27.912 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:29:27.913 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:29:27.913 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:29:26.809 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:29:26.810 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:29:26.810 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:31:27.129 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:31:27.130 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:31:27.131 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:33:26.802 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:33:26.803 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:33:26.803 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:35:26.781 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:35:26.782 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:35:26.783 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:37:26.789 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:37:26.790 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:37:26.790 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:39:26.802 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:39:26.803 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:39:26.803 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 03:55:26.711 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 03:55:26.711 NotebookApp] Saving imagenet_resnet50.ipynb
[W 03:55:26.712 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 03:57:27.023 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 03:57:27.024 NotebookApp] Saving imagenet_resnet50.ipynb
[W 03:57:27.024 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 03:59:27.573 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 03:59:27.574 NotebookApp] Saving imagenet_resnet50.ipynb
[W 03:59:27.574 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:01:26.666 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:01:26.667 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:01:26.667 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:03:26.681 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:03:26.682 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:03:26.682 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:05:26.673 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:05:26.674 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:05:26.674 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:07:26.699 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:07:26.700 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:07:26.701 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:09:26.700 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:09:26.700 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:09:26.701 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:12:27.326 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:7017eb7d0a734208846fa1f64a2fe12d
[I 17:50:06.670 NotebookApp] 302 GET / (10.150.7.107) 1.220000ms
[W 17:50:13.103 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:52:13.695 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:52:13.696 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:52:13.698 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:54:13.811 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:54:13.812 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:54:13.813 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:56:13.687 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:56:13.687 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:56:13.688 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 17:58:13.713 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 17:58:13.714 NotebookApp] Saving imagenet_resnet50.ipynb
[W 17:58:13.715 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:14:13.701 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:14:13.702 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:14:13.703 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:16:13.808 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:16:13.809 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:16:13.810 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:18:13.700 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:18:13.700 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:18:13.701 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:20:13.684 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:20:13.685 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:20:13.686 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:22:13.707 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:22:13.708 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:22:13.709 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:28:13.789 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:28:13.790 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:28:13.791 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:30:13.793 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:30:13.795 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:30:13.796 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:32:14.144 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:32:14.144 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:32:14.145 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:46:13.777 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:46:13.778 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:46:13.779 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:48:14.010 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:48:14.012 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:48:14.013 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:50:13.685 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:50:13.686 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:50:13.686 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:52:13.764 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:52:13.765 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:52:13.766 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:54:13.781 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:54:13.782 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:54:13.783 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 18:56:13.797 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 18:56:13.798 NotebookApp] Saving imagenet_resnet50.ipynb
[W 18:56:13.799 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:10:13.773 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:10:13.774 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:10:13.774 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:12:13.757 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:12:13.758 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:12:13.759 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:14:14.009 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:14:14.010 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:14:14.011 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:16:13.654 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:16:13.655 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:16:13.656 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:18:13.667 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:18:13.668 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:18:13.669 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:42:13.758 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:42:13.759 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:42:13.759 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:52:13.655 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:52:13.656 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:52:13.657 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:54:13.942 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:54:13.943 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:54:13.943 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 19:56:13.642 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 19:56:13.642 NotebookApp] Saving imagenet_resnet50.ipynb
[W 19:56:13.643 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:02:13.973 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:02:13.974 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:02:13.975 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:04:13.638 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:04:13.640 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:04:13.641 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:06:13.710 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:06:13.711 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:06:13.711 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:08:13.721 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:08:13.722 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:08:13.723 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:10:13.635 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:10:13.636 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:10:13.637 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:12:13.704 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:12:13.705 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:12:13.706 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:14:13.717 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:14:13.718 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:14:13.718 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:18:13.600 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:18:13.601 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:18:13.602 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:20:13.612 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:20:13.613 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:20:13.614 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:22:13.712 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:22:13.713 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:22:13.714 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:24:13.609 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:24:13.610 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:24:13.611 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:26:13.629 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:26:13.631 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:26:13.632 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:28:13.669 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:28:13.670 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:28:13.671 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:30:13.664 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:30:13.665 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:30:13.666 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 20:32:13.771 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 20:32:13.772 NotebookApp] Saving imagenet_resnet50.ipynb
[W 20:32:13.773 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 21:50:13.608 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 21:50:13.609 NotebookApp] Saving imagenet_resnet50.ipynb
[W 21:50:13.610 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 02:29:43.261 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:e22e11922a6e45f2b755eed50e603c52
[I 13:58:17.736 NotebookApp] 302 GET / (10.150.7.189) 1.040000ms
[I 13:58:17.751 NotebookApp] 302 GET /tree? (10.150.7.189) 1.060000ms
[I 13:58:20.197 NotebookApp] 302 POST /login?next=%2Ftree%3F (10.150.7.189) 80.970000ms
[W 13:58:24.698 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:00:24.882 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:00:24.883 NotebookApp] Saving pdh_test.ipynb
[W 14:00:24.883 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:02:25.167 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:02:25.168 NotebookApp] Saving pdh_test.ipynb
[W 14:02:25.168 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:14:25.165 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:14:25.165 NotebookApp] Saving pdh_test.ipynb
[W 14:14:25.166 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:22:24.901 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:22:24.902 NotebookApp] Saving pdh_test.ipynb
[W 14:22:24.903 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:24:25.175 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:24:25.177 NotebookApp] Saving pdh_test.ipynb
[W 14:24:25.177 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 14:30:25.170 NotebookApp] Saving file at /pdh_test.ipynb
[I 14:30:25.171 NotebookApp] Saving pdh_test.ipynb
[W 14:30:25.171 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 15:34:25.273 NotebookApp] Saving file at /pdh_test.ipynb
[I 15:34:25.274 NotebookApp] Saving pdh_test.ipynb
[W 15:34:25.274 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 12:35:39.770 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:94fb2bdf5239408589ec217164c77864
[I 12:42:05.725 NotebookApp] 302 GET / (10.150.7.189) 0.680000ms
[W 12:42:22.348 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 15:12:35.357 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:a2a1e4f6fe20460db038a35db4b11c40
[I 00:03:53.951 NotebookApp] 302 GET / (10.150.7.107) 0.890000ms
[W 00:03:59.494 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:06:00.344 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:06:00.345 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:06:00.346 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:08:00.349 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:08:00.350 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:08:00.351 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:12:00.332 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:12:00.333 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:12:00.341 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:14:00.353 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:14:00.354 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:14:00.355 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:16:02.671 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:16:02.672 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:16:02.673 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:26:00.653 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:26:00.654 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:26:00.655 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:28:00.340 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:28:00.341 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:28:00.342 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:38:00.326 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:38:00.327 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:38:00.328 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:40:00.336 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:40:00.337 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:40:00.338 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:42:00.322 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:42:00.323 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:42:00.324 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:54:00.334 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:54:00.335 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:54:00.336 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:56:00.330 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:56:00.331 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:56:00.332 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 00:58:00.317 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 00:58:00.319 NotebookApp] Saving imagenet_resnet50.ipynb
[W 00:58:00.320 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:02:00.318 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:02:00.319 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:02:00.320 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:08:00.330 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:08:00.331 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:08:00.332 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:12:00.618 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:12:00.619 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:12:00.619 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:16:00.629 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:16:00.630 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:16:00.631 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:18:00.310 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:18:00.311 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:18:00.312 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:20:00.300 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:20:00.300 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:20:00.301 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:24:00.293 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:24:00.294 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:24:00.295 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:26:00.292 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:26:00.293 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:26:00.294 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:28:01.190 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:28:01.191 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:28:01.192 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:30:00.288 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:30:00.289 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:30:00.290 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:32:00.287 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:32:00.288 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:32:00.289 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:42:00.618 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:42:00.618 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:42:00.619 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:52:00.683 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:52:00.683 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:52:00.684 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:54:01.179 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:54:01.179 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:54:01.180 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:56:00.292 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:56:00.293 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:56:00.293 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 01:58:00.279 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 01:58:00.279 NotebookApp] Saving imagenet_resnet50.ipynb
[W 01:58:00.280 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 02:00:00.278 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 02:00:00.279 NotebookApp] Saving imagenet_resnet50.ipynb
[W 02:00:00.280 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:12:00.183 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:12:00.184 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:12:00.185 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:14:00.159 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:14:00.159 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:14:00.160 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:16:00.199 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:16:00.200 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:16:00.201 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:18:00.158 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:18:00.159 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:18:00.160 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:20:00.161 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:20:00.162 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:20:00.163 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:22:00.150 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:22:00.151 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:22:00.152 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:24:00.167 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:24:00.168 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:24:00.169 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:38:01.049 NotebookApp] Saving file at /imagenet_resnet50.ipynb
[I 04:38:01.050 NotebookApp] Saving imagenet_resnet50.ipynb
[W 04:38:01.051 NotebookApp] Notebook imagenet_resnet50.ipynb is not trusted
[I 04:54:34.110 NotebookApp] Starting buffering for d6795a48-6c4e-4456-8ce6-0d102073ec65:a5d592f441a7443e8a772bca6d49d5b7
[I 09:11:31.045 NotebookApp] 302 GET / (10.150.7.189) 0.960000ms
[I 11:20:19.430 NotebookApp] 302 GET / (10.150.7.189) 0.580000ms
[W 11:20:26.761 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 11:22:27.908 NotebookApp] Saving file at /pdh_test.ipynb
[I 11:22:27.909 NotebookApp] Saving pdh_test.ipynb
[W 11:22:27.910 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 11:26:27.898 NotebookApp] Saving file at /pdh_test.ipynb
[I 11:26:27.899 NotebookApp] Saving pdh_test.ipynb
[W 11:26:27.899 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 11:29:55.317 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:2047bdd9cfde44fd8e5f5aa6b2e3cf97
[I 11:29:59.467 NotebookApp] Kernel restarted: 70aafaca-033a-4a2c-a6f9-8d60068e7fa8
[I 11:29:59.477 NotebookApp] Restoring connection for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:2047bdd9cfde44fd8e5f5aa6b2e3cf97
[I 11:30:01.064 NotebookApp] Replaying 3 buffered messages
[I 11:30:26.998 NotebookApp] Saving file at /pdh_test.ipynb
[I 11:30:26.999 NotebookApp] Saving pdh_test.ipynb
[W 11:30:26.999 NotebookApp] Notebook pdh_test.ipynb is not trusted
[I 11:58:12.778 NotebookApp] Starting buffering for 70aafaca-033a-4a2c-a6f9-8d60068e7fa8:2047bdd9cfde44fd8e5f5aa6b2e3cf97
[2022-06-07 13:09:26 | train] - -------start logging -----------

[2022-06-07 13:09:26 | train] - -------end logging -----------

[2022-06-07 13:09:26 | train] - -------0 epoch start-----------
[2022-06-07 13:09:26 | train] - -------- logging 0 batch layer input tensor ------------------
[2022-06-07 13:10:01 | train] - -------- logging end 0 --------------------
train resnet50im
/data/kjh/save_fix_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_fix_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-07 13:10:04 | train] - Train Epoch: [0] [0/1281167 (0%)]	Loss: 7.109443
[2022-06-07 13:10:36 | train] - Train Epoch: [0] [12800/1281167 (1%)]	Loss: 7.038188
[2022-06-07 13:11:04 | train] - Train Epoch: [0] [25600/1281167 (2%)]	Loss: 7.101823
[2022-06-07 13:11:32 | train] - Train Epoch: [0] [38400/1281167 (3%)]	Loss: 6.960819
[2022-06-07 13:12:00 | train] - Train Epoch: [0] [51200/1281167 (4%)]	Loss: 6.979956
[2022-06-07 13:12:28 | train] - Train Epoch: [0] [64000/1281167 (5%)]	Loss: 7.018808
[2022-06-07 13:12:56 | train] - Train Epoch: [0] [76800/1281167 (6%)]	Loss: 6.988900
[2022-06-07 13:13:25 | train] - Train Epoch: [0] [89600/1281167 (7%)]	Loss: 6.918155
[2022-06-07 13:13:53 | train] - Train Epoch: [0] [102400/1281167 (8%)]	Loss: 6.953568
[2022-06-07 13:14:21 | train] - Train Epoch: [0] [115200/1281167 (9%)]	Loss: 6.930660
[2022-06-07 13:14:49 | train] - Train Epoch: [0] [128000/1281167 (10%)]	Loss: 6.908714
[2022-06-07 13:15:17 | train] - Train Epoch: [0] [140800/1281167 (11%)]	Loss: 6.896067
[2022-06-07 13:15:45 | train] - Train Epoch: [0] [153600/1281167 (12%)]	Loss: 6.859577
[2022-06-07 13:16:13 | train] - Train Epoch: [0] [166400/1281167 (13%)]	Loss: 6.885120
[2022-06-07 13:16:41 | train] - Train Epoch: [0] [179200/1281167 (14%)]	Loss: 6.946439
[2022-06-07 13:17:09 | train] - Train Epoch: [0] [192000/1281167 (15%)]	Loss: 6.871943
[2022-06-07 13:17:37 | train] - Train Epoch: [0] [204800/1281167 (16%)]	Loss: 6.870476
[2022-06-07 13:18:05 | train] - Train Epoch: [0] [217600/1281167 (17%)]	Loss: 6.839922
[2022-06-07 13:18:33 | train] - Train Epoch: [0] [230400/1281167 (18%)]	Loss: 6.873247
[2022-06-07 13:19:01 | train] - Train Epoch: [0] [243200/1281167 (19%)]	Loss: 6.866815
[2022-06-07 13:19:29 | train] - Train Epoch: [0] [256000/1281167 (20%)]	Loss: 6.861576
[2022-06-07 13:19:57 | train] - Train Epoch: [0] [268800/1281167 (21%)]	Loss: 6.884692
[2022-06-07 13:20:25 | train] - Train Epoch: [0] [281600/1281167 (22%)]	Loss: 6.837898
[2022-06-07 13:20:53 | train] - Train Epoch: [0] [294400/1281167 (23%)]	Loss: 6.819023
[2022-06-07 13:21:21 | train] - Train Epoch: [0] [307200/1281167 (24%)]	Loss: 6.801650
[2022-06-07 13:21:49 | train] - Train Epoch: [0] [320000/1281167 (25%)]	Loss: 6.865116
[2022-06-07 13:22:17 | train] - Train Epoch: [0] [332800/1281167 (26%)]	Loss: 6.818411
[2022-06-07 13:22:45 | train] - Train Epoch: [0] [345600/1281167 (27%)]	Loss: 6.838171
[2022-06-07 13:23:13 | train] - Train Epoch: [0] [358400/1281167 (28%)]	Loss: 6.858022
[2022-06-07 13:23:42 | train] - Train Epoch: [0] [371200/1281167 (29%)]	Loss: 6.810039
[2022-06-07 13:24:10 | train] - Train Epoch: [0] [384000/1281167 (30%)]	Loss: 6.825139
[2022-06-07 13:24:38 | train] - Train Epoch: [0] [396800/1281167 (31%)]	Loss: 6.776735
[2022-06-07 13:25:06 | train] - Train Epoch: [0] [409600/1281167 (32%)]	Loss: 6.861660
[2022-06-07 13:25:34 | train] - Train Epoch: [0] [422400/1281167 (33%)]	Loss: 6.864592
[2022-06-07 13:26:02 | train] - Train Epoch: [0] [435200/1281167 (34%)]	Loss: 6.818261
[2022-06-07 13:26:30 | train] - Train Epoch: [0] [448000/1281167 (35%)]	Loss: 6.783568
[2022-06-07 13:26:58 | train] - Train Epoch: [0] [460800/1281167 (36%)]	Loss: 6.745267
[2022-06-07 13:27:26 | train] - Train Epoch: [0] [473600/1281167 (37%)]	Loss: 6.848948
[2022-06-07 13:27:54 | train] - Train Epoch: [0] [486400/1281167 (38%)]	Loss: 6.807338
[2022-06-07 13:28:22 | train] - Train Epoch: [0] [499200/1281167 (39%)]	Loss: 6.747507
[2022-06-07 13:28:50 | train] - Train Epoch: [0] [512000/1281167 (40%)]	Loss: 6.858716
[2022-06-07 13:29:18 | train] - Train Epoch: [0] [524800/1281167 (41%)]	Loss: 6.732770
[2022-06-07 13:29:46 | train] - Train Epoch: [0] [537600/1281167 (42%)]	Loss: 6.718219
[2022-06-07 13:30:14 | train] - Train Epoch: [0] [550400/1281167 (43%)]	Loss: 6.693536
[2022-06-07 13:30:42 | train] - Train Epoch: [0] [563200/1281167 (44%)]	Loss: 6.768546
[2022-06-07 13:31:10 | train] - Train Epoch: [0] [576000/1281167 (45%)]	Loss: 6.797960
[2022-06-07 13:31:38 | train] - Train Epoch: [0] [588800/1281167 (46%)]	Loss: 6.689312
[2022-06-07 13:32:06 | train] - Train Epoch: [0] [601600/1281167 (47%)]	Loss: 6.624250
[2022-06-07 13:32:34 | train] - Train Epoch: [0] [614400/1281167 (48%)]	Loss: 6.536618
[2022-06-07 13:33:02 | train] - Train Epoch: [0] [627200/1281167 (49%)]	Loss: 6.673204
[2022-06-07 13:33:30 | train] - Train Epoch: [0] [640000/1281167 (50%)]	Loss: 6.632006
[2022-06-07 13:33:58 | train] - Train Epoch: [0] [652800/1281167 (51%)]	Loss: 6.632529
[2022-06-07 13:34:30 | train] - Train Epoch: [0] [665600/1281167 (52%)]	Loss: 6.631306
[2022-06-07 13:35:02 | train] - Train Epoch: [0] [678400/1281167 (53%)]	Loss: 6.643799
[2022-06-07 13:35:23 | train] - Train Epoch: [0] [691200/1281167 (54%)]	Loss: 6.521821
[2022-06-07 13:35:45 | train] - Train Epoch: [0] [704000/1281167 (55%)]	Loss: 6.582853
[2022-06-07 13:36:07 | train] - Train Epoch: [0] [716800/1281167 (56%)]	Loss: 6.589083
[2022-06-07 13:36:29 | train] - Train Epoch: [0] [729600/1281167 (57%)]	Loss: 6.491466
[2022-06-07 13:36:51 | train] - Train Epoch: [0] [742400/1281167 (58%)]	Loss: 6.624080
[2022-06-07 13:37:13 | train] - Train Epoch: [0] [755200/1281167 (59%)]	Loss: 6.544035
[2022-06-07 13:37:35 | train] - Train Epoch: [0] [768000/1281167 (60%)]	Loss: 6.609504
[2022-06-07 13:37:56 | train] - Train Epoch: [0] [780800/1281167 (61%)]	Loss: 6.471691
[2022-06-07 13:38:18 | train] - Train Epoch: [0] [793600/1281167 (62%)]	Loss: 6.572143
[2022-06-07 13:38:40 | train] - Train Epoch: [0] [806400/1281167 (63%)]	Loss: 6.455246
[2022-06-07 13:39:04 | train] - Train Epoch: [0] [819200/1281167 (64%)]	Loss: 6.479747
[2022-06-07 13:39:27 | train] - Train Epoch: [0] [832000/1281167 (65%)]	Loss: 6.631402
[2022-06-07 13:39:51 | train] - Train Epoch: [0] [844800/1281167 (66%)]	Loss: 6.317882
[2022-06-07 13:40:15 | train] - Train Epoch: [0] [857600/1281167 (67%)]	Loss: 6.552110
[2022-06-07 13:40:39 | train] - Train Epoch: [0] [870400/1281167 (68%)]	Loss: 6.525548
[2022-06-07 13:41:03 | train] - Train Epoch: [0] [883200/1281167 (69%)]	Loss: 6.406441
[2022-06-07 13:41:26 | train] - Train Epoch: [0] [896000/1281167 (70%)]	Loss: 6.209236
[2022-06-07 13:41:49 | train] - Train Epoch: [0] [908800/1281167 (71%)]	Loss: 6.430323
[2022-06-07 13:42:13 | train] - Train Epoch: [0] [921600/1281167 (72%)]	Loss: 6.352263
[2022-06-07 13:42:37 | train] - Train Epoch: [0] [934400/1281167 (73%)]	Loss: 6.252367
[2022-06-07 13:43:01 | train] - Train Epoch: [0] [947200/1281167 (74%)]	Loss: 6.294704
[2022-06-07 13:43:24 | train] - Train Epoch: [0] [960000/1281167 (75%)]	Loss: 6.208540
[2022-06-07 13:43:47 | train] - Train Epoch: [0] [972800/1281167 (76%)]	Loss: 6.387971
[2022-06-07 13:44:10 | train] - Train Epoch: [0] [985600/1281167 (77%)]	Loss: 6.328165
[2022-06-07 13:44:34 | train] - Train Epoch: [0] [998400/1281167 (78%)]	Loss: 6.116852
[2022-06-07 13:44:57 | train] - Train Epoch: [0] [1011200/1281167 (79%)]	Loss: 6.130088
[2022-06-07 13:45:20 | train] - Train Epoch: [0] [1024000/1281167 (80%)]	Loss: 6.144495
[2022-06-07 13:45:44 | train] - Train Epoch: [0] [1036800/1281167 (81%)]	Loss: 6.063463
[2022-06-07 13:46:07 | train] - Train Epoch: [0] [1049600/1281167 (82%)]	Loss: 6.261727
[2022-06-07 13:46:29 | train] - Train Epoch: [0] [1062400/1281167 (83%)]	Loss: 6.075975
[2022-06-07 13:46:52 | train] - Train Epoch: [0] [1075200/1281167 (84%)]	Loss: 6.112543
[2022-06-07 13:47:15 | train] - Train Epoch: [0] [1088000/1281167 (85%)]	Loss: 5.921214
[2022-06-07 13:47:36 | train] - Train Epoch: [0] [1100800/1281167 (86%)]	Loss: 6.116915
[2022-06-07 13:47:58 | train] - Train Epoch: [0] [1113600/1281167 (87%)]	Loss: 6.057075
[2022-06-07 13:48:21 | train] - Train Epoch: [0] [1126400/1281167 (88%)]	Loss: 5.953308
[2022-06-07 13:48:43 | train] - Train Epoch: [0] [1139200/1281167 (89%)]	Loss: 6.187744
[2022-06-07 13:49:05 | train] - Train Epoch: [0] [1152000/1281167 (90%)]	Loss: 6.104252
[2022-06-07 13:49:27 | train] - Train Epoch: [0] [1164800/1281167 (91%)]	Loss: 5.990988
[2022-06-07 13:49:50 | train] - Train Epoch: [0] [1177600/1281167 (92%)]	Loss: 5.959211
[2022-06-07 13:50:13 | train] - Train Epoch: [0] [1190400/1281167 (93%)]	Loss: 5.943635
[2022-06-07 13:50:36 | train] - Train Epoch: [0] [1203200/1281167 (94%)]	Loss: 5.986260
[2022-06-07 13:50:59 | train] - Train Epoch: [0] [1216000/1281167 (95%)]	Loss: 6.021247
[2022-06-07 13:51:22 | train] - Train Epoch: [0] [1228800/1281167 (96%)]	Loss: 5.810485
[2022-06-07 13:51:45 | train] - Train Epoch: [0] [1241600/1281167 (97%)]	Loss: 5.878581
[2022-06-07 13:52:08 | train] - Train Epoch: [0] [1254400/1281167 (98%)]	Loss: 5.590057
[2022-06-07 13:52:30 | train] - Train Epoch: [0] [1267200/1281167 (99%)]	Loss: 5.969083
[2022-06-07 13:52:53 | train] - Train Epoch: [0] [1280000/1281167 (100%)]	Loss: 5.992537
[2022-06-07 13:52:55 | train] - Train Epoch: [0]	 Average Loss: 6.556440	 Total Acc : 1.0780	 Total Top5 Acc : 3.7072
[2022-06-07 13:52:55 | train] - -------0 epoch end-----------
========================================
-------0 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 13:54:32 | train] - 
Epoch [0] Test set: Average loss: 5.7996, Accuracy: 1893/50000 (3.7824%), Top-5 Accuracy: 11.2972%

[2022-06-07 13:54:32 | train] - save intermediate epoch [0] result


[2022-06-07 13:54:32 | train] - logging best performance 0 epoch
[2022-06-07 13:54:33 | train] - -------1 epoch start-----------
========================================
----- test end -------------------------


logging best performance 0 epoch
[2022-06-07 13:54:34 | train] - Train Epoch: [1] [0/1281167 (0%)]	Loss: 6.028047
[2022-06-07 13:54:57 | train] - Train Epoch: [1] [12800/1281167 (1%)]	Loss: 5.802866
[2022-06-07 13:55:19 | train] - Train Epoch: [1] [25600/1281167 (2%)]	Loss: 5.728394
[2022-06-07 13:55:41 | train] - Train Epoch: [1] [38400/1281167 (3%)]	Loss: 5.767605
[2022-06-07 13:56:04 | train] - Train Epoch: [1] [51200/1281167 (4%)]	Loss: 5.530654
[2022-06-07 13:56:26 | train] - Train Epoch: [1] [64000/1281167 (5%)]	Loss: 5.889191
[2022-06-07 13:56:49 | train] - Train Epoch: [1] [76800/1281167 (6%)]	Loss: 5.570868
[2022-06-07 13:57:11 | train] - Train Epoch: [1] [89600/1281167 (7%)]	Loss: 5.664110
[2022-06-07 13:57:33 | train] - Train Epoch: [1] [102400/1281167 (8%)]	Loss: 5.677552
[2022-06-07 13:57:55 | train] - Train Epoch: [1] [115200/1281167 (9%)]	Loss: 5.677850
[2022-06-07 13:58:17 | train] - Train Epoch: [1] [128000/1281167 (10%)]	Loss: 5.482359
[2022-06-07 13:58:40 | train] - Train Epoch: [1] [140800/1281167 (11%)]	Loss: 5.755910
[2022-06-07 13:59:01 | train] - Train Epoch: [1] [153600/1281167 (12%)]	Loss: 5.603666
[2022-06-07 13:59:24 | train] - Train Epoch: [1] [166400/1281167 (13%)]	Loss: 5.710536
[2022-06-07 13:59:46 | train] - Train Epoch: [1] [179200/1281167 (14%)]	Loss: 5.829131
[2022-06-07 14:00:09 | train] - Train Epoch: [1] [192000/1281167 (15%)]	Loss: 5.288658
[2022-06-07 14:00:31 | train] - Train Epoch: [1] [204800/1281167 (16%)]	Loss: 5.405383
[2022-06-07 14:00:53 | train] - Train Epoch: [1] [217600/1281167 (17%)]	Loss: 5.656490
[2022-06-07 14:01:14 | train] - Train Epoch: [1] [230400/1281167 (18%)]	Loss: 5.704031
[2022-06-07 14:01:34 | train] - Train Epoch: [1] [243200/1281167 (19%)]	Loss: 5.543175
[2022-06-07 14:01:55 | train] - Train Epoch: [1] [256000/1281167 (20%)]	Loss: 5.637224
[2022-06-07 14:02:17 | train] - Train Epoch: [1] [268800/1281167 (21%)]	Loss: 5.407696
[2022-06-07 14:02:38 | train] - Train Epoch: [1] [281600/1281167 (22%)]	Loss: 5.598012
[2022-06-07 14:02:59 | train] - Train Epoch: [1] [294400/1281167 (23%)]	Loss: 5.727098
[2022-06-07 14:03:21 | train] - Train Epoch: [1] [307200/1281167 (24%)]	Loss: 5.527773
[2022-06-07 14:03:42 | train] - Train Epoch: [1] [320000/1281167 (25%)]	Loss: 5.820261
[2022-06-07 14:04:03 | train] - Train Epoch: [1] [332800/1281167 (26%)]	Loss: 5.477269
[2022-06-07 14:04:24 | train] - Train Epoch: [1] [345600/1281167 (27%)]	Loss: 5.665658
[2022-06-07 14:04:45 | train] - Train Epoch: [1] [358400/1281167 (28%)]	Loss: 5.484795
[2022-06-07 14:05:07 | train] - Train Epoch: [1] [371200/1281167 (29%)]	Loss: 5.602572
[2022-06-07 14:05:27 | train] - Train Epoch: [1] [384000/1281167 (30%)]	Loss: 5.563184
[2022-06-07 14:05:49 | train] - Train Epoch: [1] [396800/1281167 (31%)]	Loss: 5.454150
[2022-06-07 14:06:10 | train] - Train Epoch: [1] [409600/1281167 (32%)]	Loss: 5.278774
[2022-06-07 14:06:31 | train] - Train Epoch: [1] [422400/1281167 (33%)]	Loss: 5.328390
[2022-06-07 14:06:51 | train] - Train Epoch: [1] [435200/1281167 (34%)]	Loss: 5.480735
[2022-06-07 14:07:12 | train] - Train Epoch: [1] [448000/1281167 (35%)]	Loss: 5.467120
[2022-06-07 14:07:33 | train] - Train Epoch: [1] [460800/1281167 (36%)]	Loss: 5.317337
[2022-06-07 14:07:54 | train] - Train Epoch: [1] [473600/1281167 (37%)]	Loss: 5.544143
[2022-06-07 14:08:15 | train] - Train Epoch: [1] [486400/1281167 (38%)]	Loss: 5.349880
[2022-06-07 14:08:36 | train] - Train Epoch: [1] [499200/1281167 (39%)]	Loss: 5.269543
[2022-06-07 14:08:57 | train] - Train Epoch: [1] [512000/1281167 (40%)]	Loss: 5.336698
[2022-06-07 14:09:19 | train] - Train Epoch: [1] [524800/1281167 (41%)]	Loss: 5.311239
[2022-06-07 14:09:40 | train] - Train Epoch: [1] [537600/1281167 (42%)]	Loss: 5.503712
[2022-06-07 14:10:01 | train] - Train Epoch: [1] [550400/1281167 (43%)]	Loss: 5.546009
[2022-06-07 14:10:23 | train] - Train Epoch: [1] [563200/1281167 (44%)]	Loss: 5.174885
[2022-06-07 14:10:44 | train] - Train Epoch: [1] [576000/1281167 (45%)]	Loss: 5.533169
[2022-06-07 14:11:05 | train] - Train Epoch: [1] [588800/1281167 (46%)]	Loss: 5.381692
[2022-06-07 14:11:26 | train] - Train Epoch: [1] [601600/1281167 (47%)]	Loss: 5.040653
[2022-06-07 14:11:48 | train] - Train Epoch: [1] [614400/1281167 (48%)]	Loss: 5.283222
[2022-06-07 14:12:09 | train] - Train Epoch: [1] [627200/1281167 (49%)]	Loss: 5.385727
[2022-06-07 14:12:32 | train] - Train Epoch: [1] [640000/1281167 (50%)]	Loss: 5.217540
[2022-06-07 14:12:53 | train] - Train Epoch: [1] [652800/1281167 (51%)]	Loss: 5.212396
[2022-06-07 14:13:15 | train] - Train Epoch: [1] [665600/1281167 (52%)]	Loss: 5.333871
[2022-06-07 14:13:37 | train] - Train Epoch: [1] [678400/1281167 (53%)]	Loss: 5.299065
[2022-06-07 14:13:58 | train] - Train Epoch: [1] [691200/1281167 (54%)]	Loss: 5.126813
[2022-06-07 14:14:20 | train] - Train Epoch: [1] [704000/1281167 (55%)]	Loss: 5.265757
[2022-06-07 14:14:41 | train] - Train Epoch: [1] [716800/1281167 (56%)]	Loss: 5.100782
[2022-06-07 14:15:04 | train] - Train Epoch: [1] [729600/1281167 (57%)]	Loss: 5.144635
[2022-06-07 14:15:25 | train] - Train Epoch: [1] [742400/1281167 (58%)]	Loss: 5.429510
[2022-06-07 14:15:46 | train] - Train Epoch: [1] [755200/1281167 (59%)]	Loss: 5.399065
[2022-06-07 14:16:08 | train] - Train Epoch: [1] [768000/1281167 (60%)]	Loss: 5.225728
[2022-06-07 14:16:28 | train] - Train Epoch: [1] [780800/1281167 (61%)]	Loss: 5.136721
[2022-06-07 14:16:49 | train] - Train Epoch: [1] [793600/1281167 (62%)]	Loss: 5.412877
[2022-06-07 14:17:10 | train] - Train Epoch: [1] [806400/1281167 (63%)]	Loss: 5.354912
[2022-06-07 14:17:31 | train] - Train Epoch: [1] [819200/1281167 (64%)]	Loss: 5.028739
[2022-06-07 14:17:53 | train] - Train Epoch: [1] [832000/1281167 (65%)]	Loss: 4.946313
[2022-06-07 14:18:14 | train] - Train Epoch: [1] [844800/1281167 (66%)]	Loss: 5.176234
[2022-06-07 14:18:37 | train] - Train Epoch: [1] [857600/1281167 (67%)]	Loss: 4.903141
[2022-06-07 14:18:58 | train] - Train Epoch: [1] [870400/1281167 (68%)]	Loss: 5.129220
[2022-06-07 14:19:19 | train] - Train Epoch: [1] [883200/1281167 (69%)]	Loss: 4.926968
[2022-06-07 14:19:40 | train] - Train Epoch: [1] [896000/1281167 (70%)]	Loss: 5.775239
[2022-06-07 14:20:00 | train] - Train Epoch: [1] [908800/1281167 (71%)]	Loss: 5.071947
[2022-06-07 14:20:22 | train] - Train Epoch: [1] [921600/1281167 (72%)]	Loss: 4.856146
[2022-06-07 14:20:42 | train] - Train Epoch: [1] [934400/1281167 (73%)]	Loss: 4.949497
[2022-06-07 14:21:02 | train] - Train Epoch: [1] [947200/1281167 (74%)]	Loss: 4.895217
[2022-06-07 14:21:23 | train] - Train Epoch: [1] [960000/1281167 (75%)]	Loss: 5.122449
[2022-06-07 14:21:43 | train] - Train Epoch: [1] [972800/1281167 (76%)]	Loss: 5.119404
[2022-06-07 14:22:04 | train] - Train Epoch: [1] [985600/1281167 (77%)]	Loss: 5.138934
[2022-06-07 14:22:24 | train] - Train Epoch: [1] [998400/1281167 (78%)]	Loss: 4.691060
[2022-06-07 14:22:43 | train] - Train Epoch: [1] [1011200/1281167 (79%)]	Loss: 4.602943
[2022-06-07 14:23:05 | train] - Train Epoch: [1] [1024000/1281167 (80%)]	Loss: 4.981466
[2022-06-07 14:23:26 | train] - Train Epoch: [1] [1036800/1281167 (81%)]	Loss: 5.184589
[2022-06-07 14:23:46 | train] - Train Epoch: [1] [1049600/1281167 (82%)]	Loss: 5.059227
[2022-06-07 14:24:08 | train] - Train Epoch: [1] [1062400/1281167 (83%)]	Loss: 5.121777
[2022-06-07 14:24:29 | train] - Train Epoch: [1] [1075200/1281167 (84%)]	Loss: 5.338861
[2022-06-07 14:24:51 | train] - Train Epoch: [1] [1088000/1281167 (85%)]	Loss: 4.876869
[2022-06-07 14:25:14 | train] - Train Epoch: [1] [1100800/1281167 (86%)]	Loss: 5.098272
[2022-06-07 14:25:35 | train] - Train Epoch: [1] [1113600/1281167 (87%)]	Loss: 4.975213
[2022-06-07 14:25:56 | train] - Train Epoch: [1] [1126400/1281167 (88%)]	Loss: 4.836638
[2022-06-07 14:26:18 | train] - Train Epoch: [1] [1139200/1281167 (89%)]	Loss: 5.022299
[2022-06-07 14:26:39 | train] - Train Epoch: [1] [1152000/1281167 (90%)]	Loss: 4.752618
[2022-06-07 14:27:00 | train] - Train Epoch: [1] [1164800/1281167 (91%)]	Loss: 4.390826
[2022-06-07 14:27:21 | train] - Train Epoch: [1] [1177600/1281167 (92%)]	Loss: 4.761125
[2022-06-07 14:27:44 | train] - Train Epoch: [1] [1190400/1281167 (93%)]	Loss: 4.871332
[2022-06-07 14:28:05 | train] - Train Epoch: [1] [1203200/1281167 (94%)]	Loss: 4.750477
[2022-06-07 14:28:27 | train] - Train Epoch: [1] [1216000/1281167 (95%)]	Loss: 4.739934
[2022-06-07 14:28:49 | train] - Train Epoch: [1] [1228800/1281167 (96%)]	Loss: 4.694796
[2022-06-07 14:29:11 | train] - Train Epoch: [1] [1241600/1281167 (97%)]	Loss: 5.028744
[2022-06-07 14:29:32 | train] - Train Epoch: [1] [1254400/1281167 (98%)]	Loss: 4.798120
[2022-06-07 14:29:54 | train] - Train Epoch: [1] [1267200/1281167 (99%)]	Loss: 4.697979
[2022-06-07 14:30:15 | train] - Train Epoch: [1] [1280000/1281167 (100%)]	Loss: 4.780498
[2022-06-07 14:30:17 | train] - Train Epoch: [1]	 Average Loss: 5.272423	 Total Acc : 7.5459	 Total Top5 Acc : 19.8236
[2022-06-07 14:30:17 | train] - -------1 epoch end-----------
========================================
-------1 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 14:31:51 | train] - 
Epoch [1] Test set: Average loss: 5.1079, Accuracy: 5065/50000 (10.1251%), Top-5 Accuracy: 25.1854%

[2022-06-07 14:31:51 | train] - save intermediate epoch [1] result


[2022-06-07 14:31:52 | train] - logging best performance 1 epoch
[2022-06-07 14:31:53 | train] - -------2 epoch start-----------
========================================
----- test end -------------------------


logging best performance 1 epoch
[2022-06-07 14:31:55 | train] - Train Epoch: [2] [0/1281167 (0%)]	Loss: 4.497303
[2022-06-07 14:32:17 | train] - Train Epoch: [2] [12800/1281167 (1%)]	Loss: 4.992839
[2022-06-07 14:32:40 | train] - Train Epoch: [2] [25600/1281167 (2%)]	Loss: 4.352819
[2022-06-07 14:33:02 | train] - Train Epoch: [2] [38400/1281167 (3%)]	Loss: 4.652663
[2022-06-07 14:33:24 | train] - Train Epoch: [2] [51200/1281167 (4%)]	Loss: 4.423965
[2022-06-07 14:33:46 | train] - Train Epoch: [2] [64000/1281167 (5%)]	Loss: 4.558074
[2022-06-07 14:34:08 | train] - Train Epoch: [2] [76800/1281167 (6%)]	Loss: 4.910284
[2022-06-07 14:34:30 | train] - Train Epoch: [2] [89600/1281167 (7%)]	Loss: 4.786415
[2022-06-07 14:34:52 | train] - Train Epoch: [2] [102400/1281167 (8%)]	Loss: 4.460722
[2022-06-07 14:35:14 | train] - Train Epoch: [2] [115200/1281167 (9%)]	Loss: 4.646328
[2022-06-07 14:35:36 | train] - Train Epoch: [2] [128000/1281167 (10%)]	Loss: 4.298273
[2022-06-07 14:35:58 | train] - Train Epoch: [2] [140800/1281167 (11%)]	Loss: 4.627203
[2022-06-07 14:36:21 | train] - Train Epoch: [2] [153600/1281167 (12%)]	Loss: 4.910550
[2022-06-07 14:36:42 | train] - Train Epoch: [2] [166400/1281167 (13%)]	Loss: 4.797014
[2022-06-07 14:37:05 | train] - Train Epoch: [2] [179200/1281167 (14%)]	Loss: 4.542924
[2022-06-07 14:37:27 | train] - Train Epoch: [2] [192000/1281167 (15%)]	Loss: 4.369910
[2022-06-07 14:37:47 | train] - Train Epoch: [2] [204800/1281167 (16%)]	Loss: 4.239531
[2022-06-07 14:38:08 | train] - Train Epoch: [2] [217600/1281167 (17%)]	Loss: 4.708731
[2022-06-07 14:38:31 | train] - Train Epoch: [2] [230400/1281167 (18%)]	Loss: 4.884553
[2022-06-07 14:38:53 | train] - Train Epoch: [2] [243200/1281167 (19%)]	Loss: 4.553713
[2022-06-07 14:39:15 | train] - Train Epoch: [2] [256000/1281167 (20%)]	Loss: 4.600175
[2022-06-07 14:39:38 | train] - Train Epoch: [2] [268800/1281167 (21%)]	Loss: 4.845031
[2022-06-07 14:40:00 | train] - Train Epoch: [2] [281600/1281167 (22%)]	Loss: 4.702322
[2022-06-07 14:40:22 | train] - Train Epoch: [2] [294400/1281167 (23%)]	Loss: 4.374043
[2022-06-07 14:40:43 | train] - Train Epoch: [2] [307200/1281167 (24%)]	Loss: 4.496547
[2022-06-07 14:41:05 | train] - Train Epoch: [2] [320000/1281167 (25%)]	Loss: 4.811059
[2022-06-07 14:41:27 | train] - Train Epoch: [2] [332800/1281167 (26%)]	Loss: 4.558811
[2022-06-07 14:41:49 | train] - Train Epoch: [2] [345600/1281167 (27%)]	Loss: 4.297883
[2022-06-07 14:42:11 | train] - Train Epoch: [2] [358400/1281167 (28%)]	Loss: 4.859859
[2022-06-07 14:42:33 | train] - Train Epoch: [2] [371200/1281167 (29%)]	Loss: 4.369996
[2022-06-07 14:42:56 | train] - Train Epoch: [2] [384000/1281167 (30%)]	Loss: 4.397797
[2022-06-07 14:43:18 | train] - Train Epoch: [2] [396800/1281167 (31%)]	Loss: 4.465839
[2022-06-07 14:43:40 | train] - Train Epoch: [2] [409600/1281167 (32%)]	Loss: 4.473154
[2022-06-07 14:44:03 | train] - Train Epoch: [2] [422400/1281167 (33%)]	Loss: 4.309411
[2022-06-07 14:44:25 | train] - Train Epoch: [2] [435200/1281167 (34%)]	Loss: 4.641166
[2022-06-07 14:44:47 | train] - Train Epoch: [2] [448000/1281167 (35%)]	Loss: 4.514912
[2022-06-07 14:45:09 | train] - Train Epoch: [2] [460800/1281167 (36%)]	Loss: 4.578379
[2022-06-07 14:45:31 | train] - Train Epoch: [2] [473600/1281167 (37%)]	Loss: 4.555873
[2022-06-07 14:45:53 | train] - Train Epoch: [2] [486400/1281167 (38%)]	Loss: 4.648404
[2022-06-07 14:46:14 | train] - Train Epoch: [2] [499200/1281167 (39%)]	Loss: 4.292862
[2022-06-07 14:46:35 | train] - Train Epoch: [2] [512000/1281167 (40%)]	Loss: 4.369164
[2022-06-07 14:46:57 | train] - Train Epoch: [2] [524800/1281167 (41%)]	Loss: 4.441928
[2022-06-07 14:47:19 | train] - Train Epoch: [2] [537600/1281167 (42%)]	Loss: 4.248304
[2022-06-07 14:47:41 | train] - Train Epoch: [2] [550400/1281167 (43%)]	Loss: 4.115211
[2022-06-07 14:48:03 | train] - Train Epoch: [2] [563200/1281167 (44%)]	Loss: 4.485861
[2022-06-07 14:48:26 | train] - Train Epoch: [2] [576000/1281167 (45%)]	Loss: 4.356508
[2022-06-07 14:48:48 | train] - Train Epoch: [2] [588800/1281167 (46%)]	Loss: 4.143905
[2022-06-07 14:49:10 | train] - Train Epoch: [2] [601600/1281167 (47%)]	Loss: 4.393437
[2022-06-07 14:49:32 | train] - Train Epoch: [2] [614400/1281167 (48%)]	Loss: 4.501034
[2022-06-07 14:49:53 | train] - Train Epoch: [2] [627200/1281167 (49%)]	Loss: 4.472672
[2022-06-07 14:50:15 | train] - Train Epoch: [2] [640000/1281167 (50%)]	Loss: 4.261685
[2022-06-07 14:50:38 | train] - Train Epoch: [2] [652800/1281167 (51%)]	Loss: 4.488694
[2022-06-07 14:51:00 | train] - Train Epoch: [2] [665600/1281167 (52%)]	Loss: 4.533613
[2022-06-07 14:51:22 | train] - Train Epoch: [2] [678400/1281167 (53%)]	Loss: 4.120454
[2022-06-07 14:51:44 | train] - Train Epoch: [2] [691200/1281167 (54%)]	Loss: 4.156425
[2022-06-07 14:52:05 | train] - Train Epoch: [2] [704000/1281167 (55%)]	Loss: 4.287704
[2022-06-07 14:52:27 | train] - Train Epoch: [2] [716800/1281167 (56%)]	Loss: 4.636876
[2022-06-07 14:52:50 | train] - Train Epoch: [2] [729600/1281167 (57%)]	Loss: 4.385134
[2022-06-07 14:53:12 | train] - Train Epoch: [2] [742400/1281167 (58%)]	Loss: 4.298391
[2022-06-07 14:53:34 | train] - Train Epoch: [2] [755200/1281167 (59%)]	Loss: 4.147753
[2022-06-07 14:53:56 | train] - Train Epoch: [2] [768000/1281167 (60%)]	Loss: 4.253646
[2022-06-07 14:54:17 | train] - Train Epoch: [2] [780800/1281167 (61%)]	Loss: 4.245287
[2022-06-07 14:54:39 | train] - Train Epoch: [2] [793600/1281167 (62%)]	Loss: 4.068243
[2022-06-07 14:55:01 | train] - Train Epoch: [2] [806400/1281167 (63%)]	Loss: 4.393120
[2022-06-07 14:55:23 | train] - Train Epoch: [2] [819200/1281167 (64%)]	Loss: 3.987641
[2022-06-07 14:55:44 | train] - Train Epoch: [2] [832000/1281167 (65%)]	Loss: 4.407364
[2022-06-07 14:56:06 | train] - Train Epoch: [2] [844800/1281167 (66%)]	Loss: 3.987419
[2022-06-07 14:56:28 | train] - Train Epoch: [2] [857600/1281167 (67%)]	Loss: 4.142511
[2022-06-07 14:56:50 | train] - Train Epoch: [2] [870400/1281167 (68%)]	Loss: 4.018970
[2022-06-07 14:57:12 | train] - Train Epoch: [2] [883200/1281167 (69%)]	Loss: 4.117143
[2022-06-07 14:57:35 | train] - Train Epoch: [2] [896000/1281167 (70%)]	Loss: 4.242636
[2022-06-07 14:57:57 | train] - Train Epoch: [2] [908800/1281167 (71%)]	Loss: 4.121009
[2022-06-07 14:58:18 | train] - Train Epoch: [2] [921600/1281167 (72%)]	Loss: 4.240181
[2022-06-07 14:58:41 | train] - Train Epoch: [2] [934400/1281167 (73%)]	Loss: 4.146372
[2022-06-07 14:59:03 | train] - Train Epoch: [2] [947200/1281167 (74%)]	Loss: 4.248207
[2022-06-07 14:59:25 | train] - Train Epoch: [2] [960000/1281167 (75%)]	Loss: 4.136680
[2022-06-07 14:59:48 | train] - Train Epoch: [2] [972800/1281167 (76%)]	Loss: 4.023905
[2022-06-07 15:00:11 | train] - Train Epoch: [2] [985600/1281167 (77%)]	Loss: 4.036341
[2022-06-07 15:00:32 | train] - Train Epoch: [2] [998400/1281167 (78%)]	Loss: 3.973697
[2022-06-07 15:00:54 | train] - Train Epoch: [2] [1011200/1281167 (79%)]	Loss: 3.750305
[2022-06-07 15:01:17 | train] - Train Epoch: [2] [1024000/1281167 (80%)]	Loss: 4.233612
[2022-06-07 15:01:39 | train] - Train Epoch: [2] [1036800/1281167 (81%)]	Loss: 4.265486
[2022-06-07 15:02:01 | train] - Train Epoch: [2] [1049600/1281167 (82%)]	Loss: 4.236939
[2022-06-07 15:02:23 | train] - Train Epoch: [2] [1062400/1281167 (83%)]	Loss: 4.054787
[2022-06-07 15:02:45 | train] - Train Epoch: [2] [1075200/1281167 (84%)]	Loss: 4.294543
[2022-06-07 15:03:07 | train] - Train Epoch: [2] [1088000/1281167 (85%)]	Loss: 3.844463
[2022-06-07 15:03:29 | train] - Train Epoch: [2] [1100800/1281167 (86%)]	Loss: 3.857427
[2022-06-07 15:03:53 | train] - Train Epoch: [2] [1113600/1281167 (87%)]	Loss: 4.186003
[2022-06-07 15:04:15 | train] - Train Epoch: [2] [1126400/1281167 (88%)]	Loss: 3.880328
[2022-06-07 15:04:37 | train] - Train Epoch: [2] [1139200/1281167 (89%)]	Loss: 4.185441
[2022-06-07 15:04:59 | train] - Train Epoch: [2] [1152000/1281167 (90%)]	Loss: 4.197457
[2022-06-07 15:05:22 | train] - Train Epoch: [2] [1164800/1281167 (91%)]	Loss: 4.098539
[2022-06-07 15:05:45 | train] - Train Epoch: [2] [1177600/1281167 (92%)]	Loss: 4.436045
[2022-06-07 15:06:09 | train] - Train Epoch: [2] [1190400/1281167 (93%)]	Loss: 4.241218
[2022-06-07 15:06:32 | train] - Train Epoch: [2] [1203200/1281167 (94%)]	Loss: 4.176924
[2022-06-07 15:06:56 | train] - Train Epoch: [2] [1216000/1281167 (95%)]	Loss: 4.034851
[2022-06-07 15:07:18 | train] - Train Epoch: [2] [1228800/1281167 (96%)]	Loss: 4.538511
[2022-06-07 15:07:41 | train] - Train Epoch: [2] [1241600/1281167 (97%)]	Loss: 3.627835
[2022-06-07 15:08:04 | train] - Train Epoch: [2] [1254400/1281167 (98%)]	Loss: 3.958371
[2022-06-07 15:08:27 | train] - Train Epoch: [2] [1267200/1281167 (99%)]	Loss: 4.018750
[2022-06-07 15:08:50 | train] - Train Epoch: [2] [1280000/1281167 (100%)]	Loss: 4.150120
[2022-06-07 15:08:52 | train] - Train Epoch: [2]	 Average Loss: 4.353028	 Total Acc : 16.9074	 Total Top5 Acc : 36.3863
[2022-06-07 15:08:52 | train] - -------2 epoch end-----------
========================================
-------2 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 15:10:27 | train] - 
Epoch [2] Test set: Average loss: 3.7414, Accuracy: 11808/50000 (23.5969%), Top-5 Accuracy: 47.0668%

[2022-06-07 15:10:27 | train] - save intermediate epoch [2] result


[2022-06-07 15:10:28 | train] - logging best performance 2 epoch
[2022-06-07 15:10:30 | train] - -------3 epoch start-----------
========================================
----- test end -------------------------


logging best performance 2 epoch
[2022-06-07 15:10:31 | train] - Train Epoch: [3] [0/1281167 (0%)]	Loss: 3.902777
[2022-06-07 15:10:54 | train] - Train Epoch: [3] [12800/1281167 (1%)]	Loss: 3.670844
[2022-06-07 15:11:17 | train] - Train Epoch: [3] [25600/1281167 (2%)]	Loss: 3.804869
[2022-06-07 15:11:39 | train] - Train Epoch: [3] [38400/1281167 (3%)]	Loss: 3.792621
[2022-06-07 15:12:02 | train] - Train Epoch: [3] [51200/1281167 (4%)]	Loss: 3.783345
[2022-06-07 15:12:25 | train] - Train Epoch: [3] [64000/1281167 (5%)]	Loss: 4.218131
[2022-06-07 15:12:47 | train] - Train Epoch: [3] [76800/1281167 (6%)]	Loss: 3.731722
[2022-06-07 15:13:10 | train] - Train Epoch: [3] [89600/1281167 (7%)]	Loss: 4.032062
[2022-06-07 15:13:32 | train] - Train Epoch: [3] [102400/1281167 (8%)]	Loss: 4.217072
[2022-06-07 15:13:55 | train] - Train Epoch: [3] [115200/1281167 (9%)]	Loss: 3.759286
[2022-06-07 15:14:17 | train] - Train Epoch: [3] [128000/1281167 (10%)]	Loss: 4.183084
[2022-06-07 15:14:39 | train] - Train Epoch: [3] [140800/1281167 (11%)]	Loss: 4.039880
[2022-06-07 15:15:01 | train] - Train Epoch: [3] [153600/1281167 (12%)]	Loss: 3.913095
[2022-06-07 15:15:23 | train] - Train Epoch: [3] [166400/1281167 (13%)]	Loss: 3.992519
[2022-06-07 15:15:45 | train] - Train Epoch: [3] [179200/1281167 (14%)]	Loss: 3.764454
[2022-06-07 15:16:08 | train] - Train Epoch: [3] [192000/1281167 (15%)]	Loss: 3.579763
[2022-06-07 15:16:31 | train] - Train Epoch: [3] [204800/1281167 (16%)]	Loss: 4.101350
[2022-06-07 15:16:52 | train] - Train Epoch: [3] [217600/1281167 (17%)]	Loss: 4.194740
[2022-06-07 15:17:15 | train] - Train Epoch: [3] [230400/1281167 (18%)]	Loss: 3.601738
[2022-06-07 15:17:37 | train] - Train Epoch: [3] [243200/1281167 (19%)]	Loss: 3.616403
[2022-06-07 15:17:59 | train] - Train Epoch: [3] [256000/1281167 (20%)]	Loss: 4.095368
[2022-06-07 15:18:22 | train] - Train Epoch: [3] [268800/1281167 (21%)]	Loss: 3.938546
[2022-06-07 15:18:44 | train] - Train Epoch: [3] [281600/1281167 (22%)]	Loss: 4.115911
[2022-06-07 15:19:06 | train] - Train Epoch: [3] [294400/1281167 (23%)]	Loss: 3.267875
[2022-06-07 15:19:29 | train] - Train Epoch: [3] [307200/1281167 (24%)]	Loss: 3.772586
[2022-06-07 15:19:51 | train] - Train Epoch: [3] [320000/1281167 (25%)]	Loss: 3.771381
[2022-06-07 15:20:13 | train] - Train Epoch: [3] [332800/1281167 (26%)]	Loss: 3.981357
[2022-06-07 15:20:35 | train] - Train Epoch: [3] [345600/1281167 (27%)]	Loss: 4.143556
[2022-06-07 15:20:58 | train] - Train Epoch: [3] [358400/1281167 (28%)]	Loss: 3.808450
[2022-06-07 15:21:20 | train] - Train Epoch: [3] [371200/1281167 (29%)]	Loss: 3.711270
[2022-06-07 15:21:43 | train] - Train Epoch: [3] [384000/1281167 (30%)]	Loss: 3.837382
[2022-06-07 15:22:04 | train] - Train Epoch: [3] [396800/1281167 (31%)]	Loss: 3.286186
[2022-06-07 15:22:26 | train] - Train Epoch: [3] [409600/1281167 (32%)]	Loss: 3.750825
[2022-06-07 15:22:48 | train] - Train Epoch: [3] [422400/1281167 (33%)]	Loss: 3.831370
[2022-06-07 15:23:10 | train] - Train Epoch: [3] [435200/1281167 (34%)]	Loss: 3.894168
[2022-06-07 15:23:31 | train] - Train Epoch: [3] [448000/1281167 (35%)]	Loss: 3.852617
[2022-06-07 15:23:53 | train] - Train Epoch: [3] [460800/1281167 (36%)]	Loss: 3.524079
[2022-06-07 15:24:15 | train] - Train Epoch: [3] [473600/1281167 (37%)]	Loss: 3.459770
[2022-06-07 15:24:38 | train] - Train Epoch: [3] [486400/1281167 (38%)]	Loss: 3.563025
[2022-06-07 15:25:00 | train] - Train Epoch: [3] [499200/1281167 (39%)]	Loss: 3.357398
[2022-06-07 15:25:22 | train] - Train Epoch: [3] [512000/1281167 (40%)]	Loss: 4.374869
[2022-06-07 15:25:44 | train] - Train Epoch: [3] [524800/1281167 (41%)]	Loss: 3.683329
[2022-06-07 15:26:07 | train] - Train Epoch: [3] [537600/1281167 (42%)]	Loss: 3.626460
[2022-06-07 15:26:28 | train] - Train Epoch: [3] [550400/1281167 (43%)]	Loss: 3.722837
[2022-06-07 15:26:51 | train] - Train Epoch: [3] [563200/1281167 (44%)]	Loss: 3.908886
[2022-06-07 15:27:13 | train] - Train Epoch: [3] [576000/1281167 (45%)]	Loss: 3.731302
[2022-06-07 15:27:35 | train] - Train Epoch: [3] [588800/1281167 (46%)]	Loss: 3.815292
[2022-06-07 15:27:57 | train] - Train Epoch: [3] [601600/1281167 (47%)]	Loss: 3.724393
[2022-06-07 15:28:19 | train] - Train Epoch: [3] [614400/1281167 (48%)]	Loss: 3.762697
[2022-06-07 15:28:41 | train] - Train Epoch: [3] [627200/1281167 (49%)]	Loss: 3.850469
[2022-06-07 15:29:03 | train] - Train Epoch: [3] [640000/1281167 (50%)]	Loss: 4.185139
[2022-06-07 15:29:25 | train] - Train Epoch: [3] [652800/1281167 (51%)]	Loss: 3.544054
[2022-06-07 15:29:47 | train] - Train Epoch: [3] [665600/1281167 (52%)]	Loss: 3.828357
[2022-06-07 15:30:10 | train] - Train Epoch: [3] [678400/1281167 (53%)]	Loss: 3.432317
[2022-06-07 15:30:31 | train] - Train Epoch: [3] [691200/1281167 (54%)]	Loss: 3.132060
[2022-06-07 15:30:54 | train] - Train Epoch: [3] [704000/1281167 (55%)]	Loss: 3.395311
[2022-06-07 15:31:17 | train] - Train Epoch: [3] [716800/1281167 (56%)]	Loss: 4.185993
[2022-06-07 15:31:39 | train] - Train Epoch: [3] [729600/1281167 (57%)]	Loss: 3.842088
[2022-06-07 15:32:00 | train] - Train Epoch: [3] [742400/1281167 (58%)]	Loss: 3.500752
[2022-06-07 15:32:22 | train] - Train Epoch: [3] [755200/1281167 (59%)]	Loss: 3.964593
[2022-06-07 15:32:44 | train] - Train Epoch: [3] [768000/1281167 (60%)]	Loss: 3.276853
[2022-06-07 15:33:06 | train] - Train Epoch: [3] [780800/1281167 (61%)]	Loss: 3.801934
[2022-06-07 15:33:29 | train] - Train Epoch: [3] [793600/1281167 (62%)]	Loss: 3.311563
[2022-06-07 15:33:50 | train] - Train Epoch: [3] [806400/1281167 (63%)]	Loss: 3.819407
[2022-06-07 15:34:12 | train] - Train Epoch: [3] [819200/1281167 (64%)]	Loss: 3.417177
[2022-06-07 15:34:35 | train] - Train Epoch: [3] [832000/1281167 (65%)]	Loss: 3.851420
[2022-06-07 15:34:57 | train] - Train Epoch: [3] [844800/1281167 (66%)]	Loss: 3.924368
[2022-06-07 15:35:19 | train] - Train Epoch: [3] [857600/1281167 (67%)]	Loss: 3.691150
[2022-06-07 15:35:40 | train] - Train Epoch: [3] [870400/1281167 (68%)]	Loss: 3.822418
[2022-06-07 15:36:04 | train] - Train Epoch: [3] [883200/1281167 (69%)]	Loss: 3.545047
[2022-06-07 15:36:26 | train] - Train Epoch: [3] [896000/1281167 (70%)]	Loss: 3.618523
[2022-06-07 15:36:48 | train] - Train Epoch: [3] [908800/1281167 (71%)]	Loss: 3.560202
[2022-06-07 15:37:10 | train] - Train Epoch: [3] [921600/1281167 (72%)]	Loss: 3.549173
[2022-06-07 15:37:32 | train] - Train Epoch: [3] [934400/1281167 (73%)]	Loss: 3.685767
[2022-06-07 15:37:55 | train] - Train Epoch: [3] [947200/1281167 (74%)]	Loss: 3.670070
[2022-06-07 15:38:16 | train] - Train Epoch: [3] [960000/1281167 (75%)]	Loss: 3.478057
[2022-06-07 15:38:39 | train] - Train Epoch: [3] [972800/1281167 (76%)]	Loss: 3.499781
[2022-06-07 15:39:00 | train] - Train Epoch: [3] [985600/1281167 (77%)]	Loss: 3.725381
[2022-06-07 15:39:23 | train] - Train Epoch: [3] [998400/1281167 (78%)]	Loss: 3.663660
[2022-06-07 15:39:45 | train] - Train Epoch: [3] [1011200/1281167 (79%)]	Loss: 3.580103
[2022-06-07 15:40:06 | train] - Train Epoch: [3] [1024000/1281167 (80%)]	Loss: 3.214980
[2022-06-07 15:40:29 | train] - Train Epoch: [3] [1036800/1281167 (81%)]	Loss: 3.106737
[2022-06-07 15:40:51 | train] - Train Epoch: [3] [1049600/1281167 (82%)]	Loss: 3.670677
[2022-06-07 15:41:13 | train] - Train Epoch: [3] [1062400/1281167 (83%)]	Loss: 3.841660
[2022-06-07 15:41:34 | train] - Train Epoch: [3] [1075200/1281167 (84%)]	Loss: 3.651831
[2022-06-07 15:41:57 | train] - Train Epoch: [3] [1088000/1281167 (85%)]	Loss: 3.788910
[2022-06-07 15:42:19 | train] - Train Epoch: [3] [1100800/1281167 (86%)]	Loss: 3.474401
[2022-06-07 15:42:41 | train] - Train Epoch: [3] [1113600/1281167 (87%)]	Loss: 3.475685
[2022-06-07 15:43:03 | train] - Train Epoch: [3] [1126400/1281167 (88%)]	Loss: 3.335747
[2022-06-07 15:43:25 | train] - Train Epoch: [3] [1139200/1281167 (89%)]	Loss: 3.123071
[2022-06-07 15:43:47 | train] - Train Epoch: [3] [1152000/1281167 (90%)]	Loss: 3.795538
[2022-06-07 15:44:09 | train] - Train Epoch: [3] [1164800/1281167 (91%)]	Loss: 3.940525
[2022-06-07 15:44:31 | train] - Train Epoch: [3] [1177600/1281167 (92%)]	Loss: 3.565654
[2022-06-07 15:44:53 | train] - Train Epoch: [3] [1190400/1281167 (93%)]	Loss: 3.404034
[2022-06-07 15:45:15 | train] - Train Epoch: [3] [1203200/1281167 (94%)]	Loss: 3.288732
[2022-06-07 15:45:37 | train] - Train Epoch: [3] [1216000/1281167 (95%)]	Loss: 4.078358
[2022-06-07 15:46:00 | train] - Train Epoch: [3] [1228800/1281167 (96%)]	Loss: 3.675924
[2022-06-07 15:46:22 | train] - Train Epoch: [3] [1241600/1281167 (97%)]	Loss: 3.385255
[2022-06-07 15:46:44 | train] - Train Epoch: [3] [1254400/1281167 (98%)]	Loss: 3.987474
[2022-06-07 15:47:07 | train] - Train Epoch: [3] [1267200/1281167 (99%)]	Loss: 3.378180
[2022-06-07 15:47:28 | train] - Train Epoch: [3] [1280000/1281167 (100%)]	Loss: 3.361701
[2022-06-07 15:47:30 | train] - Train Epoch: [3]	 Average Loss: 3.703290	 Total Acc : 25.5707	 Total Top5 Acc : 48.6221
[2022-06-07 15:47:30 | train] - -------3 epoch end-----------
========================================
-------3 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 15:49:07 | train] - 
Epoch [3] Test set: Average loss: 3.2902, Accuracy: 15743/50000 (31.4570%), Top-5 Accuracy: 57.2854%

[2022-06-07 15:49:07 | train] - save intermediate epoch [3] result


[2022-06-07 15:49:09 | train] - logging best performance 3 epoch
[2022-06-07 15:49:10 | train] - -------4 epoch start-----------
========================================
----- test end -------------------------


logging best performance 3 epoch
[2022-06-07 15:49:12 | train] - Train Epoch: [4] [0/1281167 (0%)]	Loss: 3.094153
[2022-06-07 15:49:34 | train] - Train Epoch: [4] [12800/1281167 (1%)]	Loss: 3.744949
[2022-06-07 15:49:57 | train] - Train Epoch: [4] [25600/1281167 (2%)]	Loss: 3.334831
[2022-06-07 15:50:20 | train] - Train Epoch: [4] [38400/1281167 (3%)]	Loss: 3.462239
[2022-06-07 15:50:42 | train] - Train Epoch: [4] [51200/1281167 (4%)]	Loss: 3.414571
[2022-06-07 15:51:05 | train] - Train Epoch: [4] [64000/1281167 (5%)]	Loss: 3.966423
[2022-06-07 15:51:28 | train] - Train Epoch: [4] [76800/1281167 (6%)]	Loss: 3.352852
[2022-06-07 15:51:50 | train] - Train Epoch: [4] [89600/1281167 (7%)]	Loss: 3.285593
[2022-06-07 15:52:13 | train] - Train Epoch: [4] [102400/1281167 (8%)]	Loss: 3.635304
[2022-06-07 15:52:35 | train] - Train Epoch: [4] [115200/1281167 (9%)]	Loss: 3.641561
[2022-06-07 15:52:58 | train] - Train Epoch: [4] [128000/1281167 (10%)]	Loss: 3.187222
[2022-06-07 15:53:20 | train] - Train Epoch: [4] [140800/1281167 (11%)]	Loss: 3.521048
[2022-06-07 15:53:43 | train] - Train Epoch: [4] [153600/1281167 (12%)]	Loss: 3.464189
[2022-06-07 15:54:06 | train] - Train Epoch: [4] [166400/1281167 (13%)]	Loss: 3.504481
[2022-06-07 15:54:28 | train] - Train Epoch: [4] [179200/1281167 (14%)]	Loss: 3.367783
[2022-06-07 15:54:50 | train] - Train Epoch: [4] [192000/1281167 (15%)]	Loss: 3.329745
[2022-06-07 15:55:13 | train] - Train Epoch: [4] [204800/1281167 (16%)]	Loss: 3.109537
[2022-06-07 15:55:35 | train] - Train Epoch: [4] [217600/1281167 (17%)]	Loss: 3.392224
[2022-06-07 15:55:57 | train] - Train Epoch: [4] [230400/1281167 (18%)]	Loss: 3.455455
[2022-06-07 15:56:21 | train] - Train Epoch: [4] [243200/1281167 (19%)]	Loss: 3.258618
[2022-06-07 15:56:43 | train] - Train Epoch: [4] [256000/1281167 (20%)]	Loss: 3.435714
[2022-06-07 15:57:05 | train] - Train Epoch: [4] [268800/1281167 (21%)]	Loss: 3.198967
[2022-06-07 15:57:28 | train] - Train Epoch: [4] [281600/1281167 (22%)]	Loss: 3.712104
[2022-06-07 15:57:50 | train] - Train Epoch: [4] [294400/1281167 (23%)]	Loss: 3.245348
[2022-06-07 15:58:12 | train] - Train Epoch: [4] [307200/1281167 (24%)]	Loss: 3.290732
[2022-06-07 15:58:35 | train] - Train Epoch: [4] [320000/1281167 (25%)]	Loss: 3.193088
[2022-06-07 15:58:57 | train] - Train Epoch: [4] [332800/1281167 (26%)]	Loss: 3.355555
[2022-06-07 15:59:19 | train] - Train Epoch: [4] [345600/1281167 (27%)]	Loss: 3.243927
[2022-06-07 15:59:42 | train] - Train Epoch: [4] [358400/1281167 (28%)]	Loss: 3.364838
[2022-06-07 16:00:04 | train] - Train Epoch: [4] [371200/1281167 (29%)]	Loss: 3.328038
[2022-06-07 16:00:26 | train] - Train Epoch: [4] [384000/1281167 (30%)]	Loss: 3.436292
[2022-06-07 16:00:49 | train] - Train Epoch: [4] [396800/1281167 (31%)]	Loss: 3.255919
[2022-06-07 16:01:11 | train] - Train Epoch: [4] [409600/1281167 (32%)]	Loss: 2.944664
[2022-06-07 16:01:33 | train] - Train Epoch: [4] [422400/1281167 (33%)]	Loss: 3.412162
[2022-06-07 16:01:55 | train] - Train Epoch: [4] [435200/1281167 (34%)]	Loss: 3.293045
[2022-06-07 16:02:18 | train] - Train Epoch: [4] [448000/1281167 (35%)]	Loss: 3.225373
[2022-06-07 16:02:40 | train] - Train Epoch: [4] [460800/1281167 (36%)]	Loss: 3.109079
[2022-06-07 16:03:03 | train] - Train Epoch: [4] [473600/1281167 (37%)]	Loss: 3.636754
[2022-06-07 16:03:25 | train] - Train Epoch: [4] [486400/1281167 (38%)]	Loss: 3.443965
[2022-06-07 16:03:48 | train] - Train Epoch: [4] [499200/1281167 (39%)]	Loss: 3.083367
[2022-06-07 16:04:10 | train] - Train Epoch: [4] [512000/1281167 (40%)]	Loss: 3.022994
[2022-06-07 16:04:33 | train] - Train Epoch: [4] [524800/1281167 (41%)]	Loss: 3.264653
[2022-06-07 16:04:55 | train] - Train Epoch: [4] [537600/1281167 (42%)]	Loss: 2.901103
[2022-06-07 16:05:17 | train] - Train Epoch: [4] [550400/1281167 (43%)]	Loss: 3.468724
[2022-06-07 16:05:40 | train] - Train Epoch: [4] [563200/1281167 (44%)]	Loss: 3.351649
[2022-06-07 16:06:02 | train] - Train Epoch: [4] [576000/1281167 (45%)]	Loss: 3.440959
[2022-06-07 16:06:24 | train] - Train Epoch: [4] [588800/1281167 (46%)]	Loss: 3.582954
[2022-06-07 16:06:47 | train] - Train Epoch: [4] [601600/1281167 (47%)]	Loss: 3.104806
[2022-06-07 16:07:08 | train] - Train Epoch: [4] [614400/1281167 (48%)]	Loss: 3.413635
[2022-06-07 16:07:28 | train] - Train Epoch: [4] [627200/1281167 (49%)]	Loss: 3.232029
[2022-06-07 16:07:50 | train] - Train Epoch: [4] [640000/1281167 (50%)]	Loss: 3.475636
[2022-06-07 16:08:11 | train] - Train Epoch: [4] [652800/1281167 (51%)]	Loss: 2.860166
[2022-06-07 16:08:32 | train] - Train Epoch: [4] [665600/1281167 (52%)]	Loss: 3.330040
[2022-06-07 16:08:54 | train] - Train Epoch: [4] [678400/1281167 (53%)]	Loss: 3.511033
[2022-06-07 16:09:15 | train] - Train Epoch: [4] [691200/1281167 (54%)]	Loss: 3.205623
[2022-06-07 16:09:36 | train] - Train Epoch: [4] [704000/1281167 (55%)]	Loss: 3.517741
[2022-06-07 16:09:58 | train] - Train Epoch: [4] [716800/1281167 (56%)]	Loss: 2.689344
[2022-06-07 16:10:20 | train] - Train Epoch: [4] [729600/1281167 (57%)]	Loss: 2.969423
[2022-06-07 16:10:40 | train] - Train Epoch: [4] [742400/1281167 (58%)]	Loss: 3.181617
[2022-06-07 16:11:01 | train] - Train Epoch: [4] [755200/1281167 (59%)]	Loss: 3.481339
[2022-06-07 16:11:23 | train] - Train Epoch: [4] [768000/1281167 (60%)]	Loss: 3.334618
[2022-06-07 16:11:44 | train] - Train Epoch: [4] [780800/1281167 (61%)]	Loss: 2.895924
[2022-06-07 16:12:04 | train] - Train Epoch: [4] [793600/1281167 (62%)]	Loss: 2.934073
[2022-06-07 16:12:26 | train] - Train Epoch: [4] [806400/1281167 (63%)]	Loss: 3.222282
[2022-06-07 16:12:47 | train] - Train Epoch: [4] [819200/1281167 (64%)]	Loss: 2.981105
[2022-06-07 16:13:08 | train] - Train Epoch: [4] [832000/1281167 (65%)]	Loss: 3.547877
[2022-06-07 16:13:29 | train] - Train Epoch: [4] [844800/1281167 (66%)]	Loss: 3.131328
[2022-06-07 16:13:50 | train] - Train Epoch: [4] [857600/1281167 (67%)]	Loss: 2.861883
[2022-06-07 16:14:10 | train] - Train Epoch: [4] [870400/1281167 (68%)]	Loss: 3.191182
[2022-06-07 16:14:32 | train] - Train Epoch: [4] [883200/1281167 (69%)]	Loss: 2.940336
[2022-06-07 16:14:53 | train] - Train Epoch: [4] [896000/1281167 (70%)]	Loss: 3.241138
[2022-06-07 16:15:14 | train] - Train Epoch: [4] [908800/1281167 (71%)]	Loss: 3.599125
[2022-06-07 16:15:36 | train] - Train Epoch: [4] [921600/1281167 (72%)]	Loss: 3.428506
[2022-06-07 16:15:56 | train] - Train Epoch: [4] [934400/1281167 (73%)]	Loss: 2.982342
[2022-06-07 16:16:18 | train] - Train Epoch: [4] [947200/1281167 (74%)]	Loss: 3.004529
[2022-06-07 16:16:39 | train] - Train Epoch: [4] [960000/1281167 (75%)]	Loss: 3.332050
[2022-06-07 16:17:01 | train] - Train Epoch: [4] [972800/1281167 (76%)]	Loss: 3.090811
[2022-06-07 16:17:23 | train] - Train Epoch: [4] [985600/1281167 (77%)]	Loss: 2.946157
[2022-06-07 16:17:46 | train] - Train Epoch: [4] [998400/1281167 (78%)]	Loss: 3.119311
[2022-06-07 16:18:08 | train] - Train Epoch: [4] [1011200/1281167 (79%)]	Loss: 3.250375
[2022-06-07 16:18:29 | train] - Train Epoch: [4] [1024000/1281167 (80%)]	Loss: 2.772743
[2022-06-07 16:18:51 | train] - Train Epoch: [4] [1036800/1281167 (81%)]	Loss: 3.325587
[2022-06-07 16:19:12 | train] - Train Epoch: [4] [1049600/1281167 (82%)]	Loss: 3.123425
[2022-06-07 16:19:33 | train] - Train Epoch: [4] [1062400/1281167 (83%)]	Loss: 3.241584
[2022-06-07 16:19:55 | train] - Train Epoch: [4] [1075200/1281167 (84%)]	Loss: 3.028677
[2022-06-07 16:20:15 | train] - Train Epoch: [4] [1088000/1281167 (85%)]	Loss: 3.050564
[2022-06-07 16:20:37 | train] - Train Epoch: [4] [1100800/1281167 (86%)]	Loss: 3.308260
[2022-06-07 16:20:59 | train] - Train Epoch: [4] [1113600/1281167 (87%)]	Loss: 3.217623
[2022-06-07 16:21:19 | train] - Train Epoch: [4] [1126400/1281167 (88%)]	Loss: 3.096547
[2022-06-07 16:21:39 | train] - Train Epoch: [4] [1139200/1281167 (89%)]	Loss: 3.495472
[2022-06-07 16:22:00 | train] - Train Epoch: [4] [1152000/1281167 (90%)]	Loss: 3.447566
[2022-06-07 16:22:21 | train] - Train Epoch: [4] [1164800/1281167 (91%)]	Loss: 3.117121
[2022-06-07 16:22:42 | train] - Train Epoch: [4] [1177600/1281167 (92%)]	Loss: 3.302402
[2022-06-07 16:23:03 | train] - Train Epoch: [4] [1190400/1281167 (93%)]	Loss: 3.104038
[2022-06-07 16:23:24 | train] - Train Epoch: [4] [1203200/1281167 (94%)]	Loss: 3.084651
[2022-06-07 16:23:45 | train] - Train Epoch: [4] [1216000/1281167 (95%)]	Loss: 3.329698
[2022-06-07 16:24:07 | train] - Train Epoch: [4] [1228800/1281167 (96%)]	Loss: 2.998639
[2022-06-07 16:24:29 | train] - Train Epoch: [4] [1241600/1281167 (97%)]	Loss: 3.162514
[2022-06-07 16:24:49 | train] - Train Epoch: [4] [1254400/1281167 (98%)]	Loss: 3.174136
[2022-06-07 16:25:10 | train] - Train Epoch: [4] [1267200/1281167 (99%)]	Loss: 2.667036
[2022-06-07 16:25:31 | train] - Train Epoch: [4] [1280000/1281167 (100%)]	Loss: 3.385024
[2022-06-07 16:25:33 | train] - Train Epoch: [4]	 Average Loss: 3.276022	 Total Acc : 32.0757	 Total Top5 Acc : 56.3880
[2022-06-07 16:25:33 | train] - -------4 epoch end-----------
========================================
-------4 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 16:27:04 | train] - 
Epoch [4] Test set: Average loss: 2.8009, Accuracy: 19323/50000 (38.6197%), Top-5 Accuracy: 64.8042%

[2022-06-07 16:27:04 | train] - save intermediate epoch [4] result


[2022-06-07 16:27:06 | train] - logging best performance 4 epoch
[2022-06-07 16:27:08 | train] - -------5 epoch start-----------
========================================
----- test end -------------------------


logging best performance 4 epoch
[2022-06-07 16:27:10 | train] - Train Epoch: [5] [0/1281167 (0%)]	Loss: 2.781061
[2022-06-07 16:27:31 | train] - Train Epoch: [5] [12800/1281167 (1%)]	Loss: 3.337211
[2022-06-07 16:27:52 | train] - Train Epoch: [5] [25600/1281167 (2%)]	Loss: 2.919298
[2022-06-07 16:28:13 | train] - Train Epoch: [5] [38400/1281167 (3%)]	Loss: 3.377426
[2022-06-07 16:28:33 | train] - Train Epoch: [5] [51200/1281167 (4%)]	Loss: 3.030362
[2022-06-07 16:28:55 | train] - Train Epoch: [5] [64000/1281167 (5%)]	Loss: 3.053632
[2022-06-07 16:29:15 | train] - Train Epoch: [5] [76800/1281167 (6%)]	Loss: 3.018884
[2022-06-07 16:29:35 | train] - Train Epoch: [5] [89600/1281167 (7%)]	Loss: 3.334901
[2022-06-07 16:29:56 | train] - Train Epoch: [5] [102400/1281167 (8%)]	Loss: 3.617581
[2022-06-07 16:30:17 | train] - Train Epoch: [5] [115200/1281167 (9%)]	Loss: 2.789084
[2022-06-07 16:30:38 | train] - Train Epoch: [5] [128000/1281167 (10%)]	Loss: 3.240192
[2022-06-07 16:30:59 | train] - Train Epoch: [5] [140800/1281167 (11%)]	Loss: 2.860555
[2022-06-07 16:31:20 | train] - Train Epoch: [5] [153600/1281167 (12%)]	Loss: 2.887753
[2022-06-07 16:31:41 | train] - Train Epoch: [5] [166400/1281167 (13%)]	Loss: 2.706789
[2022-06-07 16:32:02 | train] - Train Epoch: [5] [179200/1281167 (14%)]	Loss: 3.287700
[2022-06-07 16:32:23 | train] - Train Epoch: [5] [192000/1281167 (15%)]	Loss: 3.310253
[2022-06-07 16:32:44 | train] - Train Epoch: [5] [204800/1281167 (16%)]	Loss: 2.927762
[2022-06-07 16:33:05 | train] - Train Epoch: [5] [217600/1281167 (17%)]	Loss: 3.045499
[2022-06-07 16:33:26 | train] - Train Epoch: [5] [230400/1281167 (18%)]	Loss: 2.886472
[2022-06-07 16:33:47 | train] - Train Epoch: [5] [243200/1281167 (19%)]	Loss: 2.818656
[2022-06-07 16:34:08 | train] - Train Epoch: [5] [256000/1281167 (20%)]	Loss: 3.042259
[2022-06-07 16:34:30 | train] - Train Epoch: [5] [268800/1281167 (21%)]	Loss: 3.098162
[2022-06-07 16:34:51 | train] - Train Epoch: [5] [281600/1281167 (22%)]	Loss: 3.163288
[2022-06-07 16:35:10 | train] - Train Epoch: [5] [294400/1281167 (23%)]	Loss: 3.283255
[2022-06-07 16:35:30 | train] - Train Epoch: [5] [307200/1281167 (24%)]	Loss: 3.342644
[2022-06-07 16:35:51 | train] - Train Epoch: [5] [320000/1281167 (25%)]	Loss: 2.796739
[2022-06-07 16:36:12 | train] - Train Epoch: [5] [332800/1281167 (26%)]	Loss: 2.993931
[2022-06-07 16:36:33 | train] - Train Epoch: [5] [345600/1281167 (27%)]	Loss: 2.963295
[2022-06-07 16:36:54 | train] - Train Epoch: [5] [358400/1281167 (28%)]	Loss: 3.273177
[2022-06-07 16:37:15 | train] - Train Epoch: [5] [371200/1281167 (29%)]	Loss: 3.086786
[2022-06-07 16:37:36 | train] - Train Epoch: [5] [384000/1281167 (30%)]	Loss: 3.105533
[2022-06-07 16:37:56 | train] - Train Epoch: [5] [396800/1281167 (31%)]	Loss: 2.683052
[2022-06-07 16:38:17 | train] - Train Epoch: [5] [409600/1281167 (32%)]	Loss: 2.784541
[2022-06-07 16:38:38 | train] - Train Epoch: [5] [422400/1281167 (33%)]	Loss: 2.807715
[2022-06-07 16:38:59 | train] - Train Epoch: [5] [435200/1281167 (34%)]	Loss: 2.929905
[2022-06-07 16:39:20 | train] - Train Epoch: [5] [448000/1281167 (35%)]	Loss: 3.433678
[2022-06-07 16:39:42 | train] - Train Epoch: [5] [460800/1281167 (36%)]	Loss: 2.824233
[2022-06-07 16:40:03 | train] - Train Epoch: [5] [473600/1281167 (37%)]	Loss: 2.643152
[2022-06-07 16:40:25 | train] - Train Epoch: [5] [486400/1281167 (38%)]	Loss: 3.193687
[2022-06-07 16:40:45 | train] - Train Epoch: [5] [499200/1281167 (39%)]	Loss: 3.126223
[2022-06-07 16:41:07 | train] - Train Epoch: [5] [512000/1281167 (40%)]	Loss: 3.131709
[2022-06-07 16:41:29 | train] - Train Epoch: [5] [524800/1281167 (41%)]	Loss: 3.056935
[2022-06-07 16:41:51 | train] - Train Epoch: [5] [537600/1281167 (42%)]	Loss: 2.365621
[2022-06-07 16:42:12 | train] - Train Epoch: [5] [550400/1281167 (43%)]	Loss: 2.575420
[2022-06-07 16:42:34 | train] - Train Epoch: [5] [563200/1281167 (44%)]	Loss: 2.946578
[2022-06-07 16:42:56 | train] - Train Epoch: [5] [576000/1281167 (45%)]	Loss: 2.863941
[2022-06-07 16:43:18 | train] - Train Epoch: [5] [588800/1281167 (46%)]	Loss: 2.724440
[2022-06-07 16:43:39 | train] - Train Epoch: [5] [601600/1281167 (47%)]	Loss: 3.154702
[2022-06-07 16:44:01 | train] - Train Epoch: [5] [614400/1281167 (48%)]	Loss: 2.677111
[2022-06-07 16:44:22 | train] - Train Epoch: [5] [627200/1281167 (49%)]	Loss: 2.626104
[2022-06-07 16:44:43 | train] - Train Epoch: [5] [640000/1281167 (50%)]	Loss: 3.319455
[2022-06-07 16:45:03 | train] - Train Epoch: [5] [652800/1281167 (51%)]	Loss: 2.787636
[2022-06-07 16:45:24 | train] - Train Epoch: [5] [665600/1281167 (52%)]	Loss: 2.684430
[2022-06-07 16:45:46 | train] - Train Epoch: [5] [678400/1281167 (53%)]	Loss: 2.834663
[2022-06-07 16:46:07 | train] - Train Epoch: [5] [691200/1281167 (54%)]	Loss: 2.596619
[2022-06-07 16:46:29 | train] - Train Epoch: [5] [704000/1281167 (55%)]	Loss: 3.188155
[2022-06-07 16:46:50 | train] - Train Epoch: [5] [716800/1281167 (56%)]	Loss: 2.619348
[2022-06-07 16:47:11 | train] - Train Epoch: [5] [729600/1281167 (57%)]	Loss: 2.936188
[2022-06-07 16:47:32 | train] - Train Epoch: [5] [742400/1281167 (58%)]	Loss: 3.113781
[2022-06-07 16:47:52 | train] - Train Epoch: [5] [755200/1281167 (59%)]	Loss: 3.188195
[2022-06-07 16:48:14 | train] - Train Epoch: [5] [768000/1281167 (60%)]	Loss: 2.832579
[2022-06-07 16:48:35 | train] - Train Epoch: [5] [780800/1281167 (61%)]	Loss: 3.547481
[2022-06-07 16:48:57 | train] - Train Epoch: [5] [793600/1281167 (62%)]	Loss: 2.734603
[2022-06-07 16:49:16 | train] - Train Epoch: [5] [806400/1281167 (63%)]	Loss: 3.023799
[2022-06-07 16:49:38 | train] - Train Epoch: [5] [819200/1281167 (64%)]	Loss: 2.976270
[2022-06-07 16:50:00 | train] - Train Epoch: [5] [832000/1281167 (65%)]	Loss: 2.949028
[2022-06-07 16:50:22 | train] - Train Epoch: [5] [844800/1281167 (66%)]	Loss: 3.135162
[2022-06-07 16:50:43 | train] - Train Epoch: [5] [857600/1281167 (67%)]	Loss: 2.749235
[2022-06-07 16:51:05 | train] - Train Epoch: [5] [870400/1281167 (68%)]	Loss: 2.656254
[2022-06-07 16:51:26 | train] - Train Epoch: [5] [883200/1281167 (69%)]	Loss: 2.644125
[2022-06-07 16:51:48 | train] - Train Epoch: [5] [896000/1281167 (70%)]	Loss: 2.929320
[2022-06-07 16:52:09 | train] - Train Epoch: [5] [908800/1281167 (71%)]	Loss: 2.607255
[2022-06-07 16:52:31 | train] - Train Epoch: [5] [921600/1281167 (72%)]	Loss: 2.810245
[2022-06-07 16:52:53 | train] - Train Epoch: [5] [934400/1281167 (73%)]	Loss: 3.001975
[2022-06-07 16:53:15 | train] - Train Epoch: [5] [947200/1281167 (74%)]	Loss: 2.856982
[2022-06-07 16:53:36 | train] - Train Epoch: [5] [960000/1281167 (75%)]	Loss: 2.977756
[2022-06-07 16:53:59 | train] - Train Epoch: [5] [972800/1281167 (76%)]	Loss: 2.682698
[2022-06-07 16:54:20 | train] - Train Epoch: [5] [985600/1281167 (77%)]	Loss: 2.883588
[2022-06-07 16:54:42 | train] - Train Epoch: [5] [998400/1281167 (78%)]	Loss: 2.884037
[2022-06-07 16:55:04 | train] - Train Epoch: [5] [1011200/1281167 (79%)]	Loss: 2.835941
[2022-06-07 16:55:27 | train] - Train Epoch: [5] [1024000/1281167 (80%)]	Loss: 3.143345
[2022-06-07 16:55:49 | train] - Train Epoch: [5] [1036800/1281167 (81%)]	Loss: 2.556369
[2022-06-07 16:56:10 | train] - Train Epoch: [5] [1049600/1281167 (82%)]	Loss: 2.858539
[2022-06-07 16:56:32 | train] - Train Epoch: [5] [1062400/1281167 (83%)]	Loss: 2.599984
[2022-06-07 16:56:54 | train] - Train Epoch: [5] [1075200/1281167 (84%)]	Loss: 3.101985
[2022-06-07 16:57:16 | train] - Train Epoch: [5] [1088000/1281167 (85%)]	Loss: 2.683779
[2022-06-07 16:57:39 | train] - Train Epoch: [5] [1100800/1281167 (86%)]	Loss: 2.575737
[2022-06-07 16:58:01 | train] - Train Epoch: [5] [1113600/1281167 (87%)]	Loss: 2.605953
[2022-06-07 16:58:23 | train] - Train Epoch: [5] [1126400/1281167 (88%)]	Loss: 2.921199
[2022-06-07 16:58:44 | train] - Train Epoch: [5] [1139200/1281167 (89%)]	Loss: 2.735529
[2022-06-07 16:59:06 | train] - Train Epoch: [5] [1152000/1281167 (90%)]	Loss: 2.754177
[2022-06-07 16:59:29 | train] - Train Epoch: [5] [1164800/1281167 (91%)]	Loss: 2.373055
[2022-06-07 16:59:51 | train] - Train Epoch: [5] [1177600/1281167 (92%)]	Loss: 2.893969
[2022-06-07 17:00:13 | train] - Train Epoch: [5] [1190400/1281167 (93%)]	Loss: 2.582070
[2022-06-07 17:00:35 | train] - Train Epoch: [5] [1203200/1281167 (94%)]	Loss: 2.728569
[2022-06-07 17:00:56 | train] - Train Epoch: [5] [1216000/1281167 (95%)]	Loss: 2.618118
[2022-06-07 17:01:18 | train] - Train Epoch: [5] [1228800/1281167 (96%)]	Loss: 2.945101
[2022-06-07 17:01:40 | train] - Train Epoch: [5] [1241600/1281167 (97%)]	Loss: 3.097255
[2022-06-07 17:02:02 | train] - Train Epoch: [5] [1254400/1281167 (98%)]	Loss: 3.097666
[2022-06-07 17:02:24 | train] - Train Epoch: [5] [1267200/1281167 (99%)]	Loss: 2.973057
[2022-06-07 17:02:46 | train] - Train Epoch: [5] [1280000/1281167 (100%)]	Loss: 2.872063
[2022-06-07 17:02:48 | train] - Train Epoch: [5]	 Average Loss: 2.952211	 Total Acc : 37.3951	 Total Top5 Acc : 62.0607
[2022-06-07 17:02:48 | train] - -------5 epoch end-----------
========================================
-------5 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 17:04:24 | train] - 
Epoch [5] Test set: Average loss: 2.5684, Accuracy: 21566/50000 (43.1002%), Top-5 Accuracy: 68.9454%

[2022-06-07 17:04:24 | train] - save intermediate epoch [5] result


[2022-06-07 17:04:26 | train] - logging best performance 5 epoch
[2022-06-07 17:04:28 | train] - -------6 epoch start-----------
========================================
----- test end -------------------------


logging best performance 5 epoch
[2022-06-07 17:04:29 | train] - Train Epoch: [6] [0/1281167 (0%)]	Loss: 2.760615
[2022-06-07 17:04:52 | train] - Train Epoch: [6] [12800/1281167 (1%)]	Loss: 2.794387
[2022-06-07 17:05:15 | train] - Train Epoch: [6] [25600/1281167 (2%)]	Loss: 2.914107
[2022-06-07 17:05:37 | train] - Train Epoch: [6] [38400/1281167 (3%)]	Loss: 2.975469
[2022-06-07 17:05:59 | train] - Train Epoch: [6] [51200/1281167 (4%)]	Loss: 2.796561
[2022-06-07 17:06:21 | train] - Train Epoch: [6] [64000/1281167 (5%)]	Loss: 2.582011
[2022-06-07 17:06:44 | train] - Train Epoch: [6] [76800/1281167 (6%)]	Loss: 2.902590
[2022-06-07 17:07:06 | train] - Train Epoch: [6] [89600/1281167 (7%)]	Loss: 2.946470
[2022-06-07 17:07:28 | train] - Train Epoch: [6] [102400/1281167 (8%)]	Loss: 2.688368
[2022-06-07 17:07:51 | train] - Train Epoch: [6] [115200/1281167 (9%)]	Loss: 3.162198
[2022-06-07 17:08:14 | train] - Train Epoch: [6] [128000/1281167 (10%)]	Loss: 2.874804
[2022-06-07 17:08:36 | train] - Train Epoch: [6] [140800/1281167 (11%)]	Loss: 3.074903
[2022-06-07 17:08:58 | train] - Train Epoch: [6] [153600/1281167 (12%)]	Loss: 3.089100
[2022-06-07 17:09:21 | train] - Train Epoch: [6] [166400/1281167 (13%)]	Loss: 3.092362
[2022-06-07 17:09:43 | train] - Train Epoch: [6] [179200/1281167 (14%)]	Loss: 2.591240
[2022-06-07 17:10:05 | train] - Train Epoch: [6] [192000/1281167 (15%)]	Loss: 2.540966
[2022-06-07 17:10:28 | train] - Train Epoch: [6] [204800/1281167 (16%)]	Loss: 2.937876
[2022-06-07 17:10:51 | train] - Train Epoch: [6] [217600/1281167 (17%)]	Loss: 2.665069
[2022-06-07 17:11:12 | train] - Train Epoch: [6] [230400/1281167 (18%)]	Loss: 2.727546
[2022-06-07 17:11:34 | train] - Train Epoch: [6] [243200/1281167 (19%)]	Loss: 2.537715
[2022-06-07 17:11:55 | train] - Train Epoch: [6] [256000/1281167 (20%)]	Loss: 3.077408
[2022-06-07 17:12:18 | train] - Train Epoch: [6] [268800/1281167 (21%)]	Loss: 2.781199
[2022-06-07 17:12:40 | train] - Train Epoch: [6] [281600/1281167 (22%)]	Loss: 2.459596
[2022-06-07 17:13:02 | train] - Train Epoch: [6] [294400/1281167 (23%)]	Loss: 2.680083
[2022-06-07 17:13:23 | train] - Train Epoch: [6] [307200/1281167 (24%)]	Loss: 2.538925
[2022-06-07 17:13:45 | train] - Train Epoch: [6] [320000/1281167 (25%)]	Loss: 2.468842
[2022-06-07 17:14:07 | train] - Train Epoch: [6] [332800/1281167 (26%)]	Loss: 2.877126
[2022-06-07 17:14:29 | train] - Train Epoch: [6] [345600/1281167 (27%)]	Loss: 2.272544
[2022-06-07 17:14:51 | train] - Train Epoch: [6] [358400/1281167 (28%)]	Loss: 2.785151
[2022-06-07 17:15:13 | train] - Train Epoch: [6] [371200/1281167 (29%)]	Loss: 2.749342
[2022-06-07 17:15:35 | train] - Train Epoch: [6] [384000/1281167 (30%)]	Loss: 3.045293
[2022-06-07 17:15:58 | train] - Train Epoch: [6] [396800/1281167 (31%)]	Loss: 3.056136
[2022-06-07 17:16:20 | train] - Train Epoch: [6] [409600/1281167 (32%)]	Loss: 2.737615
[2022-06-07 17:16:41 | train] - Train Epoch: [6] [422400/1281167 (33%)]	Loss: 2.898787
[2022-06-07 17:17:02 | train] - Train Epoch: [6] [435200/1281167 (34%)]	Loss: 2.466705
[2022-06-07 17:17:23 | train] - Train Epoch: [6] [448000/1281167 (35%)]	Loss: 2.683298
[2022-06-07 17:17:46 | train] - Train Epoch: [6] [460800/1281167 (36%)]	Loss: 2.960357
[2022-06-07 17:18:08 | train] - Train Epoch: [6] [473600/1281167 (37%)]	Loss: 2.649957
[2022-06-07 17:18:30 | train] - Train Epoch: [6] [486400/1281167 (38%)]	Loss: 2.663851
[2022-06-07 17:18:52 | train] - Train Epoch: [6] [499200/1281167 (39%)]	Loss: 3.092776
[2022-06-07 17:19:15 | train] - Train Epoch: [6] [512000/1281167 (40%)]	Loss: 3.060647
[2022-06-07 17:19:37 | train] - Train Epoch: [6] [524800/1281167 (41%)]	Loss: 2.301620
[2022-06-07 17:19:59 | train] - Train Epoch: [6] [537600/1281167 (42%)]	Loss: 2.557757
[2022-06-07 17:20:21 | train] - Train Epoch: [6] [550400/1281167 (43%)]	Loss: 2.889829
[2022-06-07 17:20:44 | train] - Train Epoch: [6] [563200/1281167 (44%)]	Loss: 2.312844
[2022-06-07 17:21:06 | train] - Train Epoch: [6] [576000/1281167 (45%)]	Loss: 2.961655
[2022-06-07 17:21:28 | train] - Train Epoch: [6] [588800/1281167 (46%)]	Loss: 2.672245
[2022-06-07 17:21:49 | train] - Train Epoch: [6] [601600/1281167 (47%)]	Loss: 2.400609
[2022-06-07 17:22:12 | train] - Train Epoch: [6] [614400/1281167 (48%)]	Loss: 2.806733
[2022-06-07 17:22:34 | train] - Train Epoch: [6] [627200/1281167 (49%)]	Loss: 2.373355
[2022-06-07 17:22:56 | train] - Train Epoch: [6] [640000/1281167 (50%)]	Loss: 2.665908
[2022-06-07 17:23:18 | train] - Train Epoch: [6] [652800/1281167 (51%)]	Loss: 2.769173
[2022-06-07 17:23:41 | train] - Train Epoch: [6] [665600/1281167 (52%)]	Loss: 2.465855
[2022-06-07 17:24:04 | train] - Train Epoch: [6] [678400/1281167 (53%)]	Loss: 2.622885
[2022-06-07 17:24:25 | train] - Train Epoch: [6] [691200/1281167 (54%)]	Loss: 2.484388
[2022-06-07 17:24:47 | train] - Train Epoch: [6] [704000/1281167 (55%)]	Loss: 2.891403
[2022-06-07 17:25:10 | train] - Train Epoch: [6] [716800/1281167 (56%)]	Loss: 2.813160
[2022-06-07 17:25:32 | train] - Train Epoch: [6] [729600/1281167 (57%)]	Loss: 2.755449
[2022-06-07 17:25:53 | train] - Train Epoch: [6] [742400/1281167 (58%)]	Loss: 2.840830
[2022-06-07 17:26:15 | train] - Train Epoch: [6] [755200/1281167 (59%)]	Loss: 2.957156
[2022-06-07 17:26:38 | train] - Train Epoch: [6] [768000/1281167 (60%)]	Loss: 2.687989
[2022-06-07 17:26:59 | train] - Train Epoch: [6] [780800/1281167 (61%)]	Loss: 2.517396
[2022-06-07 17:27:20 | train] - Train Epoch: [6] [793600/1281167 (62%)]	Loss: 2.946630
[2022-06-07 17:27:43 | train] - Train Epoch: [6] [806400/1281167 (63%)]	Loss: 2.633781
[2022-06-07 17:28:06 | train] - Train Epoch: [6] [819200/1281167 (64%)]	Loss: 2.721601
[2022-06-07 17:28:28 | train] - Train Epoch: [6] [832000/1281167 (65%)]	Loss: 2.923810
[2022-06-07 17:28:50 | train] - Train Epoch: [6] [844800/1281167 (66%)]	Loss: 2.537476
[2022-06-07 17:29:12 | train] - Train Epoch: [6] [857600/1281167 (67%)]	Loss: 2.566056
[2022-06-07 17:29:35 | train] - Train Epoch: [6] [870400/1281167 (68%)]	Loss: 2.453721
[2022-06-07 17:29:57 | train] - Train Epoch: [6] [883200/1281167 (69%)]	Loss: 3.013359
[2022-06-07 17:30:19 | train] - Train Epoch: [6] [896000/1281167 (70%)]	Loss: 2.726772
[2022-06-07 17:30:41 | train] - Train Epoch: [6] [908800/1281167 (71%)]	Loss: 2.694916
[2022-06-07 17:31:05 | train] - Train Epoch: [6] [921600/1281167 (72%)]	Loss: 2.682283
[2022-06-07 17:31:27 | train] - Train Epoch: [6] [934400/1281167 (73%)]	Loss: 2.647098
[2022-06-07 17:31:48 | train] - Train Epoch: [6] [947200/1281167 (74%)]	Loss: 2.716658
[2022-06-07 17:32:10 | train] - Train Epoch: [6] [960000/1281167 (75%)]	Loss: 2.744409
[2022-06-07 17:32:33 | train] - Train Epoch: [6] [972800/1281167 (76%)]	Loss: 2.351673
[2022-06-07 17:32:55 | train] - Train Epoch: [6] [985600/1281167 (77%)]	Loss: 2.296844
[2022-06-07 17:33:16 | train] - Train Epoch: [6] [998400/1281167 (78%)]	Loss: 2.786686
[2022-06-07 17:33:38 | train] - Train Epoch: [6] [1011200/1281167 (79%)]	Loss: 2.487098
[2022-06-07 17:34:00 | train] - Train Epoch: [6] [1024000/1281167 (80%)]	Loss: 2.614551
[2022-06-07 17:34:22 | train] - Train Epoch: [6] [1036800/1281167 (81%)]	Loss: 2.891168
[2022-06-07 17:34:44 | train] - Train Epoch: [6] [1049600/1281167 (82%)]	Loss: 2.660226
[2022-06-07 17:35:06 | train] - Train Epoch: [6] [1062400/1281167 (83%)]	Loss: 2.451099
[2022-06-07 17:35:28 | train] - Train Epoch: [6] [1075200/1281167 (84%)]	Loss: 2.513525
[2022-06-07 17:35:50 | train] - Train Epoch: [6] [1088000/1281167 (85%)]	Loss: 2.565166
[2022-06-07 17:36:12 | train] - Train Epoch: [6] [1100800/1281167 (86%)]	Loss: 2.505287
[2022-06-07 17:36:34 | train] - Train Epoch: [6] [1113600/1281167 (87%)]	Loss: 2.297149
[2022-06-07 17:36:55 | train] - Train Epoch: [6] [1126400/1281167 (88%)]	Loss: 2.793879
[2022-06-07 17:37:18 | train] - Train Epoch: [6] [1139200/1281167 (89%)]	Loss: 2.680808
[2022-06-07 17:37:40 | train] - Train Epoch: [6] [1152000/1281167 (90%)]	Loss: 2.521378
[2022-06-07 17:38:02 | train] - Train Epoch: [6] [1164800/1281167 (91%)]	Loss: 2.809117
[2022-06-07 17:38:24 | train] - Train Epoch: [6] [1177600/1281167 (92%)]	Loss: 2.574673
[2022-06-07 17:38:47 | train] - Train Epoch: [6] [1190400/1281167 (93%)]	Loss: 2.344736
[2022-06-07 17:39:08 | train] - Train Epoch: [6] [1203200/1281167 (94%)]	Loss: 2.717791
[2022-06-07 17:39:30 | train] - Train Epoch: [6] [1216000/1281167 (95%)]	Loss: 2.704575
[2022-06-07 17:39:51 | train] - Train Epoch: [6] [1228800/1281167 (96%)]	Loss: 2.888066
[2022-06-07 17:40:13 | train] - Train Epoch: [6] [1241600/1281167 (97%)]	Loss: 2.996627
[2022-06-07 17:40:35 | train] - Train Epoch: [6] [1254400/1281167 (98%)]	Loss: 2.535594
[2022-06-07 17:40:57 | train] - Train Epoch: [6] [1267200/1281167 (99%)]	Loss: 2.625555
[2022-06-07 17:41:19 | train] - Train Epoch: [6] [1280000/1281167 (100%)]	Loss: 2.437892
[2022-06-07 17:41:21 | train] - Train Epoch: [6]	 Average Loss: 2.705726	 Total Acc : 41.6442	 Total Top5 Acc : 66.2604
[2022-06-07 17:41:21 | train] - -------6 epoch end-----------
========================================
-------6 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 17:42:57 | train] - 
Epoch [6] Test set: Average loss: 2.2996, Accuracy: 23934/50000 (47.8317%), Top-5 Accuracy: 73.2884%

[2022-06-07 17:42:57 | train] - save intermediate epoch [6] result


[2022-06-07 17:42:59 | train] - logging best performance 6 epoch
[2022-06-07 17:43:01 | train] - -------7 epoch start-----------
========================================
----- test end -------------------------


logging best performance 6 epoch
[2022-06-07 17:43:02 | train] - Train Epoch: [7] [0/1281167 (0%)]	Loss: 2.913925
[2022-06-07 17:43:25 | train] - Train Epoch: [7] [12800/1281167 (1%)]	Loss: 2.508827
[2022-06-07 17:43:47 | train] - Train Epoch: [7] [25600/1281167 (2%)]	Loss: 2.304871
[2022-06-07 17:44:09 | train] - Train Epoch: [7] [38400/1281167 (3%)]	Loss: 2.839750
[2022-06-07 17:44:31 | train] - Train Epoch: [7] [51200/1281167 (4%)]	Loss: 2.663939
[2022-06-07 17:44:53 | train] - Train Epoch: [7] [64000/1281167 (5%)]	Loss: 2.769438
[2022-06-07 17:45:15 | train] - Train Epoch: [7] [76800/1281167 (6%)]	Loss: 2.491832
[2022-06-07 17:45:36 | train] - Train Epoch: [7] [89600/1281167 (7%)]	Loss: 2.341407
[2022-06-07 17:45:59 | train] - Train Epoch: [7] [102400/1281167 (8%)]	Loss: 2.505706
[2022-06-07 17:46:21 | train] - Train Epoch: [7] [115200/1281167 (9%)]	Loss: 2.465463
[2022-06-07 17:46:43 | train] - Train Epoch: [7] [128000/1281167 (10%)]	Loss: 2.467517
[2022-06-07 17:47:04 | train] - Train Epoch: [7] [140800/1281167 (11%)]	Loss: 2.589681
[2022-06-07 17:47:26 | train] - Train Epoch: [7] [153600/1281167 (12%)]	Loss: 2.445889
[2022-06-07 17:47:48 | train] - Train Epoch: [7] [166400/1281167 (13%)]	Loss: 2.780943
[2022-06-07 17:48:11 | train] - Train Epoch: [7] [179200/1281167 (14%)]	Loss: 2.022808
[2022-06-07 17:48:33 | train] - Train Epoch: [7] [192000/1281167 (15%)]	Loss: 2.838210
[2022-06-07 17:48:55 | train] - Train Epoch: [7] [204800/1281167 (16%)]	Loss: 2.252264
[2022-06-07 17:49:16 | train] - Train Epoch: [7] [217600/1281167 (17%)]	Loss: 2.679855
[2022-06-07 17:49:38 | train] - Train Epoch: [7] [230400/1281167 (18%)]	Loss: 2.630735
[2022-06-07 17:50:00 | train] - Train Epoch: [7] [243200/1281167 (19%)]	Loss: 2.543107
[2022-06-07 17:50:22 | train] - Train Epoch: [7] [256000/1281167 (20%)]	Loss: 2.508309
[2022-06-07 17:50:45 | train] - Train Epoch: [7] [268800/1281167 (21%)]	Loss: 2.750278
[2022-06-07 17:51:06 | train] - Train Epoch: [7] [281600/1281167 (22%)]	Loss: 2.725416
[2022-06-07 17:51:29 | train] - Train Epoch: [7] [294400/1281167 (23%)]	Loss: 2.590312
[2022-06-07 17:51:52 | train] - Train Epoch: [7] [307200/1281167 (24%)]	Loss: 2.677564
[2022-06-07 17:52:13 | train] - Train Epoch: [7] [320000/1281167 (25%)]	Loss: 2.693976
[2022-06-07 17:52:35 | train] - Train Epoch: [7] [332800/1281167 (26%)]	Loss: 2.934937
[2022-06-07 17:52:57 | train] - Train Epoch: [7] [345600/1281167 (27%)]	Loss: 2.839666
[2022-06-07 17:53:19 | train] - Train Epoch: [7] [358400/1281167 (28%)]	Loss: 2.589875
[2022-06-07 17:53:41 | train] - Train Epoch: [7] [371200/1281167 (29%)]	Loss: 2.729720
[2022-06-07 17:54:02 | train] - Train Epoch: [7] [384000/1281167 (30%)]	Loss: 2.289649
[2022-06-07 17:54:25 | train] - Train Epoch: [7] [396800/1281167 (31%)]	Loss: 2.442599
[2022-06-07 17:54:47 | train] - Train Epoch: [7] [409600/1281167 (32%)]	Loss: 2.443446
[2022-06-07 17:55:09 | train] - Train Epoch: [7] [422400/1281167 (33%)]	Loss: 2.438233
[2022-06-07 17:55:31 | train] - Train Epoch: [7] [435200/1281167 (34%)]	Loss: 2.769902
[2022-06-07 17:55:53 | train] - Train Epoch: [7] [448000/1281167 (35%)]	Loss: 2.659497
[2022-06-07 17:56:16 | train] - Train Epoch: [7] [460800/1281167 (36%)]	Loss: 2.576721
[2022-06-07 17:56:38 | train] - Train Epoch: [7] [473600/1281167 (37%)]	Loss: 2.389072
[2022-06-07 17:57:00 | train] - Train Epoch: [7] [486400/1281167 (38%)]	Loss: 2.291140
[2022-06-07 17:57:22 | train] - Train Epoch: [7] [499200/1281167 (39%)]	Loss: 2.414484
[2022-06-07 17:57:44 | train] - Train Epoch: [7] [512000/1281167 (40%)]	Loss: 2.924739
[2022-06-07 17:58:06 | train] - Train Epoch: [7] [524800/1281167 (41%)]	Loss: 2.416302
[2022-06-07 17:58:28 | train] - Train Epoch: [7] [537600/1281167 (42%)]	Loss: 2.261134
[2022-06-07 17:58:50 | train] - Train Epoch: [7] [550400/1281167 (43%)]	Loss: 2.769428
[2022-06-07 17:59:12 | train] - Train Epoch: [7] [563200/1281167 (44%)]	Loss: 2.725060
[2022-06-07 17:59:34 | train] - Train Epoch: [7] [576000/1281167 (45%)]	Loss: 2.482600
[2022-06-07 17:59:56 | train] - Train Epoch: [7] [588800/1281167 (46%)]	Loss: 2.357935
[2022-06-07 18:00:17 | train] - Train Epoch: [7] [601600/1281167 (47%)]	Loss: 2.586386
[2022-06-07 18:00:39 | train] - Train Epoch: [7] [614400/1281167 (48%)]	Loss: 2.706645
[2022-06-07 18:01:01 | train] - Train Epoch: [7] [627200/1281167 (49%)]	Loss: 2.553373
[2022-06-07 18:01:23 | train] - Train Epoch: [7] [640000/1281167 (50%)]	Loss: 2.495222
[2022-06-07 18:01:45 | train] - Train Epoch: [7] [652800/1281167 (51%)]	Loss: 2.917665
[2022-06-07 18:02:07 | train] - Train Epoch: [7] [665600/1281167 (52%)]	Loss: 2.394104
[2022-06-07 18:02:29 | train] - Train Epoch: [7] [678400/1281167 (53%)]	Loss: 2.293441
[2022-06-07 18:02:51 | train] - Train Epoch: [7] [691200/1281167 (54%)]	Loss: 2.687594
[2022-06-07 18:03:14 | train] - Train Epoch: [7] [704000/1281167 (55%)]	Loss: 2.184948
[2022-06-07 18:03:36 | train] - Train Epoch: [7] [716800/1281167 (56%)]	Loss: 2.422851
[2022-06-07 18:03:58 | train] - Train Epoch: [7] [729600/1281167 (57%)]	Loss: 2.689106
[2022-06-07 18:04:19 | train] - Train Epoch: [7] [742400/1281167 (58%)]	Loss: 2.541636
[2022-06-07 18:04:42 | train] - Train Epoch: [7] [755200/1281167 (59%)]	Loss: 2.833473
[2022-06-07 18:05:03 | train] - Train Epoch: [7] [768000/1281167 (60%)]	Loss: 2.613764
[2022-06-07 18:05:26 | train] - Train Epoch: [7] [780800/1281167 (61%)]	Loss: 2.476451
[2022-06-07 18:05:47 | train] - Train Epoch: [7] [793600/1281167 (62%)]	Loss: 2.475839
[2022-06-07 18:06:10 | train] - Train Epoch: [7] [806400/1281167 (63%)]	Loss: 2.428261
[2022-06-07 18:06:32 | train] - Train Epoch: [7] [819200/1281167 (64%)]	Loss: 2.877769
[2022-06-07 18:06:53 | train] - Train Epoch: [7] [832000/1281167 (65%)]	Loss: 2.589761
[2022-06-07 18:07:16 | train] - Train Epoch: [7] [844800/1281167 (66%)]	Loss: 2.808859
[2022-06-07 18:07:37 | train] - Train Epoch: [7] [857600/1281167 (67%)]	Loss: 2.480971
[2022-06-07 18:07:59 | train] - Train Epoch: [7] [870400/1281167 (68%)]	Loss: 2.263078
[2022-06-07 18:08:21 | train] - Train Epoch: [7] [883200/1281167 (69%)]	Loss: 2.580319
[2022-06-07 18:08:43 | train] - Train Epoch: [7] [896000/1281167 (70%)]	Loss: 2.595255
[2022-06-07 18:09:05 | train] - Train Epoch: [7] [908800/1281167 (71%)]	Loss: 2.524851
[2022-06-07 18:09:27 | train] - Train Epoch: [7] [921600/1281167 (72%)]	Loss: 2.438335
[2022-06-07 18:09:49 | train] - Train Epoch: [7] [934400/1281167 (73%)]	Loss: 2.566784
[2022-06-07 18:10:12 | train] - Train Epoch: [7] [947200/1281167 (74%)]	Loss: 2.676298
[2022-06-07 18:10:33 | train] - Train Epoch: [7] [960000/1281167 (75%)]	Loss: 2.494553
[2022-06-07 18:10:55 | train] - Train Epoch: [7] [972800/1281167 (76%)]	Loss: 2.669866
[2022-06-07 18:11:17 | train] - Train Epoch: [7] [985600/1281167 (77%)]	Loss: 2.520969
[2022-06-07 18:11:40 | train] - Train Epoch: [7] [998400/1281167 (78%)]	Loss: 2.193595
[2022-06-07 18:12:02 | train] - Train Epoch: [7] [1011200/1281167 (79%)]	Loss: 2.664796
[2022-06-07 18:12:23 | train] - Train Epoch: [7] [1024000/1281167 (80%)]	Loss: 2.282960
[2022-06-07 18:12:44 | train] - Train Epoch: [7] [1036800/1281167 (81%)]	Loss: 2.368271
[2022-06-07 18:13:06 | train] - Train Epoch: [7] [1049600/1281167 (82%)]	Loss: 2.352463
[2022-06-07 18:13:28 | train] - Train Epoch: [7] [1062400/1281167 (83%)]	Loss: 2.573052
[2022-06-07 18:13:49 | train] - Train Epoch: [7] [1075200/1281167 (84%)]	Loss: 2.526905
[2022-06-07 18:14:11 | train] - Train Epoch: [7] [1088000/1281167 (85%)]	Loss: 2.454763
[2022-06-07 18:14:32 | train] - Train Epoch: [7] [1100800/1281167 (86%)]	Loss: 2.766108
[2022-06-07 18:14:55 | train] - Train Epoch: [7] [1113600/1281167 (87%)]	Loss: 2.542271
[2022-06-07 18:15:17 | train] - Train Epoch: [7] [1126400/1281167 (88%)]	Loss: 2.282242
[2022-06-07 18:15:39 | train] - Train Epoch: [7] [1139200/1281167 (89%)]	Loss: 2.531673
[2022-06-07 18:16:01 | train] - Train Epoch: [7] [1152000/1281167 (90%)]	Loss: 2.644630
[2022-06-07 18:16:22 | train] - Train Epoch: [7] [1164800/1281167 (91%)]	Loss: 1.995805
[2022-06-07 18:16:45 | train] - Train Epoch: [7] [1177600/1281167 (92%)]	Loss: 2.259861
[2022-06-07 18:17:07 | train] - Train Epoch: [7] [1190400/1281167 (93%)]	Loss: 2.299565
[2022-06-07 18:17:28 | train] - Train Epoch: [7] [1203200/1281167 (94%)]	Loss: 2.311457
[2022-06-07 18:17:50 | train] - Train Epoch: [7] [1216000/1281167 (95%)]	Loss: 2.145550
[2022-06-07 18:18:12 | train] - Train Epoch: [7] [1228800/1281167 (96%)]	Loss: 2.712127
[2022-06-07 18:18:35 | train] - Train Epoch: [7] [1241600/1281167 (97%)]	Loss: 2.800950
[2022-06-07 18:18:57 | train] - Train Epoch: [7] [1254400/1281167 (98%)]	Loss: 2.168580
[2022-06-07 18:19:19 | train] - Train Epoch: [7] [1267200/1281167 (99%)]	Loss: 2.703282
[2022-06-07 18:19:41 | train] - Train Epoch: [7] [1280000/1281167 (100%)]	Loss: 2.420431
[2022-06-07 18:19:43 | train] - Train Epoch: [7]	 Average Loss: 2.532190	 Total Acc : 44.7981	 Total Top5 Acc : 69.1370
[2022-06-07 18:19:43 | train] - -------7 epoch end-----------
========================================
-------7 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 18:21:15 | train] - 
Epoch [7] Test set: Average loss: 2.1771, Accuracy: 25209/50000 (50.3732%), Top-5 Accuracy: 75.3573%

[2022-06-07 18:21:15 | train] - save intermediate epoch [7] result


[2022-06-07 18:21:18 | train] - logging best performance 7 epoch
[2022-06-07 18:21:19 | train] - -------8 epoch start-----------
========================================
----- test end -------------------------


logging best performance 7 epoch
[2022-06-07 18:21:21 | train] - Train Epoch: [8] [0/1281167 (0%)]	Loss: 2.356076
[2022-06-07 18:21:44 | train] - Train Epoch: [8] [12800/1281167 (1%)]	Loss: 2.634550
[2022-06-07 18:22:07 | train] - Train Epoch: [8] [25600/1281167 (2%)]	Loss: 2.600785
[2022-06-07 18:22:28 | train] - Train Epoch: [8] [38400/1281167 (3%)]	Loss: 2.302856
[2022-06-07 18:22:50 | train] - Train Epoch: [8] [51200/1281167 (4%)]	Loss: 2.405138
[2022-06-07 18:23:12 | train] - Train Epoch: [8] [64000/1281167 (5%)]	Loss: 2.358877
[2022-06-07 18:23:35 | train] - Train Epoch: [8] [76800/1281167 (6%)]	Loss: 2.300576
[2022-06-07 18:23:57 | train] - Train Epoch: [8] [89600/1281167 (7%)]	Loss: 2.350532
[2022-06-07 18:24:19 | train] - Train Epoch: [8] [102400/1281167 (8%)]	Loss: 2.194305
[2022-06-07 18:24:41 | train] - Train Epoch: [8] [115200/1281167 (9%)]	Loss: 2.521523
[2022-06-07 18:25:02 | train] - Train Epoch: [8] [128000/1281167 (10%)]	Loss: 2.750552
[2022-06-07 18:25:25 | train] - Train Epoch: [8] [140800/1281167 (11%)]	Loss: 2.649688
[2022-06-07 18:25:48 | train] - Train Epoch: [8] [153600/1281167 (12%)]	Loss: 2.290885
[2022-06-07 18:26:09 | train] - Train Epoch: [8] [166400/1281167 (13%)]	Loss: 2.654470
[2022-06-07 18:26:31 | train] - Train Epoch: [8] [179200/1281167 (14%)]	Loss: 2.296628
[2022-06-07 18:26:53 | train] - Train Epoch: [8] [192000/1281167 (15%)]	Loss: 2.326849
[2022-06-07 18:27:16 | train] - Train Epoch: [8] [204800/1281167 (16%)]	Loss: 2.525017
[2022-06-07 18:27:37 | train] - Train Epoch: [8] [217600/1281167 (17%)]	Loss: 2.460369
[2022-06-07 18:27:59 | train] - Train Epoch: [8] [230400/1281167 (18%)]	Loss: 2.651371
[2022-06-07 18:28:22 | train] - Train Epoch: [8] [243200/1281167 (19%)]	Loss: 2.389448
[2022-06-07 18:28:44 | train] - Train Epoch: [8] [256000/1281167 (20%)]	Loss: 2.344844
[2022-06-07 18:29:07 | train] - Train Epoch: [8] [268800/1281167 (21%)]	Loss: 1.996243
[2022-06-07 18:29:29 | train] - Train Epoch: [8] [281600/1281167 (22%)]	Loss: 2.460281
[2022-06-07 18:29:51 | train] - Train Epoch: [8] [294400/1281167 (23%)]	Loss: 2.781286
[2022-06-07 18:30:13 | train] - Train Epoch: [8] [307200/1281167 (24%)]	Loss: 2.572222
[2022-06-07 18:30:36 | train] - Train Epoch: [8] [320000/1281167 (25%)]	Loss: 1.829790
[2022-06-07 18:30:58 | train] - Train Epoch: [8] [332800/1281167 (26%)]	Loss: 2.771420
[2022-06-07 18:31:21 | train] - Train Epoch: [8] [345600/1281167 (27%)]	Loss: 2.482433
[2022-06-07 18:31:42 | train] - Train Epoch: [8] [358400/1281167 (28%)]	Loss: 2.438575
[2022-06-07 18:32:05 | train] - Train Epoch: [8] [371200/1281167 (29%)]	Loss: 2.756299
[2022-06-07 18:32:27 | train] - Train Epoch: [8] [384000/1281167 (30%)]	Loss: 2.395784
[2022-06-07 18:32:49 | train] - Train Epoch: [8] [396800/1281167 (31%)]	Loss: 2.531664
[2022-06-07 18:33:11 | train] - Train Epoch: [8] [409600/1281167 (32%)]	Loss: 3.012933
[2022-06-07 18:33:32 | train] - Train Epoch: [8] [422400/1281167 (33%)]	Loss: 2.553103
[2022-06-07 18:33:54 | train] - Train Epoch: [8] [435200/1281167 (34%)]	Loss: 2.207932
[2022-06-07 18:34:16 | train] - Train Epoch: [8] [448000/1281167 (35%)]	Loss: 2.678364
[2022-06-07 18:34:39 | train] - Train Epoch: [8] [460800/1281167 (36%)]	Loss: 2.657187
[2022-06-07 18:35:01 | train] - Train Epoch: [8] [473600/1281167 (37%)]	Loss: 2.287407
[2022-06-07 18:35:24 | train] - Train Epoch: [8] [486400/1281167 (38%)]	Loss: 2.235394
[2022-06-07 18:35:45 | train] - Train Epoch: [8] [499200/1281167 (39%)]	Loss: 2.408848
[2022-06-07 18:36:08 | train] - Train Epoch: [8] [512000/1281167 (40%)]	Loss: 2.400460
[2022-06-07 18:36:30 | train] - Train Epoch: [8] [524800/1281167 (41%)]	Loss: 2.155328
[2022-06-07 18:36:52 | train] - Train Epoch: [8] [537600/1281167 (42%)]	Loss: 2.418953
[2022-06-07 18:37:15 | train] - Train Epoch: [8] [550400/1281167 (43%)]	Loss: 2.522395
[2022-06-07 18:37:38 | train] - Train Epoch: [8] [563200/1281167 (44%)]	Loss: 2.563342
[2022-06-07 18:38:01 | train] - Train Epoch: [8] [576000/1281167 (45%)]	Loss: 2.400815
[2022-06-07 18:38:22 | train] - Train Epoch: [8] [588800/1281167 (46%)]	Loss: 2.496407
[2022-06-07 18:38:45 | train] - Train Epoch: [8] [601600/1281167 (47%)]	Loss: 2.231436
[2022-06-07 18:39:06 | train] - Train Epoch: [8] [614400/1281167 (48%)]	Loss: 2.664093
[2022-06-07 18:39:28 | train] - Train Epoch: [8] [627200/1281167 (49%)]	Loss: 2.250835
[2022-06-07 18:39:51 | train] - Train Epoch: [8] [640000/1281167 (50%)]	Loss: 2.333670
[2022-06-07 18:40:13 | train] - Train Epoch: [8] [652800/1281167 (51%)]	Loss: 2.948713
[2022-06-07 18:40:34 | train] - Train Epoch: [8] [665600/1281167 (52%)]	Loss: 2.245875
[2022-06-07 18:40:56 | train] - Train Epoch: [8] [678400/1281167 (53%)]	Loss: 2.680415
[2022-06-07 18:41:18 | train] - Train Epoch: [8] [691200/1281167 (54%)]	Loss: 2.032792
[2022-06-07 18:41:40 | train] - Train Epoch: [8] [704000/1281167 (55%)]	Loss: 2.646705
[2022-06-07 18:42:02 | train] - Train Epoch: [8] [716800/1281167 (56%)]	Loss: 2.317836
[2022-06-07 18:42:24 | train] - Train Epoch: [8] [729600/1281167 (57%)]	Loss: 2.236892
[2022-06-07 18:42:46 | train] - Train Epoch: [8] [742400/1281167 (58%)]	Loss: 2.232841
[2022-06-07 18:43:08 | train] - Train Epoch: [8] [755200/1281167 (59%)]	Loss: 2.360020
[2022-06-07 18:43:31 | train] - Train Epoch: [8] [768000/1281167 (60%)]	Loss: 2.216958
[2022-06-07 18:43:54 | train] - Train Epoch: [8] [780800/1281167 (61%)]	Loss: 2.221970
[2022-06-07 18:44:15 | train] - Train Epoch: [8] [793600/1281167 (62%)]	Loss: 2.429878
[2022-06-07 18:44:38 | train] - Train Epoch: [8] [806400/1281167 (63%)]	Loss: 2.454083
[2022-06-07 18:44:59 | train] - Train Epoch: [8] [819200/1281167 (64%)]	Loss: 2.232767
[2022-06-07 18:45:22 | train] - Train Epoch: [8] [832000/1281167 (65%)]	Loss: 2.697827
[2022-06-07 18:45:45 | train] - Train Epoch: [8] [844800/1281167 (66%)]	Loss: 2.176841
[2022-06-07 18:46:06 | train] - Train Epoch: [8] [857600/1281167 (67%)]	Loss: 2.188447
[2022-06-07 18:46:28 | train] - Train Epoch: [8] [870400/1281167 (68%)]	Loss: 2.549839
[2022-06-07 18:46:50 | train] - Train Epoch: [8] [883200/1281167 (69%)]	Loss: 2.444508
[2022-06-07 18:47:13 | train] - Train Epoch: [8] [896000/1281167 (70%)]	Loss: 2.194245
[2022-06-07 18:47:36 | train] - Train Epoch: [8] [908800/1281167 (71%)]	Loss: 2.633475
[2022-06-07 18:47:57 | train] - Train Epoch: [8] [921600/1281167 (72%)]	Loss: 2.604309
[2022-06-07 18:48:19 | train] - Train Epoch: [8] [934400/1281167 (73%)]	Loss: 2.185809
[2022-06-07 18:48:40 | train] - Train Epoch: [8] [947200/1281167 (74%)]	Loss: 2.529114
[2022-06-07 18:49:03 | train] - Train Epoch: [8] [960000/1281167 (75%)]	Loss: 2.584556
[2022-06-07 18:49:24 | train] - Train Epoch: [8] [972800/1281167 (76%)]	Loss: 2.685021
[2022-06-07 18:49:45 | train] - Train Epoch: [8] [985600/1281167 (77%)]	Loss: 2.051848
[2022-06-07 18:50:08 | train] - Train Epoch: [8] [998400/1281167 (78%)]	Loss: 2.323617
[2022-06-07 18:50:30 | train] - Train Epoch: [8] [1011200/1281167 (79%)]	Loss: 2.525821
[2022-06-07 18:50:52 | train] - Train Epoch: [8] [1024000/1281167 (80%)]	Loss: 2.255111
[2022-06-07 18:51:14 | train] - Train Epoch: [8] [1036800/1281167 (81%)]	Loss: 3.018017
[2022-06-07 18:51:36 | train] - Train Epoch: [8] [1049600/1281167 (82%)]	Loss: 2.552762
[2022-06-07 18:51:58 | train] - Train Epoch: [8] [1062400/1281167 (83%)]	Loss: 2.467089
[2022-06-07 18:52:20 | train] - Train Epoch: [8] [1075200/1281167 (84%)]	Loss: 2.561869
[2022-06-07 18:52:42 | train] - Train Epoch: [8] [1088000/1281167 (85%)]	Loss: 2.458441
[2022-06-07 18:53:04 | train] - Train Epoch: [8] [1100800/1281167 (86%)]	Loss: 2.487180
[2022-06-07 18:53:26 | train] - Train Epoch: [8] [1113600/1281167 (87%)]	Loss: 2.314077
[2022-06-07 18:53:48 | train] - Train Epoch: [8] [1126400/1281167 (88%)]	Loss: 2.222374
[2022-06-07 18:54:10 | train] - Train Epoch: [8] [1139200/1281167 (89%)]	Loss: 2.549002
[2022-06-07 18:54:32 | train] - Train Epoch: [8] [1152000/1281167 (90%)]	Loss: 2.125961
[2022-06-07 18:54:54 | train] - Train Epoch: [8] [1164800/1281167 (91%)]	Loss: 2.174517
[2022-06-07 18:55:16 | train] - Train Epoch: [8] [1177600/1281167 (92%)]	Loss: 2.376531
[2022-06-07 18:55:38 | train] - Train Epoch: [8] [1190400/1281167 (93%)]	Loss: 2.484445
[2022-06-07 18:56:01 | train] - Train Epoch: [8] [1203200/1281167 (94%)]	Loss: 2.377872
[2022-06-07 18:56:23 | train] - Train Epoch: [8] [1216000/1281167 (95%)]	Loss: 2.187584
[2022-06-07 18:56:45 | train] - Train Epoch: [8] [1228800/1281167 (96%)]	Loss: 2.355486
[2022-06-07 18:57:08 | train] - Train Epoch: [8] [1241600/1281167 (97%)]	Loss: 2.519929
[2022-06-07 18:57:29 | train] - Train Epoch: [8] [1254400/1281167 (98%)]	Loss: 2.301175
[2022-06-07 18:57:51 | train] - Train Epoch: [8] [1267200/1281167 (99%)]	Loss: 2.380955
[2022-06-07 18:58:13 | train] - Train Epoch: [8] [1280000/1281167 (100%)]	Loss: 2.394219
[2022-06-07 18:58:15 | train] - Train Epoch: [8]	 Average Loss: 2.399995	 Total Acc : 47.2306	 Total Top5 Acc : 71.2974
[2022-06-07 18:58:15 | train] - -------8 epoch end-----------
========================================
-------8 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-07 18:59:51 | train] - 
Epoch [8] Test set: Average loss: 2.0224, Accuracy: 26582/50000 (53.1322%), Top-5 Accuracy: 77.7969%

[2022-06-07 18:59:51 | train] - save intermediate epoch [8] result


[2022-06-07 18:59:54 | train] - logging best performance 8 epoch
[2022-06-07 18:59:55 | train] - -------9 epoch start-----------
========================================
----- test end -------------------------


logging best performance 8 epoch
[2022-06-07 18:59:57 | train] - Train Epoch: [9] [0/1281167 (0%)]	Loss: 2.362694
[2022-06-07 19:00:19 | train] - Train Epoch: [9] [12800/1281167 (1%)]	Loss: 2.434580
Traceback (most recent call last):
  File "main.py", line 390, in <module>
    main()
  File "main.py", line 349, in main
    train_acc, train_top5_acc, train_loss = train(net, train_loader, optimizer, epoch, device, logger)
  File "main.py", line 55, in train
    for batch_idx, (data, target) in enumerate(train_loader):
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.8/site-packages/torch/_utils.py", line 438, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 84, in default_collate
    return [default_collate(samples) for samples in transposed]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 84, in <listcomp>
    return [default_collate(samples) for samples in transposed]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 54, in default_collate
    storage = elem.storage()._new_shared(numel)
  File "/opt/conda/lib/python3.8/site-packages/torch/storage.py", line 486, in _new_shared
    untyped_storage = module.UntypedStorage._new_shared(size * cls().element_size())
  File "/opt/conda/lib/python3.8/site-packages/torch/storage.py", line 173, in _new_shared
    return cls._new_using_fd(size)
RuntimeError: falseINTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/aten/src/ATen/MapAllocator.cpp":263, please report a bug to PyTorch. unable to open shared memory object </torch_832_98> in read-write mode

[2022-06-08 03:10:21 | train] - -------start logging -----------

[2022-06-08 03:10:21 | train] - -------end logging -----------

[2022-06-08 03:10:21 | train] - -------10 epoch start-----------
/data/kjh/save_fix_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
load log path /data/kjh/save_fix_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/
load pretrained model : epoch 10
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_fix_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
[2022-06-08 03:10:24 | train] - Train Epoch: [10] [0/1281167 (0%)]	Loss: 2.042243
[2022-06-08 03:10:48 | train] - Train Epoch: [10] [12800/1281167 (1%)]	Loss: 2.141354
[2022-06-08 03:11:12 | train] - Train Epoch: [10] [25600/1281167 (2%)]	Loss: 1.860478
[2022-06-08 03:11:37 | train] - Train Epoch: [10] [38400/1281167 (3%)]	Loss: 1.819035
[2022-06-08 03:12:02 | train] - Train Epoch: [10] [51200/1281167 (4%)]	Loss: 1.711947
[2022-06-08 03:12:27 | train] - Train Epoch: [10] [64000/1281167 (5%)]	Loss: 2.024759
[2022-06-08 03:12:53 | train] - Train Epoch: [10] [76800/1281167 (6%)]	Loss: 2.209947
[2022-06-08 03:13:17 | train] - Train Epoch: [10] [89600/1281167 (7%)]	Loss: 1.977053
[2022-06-08 03:13:42 | train] - Train Epoch: [10] [102400/1281167 (8%)]	Loss: 2.134609
[2022-06-08 03:14:05 | train] - Train Epoch: [10] [115200/1281167 (9%)]	Loss: 2.143683
[2022-06-08 03:14:29 | train] - Train Epoch: [10] [128000/1281167 (10%)]	Loss: 2.025681
[2022-06-08 03:14:52 | train] - Train Epoch: [10] [140800/1281167 (11%)]	Loss: 2.268117
[2022-06-08 03:15:17 | train] - Train Epoch: [10] [153600/1281167 (12%)]	Loss: 2.120395
[2022-06-08 03:15:41 | train] - Train Epoch: [10] [166400/1281167 (13%)]	Loss: 2.037008
[2022-06-08 03:16:04 | train] - Train Epoch: [10] [179200/1281167 (14%)]	Loss: 2.268838
[2022-06-08 03:16:29 | train] - Train Epoch: [10] [192000/1281167 (15%)]	Loss: 2.052109
[2022-06-08 03:16:54 | train] - Train Epoch: [10] [204800/1281167 (16%)]	Loss: 1.889311
[2022-06-08 03:17:21 | train] - Train Epoch: [10] [217600/1281167 (17%)]	Loss: 2.218327
[2022-06-08 03:17:48 | train] - Train Epoch: [10] [230400/1281167 (18%)]	Loss: 2.069377
[2022-06-08 03:18:15 | train] - Train Epoch: [10] [243200/1281167 (19%)]	Loss: 2.185972
[2022-06-08 03:18:41 | train] - Train Epoch: [10] [256000/1281167 (20%)]	Loss: 2.153997
[2022-06-08 03:19:07 | train] - Train Epoch: [10] [268800/1281167 (21%)]	Loss: 2.447727
[2022-06-08 03:19:32 | train] - Train Epoch: [10] [281600/1281167 (22%)]	Loss: 1.882064
[2022-06-08 03:19:59 | train] - Train Epoch: [10] [294400/1281167 (23%)]	Loss: 1.693018
[2022-06-08 03:20:26 | train] - Train Epoch: [10] [307200/1281167 (24%)]	Loss: 1.685130
[2022-06-08 03:20:51 | train] - Train Epoch: [10] [320000/1281167 (25%)]	Loss: 2.263622
[2022-06-08 03:21:17 | train] - Train Epoch: [10] [332800/1281167 (26%)]	Loss: 1.848523
[2022-06-08 03:21:47 | train] - Train Epoch: [10] [345600/1281167 (27%)]	Loss: 2.326190
[2022-06-08 03:22:13 | train] - Train Epoch: [10] [358400/1281167 (28%)]	Loss: 2.075045
[2022-06-08 03:22:39 | train] - Train Epoch: [10] [371200/1281167 (29%)]	Loss: 1.906288
[2022-06-08 03:23:07 | train] - Train Epoch: [10] [384000/1281167 (30%)]	Loss: 1.939115
[2022-06-08 03:23:34 | train] - Train Epoch: [10] [396800/1281167 (31%)]	Loss: 1.759686
[2022-06-08 03:24:02 | train] - Train Epoch: [10] [409600/1281167 (32%)]	Loss: 2.455663
[2022-06-08 03:24:28 | train] - Train Epoch: [10] [422400/1281167 (33%)]	Loss: 1.937260
[2022-06-08 03:24:57 | train] - Train Epoch: [10] [435200/1281167 (34%)]	Loss: 1.975672
[2022-06-08 03:25:25 | train] - Train Epoch: [10] [448000/1281167 (35%)]	Loss: 1.725246
[2022-06-08 03:25:52 | train] - Train Epoch: [10] [460800/1281167 (36%)]	Loss: 1.996650
[2022-06-08 03:26:19 | train] - Train Epoch: [10] [473600/1281167 (37%)]	Loss: 1.970847
[2022-06-08 03:26:48 | train] - Train Epoch: [10] [486400/1281167 (38%)]	Loss: 1.956221
[2022-06-08 03:27:15 | train] - Train Epoch: [10] [499200/1281167 (39%)]	Loss: 1.760799
[2022-06-08 03:27:43 | train] - Train Epoch: [10] [512000/1281167 (40%)]	Loss: 1.921788
[2022-06-08 03:28:10 | train] - Train Epoch: [10] [524800/1281167 (41%)]	Loss: 2.068348
[2022-06-08 03:28:38 | train] - Train Epoch: [10] [537600/1281167 (42%)]	Loss: 1.817319
[2022-06-08 03:29:06 | train] - Train Epoch: [10] [550400/1281167 (43%)]	Loss: 1.772241
[2022-06-08 03:29:35 | train] - Train Epoch: [10] [563200/1281167 (44%)]	Loss: 1.861827
[2022-06-08 03:30:02 | train] - Train Epoch: [10] [576000/1281167 (45%)]	Loss: 1.886544
[2022-06-08 03:30:30 | train] - Train Epoch: [10] [588800/1281167 (46%)]	Loss: 2.250956
[2022-06-08 03:30:58 | train] - Train Epoch: [10] [601600/1281167 (47%)]	Loss: 2.135151
[2022-06-08 03:31:25 | train] - Train Epoch: [10] [614400/1281167 (48%)]	Loss: 1.643680
[2022-06-08 03:31:53 | train] - Train Epoch: [10] [627200/1281167 (49%)]	Loss: 1.902355
[2022-06-08 03:32:21 | train] - Train Epoch: [10] [640000/1281167 (50%)]	Loss: 1.978604
[2022-06-08 03:32:49 | train] - Train Epoch: [10] [652800/1281167 (51%)]	Loss: 1.976681
[2022-06-08 03:33:17 | train] - Train Epoch: [10] [665600/1281167 (52%)]	Loss: 2.162828
[2022-06-08 03:33:45 | train] - Train Epoch: [10] [678400/1281167 (53%)]	Loss: 1.865100
[2022-06-08 03:34:12 | train] - Train Epoch: [10] [691200/1281167 (54%)]	Loss: 1.860084
[2022-06-08 03:34:40 | train] - Train Epoch: [10] [704000/1281167 (55%)]	Loss: 2.309577
[2022-06-08 03:35:08 | train] - Train Epoch: [10] [716800/1281167 (56%)]	Loss: 1.900495
[2022-06-08 03:35:34 | train] - Train Epoch: [10] [729600/1281167 (57%)]	Loss: 1.509311
[2022-06-08 03:36:01 | train] - Train Epoch: [10] [742400/1281167 (58%)]	Loss: 2.163202
[2022-06-08 03:36:29 | train] - Train Epoch: [10] [755200/1281167 (59%)]	Loss: 2.236228
[2022-06-08 03:36:56 | train] - Train Epoch: [10] [768000/1281167 (60%)]	Loss: 1.986968
[2022-06-08 03:37:25 | train] - Train Epoch: [10] [780800/1281167 (61%)]	Loss: 1.617976
[2022-06-08 03:37:54 | train] - Train Epoch: [10] [793600/1281167 (62%)]	Loss: 1.921726
[2022-06-08 03:38:22 | train] - Train Epoch: [10] [806400/1281167 (63%)]	Loss: 1.908488
[2022-06-08 03:38:51 | train] - Train Epoch: [10] [819200/1281167 (64%)]	Loss: 1.841183
[2022-06-08 03:39:19 | train] - Train Epoch: [10] [832000/1281167 (65%)]	Loss: 2.141299
[2022-06-08 03:39:46 | train] - Train Epoch: [10] [844800/1281167 (66%)]	Loss: 1.895603
[2022-06-08 03:40:15 | train] - Train Epoch: [10] [857600/1281167 (67%)]	Loss: 1.963336
[2022-06-08 03:40:42 | train] - Train Epoch: [10] [870400/1281167 (68%)]	Loss: 1.705373
[2022-06-08 03:41:11 | train] - Train Epoch: [10] [883200/1281167 (69%)]	Loss: 1.982080
[2022-06-08 03:41:39 | train] - Train Epoch: [10] [896000/1281167 (70%)]	Loss: 1.957757
[2022-06-08 03:42:07 | train] - Train Epoch: [10] [908800/1281167 (71%)]	Loss: 1.921458
[2022-06-08 03:42:37 | train] - Train Epoch: [10] [921600/1281167 (72%)]	Loss: 2.374583
[2022-06-08 03:43:06 | train] - Train Epoch: [10] [934400/1281167 (73%)]	Loss: 1.808212
[2022-06-08 03:43:35 | train] - Train Epoch: [10] [947200/1281167 (74%)]	Loss: 1.975698
[2022-06-08 03:44:02 | train] - Train Epoch: [10] [960000/1281167 (75%)]	Loss: 2.037907
[2022-06-08 03:44:31 | train] - Train Epoch: [10] [972800/1281167 (76%)]	Loss: 2.141943
[2022-06-08 03:45:00 | train] - Train Epoch: [10] [985600/1281167 (77%)]	Loss: 2.027923
[2022-06-08 03:45:28 | train] - Train Epoch: [10] [998400/1281167 (78%)]	Loss: 1.937186
[2022-06-08 03:45:56 | train] - Train Epoch: [10] [1011200/1281167 (79%)]	Loss: 1.932243
[2022-06-08 03:46:25 | train] - Train Epoch: [10] [1024000/1281167 (80%)]	Loss: 1.913095
[2022-06-08 03:46:53 | train] - Train Epoch: [10] [1036800/1281167 (81%)]	Loss: 2.126398
[2022-06-08 03:47:19 | train] - Train Epoch: [10] [1049600/1281167 (82%)]	Loss: 2.310741
[2022-06-08 03:47:39 | train] - Train Epoch: [10] [1062400/1281167 (83%)]	Loss: 1.900500
[2022-06-08 03:47:59 | train] - Train Epoch: [10] [1075200/1281167 (84%)]	Loss: 2.428125
[2022-06-08 03:48:19 | train] - Train Epoch: [10] [1088000/1281167 (85%)]	Loss: 1.527014
[2022-06-08 03:48:40 | train] - Train Epoch: [10] [1100800/1281167 (86%)]	Loss: 2.001863
[2022-06-08 03:49:00 | train] - Train Epoch: [10] [1113600/1281167 (87%)]	Loss: 1.706062
[2022-06-08 03:49:21 | train] - Train Epoch: [10] [1126400/1281167 (88%)]	Loss: 1.863952
[2022-06-08 03:49:42 | train] - Train Epoch: [10] [1139200/1281167 (89%)]	Loss: 2.246631
[2022-06-08 03:50:02 | train] - Train Epoch: [10] [1152000/1281167 (90%)]	Loss: 2.255794
[2022-06-08 03:50:23 | train] - Train Epoch: [10] [1164800/1281167 (91%)]	Loss: 2.242029
[2022-06-08 03:50:43 | train] - Train Epoch: [10] [1177600/1281167 (92%)]	Loss: 2.611348
[2022-06-08 03:51:04 | train] - Train Epoch: [10] [1190400/1281167 (93%)]	Loss: 2.061481
[2022-06-08 03:51:25 | train] - Train Epoch: [10] [1203200/1281167 (94%)]	Loss: 2.066566
[2022-06-08 03:51:46 | train] - Train Epoch: [10] [1216000/1281167 (95%)]	Loss: 1.880338
[2022-06-08 03:52:06 | train] - Train Epoch: [10] [1228800/1281167 (96%)]	Loss: 1.803014
[2022-06-08 03:52:27 | train] - Train Epoch: [10] [1241600/1281167 (97%)]	Loss: 2.153260
[2022-06-08 03:52:48 | train] - Train Epoch: [10] [1254400/1281167 (98%)]	Loss: 1.703936
[2022-06-08 03:53:10 | train] - Train Epoch: [10] [1267200/1281167 (99%)]	Loss: 2.236974
[2022-06-08 03:53:29 | train] - Train Epoch: [10] [1280000/1281167 (100%)]	Loss: 1.978915
[2022-06-08 03:53:31 | train] - Train Epoch: [10]	 Average Loss: 2.027444	 Total Acc : 54.2063	 Total Top5 Acc : 76.9561
[2022-06-08 03:53:31 | train] - -------10 epoch end-----------
========================================
-------10 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 03:55:04 | train] - 
Epoch [10] Test set: Average loss: 1.9487, Accuracy: 27403/50000 (54.7702%), Top-5 Accuracy: 79.1272%

[2022-06-08 03:55:04 | train] - save intermediate epoch [10] result


[2022-06-08 03:55:05 | train] - logging best performance 10 epoch
[2022-06-08 03:55:06 | train] - -------11 epoch start-----------
========================================
----- test end -------------------------


logging best performance 10 epoch
[2022-06-08 03:55:08 | train] - Train Epoch: [11] [0/1281167 (0%)]	Loss: 2.331740
[2022-06-08 03:55:28 | train] - Train Epoch: [11] [12800/1281167 (1%)]	Loss: 2.039801
[2022-06-08 03:55:48 | train] - Train Epoch: [11] [25600/1281167 (2%)]	Loss: 2.329550
[2022-06-08 03:56:08 | train] - Train Epoch: [11] [38400/1281167 (3%)]	Loss: 1.911123
[2022-06-08 03:56:29 | train] - Train Epoch: [11] [51200/1281167 (4%)]	Loss: 2.086304
[2022-06-08 03:56:49 | train] - Train Epoch: [11] [64000/1281167 (5%)]	Loss: 2.293443
[2022-06-08 03:57:10 | train] - Train Epoch: [11] [76800/1281167 (6%)]	Loss: 2.001710
[2022-06-08 03:57:29 | train] - Train Epoch: [11] [89600/1281167 (7%)]	Loss: 2.053684
[2022-06-08 03:57:50 | train] - Train Epoch: [11] [102400/1281167 (8%)]	Loss: 2.241762
[2022-06-08 03:58:10 | train] - Train Epoch: [11] [115200/1281167 (9%)]	Loss: 1.782686
[2022-06-08 03:58:30 | train] - Train Epoch: [11] [128000/1281167 (10%)]	Loss: 2.001726
[2022-06-08 03:58:51 | train] - Train Epoch: [11] [140800/1281167 (11%)]	Loss: 2.087401
[2022-06-08 03:59:11 | train] - Train Epoch: [11] [153600/1281167 (12%)]	Loss: 2.082101
[2022-06-08 03:59:31 | train] - Train Epoch: [11] [166400/1281167 (13%)]	Loss: 2.666913
[2022-06-08 03:59:51 | train] - Train Epoch: [11] [179200/1281167 (14%)]	Loss: 2.431480
[2022-06-08 04:00:12 | train] - Train Epoch: [11] [192000/1281167 (15%)]	Loss: 2.062929
[2022-06-08 04:00:32 | train] - Train Epoch: [11] [204800/1281167 (16%)]	Loss: 1.903716
[2022-06-08 04:00:53 | train] - Train Epoch: [11] [217600/1281167 (17%)]	Loss: 2.058879
[2022-06-08 04:01:13 | train] - Train Epoch: [11] [230400/1281167 (18%)]	Loss: 2.132063
[2022-06-08 04:01:33 | train] - Train Epoch: [11] [243200/1281167 (19%)]	Loss: 2.265707
[2022-06-08 04:01:54 | train] - Train Epoch: [11] [256000/1281167 (20%)]	Loss: 2.095253
[2022-06-08 04:02:14 | train] - Train Epoch: [11] [268800/1281167 (21%)]	Loss: 2.014547
[2022-06-08 04:02:35 | train] - Train Epoch: [11] [281600/1281167 (22%)]	Loss: 2.279750
[2022-06-08 04:02:55 | train] - Train Epoch: [11] [294400/1281167 (23%)]	Loss: 2.104378
[2022-06-08 04:03:16 | train] - Train Epoch: [11] [307200/1281167 (24%)]	Loss: 2.331440
[2022-06-08 04:03:36 | train] - Train Epoch: [11] [320000/1281167 (25%)]	Loss: 2.520868
[2022-06-08 04:03:57 | train] - Train Epoch: [11] [332800/1281167 (26%)]	Loss: 2.361045
[2022-06-08 04:04:18 | train] - Train Epoch: [11] [345600/1281167 (27%)]	Loss: 2.245372
[2022-06-08 04:04:39 | train] - Train Epoch: [11] [358400/1281167 (28%)]	Loss: 2.308501
[2022-06-08 04:05:00 | train] - Train Epoch: [11] [371200/1281167 (29%)]	Loss: 2.258565
[2022-06-08 04:05:21 | train] - Train Epoch: [11] [384000/1281167 (30%)]	Loss: 2.529750
[2022-06-08 04:05:41 | train] - Train Epoch: [11] [396800/1281167 (31%)]	Loss: 2.150546
[2022-06-08 04:06:02 | train] - Train Epoch: [11] [409600/1281167 (32%)]	Loss: 1.983369
[2022-06-08 04:06:22 | train] - Train Epoch: [11] [422400/1281167 (33%)]	Loss: 2.150041
[2022-06-08 04:06:43 | train] - Train Epoch: [11] [435200/1281167 (34%)]	Loss: 2.292639
[2022-06-08 04:07:03 | train] - Train Epoch: [11] [448000/1281167 (35%)]	Loss: 2.420207
[2022-06-08 04:07:23 | train] - Train Epoch: [11] [460800/1281167 (36%)]	Loss: 1.912262
[2022-06-08 04:07:43 | train] - Train Epoch: [11] [473600/1281167 (37%)]	Loss: 2.080389
[2022-06-08 04:08:03 | train] - Train Epoch: [11] [486400/1281167 (38%)]	Loss: 2.101270
[2022-06-08 04:08:24 | train] - Train Epoch: [11] [499200/1281167 (39%)]	Loss: 2.378277
[2022-06-08 04:08:45 | train] - Train Epoch: [11] [512000/1281167 (40%)]	Loss: 2.065563
[2022-06-08 04:09:05 | train] - Train Epoch: [11] [524800/1281167 (41%)]	Loss: 1.985556
[2022-06-08 04:09:25 | train] - Train Epoch: [11] [537600/1281167 (42%)]	Loss: 2.307956
[2022-06-08 04:09:45 | train] - Train Epoch: [11] [550400/1281167 (43%)]	Loss: 2.298995
[2022-06-08 04:10:05 | train] - Train Epoch: [11] [563200/1281167 (44%)]	Loss: 2.038620
[2022-06-08 04:10:26 | train] - Train Epoch: [11] [576000/1281167 (45%)]	Loss: 2.326083
[2022-06-08 04:10:47 | train] - Train Epoch: [11] [588800/1281167 (46%)]	Loss: 2.030746
[2022-06-08 04:11:07 | train] - Train Epoch: [11] [601600/1281167 (47%)]	Loss: 2.114016
[2022-06-08 04:11:27 | train] - Train Epoch: [11] [614400/1281167 (48%)]	Loss: 2.271919
[2022-06-08 04:11:47 | train] - Train Epoch: [11] [627200/1281167 (49%)]	Loss: 2.149446
[2022-06-08 04:12:07 | train] - Train Epoch: [11] [640000/1281167 (50%)]	Loss: 1.828936
[2022-06-08 04:12:28 | train] - Train Epoch: [11] [652800/1281167 (51%)]	Loss: 2.078437
[2022-06-08 04:12:48 | train] - Train Epoch: [11] [665600/1281167 (52%)]	Loss: 2.322811
[2022-06-08 04:13:09 | train] - Train Epoch: [11] [678400/1281167 (53%)]	Loss: 2.294571
[2022-06-08 04:13:29 | train] - Train Epoch: [11] [691200/1281167 (54%)]	Loss: 2.421290
[2022-06-08 04:13:50 | train] - Train Epoch: [11] [704000/1281167 (55%)]	Loss: 2.059168
[2022-06-08 04:14:10 | train] - Train Epoch: [11] [716800/1281167 (56%)]	Loss: 1.938333
[2022-06-08 04:14:30 | train] - Train Epoch: [11] [729600/1281167 (57%)]	Loss: 1.867309
[2022-06-08 04:14:50 | train] - Train Epoch: [11] [742400/1281167 (58%)]	Loss: 2.542420
[2022-06-08 04:15:10 | train] - Train Epoch: [11] [755200/1281167 (59%)]	Loss: 2.180372
[2022-06-08 04:15:30 | train] - Train Epoch: [11] [768000/1281167 (60%)]	Loss: 2.032252
[2022-06-08 04:15:51 | train] - Train Epoch: [11] [780800/1281167 (61%)]	Loss: 2.001029
[2022-06-08 04:16:11 | train] - Train Epoch: [11] [793600/1281167 (62%)]	Loss: 2.366841
[2022-06-08 04:16:31 | train] - Train Epoch: [11] [806400/1281167 (63%)]	Loss: 2.322146
[2022-06-08 04:16:51 | train] - Train Epoch: [11] [819200/1281167 (64%)]	Loss: 1.776310
[2022-06-08 04:17:11 | train] - Train Epoch: [11] [832000/1281167 (65%)]	Loss: 2.000883
[2022-06-08 04:17:31 | train] - Train Epoch: [11] [844800/1281167 (66%)]	Loss: 2.134810
[2022-06-08 04:17:52 | train] - Train Epoch: [11] [857600/1281167 (67%)]	Loss: 2.065040
[2022-06-08 04:18:12 | train] - Train Epoch: [11] [870400/1281167 (68%)]	Loss: 2.229752
[2022-06-08 04:18:32 | train] - Train Epoch: [11] [883200/1281167 (69%)]	Loss: 1.702366
[2022-06-08 04:18:52 | train] - Train Epoch: [11] [896000/1281167 (70%)]	Loss: 2.711015
[2022-06-08 04:19:12 | train] - Train Epoch: [11] [908800/1281167 (71%)]	Loss: 1.985119
[2022-06-08 04:19:32 | train] - Train Epoch: [11] [921600/1281167 (72%)]	Loss: 1.934804
[2022-06-08 04:19:52 | train] - Train Epoch: [11] [934400/1281167 (73%)]	Loss: 2.288697
[2022-06-08 04:20:12 | train] - Train Epoch: [11] [947200/1281167 (74%)]	Loss: 1.861878
[2022-06-08 04:20:32 | train] - Train Epoch: [11] [960000/1281167 (75%)]	Loss: 2.396050
[2022-06-08 04:20:52 | train] - Train Epoch: [11] [972800/1281167 (76%)]	Loss: 2.274985
[2022-06-08 04:21:12 | train] - Train Epoch: [11] [985600/1281167 (77%)]	Loss: 2.321739
[2022-06-08 04:21:32 | train] - Train Epoch: [11] [998400/1281167 (78%)]	Loss: 2.301979
[2022-06-08 04:21:52 | train] - Train Epoch: [11] [1011200/1281167 (79%)]	Loss: 1.840042
[2022-06-08 04:22:13 | train] - Train Epoch: [11] [1024000/1281167 (80%)]	Loss: 2.270960
[2022-06-08 04:22:33 | train] - Train Epoch: [11] [1036800/1281167 (81%)]	Loss: 2.516605
[2022-06-08 04:22:53 | train] - Train Epoch: [11] [1049600/1281167 (82%)]	Loss: 2.128748
[2022-06-08 04:23:13 | train] - Train Epoch: [11] [1062400/1281167 (83%)]	Loss: 2.060921
[2022-06-08 04:23:34 | train] - Train Epoch: [11] [1075200/1281167 (84%)]	Loss: 2.342511
[2022-06-08 04:23:54 | train] - Train Epoch: [11] [1088000/1281167 (85%)]	Loss: 1.771513
[2022-06-08 04:24:14 | train] - Train Epoch: [11] [1100800/1281167 (86%)]	Loss: 2.320668
[2022-06-08 04:24:35 | train] - Train Epoch: [11] [1113600/1281167 (87%)]	Loss: 2.376704
[2022-06-08 04:24:55 | train] - Train Epoch: [11] [1126400/1281167 (88%)]	Loss: 1.977821
[2022-06-08 04:25:15 | train] - Train Epoch: [11] [1139200/1281167 (89%)]	Loss: 2.000906
[2022-06-08 04:25:35 | train] - Train Epoch: [11] [1152000/1281167 (90%)]	Loss: 2.122547
[2022-06-08 04:25:55 | train] - Train Epoch: [11] [1164800/1281167 (91%)]	Loss: 1.807359
[2022-06-08 04:26:16 | train] - Train Epoch: [11] [1177600/1281167 (92%)]	Loss: 1.980027
[2022-06-08 04:26:37 | train] - Train Epoch: [11] [1190400/1281167 (93%)]	Loss: 2.106138
[2022-06-08 04:26:57 | train] - Train Epoch: [11] [1203200/1281167 (94%)]	Loss: 1.912541
[2022-06-08 04:27:17 | train] - Train Epoch: [11] [1216000/1281167 (95%)]	Loss: 2.192498
[2022-06-08 04:27:37 | train] - Train Epoch: [11] [1228800/1281167 (96%)]	Loss: 2.004085
[2022-06-08 04:27:57 | train] - Train Epoch: [11] [1241600/1281167 (97%)]	Loss: 2.131028
[2022-06-08 04:28:18 | train] - Train Epoch: [11] [1254400/1281167 (98%)]	Loss: 2.112015
[2022-06-08 04:28:38 | train] - Train Epoch: [11] [1267200/1281167 (99%)]	Loss: 2.144606
[2022-06-08 04:28:59 | train] - Train Epoch: [11] [1280000/1281167 (100%)]	Loss: 2.084502
[2022-06-08 04:29:01 | train] - Train Epoch: [11]	 Average Loss: 2.164344	 Total Acc : 51.5908	 Total Top5 Acc : 74.9698
[2022-06-08 04:29:01 | train] - -------11 epoch end-----------
========================================
-------11 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 04:30:32 | train] - 
Epoch [11] Test set: Average loss: 1.8727, Accuracy: 28238/50000 (56.4578%), Top-5 Accuracy: 79.9285%

[2022-06-08 04:30:32 | train] - save intermediate epoch [11] result


[2022-06-08 04:30:33 | train] - logging best performance 11 epoch
[2022-06-08 04:30:35 | train] - -------12 epoch start-----------
========================================
----- test end -------------------------


logging best performance 11 epoch
[2022-06-08 04:30:36 | train] - Train Epoch: [12] [0/1281167 (0%)]	Loss: 2.017002
[2022-06-08 04:30:56 | train] - Train Epoch: [12] [12800/1281167 (1%)]	Loss: 2.143799
[2022-06-08 04:31:16 | train] - Train Epoch: [12] [25600/1281167 (2%)]	Loss: 2.211183
[2022-06-08 04:31:35 | train] - Train Epoch: [12] [38400/1281167 (3%)]	Loss: 1.702408
[2022-06-08 04:31:55 | train] - Train Epoch: [12] [51200/1281167 (4%)]	Loss: 1.691298
[2022-06-08 04:32:15 | train] - Train Epoch: [12] [64000/1281167 (5%)]	Loss: 1.929177
[2022-06-08 04:32:34 | train] - Train Epoch: [12] [76800/1281167 (6%)]	Loss: 2.218263
[2022-06-08 04:32:54 | train] - Train Epoch: [12] [89600/1281167 (7%)]	Loss: 2.550043
[2022-06-08 04:33:14 | train] - Train Epoch: [12] [102400/1281167 (8%)]	Loss: 2.108159
[2022-06-08 04:33:34 | train] - Train Epoch: [12] [115200/1281167 (9%)]	Loss: 2.043339
[2022-06-08 04:33:53 | train] - Train Epoch: [12] [128000/1281167 (10%)]	Loss: 1.861656
[2022-06-08 04:34:13 | train] - Train Epoch: [12] [140800/1281167 (11%)]	Loss: 2.252251
[2022-06-08 04:34:34 | train] - Train Epoch: [12] [153600/1281167 (12%)]	Loss: 2.288104
[2022-06-08 04:34:53 | train] - Train Epoch: [12] [166400/1281167 (13%)]	Loss: 2.203997
[2022-06-08 04:35:13 | train] - Train Epoch: [12] [179200/1281167 (14%)]	Loss: 2.089952
[2022-06-08 04:35:32 | train] - Train Epoch: [12] [192000/1281167 (15%)]	Loss: 1.984291
[2022-06-08 04:35:51 | train] - Train Epoch: [12] [204800/1281167 (16%)]	Loss: 1.657989
[2022-06-08 04:36:11 | train] - Train Epoch: [12] [217600/1281167 (17%)]	Loss: 2.033710
[2022-06-08 04:36:30 | train] - Train Epoch: [12] [230400/1281167 (18%)]	Loss: 2.222921
[2022-06-08 04:36:50 | train] - Train Epoch: [12] [243200/1281167 (19%)]	Loss: 2.061307
[2022-06-08 04:37:10 | train] - Train Epoch: [12] [256000/1281167 (20%)]	Loss: 1.971032
[2022-06-08 04:37:30 | train] - Train Epoch: [12] [268800/1281167 (21%)]	Loss: 2.194107
[2022-06-08 04:37:50 | train] - Train Epoch: [12] [281600/1281167 (22%)]	Loss: 1.898014
[2022-06-08 04:38:09 | train] - Train Epoch: [12] [294400/1281167 (23%)]	Loss: 1.793104
[2022-06-08 04:38:29 | train] - Train Epoch: [12] [307200/1281167 (24%)]	Loss: 2.098047
[2022-06-08 04:38:49 | train] - Train Epoch: [12] [320000/1281167 (25%)]	Loss: 2.061317
[2022-06-08 04:39:09 | train] - Train Epoch: [12] [332800/1281167 (26%)]	Loss: 1.953098
[2022-06-08 04:39:28 | train] - Train Epoch: [12] [345600/1281167 (27%)]	Loss: 2.139558
[2022-06-08 04:39:48 | train] - Train Epoch: [12] [358400/1281167 (28%)]	Loss: 2.488113
[2022-06-08 04:40:08 | train] - Train Epoch: [12] [371200/1281167 (29%)]	Loss: 2.110638
[2022-06-08 04:40:27 | train] - Train Epoch: [12] [384000/1281167 (30%)]	Loss: 2.031028
[2022-06-08 04:40:48 | train] - Train Epoch: [12] [396800/1281167 (31%)]	Loss: 2.139970
[2022-06-08 04:41:08 | train] - Train Epoch: [12] [409600/1281167 (32%)]	Loss: 1.946303
[2022-06-08 04:41:28 | train] - Train Epoch: [12] [422400/1281167 (33%)]	Loss: 2.014849
[2022-06-08 04:41:48 | train] - Train Epoch: [12] [435200/1281167 (34%)]	Loss: 1.953868
[2022-06-08 04:42:08 | train] - Train Epoch: [12] [448000/1281167 (35%)]	Loss: 2.234968
[2022-06-08 04:42:28 | train] - Train Epoch: [12] [460800/1281167 (36%)]	Loss: 2.092794
[2022-06-08 04:42:48 | train] - Train Epoch: [12] [473600/1281167 (37%)]	Loss: 2.102257
[2022-06-08 04:43:08 | train] - Train Epoch: [12] [486400/1281167 (38%)]	Loss: 1.910455
[2022-06-08 04:43:28 | train] - Train Epoch: [12] [499200/1281167 (39%)]	Loss: 1.934126
[2022-06-08 04:43:47 | train] - Train Epoch: [12] [512000/1281167 (40%)]	Loss: 2.181942
[2022-06-08 04:44:07 | train] - Train Epoch: [12] [524800/1281167 (41%)]	Loss: 2.165138
[2022-06-08 04:44:26 | train] - Train Epoch: [12] [537600/1281167 (42%)]	Loss: 1.765037
[2022-06-08 04:44:46 | train] - Train Epoch: [12] [550400/1281167 (43%)]	Loss: 1.775452
[2022-06-08 04:45:06 | train] - Train Epoch: [12] [563200/1281167 (44%)]	Loss: 2.312458
[2022-06-08 04:45:26 | train] - Train Epoch: [12] [576000/1281167 (45%)]	Loss: 1.919052
[2022-06-08 04:45:45 | train] - Train Epoch: [12] [588800/1281167 (46%)]	Loss: 1.832846
[2022-06-08 04:46:05 | train] - Train Epoch: [12] [601600/1281167 (47%)]	Loss: 1.978185
[2022-06-08 04:46:24 | train] - Train Epoch: [12] [614400/1281167 (48%)]	Loss: 2.432730
[2022-06-08 04:46:44 | train] - Train Epoch: [12] [627200/1281167 (49%)]	Loss: 1.980278
[2022-06-08 04:47:04 | train] - Train Epoch: [12] [640000/1281167 (50%)]	Loss: 2.061991
[2022-06-08 04:47:24 | train] - Train Epoch: [12] [652800/1281167 (51%)]	Loss: 1.923290
[2022-06-08 04:47:44 | train] - Train Epoch: [12] [665600/1281167 (52%)]	Loss: 1.886503
[2022-06-08 04:48:03 | train] - Train Epoch: [12] [678400/1281167 (53%)]	Loss: 2.106165
[2022-06-08 04:48:23 | train] - Train Epoch: [12] [691200/1281167 (54%)]	Loss: 1.921318
[2022-06-08 04:48:42 | train] - Train Epoch: [12] [704000/1281167 (55%)]	Loss: 2.251653
[2022-06-08 04:49:02 | train] - Train Epoch: [12] [716800/1281167 (56%)]	Loss: 2.474554
[2022-06-08 04:49:21 | train] - Train Epoch: [12] [729600/1281167 (57%)]	Loss: 1.942605
[2022-06-08 04:49:41 | train] - Train Epoch: [12] [742400/1281167 (58%)]	Loss: 2.008446
[2022-06-08 04:50:00 | train] - Train Epoch: [12] [755200/1281167 (59%)]	Loss: 2.136937
[2022-06-08 04:50:19 | train] - Train Epoch: [12] [768000/1281167 (60%)]	Loss: 2.010279
[2022-06-08 04:50:39 | train] - Train Epoch: [12] [780800/1281167 (61%)]	Loss: 1.857399
[2022-06-08 04:50:59 | train] - Train Epoch: [12] [793600/1281167 (62%)]	Loss: 1.833999
[2022-06-08 04:51:18 | train] - Train Epoch: [12] [806400/1281167 (63%)]	Loss: 2.124413
[2022-06-08 04:51:38 | train] - Train Epoch: [12] [819200/1281167 (64%)]	Loss: 1.907941
[2022-06-08 04:51:57 | train] - Train Epoch: [12] [832000/1281167 (65%)]	Loss: 2.256054
[2022-06-08 04:52:17 | train] - Train Epoch: [12] [844800/1281167 (66%)]	Loss: 1.968295
[2022-06-08 04:52:36 | train] - Train Epoch: [12] [857600/1281167 (67%)]	Loss: 2.167235
[2022-06-08 04:52:56 | train] - Train Epoch: [12] [870400/1281167 (68%)]	Loss: 2.076295
[2022-06-08 04:53:16 | train] - Train Epoch: [12] [883200/1281167 (69%)]	Loss: 1.985647
[2022-06-08 04:53:36 | train] - Train Epoch: [12] [896000/1281167 (70%)]	Loss: 2.088653
[2022-06-08 04:53:57 | train] - Train Epoch: [12] [908800/1281167 (71%)]	Loss: 2.087610
[2022-06-08 04:54:16 | train] - Train Epoch: [12] [921600/1281167 (72%)]	Loss: 2.152345
[2022-06-08 04:54:36 | train] - Train Epoch: [12] [934400/1281167 (73%)]	Loss: 2.004894
[2022-06-08 04:54:56 | train] - Train Epoch: [12] [947200/1281167 (74%)]	Loss: 2.328285
[2022-06-08 04:55:16 | train] - Train Epoch: [12] [960000/1281167 (75%)]	Loss: 1.967593
[2022-06-08 04:55:35 | train] - Train Epoch: [12] [972800/1281167 (76%)]	Loss: 2.086757
[2022-06-08 04:55:55 | train] - Train Epoch: [12] [985600/1281167 (77%)]	Loss: 2.052268
[2022-06-08 04:56:14 | train] - Train Epoch: [12] [998400/1281167 (78%)]	Loss: 1.920943
[2022-06-08 04:56:34 | train] - Train Epoch: [12] [1011200/1281167 (79%)]	Loss: 1.871232
[2022-06-08 04:56:53 | train] - Train Epoch: [12] [1024000/1281167 (80%)]	Loss: 2.087582
[2022-06-08 04:57:12 | train] - Train Epoch: [12] [1036800/1281167 (81%)]	Loss: 2.131555
[2022-06-08 04:57:32 | train] - Train Epoch: [12] [1049600/1281167 (82%)]	Loss: 2.326735
[2022-06-08 04:57:53 | train] - Train Epoch: [12] [1062400/1281167 (83%)]	Loss: 2.044771
[2022-06-08 04:58:12 | train] - Train Epoch: [12] [1075200/1281167 (84%)]	Loss: 2.045874
[2022-06-08 04:58:31 | train] - Train Epoch: [12] [1088000/1281167 (85%)]	Loss: 2.005904
[2022-06-08 04:58:51 | train] - Train Epoch: [12] [1100800/1281167 (86%)]	Loss: 1.863587
[2022-06-08 04:59:11 | train] - Train Epoch: [12] [1113600/1281167 (87%)]	Loss: 2.104171
[2022-06-08 04:59:31 | train] - Train Epoch: [12] [1126400/1281167 (88%)]	Loss: 1.947734
[2022-06-08 04:59:50 | train] - Train Epoch: [12] [1139200/1281167 (89%)]	Loss: 1.922079
[2022-06-08 05:00:10 | train] - Train Epoch: [12] [1152000/1281167 (90%)]	Loss: 2.173217
[2022-06-08 05:00:30 | train] - Train Epoch: [12] [1164800/1281167 (91%)]	Loss: 2.191726
[2022-06-08 05:00:50 | train] - Train Epoch: [12] [1177600/1281167 (92%)]	Loss: 2.291914
[2022-06-08 05:01:10 | train] - Train Epoch: [12] [1190400/1281167 (93%)]	Loss: 2.175745
[2022-06-08 05:01:30 | train] - Train Epoch: [12] [1203200/1281167 (94%)]	Loss: 2.285091
[2022-06-08 05:01:50 | train] - Train Epoch: [12] [1216000/1281167 (95%)]	Loss: 2.302531
[2022-06-08 05:02:09 | train] - Train Epoch: [12] [1228800/1281167 (96%)]	Loss: 2.438375
[2022-06-08 05:02:29 | train] - Train Epoch: [12] [1241600/1281167 (97%)]	Loss: 1.622536
[2022-06-08 05:02:48 | train] - Train Epoch: [12] [1254400/1281167 (98%)]	Loss: 2.182303
[2022-06-08 05:03:08 | train] - Train Epoch: [12] [1267200/1281167 (99%)]	Loss: 2.109721
[2022-06-08 05:03:28 | train] - Train Epoch: [12] [1280000/1281167 (100%)]	Loss: 2.124974
[2022-06-08 05:03:30 | train] - Train Epoch: [12]	 Average Loss: 2.075069	 Total Acc : 53.3237	 Total Top5 Acc : 76.3130
[2022-06-08 05:03:30 | train] - -------12 epoch end-----------
========================================
-------12 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 05:05:01 | train] - 
Epoch [12] Test set: Average loss: 1.7622, Accuracy: 29200/50000 (58.3668%), Top-5 Accuracy: 81.6956%

[2022-06-08 05:05:01 | train] - save intermediate epoch [12] result


[2022-06-08 05:05:02 | train] - logging best performance 12 epoch
[2022-06-08 05:05:03 | train] - -------13 epoch start-----------
========================================
----- test end -------------------------


logging best performance 12 epoch
[2022-06-08 05:05:05 | train] - Train Epoch: [13] [0/1281167 (0%)]	Loss: 1.740013
[2022-06-08 05:05:25 | train] - Train Epoch: [13] [12800/1281167 (1%)]	Loss: 1.717582
[2022-06-08 05:05:45 | train] - Train Epoch: [13] [25600/1281167 (2%)]	Loss: 1.869091
[2022-06-08 05:06:04 | train] - Train Epoch: [13] [38400/1281167 (3%)]	Loss: 1.783848
[2022-06-08 05:06:23 | train] - Train Epoch: [13] [51200/1281167 (4%)]	Loss: 1.845306
[2022-06-08 05:06:43 | train] - Train Epoch: [13] [64000/1281167 (5%)]	Loss: 2.210934
[2022-06-08 05:07:02 | train] - Train Epoch: [13] [76800/1281167 (6%)]	Loss: 1.895770
[2022-06-08 05:07:22 | train] - Train Epoch: [13] [89600/1281167 (7%)]	Loss: 1.976199
[2022-06-08 05:07:42 | train] - Train Epoch: [13] [102400/1281167 (8%)]	Loss: 2.124106
[2022-06-08 05:08:01 | train] - Train Epoch: [13] [115200/1281167 (9%)]	Loss: 1.884946
[2022-06-08 05:08:20 | train] - Train Epoch: [13] [128000/1281167 (10%)]	Loss: 2.249734
[2022-06-08 05:08:40 | train] - Train Epoch: [13] [140800/1281167 (11%)]	Loss: 2.179293
[2022-06-08 05:08:59 | train] - Train Epoch: [13] [153600/1281167 (12%)]	Loss: 2.181156
[2022-06-08 05:09:18 | train] - Train Epoch: [13] [166400/1281167 (13%)]	Loss: 2.117329
[2022-06-08 05:09:37 | train] - Train Epoch: [13] [179200/1281167 (14%)]	Loss: 1.975181
[2022-06-08 05:09:57 | train] - Train Epoch: [13] [192000/1281167 (15%)]	Loss: 1.578173
[2022-06-08 05:10:17 | train] - Train Epoch: [13] [204800/1281167 (16%)]	Loss: 2.351918
[2022-06-08 05:10:36 | train] - Train Epoch: [13] [217600/1281167 (17%)]	Loss: 2.208532
[2022-06-08 05:10:56 | train] - Train Epoch: [13] [230400/1281167 (18%)]	Loss: 1.848872
[2022-06-08 05:11:15 | train] - Train Epoch: [13] [243200/1281167 (19%)]	Loss: 1.709125
[2022-06-08 05:11:35 | train] - Train Epoch: [13] [256000/1281167 (20%)]	Loss: 2.001659
[2022-06-08 05:11:55 | train] - Train Epoch: [13] [268800/1281167 (21%)]	Loss: 2.180939
[2022-06-08 05:12:13 | train] - Train Epoch: [13] [281600/1281167 (22%)]	Loss: 2.419546
[2022-06-08 05:12:33 | train] - Train Epoch: [13] [294400/1281167 (23%)]	Loss: 1.643093
[2022-06-08 05:12:53 | train] - Train Epoch: [13] [307200/1281167 (24%)]	Loss: 1.974537
[2022-06-08 05:13:12 | train] - Train Epoch: [13] [320000/1281167 (25%)]	Loss: 1.756816
[2022-06-08 05:13:32 | train] - Train Epoch: [13] [332800/1281167 (26%)]	Loss: 2.037675
[2022-06-08 05:13:52 | train] - Train Epoch: [13] [345600/1281167 (27%)]	Loss: 2.086939
[2022-06-08 05:14:11 | train] - Train Epoch: [13] [358400/1281167 (28%)]	Loss: 1.848836
[2022-06-08 05:14:31 | train] - Train Epoch: [13] [371200/1281167 (29%)]	Loss: 2.011903
[2022-06-08 05:14:50 | train] - Train Epoch: [13] [384000/1281167 (30%)]	Loss: 2.138579
[2022-06-08 05:15:10 | train] - Train Epoch: [13] [396800/1281167 (31%)]	Loss: 1.805516
[2022-06-08 05:15:29 | train] - Train Epoch: [13] [409600/1281167 (32%)]	Loss: 1.858451
[2022-06-08 05:15:49 | train] - Train Epoch: [13] [422400/1281167 (33%)]	Loss: 2.050050
[2022-06-08 05:16:09 | train] - Train Epoch: [13] [435200/1281167 (34%)]	Loss: 2.079949
[2022-06-08 05:16:30 | train] - Train Epoch: [13] [448000/1281167 (35%)]	Loss: 2.111223
[2022-06-08 05:16:50 | train] - Train Epoch: [13] [460800/1281167 (36%)]	Loss: 1.963976
[2022-06-08 05:17:10 | train] - Train Epoch: [13] [473600/1281167 (37%)]	Loss: 1.714066
[2022-06-08 05:17:31 | train] - Train Epoch: [13] [486400/1281167 (38%)]	Loss: 1.951319
[2022-06-08 05:17:51 | train] - Train Epoch: [13] [499200/1281167 (39%)]	Loss: 1.847278
[2022-06-08 05:18:10 | train] - Train Epoch: [13] [512000/1281167 (40%)]	Loss: 2.381528
[2022-06-08 05:18:30 | train] - Train Epoch: [13] [524800/1281167 (41%)]	Loss: 2.088265
[2022-06-08 05:18:51 | train] - Train Epoch: [13] [537600/1281167 (42%)]	Loss: 1.991592
[2022-06-08 05:19:12 | train] - Train Epoch: [13] [550400/1281167 (43%)]	Loss: 1.991744
[2022-06-08 05:19:31 | train] - Train Epoch: [13] [563200/1281167 (44%)]	Loss: 2.009409
[2022-06-08 05:19:50 | train] - Train Epoch: [13] [576000/1281167 (45%)]	Loss: 2.109214
[2022-06-08 05:20:11 | train] - Train Epoch: [13] [588800/1281167 (46%)]	Loss: 2.219160
[2022-06-08 05:20:32 | train] - Train Epoch: [13] [601600/1281167 (47%)]	Loss: 2.055184
[2022-06-08 05:20:51 | train] - Train Epoch: [13] [614400/1281167 (48%)]	Loss: 1.923883
[2022-06-08 05:21:12 | train] - Train Epoch: [13] [627200/1281167 (49%)]	Loss: 2.075691
[2022-06-08 05:21:32 | train] - Train Epoch: [13] [640000/1281167 (50%)]	Loss: 2.533012
[2022-06-08 05:21:53 | train] - Train Epoch: [13] [652800/1281167 (51%)]	Loss: 1.813087
[2022-06-08 05:22:14 | train] - Train Epoch: [13] [665600/1281167 (52%)]	Loss: 2.007213
[2022-06-08 05:22:35 | train] - Train Epoch: [13] [678400/1281167 (53%)]	Loss: 1.827870
[2022-06-08 05:22:56 | train] - Train Epoch: [13] [691200/1281167 (54%)]	Loss: 1.458702
[2022-06-08 05:23:17 | train] - Train Epoch: [13] [704000/1281167 (55%)]	Loss: 1.797936
[2022-06-08 05:23:39 | train] - Train Epoch: [13] [716800/1281167 (56%)]	Loss: 2.384319
[2022-06-08 05:24:00 | train] - Train Epoch: [13] [729600/1281167 (57%)]	Loss: 2.270610
[2022-06-08 05:24:21 | train] - Train Epoch: [13] [742400/1281167 (58%)]	Loss: 1.735538
[2022-06-08 05:24:42 | train] - Train Epoch: [13] [755200/1281167 (59%)]	Loss: 2.044684
[2022-06-08 05:25:03 | train] - Train Epoch: [13] [768000/1281167 (60%)]	Loss: 1.517717
[2022-06-08 05:25:24 | train] - Train Epoch: [13] [780800/1281167 (61%)]	Loss: 2.330181
[2022-06-08 05:25:46 | train] - Train Epoch: [13] [793600/1281167 (62%)]	Loss: 1.722161
[2022-06-08 05:26:08 | train] - Train Epoch: [13] [806400/1281167 (63%)]	Loss: 2.181831
[2022-06-08 05:26:29 | train] - Train Epoch: [13] [819200/1281167 (64%)]	Loss: 1.811218
[2022-06-08 05:26:51 | train] - Train Epoch: [13] [832000/1281167 (65%)]	Loss: 1.999309
[2022-06-08 05:27:11 | train] - Train Epoch: [13] [844800/1281167 (66%)]	Loss: 2.327030
[2022-06-08 05:27:32 | train] - Train Epoch: [13] [857600/1281167 (67%)]	Loss: 1.866986
[2022-06-08 05:27:53 | train] - Train Epoch: [13] [870400/1281167 (68%)]	Loss: 2.192251
[2022-06-08 05:28:15 | train] - Train Epoch: [13] [883200/1281167 (69%)]	Loss: 1.969111
[2022-06-08 05:28:36 | train] - Train Epoch: [13] [896000/1281167 (70%)]	Loss: 1.894990
[2022-06-08 05:28:58 | train] - Train Epoch: [13] [908800/1281167 (71%)]	Loss: 1.921381
[2022-06-08 05:29:18 | train] - Train Epoch: [13] [921600/1281167 (72%)]	Loss: 2.173213
[2022-06-08 05:29:39 | train] - Train Epoch: [13] [934400/1281167 (73%)]	Loss: 2.237348
[2022-06-08 05:30:00 | train] - Train Epoch: [13] [947200/1281167 (74%)]	Loss: 2.059241
[2022-06-08 05:30:22 | train] - Train Epoch: [13] [960000/1281167 (75%)]	Loss: 2.071269
[2022-06-08 05:30:42 | train] - Train Epoch: [13] [972800/1281167 (76%)]	Loss: 2.134814
[2022-06-08 05:31:04 | train] - Train Epoch: [13] [985600/1281167 (77%)]	Loss: 1.981216
[2022-06-08 05:31:24 | train] - Train Epoch: [13] [998400/1281167 (78%)]	Loss: 1.997526
[2022-06-08 05:31:46 | train] - Train Epoch: [13] [1011200/1281167 (79%)]	Loss: 1.993636
[2022-06-08 05:32:07 | train] - Train Epoch: [13] [1024000/1281167 (80%)]	Loss: 1.861318
[2022-06-08 05:32:29 | train] - Train Epoch: [13] [1036800/1281167 (81%)]	Loss: 1.688036
[2022-06-08 05:32:50 | train] - Train Epoch: [13] [1049600/1281167 (82%)]	Loss: 1.790967
[2022-06-08 05:33:11 | train] - Train Epoch: [13] [1062400/1281167 (83%)]	Loss: 2.229442
[2022-06-08 05:33:32 | train] - Train Epoch: [13] [1075200/1281167 (84%)]	Loss: 1.895864
[2022-06-08 05:33:54 | train] - Train Epoch: [13] [1088000/1281167 (85%)]	Loss: 2.150696
[2022-06-08 05:34:15 | train] - Train Epoch: [13] [1100800/1281167 (86%)]	Loss: 1.834746
[2022-06-08 05:34:36 | train] - Train Epoch: [13] [1113600/1281167 (87%)]	Loss: 1.866611
[2022-06-08 05:34:57 | train] - Train Epoch: [13] [1126400/1281167 (88%)]	Loss: 2.092815
[2022-06-08 05:35:18 | train] - Train Epoch: [13] [1139200/1281167 (89%)]	Loss: 1.560771
[2022-06-08 05:35:40 | train] - Train Epoch: [13] [1152000/1281167 (90%)]	Loss: 2.099132
[2022-06-08 05:36:01 | train] - Train Epoch: [13] [1164800/1281167 (91%)]	Loss: 2.236163
[2022-06-08 05:36:23 | train] - Train Epoch: [13] [1177600/1281167 (92%)]	Loss: 2.055557
[2022-06-08 05:36:44 | train] - Train Epoch: [13] [1190400/1281167 (93%)]	Loss: 2.080649
[2022-06-08 05:37:05 | train] - Train Epoch: [13] [1203200/1281167 (94%)]	Loss: 1.587717
[2022-06-08 05:37:26 | train] - Train Epoch: [13] [1216000/1281167 (95%)]	Loss: 2.213718
[2022-06-08 05:37:47 | train] - Train Epoch: [13] [1228800/1281167 (96%)]	Loss: 1.873318
[2022-06-08 05:38:08 | train] - Train Epoch: [13] [1241600/1281167 (97%)]	Loss: 1.895526
[2022-06-08 05:38:29 | train] - Train Epoch: [13] [1254400/1281167 (98%)]	Loss: 2.461615
[2022-06-08 05:38:50 | train] - Train Epoch: [13] [1267200/1281167 (99%)]	Loss: 1.845498
[2022-06-08 05:39:12 | train] - Train Epoch: [13] [1280000/1281167 (100%)]	Loss: 1.848893
[2022-06-08 05:39:13 | train] - Train Epoch: [13]	 Average Loss: 2.007235	 Total Acc : 54.6144	 Total Top5 Acc : 77.3503
[2022-06-08 05:39:13 | train] - -------13 epoch end-----------
========================================
-------13 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 05:40:48 | train] - 
Epoch [13] Test set: Average loss: 1.7317, Accuracy: 29650/50000 (59.2599%), Top-5 Accuracy: 82.1276%

[2022-06-08 05:40:48 | train] - save intermediate epoch [13] result


[2022-06-08 05:40:49 | train] - logging best performance 13 epoch
[2022-06-08 05:40:51 | train] - -------14 epoch start-----------
========================================
----- test end -------------------------


logging best performance 13 epoch
[2022-06-08 05:40:52 | train] - Train Epoch: [14] [0/1281167 (0%)]	Loss: 1.603366
[2022-06-08 05:41:13 | train] - Train Epoch: [14] [12800/1281167 (1%)]	Loss: 2.225738
[2022-06-08 05:41:34 | train] - Train Epoch: [14] [25600/1281167 (2%)]	Loss: 1.903580
[2022-06-08 05:41:55 | train] - Train Epoch: [14] [38400/1281167 (3%)]	Loss: 1.926233
[2022-06-08 05:42:16 | train] - Train Epoch: [14] [51200/1281167 (4%)]	Loss: 2.033711
[2022-06-08 05:42:37 | train] - Train Epoch: [14] [64000/1281167 (5%)]	Loss: 2.369888
[2022-06-08 05:42:59 | train] - Train Epoch: [14] [76800/1281167 (6%)]	Loss: 1.902037
[2022-06-08 05:43:20 | train] - Train Epoch: [14] [89600/1281167 (7%)]	Loss: 1.949677
[2022-06-08 05:43:40 | train] - Train Epoch: [14] [102400/1281167 (8%)]	Loss: 2.146231
[2022-06-08 05:44:01 | train] - Train Epoch: [14] [115200/1281167 (9%)]	Loss: 2.111877
[2022-06-08 05:44:22 | train] - Train Epoch: [14] [128000/1281167 (10%)]	Loss: 2.040271
[2022-06-08 05:44:43 | train] - Train Epoch: [14] [140800/1281167 (11%)]	Loss: 2.222027
[2022-06-08 05:45:04 | train] - Train Epoch: [14] [153600/1281167 (12%)]	Loss: 2.280040
[2022-06-08 05:45:25 | train] - Train Epoch: [14] [166400/1281167 (13%)]	Loss: 1.981520
[2022-06-08 05:45:46 | train] - Train Epoch: [14] [179200/1281167 (14%)]	Loss: 1.735480
[2022-06-08 05:46:07 | train] - Train Epoch: [14] [192000/1281167 (15%)]	Loss: 1.885754
[2022-06-08 05:46:28 | train] - Train Epoch: [14] [204800/1281167 (16%)]	Loss: 1.591075
[2022-06-08 05:46:48 | train] - Train Epoch: [14] [217600/1281167 (17%)]	Loss: 1.701814
[2022-06-08 05:47:09 | train] - Train Epoch: [14] [230400/1281167 (18%)]	Loss: 2.005161
[2022-06-08 05:47:29 | train] - Train Epoch: [14] [243200/1281167 (19%)]	Loss: 1.980423
[2022-06-08 05:47:51 | train] - Train Epoch: [14] [256000/1281167 (20%)]	Loss: 2.106486
[2022-06-08 05:48:12 | train] - Train Epoch: [14] [268800/1281167 (21%)]	Loss: 2.027895
[2022-06-08 05:48:33 | train] - Train Epoch: [14] [281600/1281167 (22%)]	Loss: 2.261900
[2022-06-08 05:48:54 | train] - Train Epoch: [14] [294400/1281167 (23%)]	Loss: 1.954873
[2022-06-08 05:49:15 | train] - Train Epoch: [14] [307200/1281167 (24%)]	Loss: 1.990443
[2022-06-08 05:49:36 | train] - Train Epoch: [14] [320000/1281167 (25%)]	Loss: 1.697081
[2022-06-08 05:49:57 | train] - Train Epoch: [14] [332800/1281167 (26%)]	Loss: 2.030138
[2022-06-08 05:50:18 | train] - Train Epoch: [14] [345600/1281167 (27%)]	Loss: 2.007477
[2022-06-08 05:50:39 | train] - Train Epoch: [14] [358400/1281167 (28%)]	Loss: 1.914409
[2022-06-08 05:50:59 | train] - Train Epoch: [14] [371200/1281167 (29%)]	Loss: 1.851364
[2022-06-08 05:51:20 | train] - Train Epoch: [14] [384000/1281167 (30%)]	Loss: 1.923679
[2022-06-08 05:51:41 | train] - Train Epoch: [14] [396800/1281167 (31%)]	Loss: 1.780882
[2022-06-08 05:52:01 | train] - Train Epoch: [14] [409600/1281167 (32%)]	Loss: 1.778025
[2022-06-08 05:52:21 | train] - Train Epoch: [14] [422400/1281167 (33%)]	Loss: 1.938033
[2022-06-08 05:52:43 | train] - Train Epoch: [14] [435200/1281167 (34%)]	Loss: 1.970520
[2022-06-08 05:53:04 | train] - Train Epoch: [14] [448000/1281167 (35%)]	Loss: 1.706993
[2022-06-08 05:53:25 | train] - Train Epoch: [14] [460800/1281167 (36%)]	Loss: 1.871250
[2022-06-08 05:53:47 | train] - Train Epoch: [14] [473600/1281167 (37%)]	Loss: 2.286157
[2022-06-08 05:54:08 | train] - Train Epoch: [14] [486400/1281167 (38%)]	Loss: 1.998527
[2022-06-08 05:54:29 | train] - Train Epoch: [14] [499200/1281167 (39%)]	Loss: 1.882354
[2022-06-08 05:54:51 | train] - Train Epoch: [14] [512000/1281167 (40%)]	Loss: 1.937688
[2022-06-08 05:55:12 | train] - Train Epoch: [14] [524800/1281167 (41%)]	Loss: 1.755796
[2022-06-08 05:55:34 | train] - Train Epoch: [14] [537600/1281167 (42%)]	Loss: 1.833479
[2022-06-08 05:55:55 | train] - Train Epoch: [14] [550400/1281167 (43%)]	Loss: 1.988579
[2022-06-08 05:56:16 | train] - Train Epoch: [14] [563200/1281167 (44%)]	Loss: 1.923119
[2022-06-08 05:56:37 | train] - Train Epoch: [14] [576000/1281167 (45%)]	Loss: 2.019773
[2022-06-08 05:56:58 | train] - Train Epoch: [14] [588800/1281167 (46%)]	Loss: 1.938463
[2022-06-08 05:57:19 | train] - Train Epoch: [14] [601600/1281167 (47%)]	Loss: 1.545825
[2022-06-08 05:57:40 | train] - Train Epoch: [14] [614400/1281167 (48%)]	Loss: 1.714732
[2022-06-08 05:58:01 | train] - Train Epoch: [14] [627200/1281167 (49%)]	Loss: 2.028493
[2022-06-08 05:58:21 | train] - Train Epoch: [14] [640000/1281167 (50%)]	Loss: 2.134187
[2022-06-08 05:58:42 | train] - Train Epoch: [14] [652800/1281167 (51%)]	Loss: 1.770488
[2022-06-08 05:59:02 | train] - Train Epoch: [14] [665600/1281167 (52%)]	Loss: 2.128378
[2022-06-08 05:59:22 | train] - Train Epoch: [14] [678400/1281167 (53%)]	Loss: 2.102000
[2022-06-08 05:59:43 | train] - Train Epoch: [14] [691200/1281167 (54%)]	Loss: 1.860007
[2022-06-08 06:00:04 | train] - Train Epoch: [14] [704000/1281167 (55%)]	Loss: 2.037795
[2022-06-08 06:00:25 | train] - Train Epoch: [14] [716800/1281167 (56%)]	Loss: 1.487191
[2022-06-08 06:00:46 | train] - Train Epoch: [14] [729600/1281167 (57%)]	Loss: 1.661220
[2022-06-08 06:01:07 | train] - Train Epoch: [14] [742400/1281167 (58%)]	Loss: 1.819437
[2022-06-08 06:01:28 | train] - Train Epoch: [14] [755200/1281167 (59%)]	Loss: 2.155405
[2022-06-08 06:01:49 | train] - Train Epoch: [14] [768000/1281167 (60%)]	Loss: 1.952343
[2022-06-08 06:02:10 | train] - Train Epoch: [14] [780800/1281167 (61%)]	Loss: 1.713268
[2022-06-08 06:02:31 | train] - Train Epoch: [14] [793600/1281167 (62%)]	Loss: 1.849584
[2022-06-08 06:02:52 | train] - Train Epoch: [14] [806400/1281167 (63%)]	Loss: 1.846517
[2022-06-08 06:03:13 | train] - Train Epoch: [14] [819200/1281167 (64%)]	Loss: 1.662187
[2022-06-08 06:03:34 | train] - Train Epoch: [14] [832000/1281167 (65%)]	Loss: 2.133161
[2022-06-08 06:03:54 | train] - Train Epoch: [14] [844800/1281167 (66%)]	Loss: 1.790424
[2022-06-08 06:04:14 | train] - Train Epoch: [14] [857600/1281167 (67%)]	Loss: 1.768070
[2022-06-08 06:04:35 | train] - Train Epoch: [14] [870400/1281167 (68%)]	Loss: 2.056751
[2022-06-08 06:04:56 | train] - Train Epoch: [14] [883200/1281167 (69%)]	Loss: 1.704161
[2022-06-08 06:05:18 | train] - Train Epoch: [14] [896000/1281167 (70%)]	Loss: 1.782519
[2022-06-08 06:05:39 | train] - Train Epoch: [14] [908800/1281167 (71%)]	Loss: 2.147573
[2022-06-08 06:06:00 | train] - Train Epoch: [14] [921600/1281167 (72%)]	Loss: 2.196240
[2022-06-08 06:06:20 | train] - Train Epoch: [14] [934400/1281167 (73%)]	Loss: 1.795421
[2022-06-08 06:06:42 | train] - Train Epoch: [14] [947200/1281167 (74%)]	Loss: 1.631120
[2022-06-08 06:07:03 | train] - Train Epoch: [14] [960000/1281167 (75%)]	Loss: 1.930551
[2022-06-08 06:07:25 | train] - Train Epoch: [14] [972800/1281167 (76%)]	Loss: 1.934339
[2022-06-08 06:07:46 | train] - Train Epoch: [14] [985600/1281167 (77%)]	Loss: 1.755068
[2022-06-08 06:08:08 | train] - Train Epoch: [14] [998400/1281167 (78%)]	Loss: 2.094143
[2022-06-08 06:08:29 | train] - Train Epoch: [14] [1011200/1281167 (79%)]	Loss: 1.794717
[2022-06-08 06:08:50 | train] - Train Epoch: [14] [1024000/1281167 (80%)]	Loss: 1.630699
[2022-06-08 06:09:11 | train] - Train Epoch: [14] [1036800/1281167 (81%)]	Loss: 2.055870
[2022-06-08 06:09:32 | train] - Train Epoch: [14] [1049600/1281167 (82%)]	Loss: 1.966053
[2022-06-08 06:09:53 | train] - Train Epoch: [14] [1062400/1281167 (83%)]	Loss: 2.082022
[2022-06-08 06:10:14 | train] - Train Epoch: [14] [1075200/1281167 (84%)]	Loss: 1.810539
[2022-06-08 06:10:35 | train] - Train Epoch: [14] [1088000/1281167 (85%)]	Loss: 1.704493
[2022-06-08 06:10:57 | train] - Train Epoch: [14] [1100800/1281167 (86%)]	Loss: 1.901203
[2022-06-08 06:11:17 | train] - Train Epoch: [14] [1113600/1281167 (87%)]	Loss: 1.936215
[2022-06-08 06:11:38 | train] - Train Epoch: [14] [1126400/1281167 (88%)]	Loss: 1.795633
[2022-06-08 06:11:58 | train] - Train Epoch: [14] [1139200/1281167 (89%)]	Loss: 2.154809
[2022-06-08 06:12:19 | train] - Train Epoch: [14] [1152000/1281167 (90%)]	Loss: 2.138269
[2022-06-08 06:12:40 | train] - Train Epoch: [14] [1164800/1281167 (91%)]	Loss: 2.001778
[2022-06-08 06:13:01 | train] - Train Epoch: [14] [1177600/1281167 (92%)]	Loss: 1.937069
[2022-06-08 06:13:22 | train] - Train Epoch: [14] [1190400/1281167 (93%)]	Loss: 1.795578
[2022-06-08 06:13:42 | train] - Train Epoch: [14] [1203200/1281167 (94%)]	Loss: 1.849159
[2022-06-08 06:14:03 | train] - Train Epoch: [14] [1216000/1281167 (95%)]	Loss: 2.015687
[2022-06-08 06:14:24 | train] - Train Epoch: [14] [1228800/1281167 (96%)]	Loss: 1.743810
[2022-06-08 06:14:45 | train] - Train Epoch: [14] [1241600/1281167 (97%)]	Loss: 2.013747
[2022-06-08 06:15:06 | train] - Train Epoch: [14] [1254400/1281167 (98%)]	Loss: 1.847873
[2022-06-08 06:15:26 | train] - Train Epoch: [14] [1267200/1281167 (99%)]	Loss: 1.615420
[2022-06-08 06:15:48 | train] - Train Epoch: [14] [1280000/1281167 (100%)]	Loss: 2.098624
[2022-06-08 06:15:50 | train] - Train Epoch: [14]	 Average Loss: 1.946808	 Total Acc : 55.7749	 Total Top5 Acc : 78.2713
[2022-06-08 06:15:50 | train] - -------14 epoch end-----------
========================================
-------14 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 06:17:23 | train] - 
Epoch [14] Test set: Average loss: 1.6817, Accuracy: 30024/50000 (60.0096%), Top-5 Accuracy: 82.9532%

[2022-06-08 06:17:23 | train] - save intermediate epoch [14] result


[2022-06-08 06:17:25 | train] - logging best performance 14 epoch
[2022-06-08 06:17:27 | train] - -------15 epoch start-----------
========================================
----- test end -------------------------


logging best performance 14 epoch
[2022-06-08 06:17:28 | train] - Train Epoch: [15] [0/1281167 (0%)]	Loss: 1.560271
[2022-06-08 06:17:50 | train] - Train Epoch: [15] [12800/1281167 (1%)]	Loss: 1.893657
[2022-06-08 06:18:12 | train] - Train Epoch: [15] [25600/1281167 (2%)]	Loss: 1.618976
[2022-06-08 06:18:34 | train] - Train Epoch: [15] [38400/1281167 (3%)]	Loss: 2.224553
[2022-06-08 06:18:55 | train] - Train Epoch: [15] [51200/1281167 (4%)]	Loss: 1.665908
[2022-06-08 06:19:17 | train] - Train Epoch: [15] [64000/1281167 (5%)]	Loss: 1.649248
[2022-06-08 06:19:38 | train] - Train Epoch: [15] [76800/1281167 (6%)]	Loss: 2.092930
[2022-06-08 06:20:00 | train] - Train Epoch: [15] [89600/1281167 (7%)]	Loss: 2.023360
[2022-06-08 06:20:22 | train] - Train Epoch: [15] [102400/1281167 (8%)]	Loss: 2.239219
[2022-06-08 06:20:43 | train] - Train Epoch: [15] [115200/1281167 (9%)]	Loss: 1.738325
[2022-06-08 06:21:05 | train] - Train Epoch: [15] [128000/1281167 (10%)]	Loss: 1.831915
[2022-06-08 06:21:27 | train] - Train Epoch: [15] [140800/1281167 (11%)]	Loss: 1.830482
[2022-06-08 06:21:48 | train] - Train Epoch: [15] [153600/1281167 (12%)]	Loss: 1.791744
[2022-06-08 06:22:09 | train] - Train Epoch: [15] [166400/1281167 (13%)]	Loss: 1.681155
[2022-06-08 06:22:29 | train] - Train Epoch: [15] [179200/1281167 (14%)]	Loss: 1.907333
[2022-06-08 06:22:50 | train] - Train Epoch: [15] [192000/1281167 (15%)]	Loss: 2.310431
[2022-06-08 06:23:12 | train] - Train Epoch: [15] [204800/1281167 (16%)]	Loss: 1.751181
[2022-06-08 06:23:34 | train] - Train Epoch: [15] [217600/1281167 (17%)]	Loss: 1.891508
[2022-06-08 06:23:57 | train] - Train Epoch: [15] [230400/1281167 (18%)]	Loss: 1.671315
[2022-06-08 06:24:19 | train] - Train Epoch: [15] [243200/1281167 (19%)]	Loss: 1.685281
[2022-06-08 06:24:40 | train] - Train Epoch: [15] [256000/1281167 (20%)]	Loss: 1.809505
[2022-06-08 06:25:02 | train] - Train Epoch: [15] [268800/1281167 (21%)]	Loss: 1.859106
[2022-06-08 06:25:23 | train] - Train Epoch: [15] [281600/1281167 (22%)]	Loss: 2.071019
[2022-06-08 06:25:45 | train] - Train Epoch: [15] [294400/1281167 (23%)]	Loss: 1.883846
[2022-06-08 06:26:07 | train] - Train Epoch: [15] [307200/1281167 (24%)]	Loss: 2.030743
[2022-06-08 06:26:29 | train] - Train Epoch: [15] [320000/1281167 (25%)]	Loss: 1.591812
[2022-06-08 06:26:51 | train] - Train Epoch: [15] [332800/1281167 (26%)]	Loss: 1.998523
[2022-06-08 06:27:13 | train] - Train Epoch: [15] [345600/1281167 (27%)]	Loss: 1.854061
[2022-06-08 06:27:35 | train] - Train Epoch: [15] [358400/1281167 (28%)]	Loss: 2.081673
[2022-06-08 06:27:56 | train] - Train Epoch: [15] [371200/1281167 (29%)]	Loss: 2.103392
[2022-06-08 06:28:18 | train] - Train Epoch: [15] [384000/1281167 (30%)]	Loss: 1.969400
[2022-06-08 06:28:40 | train] - Train Epoch: [15] [396800/1281167 (31%)]	Loss: 1.599315
[2022-06-08 06:29:01 | train] - Train Epoch: [15] [409600/1281167 (32%)]	Loss: 1.799343
[2022-06-08 06:29:24 | train] - Train Epoch: [15] [422400/1281167 (33%)]	Loss: 1.865767
[2022-06-08 06:29:46 | train] - Train Epoch: [15] [435200/1281167 (34%)]	Loss: 1.708718
[2022-06-08 06:30:08 | train] - Train Epoch: [15] [448000/1281167 (35%)]	Loss: 2.127940
[2022-06-08 06:30:28 | train] - Train Epoch: [15] [460800/1281167 (36%)]	Loss: 1.721635
[2022-06-08 06:30:51 | train] - Train Epoch: [15] [473600/1281167 (37%)]	Loss: 1.556451
[2022-06-08 06:31:12 | train] - Train Epoch: [15] [486400/1281167 (38%)]	Loss: 1.990226
[2022-06-08 06:31:34 | train] - Train Epoch: [15] [499200/1281167 (39%)]	Loss: 2.204598
[2022-06-08 06:31:56 | train] - Train Epoch: [15] [512000/1281167 (40%)]	Loss: 2.046486
[2022-06-08 06:32:18 | train] - Train Epoch: [15] [524800/1281167 (41%)]	Loss: 2.050497
[2022-06-08 06:32:39 | train] - Train Epoch: [15] [537600/1281167 (42%)]	Loss: 1.459723
[2022-06-08 06:33:01 | train] - Train Epoch: [15] [550400/1281167 (43%)]	Loss: 1.428886
[2022-06-08 06:33:23 | train] - Train Epoch: [15] [563200/1281167 (44%)]	Loss: 1.825217
[2022-06-08 06:33:46 | train] - Train Epoch: [15] [576000/1281167 (45%)]	Loss: 1.703124
[2022-06-08 06:34:08 | train] - Train Epoch: [15] [588800/1281167 (46%)]	Loss: 1.596326
[2022-06-08 06:34:30 | train] - Train Epoch: [15] [601600/1281167 (47%)]	Loss: 2.049525
[2022-06-08 06:34:52 | train] - Train Epoch: [15] [614400/1281167 (48%)]	Loss: 1.651357
[2022-06-08 06:35:13 | train] - Train Epoch: [15] [627200/1281167 (49%)]	Loss: 1.493936
[2022-06-08 06:35:36 | train] - Train Epoch: [15] [640000/1281167 (50%)]	Loss: 1.922106
[2022-06-08 06:35:57 | train] - Train Epoch: [15] [652800/1281167 (51%)]	Loss: 1.728932
[2022-06-08 06:36:19 | train] - Train Epoch: [15] [665600/1281167 (52%)]	Loss: 1.871174
[2022-06-08 06:36:41 | train] - Train Epoch: [15] [678400/1281167 (53%)]	Loss: 1.772252
[2022-06-08 06:37:03 | train] - Train Epoch: [15] [691200/1281167 (54%)]	Loss: 1.592934
[2022-06-08 06:37:25 | train] - Train Epoch: [15] [704000/1281167 (55%)]	Loss: 2.161434
[2022-06-08 06:37:47 | train] - Train Epoch: [15] [716800/1281167 (56%)]	Loss: 1.591885
[2022-06-08 06:38:09 | train] - Train Epoch: [15] [729600/1281167 (57%)]	Loss: 1.855776
[2022-06-08 06:38:31 | train] - Train Epoch: [15] [742400/1281167 (58%)]	Loss: 1.868340
[2022-06-08 06:38:54 | train] - Train Epoch: [15] [755200/1281167 (59%)]	Loss: 1.861922
[2022-06-08 06:39:16 | train] - Train Epoch: [15] [768000/1281167 (60%)]	Loss: 2.029691
[2022-06-08 06:39:37 | train] - Train Epoch: [15] [780800/1281167 (61%)]	Loss: 2.384387
[2022-06-08 06:39:59 | train] - Train Epoch: [15] [793600/1281167 (62%)]	Loss: 1.770910
[2022-06-08 06:40:21 | train] - Train Epoch: [15] [806400/1281167 (63%)]	Loss: 2.082457
[2022-06-08 06:40:44 | train] - Train Epoch: [15] [819200/1281167 (64%)]	Loss: 1.856849
[2022-06-08 06:41:05 | train] - Train Epoch: [15] [832000/1281167 (65%)]	Loss: 1.842997
[2022-06-08 06:41:27 | train] - Train Epoch: [15] [844800/1281167 (66%)]	Loss: 2.074427
[2022-06-08 06:41:48 | train] - Train Epoch: [15] [857600/1281167 (67%)]	Loss: 1.727665
[2022-06-08 06:42:10 | train] - Train Epoch: [15] [870400/1281167 (68%)]	Loss: 1.741970
[2022-06-08 06:42:32 | train] - Train Epoch: [15] [883200/1281167 (69%)]	Loss: 1.583142
[2022-06-08 06:42:54 | train] - Train Epoch: [15] [896000/1281167 (70%)]	Loss: 1.797947
[2022-06-08 06:43:15 | train] - Train Epoch: [15] [908800/1281167 (71%)]	Loss: 1.840768
[2022-06-08 06:43:37 | train] - Train Epoch: [15] [921600/1281167 (72%)]	Loss: 1.716363
[2022-06-08 06:43:59 | train] - Train Epoch: [15] [934400/1281167 (73%)]	Loss: 2.219469
[2022-06-08 06:44:21 | train] - Train Epoch: [15] [947200/1281167 (74%)]	Loss: 1.852973
[2022-06-08 06:44:43 | train] - Train Epoch: [15] [960000/1281167 (75%)]	Loss: 1.761729
[2022-06-08 06:45:05 | train] - Train Epoch: [15] [972800/1281167 (76%)]	Loss: 1.622839
[2022-06-08 06:45:27 | train] - Train Epoch: [15] [985600/1281167 (77%)]	Loss: 1.761518
[2022-06-08 06:45:49 | train] - Train Epoch: [15] [998400/1281167 (78%)]	Loss: 1.658574
[2022-06-08 06:46:10 | train] - Train Epoch: [15] [1011200/1281167 (79%)]	Loss: 1.985622
[2022-06-08 06:46:33 | train] - Train Epoch: [15] [1024000/1281167 (80%)]	Loss: 2.030392
[2022-06-08 06:46:55 | train] - Train Epoch: [15] [1036800/1281167 (81%)]	Loss: 1.622946
[2022-06-08 06:47:17 | train] - Train Epoch: [15] [1049600/1281167 (82%)]	Loss: 1.688582
[2022-06-08 06:47:38 | train] - Train Epoch: [15] [1062400/1281167 (83%)]	Loss: 1.884753
[2022-06-08 06:48:00 | train] - Train Epoch: [15] [1075200/1281167 (84%)]	Loss: 2.075825
[2022-06-08 06:48:22 | train] - Train Epoch: [15] [1088000/1281167 (85%)]	Loss: 1.757368
[2022-06-08 06:48:45 | train] - Train Epoch: [15] [1100800/1281167 (86%)]	Loss: 1.627814
[2022-06-08 06:49:06 | train] - Train Epoch: [15] [1113600/1281167 (87%)]	Loss: 1.622136
[2022-06-08 06:49:28 | train] - Train Epoch: [15] [1126400/1281167 (88%)]	Loss: 1.969203
[2022-06-08 06:49:49 | train] - Train Epoch: [15] [1139200/1281167 (89%)]	Loss: 1.861091
[2022-06-08 06:50:11 | train] - Train Epoch: [15] [1152000/1281167 (90%)]	Loss: 1.603494
[2022-06-08 06:50:33 | train] - Train Epoch: [15] [1164800/1281167 (91%)]	Loss: 1.330185
[2022-06-08 06:50:55 | train] - Train Epoch: [15] [1177600/1281167 (92%)]	Loss: 1.984394
[2022-06-08 06:51:18 | train] - Train Epoch: [15] [1190400/1281167 (93%)]	Loss: 1.749656
[2022-06-08 06:51:39 | train] - Train Epoch: [15] [1203200/1281167 (94%)]	Loss: 1.824310
[2022-06-08 06:52:01 | train] - Train Epoch: [15] [1216000/1281167 (95%)]	Loss: 1.887192
[2022-06-08 06:52:23 | train] - Train Epoch: [15] [1228800/1281167 (96%)]	Loss: 2.138806
[2022-06-08 06:52:45 | train] - Train Epoch: [15] [1241600/1281167 (97%)]	Loss: 2.131812
[2022-06-08 06:53:08 | train] - Train Epoch: [15] [1254400/1281167 (98%)]	Loss: 2.026449
[2022-06-08 06:53:30 | train] - Train Epoch: [15] [1267200/1281167 (99%)]	Loss: 1.785725
[2022-06-08 06:53:52 | train] - Train Epoch: [15] [1280000/1281167 (100%)]	Loss: 1.908114
[2022-06-08 06:53:54 | train] - Train Epoch: [15]	 Average Loss: 1.894989	 Total Acc : 56.7947	 Total Top5 Acc : 79.0167
[2022-06-08 06:53:54 | train] - -------15 epoch end-----------
========================================
-------15 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 06:55:29 | train] - 
Epoch [15] Test set: Average loss: 1.6770, Accuracy: 30268/50000 (60.5007%), Top-5 Accuracy: 82.9648%

[2022-06-08 06:55:29 | train] - save intermediate epoch [15] result


[2022-06-08 06:55:31 | train] - logging best performance 15 epoch
[2022-06-08 06:55:33 | train] - -------16 epoch start-----------
========================================
----- test end -------------------------


logging best performance 15 epoch
[2022-06-08 06:55:34 | train] - Train Epoch: [16] [0/1281167 (0%)]	Loss: 1.735332
[2022-06-08 06:55:57 | train] - Train Epoch: [16] [12800/1281167 (1%)]	Loss: 1.757018
[2022-06-08 06:56:19 | train] - Train Epoch: [16] [25600/1281167 (2%)]	Loss: 1.910772
[2022-06-08 06:56:40 | train] - Train Epoch: [16] [38400/1281167 (3%)]	Loss: 1.943048
[2022-06-08 06:57:02 | train] - Train Epoch: [16] [51200/1281167 (4%)]	Loss: 2.053929
[2022-06-08 06:57:24 | train] - Train Epoch: [16] [64000/1281167 (5%)]	Loss: 1.776004
[2022-06-08 06:57:46 | train] - Train Epoch: [16] [76800/1281167 (6%)]	Loss: 1.956644
[2022-06-08 06:58:07 | train] - Train Epoch: [16] [89600/1281167 (7%)]	Loss: 2.138126
[2022-06-08 06:58:30 | train] - Train Epoch: [16] [102400/1281167 (8%)]	Loss: 1.860958
[2022-06-08 06:58:51 | train] - Train Epoch: [16] [115200/1281167 (9%)]	Loss: 2.283530
[2022-06-08 06:59:13 | train] - Train Epoch: [16] [128000/1281167 (10%)]	Loss: 1.882513
[2022-06-08 06:59:35 | train] - Train Epoch: [16] [140800/1281167 (11%)]	Loss: 2.049674
[2022-06-08 06:59:57 | train] - Train Epoch: [16] [153600/1281167 (12%)]	Loss: 2.207198
[2022-06-08 07:00:20 | train] - Train Epoch: [16] [166400/1281167 (13%)]	Loss: 2.177669
[2022-06-08 07:00:42 | train] - Train Epoch: [16] [179200/1281167 (14%)]	Loss: 1.724129
[2022-06-08 07:01:04 | train] - Train Epoch: [16] [192000/1281167 (15%)]	Loss: 1.770189
[2022-06-08 07:01:26 | train] - Train Epoch: [16] [204800/1281167 (16%)]	Loss: 1.837532
[2022-06-08 07:01:48 | train] - Train Epoch: [16] [217600/1281167 (17%)]	Loss: 1.774256
[2022-06-08 07:02:10 | train] - Train Epoch: [16] [230400/1281167 (18%)]	Loss: 1.667529
[2022-06-08 07:02:32 | train] - Train Epoch: [16] [243200/1281167 (19%)]	Loss: 1.715518
[2022-06-08 07:02:54 | train] - Train Epoch: [16] [256000/1281167 (20%)]	Loss: 2.232606
[2022-06-08 07:03:16 | train] - Train Epoch: [16] [268800/1281167 (21%)]	Loss: 1.754971
[2022-06-08 07:03:38 | train] - Train Epoch: [16] [281600/1281167 (22%)]	Loss: 1.604854
[2022-06-08 07:04:00 | train] - Train Epoch: [16] [294400/1281167 (23%)]	Loss: 1.773415
[2022-06-08 07:04:22 | train] - Train Epoch: [16] [307200/1281167 (24%)]	Loss: 1.605643
[2022-06-08 07:04:44 | train] - Train Epoch: [16] [320000/1281167 (25%)]	Loss: 1.608191
[2022-06-08 07:05:06 | train] - Train Epoch: [16] [332800/1281167 (26%)]	Loss: 2.240284
[2022-06-08 07:05:27 | train] - Train Epoch: [16] [345600/1281167 (27%)]	Loss: 1.412976
[2022-06-08 07:05:49 | train] - Train Epoch: [16] [358400/1281167 (28%)]	Loss: 1.956034
[2022-06-08 07:06:11 | train] - Train Epoch: [16] [371200/1281167 (29%)]	Loss: 1.971562
[2022-06-08 07:06:33 | train] - Train Epoch: [16] [384000/1281167 (30%)]	Loss: 2.080728
[2022-06-08 07:06:55 | train] - Train Epoch: [16] [396800/1281167 (31%)]	Loss: 2.392003
[2022-06-08 07:07:17 | train] - Train Epoch: [16] [409600/1281167 (32%)]	Loss: 2.046990
[2022-06-08 07:07:39 | train] - Train Epoch: [16] [422400/1281167 (33%)]	Loss: 1.960053
[2022-06-08 07:08:02 | train] - Train Epoch: [16] [435200/1281167 (34%)]	Loss: 1.676031
[2022-06-08 07:08:23 | train] - Train Epoch: [16] [448000/1281167 (35%)]	Loss: 1.724578
[2022-06-08 07:08:45 | train] - Train Epoch: [16] [460800/1281167 (36%)]	Loss: 1.860384
[2022-06-08 07:09:08 | train] - Train Epoch: [16] [473600/1281167 (37%)]	Loss: 1.753984
[2022-06-08 07:09:29 | train] - Train Epoch: [16] [486400/1281167 (38%)]	Loss: 1.962570
[2022-06-08 07:09:51 | train] - Train Epoch: [16] [499200/1281167 (39%)]	Loss: 2.281449
[2022-06-08 07:10:14 | train] - Train Epoch: [16] [512000/1281167 (40%)]	Loss: 2.105097
[2022-06-08 07:10:35 | train] - Train Epoch: [16] [524800/1281167 (41%)]	Loss: 1.313228
[2022-06-08 07:10:58 | train] - Train Epoch: [16] [537600/1281167 (42%)]	Loss: 1.671108
[2022-06-08 07:11:19 | train] - Train Epoch: [16] [550400/1281167 (43%)]	Loss: 1.960227
[2022-06-08 07:11:41 | train] - Train Epoch: [16] [563200/1281167 (44%)]	Loss: 1.521235
[2022-06-08 07:12:03 | train] - Train Epoch: [16] [576000/1281167 (45%)]	Loss: 2.151922
[2022-06-08 07:12:25 | train] - Train Epoch: [16] [588800/1281167 (46%)]	Loss: 1.851022
[2022-06-08 07:12:47 | train] - Train Epoch: [16] [601600/1281167 (47%)]	Loss: 1.701857
[2022-06-08 07:13:08 | train] - Train Epoch: [16] [614400/1281167 (48%)]	Loss: 1.951424
[2022-06-08 07:13:30 | train] - Train Epoch: [16] [627200/1281167 (49%)]	Loss: 1.622751
[2022-06-08 07:13:52 | train] - Train Epoch: [16] [640000/1281167 (50%)]	Loss: 1.911880
[2022-06-08 07:14:15 | train] - Train Epoch: [16] [652800/1281167 (51%)]	Loss: 1.816376
[2022-06-08 07:14:37 | train] - Train Epoch: [16] [665600/1281167 (52%)]	Loss: 1.662036
[2022-06-08 07:14:59 | train] - Train Epoch: [16] [678400/1281167 (53%)]	Loss: 1.914633
[2022-06-08 07:15:21 | train] - Train Epoch: [16] [691200/1281167 (54%)]	Loss: 1.885628
[2022-06-08 07:15:42 | train] - Train Epoch: [16] [704000/1281167 (55%)]	Loss: 1.974603
[2022-06-08 07:16:05 | train] - Train Epoch: [16] [716800/1281167 (56%)]	Loss: 1.942128
[2022-06-08 07:16:26 | train] - Train Epoch: [16] [729600/1281167 (57%)]	Loss: 1.920771
[2022-06-08 07:16:49 | train] - Train Epoch: [16] [742400/1281167 (58%)]	Loss: 1.893342
[2022-06-08 07:17:11 | train] - Train Epoch: [16] [755200/1281167 (59%)]	Loss: 1.943992
[2022-06-08 07:17:33 | train] - Train Epoch: [16] [768000/1281167 (60%)]	Loss: 1.851206
[2022-06-08 07:17:55 | train] - Train Epoch: [16] [780800/1281167 (61%)]	Loss: 1.584245
[2022-06-08 07:18:17 | train] - Train Epoch: [16] [793600/1281167 (62%)]	Loss: 2.089884
[2022-06-08 07:18:39 | train] - Train Epoch: [16] [806400/1281167 (63%)]	Loss: 1.792504
[2022-06-08 07:19:01 | train] - Train Epoch: [16] [819200/1281167 (64%)]	Loss: 1.851589
[2022-06-08 07:19:24 | train] - Train Epoch: [16] [832000/1281167 (65%)]	Loss: 1.831735
[2022-06-08 07:19:46 | train] - Train Epoch: [16] [844800/1281167 (66%)]	Loss: 1.939246
[2022-06-08 07:20:08 | train] - Train Epoch: [16] [857600/1281167 (67%)]	Loss: 1.743178
[2022-06-08 07:20:29 | train] - Train Epoch: [16] [870400/1281167 (68%)]	Loss: 1.665135
[2022-06-08 07:20:52 | train] - Train Epoch: [16] [883200/1281167 (69%)]	Loss: 1.998805
[2022-06-08 07:21:14 | train] - Train Epoch: [16] [896000/1281167 (70%)]	Loss: 1.697600
[2022-06-08 07:21:36 | train] - Train Epoch: [16] [908800/1281167 (71%)]	Loss: 1.951171
[2022-06-08 07:21:59 | train] - Train Epoch: [16] [921600/1281167 (72%)]	Loss: 1.925376
[2022-06-08 07:22:21 | train] - Train Epoch: [16] [934400/1281167 (73%)]	Loss: 1.716971
[2022-06-08 07:22:43 | train] - Train Epoch: [16] [947200/1281167 (74%)]	Loss: 1.874421
[2022-06-08 07:23:05 | train] - Train Epoch: [16] [960000/1281167 (75%)]	Loss: 1.761725
[2022-06-08 07:23:27 | train] - Train Epoch: [16] [972800/1281167 (76%)]	Loss: 1.589907
[2022-06-08 07:23:49 | train] - Train Epoch: [16] [985600/1281167 (77%)]	Loss: 1.517699
[2022-06-08 07:24:10 | train] - Train Epoch: [16] [998400/1281167 (78%)]	Loss: 1.875214
[2022-06-08 07:24:32 | train] - Train Epoch: [16] [1011200/1281167 (79%)]	Loss: 1.695085
[2022-06-08 07:24:54 | train] - Train Epoch: [16] [1024000/1281167 (80%)]	Loss: 1.692678
[2022-06-08 07:25:16 | train] - Train Epoch: [16] [1036800/1281167 (81%)]	Loss: 2.041078
[2022-06-08 07:25:37 | train] - Train Epoch: [16] [1049600/1281167 (82%)]	Loss: 1.858311
[2022-06-08 07:26:00 | train] - Train Epoch: [16] [1062400/1281167 (83%)]	Loss: 1.584890
[2022-06-08 07:26:22 | train] - Train Epoch: [16] [1075200/1281167 (84%)]	Loss: 1.733425
[2022-06-08 07:26:44 | train] - Train Epoch: [16] [1088000/1281167 (85%)]	Loss: 1.881243
[2022-06-08 07:27:07 | train] - Train Epoch: [16] [1100800/1281167 (86%)]	Loss: 1.649517
[2022-06-08 07:27:28 | train] - Train Epoch: [16] [1113600/1281167 (87%)]	Loss: 1.686739
[2022-06-08 07:27:51 | train] - Train Epoch: [16] [1126400/1281167 (88%)]	Loss: 1.924417
[2022-06-08 07:28:12 | train] - Train Epoch: [16] [1139200/1281167 (89%)]	Loss: 1.912394
[2022-06-08 07:28:34 | train] - Train Epoch: [16] [1152000/1281167 (90%)]	Loss: 1.748457
[2022-06-08 07:28:56 | train] - Train Epoch: [16] [1164800/1281167 (91%)]	Loss: 1.974889
[2022-06-08 07:29:19 | train] - Train Epoch: [16] [1177600/1281167 (92%)]	Loss: 1.871066
[2022-06-08 07:29:41 | train] - Train Epoch: [16] [1190400/1281167 (93%)]	Loss: 1.536280
[2022-06-08 07:30:02 | train] - Train Epoch: [16] [1203200/1281167 (94%)]	Loss: 1.991141
[2022-06-08 07:30:25 | train] - Train Epoch: [16] [1216000/1281167 (95%)]	Loss: 1.896803
[2022-06-08 07:30:46 | train] - Train Epoch: [16] [1228800/1281167 (96%)]	Loss: 2.125472
[2022-06-08 07:31:09 | train] - Train Epoch: [16] [1241600/1281167 (97%)]	Loss: 2.132354
[2022-06-08 07:31:31 | train] - Train Epoch: [16] [1254400/1281167 (98%)]	Loss: 1.768074
[2022-06-08 07:31:53 | train] - Train Epoch: [16] [1267200/1281167 (99%)]	Loss: 1.846647
[2022-06-08 07:32:16 | train] - Train Epoch: [16] [1280000/1281167 (100%)]	Loss: 1.618475
[2022-06-08 07:32:18 | train] - Train Epoch: [16]	 Average Loss: 1.843414	 Total Acc : 57.7653	 Total Top5 Acc : 79.7659
[2022-06-08 07:32:18 | train] - -------16 epoch end-----------
========================================
-------16 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 07:33:54 | train] - 
Epoch [16] Test set: Average loss: 1.6580, Accuracy: 30247/50000 (60.4576%), Top-5 Accuracy: 83.2373%

[2022-06-08 07:33:54 | train] - save intermediate epoch [16] result


[2022-06-08 07:33:57 | train] - -------17 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 07:33:59 | train] - Train Epoch: [17] [0/1281167 (0%)]	Loss: 2.003962
[2022-06-08 07:34:21 | train] - Train Epoch: [17] [12800/1281167 (1%)]	Loss: 1.774740
[2022-06-08 07:34:43 | train] - Train Epoch: [17] [25600/1281167 (2%)]	Loss: 1.469241
[2022-06-08 07:35:05 | train] - Train Epoch: [17] [38400/1281167 (3%)]	Loss: 1.869797
[2022-06-08 07:35:27 | train] - Train Epoch: [17] [51200/1281167 (4%)]	Loss: 1.830088
[2022-06-08 07:35:49 | train] - Train Epoch: [17] [64000/1281167 (5%)]	Loss: 1.914099
[2022-06-08 07:36:11 | train] - Train Epoch: [17] [76800/1281167 (6%)]	Loss: 1.725493
[2022-06-08 07:36:32 | train] - Train Epoch: [17] [89600/1281167 (7%)]	Loss: 1.571989
[2022-06-08 07:36:54 | train] - Train Epoch: [17] [102400/1281167 (8%)]	Loss: 1.666918
[2022-06-08 07:37:15 | train] - Train Epoch: [17] [115200/1281167 (9%)]	Loss: 1.551228
[2022-06-08 07:37:37 | train] - Train Epoch: [17] [128000/1281167 (10%)]	Loss: 1.786097
[2022-06-08 07:38:00 | train] - Train Epoch: [17] [140800/1281167 (11%)]	Loss: 1.695719
[2022-06-08 07:38:22 | train] - Train Epoch: [17] [153600/1281167 (12%)]	Loss: 1.569275
[2022-06-08 07:38:44 | train] - Train Epoch: [17] [166400/1281167 (13%)]	Loss: 2.014121
[2022-06-08 07:39:06 | train] - Train Epoch: [17] [179200/1281167 (14%)]	Loss: 1.383491
[2022-06-08 07:39:29 | train] - Train Epoch: [17] [192000/1281167 (15%)]	Loss: 1.977151
[2022-06-08 07:39:50 | train] - Train Epoch: [17] [204800/1281167 (16%)]	Loss: 1.691089
[2022-06-08 07:40:12 | train] - Train Epoch: [17] [217600/1281167 (17%)]	Loss: 1.909912
[2022-06-08 07:40:34 | train] - Train Epoch: [17] [230400/1281167 (18%)]	Loss: 1.804989
[2022-06-08 07:40:56 | train] - Train Epoch: [17] [243200/1281167 (19%)]	Loss: 1.731392
[2022-06-08 07:41:17 | train] - Train Epoch: [17] [256000/1281167 (20%)]	Loss: 1.645486
[2022-06-08 07:41:40 | train] - Train Epoch: [17] [268800/1281167 (21%)]	Loss: 2.024892
[2022-06-08 07:42:01 | train] - Train Epoch: [17] [281600/1281167 (22%)]	Loss: 1.957008
[2022-06-08 07:42:23 | train] - Train Epoch: [17] [294400/1281167 (23%)]	Loss: 1.650066
[2022-06-08 07:42:44 | train] - Train Epoch: [17] [307200/1281167 (24%)]	Loss: 1.946182
[2022-06-08 07:43:05 | train] - Train Epoch: [17] [320000/1281167 (25%)]	Loss: 1.951513
[2022-06-08 07:43:27 | train] - Train Epoch: [17] [332800/1281167 (26%)]	Loss: 2.068996
[2022-06-08 07:43:49 | train] - Train Epoch: [17] [345600/1281167 (27%)]	Loss: 1.935600
[2022-06-08 07:44:11 | train] - Train Epoch: [17] [358400/1281167 (28%)]	Loss: 1.757033
[2022-06-08 07:44:32 | train] - Train Epoch: [17] [371200/1281167 (29%)]	Loss: 1.995178
[2022-06-08 07:44:54 | train] - Train Epoch: [17] [384000/1281167 (30%)]	Loss: 1.488015
[2022-06-08 07:45:16 | train] - Train Epoch: [17] [396800/1281167 (31%)]	Loss: 1.634717
[2022-06-08 07:45:38 | train] - Train Epoch: [17] [409600/1281167 (32%)]	Loss: 1.561563
[2022-06-08 07:46:01 | train] - Train Epoch: [17] [422400/1281167 (33%)]	Loss: 1.712133
[2022-06-08 07:46:23 | train] - Train Epoch: [17] [435200/1281167 (34%)]	Loss: 2.179999
[2022-06-08 07:46:44 | train] - Train Epoch: [17] [448000/1281167 (35%)]	Loss: 2.009729
[2022-06-08 07:47:06 | train] - Train Epoch: [17] [460800/1281167 (36%)]	Loss: 1.860274
[2022-06-08 07:47:28 | train] - Train Epoch: [17] [473600/1281167 (37%)]	Loss: 1.627787
[2022-06-08 07:47:50 | train] - Train Epoch: [17] [486400/1281167 (38%)]	Loss: 1.641098
[2022-06-08 07:48:12 | train] - Train Epoch: [17] [499200/1281167 (39%)]	Loss: 1.849948
[2022-06-08 07:48:35 | train] - Train Epoch: [17] [512000/1281167 (40%)]	Loss: 2.238145
[2022-06-08 07:48:56 | train] - Train Epoch: [17] [524800/1281167 (41%)]	Loss: 1.633814
[2022-06-08 07:49:18 | train] - Train Epoch: [17] [537600/1281167 (42%)]	Loss: 1.550564
[2022-06-08 07:49:39 | train] - Train Epoch: [17] [550400/1281167 (43%)]	Loss: 2.091475
[2022-06-08 07:50:00 | train] - Train Epoch: [17] [563200/1281167 (44%)]	Loss: 1.893799
[2022-06-08 07:50:22 | train] - Train Epoch: [17] [576000/1281167 (45%)]	Loss: 1.763894
[2022-06-08 07:50:45 | train] - Train Epoch: [17] [588800/1281167 (46%)]	Loss: 1.523891
[2022-06-08 07:51:07 | train] - Train Epoch: [17] [601600/1281167 (47%)]	Loss: 1.770354
[2022-06-08 07:51:29 | train] - Train Epoch: [17] [614400/1281167 (48%)]	Loss: 2.079751
[2022-06-08 07:51:51 | train] - Train Epoch: [17] [627200/1281167 (49%)]	Loss: 1.836985
[2022-06-08 07:52:13 | train] - Train Epoch: [17] [640000/1281167 (50%)]	Loss: 1.799983
[2022-06-08 07:52:35 | train] - Train Epoch: [17] [652800/1281167 (51%)]	Loss: 2.198066
[2022-06-08 07:52:57 | train] - Train Epoch: [17] [665600/1281167 (52%)]	Loss: 1.677520
[2022-06-08 07:53:19 | train] - Train Epoch: [17] [678400/1281167 (53%)]	Loss: 1.563136
[2022-06-08 07:53:41 | train] - Train Epoch: [17] [691200/1281167 (54%)]	Loss: 2.011456
[2022-06-08 07:54:03 | train] - Train Epoch: [17] [704000/1281167 (55%)]	Loss: 1.465587
[2022-06-08 07:54:24 | train] - Train Epoch: [17] [716800/1281167 (56%)]	Loss: 1.683018
[2022-06-08 07:54:46 | train] - Train Epoch: [17] [729600/1281167 (57%)]	Loss: 1.806730
[2022-06-08 07:55:08 | train] - Train Epoch: [17] [742400/1281167 (58%)]	Loss: 1.692452
[2022-06-08 07:55:30 | train] - Train Epoch: [17] [755200/1281167 (59%)]	Loss: 1.908949
[2022-06-08 07:55:52 | train] - Train Epoch: [17] [768000/1281167 (60%)]	Loss: 1.808866
[2022-06-08 07:56:13 | train] - Train Epoch: [17] [780800/1281167 (61%)]	Loss: 1.724110
[2022-06-08 07:56:35 | train] - Train Epoch: [17] [793600/1281167 (62%)]	Loss: 1.514640
[2022-06-08 07:56:57 | train] - Train Epoch: [17] [806400/1281167 (63%)]	Loss: 1.686725
[2022-06-08 07:57:18 | train] - Train Epoch: [17] [819200/1281167 (64%)]	Loss: 2.116838
[2022-06-08 07:57:41 | train] - Train Epoch: [17] [832000/1281167 (65%)]	Loss: 1.756034
[2022-06-08 07:58:03 | train] - Train Epoch: [17] [844800/1281167 (66%)]	Loss: 1.990270
[2022-06-08 07:58:25 | train] - Train Epoch: [17] [857600/1281167 (67%)]	Loss: 1.805569
[2022-06-08 07:58:47 | train] - Train Epoch: [17] [870400/1281167 (68%)]	Loss: 1.455026
[2022-06-08 07:59:09 | train] - Train Epoch: [17] [883200/1281167 (69%)]	Loss: 1.861136
[2022-06-08 07:59:31 | train] - Train Epoch: [17] [896000/1281167 (70%)]	Loss: 1.781465
[2022-06-08 07:59:53 | train] - Train Epoch: [17] [908800/1281167 (71%)]	Loss: 1.954711
[2022-06-08 08:00:15 | train] - Train Epoch: [17] [921600/1281167 (72%)]	Loss: 1.793209
[2022-06-08 08:00:36 | train] - Train Epoch: [17] [934400/1281167 (73%)]	Loss: 1.680528
[2022-06-08 08:00:58 | train] - Train Epoch: [17] [947200/1281167 (74%)]	Loss: 1.928397
[2022-06-08 08:01:20 | train] - Train Epoch: [17] [960000/1281167 (75%)]	Loss: 1.741085
[2022-06-08 08:01:42 | train] - Train Epoch: [17] [972800/1281167 (76%)]	Loss: 1.969159
[2022-06-08 08:02:04 | train] - Train Epoch: [17] [985600/1281167 (77%)]	Loss: 1.830087
[2022-06-08 08:02:25 | train] - Train Epoch: [17] [998400/1281167 (78%)]	Loss: 1.490095
[2022-06-08 08:02:48 | train] - Train Epoch: [17] [1011200/1281167 (79%)]	Loss: 1.867123
[2022-06-08 08:03:09 | train] - Train Epoch: [17] [1024000/1281167 (80%)]	Loss: 1.559967
[2022-06-08 08:03:31 | train] - Train Epoch: [17] [1036800/1281167 (81%)]	Loss: 1.691024
[2022-06-08 08:03:53 | train] - Train Epoch: [17] [1049600/1281167 (82%)]	Loss: 1.737936
[2022-06-08 08:04:15 | train] - Train Epoch: [17] [1062400/1281167 (83%)]	Loss: 1.980444
[2022-06-08 08:04:37 | train] - Train Epoch: [17] [1075200/1281167 (84%)]	Loss: 1.833862
[2022-06-08 08:04:59 | train] - Train Epoch: [17] [1088000/1281167 (85%)]	Loss: 1.930557
[2022-06-08 08:05:21 | train] - Train Epoch: [17] [1100800/1281167 (86%)]	Loss: 2.095553
[2022-06-08 08:05:44 | train] - Train Epoch: [17] [1113600/1281167 (87%)]	Loss: 1.971649
[2022-06-08 08:06:05 | train] - Train Epoch: [17] [1126400/1281167 (88%)]	Loss: 1.540945
[2022-06-08 08:06:27 | train] - Train Epoch: [17] [1139200/1281167 (89%)]	Loss: 1.721318
[2022-06-08 08:06:49 | train] - Train Epoch: [17] [1152000/1281167 (90%)]	Loss: 1.920500
[2022-06-08 08:07:10 | train] - Train Epoch: [17] [1164800/1281167 (91%)]	Loss: 1.511974
[2022-06-08 08:07:32 | train] - Train Epoch: [17] [1177600/1281167 (92%)]	Loss: 1.561784
[2022-06-08 08:07:55 | train] - Train Epoch: [17] [1190400/1281167 (93%)]	Loss: 1.692254
[2022-06-08 08:08:16 | train] - Train Epoch: [17] [1203200/1281167 (94%)]	Loss: 1.683134
[2022-06-08 08:08:39 | train] - Train Epoch: [17] [1216000/1281167 (95%)]	Loss: 1.679591
[2022-06-08 08:09:01 | train] - Train Epoch: [17] [1228800/1281167 (96%)]	Loss: 1.988152
[2022-06-08 08:09:23 | train] - Train Epoch: [17] [1241600/1281167 (97%)]	Loss: 2.193308
[2022-06-08 08:09:45 | train] - Train Epoch: [17] [1254400/1281167 (98%)]	Loss: 1.611335
[2022-06-08 08:10:07 | train] - Train Epoch: [17] [1267200/1281167 (99%)]	Loss: 1.894022
[2022-06-08 08:10:28 | train] - Train Epoch: [17] [1280000/1281167 (100%)]	Loss: 1.668618
[2022-06-08 08:10:30 | train] - Train Epoch: [17]	 Average Loss: 1.800057	 Total Acc : 58.6714	 Total Top5 Acc : 80.4093
[2022-06-08 08:10:30 | train] - -------17 epoch end-----------
========================================
-------17 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 08:12:04 | train] - 
Epoch [17] Test set: Average loss: 1.6148, Accuracy: 30772/50000 (61.5066%), Top-5 Accuracy: 84.0885%

[2022-06-08 08:12:04 | train] - save intermediate epoch [17] result


[2022-06-08 08:12:07 | train] - logging best performance 17 epoch
[2022-06-08 08:12:08 | train] - -------18 epoch start-----------
========================================
----- test end -------------------------


logging best performance 17 epoch
[2022-06-08 08:12:10 | train] - Train Epoch: [18] [0/1281167 (0%)]	Loss: 1.715947
[2022-06-08 08:12:32 | train] - Train Epoch: [18] [12800/1281167 (1%)]	Loss: 1.905692
[2022-06-08 08:12:54 | train] - Train Epoch: [18] [25600/1281167 (2%)]	Loss: 1.918820
[2022-06-08 08:13:16 | train] - Train Epoch: [18] [38400/1281167 (3%)]	Loss: 1.722345
[2022-06-08 08:13:38 | train] - Train Epoch: [18] [51200/1281167 (4%)]	Loss: 1.784795
[2022-06-08 08:14:00 | train] - Train Epoch: [18] [64000/1281167 (5%)]	Loss: 1.744654
[2022-06-08 08:14:22 | train] - Train Epoch: [18] [76800/1281167 (6%)]	Loss: 1.567042
[2022-06-08 08:14:44 | train] - Train Epoch: [18] [89600/1281167 (7%)]	Loss: 1.776269
[2022-06-08 08:15:06 | train] - Train Epoch: [18] [102400/1281167 (8%)]	Loss: 1.505848
[2022-06-08 08:15:29 | train] - Train Epoch: [18] [115200/1281167 (9%)]	Loss: 1.811309
[2022-06-08 08:15:51 | train] - Train Epoch: [18] [128000/1281167 (10%)]	Loss: 2.009157
[2022-06-08 08:16:13 | train] - Train Epoch: [18] [140800/1281167 (11%)]	Loss: 1.983430
[2022-06-08 08:16:35 | train] - Train Epoch: [18] [153600/1281167 (12%)]	Loss: 1.794322
[2022-06-08 08:16:57 | train] - Train Epoch: [18] [166400/1281167 (13%)]	Loss: 1.929470
[2022-06-08 08:17:19 | train] - Train Epoch: [18] [179200/1281167 (14%)]	Loss: 1.659427
[2022-06-08 08:17:41 | train] - Train Epoch: [18] [192000/1281167 (15%)]	Loss: 1.711474
[2022-06-08 08:18:03 | train] - Train Epoch: [18] [204800/1281167 (16%)]	Loss: 1.986496
[2022-06-08 08:18:25 | train] - Train Epoch: [18] [217600/1281167 (17%)]	Loss: 1.836682
[2022-06-08 08:18:47 | train] - Train Epoch: [18] [230400/1281167 (18%)]	Loss: 1.912304
[2022-06-08 08:19:08 | train] - Train Epoch: [18] [243200/1281167 (19%)]	Loss: 1.597539
[2022-06-08 08:19:30 | train] - Train Epoch: [18] [256000/1281167 (20%)]	Loss: 1.668740
[2022-06-08 08:19:53 | train] - Train Epoch: [18] [268800/1281167 (21%)]	Loss: 1.522786
[2022-06-08 08:20:15 | train] - Train Epoch: [18] [281600/1281167 (22%)]	Loss: 1.823020
[2022-06-08 08:20:36 | train] - Train Epoch: [18] [294400/1281167 (23%)]	Loss: 1.980573
[2022-06-08 08:20:58 | train] - Train Epoch: [18] [307200/1281167 (24%)]	Loss: 1.764023
[2022-06-08 08:21:20 | train] - Train Epoch: [18] [320000/1281167 (25%)]	Loss: 1.206861
[2022-06-08 08:21:42 | train] - Train Epoch: [18] [332800/1281167 (26%)]	Loss: 2.060070
[2022-06-08 08:22:04 | train] - Train Epoch: [18] [345600/1281167 (27%)]	Loss: 1.780978
[2022-06-08 08:22:26 | train] - Train Epoch: [18] [358400/1281167 (28%)]	Loss: 1.837585
[2022-06-08 08:22:48 | train] - Train Epoch: [18] [371200/1281167 (29%)]	Loss: 2.168382
[2022-06-08 08:23:10 | train] - Train Epoch: [18] [384000/1281167 (30%)]	Loss: 1.746436
[2022-06-08 08:23:32 | train] - Train Epoch: [18] [396800/1281167 (31%)]	Loss: 1.966183
[2022-06-08 08:23:55 | train] - Train Epoch: [18] [409600/1281167 (32%)]	Loss: 2.229963
[2022-06-08 08:24:16 | train] - Train Epoch: [18] [422400/1281167 (33%)]	Loss: 1.697898
[2022-06-08 08:24:38 | train] - Train Epoch: [18] [435200/1281167 (34%)]	Loss: 1.696344
[2022-06-08 08:25:00 | train] - Train Epoch: [18] [448000/1281167 (35%)]	Loss: 1.848791
[2022-06-08 08:25:23 | train] - Train Epoch: [18] [460800/1281167 (36%)]	Loss: 1.914865
[2022-06-08 08:25:45 | train] - Train Epoch: [18] [473600/1281167 (37%)]	Loss: 1.658114
[2022-06-08 08:26:06 | train] - Train Epoch: [18] [486400/1281167 (38%)]	Loss: 1.686820
[2022-06-08 08:26:28 | train] - Train Epoch: [18] [499200/1281167 (39%)]	Loss: 1.744328
[2022-06-08 08:26:49 | train] - Train Epoch: [18] [512000/1281167 (40%)]	Loss: 1.596931
[2022-06-08 08:27:10 | train] - Train Epoch: [18] [524800/1281167 (41%)]	Loss: 1.553139
[2022-06-08 08:27:32 | train] - Train Epoch: [18] [537600/1281167 (42%)]	Loss: 1.765870
[2022-06-08 08:27:54 | train] - Train Epoch: [18] [550400/1281167 (43%)]	Loss: 1.771012
[2022-06-08 08:28:16 | train] - Train Epoch: [18] [563200/1281167 (44%)]	Loss: 1.947092
[2022-06-08 08:28:37 | train] - Train Epoch: [18] [576000/1281167 (45%)]	Loss: 1.745000
[2022-06-08 08:29:00 | train] - Train Epoch: [18] [588800/1281167 (46%)]	Loss: 1.803377
[2022-06-08 08:29:22 | train] - Train Epoch: [18] [601600/1281167 (47%)]	Loss: 1.572402
[2022-06-08 08:29:44 | train] - Train Epoch: [18] [614400/1281167 (48%)]	Loss: 1.997959
[2022-06-08 08:30:06 | train] - Train Epoch: [18] [627200/1281167 (49%)]	Loss: 1.628133
[2022-06-08 08:30:28 | train] - Train Epoch: [18] [640000/1281167 (50%)]	Loss: 1.665390
[2022-06-08 08:30:50 | train] - Train Epoch: [18] [652800/1281167 (51%)]	Loss: 2.301904
[2022-06-08 08:31:12 | train] - Train Epoch: [18] [665600/1281167 (52%)]	Loss: 1.730187
[2022-06-08 08:31:34 | train] - Train Epoch: [18] [678400/1281167 (53%)]	Loss: 1.911474
[2022-06-08 08:31:56 | train] - Train Epoch: [18] [691200/1281167 (54%)]	Loss: 1.409082
[2022-06-08 08:32:19 | train] - Train Epoch: [18] [704000/1281167 (55%)]	Loss: 2.028429
[2022-06-08 08:32:41 | train] - Train Epoch: [18] [716800/1281167 (56%)]	Loss: 1.791230
[2022-06-08 08:33:03 | train] - Train Epoch: [18] [729600/1281167 (57%)]	Loss: 1.538044
[2022-06-08 08:33:25 | train] - Train Epoch: [18] [742400/1281167 (58%)]	Loss: 1.699539
[2022-06-08 08:33:46 | train] - Train Epoch: [18] [755200/1281167 (59%)]	Loss: 1.611791
[2022-06-08 08:34:07 | train] - Train Epoch: [18] [768000/1281167 (60%)]	Loss: 1.587647
[2022-06-08 08:34:29 | train] - Train Epoch: [18] [780800/1281167 (61%)]	Loss: 1.608433
[2022-06-08 08:34:51 | train] - Train Epoch: [18] [793600/1281167 (62%)]	Loss: 1.770330
[2022-06-08 08:35:14 | train] - Train Epoch: [18] [806400/1281167 (63%)]	Loss: 1.713627
[2022-06-08 08:35:35 | train] - Train Epoch: [18] [819200/1281167 (64%)]	Loss: 1.604488
[2022-06-08 08:35:57 | train] - Train Epoch: [18] [832000/1281167 (65%)]	Loss: 2.028700
[2022-06-08 08:36:19 | train] - Train Epoch: [18] [844800/1281167 (66%)]	Loss: 1.563294
[2022-06-08 08:36:41 | train] - Train Epoch: [18] [857600/1281167 (67%)]	Loss: 1.803217
[2022-06-08 08:37:03 | train] - Train Epoch: [18] [870400/1281167 (68%)]	Loss: 1.820914
[2022-06-08 08:37:25 | train] - Train Epoch: [18] [883200/1281167 (69%)]	Loss: 1.593022
[2022-06-08 08:37:47 | train] - Train Epoch: [18] [896000/1281167 (70%)]	Loss: 1.484365
[2022-06-08 08:38:10 | train] - Train Epoch: [18] [908800/1281167 (71%)]	Loss: 1.996965
[2022-06-08 08:38:31 | train] - Train Epoch: [18] [921600/1281167 (72%)]	Loss: 2.010488
[2022-06-08 08:38:53 | train] - Train Epoch: [18] [934400/1281167 (73%)]	Loss: 1.626731
[2022-06-08 08:39:15 | train] - Train Epoch: [18] [947200/1281167 (74%)]	Loss: 1.981290
[2022-06-08 08:39:36 | train] - Train Epoch: [18] [960000/1281167 (75%)]	Loss: 1.942358
[2022-06-08 08:39:58 | train] - Train Epoch: [18] [972800/1281167 (76%)]	Loss: 1.911622
[2022-06-08 08:40:19 | train] - Train Epoch: [18] [985600/1281167 (77%)]	Loss: 1.565778
[2022-06-08 08:40:42 | train] - Train Epoch: [18] [998400/1281167 (78%)]	Loss: 1.703897
[2022-06-08 08:41:03 | train] - Train Epoch: [18] [1011200/1281167 (79%)]	Loss: 1.921166
[2022-06-08 08:41:24 | train] - Train Epoch: [18] [1024000/1281167 (80%)]	Loss: 1.683512
[2022-06-08 08:41:46 | train] - Train Epoch: [18] [1036800/1281167 (81%)]	Loss: 2.236192
[2022-06-08 08:42:08 | train] - Train Epoch: [18] [1049600/1281167 (82%)]	Loss: 1.962277
[2022-06-08 08:42:30 | train] - Train Epoch: [18] [1062400/1281167 (83%)]	Loss: 1.927349
[2022-06-08 08:42:52 | train] - Train Epoch: [18] [1075200/1281167 (84%)]	Loss: 2.021254
[2022-06-08 08:43:13 | train] - Train Epoch: [18] [1088000/1281167 (85%)]	Loss: 1.838158
[2022-06-08 08:43:35 | train] - Train Epoch: [18] [1100800/1281167 (86%)]	Loss: 2.080253
[2022-06-08 08:43:57 | train] - Train Epoch: [18] [1113600/1281167 (87%)]	Loss: 1.752462
[2022-06-08 08:44:20 | train] - Train Epoch: [18] [1126400/1281167 (88%)]	Loss: 1.720959
[2022-06-08 08:44:42 | train] - Train Epoch: [18] [1139200/1281167 (89%)]	Loss: 1.978926
[2022-06-08 08:45:03 | train] - Train Epoch: [18] [1152000/1281167 (90%)]	Loss: 1.544059
[2022-06-08 08:45:24 | train] - Train Epoch: [18] [1164800/1281167 (91%)]	Loss: 1.656764
[2022-06-08 08:45:46 | train] - Train Epoch: [18] [1177600/1281167 (92%)]	Loss: 1.742447
[2022-06-08 08:46:08 | train] - Train Epoch: [18] [1190400/1281167 (93%)]	Loss: 1.927893
[2022-06-08 08:46:31 | train] - Train Epoch: [18] [1203200/1281167 (94%)]	Loss: 1.847392
[2022-06-08 08:46:53 | train] - Train Epoch: [18] [1216000/1281167 (95%)]	Loss: 1.650097
[2022-06-08 08:47:14 | train] - Train Epoch: [18] [1228800/1281167 (96%)]	Loss: 1.798772
[2022-06-08 08:47:37 | train] - Train Epoch: [18] [1241600/1281167 (97%)]	Loss: 1.824091
[2022-06-08 08:47:59 | train] - Train Epoch: [18] [1254400/1281167 (98%)]	Loss: 1.568766
[2022-06-08 08:48:22 | train] - Train Epoch: [18] [1267200/1281167 (99%)]	Loss: 1.805157
[2022-06-08 08:48:43 | train] - Train Epoch: [18] [1280000/1281167 (100%)]	Loss: 1.725230
[2022-06-08 08:48:45 | train] - Train Epoch: [18]	 Average Loss: 1.760800	 Total Acc : 59.4787	 Total Top5 Acc : 80.9768
[2022-06-08 08:48:45 | train] - -------18 epoch end-----------
========================================
-------18 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 08:50:19 | train] - 
Epoch [18] Test set: Average loss: 1.5918, Accuracy: 31128/50000 (62.2215%), Top-5 Accuracy: 84.3694%

[2022-06-08 08:50:19 | train] - save intermediate epoch [18] result


[2022-06-08 08:50:22 | train] - logging best performance 18 epoch
[2022-06-08 08:50:23 | train] - -------19 epoch start-----------
========================================
----- test end -------------------------


logging best performance 18 epoch
[2022-06-08 08:50:25 | train] - Train Epoch: [19] [0/1281167 (0%)]	Loss: 1.692914
[2022-06-08 08:50:46 | train] - Train Epoch: [19] [12800/1281167 (1%)]	Loss: 1.977862
[2022-06-08 08:51:07 | train] - Train Epoch: [19] [25600/1281167 (2%)]	Loss: 1.604987
[2022-06-08 08:51:29 | train] - Train Epoch: [19] [38400/1281167 (3%)]	Loss: 1.538085
[2022-06-08 08:51:51 | train] - Train Epoch: [19] [51200/1281167 (4%)]	Loss: 1.760408
[2022-06-08 08:52:12 | train] - Train Epoch: [19] [64000/1281167 (5%)]	Loss: 1.825380
[2022-06-08 08:52:34 | train] - Train Epoch: [19] [76800/1281167 (6%)]	Loss: 1.567261
[2022-06-08 08:52:56 | train] - Train Epoch: [19] [89600/1281167 (7%)]	Loss: 1.819975
[2022-06-08 08:53:17 | train] - Train Epoch: [19] [102400/1281167 (8%)]	Loss: 1.640376
[2022-06-08 08:53:40 | train] - Train Epoch: [19] [115200/1281167 (9%)]	Loss: 1.535892
[2022-06-08 08:54:01 | train] - Train Epoch: [19] [128000/1281167 (10%)]	Loss: 1.458875
[2022-06-08 08:54:23 | train] - Train Epoch: [19] [140800/1281167 (11%)]	Loss: 1.651699
[2022-06-08 08:54:45 | train] - Train Epoch: [19] [153600/1281167 (12%)]	Loss: 2.186752
[2022-06-08 08:55:07 | train] - Train Epoch: [19] [166400/1281167 (13%)]	Loss: 1.668396
[2022-06-08 08:55:28 | train] - Train Epoch: [19] [179200/1281167 (14%)]	Loss: 1.776335
[2022-06-08 08:55:49 | train] - Train Epoch: [19] [192000/1281167 (15%)]	Loss: 2.144524
[2022-06-08 08:56:11 | train] - Train Epoch: [19] [204800/1281167 (16%)]	Loss: 1.938750
[2022-06-08 08:56:33 | train] - Train Epoch: [19] [217600/1281167 (17%)]	Loss: 1.940202
[2022-06-08 08:56:54 | train] - Train Epoch: [19] [230400/1281167 (18%)]	Loss: 2.120307
[2022-06-08 08:57:16 | train] - Train Epoch: [19] [243200/1281167 (19%)]	Loss: 1.822892
[2022-06-08 08:57:37 | train] - Train Epoch: [19] [256000/1281167 (20%)]	Loss: 1.907731
[2022-06-08 08:57:59 | train] - Train Epoch: [19] [268800/1281167 (21%)]	Loss: 1.247678
[2022-06-08 08:58:21 | train] - Train Epoch: [19] [281600/1281167 (22%)]	Loss: 1.797912
[2022-06-08 08:58:41 | train] - Train Epoch: [19] [294400/1281167 (23%)]	Loss: 1.585683
[2022-06-08 08:59:02 | train] - Train Epoch: [19] [307200/1281167 (24%)]	Loss: 1.357190
[2022-06-08 08:59:24 | train] - Train Epoch: [19] [320000/1281167 (25%)]	Loss: 1.806513
[2022-06-08 08:59:45 | train] - Train Epoch: [19] [332800/1281167 (26%)]	Loss: 1.698101
[2022-06-08 09:00:06 | train] - Train Epoch: [19] [345600/1281167 (27%)]	Loss: 1.655404
[2022-06-08 09:00:28 | train] - Train Epoch: [19] [358400/1281167 (28%)]	Loss: 1.776960
[2022-06-08 09:00:50 | train] - Train Epoch: [19] [371200/1281167 (29%)]	Loss: 1.472746
[2022-06-08 09:01:11 | train] - Train Epoch: [19] [384000/1281167 (30%)]	Loss: 1.945993
[2022-06-08 09:01:32 | train] - Train Epoch: [19] [396800/1281167 (31%)]	Loss: 1.931802
[2022-06-08 09:01:54 | train] - Train Epoch: [19] [409600/1281167 (32%)]	Loss: 1.922701
[2022-06-08 09:02:16 | train] - Train Epoch: [19] [422400/1281167 (33%)]	Loss: 1.679125
[2022-06-08 09:02:38 | train] - Train Epoch: [19] [435200/1281167 (34%)]	Loss: 1.888747
[2022-06-08 09:03:00 | train] - Train Epoch: [19] [448000/1281167 (35%)]	Loss: 1.872416
[2022-06-08 09:03:21 | train] - Train Epoch: [19] [460800/1281167 (36%)]	Loss: 1.400665
[2022-06-08 09:03:43 | train] - Train Epoch: [19] [473600/1281167 (37%)]	Loss: 1.487211
[2022-06-08 09:04:04 | train] - Train Epoch: [19] [486400/1281167 (38%)]	Loss: 1.815275
[2022-06-08 09:04:26 | train] - Train Epoch: [19] [499200/1281167 (39%)]	Loss: 1.658058
[2022-06-08 09:04:47 | train] - Train Epoch: [19] [512000/1281167 (40%)]	Loss: 1.511135
[2022-06-08 09:05:09 | train] - Train Epoch: [19] [524800/1281167 (41%)]	Loss: 2.229872
[2022-06-08 09:05:31 | train] - Train Epoch: [19] [537600/1281167 (42%)]	Loss: 1.661872
[2022-06-08 09:05:53 | train] - Train Epoch: [19] [550400/1281167 (43%)]	Loss: 1.602915
[2022-06-08 09:06:14 | train] - Train Epoch: [19] [563200/1281167 (44%)]	Loss: 1.934130
[2022-06-08 09:06:36 | train] - Train Epoch: [19] [576000/1281167 (45%)]	Loss: 1.750252
[2022-06-08 09:06:57 | train] - Train Epoch: [19] [588800/1281167 (46%)]	Loss: 2.063744
[2022-06-08 09:07:18 | train] - Train Epoch: [19] [601600/1281167 (47%)]	Loss: 1.639864
[2022-06-08 09:07:40 | train] - Train Epoch: [19] [614400/1281167 (48%)]	Loss: 1.448061
[2022-06-08 09:08:01 | train] - Train Epoch: [19] [627200/1281167 (49%)]	Loss: 1.862730
[2022-06-08 09:08:23 | train] - Train Epoch: [19] [640000/1281167 (50%)]	Loss: 1.920997
[2022-06-08 09:08:44 | train] - Train Epoch: [19] [652800/1281167 (51%)]	Loss: 1.765037
[2022-06-08 09:09:06 | train] - Train Epoch: [19] [665600/1281167 (52%)]	Loss: 1.441063
[2022-06-08 09:09:27 | train] - Train Epoch: [19] [678400/1281167 (53%)]	Loss: 1.905061
[2022-06-08 09:09:48 | train] - Train Epoch: [19] [691200/1281167 (54%)]	Loss: 1.809069
[2022-06-08 09:10:10 | train] - Train Epoch: [19] [704000/1281167 (55%)]	Loss: 1.762312
[2022-06-08 09:10:31 | train] - Train Epoch: [19] [716800/1281167 (56%)]	Loss: 1.453589
[2022-06-08 09:10:53 | train] - Train Epoch: [19] [729600/1281167 (57%)]	Loss: 2.080126
[2022-06-08 09:11:14 | train] - Train Epoch: [19] [742400/1281167 (58%)]	Loss: 1.775647
[2022-06-08 09:11:36 | train] - Train Epoch: [19] [755200/1281167 (59%)]	Loss: 1.436243
[2022-06-08 09:11:58 | train] - Train Epoch: [19] [768000/1281167 (60%)]	Loss: 1.870875
[2022-06-08 09:12:19 | train] - Train Epoch: [19] [780800/1281167 (61%)]	Loss: 1.402937
[2022-06-08 09:12:40 | train] - Train Epoch: [19] [793600/1281167 (62%)]	Loss: 1.756864
[2022-06-08 09:13:02 | train] - Train Epoch: [19] [806400/1281167 (63%)]	Loss: 1.690583
[2022-06-08 09:13:23 | train] - Train Epoch: [19] [819200/1281167 (64%)]	Loss: 1.854303
[2022-06-08 09:13:45 | train] - Train Epoch: [19] [832000/1281167 (65%)]	Loss: 1.622945
[2022-06-08 09:14:06 | train] - Train Epoch: [19] [844800/1281167 (66%)]	Loss: 1.619040
[2022-06-08 09:14:28 | train] - Train Epoch: [19] [857600/1281167 (67%)]	Loss: 1.672184
[2022-06-08 09:14:50 | train] - Train Epoch: [19] [870400/1281167 (68%)]	Loss: 1.593467
[2022-06-08 09:15:10 | train] - Train Epoch: [19] [883200/1281167 (69%)]	Loss: 1.907751
[2022-06-08 09:15:32 | train] - Train Epoch: [19] [896000/1281167 (70%)]	Loss: 1.544809
[2022-06-08 09:15:54 | train] - Train Epoch: [19] [908800/1281167 (71%)]	Loss: 1.412231
[2022-06-08 09:16:16 | train] - Train Epoch: [19] [921600/1281167 (72%)]	Loss: 1.593568
[2022-06-08 09:16:38 | train] - Train Epoch: [19] [934400/1281167 (73%)]	Loss: 1.633854
[2022-06-08 09:16:59 | train] - Train Epoch: [19] [947200/1281167 (74%)]	Loss: 1.607242
[2022-06-08 09:17:21 | train] - Train Epoch: [19] [960000/1281167 (75%)]	Loss: 1.619686
[2022-06-08 09:17:43 | train] - Train Epoch: [19] [972800/1281167 (76%)]	Loss: 1.591728
[2022-06-08 09:18:04 | train] - Train Epoch: [19] [985600/1281167 (77%)]	Loss: 1.488007
[2022-06-08 09:18:25 | train] - Train Epoch: [19] [998400/1281167 (78%)]	Loss: 1.700650
[2022-06-08 09:18:47 | train] - Train Epoch: [19] [1011200/1281167 (79%)]	Loss: 1.675565
[2022-06-08 09:19:09 | train] - Train Epoch: [19] [1024000/1281167 (80%)]	Loss: 1.841663
[2022-06-08 09:19:30 | train] - Train Epoch: [19] [1036800/1281167 (81%)]	Loss: 1.666013
[2022-06-08 09:19:53 | train] - Train Epoch: [19] [1049600/1281167 (82%)]	Loss: 1.974887
[2022-06-08 09:20:14 | train] - Train Epoch: [19] [1062400/1281167 (83%)]	Loss: 1.870949
[2022-06-08 09:20:35 | train] - Train Epoch: [19] [1075200/1281167 (84%)]	Loss: 1.803661
[2022-06-08 09:20:57 | train] - Train Epoch: [19] [1088000/1281167 (85%)]	Loss: 1.817269
[2022-06-08 09:21:18 | train] - Train Epoch: [19] [1100800/1281167 (86%)]	Loss: 1.746649
[2022-06-08 09:21:40 | train] - Train Epoch: [19] [1113600/1281167 (87%)]	Loss: 1.885295
[2022-06-08 09:22:01 | train] - Train Epoch: [19] [1126400/1281167 (88%)]	Loss: 1.791513
[2022-06-08 09:22:23 | train] - Train Epoch: [19] [1139200/1281167 (89%)]	Loss: 1.832917
[2022-06-08 09:22:45 | train] - Train Epoch: [19] [1152000/1281167 (90%)]	Loss: 1.365192
[2022-06-08 09:23:06 | train] - Train Epoch: [19] [1164800/1281167 (91%)]	Loss: 1.715238
[2022-06-08 09:23:28 | train] - Train Epoch: [19] [1177600/1281167 (92%)]	Loss: 1.991724
[2022-06-08 09:23:49 | train] - Train Epoch: [19] [1190400/1281167 (93%)]	Loss: 1.614890
[2022-06-08 09:24:11 | train] - Train Epoch: [19] [1203200/1281167 (94%)]	Loss: 1.804244
[2022-06-08 09:24:33 | train] - Train Epoch: [19] [1216000/1281167 (95%)]	Loss: 1.822887
[2022-06-08 09:24:55 | train] - Train Epoch: [19] [1228800/1281167 (96%)]	Loss: 2.029301
[2022-06-08 09:25:17 | train] - Train Epoch: [19] [1241600/1281167 (97%)]	Loss: 1.560275
[2022-06-08 09:25:38 | train] - Train Epoch: [19] [1254400/1281167 (98%)]	Loss: 1.478635
[2022-06-08 09:26:00 | train] - Train Epoch: [19] [1267200/1281167 (99%)]	Loss: 1.602206
[2022-06-08 09:26:22 | train] - Train Epoch: [19] [1280000/1281167 (100%)]	Loss: 1.704696
[2022-06-08 09:26:24 | train] - Train Epoch: [19]	 Average Loss: 1.763351	 Total Acc : 59.4266	 Total Top5 Acc : 80.9717
[2022-06-08 09:26:24 | train] - -------19 epoch end-----------
========================================
-------19 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 09:27:57 | train] - 
Epoch [19] Test set: Average loss: 1.5685, Accuracy: 31283/50000 (62.5204%), Top-5 Accuracy: 84.5668%

[2022-06-08 09:27:57 | train] - save intermediate epoch [19] result


[2022-06-08 09:28:01 | train] - logging best performance 19 epoch
[2022-06-08 09:28:02 | train] - -------20 epoch start-----------
========================================
----- test end -------------------------


logging best performance 19 epoch
[2022-06-08 09:28:04 | train] - Train Epoch: [20] [0/1281167 (0%)]	Loss: 1.599721
[2022-06-08 09:28:26 | train] - Train Epoch: [20] [12800/1281167 (1%)]	Loss: 1.263499
[2022-06-08 09:28:48 | train] - Train Epoch: [20] [25600/1281167 (2%)]	Loss: 1.624146
[2022-06-08 09:29:10 | train] - Train Epoch: [20] [38400/1281167 (3%)]	Loss: 1.870816
[2022-06-08 09:29:31 | train] - Train Epoch: [20] [51200/1281167 (4%)]	Loss: 1.830967
[2022-06-08 09:29:53 | train] - Train Epoch: [20] [64000/1281167 (5%)]	Loss: 1.948510
[2022-06-08 09:30:15 | train] - Train Epoch: [20] [76800/1281167 (6%)]	Loss: 1.623368
[2022-06-08 09:30:37 | train] - Train Epoch: [20] [89600/1281167 (7%)]	Loss: 1.683862
[2022-06-08 09:30:59 | train] - Train Epoch: [20] [102400/1281167 (8%)]	Loss: 1.302813
[2022-06-08 09:31:21 | train] - Train Epoch: [20] [115200/1281167 (9%)]	Loss: 1.429545
[2022-06-08 09:31:43 | train] - Train Epoch: [20] [128000/1281167 (10%)]	Loss: 1.829699
[2022-06-08 09:32:05 | train] - Train Epoch: [20] [140800/1281167 (11%)]	Loss: 1.649145
[2022-06-08 09:32:28 | train] - Train Epoch: [20] [153600/1281167 (12%)]	Loss: 1.524462
[2022-06-08 09:32:49 | train] - Train Epoch: [20] [166400/1281167 (13%)]	Loss: 1.840892
[2022-06-08 09:33:10 | train] - Train Epoch: [20] [179200/1281167 (14%)]	Loss: 1.920851
[2022-06-08 09:33:33 | train] - Train Epoch: [20] [192000/1281167 (15%)]	Loss: 2.063746
[2022-06-08 09:33:55 | train] - Train Epoch: [20] [204800/1281167 (16%)]	Loss: 1.483972
[2022-06-08 09:34:17 | train] - Train Epoch: [20] [217600/1281167 (17%)]	Loss: 1.442351
[2022-06-08 09:34:38 | train] - Train Epoch: [20] [230400/1281167 (18%)]	Loss: 1.559358
[2022-06-08 09:35:00 | train] - Train Epoch: [20] [243200/1281167 (19%)]	Loss: 1.877347
[2022-06-08 09:35:22 | train] - Train Epoch: [20] [256000/1281167 (20%)]	Loss: 1.746478
[2022-06-08 09:35:44 | train] - Train Epoch: [20] [268800/1281167 (21%)]	Loss: 1.573046
[2022-06-08 09:36:06 | train] - Train Epoch: [20] [281600/1281167 (22%)]	Loss: 1.569561
[2022-06-08 09:36:27 | train] - Train Epoch: [20] [294400/1281167 (23%)]	Loss: 1.624632
[2022-06-08 09:36:49 | train] - Train Epoch: [20] [307200/1281167 (24%)]	Loss: 1.624468
[2022-06-08 09:37:12 | train] - Train Epoch: [20] [320000/1281167 (25%)]	Loss: 1.876655
[2022-06-08 09:37:34 | train] - Train Epoch: [20] [332800/1281167 (26%)]	Loss: 1.957791
[2022-06-08 09:37:56 | train] - Train Epoch: [20] [345600/1281167 (27%)]	Loss: 1.691370
[2022-06-08 09:38:17 | train] - Train Epoch: [20] [358400/1281167 (28%)]	Loss: 1.706993
[2022-06-08 09:38:40 | train] - Train Epoch: [20] [371200/1281167 (29%)]	Loss: 1.669226
[2022-06-08 09:39:02 | train] - Train Epoch: [20] [384000/1281167 (30%)]	Loss: 1.819226
[2022-06-08 09:39:24 | train] - Train Epoch: [20] [396800/1281167 (31%)]	Loss: 1.720875
[2022-06-08 09:39:46 | train] - Train Epoch: [20] [409600/1281167 (32%)]	Loss: 2.036880
[2022-06-08 09:40:07 | train] - Train Epoch: [20] [422400/1281167 (33%)]	Loss: 1.926725
[2022-06-08 09:40:29 | train] - Train Epoch: [20] [435200/1281167 (34%)]	Loss: 1.718991
[2022-06-08 09:40:51 | train] - Train Epoch: [20] [448000/1281167 (35%)]	Loss: 1.790567
[2022-06-08 09:41:13 | train] - Train Epoch: [20] [460800/1281167 (36%)]	Loss: 1.611454
[2022-06-08 09:41:35 | train] - Train Epoch: [20] [473600/1281167 (37%)]	Loss: 1.515251
[2022-06-08 09:41:56 | train] - Train Epoch: [20] [486400/1281167 (38%)]	Loss: 1.982640
[2022-06-08 09:42:17 | train] - Train Epoch: [20] [499200/1281167 (39%)]	Loss: 1.706292
[2022-06-08 09:42:40 | train] - Train Epoch: [20] [512000/1281167 (40%)]	Loss: 1.407345
[2022-06-08 09:43:02 | train] - Train Epoch: [20] [524800/1281167 (41%)]	Loss: 1.628741
[2022-06-08 09:43:23 | train] - Train Epoch: [20] [537600/1281167 (42%)]	Loss: 1.885112
[2022-06-08 09:43:44 | train] - Train Epoch: [20] [550400/1281167 (43%)]	Loss: 2.178428
[2022-06-08 09:44:06 | train] - Train Epoch: [20] [563200/1281167 (44%)]	Loss: 1.942006
[2022-06-08 09:44:28 | train] - Train Epoch: [20] [576000/1281167 (45%)]	Loss: 1.536390
[2022-06-08 09:44:50 | train] - Train Epoch: [20] [588800/1281167 (46%)]	Loss: 1.603537
[2022-06-08 09:45:11 | train] - Train Epoch: [20] [601600/1281167 (47%)]	Loss: 1.670932
[2022-06-08 09:45:34 | train] - Train Epoch: [20] [614400/1281167 (48%)]	Loss: 1.623817
[2022-06-08 09:45:55 | train] - Train Epoch: [20] [627200/1281167 (49%)]	Loss: 1.578359
[2022-06-08 09:46:17 | train] - Train Epoch: [20] [640000/1281167 (50%)]	Loss: 1.830833
[2022-06-08 09:46:39 | train] - Train Epoch: [20] [652800/1281167 (51%)]	Loss: 1.374580
[2022-06-08 09:47:01 | train] - Train Epoch: [20] [665600/1281167 (52%)]	Loss: 1.488451
[2022-06-08 09:47:23 | train] - Train Epoch: [20] [678400/1281167 (53%)]	Loss: 1.822288
[2022-06-08 09:47:45 | train] - Train Epoch: [20] [691200/1281167 (54%)]	Loss: 1.821823
[2022-06-08 09:48:06 | train] - Train Epoch: [20] [704000/1281167 (55%)]	Loss: 1.940734
[2022-06-08 09:48:28 | train] - Train Epoch: [20] [716800/1281167 (56%)]	Loss: 1.978281
[2022-06-08 09:48:49 | train] - Train Epoch: [20] [729600/1281167 (57%)]	Loss: 1.341890
[2022-06-08 09:49:11 | train] - Train Epoch: [20] [742400/1281167 (58%)]	Loss: 2.119140
[2022-06-08 09:49:33 | train] - Train Epoch: [20] [755200/1281167 (59%)]	Loss: 1.881848
[2022-06-08 09:49:54 | train] - Train Epoch: [20] [768000/1281167 (60%)]	Loss: 1.696229
[2022-06-08 09:50:16 | train] - Train Epoch: [20] [780800/1281167 (61%)]	Loss: 1.793654
[2022-06-08 09:50:38 | train] - Train Epoch: [20] [793600/1281167 (62%)]	Loss: 1.642664
[2022-06-08 09:51:00 | train] - Train Epoch: [20] [806400/1281167 (63%)]	Loss: 1.296538
[2022-06-08 09:51:22 | train] - Train Epoch: [20] [819200/1281167 (64%)]	Loss: 1.864190
[2022-06-08 09:51:44 | train] - Train Epoch: [20] [832000/1281167 (65%)]	Loss: 1.861195
[2022-06-08 09:52:06 | train] - Train Epoch: [20] [844800/1281167 (66%)]	Loss: 1.616794
[2022-06-08 09:52:28 | train] - Train Epoch: [20] [857600/1281167 (67%)]	Loss: 2.001138
[2022-06-08 09:52:50 | train] - Train Epoch: [20] [870400/1281167 (68%)]	Loss: 1.998577
[2022-06-08 09:53:12 | train] - Train Epoch: [20] [883200/1281167 (69%)]	Loss: 1.891949
[2022-06-08 09:53:34 | train] - Train Epoch: [20] [896000/1281167 (70%)]	Loss: 1.894108
[2022-06-08 09:53:57 | train] - Train Epoch: [20] [908800/1281167 (71%)]	Loss: 2.055453
[2022-06-08 09:54:19 | train] - Train Epoch: [20] [921600/1281167 (72%)]	Loss: 1.744956
[2022-06-08 09:54:40 | train] - Train Epoch: [20] [934400/1281167 (73%)]	Loss: 1.675142
[2022-06-08 09:55:02 | train] - Train Epoch: [20] [947200/1281167 (74%)]	Loss: 1.372484
[2022-06-08 09:55:24 | train] - Train Epoch: [20] [960000/1281167 (75%)]	Loss: 1.627037
[2022-06-08 09:55:45 | train] - Train Epoch: [20] [972800/1281167 (76%)]	Loss: 1.493823
[2022-06-08 09:56:07 | train] - Train Epoch: [20] [985600/1281167 (77%)]	Loss: 1.842693
[2022-06-08 09:56:29 | train] - Train Epoch: [20] [998400/1281167 (78%)]	Loss: 1.876743
[2022-06-08 09:56:51 | train] - Train Epoch: [20] [1011200/1281167 (79%)]	Loss: 1.671842
[2022-06-08 09:57:13 | train] - Train Epoch: [20] [1024000/1281167 (80%)]	Loss: 1.553703
[2022-06-08 09:57:34 | train] - Train Epoch: [20] [1036800/1281167 (81%)]	Loss: 1.533286
[2022-06-08 09:57:56 | train] - Train Epoch: [20] [1049600/1281167 (82%)]	Loss: 1.495691
[2022-06-08 09:58:18 | train] - Train Epoch: [20] [1062400/1281167 (83%)]	Loss: 1.536948
[2022-06-08 09:58:40 | train] - Train Epoch: [20] [1075200/1281167 (84%)]	Loss: 2.001523
[2022-06-08 09:59:02 | train] - Train Epoch: [20] [1088000/1281167 (85%)]	Loss: 1.614375
[2022-06-08 09:59:24 | train] - Train Epoch: [20] [1100800/1281167 (86%)]	Loss: 1.578466
[2022-06-08 09:59:46 | train] - Train Epoch: [20] [1113600/1281167 (87%)]	Loss: 1.701689
[2022-06-08 10:00:08 | train] - Train Epoch: [20] [1126400/1281167 (88%)]	Loss: 1.453693
[2022-06-08 10:00:30 | train] - Train Epoch: [20] [1139200/1281167 (89%)]	Loss: 1.571872
[2022-06-08 10:00:51 | train] - Train Epoch: [20] [1152000/1281167 (90%)]	Loss: 1.794741
[2022-06-08 10:01:13 | train] - Train Epoch: [20] [1164800/1281167 (91%)]	Loss: 1.733598
[2022-06-08 10:01:35 | train] - Train Epoch: [20] [1177600/1281167 (92%)]	Loss: 2.026654
[2022-06-08 10:01:57 | train] - Train Epoch: [20] [1190400/1281167 (93%)]	Loss: 1.798268
[2022-06-08 10:02:19 | train] - Train Epoch: [20] [1203200/1281167 (94%)]	Loss: 1.560937
[2022-06-08 10:02:41 | train] - Train Epoch: [20] [1216000/1281167 (95%)]	Loss: 2.091334
[2022-06-08 10:03:03 | train] - Train Epoch: [20] [1228800/1281167 (96%)]	Loss: 1.808149
[2022-06-08 10:03:24 | train] - Train Epoch: [20] [1241600/1281167 (97%)]	Loss: 1.587484
[2022-06-08 10:03:46 | train] - Train Epoch: [20] [1254400/1281167 (98%)]	Loss: 1.733996
[2022-06-08 10:04:08 | train] - Train Epoch: [20] [1267200/1281167 (99%)]	Loss: 1.762838
[2022-06-08 10:04:30 | train] - Train Epoch: [20] [1280000/1281167 (100%)]	Loss: 2.243004
[2022-06-08 10:04:32 | train] - Train Epoch: [20]	 Average Loss: 1.730876	 Total Acc : 60.0623	 Total Top5 Acc : 81.4070
[2022-06-08 10:04:32 | train] - -------20 epoch end-----------
========================================
-------20 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 10:06:06 | train] - 
Epoch [20] Test set: Average loss: 1.5332, Accuracy: 31640/50000 (63.2565%), Top-5 Accuracy: 85.0208%

[2022-06-08 10:06:06 | train] - save intermediate epoch [20] result


[2022-06-08 10:06:10 | train] - logging best performance 20 epoch
[2022-06-08 10:06:11 | train] - -------21 epoch start-----------
========================================
----- test end -------------------------


logging best performance 20 epoch
[2022-06-08 10:06:13 | train] - Train Epoch: [21] [0/1281167 (0%)]	Loss: 1.741978
[2022-06-08 10:06:35 | train] - Train Epoch: [21] [12800/1281167 (1%)]	Loss: 1.505642
[2022-06-08 10:06:57 | train] - Train Epoch: [21] [25600/1281167 (2%)]	Loss: 1.460512
[2022-06-08 10:07:19 | train] - Train Epoch: [21] [38400/1281167 (3%)]	Loss: 1.882970
[2022-06-08 10:07:41 | train] - Train Epoch: [21] [51200/1281167 (4%)]	Loss: 1.728495
[2022-06-08 10:08:03 | train] - Train Epoch: [21] [64000/1281167 (5%)]	Loss: 1.666246
[2022-06-08 10:08:25 | train] - Train Epoch: [21] [76800/1281167 (6%)]	Loss: 1.685225
[2022-06-08 10:08:47 | train] - Train Epoch: [21] [89600/1281167 (7%)]	Loss: 1.791980
[2022-06-08 10:09:09 | train] - Train Epoch: [21] [102400/1281167 (8%)]	Loss: 1.330397
[2022-06-08 10:09:31 | train] - Train Epoch: [21] [115200/1281167 (9%)]	Loss: 1.943284
[2022-06-08 10:09:53 | train] - Train Epoch: [21] [128000/1281167 (10%)]	Loss: 1.595752
[2022-06-08 10:10:16 | train] - Train Epoch: [21] [140800/1281167 (11%)]	Loss: 1.903152
[2022-06-08 10:10:38 | train] - Train Epoch: [21] [153600/1281167 (12%)]	Loss: 2.224970
[2022-06-08 10:11:00 | train] - Train Epoch: [21] [166400/1281167 (13%)]	Loss: 1.811319
[2022-06-08 10:11:22 | train] - Train Epoch: [21] [179200/1281167 (14%)]	Loss: 1.783819
[2022-06-08 10:11:44 | train] - Train Epoch: [21] [192000/1281167 (15%)]	Loss: 1.768401
[2022-06-08 10:12:06 | train] - Train Epoch: [21] [204800/1281167 (16%)]	Loss: 1.828609
[2022-06-08 10:12:28 | train] - Train Epoch: [21] [217600/1281167 (17%)]	Loss: 1.826234
[2022-06-08 10:12:50 | train] - Train Epoch: [21] [230400/1281167 (18%)]	Loss: 1.677199
[2022-06-08 10:13:11 | train] - Train Epoch: [21] [243200/1281167 (19%)]	Loss: 1.640872
[2022-06-08 10:13:33 | train] - Train Epoch: [21] [256000/1281167 (20%)]	Loss: 1.991599
[2022-06-08 10:13:55 | train] - Train Epoch: [21] [268800/1281167 (21%)]	Loss: 1.569131
[2022-06-08 10:14:16 | train] - Train Epoch: [21] [281600/1281167 (22%)]	Loss: 1.806535
[2022-06-08 10:14:38 | train] - Train Epoch: [21] [294400/1281167 (23%)]	Loss: 1.668112
[2022-06-08 10:15:00 | train] - Train Epoch: [21] [307200/1281167 (24%)]	Loss: 2.018732
[2022-06-08 10:15:22 | train] - Train Epoch: [21] [320000/1281167 (25%)]	Loss: 1.641939
[2022-06-08 10:15:44 | train] - Train Epoch: [21] [332800/1281167 (26%)]	Loss: 2.117177
[2022-06-08 10:16:05 | train] - Train Epoch: [21] [345600/1281167 (27%)]	Loss: 2.037091
[2022-06-08 10:16:27 | train] - Train Epoch: [21] [358400/1281167 (28%)]	Loss: 1.615330
[2022-06-08 10:16:49 | train] - Train Epoch: [21] [371200/1281167 (29%)]	Loss: 1.514982
[2022-06-08 10:17:10 | train] - Train Epoch: [21] [384000/1281167 (30%)]	Loss: 1.665159
[2022-06-08 10:17:32 | train] - Train Epoch: [21] [396800/1281167 (31%)]	Loss: 1.647532
[2022-06-08 10:17:54 | train] - Train Epoch: [21] [409600/1281167 (32%)]	Loss: 1.773828
[2022-06-08 10:18:16 | train] - Train Epoch: [21] [422400/1281167 (33%)]	Loss: 1.594108
[2022-06-08 10:18:38 | train] - Train Epoch: [21] [435200/1281167 (34%)]	Loss: 1.802664
[2022-06-08 10:18:59 | train] - Train Epoch: [21] [448000/1281167 (35%)]	Loss: 1.819846
[2022-06-08 10:19:21 | train] - Train Epoch: [21] [460800/1281167 (36%)]	Loss: 1.254293
[2022-06-08 10:19:43 | train] - Train Epoch: [21] [473600/1281167 (37%)]	Loss: 1.732683
[2022-06-08 10:20:04 | train] - Train Epoch: [21] [486400/1281167 (38%)]	Loss: 1.795936
[2022-06-08 10:20:26 | train] - Train Epoch: [21] [499200/1281167 (39%)]	Loss: 2.052253
[2022-06-08 10:20:48 | train] - Train Epoch: [21] [512000/1281167 (40%)]	Loss: 1.887583
[2022-06-08 10:21:10 | train] - Train Epoch: [21] [524800/1281167 (41%)]	Loss: 1.565511
[2022-06-08 10:21:32 | train] - Train Epoch: [21] [537600/1281167 (42%)]	Loss: 1.698208
[2022-06-08 10:21:53 | train] - Train Epoch: [21] [550400/1281167 (43%)]	Loss: 1.364409
[2022-06-08 10:22:15 | train] - Train Epoch: [21] [563200/1281167 (44%)]	Loss: 1.366575
[2022-06-08 10:22:36 | train] - Train Epoch: [21] [576000/1281167 (45%)]	Loss: 1.544107
[2022-06-08 10:22:57 | train] - Train Epoch: [21] [588800/1281167 (46%)]	Loss: 1.902733
[2022-06-08 10:23:19 | train] - Train Epoch: [21] [601600/1281167 (47%)]	Loss: 2.119183
[2022-06-08 10:23:41 | train] - Train Epoch: [21] [614400/1281167 (48%)]	Loss: 1.629591
[2022-06-08 10:24:02 | train] - Train Epoch: [21] [627200/1281167 (49%)]	Loss: 1.792233
[2022-06-08 10:24:24 | train] - Train Epoch: [21] [640000/1281167 (50%)]	Loss: 1.917693
[2022-06-08 10:24:45 | train] - Train Epoch: [21] [652800/1281167 (51%)]	Loss: 1.443324
[2022-06-08 10:25:06 | train] - Train Epoch: [21] [665600/1281167 (52%)]	Loss: 1.727828
[2022-06-08 10:25:28 | train] - Train Epoch: [21] [678400/1281167 (53%)]	Loss: 1.892573
[2022-06-08 10:25:50 | train] - Train Epoch: [21] [691200/1281167 (54%)]	Loss: 1.680455
[2022-06-08 10:26:11 | train] - Train Epoch: [21] [704000/1281167 (55%)]	Loss: 1.762715
[2022-06-08 10:26:33 | train] - Train Epoch: [21] [716800/1281167 (56%)]	Loss: 1.677572
[2022-06-08 10:26:54 | train] - Train Epoch: [21] [729600/1281167 (57%)]	Loss: 1.531396
[2022-06-08 10:27:16 | train] - Train Epoch: [21] [742400/1281167 (58%)]	Loss: 1.842573
[2022-06-08 10:27:37 | train] - Train Epoch: [21] [755200/1281167 (59%)]	Loss: 1.675328
[2022-06-08 10:27:58 | train] - Train Epoch: [21] [768000/1281167 (60%)]	Loss: 1.505839
[2022-06-08 10:28:21 | train] - Train Epoch: [21] [780800/1281167 (61%)]	Loss: 1.672726
[2022-06-08 10:28:42 | train] - Train Epoch: [21] [793600/1281167 (62%)]	Loss: 1.768248
[2022-06-08 10:29:03 | train] - Train Epoch: [21] [806400/1281167 (63%)]	Loss: 1.643491
[2022-06-08 10:29:25 | train] - Train Epoch: [21] [819200/1281167 (64%)]	Loss: 1.774882
[2022-06-08 10:29:47 | train] - Train Epoch: [21] [832000/1281167 (65%)]	Loss: 1.850014
[2022-06-08 10:30:09 | train] - Train Epoch: [21] [844800/1281167 (66%)]	Loss: 1.816126
[2022-06-08 10:30:30 | train] - Train Epoch: [21] [857600/1281167 (67%)]	Loss: 1.497522
[2022-06-08 10:30:52 | train] - Train Epoch: [21] [870400/1281167 (68%)]	Loss: 1.721822
[2022-06-08 10:31:13 | train] - Train Epoch: [21] [883200/1281167 (69%)]	Loss: 1.828805
[2022-06-08 10:31:35 | train] - Train Epoch: [21] [896000/1281167 (70%)]	Loss: 1.661730
[2022-06-08 10:31:56 | train] - Train Epoch: [21] [908800/1281167 (71%)]	Loss: 2.112286
[2022-06-08 10:32:18 | train] - Train Epoch: [21] [921600/1281167 (72%)]	Loss: 1.837847
[2022-06-08 10:32:39 | train] - Train Epoch: [21] [934400/1281167 (73%)]	Loss: 1.473852
[2022-06-08 10:33:01 | train] - Train Epoch: [21] [947200/1281167 (74%)]	Loss: 1.721861
[2022-06-08 10:33:22 | train] - Train Epoch: [21] [960000/1281167 (75%)]	Loss: 1.925416
[2022-06-08 10:33:43 | train] - Train Epoch: [21] [972800/1281167 (76%)]	Loss: 1.926695
[2022-06-08 10:34:04 | train] - Train Epoch: [21] [985600/1281167 (77%)]	Loss: 1.825589
[2022-06-08 10:34:25 | train] - Train Epoch: [21] [998400/1281167 (78%)]	Loss: 1.521793
[2022-06-08 10:34:47 | train] - Train Epoch: [21] [1011200/1281167 (79%)]	Loss: 1.858643
[2022-06-08 10:35:08 | train] - Train Epoch: [21] [1024000/1281167 (80%)]	Loss: 2.078010
[2022-06-08 10:35:30 | train] - Train Epoch: [21] [1036800/1281167 (81%)]	Loss: 1.882172
[2022-06-08 10:35:52 | train] - Train Epoch: [21] [1049600/1281167 (82%)]	Loss: 1.923663
[2022-06-08 10:36:14 | train] - Train Epoch: [21] [1062400/1281167 (83%)]	Loss: 1.790383
[2022-06-08 10:36:35 | train] - Train Epoch: [21] [1075200/1281167 (84%)]	Loss: 1.250107
[2022-06-08 10:36:57 | train] - Train Epoch: [21] [1088000/1281167 (85%)]	Loss: 1.727779
[2022-06-08 10:37:18 | train] - Train Epoch: [21] [1100800/1281167 (86%)]	Loss: 1.789216
[2022-06-08 10:37:41 | train] - Train Epoch: [21] [1113600/1281167 (87%)]	Loss: 1.876052
[2022-06-08 10:38:02 | train] - Train Epoch: [21] [1126400/1281167 (88%)]	Loss: 1.735126
[2022-06-08 10:38:23 | train] - Train Epoch: [21] [1139200/1281167 (89%)]	Loss: 1.413690
[2022-06-08 10:38:45 | train] - Train Epoch: [21] [1152000/1281167 (90%)]	Loss: 1.419098
[2022-06-08 10:39:06 | train] - Train Epoch: [21] [1164800/1281167 (91%)]	Loss: 1.634949
[2022-06-08 10:39:28 | train] - Train Epoch: [21] [1177600/1281167 (92%)]	Loss: 1.916990
[2022-06-08 10:39:49 | train] - Train Epoch: [21] [1190400/1281167 (93%)]	Loss: 1.676036
[2022-06-08 10:40:11 | train] - Train Epoch: [21] [1203200/1281167 (94%)]	Loss: 1.430880
[2022-06-08 10:40:33 | train] - Train Epoch: [21] [1216000/1281167 (95%)]	Loss: 1.915185
[2022-06-08 10:40:54 | train] - Train Epoch: [21] [1228800/1281167 (96%)]	Loss: 1.973749
[2022-06-08 10:41:17 | train] - Train Epoch: [21] [1241600/1281167 (97%)]	Loss: 1.752321
[2022-06-08 10:41:37 | train] - Train Epoch: [21] [1254400/1281167 (98%)]	Loss: 1.860828
[2022-06-08 10:41:59 | train] - Train Epoch: [21] [1267200/1281167 (99%)]	Loss: 1.833474
[2022-06-08 10:42:21 | train] - Train Epoch: [21] [1280000/1281167 (100%)]	Loss: 1.566142
[2022-06-08 10:42:23 | train] - Train Epoch: [21]	 Average Loss: 1.702092	 Total Acc : 60.5767	 Total Top5 Acc : 81.8156
[2022-06-08 10:42:23 | train] - -------21 epoch end-----------
========================================
-------21 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 10:43:58 | train] - 
Epoch [21] Test set: Average loss: 1.5227, Accuracy: 31664/50000 (63.2996%), Top-5 Accuracy: 85.3033%

[2022-06-08 10:43:58 | train] - save intermediate epoch [21] result


[2022-06-08 10:44:02 | train] - logging best performance 21 epoch
[2022-06-08 10:44:03 | train] - -------22 epoch start-----------
========================================
----- test end -------------------------


logging best performance 21 epoch
[2022-06-08 10:44:05 | train] - Train Epoch: [22] [0/1281167 (0%)]	Loss: 1.809880
[2022-06-08 10:44:26 | train] - Train Epoch: [22] [12800/1281167 (1%)]	Loss: 1.435443
[2022-06-08 10:44:48 | train] - Train Epoch: [22] [25600/1281167 (2%)]	Loss: 1.467446
[2022-06-08 10:45:10 | train] - Train Epoch: [22] [38400/1281167 (3%)]	Loss: 1.648704
[2022-06-08 10:45:31 | train] - Train Epoch: [22] [51200/1281167 (4%)]	Loss: 1.452555
[2022-06-08 10:45:54 | train] - Train Epoch: [22] [64000/1281167 (5%)]	Loss: 1.710171
[2022-06-08 10:46:15 | train] - Train Epoch: [22] [76800/1281167 (6%)]	Loss: 1.688214
[2022-06-08 10:46:37 | train] - Train Epoch: [22] [89600/1281167 (7%)]	Loss: 1.406121
[2022-06-08 10:46:58 | train] - Train Epoch: [22] [102400/1281167 (8%)]	Loss: 1.519353
[2022-06-08 10:47:20 | train] - Train Epoch: [22] [115200/1281167 (9%)]	Loss: 1.234233
[2022-06-08 10:47:42 | train] - Train Epoch: [22] [128000/1281167 (10%)]	Loss: 1.759358
[2022-06-08 10:48:04 | train] - Train Epoch: [22] [140800/1281167 (11%)]	Loss: 1.791134
[2022-06-08 10:48:26 | train] - Train Epoch: [22] [153600/1281167 (12%)]	Loss: 1.561763
[2022-06-08 10:48:48 | train] - Train Epoch: [22] [166400/1281167 (13%)]	Loss: 1.823632
[2022-06-08 10:49:10 | train] - Train Epoch: [22] [179200/1281167 (14%)]	Loss: 1.720198
[2022-06-08 10:49:31 | train] - Train Epoch: [22] [192000/1281167 (15%)]	Loss: 1.661822
[2022-06-08 10:49:53 | train] - Train Epoch: [22] [204800/1281167 (16%)]	Loss: 1.561269
[2022-06-08 10:50:14 | train] - Train Epoch: [22] [217600/1281167 (17%)]	Loss: 1.927947
[2022-06-08 10:50:36 | train] - Train Epoch: [22] [230400/1281167 (18%)]	Loss: 1.930654
[2022-06-08 10:50:57 | train] - Train Epoch: [22] [243200/1281167 (19%)]	Loss: 1.874812
[2022-06-08 10:51:19 | train] - Train Epoch: [22] [256000/1281167 (20%)]	Loss: 1.756377
[2022-06-08 10:51:41 | train] - Train Epoch: [22] [268800/1281167 (21%)]	Loss: 1.505333
[2022-06-08 10:52:03 | train] - Train Epoch: [22] [281600/1281167 (22%)]	Loss: 1.927830
[2022-06-08 10:52:25 | train] - Train Epoch: [22] [294400/1281167 (23%)]	Loss: 1.726303
[2022-06-08 10:52:46 | train] - Train Epoch: [22] [307200/1281167 (24%)]	Loss: 1.435666
[2022-06-08 10:53:07 | train] - Train Epoch: [22] [320000/1281167 (25%)]	Loss: 1.463701
[2022-06-08 10:53:29 | train] - Train Epoch: [22] [332800/1281167 (26%)]	Loss: 1.775393
[2022-06-08 10:53:50 | train] - Train Epoch: [22] [345600/1281167 (27%)]	Loss: 1.417934
[2022-06-08 10:54:13 | train] - Train Epoch: [22] [358400/1281167 (28%)]	Loss: 1.618978
[2022-06-08 10:54:34 | train] - Train Epoch: [22] [371200/1281167 (29%)]	Loss: 1.621835
[2022-06-08 10:54:55 | train] - Train Epoch: [22] [384000/1281167 (30%)]	Loss: 1.632628
[2022-06-08 10:55:16 | train] - Train Epoch: [22] [396800/1281167 (31%)]	Loss: 1.775128
[2022-06-08 10:55:38 | train] - Train Epoch: [22] [409600/1281167 (32%)]	Loss: 1.469921
[2022-06-08 10:56:00 | train] - Train Epoch: [22] [422400/1281167 (33%)]	Loss: 1.694622
[2022-06-08 10:56:22 | train] - Train Epoch: [22] [435200/1281167 (34%)]	Loss: 1.798684
[2022-06-08 10:56:43 | train] - Train Epoch: [22] [448000/1281167 (35%)]	Loss: 1.407983
[2022-06-08 10:57:05 | train] - Train Epoch: [22] [460800/1281167 (36%)]	Loss: 1.935487
[2022-06-08 10:57:26 | train] - Train Epoch: [22] [473600/1281167 (37%)]	Loss: 1.585777
[2022-06-08 10:57:48 | train] - Train Epoch: [22] [486400/1281167 (38%)]	Loss: 1.777248
[2022-06-08 10:58:09 | train] - Train Epoch: [22] [499200/1281167 (39%)]	Loss: 1.574908
[2022-06-08 10:58:30 | train] - Train Epoch: [22] [512000/1281167 (40%)]	Loss: 1.783074
[2022-06-08 10:58:52 | train] - Train Epoch: [22] [524800/1281167 (41%)]	Loss: 1.569750
[2022-06-08 10:59:14 | train] - Train Epoch: [22] [537600/1281167 (42%)]	Loss: 1.647220
[2022-06-08 10:59:35 | train] - Train Epoch: [22] [550400/1281167 (43%)]	Loss: 1.652696
[2022-06-08 10:59:58 | train] - Train Epoch: [22] [563200/1281167 (44%)]	Loss: 1.570121
[2022-06-08 11:00:19 | train] - Train Epoch: [22] [576000/1281167 (45%)]	Loss: 1.254656
[2022-06-08 11:00:41 | train] - Train Epoch: [22] [588800/1281167 (46%)]	Loss: 1.565707
[2022-06-08 11:01:03 | train] - Train Epoch: [22] [601600/1281167 (47%)]	Loss: 1.803317
[2022-06-08 11:01:24 | train] - Train Epoch: [22] [614400/1281167 (48%)]	Loss: 1.635449
[2022-06-08 11:01:45 | train] - Train Epoch: [22] [627200/1281167 (49%)]	Loss: 1.572868
[2022-06-08 11:02:07 | train] - Train Epoch: [22] [640000/1281167 (50%)]	Loss: 1.852762
[2022-06-08 11:02:28 | train] - Train Epoch: [22] [652800/1281167 (51%)]	Loss: 1.703079
[2022-06-08 11:02:49 | train] - Train Epoch: [22] [665600/1281167 (52%)]	Loss: 1.448018
[2022-06-08 11:03:11 | train] - Train Epoch: [22] [678400/1281167 (53%)]	Loss: 1.637908
[2022-06-08 11:03:33 | train] - Train Epoch: [22] [691200/1281167 (54%)]	Loss: 1.611403
[2022-06-08 11:03:55 | train] - Train Epoch: [22] [704000/1281167 (55%)]	Loss: 1.497555
[2022-06-08 11:04:18 | train] - Train Epoch: [22] [716800/1281167 (56%)]	Loss: 1.765156
[2022-06-08 11:04:40 | train] - Train Epoch: [22] [729600/1281167 (57%)]	Loss: 1.471376
[2022-06-08 11:05:02 | train] - Train Epoch: [22] [742400/1281167 (58%)]	Loss: 1.487317
[2022-06-08 11:05:24 | train] - Train Epoch: [22] [755200/1281167 (59%)]	Loss: 1.591599
[2022-06-08 11:05:45 | train] - Train Epoch: [22] [768000/1281167 (60%)]	Loss: 1.717464
[2022-06-08 11:06:07 | train] - Train Epoch: [22] [780800/1281167 (61%)]	Loss: 1.854285
[2022-06-08 11:06:28 | train] - Train Epoch: [22] [793600/1281167 (62%)]	Loss: 1.469543
[2022-06-08 11:06:50 | train] - Train Epoch: [22] [806400/1281167 (63%)]	Loss: 1.909601
[2022-06-08 11:07:12 | train] - Train Epoch: [22] [819200/1281167 (64%)]	Loss: 1.779767
[2022-06-08 11:07:33 | train] - Train Epoch: [22] [832000/1281167 (65%)]	Loss: 1.949789
[2022-06-08 11:07:55 | train] - Train Epoch: [22] [844800/1281167 (66%)]	Loss: 1.524292
[2022-06-08 11:08:15 | train] - Train Epoch: [22] [857600/1281167 (67%)]	Loss: 1.503883
[2022-06-08 11:08:37 | train] - Train Epoch: [22] [870400/1281167 (68%)]	Loss: 1.713071
[2022-06-08 11:08:59 | train] - Train Epoch: [22] [883200/1281167 (69%)]	Loss: 1.608869
[2022-06-08 11:09:21 | train] - Train Epoch: [22] [896000/1281167 (70%)]	Loss: 1.562214
[2022-06-08 11:09:43 | train] - Train Epoch: [22] [908800/1281167 (71%)]	Loss: 1.642577
[2022-06-08 11:10:05 | train] - Train Epoch: [22] [921600/1281167 (72%)]	Loss: 1.929854
[2022-06-08 11:10:26 | train] - Train Epoch: [22] [934400/1281167 (73%)]	Loss: 2.102318
[2022-06-08 11:10:47 | train] - Train Epoch: [22] [947200/1281167 (74%)]	Loss: 1.585457
[2022-06-08 11:11:09 | train] - Train Epoch: [22] [960000/1281167 (75%)]	Loss: 1.638099
[2022-06-08 11:11:30 | train] - Train Epoch: [22] [972800/1281167 (76%)]	Loss: 1.856986
[2022-06-08 11:11:51 | train] - Train Epoch: [22] [985600/1281167 (77%)]	Loss: 1.594889
[2022-06-08 11:12:13 | train] - Train Epoch: [22] [998400/1281167 (78%)]	Loss: 1.726808
[2022-06-08 11:12:34 | train] - Train Epoch: [22] [1011200/1281167 (79%)]	Loss: 1.521807
[2022-06-08 11:12:56 | train] - Train Epoch: [22] [1024000/1281167 (80%)]	Loss: 1.490228
[2022-06-08 11:13:17 | train] - Train Epoch: [22] [1036800/1281167 (81%)]	Loss: 2.031157
[2022-06-08 11:13:39 | train] - Train Epoch: [22] [1049600/1281167 (82%)]	Loss: 1.588777
[2022-06-08 11:14:00 | train] - Train Epoch: [22] [1062400/1281167 (83%)]	Loss: 1.779215
[2022-06-08 11:14:22 | train] - Train Epoch: [22] [1075200/1281167 (84%)]	Loss: 1.502045
[2022-06-08 11:14:43 | train] - Train Epoch: [22] [1088000/1281167 (85%)]	Loss: 1.731963
[2022-06-08 11:15:05 | train] - Train Epoch: [22] [1100800/1281167 (86%)]	Loss: 1.708976
[2022-06-08 11:15:27 | train] - Train Epoch: [22] [1113600/1281167 (87%)]	Loss: 1.788444
[2022-06-08 11:15:48 | train] - Train Epoch: [22] [1126400/1281167 (88%)]	Loss: 1.832835
[2022-06-08 11:16:10 | train] - Train Epoch: [22] [1139200/1281167 (89%)]	Loss: 1.485753
[2022-06-08 11:16:32 | train] - Train Epoch: [22] [1152000/1281167 (90%)]	Loss: 1.760922
[2022-06-08 11:16:53 | train] - Train Epoch: [22] [1164800/1281167 (91%)]	Loss: 1.585159
[2022-06-08 11:17:14 | train] - Train Epoch: [22] [1177600/1281167 (92%)]	Loss: 1.534491
[2022-06-08 11:17:36 | train] - Train Epoch: [22] [1190400/1281167 (93%)]	Loss: 1.535654
[2022-06-08 11:17:57 | train] - Train Epoch: [22] [1203200/1281167 (94%)]	Loss: 1.869232
[2022-06-08 11:18:19 | train] - Train Epoch: [22] [1216000/1281167 (95%)]	Loss: 1.566655
[2022-06-08 11:18:40 | train] - Train Epoch: [22] [1228800/1281167 (96%)]	Loss: 1.788243
[2022-06-08 11:19:02 | train] - Train Epoch: [22] [1241600/1281167 (97%)]	Loss: 1.396477
[2022-06-08 11:19:23 | train] - Train Epoch: [22] [1254400/1281167 (98%)]	Loss: 1.673543
[2022-06-08 11:19:44 | train] - Train Epoch: [22] [1267200/1281167 (99%)]	Loss: 1.719434
[2022-06-08 11:20:05 | train] - Train Epoch: [22] [1280000/1281167 (100%)]	Loss: 1.776109
[2022-06-08 11:20:07 | train] - Train Epoch: [22]	 Average Loss: 1.674277	 Total Acc : 61.1765	 Total Top5 Acc : 82.2109
[2022-06-08 11:20:07 | train] - -------22 epoch end-----------
========================================
-------22 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 11:21:40 | train] - 
Epoch [22] Test set: Average loss: 1.5063, Accuracy: 32000/50000 (63.9758%), Top-5 Accuracy: 85.5359%

[2022-06-08 11:21:40 | train] - save intermediate epoch [22] result


[2022-06-08 11:21:44 | train] - logging best performance 22 epoch
[2022-06-08 11:21:45 | train] - -------23 epoch start-----------
========================================
----- test end -------------------------


logging best performance 22 epoch
[2022-06-08 11:21:47 | train] - Train Epoch: [23] [0/1281167 (0%)]	Loss: 1.443778
[2022-06-08 11:22:09 | train] - Train Epoch: [23] [12800/1281167 (1%)]	Loss: 1.492877
[2022-06-08 11:22:30 | train] - Train Epoch: [23] [25600/1281167 (2%)]	Loss: 1.669328
[2022-06-08 11:22:52 | train] - Train Epoch: [23] [38400/1281167 (3%)]	Loss: 1.856461
[2022-06-08 11:23:15 | train] - Train Epoch: [23] [51200/1281167 (4%)]	Loss: 1.640301
[2022-06-08 11:23:37 | train] - Train Epoch: [23] [64000/1281167 (5%)]	Loss: 1.355938
[2022-06-08 11:23:58 | train] - Train Epoch: [23] [76800/1281167 (6%)]	Loss: 1.275394
[2022-06-08 11:24:20 | train] - Train Epoch: [23] [89600/1281167 (7%)]	Loss: 1.600550
[2022-06-08 11:24:40 | train] - Train Epoch: [23] [102400/1281167 (8%)]	Loss: 2.080274
[2022-06-08 11:25:02 | train] - Train Epoch: [23] [115200/1281167 (9%)]	Loss: 1.582643
[2022-06-08 11:25:24 | train] - Train Epoch: [23] [128000/1281167 (10%)]	Loss: 1.759815
[2022-06-08 11:25:45 | train] - Train Epoch: [23] [140800/1281167 (11%)]	Loss: 1.501778
[2022-06-08 11:26:08 | train] - Train Epoch: [23] [153600/1281167 (12%)]	Loss: 2.066147
[2022-06-08 11:26:30 | train] - Train Epoch: [23] [166400/1281167 (13%)]	Loss: 1.463571
[2022-06-08 11:26:51 | train] - Train Epoch: [23] [179200/1281167 (14%)]	Loss: 1.950793
[2022-06-08 11:27:13 | train] - Train Epoch: [23] [192000/1281167 (15%)]	Loss: 1.617448
[2022-06-08 11:27:35 | train] - Train Epoch: [23] [204800/1281167 (16%)]	Loss: 1.352870
[2022-06-08 11:27:57 | train] - Train Epoch: [23] [217600/1281167 (17%)]	Loss: 1.464483
[2022-06-08 11:28:19 | train] - Train Epoch: [23] [230400/1281167 (18%)]	Loss: 1.587710
[2022-06-08 11:28:41 | train] - Train Epoch: [23] [243200/1281167 (19%)]	Loss: 1.417741
[2022-06-08 11:29:02 | train] - Train Epoch: [23] [256000/1281167 (20%)]	Loss: 1.445700
[2022-06-08 11:29:23 | train] - Train Epoch: [23] [268800/1281167 (21%)]	Loss: 1.775931
[2022-06-08 11:29:45 | train] - Train Epoch: [23] [281600/1281167 (22%)]	Loss: 1.698438
[2022-06-08 11:30:07 | train] - Train Epoch: [23] [294400/1281167 (23%)]	Loss: 1.681952
[2022-06-08 11:30:28 | train] - Train Epoch: [23] [307200/1281167 (24%)]	Loss: 1.550383
[2022-06-08 11:30:50 | train] - Train Epoch: [23] [320000/1281167 (25%)]	Loss: 1.371073
[2022-06-08 11:31:12 | train] - Train Epoch: [23] [332800/1281167 (26%)]	Loss: 1.624000
[2022-06-08 11:31:33 | train] - Train Epoch: [23] [345600/1281167 (27%)]	Loss: 1.382972
[2022-06-08 11:31:55 | train] - Train Epoch: [23] [358400/1281167 (28%)]	Loss: 1.462353
[2022-06-08 11:32:17 | train] - Train Epoch: [23] [371200/1281167 (29%)]	Loss: 1.601015
[2022-06-08 11:32:38 | train] - Train Epoch: [23] [384000/1281167 (30%)]	Loss: 1.329331
[2022-06-08 11:33:00 | train] - Train Epoch: [23] [396800/1281167 (31%)]	Loss: 1.641309
[2022-06-08 11:33:21 | train] - Train Epoch: [23] [409600/1281167 (32%)]	Loss: 1.925809
[2022-06-08 11:33:43 | train] - Train Epoch: [23] [422400/1281167 (33%)]	Loss: 1.472049
[2022-06-08 11:34:04 | train] - Train Epoch: [23] [435200/1281167 (34%)]	Loss: 1.640364
[2022-06-08 11:34:26 | train] - Train Epoch: [23] [448000/1281167 (35%)]	Loss: 1.989035
[2022-06-08 11:34:48 | train] - Train Epoch: [23] [460800/1281167 (36%)]	Loss: 1.720856
[2022-06-08 11:35:09 | train] - Train Epoch: [23] [473600/1281167 (37%)]	Loss: 1.865773
[2022-06-08 11:35:31 | train] - Train Epoch: [23] [486400/1281167 (38%)]	Loss: 1.335855
[2022-06-08 11:35:52 | train] - Train Epoch: [23] [499200/1281167 (39%)]	Loss: 1.449790
[2022-06-08 11:36:14 | train] - Train Epoch: [23] [512000/1281167 (40%)]	Loss: 1.843556
[2022-06-08 11:36:37 | train] - Train Epoch: [23] [524800/1281167 (41%)]	Loss: 1.544962
[2022-06-08 11:36:59 | train] - Train Epoch: [23] [537600/1281167 (42%)]	Loss: 1.645684
[2022-06-08 11:37:20 | train] - Train Epoch: [23] [550400/1281167 (43%)]	Loss: 1.639668
[2022-06-08 11:37:42 | train] - Train Epoch: [23] [563200/1281167 (44%)]	Loss: 1.515801
[2022-06-08 11:38:05 | train] - Train Epoch: [23] [576000/1281167 (45%)]	Loss: 1.921353
[2022-06-08 11:38:26 | train] - Train Epoch: [23] [588800/1281167 (46%)]	Loss: 1.745964
[2022-06-08 11:38:49 | train] - Train Epoch: [23] [601600/1281167 (47%)]	Loss: 1.812002
[2022-06-08 11:39:10 | train] - Train Epoch: [23] [614400/1281167 (48%)]	Loss: 1.876727
[2022-06-08 11:39:32 | train] - Train Epoch: [23] [627200/1281167 (49%)]	Loss: 1.406401
[2022-06-08 11:39:54 | train] - Train Epoch: [23] [640000/1281167 (50%)]	Loss: 1.651833
[2022-06-08 11:40:16 | train] - Train Epoch: [23] [652800/1281167 (51%)]	Loss: 1.803588
[2022-06-08 11:40:37 | train] - Train Epoch: [23] [665600/1281167 (52%)]	Loss: 1.483482
[2022-06-08 11:40:59 | train] - Train Epoch: [23] [678400/1281167 (53%)]	Loss: 2.023000
[2022-06-08 11:41:21 | train] - Train Epoch: [23] [691200/1281167 (54%)]	Loss: 1.743263
[2022-06-08 11:41:43 | train] - Train Epoch: [23] [704000/1281167 (55%)]	Loss: 1.757017
[2022-06-08 11:42:05 | train] - Train Epoch: [23] [716800/1281167 (56%)]	Loss: 1.537194
[2022-06-08 11:42:27 | train] - Train Epoch: [23] [729600/1281167 (57%)]	Loss: 1.294326
[2022-06-08 11:42:49 | train] - Train Epoch: [23] [742400/1281167 (58%)]	Loss: 1.660573
[2022-06-08 11:43:12 | train] - Train Epoch: [23] [755200/1281167 (59%)]	Loss: 1.726663
[2022-06-08 11:43:33 | train] - Train Epoch: [23] [768000/1281167 (60%)]	Loss: 1.728646
[2022-06-08 11:43:55 | train] - Train Epoch: [23] [780800/1281167 (61%)]	Loss: 1.781647
[2022-06-08 11:44:16 | train] - Train Epoch: [23] [793600/1281167 (62%)]	Loss: 1.725701
[2022-06-08 11:44:37 | train] - Train Epoch: [23] [806400/1281167 (63%)]	Loss: 1.830410
[2022-06-08 11:44:59 | train] - Train Epoch: [23] [819200/1281167 (64%)]	Loss: 1.410781
[2022-06-08 11:45:21 | train] - Train Epoch: [23] [832000/1281167 (65%)]	Loss: 1.666416
[2022-06-08 11:45:43 | train] - Train Epoch: [23] [844800/1281167 (66%)]	Loss: 1.877968
[2022-06-08 11:46:04 | train] - Train Epoch: [23] [857600/1281167 (67%)]	Loss: 1.636189
[2022-06-08 11:46:25 | train] - Train Epoch: [23] [870400/1281167 (68%)]	Loss: 1.506958
[2022-06-08 11:46:46 | train] - Train Epoch: [23] [883200/1281167 (69%)]	Loss: 1.617205
[2022-06-08 11:47:07 | train] - Train Epoch: [23] [896000/1281167 (70%)]	Loss: 1.627568
[2022-06-08 11:47:29 | train] - Train Epoch: [23] [908800/1281167 (71%)]	Loss: 1.692749
[2022-06-08 11:47:50 | train] - Train Epoch: [23] [921600/1281167 (72%)]	Loss: 1.695042
[2022-06-08 11:48:12 | train] - Train Epoch: [23] [934400/1281167 (73%)]	Loss: 1.448919
[2022-06-08 11:48:34 | train] - Train Epoch: [23] [947200/1281167 (74%)]	Loss: 1.498769
[2022-06-08 11:48:55 | train] - Train Epoch: [23] [960000/1281167 (75%)]	Loss: 1.752963
[2022-06-08 11:49:18 | train] - Train Epoch: [23] [972800/1281167 (76%)]	Loss: 1.417630
[2022-06-08 11:49:40 | train] - Train Epoch: [23] [985600/1281167 (77%)]	Loss: 1.583327
[2022-06-08 11:50:00 | train] - Train Epoch: [23] [998400/1281167 (78%)]	Loss: 1.697517
[2022-06-08 11:50:22 | train] - Train Epoch: [23] [1011200/1281167 (79%)]	Loss: 1.776456
[2022-06-08 11:50:44 | train] - Train Epoch: [23] [1024000/1281167 (80%)]	Loss: 1.646531
[2022-06-08 11:51:06 | train] - Train Epoch: [23] [1036800/1281167 (81%)]	Loss: 1.443291
[2022-06-08 11:51:27 | train] - Train Epoch: [23] [1049600/1281167 (82%)]	Loss: 1.506380
[2022-06-08 11:51:48 | train] - Train Epoch: [23] [1062400/1281167 (83%)]	Loss: 1.281094
[2022-06-08 11:52:09 | train] - Train Epoch: [23] [1075200/1281167 (84%)]	Loss: 1.496669
[2022-06-08 11:52:31 | train] - Train Epoch: [23] [1088000/1281167 (85%)]	Loss: 1.633664
[2022-06-08 11:52:53 | train] - Train Epoch: [23] [1100800/1281167 (86%)]	Loss: 1.756604
[2022-06-08 11:53:14 | train] - Train Epoch: [23] [1113600/1281167 (87%)]	Loss: 1.629703
[2022-06-08 11:53:36 | train] - Train Epoch: [23] [1126400/1281167 (88%)]	Loss: 1.414285
[2022-06-08 11:53:58 | train] - Train Epoch: [23] [1139200/1281167 (89%)]	Loss: 1.681279
[2022-06-08 11:54:19 | train] - Train Epoch: [23] [1152000/1281167 (90%)]	Loss: 1.765030
[2022-06-08 11:54:41 | train] - Train Epoch: [23] [1164800/1281167 (91%)]	Loss: 1.847033
[2022-06-08 11:55:03 | train] - Train Epoch: [23] [1177600/1281167 (92%)]	Loss: 1.890753
[2022-06-08 11:55:25 | train] - Train Epoch: [23] [1190400/1281167 (93%)]	Loss: 1.583433
[2022-06-08 11:55:47 | train] - Train Epoch: [23] [1203200/1281167 (94%)]	Loss: 1.716432
[2022-06-08 11:56:09 | train] - Train Epoch: [23] [1216000/1281167 (95%)]	Loss: 1.558018
[2022-06-08 11:56:31 | train] - Train Epoch: [23] [1228800/1281167 (96%)]	Loss: 1.967490
[2022-06-08 11:56:52 | train] - Train Epoch: [23] [1241600/1281167 (97%)]	Loss: 1.530370
[2022-06-08 11:57:14 | train] - Train Epoch: [23] [1254400/1281167 (98%)]	Loss: 1.848886
[2022-06-08 11:57:35 | train] - Train Epoch: [23] [1267200/1281167 (99%)]	Loss: 1.632593
[2022-06-08 11:57:56 | train] - Train Epoch: [23] [1280000/1281167 (100%)]	Loss: 1.509846
[2022-06-08 11:57:58 | train] - Train Epoch: [23]	 Average Loss: 1.646917	 Total Acc : 61.7196	 Total Top5 Acc : 82.6001
[2022-06-08 11:57:58 | train] - -------23 epoch end-----------
========================================
-------23 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 11:59:33 | train] - 
Epoch [23] Test set: Average loss: 1.4939, Accuracy: 32212/50000 (64.3910%), Top-5 Accuracy: 85.7796%

[2022-06-08 11:59:33 | train] - save intermediate epoch [23] result


[2022-06-08 11:59:38 | train] - logging best performance 23 epoch
[2022-06-08 11:59:39 | train] - -------24 epoch start-----------
========================================
----- test end -------------------------


logging best performance 23 epoch
[2022-06-08 11:59:41 | train] - Train Epoch: [24] [0/1281167 (0%)]	Loss: 1.772873
[2022-06-08 12:00:03 | train] - Train Epoch: [24] [12800/1281167 (1%)]	Loss: 1.620458
[2022-06-08 12:00:24 | train] - Train Epoch: [24] [25600/1281167 (2%)]	Loss: 1.777807
[2022-06-08 12:00:46 | train] - Train Epoch: [24] [38400/1281167 (3%)]	Loss: 1.779815
[2022-06-08 12:01:08 | train] - Train Epoch: [24] [51200/1281167 (4%)]	Loss: 1.304769
[2022-06-08 12:01:30 | train] - Train Epoch: [24] [64000/1281167 (5%)]	Loss: 1.761385
[2022-06-08 12:01:51 | train] - Train Epoch: [24] [76800/1281167 (6%)]	Loss: 1.522876
[2022-06-08 12:02:13 | train] - Train Epoch: [24] [89600/1281167 (7%)]	Loss: 1.281484
[2022-06-08 12:02:35 | train] - Train Epoch: [24] [102400/1281167 (8%)]	Loss: 1.549417
[2022-06-08 12:02:57 | train] - Train Epoch: [24] [115200/1281167 (9%)]	Loss: 1.536624
[2022-06-08 12:03:18 | train] - Train Epoch: [24] [128000/1281167 (10%)]	Loss: 1.504192
[2022-06-08 12:03:40 | train] - Train Epoch: [24] [140800/1281167 (11%)]	Loss: 1.704676
[2022-06-08 12:04:02 | train] - Train Epoch: [24] [153600/1281167 (12%)]	Loss: 1.644617
[2022-06-08 12:04:23 | train] - Train Epoch: [24] [166400/1281167 (13%)]	Loss: 1.731302
[2022-06-08 12:04:46 | train] - Train Epoch: [24] [179200/1281167 (14%)]	Loss: 1.408783
[2022-06-08 12:05:07 | train] - Train Epoch: [24] [192000/1281167 (15%)]	Loss: 1.509381
[2022-06-08 12:05:29 | train] - Train Epoch: [24] [204800/1281167 (16%)]	Loss: 1.769400
[2022-06-08 12:05:50 | train] - Train Epoch: [24] [217600/1281167 (17%)]	Loss: 1.525059
[2022-06-08 12:06:11 | train] - Train Epoch: [24] [230400/1281167 (18%)]	Loss: 1.454638
[2022-06-08 12:06:32 | train] - Train Epoch: [24] [243200/1281167 (19%)]	Loss: 1.572051
[2022-06-08 12:06:53 | train] - Train Epoch: [24] [256000/1281167 (20%)]	Loss: 1.799266
[2022-06-08 12:07:15 | train] - Train Epoch: [24] [268800/1281167 (21%)]	Loss: 1.669185
[2022-06-08 12:07:36 | train] - Train Epoch: [24] [281600/1281167 (22%)]	Loss: 1.434422
[2022-06-08 12:07:57 | train] - Train Epoch: [24] [294400/1281167 (23%)]	Loss: 1.960271
[2022-06-08 12:08:19 | train] - Train Epoch: [24] [307200/1281167 (24%)]	Loss: 1.934820
[2022-06-08 12:08:41 | train] - Train Epoch: [24] [320000/1281167 (25%)]	Loss: 1.499924
[2022-06-08 12:09:03 | train] - Train Epoch: [24] [332800/1281167 (26%)]	Loss: 1.605572
[2022-06-08 12:09:24 | train] - Train Epoch: [24] [345600/1281167 (27%)]	Loss: 1.589444
[2022-06-08 12:09:46 | train] - Train Epoch: [24] [358400/1281167 (28%)]	Loss: 2.040614
[2022-06-08 12:10:07 | train] - Train Epoch: [24] [371200/1281167 (29%)]	Loss: 1.848217
[2022-06-08 12:10:29 | train] - Train Epoch: [24] [384000/1281167 (30%)]	Loss: 1.256927
[2022-06-08 12:10:50 | train] - Train Epoch: [24] [396800/1281167 (31%)]	Loss: 1.612603
[2022-06-08 12:11:12 | train] - Train Epoch: [24] [409600/1281167 (32%)]	Loss: 1.535196
[2022-06-08 12:11:34 | train] - Train Epoch: [24] [422400/1281167 (33%)]	Loss: 1.659729
[2022-06-08 12:11:56 | train] - Train Epoch: [24] [435200/1281167 (34%)]	Loss: 1.744860
[2022-06-08 12:12:17 | train] - Train Epoch: [24] [448000/1281167 (35%)]	Loss: 1.452822
[2022-06-08 12:12:39 | train] - Train Epoch: [24] [460800/1281167 (36%)]	Loss: 1.437258
[2022-06-08 12:13:01 | train] - Train Epoch: [24] [473600/1281167 (37%)]	Loss: 1.711176
[2022-06-08 12:13:22 | train] - Train Epoch: [24] [486400/1281167 (38%)]	Loss: 1.423352
[2022-06-08 12:13:43 | train] - Train Epoch: [24] [499200/1281167 (39%)]	Loss: 1.520091
[2022-06-08 12:14:05 | train] - Train Epoch: [24] [512000/1281167 (40%)]	Loss: 1.679029
[2022-06-08 12:14:27 | train] - Train Epoch: [24] [524800/1281167 (41%)]	Loss: 1.848361
[2022-06-08 12:14:48 | train] - Train Epoch: [24] [537600/1281167 (42%)]	Loss: 1.619955
[2022-06-08 12:15:10 | train] - Train Epoch: [24] [550400/1281167 (43%)]	Loss: 1.650794
[2022-06-08 12:15:31 | train] - Train Epoch: [24] [563200/1281167 (44%)]	Loss: 1.731343
[2022-06-08 12:15:53 | train] - Train Epoch: [24] [576000/1281167 (45%)]	Loss: 1.840133
[2022-06-08 12:16:15 | train] - Train Epoch: [24] [588800/1281167 (46%)]	Loss: 1.449115
[2022-06-08 12:16:36 | train] - Train Epoch: [24] [601600/1281167 (47%)]	Loss: 1.626547
[2022-06-08 12:16:57 | train] - Train Epoch: [24] [614400/1281167 (48%)]	Loss: 1.902199
[2022-06-08 12:17:19 | train] - Train Epoch: [24] [627200/1281167 (49%)]	Loss: 1.581378
[2022-06-08 12:17:40 | train] - Train Epoch: [24] [640000/1281167 (50%)]	Loss: 1.254573
[2022-06-08 12:18:01 | train] - Train Epoch: [24] [652800/1281167 (51%)]	Loss: 1.828510
[2022-06-08 12:18:23 | train] - Train Epoch: [24] [665600/1281167 (52%)]	Loss: 1.485146
[2022-06-08 12:18:44 | train] - Train Epoch: [24] [678400/1281167 (53%)]	Loss: 1.482064
[2022-06-08 12:19:05 | train] - Train Epoch: [24] [691200/1281167 (54%)]	Loss: 1.566031
[2022-06-08 12:19:26 | train] - Train Epoch: [24] [704000/1281167 (55%)]	Loss: 1.800954
[2022-06-08 12:19:48 | train] - Train Epoch: [24] [716800/1281167 (56%)]	Loss: 1.827121
[2022-06-08 12:20:10 | train] - Train Epoch: [24] [729600/1281167 (57%)]	Loss: 1.990555
[2022-06-08 12:20:31 | train] - Train Epoch: [24] [742400/1281167 (58%)]	Loss: 1.958330
[2022-06-08 12:20:53 | train] - Train Epoch: [24] [755200/1281167 (59%)]	Loss: 1.674567
[2022-06-08 12:21:15 | train] - Train Epoch: [24] [768000/1281167 (60%)]	Loss: 1.873968
[2022-06-08 12:21:36 | train] - Train Epoch: [24] [780800/1281167 (61%)]	Loss: 1.946309
[2022-06-08 12:21:58 | train] - Train Epoch: [24] [793600/1281167 (62%)]	Loss: 1.766102
[2022-06-08 12:22:19 | train] - Train Epoch: [24] [806400/1281167 (63%)]	Loss: 1.401666
[2022-06-08 12:22:41 | train] - Train Epoch: [24] [819200/1281167 (64%)]	Loss: 1.516652
[2022-06-08 12:23:03 | train] - Train Epoch: [24] [832000/1281167 (65%)]	Loss: 1.966303
[2022-06-08 12:23:25 | train] - Train Epoch: [24] [844800/1281167 (66%)]	Loss: 1.554763
[2022-06-08 12:23:46 | train] - Train Epoch: [24] [857600/1281167 (67%)]	Loss: 1.554326
[2022-06-08 12:24:08 | train] - Train Epoch: [24] [870400/1281167 (68%)]	Loss: 1.409792
[2022-06-08 12:24:29 | train] - Train Epoch: [24] [883200/1281167 (69%)]	Loss: 1.400112
[2022-06-08 12:24:51 | train] - Train Epoch: [24] [896000/1281167 (70%)]	Loss: 1.639884
[2022-06-08 12:25:12 | train] - Train Epoch: [24] [908800/1281167 (71%)]	Loss: 1.545907
[2022-06-08 12:25:34 | train] - Train Epoch: [24] [921600/1281167 (72%)]	Loss: 1.475163
[2022-06-08 12:25:56 | train] - Train Epoch: [24] [934400/1281167 (73%)]	Loss: 1.733310
[2022-06-08 12:26:17 | train] - Train Epoch: [24] [947200/1281167 (74%)]	Loss: 1.806101
[2022-06-08 12:26:39 | train] - Train Epoch: [24] [960000/1281167 (75%)]	Loss: 1.355129
[2022-06-08 12:27:00 | train] - Train Epoch: [24] [972800/1281167 (76%)]	Loss: 1.647228
[2022-06-08 12:27:22 | train] - Train Epoch: [24] [985600/1281167 (77%)]	Loss: 1.396042
[2022-06-08 12:27:43 | train] - Train Epoch: [24] [998400/1281167 (78%)]	Loss: 1.400620
[2022-06-08 12:28:04 | train] - Train Epoch: [24] [1011200/1281167 (79%)]	Loss: 1.428301
[2022-06-08 12:28:26 | train] - Train Epoch: [24] [1024000/1281167 (80%)]	Loss: 1.296702
[2022-06-08 12:28:48 | train] - Train Epoch: [24] [1036800/1281167 (81%)]	Loss: 1.350956
[2022-06-08 12:29:09 | train] - Train Epoch: [24] [1049600/1281167 (82%)]	Loss: 1.620164
[2022-06-08 12:29:31 | train] - Train Epoch: [24] [1062400/1281167 (83%)]	Loss: 1.414170
[2022-06-08 12:29:52 | train] - Train Epoch: [24] [1075200/1281167 (84%)]	Loss: 1.543376
[2022-06-08 12:30:14 | train] - Train Epoch: [24] [1088000/1281167 (85%)]	Loss: 1.402830
[2022-06-08 12:30:35 | train] - Train Epoch: [24] [1100800/1281167 (86%)]	Loss: 1.483958
[2022-06-08 12:30:57 | train] - Train Epoch: [24] [1113600/1281167 (87%)]	Loss: 1.700673
[2022-06-08 12:31:18 | train] - Train Epoch: [24] [1126400/1281167 (88%)]	Loss: 1.969146
[2022-06-08 12:31:40 | train] - Train Epoch: [24] [1139200/1281167 (89%)]	Loss: 1.403296
[2022-06-08 12:32:01 | train] - Train Epoch: [24] [1152000/1281167 (90%)]	Loss: 1.906816
[2022-06-08 12:32:22 | train] - Train Epoch: [24] [1164800/1281167 (91%)]	Loss: 1.850217
[2022-06-08 12:32:43 | train] - Train Epoch: [24] [1177600/1281167 (92%)]	Loss: 1.605634
[2022-06-08 12:33:04 | train] - Train Epoch: [24] [1190400/1281167 (93%)]	Loss: 1.657073
[2022-06-08 12:33:26 | train] - Train Epoch: [24] [1203200/1281167 (94%)]	Loss: 1.578314
[2022-06-08 12:33:47 | train] - Train Epoch: [24] [1216000/1281167 (95%)]	Loss: 1.555692
[2022-06-08 12:34:09 | train] - Train Epoch: [24] [1228800/1281167 (96%)]	Loss: 1.733149
[2022-06-08 12:34:31 | train] - Train Epoch: [24] [1241600/1281167 (97%)]	Loss: 1.630163
[2022-06-08 12:34:52 | train] - Train Epoch: [24] [1254400/1281167 (98%)]	Loss: 1.764273
[2022-06-08 12:35:14 | train] - Train Epoch: [24] [1267200/1281167 (99%)]	Loss: 1.616253
[2022-06-08 12:35:36 | train] - Train Epoch: [24] [1280000/1281167 (100%)]	Loss: 1.758588
[2022-06-08 12:35:38 | train] - Train Epoch: [24]	 Average Loss: 1.621589	 Total Acc : 62.2445	 Total Top5 Acc : 82.9320
[2022-06-08 12:35:38 | train] - -------24 epoch end-----------
========================================
-------24 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 12:37:12 | train] - 
Epoch [24] Test set: Average loss: 1.4911, Accuracy: 32124/50000 (64.2176%), Top-5 Accuracy: 85.8508%

[2022-06-08 12:37:12 | train] - save intermediate epoch [24] result


[2022-06-08 12:37:18 | train] - -------25 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 12:37:19 | train] - Train Epoch: [25] [0/1281167 (0%)]	Loss: 1.496751
[2022-06-08 12:37:42 | train] - Train Epoch: [25] [12800/1281167 (1%)]	Loss: 1.679020
[2022-06-08 12:38:04 | train] - Train Epoch: [25] [25600/1281167 (2%)]	Loss: 1.526034
[2022-06-08 12:38:26 | train] - Train Epoch: [25] [38400/1281167 (3%)]	Loss: 1.549873
[2022-06-08 12:38:48 | train] - Train Epoch: [25] [51200/1281167 (4%)]	Loss: 1.748221
[2022-06-08 12:39:10 | train] - Train Epoch: [25] [64000/1281167 (5%)]	Loss: 1.689193
[2022-06-08 12:39:32 | train] - Train Epoch: [25] [76800/1281167 (6%)]	Loss: 1.441067
[2022-06-08 12:39:54 | train] - Train Epoch: [25] [89600/1281167 (7%)]	Loss: 1.683901
[2022-06-08 12:40:16 | train] - Train Epoch: [25] [102400/1281167 (8%)]	Loss: 1.691566
[2022-06-08 12:40:38 | train] - Train Epoch: [25] [115200/1281167 (9%)]	Loss: 1.545011
[2022-06-08 12:41:01 | train] - Train Epoch: [25] [128000/1281167 (10%)]	Loss: 1.623070
[2022-06-08 12:41:22 | train] - Train Epoch: [25] [140800/1281167 (11%)]	Loss: 1.525325
[2022-06-08 12:41:44 | train] - Train Epoch: [25] [153600/1281167 (12%)]	Loss: 1.657135
[2022-06-08 12:42:06 | train] - Train Epoch: [25] [166400/1281167 (13%)]	Loss: 1.265510
[2022-06-08 12:42:28 | train] - Train Epoch: [25] [179200/1281167 (14%)]	Loss: 2.062300
[2022-06-08 12:42:50 | train] - Train Epoch: [25] [192000/1281167 (15%)]	Loss: 1.627206
[2022-06-08 12:43:12 | train] - Train Epoch: [25] [204800/1281167 (16%)]	Loss: 2.008197
[2022-06-08 12:43:34 | train] - Train Epoch: [25] [217600/1281167 (17%)]	Loss: 1.417025
[2022-06-08 12:43:55 | train] - Train Epoch: [25] [230400/1281167 (18%)]	Loss: 1.497405
[2022-06-08 12:44:17 | train] - Train Epoch: [25] [243200/1281167 (19%)]	Loss: 1.714409
[2022-06-08 12:44:39 | train] - Train Epoch: [25] [256000/1281167 (20%)]	Loss: 1.679427
[2022-06-08 12:45:01 | train] - Train Epoch: [25] [268800/1281167 (21%)]	Loss: 2.001699
[2022-06-08 12:45:23 | train] - Train Epoch: [25] [281600/1281167 (22%)]	Loss: 1.741781
[2022-06-08 12:45:44 | train] - Train Epoch: [25] [294400/1281167 (23%)]	Loss: 1.809403
[2022-06-08 12:46:06 | train] - Train Epoch: [25] [307200/1281167 (24%)]	Loss: 2.047003
[2022-06-08 12:46:28 | train] - Train Epoch: [25] [320000/1281167 (25%)]	Loss: 1.766732
[2022-06-08 12:46:49 | train] - Train Epoch: [25] [332800/1281167 (26%)]	Loss: 1.459876
[2022-06-08 12:47:11 | train] - Train Epoch: [25] [345600/1281167 (27%)]	Loss: 1.587145
[2022-06-08 12:47:34 | train] - Train Epoch: [25] [358400/1281167 (28%)]	Loss: 1.440296
[2022-06-08 12:47:55 | train] - Train Epoch: [25] [371200/1281167 (29%)]	Loss: 1.833510
[2022-06-08 12:48:17 | train] - Train Epoch: [25] [384000/1281167 (30%)]	Loss: 1.569038
[2022-06-08 12:48:39 | train] - Train Epoch: [25] [396800/1281167 (31%)]	Loss: 1.446126
[2022-06-08 12:49:01 | train] - Train Epoch: [25] [409600/1281167 (32%)]	Loss: 1.503369
[2022-06-08 12:49:24 | train] - Train Epoch: [25] [422400/1281167 (33%)]	Loss: 1.647989
[2022-06-08 12:49:46 | train] - Train Epoch: [25] [435200/1281167 (34%)]	Loss: 1.795853
[2022-06-08 12:50:08 | train] - Train Epoch: [25] [448000/1281167 (35%)]	Loss: 1.555343
[2022-06-08 12:50:29 | train] - Train Epoch: [25] [460800/1281167 (36%)]	Loss: 1.755429
[2022-06-08 12:50:51 | train] - Train Epoch: [25] [473600/1281167 (37%)]	Loss: 1.551103
[2022-06-08 12:51:13 | train] - Train Epoch: [25] [486400/1281167 (38%)]	Loss: 1.639583
[2022-06-08 12:51:34 | train] - Train Epoch: [25] [499200/1281167 (39%)]	Loss: 1.656794
[2022-06-08 12:51:56 | train] - Train Epoch: [25] [512000/1281167 (40%)]	Loss: 1.689647
[2022-06-08 12:52:17 | train] - Train Epoch: [25] [524800/1281167 (41%)]	Loss: 1.753335
[2022-06-08 12:52:39 | train] - Train Epoch: [25] [537600/1281167 (42%)]	Loss: 1.641869
[2022-06-08 12:53:02 | train] - Train Epoch: [25] [550400/1281167 (43%)]	Loss: 1.168661
[2022-06-08 12:53:24 | train] - Train Epoch: [25] [563200/1281167 (44%)]	Loss: 1.555934
[2022-06-08 12:53:45 | train] - Train Epoch: [25] [576000/1281167 (45%)]	Loss: 1.641662
[2022-06-08 12:54:07 | train] - Train Epoch: [25] [588800/1281167 (46%)]	Loss: 1.497517
[2022-06-08 12:54:30 | train] - Train Epoch: [25] [601600/1281167 (47%)]	Loss: 1.652404
[2022-06-08 12:54:51 | train] - Train Epoch: [25] [614400/1281167 (48%)]	Loss: 1.683920
[2022-06-08 12:55:14 | train] - Train Epoch: [25] [627200/1281167 (49%)]	Loss: 1.477037
[2022-06-08 12:55:35 | train] - Train Epoch: [25] [640000/1281167 (50%)]	Loss: 1.522588
[2022-06-08 12:55:58 | train] - Train Epoch: [25] [652800/1281167 (51%)]	Loss: 1.748953
[2022-06-08 12:56:19 | train] - Train Epoch: [25] [665600/1281167 (52%)]	Loss: 1.423723
[2022-06-08 12:56:42 | train] - Train Epoch: [25] [678400/1281167 (53%)]	Loss: 1.546225
[2022-06-08 12:57:03 | train] - Train Epoch: [25] [691200/1281167 (54%)]	Loss: 1.403493
[2022-06-08 12:57:25 | train] - Train Epoch: [25] [704000/1281167 (55%)]	Loss: 2.002023
[2022-06-08 12:57:47 | train] - Train Epoch: [25] [716800/1281167 (56%)]	Loss: 1.589716
[2022-06-08 12:58:08 | train] - Train Epoch: [25] [729600/1281167 (57%)]	Loss: 1.849336
[2022-06-08 12:58:30 | train] - Train Epoch: [25] [742400/1281167 (58%)]	Loss: 1.596585
[2022-06-08 12:58:52 | train] - Train Epoch: [25] [755200/1281167 (59%)]	Loss: 1.495102
[2022-06-08 12:59:14 | train] - Train Epoch: [25] [768000/1281167 (60%)]	Loss: 1.590851
[2022-06-08 12:59:36 | train] - Train Epoch: [25] [780800/1281167 (61%)]	Loss: 1.366831
[2022-06-08 12:59:58 | train] - Train Epoch: [25] [793600/1281167 (62%)]	Loss: 1.754506
[2022-06-08 13:00:19 | train] - Train Epoch: [25] [806400/1281167 (63%)]	Loss: 1.772624
[2022-06-08 13:00:42 | train] - Train Epoch: [25] [819200/1281167 (64%)]	Loss: 1.847069
[2022-06-08 13:01:04 | train] - Train Epoch: [25] [832000/1281167 (65%)]	Loss: 1.784679
[2022-06-08 13:01:25 | train] - Train Epoch: [25] [844800/1281167 (66%)]	Loss: 1.503770
[2022-06-08 13:01:48 | train] - Train Epoch: [25] [857600/1281167 (67%)]	Loss: 1.695489
[2022-06-08 13:02:10 | train] - Train Epoch: [25] [870400/1281167 (68%)]	Loss: 1.905396
[2022-06-08 13:02:31 | train] - Train Epoch: [25] [883200/1281167 (69%)]	Loss: 1.599037
[2022-06-08 13:02:53 | train] - Train Epoch: [25] [896000/1281167 (70%)]	Loss: 1.923044
[2022-06-08 13:03:15 | train] - Train Epoch: [25] [908800/1281167 (71%)]	Loss: 1.645887
[2022-06-08 13:03:37 | train] - Train Epoch: [25] [921600/1281167 (72%)]	Loss: 1.594298
[2022-06-08 13:03:59 | train] - Train Epoch: [25] [934400/1281167 (73%)]	Loss: 1.352056
[2022-06-08 13:04:21 | train] - Train Epoch: [25] [947200/1281167 (74%)]	Loss: 1.809074
[2022-06-08 13:04:43 | train] - Train Epoch: [25] [960000/1281167 (75%)]	Loss: 1.443813
[2022-06-08 13:05:05 | train] - Train Epoch: [25] [972800/1281167 (76%)]	Loss: 1.490347
[2022-06-08 13:05:27 | train] - Train Epoch: [25] [985600/1281167 (77%)]	Loss: 1.655261
[2022-06-08 13:05:49 | train] - Train Epoch: [25] [998400/1281167 (78%)]	Loss: 1.702713
[2022-06-08 13:06:10 | train] - Train Epoch: [25] [1011200/1281167 (79%)]	Loss: 1.388979
[2022-06-08 13:06:32 | train] - Train Epoch: [25] [1024000/1281167 (80%)]	Loss: 1.728274
[2022-06-08 13:06:53 | train] - Train Epoch: [25] [1036800/1281167 (81%)]	Loss: 1.446890
[2022-06-08 13:07:15 | train] - Train Epoch: [25] [1049600/1281167 (82%)]	Loss: 2.008976
[2022-06-08 13:07:36 | train] - Train Epoch: [25] [1062400/1281167 (83%)]	Loss: 1.296653
[2022-06-08 13:07:58 | train] - Train Epoch: [25] [1075200/1281167 (84%)]	Loss: 1.406294
[2022-06-08 13:08:19 | train] - Train Epoch: [25] [1088000/1281167 (85%)]	Loss: 1.541849
[2022-06-08 13:08:41 | train] - Train Epoch: [25] [1100800/1281167 (86%)]	Loss: 1.448244
[2022-06-08 13:09:03 | train] - Train Epoch: [25] [1113600/1281167 (87%)]	Loss: 1.571338
[2022-06-08 13:09:25 | train] - Train Epoch: [25] [1126400/1281167 (88%)]	Loss: 1.417612
[2022-06-08 13:09:47 | train] - Train Epoch: [25] [1139200/1281167 (89%)]	Loss: 1.665178
[2022-06-08 13:10:09 | train] - Train Epoch: [25] [1152000/1281167 (90%)]	Loss: 1.610376
[2022-06-08 13:10:31 | train] - Train Epoch: [25] [1164800/1281167 (91%)]	Loss: 1.318645
[2022-06-08 13:10:53 | train] - Train Epoch: [25] [1177600/1281167 (92%)]	Loss: 1.590771
[2022-06-08 13:11:15 | train] - Train Epoch: [25] [1190400/1281167 (93%)]	Loss: 1.512710
[2022-06-08 13:11:37 | train] - Train Epoch: [25] [1203200/1281167 (94%)]	Loss: 1.472197
[2022-06-08 13:11:58 | train] - Train Epoch: [25] [1216000/1281167 (95%)]	Loss: 1.563966
[2022-06-08 13:12:20 | train] - Train Epoch: [25] [1228800/1281167 (96%)]	Loss: 1.669601
[2022-06-08 13:12:42 | train] - Train Epoch: [25] [1241600/1281167 (97%)]	Loss: 1.455509
[2022-06-08 13:13:04 | train] - Train Epoch: [25] [1254400/1281167 (98%)]	Loss: 1.258770
[2022-06-08 13:13:26 | train] - Train Epoch: [25] [1267200/1281167 (99%)]	Loss: 1.764294
[2022-06-08 13:13:48 | train] - Train Epoch: [25] [1280000/1281167 (100%)]	Loss: 1.846186
[2022-06-08 13:13:50 | train] - Train Epoch: [25]	 Average Loss: 1.597807	 Total Acc : 62.7230	 Total Top5 Acc : 83.2777
[2022-06-08 13:13:50 | train] - -------25 epoch end-----------
========================================
-------25 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 13:15:24 | train] - 
Epoch [25] Test set: Average loss: 1.4690, Accuracy: 32419/50000 (64.8058%), Top-5 Accuracy: 86.1305%

[2022-06-08 13:15:24 | train] - save intermediate epoch [25] result


[2022-06-08 13:15:28 | train] - logging best performance 25 epoch
[2022-06-08 13:15:30 | train] - -------26 epoch start-----------
========================================
----- test end -------------------------


logging best performance 25 epoch
[2022-06-08 13:15:32 | train] - Train Epoch: [26] [0/1281167 (0%)]	Loss: 1.478115
[2022-06-08 13:15:54 | train] - Train Epoch: [26] [12800/1281167 (1%)]	Loss: 1.367136
[2022-06-08 13:16:16 | train] - Train Epoch: [26] [25600/1281167 (2%)]	Loss: 1.670132
[2022-06-08 13:16:38 | train] - Train Epoch: [26] [38400/1281167 (3%)]	Loss: 1.659892
[2022-06-08 13:17:00 | train] - Train Epoch: [26] [51200/1281167 (4%)]	Loss: 1.632128
[2022-06-08 13:17:22 | train] - Train Epoch: [26] [64000/1281167 (5%)]	Loss: 1.561314
[2022-06-08 13:17:43 | train] - Train Epoch: [26] [76800/1281167 (6%)]	Loss: 2.002527
[2022-06-08 13:18:05 | train] - Train Epoch: [26] [89600/1281167 (7%)]	Loss: 1.636750
[2022-06-08 13:18:27 | train] - Train Epoch: [26] [102400/1281167 (8%)]	Loss: 1.522433
[2022-06-08 13:18:49 | train] - Train Epoch: [26] [115200/1281167 (9%)]	Loss: 1.183766
[2022-06-08 13:19:11 | train] - Train Epoch: [26] [128000/1281167 (10%)]	Loss: 1.402768
[2022-06-08 13:19:32 | train] - Train Epoch: [26] [140800/1281167 (11%)]	Loss: 1.640555
[2022-06-08 13:19:53 | train] - Train Epoch: [26] [153600/1281167 (12%)]	Loss: 1.684159
[2022-06-08 13:20:16 | train] - Train Epoch: [26] [166400/1281167 (13%)]	Loss: 2.020643
[2022-06-08 13:20:37 | train] - Train Epoch: [26] [179200/1281167 (14%)]	Loss: 1.550730
[2022-06-08 13:20:59 | train] - Train Epoch: [26] [192000/1281167 (15%)]	Loss: 1.811324
[2022-06-08 13:21:21 | train] - Train Epoch: [26] [204800/1281167 (16%)]	Loss: 1.855316
[2022-06-08 13:21:43 | train] - Train Epoch: [26] [217600/1281167 (17%)]	Loss: 1.261254
[2022-06-08 13:22:05 | train] - Train Epoch: [26] [230400/1281167 (18%)]	Loss: 1.709190
[2022-06-08 13:22:27 | train] - Train Epoch: [26] [243200/1281167 (19%)]	Loss: 1.382329
[2022-06-08 13:22:49 | train] - Train Epoch: [26] [256000/1281167 (20%)]	Loss: 1.739678
[2022-06-08 13:23:11 | train] - Train Epoch: [26] [268800/1281167 (21%)]	Loss: 1.459070
[2022-06-08 13:23:33 | train] - Train Epoch: [26] [281600/1281167 (22%)]	Loss: 1.414344
[2022-06-08 13:23:55 | train] - Train Epoch: [26] [294400/1281167 (23%)]	Loss: 1.404935
[2022-06-08 13:24:17 | train] - Train Epoch: [26] [307200/1281167 (24%)]	Loss: 1.772463
[2022-06-08 13:24:38 | train] - Train Epoch: [26] [320000/1281167 (25%)]	Loss: 1.719623
[2022-06-08 13:25:00 | train] - Train Epoch: [26] [332800/1281167 (26%)]	Loss: 1.513458
[2022-06-08 13:25:22 | train] - Train Epoch: [26] [345600/1281167 (27%)]	Loss: 1.324963
[2022-06-08 13:25:44 | train] - Train Epoch: [26] [358400/1281167 (28%)]	Loss: 1.758742
[2022-06-08 13:26:06 | train] - Train Epoch: [26] [371200/1281167 (29%)]	Loss: 1.564003
[2022-06-08 13:26:28 | train] - Train Epoch: [26] [384000/1281167 (30%)]	Loss: 1.503857
[2022-06-08 13:26:51 | train] - Train Epoch: [26] [396800/1281167 (31%)]	Loss: 1.622884
[2022-06-08 13:27:12 | train] - Train Epoch: [26] [409600/1281167 (32%)]	Loss: 1.688752
[2022-06-08 13:27:34 | train] - Train Epoch: [26] [422400/1281167 (33%)]	Loss: 1.869895
[2022-06-08 13:27:56 | train] - Train Epoch: [26] [435200/1281167 (34%)]	Loss: 1.610751
[2022-06-08 13:28:18 | train] - Train Epoch: [26] [448000/1281167 (35%)]	Loss: 1.327868
[2022-06-08 13:28:40 | train] - Train Epoch: [26] [460800/1281167 (36%)]	Loss: 1.672367
[2022-06-08 13:29:01 | train] - Train Epoch: [26] [473600/1281167 (37%)]	Loss: 1.972410
[2022-06-08 13:29:23 | train] - Train Epoch: [26] [486400/1281167 (38%)]	Loss: 1.761993
[2022-06-08 13:29:45 | train] - Train Epoch: [26] [499200/1281167 (39%)]	Loss: 1.556619
[2022-06-08 13:30:07 | train] - Train Epoch: [26] [512000/1281167 (40%)]	Loss: 1.620948
[2022-06-08 13:30:29 | train] - Train Epoch: [26] [524800/1281167 (41%)]	Loss: 1.575448
[2022-06-08 13:30:51 | train] - Train Epoch: [26] [537600/1281167 (42%)]	Loss: 1.542032
[2022-06-08 13:31:12 | train] - Train Epoch: [26] [550400/1281167 (43%)]	Loss: 1.326199
[2022-06-08 13:31:34 | train] - Train Epoch: [26] [563200/1281167 (44%)]	Loss: 1.600658
[2022-06-08 13:31:56 | train] - Train Epoch: [26] [576000/1281167 (45%)]	Loss: 1.314325
[2022-06-08 13:32:18 | train] - Train Epoch: [26] [588800/1281167 (46%)]	Loss: 1.663130
[2022-06-08 13:32:41 | train] - Train Epoch: [26] [601600/1281167 (47%)]	Loss: 1.533862
[2022-06-08 13:33:03 | train] - Train Epoch: [26] [614400/1281167 (48%)]	Loss: 1.457688
[2022-06-08 13:33:24 | train] - Train Epoch: [26] [627200/1281167 (49%)]	Loss: 1.397456
[2022-06-08 13:33:46 | train] - Train Epoch: [26] [640000/1281167 (50%)]	Loss: 1.648484
[2022-06-08 13:34:08 | train] - Train Epoch: [26] [652800/1281167 (51%)]	Loss: 1.742899
[2022-06-08 13:34:30 | train] - Train Epoch: [26] [665600/1281167 (52%)]	Loss: 1.468304
[2022-06-08 13:34:52 | train] - Train Epoch: [26] [678400/1281167 (53%)]	Loss: 1.671555
[2022-06-08 13:35:14 | train] - Train Epoch: [26] [691200/1281167 (54%)]	Loss: 1.421632
[2022-06-08 13:35:36 | train] - Train Epoch: [26] [704000/1281167 (55%)]	Loss: 1.648800
[2022-06-08 13:35:58 | train] - Train Epoch: [26] [716800/1281167 (56%)]	Loss: 1.556293
[2022-06-08 13:36:20 | train] - Train Epoch: [26] [729600/1281167 (57%)]	Loss: 1.468944
[2022-06-08 13:36:42 | train] - Train Epoch: [26] [742400/1281167 (58%)]	Loss: 1.504240
[2022-06-08 13:37:04 | train] - Train Epoch: [26] [755200/1281167 (59%)]	Loss: 1.759524
[2022-06-08 13:37:25 | train] - Train Epoch: [26] [768000/1281167 (60%)]	Loss: 1.783599
[2022-06-08 13:37:47 | train] - Train Epoch: [26] [780800/1281167 (61%)]	Loss: 1.587543
[2022-06-08 13:38:10 | train] - Train Epoch: [26] [793600/1281167 (62%)]	Loss: 1.608487
[2022-06-08 13:38:32 | train] - Train Epoch: [26] [806400/1281167 (63%)]	Loss: 1.660527
[2022-06-08 13:38:54 | train] - Train Epoch: [26] [819200/1281167 (64%)]	Loss: 1.625022
[2022-06-08 13:39:16 | train] - Train Epoch: [26] [832000/1281167 (65%)]	Loss: 2.101815
[2022-06-08 13:39:37 | train] - Train Epoch: [26] [844800/1281167 (66%)]	Loss: 1.512379
[2022-06-08 13:40:00 | train] - Train Epoch: [26] [857600/1281167 (67%)]	Loss: 1.935136
[2022-06-08 13:40:22 | train] - Train Epoch: [26] [870400/1281167 (68%)]	Loss: 1.586081
[2022-06-08 13:40:44 | train] - Train Epoch: [26] [883200/1281167 (69%)]	Loss: 1.760237
[2022-06-08 13:41:06 | train] - Train Epoch: [26] [896000/1281167 (70%)]	Loss: 1.652830
[2022-06-08 13:41:29 | train] - Train Epoch: [26] [908800/1281167 (71%)]	Loss: 1.513073
[2022-06-08 13:41:51 | train] - Train Epoch: [26] [921600/1281167 (72%)]	Loss: 1.769002
[2022-06-08 13:42:13 | train] - Train Epoch: [26] [934400/1281167 (73%)]	Loss: 1.803608
[2022-06-08 13:42:35 | train] - Train Epoch: [26] [947200/1281167 (74%)]	Loss: 1.328281
[2022-06-08 13:42:57 | train] - Train Epoch: [26] [960000/1281167 (75%)]	Loss: 2.010269
[2022-06-08 13:43:18 | train] - Train Epoch: [26] [972800/1281167 (76%)]	Loss: 1.816074
[2022-06-08 13:43:40 | train] - Train Epoch: [26] [985600/1281167 (77%)]	Loss: 1.693273
[2022-06-08 13:44:02 | train] - Train Epoch: [26] [998400/1281167 (78%)]	Loss: 1.472655
[2022-06-08 13:44:24 | train] - Train Epoch: [26] [1011200/1281167 (79%)]	Loss: 1.715675
[2022-06-08 13:44:46 | train] - Train Epoch: [26] [1024000/1281167 (80%)]	Loss: 1.505898
[2022-06-08 13:45:08 | train] - Train Epoch: [26] [1036800/1281167 (81%)]	Loss: 1.640017
[2022-06-08 13:45:30 | train] - Train Epoch: [26] [1049600/1281167 (82%)]	Loss: 1.633030
[2022-06-08 13:45:51 | train] - Train Epoch: [26] [1062400/1281167 (83%)]	Loss: 1.367560
[2022-06-08 13:46:13 | train] - Train Epoch: [26] [1075200/1281167 (84%)]	Loss: 1.520157
[2022-06-08 13:46:35 | train] - Train Epoch: [26] [1088000/1281167 (85%)]	Loss: 1.766476
[2022-06-08 13:46:57 | train] - Train Epoch: [26] [1100800/1281167 (86%)]	Loss: 1.190018
[2022-06-08 13:47:19 | train] - Train Epoch: [26] [1113600/1281167 (87%)]	Loss: 1.581244
[2022-06-08 13:47:41 | train] - Train Epoch: [26] [1126400/1281167 (88%)]	Loss: 1.397706
[2022-06-08 13:48:03 | train] - Train Epoch: [26] [1139200/1281167 (89%)]	Loss: 1.625607
[2022-06-08 13:48:25 | train] - Train Epoch: [26] [1152000/1281167 (90%)]	Loss: 1.628475
[2022-06-08 13:48:47 | train] - Train Epoch: [26] [1164800/1281167 (91%)]	Loss: 1.910294
[2022-06-08 13:49:09 | train] - Train Epoch: [26] [1177600/1281167 (92%)]	Loss: 1.386702
[2022-06-08 13:49:31 | train] - Train Epoch: [26] [1190400/1281167 (93%)]	Loss: 1.450434
[2022-06-08 13:49:53 | train] - Train Epoch: [26] [1203200/1281167 (94%)]	Loss: 1.663088
[2022-06-08 13:50:15 | train] - Train Epoch: [26] [1216000/1281167 (95%)]	Loss: 1.197142
[2022-06-08 13:50:37 | train] - Train Epoch: [26] [1228800/1281167 (96%)]	Loss: 1.406199
[2022-06-08 13:50:59 | train] - Train Epoch: [26] [1241600/1281167 (97%)]	Loss: 1.683949
[2022-06-08 13:51:22 | train] - Train Epoch: [26] [1254400/1281167 (98%)]	Loss: 1.494749
[2022-06-08 13:51:43 | train] - Train Epoch: [26] [1267200/1281167 (99%)]	Loss: 1.337941
[2022-06-08 13:52:05 | train] - Train Epoch: [26] [1280000/1281167 (100%)]	Loss: 1.588406
[2022-06-08 13:52:07 | train] - Train Epoch: [26]	 Average Loss: 1.575651	 Total Acc : 63.1522	 Total Top5 Acc : 83.5828
[2022-06-08 13:52:07 | train] - -------26 epoch end-----------
========================================
-------26 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 13:53:41 | train] - 
Epoch [26] Test set: Average loss: 1.4601, Accuracy: 32574/50000 (65.1131%), Top-5 Accuracy: 86.3139%

[2022-06-08 13:53:41 | train] - save intermediate epoch [26] result


[2022-06-08 13:53:47 | train] - logging best performance 26 epoch
[2022-06-08 13:53:48 | train] - -------27 epoch start-----------
========================================
----- test end -------------------------


logging best performance 26 epoch
[2022-06-08 13:53:50 | train] - Train Epoch: [27] [0/1281167 (0%)]	Loss: 1.679734
[2022-06-08 13:54:12 | train] - Train Epoch: [27] [12800/1281167 (1%)]	Loss: 1.662811
[2022-06-08 13:54:34 | train] - Train Epoch: [27] [25600/1281167 (2%)]	Loss: 1.712664
[2022-06-08 13:54:56 | train] - Train Epoch: [27] [38400/1281167 (3%)]	Loss: 1.662020
[2022-06-08 13:55:18 | train] - Train Epoch: [27] [51200/1281167 (4%)]	Loss: 1.523467
[2022-06-08 13:55:40 | train] - Train Epoch: [27] [64000/1281167 (5%)]	Loss: 1.956677
[2022-06-08 13:56:02 | train] - Train Epoch: [27] [76800/1281167 (6%)]	Loss: 1.394657
[2022-06-08 13:56:23 | train] - Train Epoch: [27] [89600/1281167 (7%)]	Loss: 1.592627
[2022-06-08 13:56:46 | train] - Train Epoch: [27] [102400/1281167 (8%)]	Loss: 1.793374
[2022-06-08 13:57:08 | train] - Train Epoch: [27] [115200/1281167 (9%)]	Loss: 1.495923
[2022-06-08 13:57:30 | train] - Train Epoch: [27] [128000/1281167 (10%)]	Loss: 1.372149
[2022-06-08 13:57:52 | train] - Train Epoch: [27] [140800/1281167 (11%)]	Loss: 1.421995
[2022-06-08 13:58:13 | train] - Train Epoch: [27] [153600/1281167 (12%)]	Loss: 1.279516
[2022-06-08 13:58:35 | train] - Train Epoch: [27] [166400/1281167 (13%)]	Loss: 1.283941
[2022-06-08 13:58:57 | train] - Train Epoch: [27] [179200/1281167 (14%)]	Loss: 1.642177
[2022-06-08 13:59:18 | train] - Train Epoch: [27] [192000/1281167 (15%)]	Loss: 1.467284
[2022-06-08 13:59:41 | train] - Train Epoch: [27] [204800/1281167 (16%)]	Loss: 1.784123
[2022-06-08 14:00:03 | train] - Train Epoch: [27] [217600/1281167 (17%)]	Loss: 1.688408
[2022-06-08 14:00:26 | train] - Train Epoch: [27] [230400/1281167 (18%)]	Loss: 1.369979
[2022-06-08 14:00:48 | train] - Train Epoch: [27] [243200/1281167 (19%)]	Loss: 1.657503
[2022-06-08 14:01:09 | train] - Train Epoch: [27] [256000/1281167 (20%)]	Loss: 1.949463
[2022-06-08 14:01:32 | train] - Train Epoch: [27] [268800/1281167 (21%)]	Loss: 1.700374
[2022-06-08 14:01:53 | train] - Train Epoch: [27] [281600/1281167 (22%)]	Loss: 1.370105
[2022-06-08 14:02:15 | train] - Train Epoch: [27] [294400/1281167 (23%)]	Loss: 1.249564
[2022-06-08 14:02:37 | train] - Train Epoch: [27] [307200/1281167 (24%)]	Loss: 1.426176
[2022-06-08 14:02:59 | train] - Train Epoch: [27] [320000/1281167 (25%)]	Loss: 1.949010
[2022-06-08 14:03:21 | train] - Train Epoch: [27] [332800/1281167 (26%)]	Loss: 1.458530
[2022-06-08 14:03:42 | train] - Train Epoch: [27] [345600/1281167 (27%)]	Loss: 1.727425
[2022-06-08 14:04:04 | train] - Train Epoch: [27] [358400/1281167 (28%)]	Loss: 1.596189
[2022-06-08 14:04:26 | train] - Train Epoch: [27] [371200/1281167 (29%)]	Loss: 1.401587
[2022-06-08 14:04:47 | train] - Train Epoch: [27] [384000/1281167 (30%)]	Loss: 1.266863
[2022-06-08 14:05:09 | train] - Train Epoch: [27] [396800/1281167 (31%)]	Loss: 1.568377
[2022-06-08 14:05:30 | train] - Train Epoch: [27] [409600/1281167 (32%)]	Loss: 1.501233
[2022-06-08 14:05:52 | train] - Train Epoch: [27] [422400/1281167 (33%)]	Loss: 1.756897
[2022-06-08 14:06:14 | train] - Train Epoch: [27] [435200/1281167 (34%)]	Loss: 1.549491
[2022-06-08 14:06:36 | train] - Train Epoch: [27] [448000/1281167 (35%)]	Loss: 1.680872
[2022-06-08 14:06:58 | train] - Train Epoch: [27] [460800/1281167 (36%)]	Loss: 1.573671
[2022-06-08 14:07:20 | train] - Train Epoch: [27] [473600/1281167 (37%)]	Loss: 1.218503
[2022-06-08 14:07:42 | train] - Train Epoch: [27] [486400/1281167 (38%)]	Loss: 1.243783
[2022-06-08 14:08:03 | train] - Train Epoch: [27] [499200/1281167 (39%)]	Loss: 1.714161
[2022-06-08 14:08:25 | train] - Train Epoch: [27] [512000/1281167 (40%)]	Loss: 1.373432
[2022-06-08 14:08:47 | train] - Train Epoch: [27] [524800/1281167 (41%)]	Loss: 1.394530
[2022-06-08 14:09:10 | train] - Train Epoch: [27] [537600/1281167 (42%)]	Loss: 1.614739
[2022-06-08 14:09:32 | train] - Train Epoch: [27] [550400/1281167 (43%)]	Loss: 1.569949
[2022-06-08 14:09:53 | train] - Train Epoch: [27] [563200/1281167 (44%)]	Loss: 1.664546
[2022-06-08 14:10:15 | train] - Train Epoch: [27] [576000/1281167 (45%)]	Loss: 1.581147
[2022-06-08 14:10:36 | train] - Train Epoch: [27] [588800/1281167 (46%)]	Loss: 1.622801
[2022-06-08 14:10:58 | train] - Train Epoch: [27] [601600/1281167 (47%)]	Loss: 1.350778
[2022-06-08 14:11:20 | train] - Train Epoch: [27] [614400/1281167 (48%)]	Loss: 1.628949
[2022-06-08 14:11:42 | train] - Train Epoch: [27] [627200/1281167 (49%)]	Loss: 1.507091
[2022-06-08 14:12:03 | train] - Train Epoch: [27] [640000/1281167 (50%)]	Loss: 1.581679
[2022-06-08 14:12:25 | train] - Train Epoch: [27] [652800/1281167 (51%)]	Loss: 1.608691
[2022-06-08 14:12:46 | train] - Train Epoch: [27] [665600/1281167 (52%)]	Loss: 1.680413
[2022-06-08 14:13:07 | train] - Train Epoch: [27] [678400/1281167 (53%)]	Loss: 1.450862
[2022-06-08 14:13:28 | train] - Train Epoch: [27] [691200/1281167 (54%)]	Loss: 1.371680
[2022-06-08 14:13:50 | train] - Train Epoch: [27] [704000/1281167 (55%)]	Loss: 1.522048
[2022-06-08 14:14:11 | train] - Train Epoch: [27] [716800/1281167 (56%)]	Loss: 1.557252
[2022-06-08 14:14:34 | train] - Train Epoch: [27] [729600/1281167 (57%)]	Loss: 1.669095
[2022-06-08 14:14:56 | train] - Train Epoch: [27] [742400/1281167 (58%)]	Loss: 1.451535
[2022-06-08 14:15:18 | train] - Train Epoch: [27] [755200/1281167 (59%)]	Loss: 1.517277
[2022-06-08 14:15:40 | train] - Train Epoch: [27] [768000/1281167 (60%)]	Loss: 1.830808
[2022-06-08 14:16:01 | train] - Train Epoch: [27] [780800/1281167 (61%)]	Loss: 1.766733
[2022-06-08 14:16:22 | train] - Train Epoch: [27] [793600/1281167 (62%)]	Loss: 1.892090
[2022-06-08 14:16:44 | train] - Train Epoch: [27] [806400/1281167 (63%)]	Loss: 1.610539
[2022-06-08 14:17:05 | train] - Train Epoch: [27] [819200/1281167 (64%)]	Loss: 1.486510
[2022-06-08 14:17:27 | train] - Train Epoch: [27] [832000/1281167 (65%)]	Loss: 1.535582
[2022-06-08 14:17:49 | train] - Train Epoch: [27] [844800/1281167 (66%)]	Loss: 1.670187
[2022-06-08 14:18:10 | train] - Train Epoch: [27] [857600/1281167 (67%)]	Loss: 1.749115
[2022-06-08 14:18:32 | train] - Train Epoch: [27] [870400/1281167 (68%)]	Loss: 1.266734
[2022-06-08 14:18:53 | train] - Train Epoch: [27] [883200/1281167 (69%)]	Loss: 1.900160
[2022-06-08 14:19:15 | train] - Train Epoch: [27] [896000/1281167 (70%)]	Loss: 1.597773
[2022-06-08 14:19:37 | train] - Train Epoch: [27] [908800/1281167 (71%)]	Loss: 1.412252
[2022-06-08 14:19:59 | train] - Train Epoch: [27] [921600/1281167 (72%)]	Loss: 1.582399
[2022-06-08 14:20:21 | train] - Train Epoch: [27] [934400/1281167 (73%)]	Loss: 1.691322
[2022-06-08 14:20:42 | train] - Train Epoch: [27] [947200/1281167 (74%)]	Loss: 1.802627
[2022-06-08 14:21:05 | train] - Train Epoch: [27] [960000/1281167 (75%)]	Loss: 1.538532
[2022-06-08 14:21:26 | train] - Train Epoch: [27] [972800/1281167 (76%)]	Loss: 1.585573
[2022-06-08 14:21:48 | train] - Train Epoch: [27] [985600/1281167 (77%)]	Loss: 1.178756
[2022-06-08 14:22:10 | train] - Train Epoch: [27] [998400/1281167 (78%)]	Loss: 1.564486
[2022-06-08 14:22:32 | train] - Train Epoch: [27] [1011200/1281167 (79%)]	Loss: 1.618816
[2022-06-08 14:22:54 | train] - Train Epoch: [27] [1024000/1281167 (80%)]	Loss: 1.212450
[2022-06-08 14:23:16 | train] - Train Epoch: [27] [1036800/1281167 (81%)]	Loss: 1.552701
[2022-06-08 14:23:38 | train] - Train Epoch: [27] [1049600/1281167 (82%)]	Loss: 1.426467
[2022-06-08 14:24:00 | train] - Train Epoch: [27] [1062400/1281167 (83%)]	Loss: 1.341561
[2022-06-08 14:24:21 | train] - Train Epoch: [27] [1075200/1281167 (84%)]	Loss: 1.289265
[2022-06-08 14:24:43 | train] - Train Epoch: [27] [1088000/1281167 (85%)]	Loss: 1.531141
[2022-06-08 14:25:05 | train] - Train Epoch: [27] [1100800/1281167 (86%)]	Loss: 1.693965
[2022-06-08 14:25:26 | train] - Train Epoch: [27] [1113600/1281167 (87%)]	Loss: 1.491167
[2022-06-08 14:25:47 | train] - Train Epoch: [27] [1126400/1281167 (88%)]	Loss: 1.913527
[2022-06-08 14:26:09 | train] - Train Epoch: [27] [1139200/1281167 (89%)]	Loss: 1.551747
[2022-06-08 14:26:30 | train] - Train Epoch: [27] [1152000/1281167 (90%)]	Loss: 1.326990
[2022-06-08 14:26:51 | train] - Train Epoch: [27] [1164800/1281167 (91%)]	Loss: 1.569479
[2022-06-08 14:27:13 | train] - Train Epoch: [27] [1177600/1281167 (92%)]	Loss: 1.675240
[2022-06-08 14:27:34 | train] - Train Epoch: [27] [1190400/1281167 (93%)]	Loss: 1.470694
[2022-06-08 14:27:55 | train] - Train Epoch: [27] [1203200/1281167 (94%)]	Loss: 1.647176
[2022-06-08 14:28:17 | train] - Train Epoch: [27] [1216000/1281167 (95%)]	Loss: 1.591176
[2022-06-08 14:28:39 | train] - Train Epoch: [27] [1228800/1281167 (96%)]	Loss: 1.501687
[2022-06-08 14:29:01 | train] - Train Epoch: [27] [1241600/1281167 (97%)]	Loss: 1.735826
[2022-06-08 14:29:22 | train] - Train Epoch: [27] [1254400/1281167 (98%)]	Loss: 1.664344
[2022-06-08 14:29:44 | train] - Train Epoch: [27] [1267200/1281167 (99%)]	Loss: 1.979158
[2022-06-08 14:30:06 | train] - Train Epoch: [27] [1280000/1281167 (100%)]	Loss: 1.410250
[2022-06-08 14:30:07 | train] - Train Epoch: [27]	 Average Loss: 1.555002	 Total Acc : 63.6106	 Total Top5 Acc : 83.8930
[2022-06-08 14:30:07 | train] - -------27 epoch end-----------
========================================
-------27 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 14:31:43 | train] - 
Epoch [27] Test set: Average loss: 1.4582, Accuracy: 32656/50000 (65.2829%), Top-5 Accuracy: 86.3687%

[2022-06-08 14:31:43 | train] - save intermediate epoch [27] result


[2022-06-08 14:31:48 | train] - logging best performance 27 epoch
[2022-06-08 14:31:50 | train] - -------28 epoch start-----------
========================================
----- test end -------------------------


logging best performance 27 epoch
[2022-06-08 14:31:51 | train] - Train Epoch: [28] [0/1281167 (0%)]	Loss: 1.443275
[2022-06-08 14:32:12 | train] - Train Epoch: [28] [12800/1281167 (1%)]	Loss: 1.724600
[2022-06-08 14:32:33 | train] - Train Epoch: [28] [25600/1281167 (2%)]	Loss: 1.646148
[2022-06-08 14:32:55 | train] - Train Epoch: [28] [38400/1281167 (3%)]	Loss: 1.706145
[2022-06-08 14:33:15 | train] - Train Epoch: [28] [51200/1281167 (4%)]	Loss: 1.865895
[2022-06-08 14:33:37 | train] - Train Epoch: [28] [64000/1281167 (5%)]	Loss: 1.581182
[2022-06-08 14:33:58 | train] - Train Epoch: [28] [76800/1281167 (6%)]	Loss: 1.762190
[2022-06-08 14:34:20 | train] - Train Epoch: [28] [89600/1281167 (7%)]	Loss: 1.110150
[2022-06-08 14:34:41 | train] - Train Epoch: [28] [102400/1281167 (8%)]	Loss: 1.711179
[2022-06-08 14:35:03 | train] - Train Epoch: [28] [115200/1281167 (9%)]	Loss: 1.279492
[2022-06-08 14:35:25 | train] - Train Epoch: [28] [128000/1281167 (10%)]	Loss: 1.246598
[2022-06-08 14:35:46 | train] - Train Epoch: [28] [140800/1281167 (11%)]	Loss: 1.530337
[2022-06-08 14:36:07 | train] - Train Epoch: [28] [153600/1281167 (12%)]	Loss: 1.452571
[2022-06-08 14:36:29 | train] - Train Epoch: [28] [166400/1281167 (13%)]	Loss: 1.197810
[2022-06-08 14:36:50 | train] - Train Epoch: [28] [179200/1281167 (14%)]	Loss: 1.836343
[2022-06-08 14:37:12 | train] - Train Epoch: [28] [192000/1281167 (15%)]	Loss: 1.925087
[2022-06-08 14:37:32 | train] - Train Epoch: [28] [204800/1281167 (16%)]	Loss: 1.554296
[2022-06-08 14:37:54 | train] - Train Epoch: [28] [217600/1281167 (17%)]	Loss: 1.216327
[2022-06-08 14:38:15 | train] - Train Epoch: [28] [230400/1281167 (18%)]	Loss: 1.503977
[2022-06-08 14:38:37 | train] - Train Epoch: [28] [243200/1281167 (19%)]	Loss: 1.560703
[2022-06-08 14:38:57 | train] - Train Epoch: [28] [256000/1281167 (20%)]	Loss: 1.536812
[2022-06-08 14:39:18 | train] - Train Epoch: [28] [268800/1281167 (21%)]	Loss: 1.404703
[2022-06-08 14:39:39 | train] - Train Epoch: [28] [281600/1281167 (22%)]	Loss: 1.928596
[2022-06-08 14:40:00 | train] - Train Epoch: [28] [294400/1281167 (23%)]	Loss: 1.561381
[2022-06-08 14:40:21 | train] - Train Epoch: [28] [307200/1281167 (24%)]	Loss: 1.641390
[2022-06-08 14:40:42 | train] - Train Epoch: [28] [320000/1281167 (25%)]	Loss: 1.655024
[2022-06-08 14:41:04 | train] - Train Epoch: [28] [332800/1281167 (26%)]	Loss: 1.699708
[2022-06-08 14:41:25 | train] - Train Epoch: [28] [345600/1281167 (27%)]	Loss: 1.548588
[2022-06-08 14:41:45 | train] - Train Epoch: [28] [358400/1281167 (28%)]	Loss: 1.409494
[2022-06-08 14:42:06 | train] - Train Epoch: [28] [371200/1281167 (29%)]	Loss: 1.337398
[2022-06-08 14:42:28 | train] - Train Epoch: [28] [384000/1281167 (30%)]	Loss: 1.433737
[2022-06-08 14:42:48 | train] - Train Epoch: [28] [396800/1281167 (31%)]	Loss: 1.343073
[2022-06-08 14:43:09 | train] - Train Epoch: [28] [409600/1281167 (32%)]	Loss: 1.683810
[2022-06-08 14:43:30 | train] - Train Epoch: [28] [422400/1281167 (33%)]	Loss: 1.786241
[2022-06-08 14:43:51 | train] - Train Epoch: [28] [435200/1281167 (34%)]	Loss: 1.591953
[2022-06-08 14:44:12 | train] - Train Epoch: [28] [448000/1281167 (35%)]	Loss: 1.783390
[2022-06-08 14:44:32 | train] - Train Epoch: [28] [460800/1281167 (36%)]	Loss: 1.310379
[2022-06-08 14:44:53 | train] - Train Epoch: [28] [473600/1281167 (37%)]	Loss: 1.630061
[2022-06-08 14:45:15 | train] - Train Epoch: [28] [486400/1281167 (38%)]	Loss: 1.773387
[2022-06-08 14:45:35 | train] - Train Epoch: [28] [499200/1281167 (39%)]	Loss: 1.610450
[2022-06-08 14:45:57 | train] - Train Epoch: [28] [512000/1281167 (40%)]	Loss: 1.789726
[2022-06-08 14:46:18 | train] - Train Epoch: [28] [524800/1281167 (41%)]	Loss: 1.145827
[2022-06-08 14:46:39 | train] - Train Epoch: [28] [537600/1281167 (42%)]	Loss: 1.415039
[2022-06-08 14:47:00 | train] - Train Epoch: [28] [550400/1281167 (43%)]	Loss: 1.332632
[2022-06-08 14:47:20 | train] - Train Epoch: [28] [563200/1281167 (44%)]	Loss: 1.601112
[2022-06-08 14:47:40 | train] - Train Epoch: [28] [576000/1281167 (45%)]	Loss: 1.632674
[2022-06-08 14:48:01 | train] - Train Epoch: [28] [588800/1281167 (46%)]	Loss: 1.497710
[2022-06-08 14:48:21 | train] - Train Epoch: [28] [601600/1281167 (47%)]	Loss: 1.595282
[2022-06-08 14:48:42 | train] - Train Epoch: [28] [614400/1281167 (48%)]	Loss: 1.279735
[2022-06-08 14:49:04 | train] - Train Epoch: [28] [627200/1281167 (49%)]	Loss: 1.513362
[2022-06-08 14:49:25 | train] - Train Epoch: [28] [640000/1281167 (50%)]	Loss: 1.441145
[2022-06-08 14:49:47 | train] - Train Epoch: [28] [652800/1281167 (51%)]	Loss: 1.493754
[2022-06-08 14:50:08 | train] - Train Epoch: [28] [665600/1281167 (52%)]	Loss: 1.635378
[2022-06-08 14:50:28 | train] - Train Epoch: [28] [678400/1281167 (53%)]	Loss: 1.733028
[2022-06-08 14:50:48 | train] - Train Epoch: [28] [691200/1281167 (54%)]	Loss: 0.995452
[2022-06-08 14:51:09 | train] - Train Epoch: [28] [704000/1281167 (55%)]	Loss: 2.065440
[2022-06-08 14:51:30 | train] - Train Epoch: [28] [716800/1281167 (56%)]	Loss: 1.325606
[2022-06-08 14:51:50 | train] - Train Epoch: [28] [729600/1281167 (57%)]	Loss: 1.708220
[2022-06-08 14:52:12 | train] - Train Epoch: [28] [742400/1281167 (58%)]	Loss: 1.606554
[2022-06-08 14:52:33 | train] - Train Epoch: [28] [755200/1281167 (59%)]	Loss: 1.444624
[2022-06-08 14:52:54 | train] - Train Epoch: [28] [768000/1281167 (60%)]	Loss: 1.529540
[2022-06-08 14:53:15 | train] - Train Epoch: [28] [780800/1281167 (61%)]	Loss: 1.498366
[2022-06-08 14:53:36 | train] - Train Epoch: [28] [793600/1281167 (62%)]	Loss: 1.619546
[2022-06-08 14:53:57 | train] - Train Epoch: [28] [806400/1281167 (63%)]	Loss: 1.410590
[2022-06-08 14:54:19 | train] - Train Epoch: [28] [819200/1281167 (64%)]	Loss: 1.286911
[2022-06-08 14:54:40 | train] - Train Epoch: [28] [832000/1281167 (65%)]	Loss: 1.419489
[2022-06-08 14:55:01 | train] - Train Epoch: [28] [844800/1281167 (66%)]	Loss: 1.389500
[2022-06-08 14:55:22 | train] - Train Epoch: [28] [857600/1281167 (67%)]	Loss: 1.302558
[2022-06-08 14:55:43 | train] - Train Epoch: [28] [870400/1281167 (68%)]	Loss: 1.720648
[2022-06-08 14:56:03 | train] - Train Epoch: [28] [883200/1281167 (69%)]	Loss: 1.557359
[2022-06-08 14:56:25 | train] - Train Epoch: [28] [896000/1281167 (70%)]	Loss: 1.454529
[2022-06-08 14:56:46 | train] - Train Epoch: [28] [908800/1281167 (71%)]	Loss: 1.437450
[2022-06-08 14:57:07 | train] - Train Epoch: [28] [921600/1281167 (72%)]	Loss: 1.372864
[2022-06-08 14:57:28 | train] - Train Epoch: [28] [934400/1281167 (73%)]	Loss: 1.678820
[2022-06-08 14:57:48 | train] - Train Epoch: [28] [947200/1281167 (74%)]	Loss: 1.971064
[2022-06-08 14:58:10 | train] - Train Epoch: [28] [960000/1281167 (75%)]	Loss: 1.526436
[2022-06-08 14:58:31 | train] - Train Epoch: [28] [972800/1281167 (76%)]	Loss: 1.308338
[2022-06-08 14:58:53 | train] - Train Epoch: [28] [985600/1281167 (77%)]	Loss: 1.527439
[2022-06-08 14:59:13 | train] - Train Epoch: [28] [998400/1281167 (78%)]	Loss: 1.495281
[2022-06-08 14:59:34 | train] - Train Epoch: [28] [1011200/1281167 (79%)]	Loss: 1.873858
[2022-06-08 14:59:54 | train] - Train Epoch: [28] [1024000/1281167 (80%)]	Loss: 1.713750
[2022-06-08 15:00:16 | train] - Train Epoch: [28] [1036800/1281167 (81%)]	Loss: 1.488809
[2022-06-08 15:00:38 | train] - Train Epoch: [28] [1049600/1281167 (82%)]	Loss: 1.792011
[2022-06-08 15:00:59 | train] - Train Epoch: [28] [1062400/1281167 (83%)]	Loss: 1.581558
[2022-06-08 15:01:20 | train] - Train Epoch: [28] [1075200/1281167 (84%)]	Loss: 1.893532
[2022-06-08 15:01:41 | train] - Train Epoch: [28] [1088000/1281167 (85%)]	Loss: 1.522732
[2022-06-08 15:02:02 | train] - Train Epoch: [28] [1100800/1281167 (86%)]	Loss: 1.531254
[2022-06-08 15:02:24 | train] - Train Epoch: [28] [1113600/1281167 (87%)]	Loss: 1.772196
[2022-06-08 15:02:44 | train] - Train Epoch: [28] [1126400/1281167 (88%)]	Loss: 1.346451
[2022-06-08 15:03:04 | train] - Train Epoch: [28] [1139200/1281167 (89%)]	Loss: 1.761178
[2022-06-08 15:03:25 | train] - Train Epoch: [28] [1152000/1281167 (90%)]	Loss: 1.706706
[2022-06-08 15:03:46 | train] - Train Epoch: [28] [1164800/1281167 (91%)]	Loss: 1.518214
[2022-06-08 15:04:07 | train] - Train Epoch: [28] [1177600/1281167 (92%)]	Loss: 1.749379
[2022-06-08 15:04:28 | train] - Train Epoch: [28] [1190400/1281167 (93%)]	Loss: 1.587686
[2022-06-08 15:04:49 | train] - Train Epoch: [28] [1203200/1281167 (94%)]	Loss: 1.756145
[2022-06-08 15:05:10 | train] - Train Epoch: [28] [1216000/1281167 (95%)]	Loss: 1.508354
[2022-06-08 15:05:31 | train] - Train Epoch: [28] [1228800/1281167 (96%)]	Loss: 1.754087
[2022-06-08 15:05:51 | train] - Train Epoch: [28] [1241600/1281167 (97%)]	Loss: 1.423568
[2022-06-08 15:06:12 | train] - Train Epoch: [28] [1254400/1281167 (98%)]	Loss: 1.623314
[2022-06-08 15:06:32 | train] - Train Epoch: [28] [1267200/1281167 (99%)]	Loss: 1.848135
[2022-06-08 15:06:52 | train] - Train Epoch: [28] [1280000/1281167 (100%)]	Loss: 1.379523
[2022-06-08 15:06:54 | train] - Train Epoch: [28]	 Average Loss: 1.534491	 Total Acc : 64.0177	 Total Top5 Acc : 84.1343
[2022-06-08 15:06:54 | train] - -------28 epoch end-----------
========================================
-------28 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 15:08:29 | train] - 
Epoch [28] Test set: Average loss: 1.4572, Accuracy: 32679/50000 (65.3277%), Top-5 Accuracy: 86.3795%

[2022-06-08 15:08:29 | train] - save intermediate epoch [28] result


[2022-06-08 15:08:35 | train] - logging best performance 28 epoch
[2022-06-08 15:08:36 | train] - -------29 epoch start-----------
========================================
----- test end -------------------------


logging best performance 28 epoch
[2022-06-08 15:08:38 | train] - Train Epoch: [29] [0/1281167 (0%)]	Loss: 1.351151
[2022-06-08 15:08:59 | train] - Train Epoch: [29] [12800/1281167 (1%)]	Loss: 1.615834
[2022-06-08 15:09:19 | train] - Train Epoch: [29] [25600/1281167 (2%)]	Loss: 1.432563
[2022-06-08 15:09:40 | train] - Train Epoch: [29] [38400/1281167 (3%)]	Loss: 1.538713
[2022-06-08 15:10:00 | train] - Train Epoch: [29] [51200/1281167 (4%)]	Loss: 1.581267
[2022-06-08 15:10:20 | train] - Train Epoch: [29] [64000/1281167 (5%)]	Loss: 1.328522
[2022-06-08 15:10:41 | train] - Train Epoch: [29] [76800/1281167 (6%)]	Loss: 1.486003
[2022-06-08 15:11:02 | train] - Train Epoch: [29] [89600/1281167 (7%)]	Loss: 1.278040
[2022-06-08 15:11:23 | train] - Train Epoch: [29] [102400/1281167 (8%)]	Loss: 1.580823
[2022-06-08 15:11:44 | train] - Train Epoch: [29] [115200/1281167 (9%)]	Loss: 1.424176
[2022-06-08 15:12:04 | train] - Train Epoch: [29] [128000/1281167 (10%)]	Loss: 1.376501
[2022-06-08 15:12:24 | train] - Train Epoch: [29] [140800/1281167 (11%)]	Loss: 1.454024
[2022-06-08 15:12:45 | train] - Train Epoch: [29] [153600/1281167 (12%)]	Loss: 1.525226
[2022-06-08 15:13:05 | train] - Train Epoch: [29] [166400/1281167 (13%)]	Loss: 1.762494
[2022-06-08 15:13:25 | train] - Train Epoch: [29] [179200/1281167 (14%)]	Loss: 1.475146
[2022-06-08 15:13:46 | train] - Train Epoch: [29] [192000/1281167 (15%)]	Loss: 1.648415
[2022-06-08 15:14:07 | train] - Train Epoch: [29] [204800/1281167 (16%)]	Loss: 1.618593
[2022-06-08 15:14:27 | train] - Train Epoch: [29] [217600/1281167 (17%)]	Loss: 1.278082
[2022-06-08 15:14:47 | train] - Train Epoch: [29] [230400/1281167 (18%)]	Loss: 1.515321
[2022-06-08 15:15:07 | train] - Train Epoch: [29] [243200/1281167 (19%)]	Loss: 1.558406
[2022-06-08 15:15:27 | train] - Train Epoch: [29] [256000/1281167 (20%)]	Loss: 1.435189
[2022-06-08 15:15:47 | train] - Train Epoch: [29] [268800/1281167 (21%)]	Loss: 1.212089
[2022-06-08 15:16:07 | train] - Train Epoch: [29] [281600/1281167 (22%)]	Loss: 1.248473
[2022-06-08 15:16:28 | train] - Train Epoch: [29] [294400/1281167 (23%)]	Loss: 1.538780
[2022-06-08 15:16:48 | train] - Train Epoch: [29] [307200/1281167 (24%)]	Loss: 1.520748
[2022-06-08 15:17:09 | train] - Train Epoch: [29] [320000/1281167 (25%)]	Loss: 1.434242
[2022-06-08 15:17:29 | train] - Train Epoch: [29] [332800/1281167 (26%)]	Loss: 1.664706
[2022-06-08 15:17:50 | train] - Train Epoch: [29] [345600/1281167 (27%)]	Loss: 1.633271
[2022-06-08 15:18:10 | train] - Train Epoch: [29] [358400/1281167 (28%)]	Loss: 1.389639
[2022-06-08 15:18:30 | train] - Train Epoch: [29] [371200/1281167 (29%)]	Loss: 1.195336
[2022-06-08 15:18:51 | train] - Train Epoch: [29] [384000/1281167 (30%)]	Loss: 1.863805
[2022-06-08 15:19:12 | train] - Train Epoch: [29] [396800/1281167 (31%)]	Loss: 1.644600
[2022-06-08 15:19:33 | train] - Train Epoch: [29] [409600/1281167 (32%)]	Loss: 1.329883
[2022-06-08 15:19:53 | train] - Train Epoch: [29] [422400/1281167 (33%)]	Loss: 1.253954
[2022-06-08 15:20:14 | train] - Train Epoch: [29] [435200/1281167 (34%)]	Loss: 1.375885
[2022-06-08 15:20:34 | train] - Train Epoch: [29] [448000/1281167 (35%)]	Loss: 1.428777
[2022-06-08 15:20:55 | train] - Train Epoch: [29] [460800/1281167 (36%)]	Loss: 1.504498
[2022-06-08 15:21:16 | train] - Train Epoch: [29] [473600/1281167 (37%)]	Loss: 1.358231
[2022-06-08 15:21:37 | train] - Train Epoch: [29] [486400/1281167 (38%)]	Loss: 1.462424
[2022-06-08 15:21:58 | train] - Train Epoch: [29] [499200/1281167 (39%)]	Loss: 1.489840
[2022-06-08 15:22:19 | train] - Train Epoch: [29] [512000/1281167 (40%)]	Loss: 1.468735
[2022-06-08 15:22:39 | train] - Train Epoch: [29] [524800/1281167 (41%)]	Loss: 1.239729
[2022-06-08 15:23:00 | train] - Train Epoch: [29] [537600/1281167 (42%)]	Loss: 1.523335
[2022-06-08 15:23:21 | train] - Train Epoch: [29] [550400/1281167 (43%)]	Loss: 1.504194
[2022-06-08 15:23:42 | train] - Train Epoch: [29] [563200/1281167 (44%)]	Loss: 1.746596
[2022-06-08 15:24:02 | train] - Train Epoch: [29] [576000/1281167 (45%)]	Loss: 1.633542
[2022-06-08 15:24:23 | train] - Train Epoch: [29] [588800/1281167 (46%)]	Loss: 1.719894
[2022-06-08 15:24:44 | train] - Train Epoch: [29] [601600/1281167 (47%)]	Loss: 0.958512
[2022-06-08 15:25:05 | train] - Train Epoch: [29] [614400/1281167 (48%)]	Loss: 1.927410
[2022-06-08 15:25:25 | train] - Train Epoch: [29] [627200/1281167 (49%)]	Loss: 1.551414
[2022-06-08 15:25:46 | train] - Train Epoch: [29] [640000/1281167 (50%)]	Loss: 1.452441
[2022-06-08 15:26:07 | train] - Train Epoch: [29] [652800/1281167 (51%)]	Loss: 1.319401
[2022-06-08 15:26:27 | train] - Train Epoch: [29] [665600/1281167 (52%)]	Loss: 1.449207
[2022-06-08 15:26:48 | train] - Train Epoch: [29] [678400/1281167 (53%)]	Loss: 1.538700
[2022-06-08 15:27:09 | train] - Train Epoch: [29] [691200/1281167 (54%)]	Loss: 1.535603
[2022-06-08 15:27:30 | train] - Train Epoch: [29] [704000/1281167 (55%)]	Loss: 1.641524
[2022-06-08 15:27:50 | train] - Train Epoch: [29] [716800/1281167 (56%)]	Loss: 1.560241
[2022-06-08 15:28:11 | train] - Train Epoch: [29] [729600/1281167 (57%)]	Loss: 1.654668
[2022-06-08 15:28:32 | train] - Train Epoch: [29] [742400/1281167 (58%)]	Loss: 1.480087
[2022-06-08 15:28:52 | train] - Train Epoch: [29] [755200/1281167 (59%)]	Loss: 1.760113
[2022-06-08 15:29:12 | train] - Train Epoch: [29] [768000/1281167 (60%)]	Loss: 1.596159
[2022-06-08 15:29:33 | train] - Train Epoch: [29] [780800/1281167 (61%)]	Loss: 1.370406
[2022-06-08 15:29:53 | train] - Train Epoch: [29] [793600/1281167 (62%)]	Loss: 1.167022
[2022-06-08 15:30:14 | train] - Train Epoch: [29] [806400/1281167 (63%)]	Loss: 1.332214
[2022-06-08 15:30:34 | train] - Train Epoch: [29] [819200/1281167 (64%)]	Loss: 1.621995
[2022-06-08 15:30:55 | train] - Train Epoch: [29] [832000/1281167 (65%)]	Loss: 1.441965
[2022-06-08 15:31:16 | train] - Train Epoch: [29] [844800/1281167 (66%)]	Loss: 1.682074
[2022-06-08 15:31:37 | train] - Train Epoch: [29] [857600/1281167 (67%)]	Loss: 1.326244
[2022-06-08 15:31:57 | train] - Train Epoch: [29] [870400/1281167 (68%)]	Loss: 1.601441
[2022-06-08 15:32:17 | train] - Train Epoch: [29] [883200/1281167 (69%)]	Loss: 1.501576
[2022-06-08 15:32:37 | train] - Train Epoch: [29] [896000/1281167 (70%)]	Loss: 1.570728
[2022-06-08 15:32:57 | train] - Train Epoch: [29] [908800/1281167 (71%)]	Loss: 1.557381
[2022-06-08 15:33:18 | train] - Train Epoch: [29] [921600/1281167 (72%)]	Loss: 1.381958
[2022-06-08 15:33:39 | train] - Train Epoch: [29] [934400/1281167 (73%)]	Loss: 1.527560
[2022-06-08 15:33:59 | train] - Train Epoch: [29] [947200/1281167 (74%)]	Loss: 1.585126
[2022-06-08 15:34:20 | train] - Train Epoch: [29] [960000/1281167 (75%)]	Loss: 1.375821
[2022-06-08 15:34:40 | train] - Train Epoch: [29] [972800/1281167 (76%)]	Loss: 1.295903
[2022-06-08 15:35:00 | train] - Train Epoch: [29] [985600/1281167 (77%)]	Loss: 1.208644
[2022-06-08 15:35:21 | train] - Train Epoch: [29] [998400/1281167 (78%)]	Loss: 1.547408
[2022-06-08 15:35:41 | train] - Train Epoch: [29] [1011200/1281167 (79%)]	Loss: 1.425128
[2022-06-08 15:36:02 | train] - Train Epoch: [29] [1024000/1281167 (80%)]	Loss: 1.699931
[2022-06-08 15:36:22 | train] - Train Epoch: [29] [1036800/1281167 (81%)]	Loss: 1.036355
[2022-06-08 15:36:43 | train] - Train Epoch: [29] [1049600/1281167 (82%)]	Loss: 1.519463
[2022-06-08 15:37:04 | train] - Train Epoch: [29] [1062400/1281167 (83%)]	Loss: 1.622942
[2022-06-08 15:37:24 | train] - Train Epoch: [29] [1075200/1281167 (84%)]	Loss: 1.699158
[2022-06-08 15:37:44 | train] - Train Epoch: [29] [1088000/1281167 (85%)]	Loss: 1.693110
[2022-06-08 15:38:04 | train] - Train Epoch: [29] [1100800/1281167 (86%)]	Loss: 1.684423
[2022-06-08 15:38:24 | train] - Train Epoch: [29] [1113600/1281167 (87%)]	Loss: 1.440138
[2022-06-08 15:38:44 | train] - Train Epoch: [29] [1126400/1281167 (88%)]	Loss: 1.168666
[2022-06-08 15:39:04 | train] - Train Epoch: [29] [1139200/1281167 (89%)]	Loss: 1.773393
[2022-06-08 15:39:25 | train] - Train Epoch: [29] [1152000/1281167 (90%)]	Loss: 1.348401
[2022-06-08 15:39:45 | train] - Train Epoch: [29] [1164800/1281167 (91%)]	Loss: 1.243268
[2022-06-08 15:40:06 | train] - Train Epoch: [29] [1177600/1281167 (92%)]	Loss: 1.513916
[2022-06-08 15:40:26 | train] - Train Epoch: [29] [1190400/1281167 (93%)]	Loss: 1.520809
[2022-06-08 15:40:46 | train] - Train Epoch: [29] [1203200/1281167 (94%)]	Loss: 1.584359
[2022-06-08 15:41:07 | train] - Train Epoch: [29] [1216000/1281167 (95%)]	Loss: 1.528538
[2022-06-08 15:41:27 | train] - Train Epoch: [29] [1228800/1281167 (96%)]	Loss: 1.401965
[2022-06-08 15:41:47 | train] - Train Epoch: [29] [1241600/1281167 (97%)]	Loss: 1.372761
[2022-06-08 15:42:07 | train] - Train Epoch: [29] [1254400/1281167 (98%)]	Loss: 1.935823
[2022-06-08 15:42:28 | train] - Train Epoch: [29] [1267200/1281167 (99%)]	Loss: 1.709865
[2022-06-08 15:42:48 | train] - Train Epoch: [29] [1280000/1281167 (100%)]	Loss: 1.422879
[2022-06-08 15:42:50 | train] - Train Epoch: [29]	 Average Loss: 1.513323	 Total Acc : 64.4480	 Total Top5 Acc : 84.4215
[2022-06-08 15:42:50 | train] - -------29 epoch end-----------
========================================
-------29 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 15:44:24 | train] - 
Epoch [29] Test set: Average loss: 1.4161, Accuracy: 32867/50000 (65.7021%), Top-5 Accuracy: 86.6804%

[2022-06-08 15:44:24 | train] - save intermediate epoch [29] result


[2022-06-08 15:44:30 | train] - logging best performance 29 epoch
[2022-06-08 15:44:32 | train] - -------30 epoch start-----------
[2022-06-08 15:44:32 | train] - -------- logging 30 batch layer input tensor ------------------
[2022-06-08 15:45:05 | train] - -------- logging end 30 --------------------
========================================
----- test end -------------------------


logging best performance 29 epoch
batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-08 15:45:07 | train] - Train Epoch: [30] [0/1281167 (0%)]	Loss: 1.828107
[2022-06-08 15:45:31 | train] - Train Epoch: [30] [12800/1281167 (1%)]	Loss: 1.600049
[2022-06-08 15:45:54 | train] - Train Epoch: [30] [25600/1281167 (2%)]	Loss: 1.406083
[2022-06-08 15:46:18 | train] - Train Epoch: [30] [38400/1281167 (3%)]	Loss: 1.525802
[2022-06-08 15:46:42 | train] - Train Epoch: [30] [51200/1281167 (4%)]	Loss: 1.696753
[2022-06-08 15:47:04 | train] - Train Epoch: [30] [64000/1281167 (5%)]	Loss: 1.776259
[2022-06-08 15:47:29 | train] - Train Epoch: [30] [76800/1281167 (6%)]	Loss: 1.486952
[2022-06-08 15:47:54 | train] - Train Epoch: [30] [89600/1281167 (7%)]	Loss: 1.383218
[2022-06-08 15:48:19 | train] - Train Epoch: [30] [102400/1281167 (8%)]	Loss: 1.464326
[2022-06-08 15:48:44 | train] - Train Epoch: [30] [115200/1281167 (9%)]	Loss: 1.800135
[2022-06-08 15:49:09 | train] - Train Epoch: [30] [128000/1281167 (10%)]	Loss: 1.334134
[2022-06-08 15:49:32 | train] - Train Epoch: [30] [140800/1281167 (11%)]	Loss: 1.491377
[2022-06-08 15:49:53 | train] - Train Epoch: [30] [153600/1281167 (12%)]	Loss: 1.277681
[2022-06-08 15:50:15 | train] - Train Epoch: [30] [166400/1281167 (13%)]	Loss: 1.736919
[2022-06-08 15:50:37 | train] - Train Epoch: [30] [179200/1281167 (14%)]	Loss: 1.576259
[2022-06-08 15:50:58 | train] - Train Epoch: [30] [192000/1281167 (15%)]	Loss: 1.412305
[2022-06-08 15:51:20 | train] - Train Epoch: [30] [204800/1281167 (16%)]	Loss: 1.378276
[2022-06-08 15:51:42 | train] - Train Epoch: [30] [217600/1281167 (17%)]	Loss: 1.786133
[2022-06-08 15:52:04 | train] - Train Epoch: [30] [230400/1281167 (18%)]	Loss: 1.611250
[2022-06-08 15:52:25 | train] - Train Epoch: [30] [243200/1281167 (19%)]	Loss: 1.228137
[2022-06-08 15:52:46 | train] - Train Epoch: [30] [256000/1281167 (20%)]	Loss: 1.641320
[2022-06-08 15:53:07 | train] - Train Epoch: [30] [268800/1281167 (21%)]	Loss: 1.318443
[2022-06-08 15:53:29 | train] - Train Epoch: [30] [281600/1281167 (22%)]	Loss: 1.364314
[2022-06-08 15:53:51 | train] - Train Epoch: [30] [294400/1281167 (23%)]	Loss: 1.140317
[2022-06-08 15:54:13 | train] - Train Epoch: [30] [307200/1281167 (24%)]	Loss: 1.586211
[2022-06-08 15:54:34 | train] - Train Epoch: [30] [320000/1281167 (25%)]	Loss: 1.418451
[2022-06-08 15:54:55 | train] - Train Epoch: [30] [332800/1281167 (26%)]	Loss: 1.657004
[2022-06-08 15:55:18 | train] - Train Epoch: [30] [345600/1281167 (27%)]	Loss: 1.315412
[2022-06-08 15:55:39 | train] - Train Epoch: [30] [358400/1281167 (28%)]	Loss: 1.611089
[2022-06-08 15:56:01 | train] - Train Epoch: [30] [371200/1281167 (29%)]	Loss: 1.440386
[2022-06-08 15:56:23 | train] - Train Epoch: [30] [384000/1281167 (30%)]	Loss: 1.415107
[2022-06-08 15:56:45 | train] - Train Epoch: [30] [396800/1281167 (31%)]	Loss: 1.533749
[2022-06-08 15:57:07 | train] - Train Epoch: [30] [409600/1281167 (32%)]	Loss: 1.467514
[2022-06-08 15:57:27 | train] - Train Epoch: [30] [422400/1281167 (33%)]	Loss: 1.294112
[2022-06-08 15:57:47 | train] - Train Epoch: [30] [435200/1281167 (34%)]	Loss: 1.209722
[2022-06-08 15:58:08 | train] - Train Epoch: [30] [448000/1281167 (35%)]	Loss: 1.628843
[2022-06-08 15:58:30 | train] - Train Epoch: [30] [460800/1281167 (36%)]	Loss: 1.709162
[2022-06-08 15:58:52 | train] - Train Epoch: [30] [473600/1281167 (37%)]	Loss: 1.508771
[2022-06-08 15:59:14 | train] - Train Epoch: [30] [486400/1281167 (38%)]	Loss: 1.366495
[2022-06-08 15:59:35 | train] - Train Epoch: [30] [499200/1281167 (39%)]	Loss: 1.339516
[2022-06-08 15:59:58 | train] - Train Epoch: [30] [512000/1281167 (40%)]	Loss: 1.377534
[2022-06-08 16:00:20 | train] - Train Epoch: [30] [524800/1281167 (41%)]	Loss: 1.330417
[2022-06-08 16:00:42 | train] - Train Epoch: [30] [537600/1281167 (42%)]	Loss: 1.327354
[2022-06-08 16:01:03 | train] - Train Epoch: [30] [550400/1281167 (43%)]	Loss: 1.775102
[2022-06-08 16:01:24 | train] - Train Epoch: [30] [563200/1281167 (44%)]	Loss: 1.396150
[2022-06-08 16:01:46 | train] - Train Epoch: [30] [576000/1281167 (45%)]	Loss: 1.561485
[2022-06-08 16:02:07 | train] - Train Epoch: [30] [588800/1281167 (46%)]	Loss: 1.582561
[2022-06-08 16:02:28 | train] - Train Epoch: [30] [601600/1281167 (47%)]	Loss: 1.733298
[2022-06-08 16:02:51 | train] - Train Epoch: [30] [614400/1281167 (48%)]	Loss: 1.277964
[2022-06-08 16:03:12 | train] - Train Epoch: [30] [627200/1281167 (49%)]	Loss: 1.418565
[2022-06-08 16:03:33 | train] - Train Epoch: [30] [640000/1281167 (50%)]	Loss: 1.205781
[2022-06-08 16:03:55 | train] - Train Epoch: [30] [652800/1281167 (51%)]	Loss: 1.583185
[2022-06-08 16:04:18 | train] - Train Epoch: [30] [665600/1281167 (52%)]	Loss: 1.215319
[2022-06-08 16:04:38 | train] - Train Epoch: [30] [678400/1281167 (53%)]	Loss: 1.206554
[2022-06-08 16:05:00 | train] - Train Epoch: [30] [691200/1281167 (54%)]	Loss: 1.642613
[2022-06-08 16:05:22 | train] - Train Epoch: [30] [704000/1281167 (55%)]	Loss: 1.315952
[2022-06-08 16:05:43 | train] - Train Epoch: [30] [716800/1281167 (56%)]	Loss: 1.265825
[2022-06-08 16:06:05 | train] - Train Epoch: [30] [729600/1281167 (57%)]	Loss: 1.529075
[2022-06-08 16:06:26 | train] - Train Epoch: [30] [742400/1281167 (58%)]	Loss: 1.495427
[2022-06-08 16:06:48 | train] - Train Epoch: [30] [755200/1281167 (59%)]	Loss: 1.380960
[2022-06-08 16:07:09 | train] - Train Epoch: [30] [768000/1281167 (60%)]	Loss: 1.516091
[2022-06-08 16:07:31 | train] - Train Epoch: [30] [780800/1281167 (61%)]	Loss: 1.729501
[2022-06-08 16:07:53 | train] - Train Epoch: [30] [793600/1281167 (62%)]	Loss: 1.206906
[2022-06-08 16:08:14 | train] - Train Epoch: [30] [806400/1281167 (63%)]	Loss: 1.426261
[2022-06-08 16:08:36 | train] - Train Epoch: [30] [819200/1281167 (64%)]	Loss: 1.851236
[2022-06-08 16:08:59 | train] - Train Epoch: [30] [832000/1281167 (65%)]	Loss: 1.331218
[2022-06-08 16:09:21 | train] - Train Epoch: [30] [844800/1281167 (66%)]	Loss: 1.213247
[2022-06-08 16:09:42 | train] - Train Epoch: [30] [857600/1281167 (67%)]	Loss: 1.585152
[2022-06-08 16:10:04 | train] - Train Epoch: [30] [870400/1281167 (68%)]	Loss: 1.328207
[2022-06-08 16:10:26 | train] - Train Epoch: [30] [883200/1281167 (69%)]	Loss: 1.553986
[2022-06-08 16:10:48 | train] - Train Epoch: [30] [896000/1281167 (70%)]	Loss: 1.598545
[2022-06-08 16:11:09 | train] - Train Epoch: [30] [908800/1281167 (71%)]	Loss: 1.808550
[2022-06-08 16:11:31 | train] - Train Epoch: [30] [921600/1281167 (72%)]	Loss: 1.488726
[2022-06-08 16:11:53 | train] - Train Epoch: [30] [934400/1281167 (73%)]	Loss: 1.489929
[2022-06-08 16:12:15 | train] - Train Epoch: [30] [947200/1281167 (74%)]	Loss: 1.362319
[2022-06-08 16:12:37 | train] - Train Epoch: [30] [960000/1281167 (75%)]	Loss: 1.250662
[2022-06-08 16:12:58 | train] - Train Epoch: [30] [972800/1281167 (76%)]	Loss: 1.459147
[2022-06-08 16:13:20 | train] - Train Epoch: [30] [985600/1281167 (77%)]	Loss: 1.457527
[2022-06-08 16:13:41 | train] - Train Epoch: [30] [998400/1281167 (78%)]	Loss: 1.578482
[2022-06-08 16:14:03 | train] - Train Epoch: [30] [1011200/1281167 (79%)]	Loss: 1.133958
[2022-06-08 16:14:25 | train] - Train Epoch: [30] [1024000/1281167 (80%)]	Loss: 1.443829
[2022-06-08 16:14:47 | train] - Train Epoch: [30] [1036800/1281167 (81%)]	Loss: 1.361338
[2022-06-08 16:15:09 | train] - Train Epoch: [30] [1049600/1281167 (82%)]	Loss: 1.208269
[2022-06-08 16:15:31 | train] - Train Epoch: [30] [1062400/1281167 (83%)]	Loss: 1.668713
[2022-06-08 16:15:53 | train] - Train Epoch: [30] [1075200/1281167 (84%)]	Loss: 1.676035
[2022-06-08 16:16:14 | train] - Train Epoch: [30] [1088000/1281167 (85%)]	Loss: 1.474536
[2022-06-08 16:16:36 | train] - Train Epoch: [30] [1100800/1281167 (86%)]	Loss: 1.313180
[2022-06-08 16:16:59 | train] - Train Epoch: [30] [1113600/1281167 (87%)]	Loss: 1.733175
[2022-06-08 16:17:21 | train] - Train Epoch: [30] [1126400/1281167 (88%)]	Loss: 1.277628
[2022-06-08 16:17:43 | train] - Train Epoch: [30] [1139200/1281167 (89%)]	Loss: 1.450156
[2022-06-08 16:18:05 | train] - Train Epoch: [30] [1152000/1281167 (90%)]	Loss: 1.695953
[2022-06-08 16:18:26 | train] - Train Epoch: [30] [1164800/1281167 (91%)]	Loss: 1.434647
[2022-06-08 16:18:48 | train] - Train Epoch: [30] [1177600/1281167 (92%)]	Loss: 1.668488
[2022-06-08 16:19:10 | train] - Train Epoch: [30] [1190400/1281167 (93%)]	Loss: 1.501087
[2022-06-08 16:19:31 | train] - Train Epoch: [30] [1203200/1281167 (94%)]	Loss: 1.715742
[2022-06-08 16:19:54 | train] - Train Epoch: [30] [1216000/1281167 (95%)]	Loss: 1.689746
[2022-06-08 16:20:15 | train] - Train Epoch: [30] [1228800/1281167 (96%)]	Loss: 1.575393
[2022-06-08 16:20:36 | train] - Train Epoch: [30] [1241600/1281167 (97%)]	Loss: 1.505628
[2022-06-08 16:20:59 | train] - Train Epoch: [30] [1254400/1281167 (98%)]	Loss: 1.563947
[2022-06-08 16:21:21 | train] - Train Epoch: [30] [1267200/1281167 (99%)]	Loss: 1.255240
[2022-06-08 16:21:43 | train] - Train Epoch: [30] [1280000/1281167 (100%)]	Loss: 1.588608
[2022-06-08 16:21:44 | train] - Train Epoch: [30]	 Average Loss: 1.496713	 Total Acc : 64.7859	 Total Top5 Acc : 84.6964
[2022-06-08 16:21:44 | train] - -------30 epoch end-----------
========================================
-------30 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 16:23:28 | train] - 
Epoch [30] Test set: Average loss: 1.4172, Accuracy: 32934/50000 (65.8420%), Top-5 Accuracy: 86.7835%

[2022-06-08 16:23:28 | train] - save intermediate epoch [30] result


[2022-06-08 16:23:36 | train] - logging best performance 30 epoch
[2022-06-08 16:23:38 | train] - -------31 epoch start-----------
========================================
----- test end -------------------------


logging best performance 30 epoch
[2022-06-08 16:23:40 | train] - Train Epoch: [31] [0/1281167 (0%)]	Loss: 1.859842
[2022-06-08 16:24:05 | train] - Train Epoch: [31] [12800/1281167 (1%)]	Loss: 1.517862
[2022-06-08 16:24:30 | train] - Train Epoch: [31] [25600/1281167 (2%)]	Loss: 1.434278
[2022-06-08 16:24:56 | train] - Train Epoch: [31] [38400/1281167 (3%)]	Loss: 1.684865
[2022-06-08 16:25:22 | train] - Train Epoch: [31] [51200/1281167 (4%)]	Loss: 1.145018
[2022-06-08 16:25:45 | train] - Train Epoch: [31] [64000/1281167 (5%)]	Loss: 1.733643
[2022-06-08 16:26:07 | train] - Train Epoch: [31] [76800/1281167 (6%)]	Loss: 1.311825
[2022-06-08 16:26:29 | train] - Train Epoch: [31] [89600/1281167 (7%)]	Loss: 1.496200
[2022-06-08 16:26:49 | train] - Train Epoch: [31] [102400/1281167 (8%)]	Loss: 1.232245
[2022-06-08 16:27:11 | train] - Train Epoch: [31] [115200/1281167 (9%)]	Loss: 1.559986
[2022-06-08 16:27:32 | train] - Train Epoch: [31] [128000/1281167 (10%)]	Loss: 1.226424
[2022-06-08 16:27:54 | train] - Train Epoch: [31] [140800/1281167 (11%)]	Loss: 1.803791
[2022-06-08 16:28:15 | train] - Train Epoch: [31] [153600/1281167 (12%)]	Loss: 1.467832
[2022-06-08 16:28:37 | train] - Train Epoch: [31] [166400/1281167 (13%)]	Loss: 1.167024
[2022-06-08 16:28:59 | train] - Train Epoch: [31] [179200/1281167 (14%)]	Loss: 1.594461
[2022-06-08 16:29:20 | train] - Train Epoch: [31] [192000/1281167 (15%)]	Loss: 1.412501
[2022-06-08 16:29:43 | train] - Train Epoch: [31] [204800/1281167 (16%)]	Loss: 1.256661
[2022-06-08 16:30:04 | train] - Train Epoch: [31] [217600/1281167 (17%)]	Loss: 1.601008
[2022-06-08 16:30:26 | train] - Train Epoch: [31] [230400/1281167 (18%)]	Loss: 1.415598
[2022-06-08 16:30:48 | train] - Train Epoch: [31] [243200/1281167 (19%)]	Loss: 1.335204
[2022-06-08 16:31:10 | train] - Train Epoch: [31] [256000/1281167 (20%)]	Loss: 1.454851
[2022-06-08 16:31:32 | train] - Train Epoch: [31] [268800/1281167 (21%)]	Loss: 1.696677
[2022-06-08 16:31:53 | train] - Train Epoch: [31] [281600/1281167 (22%)]	Loss: 1.526554
[2022-06-08 16:32:15 | train] - Train Epoch: [31] [294400/1281167 (23%)]	Loss: 1.586072
[2022-06-08 16:32:37 | train] - Train Epoch: [31] [307200/1281167 (24%)]	Loss: 1.727329
[2022-06-08 16:32:59 | train] - Train Epoch: [31] [320000/1281167 (25%)]	Loss: 1.782919
[2022-06-08 16:33:20 | train] - Train Epoch: [31] [332800/1281167 (26%)]	Loss: 1.522236
[2022-06-08 16:33:42 | train] - Train Epoch: [31] [345600/1281167 (27%)]	Loss: 1.449723
[2022-06-08 16:34:04 | train] - Train Epoch: [31] [358400/1281167 (28%)]	Loss: 1.702342
[2022-06-08 16:34:26 | train] - Train Epoch: [31] [371200/1281167 (29%)]	Loss: 1.158435
[2022-06-08 16:34:47 | train] - Train Epoch: [31] [384000/1281167 (30%)]	Loss: 1.528194
[2022-06-08 16:35:09 | train] - Train Epoch: [31] [396800/1281167 (31%)]	Loss: 1.489593
[2022-06-08 16:35:32 | train] - Train Epoch: [31] [409600/1281167 (32%)]	Loss: 1.450769
[2022-06-08 16:35:53 | train] - Train Epoch: [31] [422400/1281167 (33%)]	Loss: 1.600508
[2022-06-08 16:36:14 | train] - Train Epoch: [31] [435200/1281167 (34%)]	Loss: 1.697024
[2022-06-08 16:36:35 | train] - Train Epoch: [31] [448000/1281167 (35%)]	Loss: 1.187390
[2022-06-08 16:36:56 | train] - Train Epoch: [31] [460800/1281167 (36%)]	Loss: 1.458061
[2022-06-08 16:37:17 | train] - Train Epoch: [31] [473600/1281167 (37%)]	Loss: 1.362221
[2022-06-08 16:37:39 | train] - Train Epoch: [31] [486400/1281167 (38%)]	Loss: 1.648897
[2022-06-08 16:38:01 | train] - Train Epoch: [31] [499200/1281167 (39%)]	Loss: 1.205429
[2022-06-08 16:38:23 | train] - Train Epoch: [31] [512000/1281167 (40%)]	Loss: 1.859790
[2022-06-08 16:38:44 | train] - Train Epoch: [31] [524800/1281167 (41%)]	Loss: 1.521999
[2022-06-08 16:39:06 | train] - Train Epoch: [31] [537600/1281167 (42%)]	Loss: 1.265871
[2022-06-08 16:39:28 | train] - Train Epoch: [31] [550400/1281167 (43%)]	Loss: 1.383412
[2022-06-08 16:39:49 | train] - Train Epoch: [31] [563200/1281167 (44%)]	Loss: 1.532259
[2022-06-08 16:40:11 | train] - Train Epoch: [31] [576000/1281167 (45%)]	Loss: 1.414242
[2022-06-08 16:40:33 | train] - Train Epoch: [31] [588800/1281167 (46%)]	Loss: 1.452357
[2022-06-08 16:40:55 | train] - Train Epoch: [31] [601600/1281167 (47%)]	Loss: 1.343132
[2022-06-08 16:41:17 | train] - Train Epoch: [31] [614400/1281167 (48%)]	Loss: 1.258935
[2022-06-08 16:41:40 | train] - Train Epoch: [31] [627200/1281167 (49%)]	Loss: 1.264619
[2022-06-08 16:42:00 | train] - Train Epoch: [31] [640000/1281167 (50%)]	Loss: 1.908424
[2022-06-08 16:42:22 | train] - Train Epoch: [31] [652800/1281167 (51%)]	Loss: 1.505662
[2022-06-08 16:42:44 | train] - Train Epoch: [31] [665600/1281167 (52%)]	Loss: 1.376198
[2022-06-08 16:43:06 | train] - Train Epoch: [31] [678400/1281167 (53%)]	Loss: 1.582268
[2022-06-08 16:43:28 | train] - Train Epoch: [31] [691200/1281167 (54%)]	Loss: 1.562541
[2022-06-08 16:43:51 | train] - Train Epoch: [31] [704000/1281167 (55%)]	Loss: 1.469416
[2022-06-08 16:44:12 | train] - Train Epoch: [31] [716800/1281167 (56%)]	Loss: 1.232322
[2022-06-08 16:44:34 | train] - Train Epoch: [31] [729600/1281167 (57%)]	Loss: 1.633486
[2022-06-08 16:44:56 | train] - Train Epoch: [31] [742400/1281167 (58%)]	Loss: 1.606920
[2022-06-08 16:45:17 | train] - Train Epoch: [31] [755200/1281167 (59%)]	Loss: 1.372811
[2022-06-08 16:45:39 | train] - Train Epoch: [31] [768000/1281167 (60%)]	Loss: 1.598455
[2022-06-08 16:46:00 | train] - Train Epoch: [31] [780800/1281167 (61%)]	Loss: 1.431533
[2022-06-08 16:46:23 | train] - Train Epoch: [31] [793600/1281167 (62%)]	Loss: 1.662850
[2022-06-08 16:46:46 | train] - Train Epoch: [31] [806400/1281167 (63%)]	Loss: 1.366124
[2022-06-08 16:47:08 | train] - Train Epoch: [31] [819200/1281167 (64%)]	Loss: 1.622510
[2022-06-08 16:47:28 | train] - Train Epoch: [31] [832000/1281167 (65%)]	Loss: 1.221823
[2022-06-08 16:47:50 | train] - Train Epoch: [31] [844800/1281167 (66%)]	Loss: 1.607577
[2022-06-08 16:48:12 | train] - Train Epoch: [31] [857600/1281167 (67%)]	Loss: 1.276404
[2022-06-08 16:48:34 | train] - Train Epoch: [31] [870400/1281167 (68%)]	Loss: 1.673680
[2022-06-08 16:48:56 | train] - Train Epoch: [31] [883200/1281167 (69%)]	Loss: 1.544359
[2022-06-08 16:49:18 | train] - Train Epoch: [31] [896000/1281167 (70%)]	Loss: 1.545217
[2022-06-08 16:49:39 | train] - Train Epoch: [31] [908800/1281167 (71%)]	Loss: 1.333560
[2022-06-08 16:50:00 | train] - Train Epoch: [31] [921600/1281167 (72%)]	Loss: 1.681181
[2022-06-08 16:50:22 | train] - Train Epoch: [31] [934400/1281167 (73%)]	Loss: 1.413315
[2022-06-08 16:50:44 | train] - Train Epoch: [31] [947200/1281167 (74%)]	Loss: 1.607899
[2022-06-08 16:51:04 | train] - Train Epoch: [31] [960000/1281167 (75%)]	Loss: 1.233152
[2022-06-08 16:51:25 | train] - Train Epoch: [31] [972800/1281167 (76%)]	Loss: 1.202130
[2022-06-08 16:51:46 | train] - Train Epoch: [31] [985600/1281167 (77%)]	Loss: 1.467945
[2022-06-08 16:52:08 | train] - Train Epoch: [31] [998400/1281167 (78%)]	Loss: 1.354829
[2022-06-08 16:52:29 | train] - Train Epoch: [31] [1011200/1281167 (79%)]	Loss: 1.528027
[2022-06-08 16:52:51 | train] - Train Epoch: [31] [1024000/1281167 (80%)]	Loss: 1.506251
[2022-06-08 16:53:12 | train] - Train Epoch: [31] [1036800/1281167 (81%)]	Loss: 1.810362
[2022-06-08 16:53:33 | train] - Train Epoch: [31] [1049600/1281167 (82%)]	Loss: 1.482146
[2022-06-08 16:53:55 | train] - Train Epoch: [31] [1062400/1281167 (83%)]	Loss: 1.390425
[2022-06-08 16:54:17 | train] - Train Epoch: [31] [1075200/1281167 (84%)]	Loss: 1.354106
[2022-06-08 16:54:37 | train] - Train Epoch: [31] [1088000/1281167 (85%)]	Loss: 1.391107
[2022-06-08 16:54:59 | train] - Train Epoch: [31] [1100800/1281167 (86%)]	Loss: 1.388890
[2022-06-08 16:55:20 | train] - Train Epoch: [31] [1113600/1281167 (87%)]	Loss: 1.401832
[2022-06-08 16:55:43 | train] - Train Epoch: [31] [1126400/1281167 (88%)]	Loss: 1.317701
[2022-06-08 16:56:03 | train] - Train Epoch: [31] [1139200/1281167 (89%)]	Loss: 1.574394
[2022-06-08 16:56:24 | train] - Train Epoch: [31] [1152000/1281167 (90%)]	Loss: 1.399636
[2022-06-08 16:56:46 | train] - Train Epoch: [31] [1164800/1281167 (91%)]	Loss: 1.208489
[2022-06-08 16:57:07 | train] - Train Epoch: [31] [1177600/1281167 (92%)]	Loss: 1.470328
[2022-06-08 16:57:28 | train] - Train Epoch: [31] [1190400/1281167 (93%)]	Loss: 1.420758
[2022-06-08 16:57:50 | train] - Train Epoch: [31] [1203200/1281167 (94%)]	Loss: 1.572797
[2022-06-08 16:58:11 | train] - Train Epoch: [31] [1216000/1281167 (95%)]	Loss: 1.926928
[2022-06-08 16:58:32 | train] - Train Epoch: [31] [1228800/1281167 (96%)]	Loss: 1.248631
[2022-06-08 16:58:53 | train] - Train Epoch: [31] [1241600/1281167 (97%)]	Loss: 1.644465
[2022-06-08 16:59:15 | train] - Train Epoch: [31] [1254400/1281167 (98%)]	Loss: 1.713015
[2022-06-08 16:59:37 | train] - Train Epoch: [31] [1267200/1281167 (99%)]	Loss: 1.645667
[2022-06-08 16:59:58 | train] - Train Epoch: [31] [1280000/1281167 (100%)]	Loss: 1.580739
[2022-06-08 17:00:00 | train] - Train Epoch: [31]	 Average Loss: 1.479693	 Total Acc : 65.1389	 Total Top5 Acc : 84.8889
[2022-06-08 17:00:00 | train] - -------31 epoch end-----------
========================================
-------31 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 17:01:39 | train] - 
Epoch [31] Test set: Average loss: 1.4238, Accuracy: 33132/50000 (66.2304%), Top-5 Accuracy: 86.8358%

[2022-06-08 17:01:39 | train] - save intermediate epoch [31] result


[2022-06-08 17:01:47 | train] - logging best performance 31 epoch
[2022-06-08 17:01:48 | train] - -------32 epoch start-----------
========================================
----- test end -------------------------


logging best performance 31 epoch
[2022-06-08 17:01:50 | train] - Train Epoch: [32] [0/1281167 (0%)]	Loss: 1.490713
[2022-06-08 17:02:15 | train] - Train Epoch: [32] [12800/1281167 (1%)]	Loss: 1.398780
[2022-06-08 17:02:41 | train] - Train Epoch: [32] [25600/1281167 (2%)]	Loss: 1.206825
[2022-06-08 17:03:06 | train] - Train Epoch: [32] [38400/1281167 (3%)]	Loss: 1.495209
[2022-06-08 17:03:31 | train] - Train Epoch: [32] [51200/1281167 (4%)]	Loss: 1.324852
[2022-06-08 17:03:57 | train] - Train Epoch: [32] [64000/1281167 (5%)]	Loss: 1.262825
[2022-06-08 17:04:22 | train] - Train Epoch: [32] [76800/1281167 (6%)]	Loss: 1.302667
[2022-06-08 17:04:45 | train] - Train Epoch: [32] [89600/1281167 (7%)]	Loss: 1.604103
[2022-06-08 17:05:07 | train] - Train Epoch: [32] [102400/1281167 (8%)]	Loss: 1.351549
[2022-06-08 17:05:29 | train] - Train Epoch: [32] [115200/1281167 (9%)]	Loss: 1.201903
[2022-06-08 17:05:50 | train] - Train Epoch: [32] [128000/1281167 (10%)]	Loss: 1.564220
[2022-06-08 17:06:12 | train] - Train Epoch: [32] [140800/1281167 (11%)]	Loss: 1.338918
[2022-06-08 17:06:34 | train] - Train Epoch: [32] [153600/1281167 (12%)]	Loss: 1.299430
[2022-06-08 17:06:55 | train] - Train Epoch: [32] [166400/1281167 (13%)]	Loss: 1.177074
[2022-06-08 17:07:16 | train] - Train Epoch: [32] [179200/1281167 (14%)]	Loss: 1.277037
[2022-06-08 17:07:38 | train] - Train Epoch: [32] [192000/1281167 (15%)]	Loss: 1.356881
[2022-06-08 17:08:01 | train] - Train Epoch: [32] [204800/1281167 (16%)]	Loss: 1.251467
[2022-06-08 17:08:26 | train] - Train Epoch: [32] [217600/1281167 (17%)]	Loss: 1.539179
[2022-06-08 17:08:52 | train] - Train Epoch: [32] [230400/1281167 (18%)]	Loss: 1.408331
[2022-06-08 17:09:17 | train] - Train Epoch: [32] [243200/1281167 (19%)]	Loss: 1.305318
[2022-06-08 17:09:42 | train] - Train Epoch: [32] [256000/1281167 (20%)]	Loss: 1.219466
[2022-06-08 17:10:07 | train] - Train Epoch: [32] [268800/1281167 (21%)]	Loss: 1.287030
[2022-06-08 17:10:33 | train] - Train Epoch: [32] [281600/1281167 (22%)]	Loss: 1.527537
[2022-06-08 17:10:57 | train] - Train Epoch: [32] [294400/1281167 (23%)]	Loss: 1.434545
[2022-06-08 17:11:23 | train] - Train Epoch: [32] [307200/1281167 (24%)]	Loss: 1.651031
[2022-06-08 17:11:45 | train] - Train Epoch: [32] [320000/1281167 (25%)]	Loss: 1.415686
[2022-06-08 17:12:08 | train] - Train Epoch: [32] [332800/1281167 (26%)]	Loss: 1.352532
[2022-06-08 17:12:30 | train] - Train Epoch: [32] [345600/1281167 (27%)]	Loss: 1.516204
[2022-06-08 17:12:51 | train] - Train Epoch: [32] [358400/1281167 (28%)]	Loss: 1.238303
[2022-06-08 17:13:13 | train] - Train Epoch: [32] [371200/1281167 (29%)]	Loss: 1.384882
[2022-06-08 17:13:35 | train] - Train Epoch: [32] [384000/1281167 (30%)]	Loss: 1.157719
[2022-06-08 17:13:57 | train] - Train Epoch: [32] [396800/1281167 (31%)]	Loss: 1.480087
[2022-06-08 17:14:19 | train] - Train Epoch: [32] [409600/1281167 (32%)]	Loss: 1.513261
[2022-06-08 17:14:40 | train] - Train Epoch: [32] [422400/1281167 (33%)]	Loss: 1.405954
[2022-06-08 17:15:02 | train] - Train Epoch: [32] [435200/1281167 (34%)]	Loss: 1.218967
[2022-06-08 17:15:23 | train] - Train Epoch: [32] [448000/1281167 (35%)]	Loss: 1.321956
[2022-06-08 17:15:46 | train] - Train Epoch: [32] [460800/1281167 (36%)]	Loss: 1.345136
[2022-06-08 17:16:06 | train] - Train Epoch: [32] [473600/1281167 (37%)]	Loss: 1.337339
[2022-06-08 17:16:28 | train] - Train Epoch: [32] [486400/1281167 (38%)]	Loss: 1.419108
[2022-06-08 17:16:51 | train] - Train Epoch: [32] [499200/1281167 (39%)]	Loss: 1.505897
[2022-06-08 17:17:13 | train] - Train Epoch: [32] [512000/1281167 (40%)]	Loss: 1.622308
[2022-06-08 17:17:34 | train] - Train Epoch: [32] [524800/1281167 (41%)]	Loss: 1.646490
[2022-06-08 17:17:57 | train] - Train Epoch: [32] [537600/1281167 (42%)]	Loss: 1.364033
[2022-06-08 17:18:18 | train] - Train Epoch: [32] [550400/1281167 (43%)]	Loss: 1.252334
[2022-06-08 17:18:39 | train] - Train Epoch: [32] [563200/1281167 (44%)]	Loss: 1.443571
[2022-06-08 17:19:00 | train] - Train Epoch: [32] [576000/1281167 (45%)]	Loss: 1.905194
[2022-06-08 17:19:22 | train] - Train Epoch: [32] [588800/1281167 (46%)]	Loss: 1.164613
[2022-06-08 17:19:43 | train] - Train Epoch: [32] [601600/1281167 (47%)]	Loss: 1.602037
[2022-06-08 17:20:06 | train] - Train Epoch: [32] [614400/1281167 (48%)]	Loss: 1.493255
[2022-06-08 17:20:28 | train] - Train Epoch: [32] [627200/1281167 (49%)]	Loss: 1.309485
[2022-06-08 17:20:49 | train] - Train Epoch: [32] [640000/1281167 (50%)]	Loss: 1.371258
[2022-06-08 17:21:11 | train] - Train Epoch: [32] [652800/1281167 (51%)]	Loss: 1.710138
[2022-06-08 17:21:33 | train] - Train Epoch: [32] [665600/1281167 (52%)]	Loss: 1.396473
[2022-06-08 17:21:55 | train] - Train Epoch: [32] [678400/1281167 (53%)]	Loss: 1.533939
[2022-06-08 17:22:17 | train] - Train Epoch: [32] [691200/1281167 (54%)]	Loss: 1.514377
[2022-06-08 17:22:39 | train] - Train Epoch: [32] [704000/1281167 (55%)]	Loss: 1.513346
[2022-06-08 17:23:01 | train] - Train Epoch: [32] [716800/1281167 (56%)]	Loss: 1.394348
[2022-06-08 17:23:22 | train] - Train Epoch: [32] [729600/1281167 (57%)]	Loss: 1.688605
[2022-06-08 17:23:44 | train] - Train Epoch: [32] [742400/1281167 (58%)]	Loss: 1.553192
[2022-06-08 17:24:06 | train] - Train Epoch: [32] [755200/1281167 (59%)]	Loss: 1.649898
[2022-06-08 17:24:28 | train] - Train Epoch: [32] [768000/1281167 (60%)]	Loss: 1.400033
[2022-06-08 17:24:49 | train] - Train Epoch: [32] [780800/1281167 (61%)]	Loss: 1.402318
[2022-06-08 17:25:12 | train] - Train Epoch: [32] [793600/1281167 (62%)]	Loss: 1.697632
[2022-06-08 17:25:33 | train] - Train Epoch: [32] [806400/1281167 (63%)]	Loss: 1.442272
[2022-06-08 17:25:54 | train] - Train Epoch: [32] [819200/1281167 (64%)]	Loss: 1.753860
[2022-06-08 17:26:16 | train] - Train Epoch: [32] [832000/1281167 (65%)]	Loss: 1.528810
[2022-06-08 17:26:38 | train] - Train Epoch: [32] [844800/1281167 (66%)]	Loss: 1.465947
[2022-06-08 17:27:00 | train] - Train Epoch: [32] [857600/1281167 (67%)]	Loss: 1.525180
[2022-06-08 17:27:22 | train] - Train Epoch: [32] [870400/1281167 (68%)]	Loss: 1.376472
[2022-06-08 17:27:43 | train] - Train Epoch: [32] [883200/1281167 (69%)]	Loss: 1.559811
[2022-06-08 17:28:05 | train] - Train Epoch: [32] [896000/1281167 (70%)]	Loss: 2.001886
[2022-06-08 17:28:26 | train] - Train Epoch: [32] [908800/1281167 (71%)]	Loss: 1.124695
[2022-06-08 17:28:48 | train] - Train Epoch: [32] [921600/1281167 (72%)]	Loss: 1.574385
[2022-06-08 17:29:10 | train] - Train Epoch: [32] [934400/1281167 (73%)]	Loss: 1.273658
[2022-06-08 17:29:32 | train] - Train Epoch: [32] [947200/1281167 (74%)]	Loss: 1.433464
[2022-06-08 17:29:53 | train] - Train Epoch: [32] [960000/1281167 (75%)]	Loss: 1.475259
[2022-06-08 17:30:15 | train] - Train Epoch: [32] [972800/1281167 (76%)]	Loss: 1.290267
[2022-06-08 17:30:37 | train] - Train Epoch: [32] [985600/1281167 (77%)]	Loss: 1.556286
[2022-06-08 17:30:58 | train] - Train Epoch: [32] [998400/1281167 (78%)]	Loss: 1.536694
[2022-06-08 17:31:19 | train] - Train Epoch: [32] [1011200/1281167 (79%)]	Loss: 1.224043
[2022-06-08 17:31:40 | train] - Train Epoch: [32] [1024000/1281167 (80%)]	Loss: 1.252810
[2022-06-08 17:32:01 | train] - Train Epoch: [32] [1036800/1281167 (81%)]	Loss: 1.255454
[2022-06-08 17:32:22 | train] - Train Epoch: [32] [1049600/1281167 (82%)]	Loss: 1.471440
[2022-06-08 17:32:44 | train] - Train Epoch: [32] [1062400/1281167 (83%)]	Loss: 1.443874
[2022-06-08 17:33:05 | train] - Train Epoch: [32] [1075200/1281167 (84%)]	Loss: 1.388485
[2022-06-08 17:33:26 | train] - Train Epoch: [32] [1088000/1281167 (85%)]	Loss: 1.645997
[2022-06-08 17:33:47 | train] - Train Epoch: [32] [1100800/1281167 (86%)]	Loss: 1.165552
[2022-06-08 17:34:09 | train] - Train Epoch: [32] [1113600/1281167 (87%)]	Loss: 1.402944
[2022-06-08 17:34:31 | train] - Train Epoch: [32] [1126400/1281167 (88%)]	Loss: 1.289505
[2022-06-08 17:34:53 | train] - Train Epoch: [32] [1139200/1281167 (89%)]	Loss: 1.687081
[2022-06-08 17:35:15 | train] - Train Epoch: [32] [1152000/1281167 (90%)]	Loss: 1.495448
[2022-06-08 17:35:36 | train] - Train Epoch: [32] [1164800/1281167 (91%)]	Loss: 1.328611
[2022-06-08 17:35:58 | train] - Train Epoch: [32] [1177600/1281167 (92%)]	Loss: 1.774245
[2022-06-08 17:36:21 | train] - Train Epoch: [32] [1190400/1281167 (93%)]	Loss: 1.800471
[2022-06-08 17:36:43 | train] - Train Epoch: [32] [1203200/1281167 (94%)]	Loss: 1.646532
[2022-06-08 17:37:04 | train] - Train Epoch: [32] [1216000/1281167 (95%)]	Loss: 1.171421
[2022-06-08 17:37:26 | train] - Train Epoch: [32] [1228800/1281167 (96%)]	Loss: 1.330138
[2022-06-08 17:37:48 | train] - Train Epoch: [32] [1241600/1281167 (97%)]	Loss: 1.754827
[2022-06-08 17:38:09 | train] - Train Epoch: [32] [1254400/1281167 (98%)]	Loss: 1.733807
[2022-06-08 17:38:31 | train] - Train Epoch: [32] [1267200/1281167 (99%)]	Loss: 1.609524
[2022-06-08 17:38:53 | train] - Train Epoch: [32] [1280000/1281167 (100%)]	Loss: 1.637312
[2022-06-08 17:38:55 | train] - Train Epoch: [32]	 Average Loss: 1.461752	 Total Acc : 65.4955	 Total Top5 Acc : 85.1252
[2022-06-08 17:38:55 | train] - -------32 epoch end-----------
========================================
-------32 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 17:40:28 | train] - 
Epoch [32] Test set: Average loss: 1.4075, Accuracy: 33304/50000 (66.5861%), Top-5 Accuracy: 86.9841%

[2022-06-08 17:40:28 | train] - save intermediate epoch [32] result


[2022-06-08 17:40:35 | train] - logging best performance 32 epoch
[2022-06-08 17:40:36 | train] - -------33 epoch start-----------
========================================
----- test end -------------------------


logging best performance 32 epoch
[2022-06-08 17:40:38 | train] - Train Epoch: [33] [0/1281167 (0%)]	Loss: 1.658209
[2022-06-08 17:40:59 | train] - Train Epoch: [33] [12800/1281167 (1%)]	Loss: 1.650488
[2022-06-08 17:41:21 | train] - Train Epoch: [33] [25600/1281167 (2%)]	Loss: 1.428848
[2022-06-08 17:41:44 | train] - Train Epoch: [33] [38400/1281167 (3%)]	Loss: 1.555870
[2022-06-08 17:42:06 | train] - Train Epoch: [33] [51200/1281167 (4%)]	Loss: 1.548126
[2022-06-08 17:42:28 | train] - Train Epoch: [33] [64000/1281167 (5%)]	Loss: 1.024724
[2022-06-08 17:42:51 | train] - Train Epoch: [33] [76800/1281167 (6%)]	Loss: 1.374790
[2022-06-08 17:43:13 | train] - Train Epoch: [33] [89600/1281167 (7%)]	Loss: 1.442224
[2022-06-08 17:43:34 | train] - Train Epoch: [33] [102400/1281167 (8%)]	Loss: 1.591814
[2022-06-08 17:43:56 | train] - Train Epoch: [33] [115200/1281167 (9%)]	Loss: 1.516482
[2022-06-08 17:44:18 | train] - Train Epoch: [33] [128000/1281167 (10%)]	Loss: 1.419769
[2022-06-08 17:44:40 | train] - Train Epoch: [33] [140800/1281167 (11%)]	Loss: 1.587192
[2022-06-08 17:45:02 | train] - Train Epoch: [33] [153600/1281167 (12%)]	Loss: 1.753317
[2022-06-08 17:45:24 | train] - Train Epoch: [33] [166400/1281167 (13%)]	Loss: 1.438653
[2022-06-08 17:45:46 | train] - Train Epoch: [33] [179200/1281167 (14%)]	Loss: 1.303508
[2022-06-08 17:46:09 | train] - Train Epoch: [33] [192000/1281167 (15%)]	Loss: 1.490162
[2022-06-08 17:46:30 | train] - Train Epoch: [33] [204800/1281167 (16%)]	Loss: 1.193344
[2022-06-08 17:46:51 | train] - Train Epoch: [33] [217600/1281167 (17%)]	Loss: 1.217663
[2022-06-08 17:47:13 | train] - Train Epoch: [33] [230400/1281167 (18%)]	Loss: 1.733185
[2022-06-08 17:47:35 | train] - Train Epoch: [33] [243200/1281167 (19%)]	Loss: 1.484675
[2022-06-08 17:47:58 | train] - Train Epoch: [33] [256000/1281167 (20%)]	Loss: 1.615118
[2022-06-08 17:48:19 | train] - Train Epoch: [33] [268800/1281167 (21%)]	Loss: 1.255034
[2022-06-08 17:48:41 | train] - Train Epoch: [33] [281600/1281167 (22%)]	Loss: 1.479702
[2022-06-08 17:49:03 | train] - Train Epoch: [33] [294400/1281167 (23%)]	Loss: 1.328371
[2022-06-08 17:49:25 | train] - Train Epoch: [33] [307200/1281167 (24%)]	Loss: 1.756071
[2022-06-08 17:49:47 | train] - Train Epoch: [33] [320000/1281167 (25%)]	Loss: 1.714503
[2022-06-08 17:50:09 | train] - Train Epoch: [33] [332800/1281167 (26%)]	Loss: 1.211842
[2022-06-08 17:50:31 | train] - Train Epoch: [33] [345600/1281167 (27%)]	Loss: 1.646898
[2022-06-08 17:50:52 | train] - Train Epoch: [33] [358400/1281167 (28%)]	Loss: 1.220389
[2022-06-08 17:51:15 | train] - Train Epoch: [33] [371200/1281167 (29%)]	Loss: 1.570780
[2022-06-08 17:51:37 | train] - Train Epoch: [33] [384000/1281167 (30%)]	Loss: 1.485243
[2022-06-08 17:51:59 | train] - Train Epoch: [33] [396800/1281167 (31%)]	Loss: 1.673762
[2022-06-08 17:52:21 | train] - Train Epoch: [33] [409600/1281167 (32%)]	Loss: 1.293728
[2022-06-08 17:52:42 | train] - Train Epoch: [33] [422400/1281167 (33%)]	Loss: 1.128298
[2022-06-08 17:53:05 | train] - Train Epoch: [33] [435200/1281167 (34%)]	Loss: 1.359398
[2022-06-08 17:53:27 | train] - Train Epoch: [33] [448000/1281167 (35%)]	Loss: 1.901197
[2022-06-08 17:53:49 | train] - Train Epoch: [33] [460800/1281167 (36%)]	Loss: 1.456709
[2022-06-08 17:54:11 | train] - Train Epoch: [33] [473600/1281167 (37%)]	Loss: 1.556715
[2022-06-08 17:54:32 | train] - Train Epoch: [33] [486400/1281167 (38%)]	Loss: 1.645739
[2022-06-08 17:54:53 | train] - Train Epoch: [33] [499200/1281167 (39%)]	Loss: 1.530672
[2022-06-08 17:55:14 | train] - Train Epoch: [33] [512000/1281167 (40%)]	Loss: 1.612198
[2022-06-08 17:55:35 | train] - Train Epoch: [33] [524800/1281167 (41%)]	Loss: 1.503452
[2022-06-08 17:55:56 | train] - Train Epoch: [33] [537600/1281167 (42%)]	Loss: 1.525120
[2022-06-08 17:56:17 | train] - Train Epoch: [33] [550400/1281167 (43%)]	Loss: 1.406913
[2022-06-08 17:56:37 | train] - Train Epoch: [33] [563200/1281167 (44%)]	Loss: 1.538813
[2022-06-08 17:57:00 | train] - Train Epoch: [33] [576000/1281167 (45%)]	Loss: 1.250582
[2022-06-08 17:57:21 | train] - Train Epoch: [33] [588800/1281167 (46%)]	Loss: 1.329414
[2022-06-08 17:57:43 | train] - Train Epoch: [33] [601600/1281167 (47%)]	Loss: 1.268090
[2022-06-08 17:58:05 | train] - Train Epoch: [33] [614400/1281167 (48%)]	Loss: 1.427256
[2022-06-08 17:58:27 | train] - Train Epoch: [33] [627200/1281167 (49%)]	Loss: 1.635667
[2022-06-08 17:58:48 | train] - Train Epoch: [33] [640000/1281167 (50%)]	Loss: 1.484004
[2022-06-08 17:59:10 | train] - Train Epoch: [33] [652800/1281167 (51%)]	Loss: 1.336511
[2022-06-08 17:59:32 | train] - Train Epoch: [33] [665600/1281167 (52%)]	Loss: 1.759159
[2022-06-08 17:59:54 | train] - Train Epoch: [33] [678400/1281167 (53%)]	Loss: 1.432978
[2022-06-08 18:00:16 | train] - Train Epoch: [33] [691200/1281167 (54%)]	Loss: 1.372244
[2022-06-08 18:00:38 | train] - Train Epoch: [33] [704000/1281167 (55%)]	Loss: 1.637053
[2022-06-08 18:01:01 | train] - Train Epoch: [33] [716800/1281167 (56%)]	Loss: 1.660833
[2022-06-08 18:01:22 | train] - Train Epoch: [33] [729600/1281167 (57%)]	Loss: 1.314495
[2022-06-08 18:01:44 | train] - Train Epoch: [33] [742400/1281167 (58%)]	Loss: 1.360145
[2022-06-08 18:02:05 | train] - Train Epoch: [33] [755200/1281167 (59%)]	Loss: 1.709328
[2022-06-08 18:02:27 | train] - Train Epoch: [33] [768000/1281167 (60%)]	Loss: 1.480067
[2022-06-08 18:02:50 | train] - Train Epoch: [33] [780800/1281167 (61%)]	Loss: 1.467406
[2022-06-08 18:03:12 | train] - Train Epoch: [33] [793600/1281167 (62%)]	Loss: 1.134589
[2022-06-08 18:03:33 | train] - Train Epoch: [33] [806400/1281167 (63%)]	Loss: 1.642799
[2022-06-08 18:03:55 | train] - Train Epoch: [33] [819200/1281167 (64%)]	Loss: 1.415985
[2022-06-08 18:04:16 | train] - Train Epoch: [33] [832000/1281167 (65%)]	Loss: 1.532753
[2022-06-08 18:04:38 | train] - Train Epoch: [33] [844800/1281167 (66%)]	Loss: 1.451790
[2022-06-08 18:05:00 | train] - Train Epoch: [33] [857600/1281167 (67%)]	Loss: 1.604503
[2022-06-08 18:05:22 | train] - Train Epoch: [33] [870400/1281167 (68%)]	Loss: 1.408012
[2022-06-08 18:05:44 | train] - Train Epoch: [33] [883200/1281167 (69%)]	Loss: 1.422855
[2022-06-08 18:06:06 | train] - Train Epoch: [33] [896000/1281167 (70%)]	Loss: 1.632734
[2022-06-08 18:06:28 | train] - Train Epoch: [33] [908800/1281167 (71%)]	Loss: 1.763951
[2022-06-08 18:06:49 | train] - Train Epoch: [33] [921600/1281167 (72%)]	Loss: 1.083083
[2022-06-08 18:07:11 | train] - Train Epoch: [33] [934400/1281167 (73%)]	Loss: 1.634958
[2022-06-08 18:07:33 | train] - Train Epoch: [33] [947200/1281167 (74%)]	Loss: 1.211142
[2022-06-08 18:07:55 | train] - Train Epoch: [33] [960000/1281167 (75%)]	Loss: 1.344220
[2022-06-08 18:08:17 | train] - Train Epoch: [33] [972800/1281167 (76%)]	Loss: 2.105789
[2022-06-08 18:08:39 | train] - Train Epoch: [33] [985600/1281167 (77%)]	Loss: 1.542874
[2022-06-08 18:09:01 | train] - Train Epoch: [33] [998400/1281167 (78%)]	Loss: 1.302663
[2022-06-08 18:09:22 | train] - Train Epoch: [33] [1011200/1281167 (79%)]	Loss: 1.347859
[2022-06-08 18:09:44 | train] - Train Epoch: [33] [1024000/1281167 (80%)]	Loss: 1.320182
[2022-06-08 18:10:05 | train] - Train Epoch: [33] [1036800/1281167 (81%)]	Loss: 1.498751
[2022-06-08 18:10:26 | train] - Train Epoch: [33] [1049600/1281167 (82%)]	Loss: 1.079070
[2022-06-08 18:10:48 | train] - Train Epoch: [33] [1062400/1281167 (83%)]	Loss: 1.443337
[2022-06-08 18:11:09 | train] - Train Epoch: [33] [1075200/1281167 (84%)]	Loss: 1.787967
[2022-06-08 18:11:31 | train] - Train Epoch: [33] [1088000/1281167 (85%)]	Loss: 1.229351
[2022-06-08 18:11:53 | train] - Train Epoch: [33] [1100800/1281167 (86%)]	Loss: 1.904411
[2022-06-08 18:12:15 | train] - Train Epoch: [33] [1113600/1281167 (87%)]	Loss: 1.747585
[2022-06-08 18:12:37 | train] - Train Epoch: [33] [1126400/1281167 (88%)]	Loss: 1.603223
[2022-06-08 18:12:59 | train] - Train Epoch: [33] [1139200/1281167 (89%)]	Loss: 1.353560
[2022-06-08 18:13:20 | train] - Train Epoch: [33] [1152000/1281167 (90%)]	Loss: 1.392981
[2022-06-08 18:13:42 | train] - Train Epoch: [33] [1164800/1281167 (91%)]	Loss: 1.279684
[2022-06-08 18:14:03 | train] - Train Epoch: [33] [1177600/1281167 (92%)]	Loss: 1.398949
[2022-06-08 18:14:25 | train] - Train Epoch: [33] [1190400/1281167 (93%)]	Loss: 1.362788
[2022-06-08 18:14:47 | train] - Train Epoch: [33] [1203200/1281167 (94%)]	Loss: 1.545252
[2022-06-08 18:15:09 | train] - Train Epoch: [33] [1216000/1281167 (95%)]	Loss: 1.653858
[2022-06-08 18:15:30 | train] - Train Epoch: [33] [1228800/1281167 (96%)]	Loss: 1.298711
[2022-06-08 18:15:52 | train] - Train Epoch: [33] [1241600/1281167 (97%)]	Loss: 1.547062
[2022-06-08 18:16:14 | train] - Train Epoch: [33] [1254400/1281167 (98%)]	Loss: 1.424202
[2022-06-08 18:16:37 | train] - Train Epoch: [33] [1267200/1281167 (99%)]	Loss: 1.270648
[2022-06-08 18:16:59 | train] - Train Epoch: [33] [1280000/1281167 (100%)]	Loss: 1.386529
[2022-06-08 18:17:01 | train] - Train Epoch: [33]	 Average Loss: 1.444404	 Total Acc : 65.9040	 Total Top5 Acc : 85.2971
[2022-06-08 18:17:01 | train] - -------33 epoch end-----------
========================================
-------33 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 18:18:36 | train] - 
Epoch [33] Test set: Average loss: 1.4026, Accuracy: 33304/50000 (66.5849%), Top-5 Accuracy: 87.3577%

[2022-06-08 18:18:36 | train] - save intermediate epoch [33] result


[2022-06-08 18:18:45 | train] - -------34 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 18:18:47 | train] - Train Epoch: [34] [0/1281167 (0%)]	Loss: 1.294600
[2022-06-08 18:19:09 | train] - Train Epoch: [34] [12800/1281167 (1%)]	Loss: 1.725478
[2022-06-08 18:19:31 | train] - Train Epoch: [34] [25600/1281167 (2%)]	Loss: 1.744911
[2022-06-08 18:19:53 | train] - Train Epoch: [34] [38400/1281167 (3%)]	Loss: 1.291995
[2022-06-08 18:20:15 | train] - Train Epoch: [34] [51200/1281167 (4%)]	Loss: 1.140854
[2022-06-08 18:20:36 | train] - Train Epoch: [34] [64000/1281167 (5%)]	Loss: 1.812606
[2022-06-08 18:20:59 | train] - Train Epoch: [34] [76800/1281167 (6%)]	Loss: 1.386490
[2022-06-08 18:21:20 | train] - Train Epoch: [34] [89600/1281167 (7%)]	Loss: 1.289461
[2022-06-08 18:21:42 | train] - Train Epoch: [34] [102400/1281167 (8%)]	Loss: 1.326963
[2022-06-08 18:22:04 | train] - Train Epoch: [34] [115200/1281167 (9%)]	Loss: 1.378421
[2022-06-08 18:22:26 | train] - Train Epoch: [34] [128000/1281167 (10%)]	Loss: 1.503545
[2022-06-08 18:22:48 | train] - Train Epoch: [34] [140800/1281167 (11%)]	Loss: 1.573012
[2022-06-08 18:23:10 | train] - Train Epoch: [34] [153600/1281167 (12%)]	Loss: 1.467118
[2022-06-08 18:23:31 | train] - Train Epoch: [34] [166400/1281167 (13%)]	Loss: 1.412986
[2022-06-08 18:23:53 | train] - Train Epoch: [34] [179200/1281167 (14%)]	Loss: 1.182059
[2022-06-08 18:24:16 | train] - Train Epoch: [34] [192000/1281167 (15%)]	Loss: 1.580448
[2022-06-08 18:24:37 | train] - Train Epoch: [34] [204800/1281167 (16%)]	Loss: 1.203993
[2022-06-08 18:24:59 | train] - Train Epoch: [34] [217600/1281167 (17%)]	Loss: 1.546510
[2022-06-08 18:25:21 | train] - Train Epoch: [34] [230400/1281167 (18%)]	Loss: 1.198368
[2022-06-08 18:25:43 | train] - Train Epoch: [34] [243200/1281167 (19%)]	Loss: 1.293436
[2022-06-08 18:26:05 | train] - Train Epoch: [34] [256000/1281167 (20%)]	Loss: 1.218690
[2022-06-08 18:26:27 | train] - Train Epoch: [34] [268800/1281167 (21%)]	Loss: 1.525831
[2022-06-08 18:26:49 | train] - Train Epoch: [34] [281600/1281167 (22%)]	Loss: 1.389885
[2022-06-08 18:27:10 | train] - Train Epoch: [34] [294400/1281167 (23%)]	Loss: 1.401221
[2022-06-08 18:27:32 | train] - Train Epoch: [34] [307200/1281167 (24%)]	Loss: 1.611962
[2022-06-08 18:27:54 | train] - Train Epoch: [34] [320000/1281167 (25%)]	Loss: 1.532122
[2022-06-08 18:28:16 | train] - Train Epoch: [34] [332800/1281167 (26%)]	Loss: 1.491525
[2022-06-08 18:28:38 | train] - Train Epoch: [34] [345600/1281167 (27%)]	Loss: 1.410149
[2022-06-08 18:29:00 | train] - Train Epoch: [34] [358400/1281167 (28%)]	Loss: 1.542987
[2022-06-08 18:29:22 | train] - Train Epoch: [34] [371200/1281167 (29%)]	Loss: 1.538700
[2022-06-08 18:29:44 | train] - Train Epoch: [34] [384000/1281167 (30%)]	Loss: 1.405316
[2022-06-08 18:30:07 | train] - Train Epoch: [34] [396800/1281167 (31%)]	Loss: 1.445069
[2022-06-08 18:30:29 | train] - Train Epoch: [34] [409600/1281167 (32%)]	Loss: 0.957318
[2022-06-08 18:30:51 | train] - Train Epoch: [34] [422400/1281167 (33%)]	Loss: 1.714635
[2022-06-08 18:31:13 | train] - Train Epoch: [34] [435200/1281167 (34%)]	Loss: 1.502863
[2022-06-08 18:31:35 | train] - Train Epoch: [34] [448000/1281167 (35%)]	Loss: 1.378431
[2022-06-08 18:31:57 | train] - Train Epoch: [34] [460800/1281167 (36%)]	Loss: 1.730373
[2022-06-08 18:32:19 | train] - Train Epoch: [34] [473600/1281167 (37%)]	Loss: 1.443366
[2022-06-08 18:32:41 | train] - Train Epoch: [34] [486400/1281167 (38%)]	Loss: 1.783556
[2022-06-08 18:33:03 | train] - Train Epoch: [34] [499200/1281167 (39%)]	Loss: 1.493739
[2022-06-08 18:33:25 | train] - Train Epoch: [34] [512000/1281167 (40%)]	Loss: 1.474568
[2022-06-08 18:33:47 | train] - Train Epoch: [34] [524800/1281167 (41%)]	Loss: 1.137830
[2022-06-08 18:34:09 | train] - Train Epoch: [34] [537600/1281167 (42%)]	Loss: 1.525875
[2022-06-08 18:34:31 | train] - Train Epoch: [34] [550400/1281167 (43%)]	Loss: 1.247567
[2022-06-08 18:34:53 | train] - Train Epoch: [34] [563200/1281167 (44%)]	Loss: 1.840356
[2022-06-08 18:35:15 | train] - Train Epoch: [34] [576000/1281167 (45%)]	Loss: 1.199927
[2022-06-08 18:35:37 | train] - Train Epoch: [34] [588800/1281167 (46%)]	Loss: 1.193680
[2022-06-08 18:35:59 | train] - Train Epoch: [34] [601600/1281167 (47%)]	Loss: 1.648239
[2022-06-08 18:36:21 | train] - Train Epoch: [34] [614400/1281167 (48%)]	Loss: 1.476766
[2022-06-08 18:36:42 | train] - Train Epoch: [34] [627200/1281167 (49%)]	Loss: 1.201537
[2022-06-08 18:37:04 | train] - Train Epoch: [34] [640000/1281167 (50%)]	Loss: 1.304132
[2022-06-08 18:37:26 | train] - Train Epoch: [34] [652800/1281167 (51%)]	Loss: 1.627771
[2022-06-08 18:37:48 | train] - Train Epoch: [34] [665600/1281167 (52%)]	Loss: 1.392923
[2022-06-08 18:38:11 | train] - Train Epoch: [34] [678400/1281167 (53%)]	Loss: 1.290138
[2022-06-08 18:38:33 | train] - Train Epoch: [34] [691200/1281167 (54%)]	Loss: 1.207587
[2022-06-08 18:38:55 | train] - Train Epoch: [34] [704000/1281167 (55%)]	Loss: 1.347412
[2022-06-08 18:39:17 | train] - Train Epoch: [34] [716800/1281167 (56%)]	Loss: 1.732443
[2022-06-08 18:39:39 | train] - Train Epoch: [34] [729600/1281167 (57%)]	Loss: 1.498678
[2022-06-08 18:40:01 | train] - Train Epoch: [34] [742400/1281167 (58%)]	Loss: 1.551401
[2022-06-08 18:40:23 | train] - Train Epoch: [34] [755200/1281167 (59%)]	Loss: 1.548574
[2022-06-08 18:40:45 | train] - Train Epoch: [34] [768000/1281167 (60%)]	Loss: 1.629669
[2022-06-08 18:41:07 | train] - Train Epoch: [34] [780800/1281167 (61%)]	Loss: 1.648075
[2022-06-08 18:41:30 | train] - Train Epoch: [34] [793600/1281167 (62%)]	Loss: 1.342647
[2022-06-08 18:41:51 | train] - Train Epoch: [34] [806400/1281167 (63%)]	Loss: 1.216497
[2022-06-08 18:42:13 | train] - Train Epoch: [34] [819200/1281167 (64%)]	Loss: 1.579639
[2022-06-08 18:42:36 | train] - Train Epoch: [34] [832000/1281167 (65%)]	Loss: 1.431880
[2022-06-08 18:42:58 | train] - Train Epoch: [34] [844800/1281167 (66%)]	Loss: 1.233504
[2022-06-08 18:43:20 | train] - Train Epoch: [34] [857600/1281167 (67%)]	Loss: 1.163116
[2022-06-08 18:43:42 | train] - Train Epoch: [34] [870400/1281167 (68%)]	Loss: 1.472727
[2022-06-08 18:44:05 | train] - Train Epoch: [34] [883200/1281167 (69%)]	Loss: 1.769982
[2022-06-08 18:44:26 | train] - Train Epoch: [34] [896000/1281167 (70%)]	Loss: 1.227351
[2022-06-08 18:44:49 | train] - Train Epoch: [34] [908800/1281167 (71%)]	Loss: 1.434720
[2022-06-08 18:45:10 | train] - Train Epoch: [34] [921600/1281167 (72%)]	Loss: 1.752075
[2022-06-08 18:45:32 | train] - Train Epoch: [34] [934400/1281167 (73%)]	Loss: 1.401629
[2022-06-08 18:45:54 | train] - Train Epoch: [34] [947200/1281167 (74%)]	Loss: 1.266157
[2022-06-08 18:46:17 | train] - Train Epoch: [34] [960000/1281167 (75%)]	Loss: 1.402064
[2022-06-08 18:46:39 | train] - Train Epoch: [34] [972800/1281167 (76%)]	Loss: 1.315228
[2022-06-08 18:47:01 | train] - Train Epoch: [34] [985600/1281167 (77%)]	Loss: 1.282788
[2022-06-08 18:47:22 | train] - Train Epoch: [34] [998400/1281167 (78%)]	Loss: 1.711864
[2022-06-08 18:47:44 | train] - Train Epoch: [34] [1011200/1281167 (79%)]	Loss: 1.404965
[2022-06-08 18:48:06 | train] - Train Epoch: [34] [1024000/1281167 (80%)]	Loss: 1.313900
[2022-06-08 18:48:28 | train] - Train Epoch: [34] [1036800/1281167 (81%)]	Loss: 1.173582
[2022-06-08 18:48:50 | train] - Train Epoch: [34] [1049600/1281167 (82%)]	Loss: 1.441200
[2022-06-08 18:49:12 | train] - Train Epoch: [34] [1062400/1281167 (83%)]	Loss: 1.363678
[2022-06-08 18:49:34 | train] - Train Epoch: [34] [1075200/1281167 (84%)]	Loss: 1.477297
[2022-06-08 18:49:56 | train] - Train Epoch: [34] [1088000/1281167 (85%)]	Loss: 1.423358
[2022-06-08 18:50:18 | train] - Train Epoch: [34] [1100800/1281167 (86%)]	Loss: 1.476021
[2022-06-08 18:50:39 | train] - Train Epoch: [34] [1113600/1281167 (87%)]	Loss: 1.368628
[2022-06-08 18:51:01 | train] - Train Epoch: [34] [1126400/1281167 (88%)]	Loss: 1.367656
[2022-06-08 18:51:23 | train] - Train Epoch: [34] [1139200/1281167 (89%)]	Loss: 1.429349
[2022-06-08 18:51:45 | train] - Train Epoch: [34] [1152000/1281167 (90%)]	Loss: 1.187685
[2022-06-08 18:52:06 | train] - Train Epoch: [34] [1164800/1281167 (91%)]	Loss: 1.235277
[2022-06-08 18:52:28 | train] - Train Epoch: [34] [1177600/1281167 (92%)]	Loss: 1.322652
[2022-06-08 18:52:50 | train] - Train Epoch: [34] [1190400/1281167 (93%)]	Loss: 1.473201
[2022-06-08 18:53:12 | train] - Train Epoch: [34] [1203200/1281167 (94%)]	Loss: 1.677130
[2022-06-08 18:53:34 | train] - Train Epoch: [34] [1216000/1281167 (95%)]	Loss: 1.479106
[2022-06-08 18:53:56 | train] - Train Epoch: [34] [1228800/1281167 (96%)]	Loss: 1.721506
[2022-06-08 18:54:18 | train] - Train Epoch: [34] [1241600/1281167 (97%)]	Loss: 1.389992
[2022-06-08 18:54:40 | train] - Train Epoch: [34] [1254400/1281167 (98%)]	Loss: 1.278140
[2022-06-08 18:55:02 | train] - Train Epoch: [34] [1267200/1281167 (99%)]	Loss: 1.792640
[2022-06-08 18:55:24 | train] - Train Epoch: [34] [1280000/1281167 (100%)]	Loss: 1.284872
[2022-06-08 18:55:26 | train] - Train Epoch: [34]	 Average Loss: 1.428686	 Total Acc : 66.1471	 Total Top5 Acc : 85.5880
[2022-06-08 18:55:26 | train] - -------34 epoch end-----------
========================================
-------34 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 18:56:59 | train] - 
Epoch [34] Test set: Average loss: 1.4154, Accuracy: 33242/50000 (66.4598%), Top-5 Accuracy: 87.0165%

[2022-06-08 18:56:59 | train] - save intermediate epoch [34] result


[2022-06-08 18:57:07 | train] - -------35 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 18:57:09 | train] - Train Epoch: [35] [0/1281167 (0%)]	Loss: 1.177215
[2022-06-08 18:57:31 | train] - Train Epoch: [35] [12800/1281167 (1%)]	Loss: 1.293975
[2022-06-08 18:57:53 | train] - Train Epoch: [35] [25600/1281167 (2%)]	Loss: 1.566554
[2022-06-08 18:58:16 | train] - Train Epoch: [35] [38400/1281167 (3%)]	Loss: 1.222882
[2022-06-08 18:58:38 | train] - Train Epoch: [35] [51200/1281167 (4%)]	Loss: 1.474414
[2022-06-08 18:59:01 | train] - Train Epoch: [35] [64000/1281167 (5%)]	Loss: 1.175044
[2022-06-08 18:59:23 | train] - Train Epoch: [35] [76800/1281167 (6%)]	Loss: 1.348052
[2022-06-08 18:59:45 | train] - Train Epoch: [35] [89600/1281167 (7%)]	Loss: 1.293091
[2022-06-08 19:00:08 | train] - Train Epoch: [35] [102400/1281167 (8%)]	Loss: 1.251641
[2022-06-08 19:00:30 | train] - Train Epoch: [35] [115200/1281167 (9%)]	Loss: 1.411682
[2022-06-08 19:00:52 | train] - Train Epoch: [35] [128000/1281167 (10%)]	Loss: 1.593304
[2022-06-08 19:01:14 | train] - Train Epoch: [35] [140800/1281167 (11%)]	Loss: 1.690390
[2022-06-08 19:01:36 | train] - Train Epoch: [35] [153600/1281167 (12%)]	Loss: 1.379196
[2022-06-08 19:01:58 | train] - Train Epoch: [35] [166400/1281167 (13%)]	Loss: 1.532546
[2022-06-08 19:02:20 | train] - Train Epoch: [35] [179200/1281167 (14%)]	Loss: 1.768876
[2022-06-08 19:02:43 | train] - Train Epoch: [35] [192000/1281167 (15%)]	Loss: 1.440747
[2022-06-08 19:03:05 | train] - Train Epoch: [35] [204800/1281167 (16%)]	Loss: 1.204015
[2022-06-08 19:03:26 | train] - Train Epoch: [35] [217600/1281167 (17%)]	Loss: 1.503964
[2022-06-08 19:03:49 | train] - Train Epoch: [35] [230400/1281167 (18%)]	Loss: 1.587689
[2022-06-08 19:04:11 | train] - Train Epoch: [35] [243200/1281167 (19%)]	Loss: 1.278970
[2022-06-08 19:04:34 | train] - Train Epoch: [35] [256000/1281167 (20%)]	Loss: 1.292781
[2022-06-08 19:04:56 | train] - Train Epoch: [35] [268800/1281167 (21%)]	Loss: 1.599979
[2022-06-08 19:05:18 | train] - Train Epoch: [35] [281600/1281167 (22%)]	Loss: 1.590896
[2022-06-08 19:05:40 | train] - Train Epoch: [35] [294400/1281167 (23%)]	Loss: 1.378097
[2022-06-08 19:06:02 | train] - Train Epoch: [35] [307200/1281167 (24%)]	Loss: 1.418735
[2022-06-08 19:06:25 | train] - Train Epoch: [35] [320000/1281167 (25%)]	Loss: 1.076444
[2022-06-08 19:06:47 | train] - Train Epoch: [35] [332800/1281167 (26%)]	Loss: 1.163675
[2022-06-08 19:07:09 | train] - Train Epoch: [35] [345600/1281167 (27%)]	Loss: 1.161927
[2022-06-08 19:07:32 | train] - Train Epoch: [35] [358400/1281167 (28%)]	Loss: 1.257977
[2022-06-08 19:07:54 | train] - Train Epoch: [35] [371200/1281167 (29%)]	Loss: 1.349510
[2022-06-08 19:08:17 | train] - Train Epoch: [35] [384000/1281167 (30%)]	Loss: 1.712200
[2022-06-08 19:08:39 | train] - Train Epoch: [35] [396800/1281167 (31%)]	Loss: 1.058898
[2022-06-08 19:09:02 | train] - Train Epoch: [35] [409600/1281167 (32%)]	Loss: 1.278880
[2022-06-08 19:09:24 | train] - Train Epoch: [35] [422400/1281167 (33%)]	Loss: 1.048156
[2022-06-08 19:09:46 | train] - Train Epoch: [35] [435200/1281167 (34%)]	Loss: 1.427559
[2022-06-08 19:10:09 | train] - Train Epoch: [35] [448000/1281167 (35%)]	Loss: 1.387641
[2022-06-08 19:10:32 | train] - Train Epoch: [35] [460800/1281167 (36%)]	Loss: 1.235862
[2022-06-08 19:10:54 | train] - Train Epoch: [35] [473600/1281167 (37%)]	Loss: 1.398425
[2022-06-08 19:11:17 | train] - Train Epoch: [35] [486400/1281167 (38%)]	Loss: 1.327441
[2022-06-08 19:11:39 | train] - Train Epoch: [35] [499200/1281167 (39%)]	Loss: 1.451907
[2022-06-08 19:12:01 | train] - Train Epoch: [35] [512000/1281167 (40%)]	Loss: 1.476889
[2022-06-08 19:12:23 | train] - Train Epoch: [35] [524800/1281167 (41%)]	Loss: 1.387620
[2022-06-08 19:12:45 | train] - Train Epoch: [35] [537600/1281167 (42%)]	Loss: 1.382055
[2022-06-08 19:13:08 | train] - Train Epoch: [35] [550400/1281167 (43%)]	Loss: 1.420465
[2022-06-08 19:13:29 | train] - Train Epoch: [35] [563200/1281167 (44%)]	Loss: 1.512359
[2022-06-08 19:13:52 | train] - Train Epoch: [35] [576000/1281167 (45%)]	Loss: 1.462068
[2022-06-08 19:14:14 | train] - Train Epoch: [35] [588800/1281167 (46%)]	Loss: 1.476292
[2022-06-08 19:14:36 | train] - Train Epoch: [35] [601600/1281167 (47%)]	Loss: 1.309058
[2022-06-08 19:14:58 | train] - Train Epoch: [35] [614400/1281167 (48%)]	Loss: 1.484120
[2022-06-08 19:15:21 | train] - Train Epoch: [35] [627200/1281167 (49%)]	Loss: 1.480777
[2022-06-08 19:15:43 | train] - Train Epoch: [35] [640000/1281167 (50%)]	Loss: 1.263605
[2022-06-08 19:16:05 | train] - Train Epoch: [35] [652800/1281167 (51%)]	Loss: 1.262555
[2022-06-08 19:16:27 | train] - Train Epoch: [35] [665600/1281167 (52%)]	Loss: 1.425552
[2022-06-08 19:16:49 | train] - Train Epoch: [35] [678400/1281167 (53%)]	Loss: 1.540765
[2022-06-08 19:17:11 | train] - Train Epoch: [35] [691200/1281167 (54%)]	Loss: 1.339777
[2022-06-08 19:17:34 | train] - Train Epoch: [35] [704000/1281167 (55%)]	Loss: 1.241081
[2022-06-08 19:17:56 | train] - Train Epoch: [35] [716800/1281167 (56%)]	Loss: 1.370188
[2022-06-08 19:18:18 | train] - Train Epoch: [35] [729600/1281167 (57%)]	Loss: 1.498049
[2022-06-08 19:18:40 | train] - Train Epoch: [35] [742400/1281167 (58%)]	Loss: 1.640185
[2022-06-08 19:19:02 | train] - Train Epoch: [35] [755200/1281167 (59%)]	Loss: 1.306410
[2022-06-08 19:19:24 | train] - Train Epoch: [35] [768000/1281167 (60%)]	Loss: 1.258663
[2022-06-08 19:19:46 | train] - Train Epoch: [35] [780800/1281167 (61%)]	Loss: 1.117538
[2022-06-08 19:20:09 | train] - Train Epoch: [35] [793600/1281167 (62%)]	Loss: 1.731208
[2022-06-08 19:20:31 | train] - Train Epoch: [35] [806400/1281167 (63%)]	Loss: 1.138870
[2022-06-08 19:20:53 | train] - Train Epoch: [35] [819200/1281167 (64%)]	Loss: 1.559169
[2022-06-08 19:21:15 | train] - Train Epoch: [35] [832000/1281167 (65%)]	Loss: 1.459973
[2022-06-08 19:21:38 | train] - Train Epoch: [35] [844800/1281167 (66%)]	Loss: 1.197730
[2022-06-08 19:22:00 | train] - Train Epoch: [35] [857600/1281167 (67%)]	Loss: 1.264425
[2022-06-08 19:22:22 | train] - Train Epoch: [35] [870400/1281167 (68%)]	Loss: 1.365904
[2022-06-08 19:22:44 | train] - Train Epoch: [35] [883200/1281167 (69%)]	Loss: 1.222536
[2022-06-08 19:23:07 | train] - Train Epoch: [35] [896000/1281167 (70%)]	Loss: 1.466394
[2022-06-08 19:23:30 | train] - Train Epoch: [35] [908800/1281167 (71%)]	Loss: 1.283116
[2022-06-08 19:23:52 | train] - Train Epoch: [35] [921600/1281167 (72%)]	Loss: 1.010097
[2022-06-08 19:24:14 | train] - Train Epoch: [35] [934400/1281167 (73%)]	Loss: 1.151326
[2022-06-08 19:24:36 | train] - Train Epoch: [35] [947200/1281167 (74%)]	Loss: 1.517382
[2022-06-08 19:24:59 | train] - Train Epoch: [35] [960000/1281167 (75%)]	Loss: 1.285549
[2022-06-08 19:25:21 | train] - Train Epoch: [35] [972800/1281167 (76%)]	Loss: 1.212984
[2022-06-08 19:25:43 | train] - Train Epoch: [35] [985600/1281167 (77%)]	Loss: 1.532764
[2022-06-08 19:26:06 | train] - Train Epoch: [35] [998400/1281167 (78%)]	Loss: 1.092532
[2022-06-08 19:26:28 | train] - Train Epoch: [35] [1011200/1281167 (79%)]	Loss: 1.408284
[2022-06-08 19:26:50 | train] - Train Epoch: [35] [1024000/1281167 (80%)]	Loss: 1.564576
[2022-06-08 19:27:12 | train] - Train Epoch: [35] [1036800/1281167 (81%)]	Loss: 1.460559
[2022-06-08 19:27:35 | train] - Train Epoch: [35] [1049600/1281167 (82%)]	Loss: 1.577220
[2022-06-08 19:27:57 | train] - Train Epoch: [35] [1062400/1281167 (83%)]	Loss: 1.769538
[2022-06-08 19:28:20 | train] - Train Epoch: [35] [1075200/1281167 (84%)]	Loss: 1.269093
[2022-06-08 19:28:42 | train] - Train Epoch: [35] [1088000/1281167 (85%)]	Loss: 1.559283
[2022-06-08 19:29:04 | train] - Train Epoch: [35] [1100800/1281167 (86%)]	Loss: 1.623904
[2022-06-08 19:29:26 | train] - Train Epoch: [35] [1113600/1281167 (87%)]	Loss: 1.639347
[2022-06-08 19:29:49 | train] - Train Epoch: [35] [1126400/1281167 (88%)]	Loss: 1.192512
[2022-06-08 19:30:11 | train] - Train Epoch: [35] [1139200/1281167 (89%)]	Loss: 1.488123
[2022-06-08 19:30:34 | train] - Train Epoch: [35] [1152000/1281167 (90%)]	Loss: 1.564461
[2022-06-08 19:30:56 | train] - Train Epoch: [35] [1164800/1281167 (91%)]	Loss: 1.840995
[2022-06-08 19:31:18 | train] - Train Epoch: [35] [1177600/1281167 (92%)]	Loss: 1.584182
[2022-06-08 19:31:40 | train] - Train Epoch: [35] [1190400/1281167 (93%)]	Loss: 1.484627
[2022-06-08 19:32:02 | train] - Train Epoch: [35] [1203200/1281167 (94%)]	Loss: 1.057848
[2022-06-08 19:32:25 | train] - Train Epoch: [35] [1216000/1281167 (95%)]	Loss: 1.614645
[2022-06-08 19:32:47 | train] - Train Epoch: [35] [1228800/1281167 (96%)]	Loss: 1.475479
[2022-06-08 19:33:09 | train] - Train Epoch: [35] [1241600/1281167 (97%)]	Loss: 1.253872
[2022-06-08 19:33:31 | train] - Train Epoch: [35] [1254400/1281167 (98%)]	Loss: 1.182420
[2022-06-08 19:33:54 | train] - Train Epoch: [35] [1267200/1281167 (99%)]	Loss: 1.509521
[2022-06-08 19:34:16 | train] - Train Epoch: [35] [1280000/1281167 (100%)]	Loss: 1.234929
[2022-06-08 19:34:18 | train] - Train Epoch: [35]	 Average Loss: 1.413882	 Total Acc : 66.5033	 Total Top5 Acc : 85.7739
[2022-06-08 19:34:18 | train] - -------35 epoch end-----------
========================================
-------35 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 19:35:54 | train] - 
Epoch [35] Test set: Average loss: 1.3900, Accuracy: 33416/50000 (66.8027%), Top-5 Accuracy: 87.4153%

[2022-06-08 19:35:54 | train] - save intermediate epoch [35] result


[2022-06-08 19:36:02 | train] - logging best performance 35 epoch
[2022-06-08 19:36:04 | train] - -------36 epoch start-----------
========================================
----- test end -------------------------


logging best performance 35 epoch
[2022-06-08 19:36:05 | train] - Train Epoch: [36] [0/1281167 (0%)]	Loss: 1.261742
[2022-06-08 19:36:27 | train] - Train Epoch: [36] [12800/1281167 (1%)]	Loss: 1.442070
[2022-06-08 19:36:50 | train] - Train Epoch: [36] [25600/1281167 (2%)]	Loss: 1.150024
[2022-06-08 19:37:12 | train] - Train Epoch: [36] [38400/1281167 (3%)]	Loss: 1.542356
[2022-06-08 19:37:34 | train] - Train Epoch: [36] [51200/1281167 (4%)]	Loss: 1.265813
[2022-06-08 19:37:56 | train] - Train Epoch: [36] [64000/1281167 (5%)]	Loss: 1.281125
[2022-06-08 19:38:18 | train] - Train Epoch: [36] [76800/1281167 (6%)]	Loss: 1.357840
[2022-06-08 19:38:41 | train] - Train Epoch: [36] [89600/1281167 (7%)]	Loss: 1.485515
[2022-06-08 19:39:03 | train] - Train Epoch: [36] [102400/1281167 (8%)]	Loss: 1.356561
[2022-06-08 19:39:25 | train] - Train Epoch: [36] [115200/1281167 (9%)]	Loss: 1.223575
[2022-06-08 19:39:47 | train] - Train Epoch: [36] [128000/1281167 (10%)]	Loss: 1.378563
[2022-06-08 19:40:10 | train] - Train Epoch: [36] [140800/1281167 (11%)]	Loss: 1.074076
[2022-06-08 19:40:32 | train] - Train Epoch: [36] [153600/1281167 (12%)]	Loss: 1.339677
[2022-06-08 19:40:54 | train] - Train Epoch: [36] [166400/1281167 (13%)]	Loss: 1.482257
[2022-06-08 19:41:17 | train] - Train Epoch: [36] [179200/1281167 (14%)]	Loss: 1.209971
[2022-06-08 19:41:39 | train] - Train Epoch: [36] [192000/1281167 (15%)]	Loss: 1.407105
[2022-06-08 19:42:01 | train] - Train Epoch: [36] [204800/1281167 (16%)]	Loss: 1.530764
[2022-06-08 19:42:23 | train] - Train Epoch: [36] [217600/1281167 (17%)]	Loss: 1.352563
[2022-06-08 19:42:45 | train] - Train Epoch: [36] [230400/1281167 (18%)]	Loss: 1.609144
[2022-06-08 19:43:07 | train] - Train Epoch: [36] [243200/1281167 (19%)]	Loss: 1.383691
[2022-06-08 19:43:29 | train] - Train Epoch: [36] [256000/1281167 (20%)]	Loss: 1.474654
[2022-06-08 19:43:51 | train] - Train Epoch: [36] [268800/1281167 (21%)]	Loss: 1.315751
[2022-06-08 19:44:14 | train] - Train Epoch: [36] [281600/1281167 (22%)]	Loss: 1.342137
[2022-06-08 19:44:36 | train] - Train Epoch: [36] [294400/1281167 (23%)]	Loss: 1.352831
[2022-06-08 19:44:57 | train] - Train Epoch: [36] [307200/1281167 (24%)]	Loss: 1.626714
[2022-06-08 19:45:19 | train] - Train Epoch: [36] [320000/1281167 (25%)]	Loss: 1.402127
[2022-06-08 19:45:41 | train] - Train Epoch: [36] [332800/1281167 (26%)]	Loss: 1.252424
[2022-06-08 19:46:02 | train] - Train Epoch: [36] [345600/1281167 (27%)]	Loss: 1.451884
[2022-06-08 19:46:23 | train] - Train Epoch: [36] [358400/1281167 (28%)]	Loss: 1.458586
[2022-06-08 19:46:45 | train] - Train Epoch: [36] [371200/1281167 (29%)]	Loss: 1.368812
[2022-06-08 19:47:08 | train] - Train Epoch: [36] [384000/1281167 (30%)]	Loss: 1.233842
[2022-06-08 19:47:29 | train] - Train Epoch: [36] [396800/1281167 (31%)]	Loss: 1.159694
[2022-06-08 19:47:51 | train] - Train Epoch: [36] [409600/1281167 (32%)]	Loss: 1.490770
[2022-06-08 19:48:14 | train] - Train Epoch: [36] [422400/1281167 (33%)]	Loss: 1.526372
[2022-06-08 19:48:35 | train] - Train Epoch: [36] [435200/1281167 (34%)]	Loss: 1.314781
[2022-06-08 19:48:58 | train] - Train Epoch: [36] [448000/1281167 (35%)]	Loss: 1.151438
[2022-06-08 19:49:20 | train] - Train Epoch: [36] [460800/1281167 (36%)]	Loss: 1.699318
[2022-06-08 19:49:42 | train] - Train Epoch: [36] [473600/1281167 (37%)]	Loss: 1.099954
[2022-06-08 19:50:04 | train] - Train Epoch: [36] [486400/1281167 (38%)]	Loss: 1.441708
[2022-06-08 19:50:26 | train] - Train Epoch: [36] [499200/1281167 (39%)]	Loss: 1.417848
[2022-06-08 19:50:48 | train] - Train Epoch: [36] [512000/1281167 (40%)]	Loss: 1.696178
[2022-06-08 19:51:09 | train] - Train Epoch: [36] [524800/1281167 (41%)]	Loss: 1.243621
[2022-06-08 19:51:31 | train] - Train Epoch: [36] [537600/1281167 (42%)]	Loss: 1.365861
[2022-06-08 19:51:53 | train] - Train Epoch: [36] [550400/1281167 (43%)]	Loss: 1.607581
[2022-06-08 19:52:15 | train] - Train Epoch: [36] [563200/1281167 (44%)]	Loss: 1.381338
[2022-06-08 19:52:37 | train] - Train Epoch: [36] [576000/1281167 (45%)]	Loss: 1.266494
[2022-06-08 19:52:59 | train] - Train Epoch: [36] [588800/1281167 (46%)]	Loss: 1.819661
[2022-06-08 19:53:21 | train] - Train Epoch: [36] [601600/1281167 (47%)]	Loss: 1.126962
[2022-06-08 19:53:43 | train] - Train Epoch: [36] [614400/1281167 (48%)]	Loss: 1.248904
[2022-06-08 19:54:06 | train] - Train Epoch: [36] [627200/1281167 (49%)]	Loss: 1.307987
[2022-06-08 19:54:28 | train] - Train Epoch: [36] [640000/1281167 (50%)]	Loss: 1.266102
[2022-06-08 19:54:49 | train] - Train Epoch: [36] [652800/1281167 (51%)]	Loss: 1.913732
[2022-06-08 19:55:11 | train] - Train Epoch: [36] [665600/1281167 (52%)]	Loss: 1.397232
[2022-06-08 19:55:33 | train] - Train Epoch: [36] [678400/1281167 (53%)]	Loss: 1.204985
[2022-06-08 19:55:55 | train] - Train Epoch: [36] [691200/1281167 (54%)]	Loss: 1.352271
[2022-06-08 19:56:17 | train] - Train Epoch: [36] [704000/1281167 (55%)]	Loss: 1.424698
[2022-06-08 19:56:40 | train] - Train Epoch: [36] [716800/1281167 (56%)]	Loss: 1.489643
[2022-06-08 19:57:02 | train] - Train Epoch: [36] [729600/1281167 (57%)]	Loss: 1.577130
[2022-06-08 19:57:24 | train] - Train Epoch: [36] [742400/1281167 (58%)]	Loss: 1.845932
[2022-06-08 19:57:46 | train] - Train Epoch: [36] [755200/1281167 (59%)]	Loss: 1.522194
[2022-06-08 19:58:09 | train] - Train Epoch: [36] [768000/1281167 (60%)]	Loss: 1.493384
[2022-06-08 19:58:31 | train] - Train Epoch: [36] [780800/1281167 (61%)]	Loss: 1.474547
[2022-06-08 19:58:53 | train] - Train Epoch: [36] [793600/1281167 (62%)]	Loss: 1.410360
[2022-06-08 19:59:15 | train] - Train Epoch: [36] [806400/1281167 (63%)]	Loss: 1.458689
[2022-06-08 19:59:37 | train] - Train Epoch: [36] [819200/1281167 (64%)]	Loss: 1.094515
[2022-06-08 19:59:59 | train] - Train Epoch: [36] [832000/1281167 (65%)]	Loss: 1.211939
[2022-06-08 20:00:22 | train] - Train Epoch: [36] [844800/1281167 (66%)]	Loss: 1.479081
[2022-06-08 20:00:44 | train] - Train Epoch: [36] [857600/1281167 (67%)]	Loss: 1.381514
[2022-06-08 20:01:06 | train] - Train Epoch: [36] [870400/1281167 (68%)]	Loss: 1.612714
[2022-06-08 20:01:29 | train] - Train Epoch: [36] [883200/1281167 (69%)]	Loss: 1.358677
[2022-06-08 20:01:51 | train] - Train Epoch: [36] [896000/1281167 (70%)]	Loss: 0.984317
[2022-06-08 20:02:13 | train] - Train Epoch: [36] [908800/1281167 (71%)]	Loss: 1.183643
[2022-06-08 20:02:34 | train] - Train Epoch: [36] [921600/1281167 (72%)]	Loss: 1.156976
[2022-06-08 20:02:56 | train] - Train Epoch: [36] [934400/1281167 (73%)]	Loss: 1.694425
[2022-06-08 20:03:18 | train] - Train Epoch: [36] [947200/1281167 (74%)]	Loss: 1.384127
[2022-06-08 20:03:40 | train] - Train Epoch: [36] [960000/1281167 (75%)]	Loss: 1.478361
[2022-06-08 20:04:02 | train] - Train Epoch: [36] [972800/1281167 (76%)]	Loss: 1.012298
[2022-06-08 20:04:24 | train] - Train Epoch: [36] [985600/1281167 (77%)]	Loss: 1.306810
[2022-06-08 20:04:46 | train] - Train Epoch: [36] [998400/1281167 (78%)]	Loss: 1.290261
[2022-06-08 20:05:09 | train] - Train Epoch: [36] [1011200/1281167 (79%)]	Loss: 1.401552
[2022-06-08 20:05:30 | train] - Train Epoch: [36] [1024000/1281167 (80%)]	Loss: 1.363271
[2022-06-08 20:05:53 | train] - Train Epoch: [36] [1036800/1281167 (81%)]	Loss: 1.308898
[2022-06-08 20:06:15 | train] - Train Epoch: [36] [1049600/1281167 (82%)]	Loss: 1.464661
[2022-06-08 20:06:37 | train] - Train Epoch: [36] [1062400/1281167 (83%)]	Loss: 1.341402
[2022-06-08 20:06:59 | train] - Train Epoch: [36] [1075200/1281167 (84%)]	Loss: 1.676533
[2022-06-08 20:07:21 | train] - Train Epoch: [36] [1088000/1281167 (85%)]	Loss: 1.417017
[2022-06-08 20:07:43 | train] - Train Epoch: [36] [1100800/1281167 (86%)]	Loss: 1.272858
[2022-06-08 20:08:06 | train] - Train Epoch: [36] [1113600/1281167 (87%)]	Loss: 1.497843
[2022-06-08 20:08:28 | train] - Train Epoch: [36] [1126400/1281167 (88%)]	Loss: 1.255986
[2022-06-08 20:08:50 | train] - Train Epoch: [36] [1139200/1281167 (89%)]	Loss: 1.628338
[2022-06-08 20:09:11 | train] - Train Epoch: [36] [1152000/1281167 (90%)]	Loss: 1.457738
[2022-06-08 20:09:33 | train] - Train Epoch: [36] [1164800/1281167 (91%)]	Loss: 1.249234
[2022-06-08 20:09:55 | train] - Train Epoch: [36] [1177600/1281167 (92%)]	Loss: 1.395080
[2022-06-08 20:10:17 | train] - Train Epoch: [36] [1190400/1281167 (93%)]	Loss: 1.339791
[2022-06-08 20:10:38 | train] - Train Epoch: [36] [1203200/1281167 (94%)]	Loss: 1.696749
[2022-06-08 20:11:01 | train] - Train Epoch: [36] [1216000/1281167 (95%)]	Loss: 1.637947
[2022-06-08 20:11:22 | train] - Train Epoch: [36] [1228800/1281167 (96%)]	Loss: 1.445911
[2022-06-08 20:11:44 | train] - Train Epoch: [36] [1241600/1281167 (97%)]	Loss: 1.412167
[2022-06-08 20:12:07 | train] - Train Epoch: [36] [1254400/1281167 (98%)]	Loss: 1.258707
[2022-06-08 20:12:29 | train] - Train Epoch: [36] [1267200/1281167 (99%)]	Loss: 1.758746
[2022-06-08 20:12:51 | train] - Train Epoch: [36] [1280000/1281167 (100%)]	Loss: 1.895784
[2022-06-08 20:12:53 | train] - Train Epoch: [36]	 Average Loss: 1.398622	 Total Acc : 66.7700	 Total Top5 Acc : 85.9900
[2022-06-08 20:12:53 | train] - -------36 epoch end-----------
========================================
-------36 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 20:14:26 | train] - 
Epoch [36] Test set: Average loss: 1.3945, Accuracy: 33481/50000 (66.9313%), Top-5 Accuracy: 87.3745%

[2022-06-08 20:14:26 | train] - save intermediate epoch [36] result


[2022-06-08 20:14:34 | train] - logging best performance 36 epoch
[2022-06-08 20:14:36 | train] - -------37 epoch start-----------
========================================
----- test end -------------------------


logging best performance 36 epoch
[2022-06-08 20:14:37 | train] - Train Epoch: [37] [0/1281167 (0%)]	Loss: 1.435186
[2022-06-08 20:14:59 | train] - Train Epoch: [37] [12800/1281167 (1%)]	Loss: 1.444317
[2022-06-08 20:15:22 | train] - Train Epoch: [37] [25600/1281167 (2%)]	Loss: 1.209899
[2022-06-08 20:15:44 | train] - Train Epoch: [37] [38400/1281167 (3%)]	Loss: 1.287341
[2022-06-08 20:16:05 | train] - Train Epoch: [37] [51200/1281167 (4%)]	Loss: 1.489659
[2022-06-08 20:16:28 | train] - Train Epoch: [37] [64000/1281167 (5%)]	Loss: 1.629635
[2022-06-08 20:16:50 | train] - Train Epoch: [37] [76800/1281167 (6%)]	Loss: 1.677874
[2022-06-08 20:17:11 | train] - Train Epoch: [37] [89600/1281167 (7%)]	Loss: 1.489456
[2022-06-08 20:17:33 | train] - Train Epoch: [37] [102400/1281167 (8%)]	Loss: 1.393249
[2022-06-08 20:17:55 | train] - Train Epoch: [37] [115200/1281167 (9%)]	Loss: 1.426844
[2022-06-08 20:18:18 | train] - Train Epoch: [37] [128000/1281167 (10%)]	Loss: 1.386721
[2022-06-08 20:18:40 | train] - Train Epoch: [37] [140800/1281167 (11%)]	Loss: 1.443746
[2022-06-08 20:19:02 | train] - Train Epoch: [37] [153600/1281167 (12%)]	Loss: 1.163129
[2022-06-08 20:19:23 | train] - Train Epoch: [37] [166400/1281167 (13%)]	Loss: 1.481291
[2022-06-08 20:19:46 | train] - Train Epoch: [37] [179200/1281167 (14%)]	Loss: 1.138395
[2022-06-08 20:20:07 | train] - Train Epoch: [37] [192000/1281167 (15%)]	Loss: 1.581805
[2022-06-08 20:20:29 | train] - Train Epoch: [37] [204800/1281167 (16%)]	Loss: 1.330192
[2022-06-08 20:20:52 | train] - Train Epoch: [37] [217600/1281167 (17%)]	Loss: 1.452275
[2022-06-08 20:21:13 | train] - Train Epoch: [37] [230400/1281167 (18%)]	Loss: 1.605726
[2022-06-08 20:21:34 | train] - Train Epoch: [37] [243200/1281167 (19%)]	Loss: 1.313772
[2022-06-08 20:21:56 | train] - Train Epoch: [37] [256000/1281167 (20%)]	Loss: 1.321811
[2022-06-08 20:22:18 | train] - Train Epoch: [37] [268800/1281167 (21%)]	Loss: 1.700747
[2022-06-08 20:22:41 | train] - Train Epoch: [37] [281600/1281167 (22%)]	Loss: 1.312215
[2022-06-08 20:23:03 | train] - Train Epoch: [37] [294400/1281167 (23%)]	Loss: 1.456636
[2022-06-08 20:23:25 | train] - Train Epoch: [37] [307200/1281167 (24%)]	Loss: 1.160860
[2022-06-08 20:23:47 | train] - Train Epoch: [37] [320000/1281167 (25%)]	Loss: 1.332668
[2022-06-08 20:24:09 | train] - Train Epoch: [37] [332800/1281167 (26%)]	Loss: 1.546896
[2022-06-08 20:24:31 | train] - Train Epoch: [37] [345600/1281167 (27%)]	Loss: 1.387221
[2022-06-08 20:24:53 | train] - Train Epoch: [37] [358400/1281167 (28%)]	Loss: 1.903877
[2022-06-08 20:25:15 | train] - Train Epoch: [37] [371200/1281167 (29%)]	Loss: 1.329079
[2022-06-08 20:25:38 | train] - Train Epoch: [37] [384000/1281167 (30%)]	Loss: 1.203589
[2022-06-08 20:26:00 | train] - Train Epoch: [37] [396800/1281167 (31%)]	Loss: 1.312915
[2022-06-08 20:26:23 | train] - Train Epoch: [37] [409600/1281167 (32%)]	Loss: 1.305690
[2022-06-08 20:26:44 | train] - Train Epoch: [37] [422400/1281167 (33%)]	Loss: 1.330702
[2022-06-08 20:27:07 | train] - Train Epoch: [37] [435200/1281167 (34%)]	Loss: 1.345467
[2022-06-08 20:27:29 | train] - Train Epoch: [37] [448000/1281167 (35%)]	Loss: 1.222897
[2022-06-08 20:27:51 | train] - Train Epoch: [37] [460800/1281167 (36%)]	Loss: 1.298596
[2022-06-08 20:28:13 | train] - Train Epoch: [37] [473600/1281167 (37%)]	Loss: 1.582189
[2022-06-08 20:28:35 | train] - Train Epoch: [37] [486400/1281167 (38%)]	Loss: 1.704276
[2022-06-08 20:28:57 | train] - Train Epoch: [37] [499200/1281167 (39%)]	Loss: 1.630501
[2022-06-08 20:29:18 | train] - Train Epoch: [37] [512000/1281167 (40%)]	Loss: 1.566461
[2022-06-08 20:29:40 | train] - Train Epoch: [37] [524800/1281167 (41%)]	Loss: 1.791770
[2022-06-08 20:30:01 | train] - Train Epoch: [37] [537600/1281167 (42%)]	Loss: 1.805387
[2022-06-08 20:30:23 | train] - Train Epoch: [37] [550400/1281167 (43%)]	Loss: 1.556328
[2022-06-08 20:30:45 | train] - Train Epoch: [37] [563200/1281167 (44%)]	Loss: 1.484617
[2022-06-08 20:31:07 | train] - Train Epoch: [37] [576000/1281167 (45%)]	Loss: 1.391313
[2022-06-08 20:31:29 | train] - Train Epoch: [37] [588800/1281167 (46%)]	Loss: 1.283147
[2022-06-08 20:31:51 | train] - Train Epoch: [37] [601600/1281167 (47%)]	Loss: 1.667061
[2022-06-08 20:32:13 | train] - Train Epoch: [37] [614400/1281167 (48%)]	Loss: 1.421142
[2022-06-08 20:32:36 | train] - Train Epoch: [37] [627200/1281167 (49%)]	Loss: 1.052982
[2022-06-08 20:32:58 | train] - Train Epoch: [37] [640000/1281167 (50%)]	Loss: 1.397396
[2022-06-08 20:33:19 | train] - Train Epoch: [37] [652800/1281167 (51%)]	Loss: 1.096927
[2022-06-08 20:33:41 | train] - Train Epoch: [37] [665600/1281167 (52%)]	Loss: 1.582244
[2022-06-08 20:34:03 | train] - Train Epoch: [37] [678400/1281167 (53%)]	Loss: 0.955335
[2022-06-08 20:34:26 | train] - Train Epoch: [37] [691200/1281167 (54%)]	Loss: 1.294329
[2022-06-08 20:34:48 | train] - Train Epoch: [37] [704000/1281167 (55%)]	Loss: 1.275019
[2022-06-08 20:35:09 | train] - Train Epoch: [37] [716800/1281167 (56%)]	Loss: 1.211760
[2022-06-08 20:35:32 | train] - Train Epoch: [37] [729600/1281167 (57%)]	Loss: 1.098859
[2022-06-08 20:35:54 | train] - Train Epoch: [37] [742400/1281167 (58%)]	Loss: 1.105079
[2022-06-08 20:36:16 | train] - Train Epoch: [37] [755200/1281167 (59%)]	Loss: 1.008803
[2022-06-08 20:36:38 | train] - Train Epoch: [37] [768000/1281167 (60%)]	Loss: 1.512225
[2022-06-08 20:36:59 | train] - Train Epoch: [37] [780800/1281167 (61%)]	Loss: 1.355439
[2022-06-08 20:37:21 | train] - Train Epoch: [37] [793600/1281167 (62%)]	Loss: 1.511402
[2022-06-08 20:37:43 | train] - Train Epoch: [37] [806400/1281167 (63%)]	Loss: 1.689314
[2022-06-08 20:38:05 | train] - Train Epoch: [37] [819200/1281167 (64%)]	Loss: 1.287384
[2022-06-08 20:38:27 | train] - Train Epoch: [37] [832000/1281167 (65%)]	Loss: 1.611338
[2022-06-08 20:38:49 | train] - Train Epoch: [37] [844800/1281167 (66%)]	Loss: 1.255384
[2022-06-08 20:39:10 | train] - Train Epoch: [37] [857600/1281167 (67%)]	Loss: 1.524947
[2022-06-08 20:39:31 | train] - Train Epoch: [37] [870400/1281167 (68%)]	Loss: 1.407095
[2022-06-08 20:39:53 | train] - Train Epoch: [37] [883200/1281167 (69%)]	Loss: 1.292775
[2022-06-08 20:40:16 | train] - Train Epoch: [37] [896000/1281167 (70%)]	Loss: 1.307936
[2022-06-08 20:40:38 | train] - Train Epoch: [37] [908800/1281167 (71%)]	Loss: 1.142657
[2022-06-08 20:41:00 | train] - Train Epoch: [37] [921600/1281167 (72%)]	Loss: 1.214546
[2022-06-08 20:41:22 | train] - Train Epoch: [37] [934400/1281167 (73%)]	Loss: 1.572329
[2022-06-08 20:41:44 | train] - Train Epoch: [37] [947200/1281167 (74%)]	Loss: 1.601974
[2022-06-08 20:42:05 | train] - Train Epoch: [37] [960000/1281167 (75%)]	Loss: 1.041971
[2022-06-08 20:42:27 | train] - Train Epoch: [37] [972800/1281167 (76%)]	Loss: 1.339365
[2022-06-08 20:42:49 | train] - Train Epoch: [37] [985600/1281167 (77%)]	Loss: 1.345845
[2022-06-08 20:43:12 | train] - Train Epoch: [37] [998400/1281167 (78%)]	Loss: 1.045095
[2022-06-08 20:43:34 | train] - Train Epoch: [37] [1011200/1281167 (79%)]	Loss: 1.440289
[2022-06-08 20:43:56 | train] - Train Epoch: [37] [1024000/1281167 (80%)]	Loss: 1.589499
[2022-06-08 20:44:18 | train] - Train Epoch: [37] [1036800/1281167 (81%)]	Loss: 1.466465
[2022-06-08 20:44:40 | train] - Train Epoch: [37] [1049600/1281167 (82%)]	Loss: 1.315325
[2022-06-08 20:45:01 | train] - Train Epoch: [37] [1062400/1281167 (83%)]	Loss: 1.374817
[2022-06-08 20:45:23 | train] - Train Epoch: [37] [1075200/1281167 (84%)]	Loss: 1.381675
[2022-06-08 20:45:46 | train] - Train Epoch: [37] [1088000/1281167 (85%)]	Loss: 1.121787
[2022-06-08 20:46:07 | train] - Train Epoch: [37] [1100800/1281167 (86%)]	Loss: 1.440369
[2022-06-08 20:46:29 | train] - Train Epoch: [37] [1113600/1281167 (87%)]	Loss: 1.456230
[2022-06-08 20:46:51 | train] - Train Epoch: [37] [1126400/1281167 (88%)]	Loss: 1.226940
[2022-06-08 20:47:13 | train] - Train Epoch: [37] [1139200/1281167 (89%)]	Loss: 1.766865
[2022-06-08 20:47:36 | train] - Train Epoch: [37] [1152000/1281167 (90%)]	Loss: 1.226135
[2022-06-08 20:47:58 | train] - Train Epoch: [37] [1164800/1281167 (91%)]	Loss: 1.665485
[2022-06-08 20:48:20 | train] - Train Epoch: [37] [1177600/1281167 (92%)]	Loss: 1.141760
[2022-06-08 20:48:42 | train] - Train Epoch: [37] [1190400/1281167 (93%)]	Loss: 1.459681
[2022-06-08 20:49:04 | train] - Train Epoch: [37] [1203200/1281167 (94%)]	Loss: 1.325885
[2022-06-08 20:49:26 | train] - Train Epoch: [37] [1216000/1281167 (95%)]	Loss: 1.381438
[2022-06-08 20:49:49 | train] - Train Epoch: [37] [1228800/1281167 (96%)]	Loss: 1.394083
[2022-06-08 20:50:10 | train] - Train Epoch: [37] [1241600/1281167 (97%)]	Loss: 1.577006
[2022-06-08 20:50:32 | train] - Train Epoch: [37] [1254400/1281167 (98%)]	Loss: 1.605278
[2022-06-08 20:50:54 | train] - Train Epoch: [37] [1267200/1281167 (99%)]	Loss: 1.576627
[2022-06-08 20:51:16 | train] - Train Epoch: [37] [1280000/1281167 (100%)]	Loss: 1.379909
[2022-06-08 20:51:18 | train] - Train Epoch: [37]	 Average Loss: 1.383742	 Total Acc : 67.1157	 Total Top5 Acc : 86.1616
[2022-06-08 20:51:18 | train] - -------37 epoch end-----------
========================================
-------37 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 20:52:52 | train] - 
Epoch [37] Test set: Average loss: 1.3922, Accuracy: 33582/50000 (67.1296%), Top-5 Accuracy: 87.5012%

[2022-06-08 20:52:52 | train] - save intermediate epoch [37] result


[2022-06-08 20:53:00 | train] - logging best performance 37 epoch
[2022-06-08 20:53:02 | train] - -------38 epoch start-----------
========================================
----- test end -------------------------


logging best performance 37 epoch
[2022-06-08 20:53:03 | train] - Train Epoch: [38] [0/1281167 (0%)]	Loss: 1.400033
[2022-06-08 20:53:25 | train] - Train Epoch: [38] [12800/1281167 (1%)]	Loss: 1.326290
[2022-06-08 20:53:47 | train] - Train Epoch: [38] [25600/1281167 (2%)]	Loss: 1.312225
[2022-06-08 20:54:09 | train] - Train Epoch: [38] [38400/1281167 (3%)]	Loss: 0.962252
[2022-06-08 20:54:31 | train] - Train Epoch: [38] [51200/1281167 (4%)]	Loss: 1.461051
[2022-06-08 20:54:53 | train] - Train Epoch: [38] [64000/1281167 (5%)]	Loss: 1.389646
[2022-06-08 20:55:15 | train] - Train Epoch: [38] [76800/1281167 (6%)]	Loss: 1.180310
[2022-06-08 20:55:38 | train] - Train Epoch: [38] [89600/1281167 (7%)]	Loss: 1.244962
[2022-06-08 20:56:00 | train] - Train Epoch: [38] [102400/1281167 (8%)]	Loss: 1.184877
[2022-06-08 20:56:22 | train] - Train Epoch: [38] [115200/1281167 (9%)]	Loss: 1.167490
[2022-06-08 20:56:44 | train] - Train Epoch: [38] [128000/1281167 (10%)]	Loss: 1.258325
[2022-06-08 20:57:06 | train] - Train Epoch: [38] [140800/1281167 (11%)]	Loss: 1.281351
[2022-06-08 20:57:28 | train] - Train Epoch: [38] [153600/1281167 (12%)]	Loss: 1.572657
[2022-06-08 20:57:50 | train] - Train Epoch: [38] [166400/1281167 (13%)]	Loss: 1.359199
[2022-06-08 20:58:12 | train] - Train Epoch: [38] [179200/1281167 (14%)]	Loss: 1.391448
[2022-06-08 20:58:34 | train] - Train Epoch: [38] [192000/1281167 (15%)]	Loss: 1.481382
[2022-06-08 20:58:56 | train] - Train Epoch: [38] [204800/1281167 (16%)]	Loss: 1.498205
[2022-06-08 20:59:18 | train] - Train Epoch: [38] [217600/1281167 (17%)]	Loss: 1.414831
[2022-06-08 20:59:39 | train] - Train Epoch: [38] [230400/1281167 (18%)]	Loss: 1.224952
[2022-06-08 21:00:01 | train] - Train Epoch: [38] [243200/1281167 (19%)]	Loss: 1.271380
[2022-06-08 21:00:23 | train] - Train Epoch: [38] [256000/1281167 (20%)]	Loss: 1.398813
[2022-06-08 21:00:45 | train] - Train Epoch: [38] [268800/1281167 (21%)]	Loss: 1.701788
[2022-06-08 21:01:07 | train] - Train Epoch: [38] [281600/1281167 (22%)]	Loss: 1.294325
[2022-06-08 21:01:29 | train] - Train Epoch: [38] [294400/1281167 (23%)]	Loss: 1.517525
[2022-06-08 21:01:51 | train] - Train Epoch: [38] [307200/1281167 (24%)]	Loss: 1.302418
[2022-06-08 21:02:13 | train] - Train Epoch: [38] [320000/1281167 (25%)]	Loss: 1.335431
[2022-06-08 21:02:35 | train] - Train Epoch: [38] [332800/1281167 (26%)]	Loss: 1.504883
[2022-06-08 21:02:57 | train] - Train Epoch: [38] [345600/1281167 (27%)]	Loss: 1.598642
[2022-06-08 21:03:19 | train] - Train Epoch: [38] [358400/1281167 (28%)]	Loss: 1.477315
[2022-06-08 21:03:41 | train] - Train Epoch: [38] [371200/1281167 (29%)]	Loss: 1.169243
[2022-06-08 21:04:02 | train] - Train Epoch: [38] [384000/1281167 (30%)]	Loss: 1.541455
[2022-06-08 21:04:25 | train] - Train Epoch: [38] [396800/1281167 (31%)]	Loss: 1.150942
[2022-06-08 21:04:46 | train] - Train Epoch: [38] [409600/1281167 (32%)]	Loss: 1.483478
[2022-06-08 21:05:08 | train] - Train Epoch: [38] [422400/1281167 (33%)]	Loss: 1.479944
[2022-06-08 21:05:30 | train] - Train Epoch: [38] [435200/1281167 (34%)]	Loss: 1.626548
[2022-06-08 21:05:51 | train] - Train Epoch: [38] [448000/1281167 (35%)]	Loss: 1.393890
[2022-06-08 21:06:14 | train] - Train Epoch: [38] [460800/1281167 (36%)]	Loss: 1.573433
[2022-06-08 21:06:36 | train] - Train Epoch: [38] [473600/1281167 (37%)]	Loss: 1.224521
[2022-06-08 21:06:58 | train] - Train Epoch: [38] [486400/1281167 (38%)]	Loss: 1.236880
[2022-06-08 21:07:20 | train] - Train Epoch: [38] [499200/1281167 (39%)]	Loss: 1.489528
[2022-06-08 21:07:42 | train] - Train Epoch: [38] [512000/1281167 (40%)]	Loss: 1.199949
[2022-06-08 21:08:03 | train] - Train Epoch: [38] [524800/1281167 (41%)]	Loss: 1.164134
[2022-06-08 21:08:25 | train] - Train Epoch: [38] [537600/1281167 (42%)]	Loss: 1.288731
[2022-06-08 21:08:48 | train] - Train Epoch: [38] [550400/1281167 (43%)]	Loss: 1.376580
[2022-06-08 21:09:10 | train] - Train Epoch: [38] [563200/1281167 (44%)]	Loss: 1.595626
[2022-06-08 21:09:32 | train] - Train Epoch: [38] [576000/1281167 (45%)]	Loss: 1.537008
[2022-06-08 21:09:55 | train] - Train Epoch: [38] [588800/1281167 (46%)]	Loss: 1.113837
[2022-06-08 21:10:16 | train] - Train Epoch: [38] [601600/1281167 (47%)]	Loss: 1.616290
[2022-06-08 21:10:38 | train] - Train Epoch: [38] [614400/1281167 (48%)]	Loss: 1.539309
[2022-06-08 21:11:00 | train] - Train Epoch: [38] [627200/1281167 (49%)]	Loss: 1.105222
[2022-06-08 21:11:23 | train] - Train Epoch: [38] [640000/1281167 (50%)]	Loss: 1.594721
[2022-06-08 21:11:44 | train] - Train Epoch: [38] [652800/1281167 (51%)]	Loss: 1.267048
[2022-06-08 21:12:07 | train] - Train Epoch: [38] [665600/1281167 (52%)]	Loss: 1.474253
[2022-06-08 21:12:28 | train] - Train Epoch: [38] [678400/1281167 (53%)]	Loss: 1.533546
[2022-06-08 21:12:50 | train] - Train Epoch: [38] [691200/1281167 (54%)]	Loss: 1.213682
[2022-06-08 21:13:12 | train] - Train Epoch: [38] [704000/1281167 (55%)]	Loss: 1.116719
[2022-06-08 21:13:34 | train] - Train Epoch: [38] [716800/1281167 (56%)]	Loss: 1.635795
[2022-06-08 21:13:56 | train] - Train Epoch: [38] [729600/1281167 (57%)]	Loss: 1.058893
[2022-06-08 21:14:18 | train] - Train Epoch: [38] [742400/1281167 (58%)]	Loss: 1.495352
[2022-06-08 21:14:40 | train] - Train Epoch: [38] [755200/1281167 (59%)]	Loss: 1.459304
[2022-06-08 21:15:03 | train] - Train Epoch: [38] [768000/1281167 (60%)]	Loss: 1.335819
[2022-06-08 21:15:24 | train] - Train Epoch: [38] [780800/1281167 (61%)]	Loss: 1.139596
[2022-06-08 21:15:46 | train] - Train Epoch: [38] [793600/1281167 (62%)]	Loss: 1.443081
[2022-06-08 21:16:09 | train] - Train Epoch: [38] [806400/1281167 (63%)]	Loss: 1.481274
[2022-06-08 21:16:30 | train] - Train Epoch: [38] [819200/1281167 (64%)]	Loss: 1.404460
[2022-06-08 21:16:52 | train] - Train Epoch: [38] [832000/1281167 (65%)]	Loss: 1.517460
[2022-06-08 21:17:14 | train] - Train Epoch: [38] [844800/1281167 (66%)]	Loss: 1.365399
[2022-06-08 21:17:36 | train] - Train Epoch: [38] [857600/1281167 (67%)]	Loss: 1.456125
[2022-06-08 21:17:58 | train] - Train Epoch: [38] [870400/1281167 (68%)]	Loss: 1.503787
[2022-06-08 21:18:19 | train] - Train Epoch: [38] [883200/1281167 (69%)]	Loss: 1.436114
[2022-06-08 21:18:41 | train] - Train Epoch: [38] [896000/1281167 (70%)]	Loss: 1.256391
[2022-06-08 21:19:02 | train] - Train Epoch: [38] [908800/1281167 (71%)]	Loss: 1.598368
[2022-06-08 21:19:25 | train] - Train Epoch: [38] [921600/1281167 (72%)]	Loss: 1.419024
[2022-06-08 21:19:46 | train] - Train Epoch: [38] [934400/1281167 (73%)]	Loss: 1.618830
[2022-06-08 21:20:08 | train] - Train Epoch: [38] [947200/1281167 (74%)]	Loss: 1.556578
[2022-06-08 21:20:31 | train] - Train Epoch: [38] [960000/1281167 (75%)]	Loss: 1.143378
[2022-06-08 21:20:52 | train] - Train Epoch: [38] [972800/1281167 (76%)]	Loss: 1.221570
[2022-06-08 21:21:13 | train] - Train Epoch: [38] [985600/1281167 (77%)]	Loss: 1.695151
[2022-06-08 21:21:35 | train] - Train Epoch: [38] [998400/1281167 (78%)]	Loss: 1.343500
[2022-06-08 21:21:56 | train] - Train Epoch: [38] [1011200/1281167 (79%)]	Loss: 1.210447
[2022-06-08 21:22:18 | train] - Train Epoch: [38] [1024000/1281167 (80%)]	Loss: 1.542828
[2022-06-08 21:22:41 | train] - Train Epoch: [38] [1036800/1281167 (81%)]	Loss: 1.572275
[2022-06-08 21:23:03 | train] - Train Epoch: [38] [1049600/1281167 (82%)]	Loss: 1.365938
[2022-06-08 21:23:24 | train] - Train Epoch: [38] [1062400/1281167 (83%)]	Loss: 0.977952
[2022-06-08 21:23:46 | train] - Train Epoch: [38] [1075200/1281167 (84%)]	Loss: 1.184817
[2022-06-08 21:24:09 | train] - Train Epoch: [38] [1088000/1281167 (85%)]	Loss: 1.205354
[2022-06-08 21:24:31 | train] - Train Epoch: [38] [1100800/1281167 (86%)]	Loss: 1.247436
[2022-06-08 21:24:53 | train] - Train Epoch: [38] [1113600/1281167 (87%)]	Loss: 1.819535
[2022-06-08 21:25:15 | train] - Train Epoch: [38] [1126400/1281167 (88%)]	Loss: 1.288472
[2022-06-08 21:25:37 | train] - Train Epoch: [38] [1139200/1281167 (89%)]	Loss: 1.327715
[2022-06-08 21:25:59 | train] - Train Epoch: [38] [1152000/1281167 (90%)]	Loss: 1.004217
[2022-06-08 21:26:20 | train] - Train Epoch: [38] [1164800/1281167 (91%)]	Loss: 1.327779
[2022-06-08 21:26:43 | train] - Train Epoch: [38] [1177600/1281167 (92%)]	Loss: 1.377216
[2022-06-08 21:27:05 | train] - Train Epoch: [38] [1190400/1281167 (93%)]	Loss: 1.605420
[2022-06-08 21:27:27 | train] - Train Epoch: [38] [1203200/1281167 (94%)]	Loss: 1.499116
[2022-06-08 21:27:48 | train] - Train Epoch: [38] [1216000/1281167 (95%)]	Loss: 1.487811
[2022-06-08 21:28:10 | train] - Train Epoch: [38] [1228800/1281167 (96%)]	Loss: 1.212564
[2022-06-08 21:28:32 | train] - Train Epoch: [38] [1241600/1281167 (97%)]	Loss: 1.529047
[2022-06-08 21:28:54 | train] - Train Epoch: [38] [1254400/1281167 (98%)]	Loss: 1.656046
[2022-06-08 21:29:16 | train] - Train Epoch: [38] [1267200/1281167 (99%)]	Loss: 1.589528
[2022-06-08 21:29:38 | train] - Train Epoch: [38] [1280000/1281167 (100%)]	Loss: 1.491728
[2022-06-08 21:29:40 | train] - Train Epoch: [38]	 Average Loss: 1.369852	 Total Acc : 67.3743	 Total Top5 Acc : 86.3422
[2022-06-08 21:29:40 | train] - -------38 epoch end-----------
========================================
-------38 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 21:31:14 | train] - 
Epoch [38] Test set: Average loss: 1.3950, Accuracy: 33547/50000 (67.0560%), Top-5 Accuracy: 87.5967%

[2022-06-08 21:31:14 | train] - save intermediate epoch [38] result


[2022-06-08 21:31:23 | train] - -------39 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 21:31:25 | train] - Train Epoch: [39] [0/1281167 (0%)]	Loss: 1.460882
[2022-06-08 21:31:47 | train] - Train Epoch: [39] [12800/1281167 (1%)]	Loss: 1.644521
[2022-06-08 21:32:09 | train] - Train Epoch: [39] [25600/1281167 (2%)]	Loss: 1.249146
[2022-06-08 21:32:31 | train] - Train Epoch: [39] [38400/1281167 (3%)]	Loss: 1.205808
[2022-06-08 21:32:53 | train] - Train Epoch: [39] [51200/1281167 (4%)]	Loss: 1.258722
[2022-06-08 21:33:15 | train] - Train Epoch: [39] [64000/1281167 (5%)]	Loss: 1.665179
[2022-06-08 21:33:37 | train] - Train Epoch: [39] [76800/1281167 (6%)]	Loss: 1.317161
[2022-06-08 21:33:59 | train] - Train Epoch: [39] [89600/1281167 (7%)]	Loss: 1.513926
[2022-06-08 21:34:21 | train] - Train Epoch: [39] [102400/1281167 (8%)]	Loss: 1.057343
[2022-06-08 21:34:43 | train] - Train Epoch: [39] [115200/1281167 (9%)]	Loss: 1.333178
[2022-06-08 21:35:05 | train] - Train Epoch: [39] [128000/1281167 (10%)]	Loss: 1.522497
[2022-06-08 21:35:27 | train] - Train Epoch: [39] [140800/1281167 (11%)]	Loss: 1.408434
[2022-06-08 21:35:50 | train] - Train Epoch: [39] [153600/1281167 (12%)]	Loss: 1.853002
[2022-06-08 21:36:10 | train] - Train Epoch: [39] [166400/1281167 (13%)]	Loss: 1.562688
[2022-06-08 21:36:32 | train] - Train Epoch: [39] [179200/1281167 (14%)]	Loss: 1.436914
[2022-06-08 21:36:53 | train] - Train Epoch: [39] [192000/1281167 (15%)]	Loss: 1.395187
[2022-06-08 21:37:15 | train] - Train Epoch: [39] [204800/1281167 (16%)]	Loss: 1.388820
[2022-06-08 21:37:37 | train] - Train Epoch: [39] [217600/1281167 (17%)]	Loss: 1.401358
[2022-06-08 21:37:58 | train] - Train Epoch: [39] [230400/1281167 (18%)]	Loss: 1.482206
[2022-06-08 21:38:20 | train] - Train Epoch: [39] [243200/1281167 (19%)]	Loss: 1.298819
[2022-06-08 21:38:42 | train] - Train Epoch: [39] [256000/1281167 (20%)]	Loss: 1.349379
[2022-06-08 21:39:04 | train] - Train Epoch: [39] [268800/1281167 (21%)]	Loss: 1.356274
[2022-06-08 21:39:26 | train] - Train Epoch: [39] [281600/1281167 (22%)]	Loss: 1.359383
[2022-06-08 21:39:47 | train] - Train Epoch: [39] [294400/1281167 (23%)]	Loss: 1.285396
[2022-06-08 21:40:10 | train] - Train Epoch: [39] [307200/1281167 (24%)]	Loss: 1.614137
[2022-06-08 21:40:31 | train] - Train Epoch: [39] [320000/1281167 (25%)]	Loss: 1.408812
[2022-06-08 21:40:53 | train] - Train Epoch: [39] [332800/1281167 (26%)]	Loss: 1.426989
[2022-06-08 21:41:15 | train] - Train Epoch: [39] [345600/1281167 (27%)]	Loss: 1.354095
[2022-06-08 21:41:37 | train] - Train Epoch: [39] [358400/1281167 (28%)]	Loss: 1.273827
[2022-06-08 21:41:59 | train] - Train Epoch: [39] [371200/1281167 (29%)]	Loss: 1.269770
[2022-06-08 21:42:21 | train] - Train Epoch: [39] [384000/1281167 (30%)]	Loss: 1.487804
[2022-06-08 21:42:41 | train] - Train Epoch: [39] [396800/1281167 (31%)]	Loss: 1.331858
[2022-06-08 21:43:04 | train] - Train Epoch: [39] [409600/1281167 (32%)]	Loss: 1.332112
[2022-06-08 21:43:25 | train] - Train Epoch: [39] [422400/1281167 (33%)]	Loss: 1.282393
[2022-06-08 21:43:47 | train] - Train Epoch: [39] [435200/1281167 (34%)]	Loss: 1.487993
[2022-06-08 21:44:09 | train] - Train Epoch: [39] [448000/1281167 (35%)]	Loss: 1.626613
[2022-06-08 21:44:31 | train] - Train Epoch: [39] [460800/1281167 (36%)]	Loss: 1.187225
[2022-06-08 21:44:52 | train] - Train Epoch: [39] [473600/1281167 (37%)]	Loss: 1.174281
[2022-06-08 21:45:15 | train] - Train Epoch: [39] [486400/1281167 (38%)]	Loss: 1.268898
[2022-06-08 21:45:37 | train] - Train Epoch: [39] [499200/1281167 (39%)]	Loss: 0.968238
[2022-06-08 21:45:59 | train] - Train Epoch: [39] [512000/1281167 (40%)]	Loss: 1.453567
[2022-06-08 21:46:21 | train] - Train Epoch: [39] [524800/1281167 (41%)]	Loss: 1.514673
[2022-06-08 21:46:43 | train] - Train Epoch: [39] [537600/1281167 (42%)]	Loss: 1.379986
[2022-06-08 21:47:05 | train] - Train Epoch: [39] [550400/1281167 (43%)]	Loss: 1.489626
[2022-06-08 21:47:27 | train] - Train Epoch: [39] [563200/1281167 (44%)]	Loss: 1.433053
[2022-06-08 21:47:49 | train] - Train Epoch: [39] [576000/1281167 (45%)]	Loss: 1.449809
[2022-06-08 21:48:10 | train] - Train Epoch: [39] [588800/1281167 (46%)]	Loss: 1.142730
[2022-06-08 21:48:32 | train] - Train Epoch: [39] [601600/1281167 (47%)]	Loss: 1.692494
[2022-06-08 21:48:54 | train] - Train Epoch: [39] [614400/1281167 (48%)]	Loss: 1.304081
[2022-06-08 21:49:15 | train] - Train Epoch: [39] [627200/1281167 (49%)]	Loss: 1.559084
[2022-06-08 21:49:37 | train] - Train Epoch: [39] [640000/1281167 (50%)]	Loss: 1.454516
[2022-06-08 21:49:59 | train] - Train Epoch: [39] [652800/1281167 (51%)]	Loss: 1.366573
[2022-06-08 21:50:20 | train] - Train Epoch: [39] [665600/1281167 (52%)]	Loss: 1.328576
[2022-06-08 21:50:41 | train] - Train Epoch: [39] [678400/1281167 (53%)]	Loss: 1.699201
[2022-06-08 21:51:03 | train] - Train Epoch: [39] [691200/1281167 (54%)]	Loss: 1.260867
[2022-06-08 21:51:25 | train] - Train Epoch: [39] [704000/1281167 (55%)]	Loss: 1.267381
[2022-06-08 21:51:46 | train] - Train Epoch: [39] [716800/1281167 (56%)]	Loss: 1.121172
[2022-06-08 21:52:08 | train] - Train Epoch: [39] [729600/1281167 (57%)]	Loss: 1.307309
[2022-06-08 21:52:30 | train] - Train Epoch: [39] [742400/1281167 (58%)]	Loss: 1.556558
[2022-06-08 21:52:52 | train] - Train Epoch: [39] [755200/1281167 (59%)]	Loss: 1.406368
[2022-06-08 21:53:14 | train] - Train Epoch: [39] [768000/1281167 (60%)]	Loss: 1.168477
[2022-06-08 21:53:36 | train] - Train Epoch: [39] [780800/1281167 (61%)]	Loss: 1.191100
[2022-06-08 21:53:58 | train] - Train Epoch: [39] [793600/1281167 (62%)]	Loss: 1.312922
[2022-06-08 21:54:20 | train] - Train Epoch: [39] [806400/1281167 (63%)]	Loss: 1.509983
[2022-06-08 21:54:41 | train] - Train Epoch: [39] [819200/1281167 (64%)]	Loss: 1.543615
[2022-06-08 21:55:03 | train] - Train Epoch: [39] [832000/1281167 (65%)]	Loss: 1.235997
[2022-06-08 21:55:25 | train] - Train Epoch: [39] [844800/1281167 (66%)]	Loss: 0.958158
[2022-06-08 21:55:47 | train] - Train Epoch: [39] [857600/1281167 (67%)]	Loss: 1.637877
[2022-06-08 21:56:08 | train] - Train Epoch: [39] [870400/1281167 (68%)]	Loss: 1.410287
[2022-06-08 21:56:30 | train] - Train Epoch: [39] [883200/1281167 (69%)]	Loss: 1.414036
[2022-06-08 21:56:52 | train] - Train Epoch: [39] [896000/1281167 (70%)]	Loss: 1.533097
[2022-06-08 21:57:14 | train] - Train Epoch: [39] [908800/1281167 (71%)]	Loss: 1.190145
[2022-06-08 21:57:36 | train] - Train Epoch: [39] [921600/1281167 (72%)]	Loss: 1.232562
[2022-06-08 21:57:58 | train] - Train Epoch: [39] [934400/1281167 (73%)]	Loss: 1.137318
[2022-06-08 21:58:19 | train] - Train Epoch: [39] [947200/1281167 (74%)]	Loss: 1.436658
[2022-06-08 21:58:41 | train] - Train Epoch: [39] [960000/1281167 (75%)]	Loss: 1.476931
[2022-06-08 21:59:03 | train] - Train Epoch: [39] [972800/1281167 (76%)]	Loss: 1.359476
[2022-06-08 21:59:25 | train] - Train Epoch: [39] [985600/1281167 (77%)]	Loss: 1.311370
[2022-06-08 21:59:46 | train] - Train Epoch: [39] [998400/1281167 (78%)]	Loss: 1.204128
[2022-06-08 22:00:09 | train] - Train Epoch: [39] [1011200/1281167 (79%)]	Loss: 1.453756
[2022-06-08 22:00:30 | train] - Train Epoch: [39] [1024000/1281167 (80%)]	Loss: 1.243377
[2022-06-08 22:00:52 | train] - Train Epoch: [39] [1036800/1281167 (81%)]	Loss: 1.853896
[2022-06-08 22:01:13 | train] - Train Epoch: [39] [1049600/1281167 (82%)]	Loss: 1.291690
[2022-06-08 22:01:34 | train] - Train Epoch: [39] [1062400/1281167 (83%)]	Loss: 1.507794
[2022-06-08 22:01:57 | train] - Train Epoch: [39] [1075200/1281167 (84%)]	Loss: 1.113180
[2022-06-08 22:02:19 | train] - Train Epoch: [39] [1088000/1281167 (85%)]	Loss: 1.572613
[2022-06-08 22:02:41 | train] - Train Epoch: [39] [1100800/1281167 (86%)]	Loss: 1.195949
[2022-06-08 22:03:03 | train] - Train Epoch: [39] [1113600/1281167 (87%)]	Loss: 1.356060
[2022-06-08 22:03:25 | train] - Train Epoch: [39] [1126400/1281167 (88%)]	Loss: 1.642609
[2022-06-08 22:03:46 | train] - Train Epoch: [39] [1139200/1281167 (89%)]	Loss: 1.341101
[2022-06-08 22:04:08 | train] - Train Epoch: [39] [1152000/1281167 (90%)]	Loss: 1.378006
[2022-06-08 22:04:30 | train] - Train Epoch: [39] [1164800/1281167 (91%)]	Loss: 1.621770
[2022-06-08 22:04:51 | train] - Train Epoch: [39] [1177600/1281167 (92%)]	Loss: 1.254661
[2022-06-08 22:05:13 | train] - Train Epoch: [39] [1190400/1281167 (93%)]	Loss: 1.491342
[2022-06-08 22:05:35 | train] - Train Epoch: [39] [1203200/1281167 (94%)]	Loss: 1.219054
[2022-06-08 22:05:57 | train] - Train Epoch: [39] [1216000/1281167 (95%)]	Loss: 1.162877
[2022-06-08 22:06:19 | train] - Train Epoch: [39] [1228800/1281167 (96%)]	Loss: 1.449148
[2022-06-08 22:06:41 | train] - Train Epoch: [39] [1241600/1281167 (97%)]	Loss: 1.302702
[2022-06-08 22:07:02 | train] - Train Epoch: [39] [1254400/1281167 (98%)]	Loss: 1.312674
[2022-06-08 22:07:24 | train] - Train Epoch: [39] [1267200/1281167 (99%)]	Loss: 1.736199
[2022-06-08 22:07:46 | train] - Train Epoch: [39] [1280000/1281167 (100%)]	Loss: 1.768844
[2022-06-08 22:07:48 | train] - Train Epoch: [39]	 Average Loss: 1.357922	 Total Acc : 67.6629	 Total Top5 Acc : 86.5238
[2022-06-08 22:07:48 | train] - -------39 epoch end-----------
========================================
-------39 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 22:09:21 | train] - 
Epoch [39] Test set: Average loss: 1.3965, Accuracy: 33492/50000 (66.9641%), Top-5 Accuracy: 87.5376%

[2022-06-08 22:09:21 | train] - save intermediate epoch [39] result


[2022-06-08 22:09:32 | train] - -------40 epoch start-----------
========================================
----- test end -------------------------


[2022-06-08 22:09:34 | train] - Train Epoch: [40] [0/1281167 (0%)]	Loss: 1.417070
[2022-06-08 22:09:55 | train] - Train Epoch: [40] [12800/1281167 (1%)]	Loss: 1.353404
[2022-06-08 22:10:17 | train] - Train Epoch: [40] [25600/1281167 (2%)]	Loss: 1.335505
[2022-06-08 22:10:38 | train] - Train Epoch: [40] [38400/1281167 (3%)]	Loss: 1.307521
[2022-06-08 22:10:59 | train] - Train Epoch: [40] [51200/1281167 (4%)]	Loss: 1.228575
[2022-06-08 22:11:21 | train] - Train Epoch: [40] [64000/1281167 (5%)]	Loss: 1.412987
[2022-06-08 22:11:43 | train] - Train Epoch: [40] [76800/1281167 (6%)]	Loss: 1.557545
[2022-06-08 22:12:05 | train] - Train Epoch: [40] [89600/1281167 (7%)]	Loss: 1.280672
[2022-06-08 22:12:27 | train] - Train Epoch: [40] [102400/1281167 (8%)]	Loss: 1.274587
[2022-06-08 22:12:48 | train] - Train Epoch: [40] [115200/1281167 (9%)]	Loss: 1.425713
[2022-06-08 22:13:10 | train] - Train Epoch: [40] [128000/1281167 (10%)]	Loss: 1.397917
[2022-06-08 22:13:32 | train] - Train Epoch: [40] [140800/1281167 (11%)]	Loss: 1.200219
[2022-06-08 22:13:54 | train] - Train Epoch: [40] [153600/1281167 (12%)]	Loss: 1.306903
[2022-06-08 22:14:15 | train] - Train Epoch: [40] [166400/1281167 (13%)]	Loss: 1.253681
[2022-06-08 22:14:36 | train] - Train Epoch: [40] [179200/1281167 (14%)]	Loss: 1.171310
[2022-06-08 22:14:58 | train] - Train Epoch: [40] [192000/1281167 (15%)]	Loss: 1.393531
[2022-06-08 22:15:19 | train] - Train Epoch: [40] [204800/1281167 (16%)]	Loss: 1.485963
[2022-06-08 22:15:41 | train] - Train Epoch: [40] [217600/1281167 (17%)]	Loss: 1.413078
[2022-06-08 22:16:02 | train] - Train Epoch: [40] [230400/1281167 (18%)]	Loss: 1.387748
[2022-06-08 22:16:24 | train] - Train Epoch: [40] [243200/1281167 (19%)]	Loss: 1.090544
[2022-06-08 22:16:46 | train] - Train Epoch: [40] [256000/1281167 (20%)]	Loss: 1.291754
[2022-06-08 22:17:07 | train] - Train Epoch: [40] [268800/1281167 (21%)]	Loss: 1.517085
[2022-06-08 22:17:29 | train] - Train Epoch: [40] [281600/1281167 (22%)]	Loss: 1.263604
[2022-06-08 22:17:50 | train] - Train Epoch: [40] [294400/1281167 (23%)]	Loss: 1.075343
[2022-06-08 22:18:11 | train] - Train Epoch: [40] [307200/1281167 (24%)]	Loss: 1.064511
[2022-06-08 22:18:33 | train] - Train Epoch: [40] [320000/1281167 (25%)]	Loss: 1.478990
[2022-06-08 22:18:54 | train] - Train Epoch: [40] [332800/1281167 (26%)]	Loss: 1.431416
[2022-06-08 22:19:16 | train] - Train Epoch: [40] [345600/1281167 (27%)]	Loss: 1.286028
[2022-06-08 22:19:37 | train] - Train Epoch: [40] [358400/1281167 (28%)]	Loss: 1.259694
[2022-06-08 22:19:58 | train] - Train Epoch: [40] [371200/1281167 (29%)]	Loss: 1.131098
[2022-06-08 22:20:20 | train] - Train Epoch: [40] [384000/1281167 (30%)]	Loss: 1.201127
[2022-06-08 22:20:41 | train] - Train Epoch: [40] [396800/1281167 (31%)]	Loss: 1.534037
[2022-06-08 22:21:03 | train] - Train Epoch: [40] [409600/1281167 (32%)]	Loss: 1.191904
[2022-06-08 22:21:25 | train] - Train Epoch: [40] [422400/1281167 (33%)]	Loss: 1.419858
[2022-06-08 22:21:46 | train] - Train Epoch: [40] [435200/1281167 (34%)]	Loss: 1.676258
[2022-06-08 22:22:08 | train] - Train Epoch: [40] [448000/1281167 (35%)]	Loss: 1.421388
[2022-06-08 22:22:30 | train] - Train Epoch: [40] [460800/1281167 (36%)]	Loss: 1.328537
[2022-06-08 22:22:51 | train] - Train Epoch: [40] [473600/1281167 (37%)]	Loss: 1.176612
[2022-06-08 22:23:13 | train] - Train Epoch: [40] [486400/1281167 (38%)]	Loss: 1.449603
[2022-06-08 22:23:34 | train] - Train Epoch: [40] [499200/1281167 (39%)]	Loss: 1.166115
[2022-06-08 22:23:56 | train] - Train Epoch: [40] [512000/1281167 (40%)]	Loss: 1.474912
[2022-06-08 22:24:18 | train] - Train Epoch: [40] [524800/1281167 (41%)]	Loss: 1.259325
[2022-06-08 22:24:40 | train] - Train Epoch: [40] [537600/1281167 (42%)]	Loss: 1.326747
[2022-06-08 22:25:01 | train] - Train Epoch: [40] [550400/1281167 (43%)]	Loss: 1.832352
[2022-06-08 22:25:22 | train] - Train Epoch: [40] [563200/1281167 (44%)]	Loss: 1.500583
[2022-06-08 22:25:44 | train] - Train Epoch: [40] [576000/1281167 (45%)]	Loss: 1.314602
[2022-06-08 22:26:05 | train] - Train Epoch: [40] [588800/1281167 (46%)]	Loss: 0.985208
[2022-06-08 22:26:27 | train] - Train Epoch: [40] [601600/1281167 (47%)]	Loss: 1.185149
[2022-06-08 22:26:49 | train] - Train Epoch: [40] [614400/1281167 (48%)]	Loss: 1.145701
[2022-06-08 22:27:10 | train] - Train Epoch: [40] [627200/1281167 (49%)]	Loss: 1.412954
[2022-06-08 22:27:32 | train] - Train Epoch: [40] [640000/1281167 (50%)]	Loss: 1.258071
[2022-06-08 22:27:53 | train] - Train Epoch: [40] [652800/1281167 (51%)]	Loss: 1.004980
[2022-06-08 22:28:15 | train] - Train Epoch: [40] [665600/1281167 (52%)]	Loss: 1.129272
[2022-06-08 22:28:37 | train] - Train Epoch: [40] [678400/1281167 (53%)]	Loss: 1.393414
[2022-06-08 22:28:58 | train] - Train Epoch: [40] [691200/1281167 (54%)]	Loss: 1.348237
[2022-06-08 22:29:19 | train] - Train Epoch: [40] [704000/1281167 (55%)]	Loss: 1.367066
[2022-06-08 22:29:41 | train] - Train Epoch: [40] [716800/1281167 (56%)]	Loss: 1.479787
[2022-06-08 22:30:03 | train] - Train Epoch: [40] [729600/1281167 (57%)]	Loss: 1.598258
[2022-06-08 22:30:25 | train] - Train Epoch: [40] [742400/1281167 (58%)]	Loss: 1.478311
[2022-06-08 22:30:46 | train] - Train Epoch: [40] [755200/1281167 (59%)]	Loss: 1.408377
[2022-06-08 22:31:07 | train] - Train Epoch: [40] [768000/1281167 (60%)]	Loss: 1.352324
[2022-06-08 22:31:28 | train] - Train Epoch: [40] [780800/1281167 (61%)]	Loss: 1.582659
[2022-06-08 22:31:49 | train] - Train Epoch: [40] [793600/1281167 (62%)]	Loss: 1.513575
[2022-06-08 22:32:11 | train] - Train Epoch: [40] [806400/1281167 (63%)]	Loss: 1.602959
[2022-06-08 22:32:32 | train] - Train Epoch: [40] [819200/1281167 (64%)]	Loss: 1.171706
[2022-06-08 22:32:54 | train] - Train Epoch: [40] [832000/1281167 (65%)]	Loss: 1.777357
[2022-06-08 22:33:15 | train] - Train Epoch: [40] [844800/1281167 (66%)]	Loss: 1.245331
[2022-06-08 22:33:37 | train] - Train Epoch: [40] [857600/1281167 (67%)]	Loss: 1.396728
[2022-06-08 22:33:59 | train] - Train Epoch: [40] [870400/1281167 (68%)]	Loss: 1.338015
[2022-06-08 22:34:21 | train] - Train Epoch: [40] [883200/1281167 (69%)]	Loss: 1.429237
[2022-06-08 22:34:42 | train] - Train Epoch: [40] [896000/1281167 (70%)]	Loss: 1.395456
[2022-06-08 22:35:04 | train] - Train Epoch: [40] [908800/1281167 (71%)]	Loss: 1.824438
[2022-06-08 22:35:25 | train] - Train Epoch: [40] [921600/1281167 (72%)]	Loss: 1.301509
[2022-06-08 22:35:47 | train] - Train Epoch: [40] [934400/1281167 (73%)]	Loss: 1.769618
[2022-06-08 22:36:08 | train] - Train Epoch: [40] [947200/1281167 (74%)]	Loss: 1.145914
[2022-06-08 22:36:29 | train] - Train Epoch: [40] [960000/1281167 (75%)]	Loss: 1.390730
[2022-06-08 22:36:50 | train] - Train Epoch: [40] [972800/1281167 (76%)]	Loss: 1.116303
[2022-06-08 22:37:12 | train] - Train Epoch: [40] [985600/1281167 (77%)]	Loss: 1.210857
[2022-06-08 22:37:33 | train] - Train Epoch: [40] [998400/1281167 (78%)]	Loss: 1.660925
[2022-06-08 22:37:55 | train] - Train Epoch: [40] [1011200/1281167 (79%)]	Loss: 1.150725
[2022-06-08 22:38:16 | train] - Train Epoch: [40] [1024000/1281167 (80%)]	Loss: 1.632951
[2022-06-08 22:38:38 | train] - Train Epoch: [40] [1036800/1281167 (81%)]	Loss: 1.357498
[2022-06-08 22:38:59 | train] - Train Epoch: [40] [1049600/1281167 (82%)]	Loss: 1.210275
[2022-06-08 22:39:21 | train] - Train Epoch: [40] [1062400/1281167 (83%)]	Loss: 1.283195
[2022-06-08 22:39:42 | train] - Train Epoch: [40] [1075200/1281167 (84%)]	Loss: 1.504824
[2022-06-08 22:40:03 | train] - Train Epoch: [40] [1088000/1281167 (85%)]	Loss: 1.310452
[2022-06-08 22:40:25 | train] - Train Epoch: [40] [1100800/1281167 (86%)]	Loss: 1.195174
[2022-06-08 22:40:46 | train] - Train Epoch: [40] [1113600/1281167 (87%)]	Loss: 1.480269
[2022-06-08 22:41:07 | train] - Train Epoch: [40] [1126400/1281167 (88%)]	Loss: 1.278581
[2022-06-08 22:41:28 | train] - Train Epoch: [40] [1139200/1281167 (89%)]	Loss: 1.279974
[2022-06-08 22:41:49 | train] - Train Epoch: [40] [1152000/1281167 (90%)]	Loss: 1.736384
[2022-06-08 22:42:11 | train] - Train Epoch: [40] [1164800/1281167 (91%)]	Loss: 1.446612
[2022-06-08 22:42:32 | train] - Train Epoch: [40] [1177600/1281167 (92%)]	Loss: 1.367176
[2022-06-08 22:42:54 | train] - Train Epoch: [40] [1190400/1281167 (93%)]	Loss: 1.662238
[2022-06-08 22:43:15 | train] - Train Epoch: [40] [1203200/1281167 (94%)]	Loss: 1.687764
[2022-06-08 22:43:37 | train] - Train Epoch: [40] [1216000/1281167 (95%)]	Loss: 1.350668
[2022-06-08 22:43:58 | train] - Train Epoch: [40] [1228800/1281167 (96%)]	Loss: 1.520388
[2022-06-08 22:44:20 | train] - Train Epoch: [40] [1241600/1281167 (97%)]	Loss: 1.454538
[2022-06-08 22:44:41 | train] - Train Epoch: [40] [1254400/1281167 (98%)]	Loss: 1.118612
[2022-06-08 22:45:02 | train] - Train Epoch: [40] [1267200/1281167 (99%)]	Loss: 1.403491
[2022-06-08 22:45:24 | train] - Train Epoch: [40] [1280000/1281167 (100%)]	Loss: 1.213910
[2022-06-08 22:45:26 | train] - Train Epoch: [40]	 Average Loss: 1.342259	 Total Acc : 68.0321	 Total Top5 Acc : 86.7099
[2022-06-08 22:45:26 | train] - -------40 epoch end-----------
========================================
-------40 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 22:46:59 | train] - 
Epoch [40] Test set: Average loss: 1.3815, Accuracy: 33590/50000 (67.1395%), Top-5 Accuracy: 87.6834%

[2022-06-08 22:46:59 | train] - save intermediate epoch [40] result


[2022-06-08 22:47:08 | train] - logging best performance 40 epoch
[2022-06-08 22:47:10 | train] - -------41 epoch start-----------
========================================
----- test end -------------------------


logging best performance 40 epoch
[2022-06-08 22:47:11 | train] - Train Epoch: [41] [0/1281167 (0%)]	Loss: 1.397666
[2022-06-08 22:47:34 | train] - Train Epoch: [41] [12800/1281167 (1%)]	Loss: 1.376401
[2022-06-08 22:47:55 | train] - Train Epoch: [41] [25600/1281167 (2%)]	Loss: 1.282521
[2022-06-08 22:48:17 | train] - Train Epoch: [41] [38400/1281167 (3%)]	Loss: 1.500879
[2022-06-08 22:48:39 | train] - Train Epoch: [41] [51200/1281167 (4%)]	Loss: 1.399095
[2022-06-08 22:49:01 | train] - Train Epoch: [41] [64000/1281167 (5%)]	Loss: 1.344206
[2022-06-08 22:49:22 | train] - Train Epoch: [41] [76800/1281167 (6%)]	Loss: 1.343442
[2022-06-08 22:49:42 | train] - Train Epoch: [41] [89600/1281167 (7%)]	Loss: 1.410783
[2022-06-08 22:50:05 | train] - Train Epoch: [41] [102400/1281167 (8%)]	Loss: 1.135788
[2022-06-08 22:50:27 | train] - Train Epoch: [41] [115200/1281167 (9%)]	Loss: 1.333727
[2022-06-08 22:50:48 | train] - Train Epoch: [41] [128000/1281167 (10%)]	Loss: 1.220839
[2022-06-08 22:51:10 | train] - Train Epoch: [41] [140800/1281167 (11%)]	Loss: 1.337288
[2022-06-08 22:51:32 | train] - Train Epoch: [41] [153600/1281167 (12%)]	Loss: 1.341808
[2022-06-08 22:51:55 | train] - Train Epoch: [41] [166400/1281167 (13%)]	Loss: 1.429622
[2022-06-08 22:52:17 | train] - Train Epoch: [41] [179200/1281167 (14%)]	Loss: 1.087213
[2022-06-08 22:52:39 | train] - Train Epoch: [41] [192000/1281167 (15%)]	Loss: 1.330654
[2022-06-08 22:53:01 | train] - Train Epoch: [41] [204800/1281167 (16%)]	Loss: 1.354592
[2022-06-08 22:53:23 | train] - Train Epoch: [41] [217600/1281167 (17%)]	Loss: 1.164462
[2022-06-08 22:53:45 | train] - Train Epoch: [41] [230400/1281167 (18%)]	Loss: 1.486929
[2022-06-08 22:54:06 | train] - Train Epoch: [41] [243200/1281167 (19%)]	Loss: 1.324112
[2022-06-08 22:54:27 | train] - Train Epoch: [41] [256000/1281167 (20%)]	Loss: 1.368830
[2022-06-08 22:54:49 | train] - Train Epoch: [41] [268800/1281167 (21%)]	Loss: 1.215692
[2022-06-08 22:55:11 | train] - Train Epoch: [41] [281600/1281167 (22%)]	Loss: 1.823113
[2022-06-08 22:55:31 | train] - Train Epoch: [41] [294400/1281167 (23%)]	Loss: 1.386724
[2022-06-08 22:55:53 | train] - Train Epoch: [41] [307200/1281167 (24%)]	Loss: 1.541440
[2022-06-08 22:56:15 | train] - Train Epoch: [41] [320000/1281167 (25%)]	Loss: 1.347398
[2022-06-08 22:56:35 | train] - Train Epoch: [41] [332800/1281167 (26%)]	Loss: 1.342862
[2022-06-08 22:56:58 | train] - Train Epoch: [41] [345600/1281167 (27%)]	Loss: 1.313267
[2022-06-08 22:57:19 | train] - Train Epoch: [41] [358400/1281167 (28%)]	Loss: 1.145171
[2022-06-08 22:57:41 | train] - Train Epoch: [41] [371200/1281167 (29%)]	Loss: 1.687525
[2022-06-08 22:58:01 | train] - Train Epoch: [41] [384000/1281167 (30%)]	Loss: 1.096557
[2022-06-08 22:58:21 | train] - Train Epoch: [41] [396800/1281167 (31%)]	Loss: 1.094960
[2022-06-08 22:58:43 | train] - Train Epoch: [41] [409600/1281167 (32%)]	Loss: 1.201500
[2022-06-08 22:59:04 | train] - Train Epoch: [41] [422400/1281167 (33%)]	Loss: 1.114542
[2022-06-08 22:59:24 | train] - Train Epoch: [41] [435200/1281167 (34%)]	Loss: 1.157992
[2022-06-08 22:59:45 | train] - Train Epoch: [41] [448000/1281167 (35%)]	Loss: 1.174294
[2022-06-08 23:00:06 | train] - Train Epoch: [41] [460800/1281167 (36%)]	Loss: 1.121934
[2022-06-08 23:00:28 | train] - Train Epoch: [41] [473600/1281167 (37%)]	Loss: 1.338197
[2022-06-08 23:00:50 | train] - Train Epoch: [41] [486400/1281167 (38%)]	Loss: 1.270570
[2022-06-08 23:01:12 | train] - Train Epoch: [41] [499200/1281167 (39%)]	Loss: 1.291453
[2022-06-08 23:01:33 | train] - Train Epoch: [41] [512000/1281167 (40%)]	Loss: 1.247861
[2022-06-08 23:01:54 | train] - Train Epoch: [41] [524800/1281167 (41%)]	Loss: 1.510067
[2022-06-08 23:02:14 | train] - Train Epoch: [41] [537600/1281167 (42%)]	Loss: 1.440610
[2022-06-08 23:02:35 | train] - Train Epoch: [41] [550400/1281167 (43%)]	Loss: 1.608883
[2022-06-08 23:02:56 | train] - Train Epoch: [41] [563200/1281167 (44%)]	Loss: 1.286028
[2022-06-08 23:03:18 | train] - Train Epoch: [41] [576000/1281167 (45%)]	Loss: 1.284723
[2022-06-08 23:03:39 | train] - Train Epoch: [41] [588800/1281167 (46%)]	Loss: 1.027604
[2022-06-08 23:04:00 | train] - Train Epoch: [41] [601600/1281167 (47%)]	Loss: 1.282349
[2022-06-08 23:04:21 | train] - Train Epoch: [41] [614400/1281167 (48%)]	Loss: 1.223083
[2022-06-08 23:04:43 | train] - Train Epoch: [41] [627200/1281167 (49%)]	Loss: 1.365741
[2022-06-08 23:05:05 | train] - Train Epoch: [41] [640000/1281167 (50%)]	Loss: 1.174978
[2022-06-08 23:05:26 | train] - Train Epoch: [41] [652800/1281167 (51%)]	Loss: 1.406122
[2022-06-08 23:05:47 | train] - Train Epoch: [41] [665600/1281167 (52%)]	Loss: 1.281723
[2022-06-08 23:06:08 | train] - Train Epoch: [41] [678400/1281167 (53%)]	Loss: 1.117014
[2022-06-08 23:06:30 | train] - Train Epoch: [41] [691200/1281167 (54%)]	Loss: 1.501453
[2022-06-08 23:06:50 | train] - Train Epoch: [41] [704000/1281167 (55%)]	Loss: 1.139403
[2022-06-08 23:07:11 | train] - Train Epoch: [41] [716800/1281167 (56%)]	Loss: 1.122626
[2022-06-08 23:07:32 | train] - Train Epoch: [41] [729600/1281167 (57%)]	Loss: 1.170413
[2022-06-08 23:07:53 | train] - Train Epoch: [41] [742400/1281167 (58%)]	Loss: 1.191423
[2022-06-08 23:08:13 | train] - Train Epoch: [41] [755200/1281167 (59%)]	Loss: 1.113450
[2022-06-08 23:08:35 | train] - Train Epoch: [41] [768000/1281167 (60%)]	Loss: 1.144149
[2022-06-08 23:08:56 | train] - Train Epoch: [41] [780800/1281167 (61%)]	Loss: 1.296089
[2022-06-08 23:09:18 | train] - Train Epoch: [41] [793600/1281167 (62%)]	Loss: 1.506244
[2022-06-08 23:09:39 | train] - Train Epoch: [41] [806400/1281167 (63%)]	Loss: 1.362588
[2022-06-08 23:10:01 | train] - Train Epoch: [41] [819200/1281167 (64%)]	Loss: 1.471749
[2022-06-08 23:10:23 | train] - Train Epoch: [41] [832000/1281167 (65%)]	Loss: 1.491043
[2022-06-08 23:10:45 | train] - Train Epoch: [41] [844800/1281167 (66%)]	Loss: 1.306991
[2022-06-08 23:11:07 | train] - Train Epoch: [41] [857600/1281167 (67%)]	Loss: 1.279242
[2022-06-08 23:11:28 | train] - Train Epoch: [41] [870400/1281167 (68%)]	Loss: 1.349231
[2022-06-08 23:11:49 | train] - Train Epoch: [41] [883200/1281167 (69%)]	Loss: 1.238963
[2022-06-08 23:12:11 | train] - Train Epoch: [41] [896000/1281167 (70%)]	Loss: 1.309887
[2022-06-08 23:12:31 | train] - Train Epoch: [41] [908800/1281167 (71%)]	Loss: 1.322943
[2022-06-08 23:12:53 | train] - Train Epoch: [41] [921600/1281167 (72%)]	Loss: 1.510418
[2022-06-08 23:13:15 | train] - Train Epoch: [41] [934400/1281167 (73%)]	Loss: 1.344911
[2022-06-08 23:13:36 | train] - Train Epoch: [41] [947200/1281167 (74%)]	Loss: 1.123530
[2022-06-08 23:13:58 | train] - Train Epoch: [41] [960000/1281167 (75%)]	Loss: 1.456184
[2022-06-08 23:14:19 | train] - Train Epoch: [41] [972800/1281167 (76%)]	Loss: 1.480530
[2022-06-08 23:14:41 | train] - Train Epoch: [41] [985600/1281167 (77%)]	Loss: 1.287084
[2022-06-08 23:15:03 | train] - Train Epoch: [41] [998400/1281167 (78%)]	Loss: 1.691695
[2022-06-08 23:15:24 | train] - Train Epoch: [41] [1011200/1281167 (79%)]	Loss: 1.625591
[2022-06-08 23:15:45 | train] - Train Epoch: [41] [1024000/1281167 (80%)]	Loss: 1.588454
[2022-06-08 23:16:07 | train] - Train Epoch: [41] [1036800/1281167 (81%)]	Loss: 1.454921
[2022-06-08 23:16:29 | train] - Train Epoch: [41] [1049600/1281167 (82%)]	Loss: 1.115634
[2022-06-08 23:16:51 | train] - Train Epoch: [41] [1062400/1281167 (83%)]	Loss: 1.584486
[2022-06-08 23:17:13 | train] - Train Epoch: [41] [1075200/1281167 (84%)]	Loss: 1.588377
[2022-06-08 23:17:34 | train] - Train Epoch: [41] [1088000/1281167 (85%)]	Loss: 1.339713
[2022-06-08 23:17:56 | train] - Train Epoch: [41] [1100800/1281167 (86%)]	Loss: 1.301942
[2022-06-08 23:18:17 | train] - Train Epoch: [41] [1113600/1281167 (87%)]	Loss: 1.356749
[2022-06-08 23:18:39 | train] - Train Epoch: [41] [1126400/1281167 (88%)]	Loss: 1.524431
[2022-06-08 23:19:01 | train] - Train Epoch: [41] [1139200/1281167 (89%)]	Loss: 1.269303
[2022-06-08 23:19:23 | train] - Train Epoch: [41] [1152000/1281167 (90%)]	Loss: 1.078704
[2022-06-08 23:19:44 | train] - Train Epoch: [41] [1164800/1281167 (91%)]	Loss: 1.417380
[2022-06-08 23:20:06 | train] - Train Epoch: [41] [1177600/1281167 (92%)]	Loss: 1.761879
[2022-06-08 23:20:27 | train] - Train Epoch: [41] [1190400/1281167 (93%)]	Loss: 1.030898
[2022-06-08 23:20:49 | train] - Train Epoch: [41] [1203200/1281167 (94%)]	Loss: 1.274961
[2022-06-08 23:21:10 | train] - Train Epoch: [41] [1216000/1281167 (95%)]	Loss: 1.055488
[2022-06-08 23:21:31 | train] - Train Epoch: [41] [1228800/1281167 (96%)]	Loss: 1.668557
[2022-06-08 23:21:53 | train] - Train Epoch: [41] [1241600/1281167 (97%)]	Loss: 1.296940
[2022-06-08 23:22:14 | train] - Train Epoch: [41] [1254400/1281167 (98%)]	Loss: 1.457546
[2022-06-08 23:22:36 | train] - Train Epoch: [41] [1267200/1281167 (99%)]	Loss: 1.262551
[2022-06-08 23:22:56 | train] - Train Epoch: [41] [1280000/1281167 (100%)]	Loss: 1.463851
[2022-06-08 23:22:58 | train] - Train Epoch: [41]	 Average Loss: 1.330410	 Total Acc : 68.2238	 Total Top5 Acc : 86.8556
[2022-06-08 23:22:58 | train] - -------41 epoch end-----------
========================================
-------41 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-08 23:24:32 | train] - 
Epoch [41] Test set: Average loss: 1.3803, Accuracy: 33779/50000 (67.5304%), Top-5 Accuracy: 87.6431%

[2022-06-08 23:24:32 | train] - save intermediate epoch [41] result


[2022-06-08 23:24:41 | train] - logging best performance 41 epoch
[2022-06-08 23:24:43 | train] - -------42 epoch start-----------
========================================
----- test end -------------------------


logging best performance 41 epoch
[2022-06-08 23:24:45 | train] - Train Epoch: [42] [0/1281167 (0%)]	Loss: 1.176821
[2022-06-08 23:25:05 | train] - Train Epoch: [42] [12800/1281167 (1%)]	Loss: 1.019506
[2022-06-08 23:25:27 | train] - Train Epoch: [42] [25600/1281167 (2%)]	Loss: 1.536252
[2022-06-08 23:25:48 | train] - Train Epoch: [42] [38400/1281167 (3%)]	Loss: 1.099433
[2022-06-08 23:26:09 | train] - Train Epoch: [42] [51200/1281167 (4%)]	Loss: 1.306101
[2022-06-08 23:26:29 | train] - Train Epoch: [42] [64000/1281167 (5%)]	Loss: 1.305799
[2022-06-08 23:26:50 | train] - Train Epoch: [42] [76800/1281167 (6%)]	Loss: 1.429182
[2022-06-08 23:27:11 | train] - Train Epoch: [42] [89600/1281167 (7%)]	Loss: 1.381883
[2022-06-08 23:27:31 | train] - Train Epoch: [42] [102400/1281167 (8%)]	Loss: 1.438365
[2022-06-08 23:27:52 | train] - Train Epoch: [42] [115200/1281167 (9%)]	Loss: 1.453800
[2022-06-08 23:28:13 | train] - Train Epoch: [42] [128000/1281167 (10%)]	Loss: 1.618137
[2022-06-08 23:28:34 | train] - Train Epoch: [42] [140800/1281167 (11%)]	Loss: 1.292297
[2022-06-08 23:28:55 | train] - Train Epoch: [42] [153600/1281167 (12%)]	Loss: 1.128459
[2022-06-08 23:29:16 | train] - Train Epoch: [42] [166400/1281167 (13%)]	Loss: 1.258552
[2022-06-08 23:29:36 | train] - Train Epoch: [42] [179200/1281167 (14%)]	Loss: 1.270941
[2022-06-08 23:29:57 | train] - Train Epoch: [42] [192000/1281167 (15%)]	Loss: 1.064132
[2022-06-08 23:30:17 | train] - Train Epoch: [42] [204800/1281167 (16%)]	Loss: 1.541500
[2022-06-08 23:30:39 | train] - Train Epoch: [42] [217600/1281167 (17%)]	Loss: 1.477230
[2022-06-08 23:31:00 | train] - Train Epoch: [42] [230400/1281167 (18%)]	Loss: 1.295839
[2022-06-08 23:31:20 | train] - Train Epoch: [42] [243200/1281167 (19%)]	Loss: 1.452613
[2022-06-08 23:31:41 | train] - Train Epoch: [42] [256000/1281167 (20%)]	Loss: 1.132806
[2022-06-08 23:32:02 | train] - Train Epoch: [42] [268800/1281167 (21%)]	Loss: 1.220189
[2022-06-08 23:32:22 | train] - Train Epoch: [42] [281600/1281167 (22%)]	Loss: 1.158618
[2022-06-08 23:32:42 | train] - Train Epoch: [42] [294400/1281167 (23%)]	Loss: 1.541582
[2022-06-08 23:33:04 | train] - Train Epoch: [42] [307200/1281167 (24%)]	Loss: 1.257846
[2022-06-08 23:33:25 | train] - Train Epoch: [42] [320000/1281167 (25%)]	Loss: 1.359122
[2022-06-08 23:33:46 | train] - Train Epoch: [42] [332800/1281167 (26%)]	Loss: 1.380452
[2022-06-08 23:34:07 | train] - Train Epoch: [42] [345600/1281167 (27%)]	Loss: 1.172848
[2022-06-08 23:34:28 | train] - Train Epoch: [42] [358400/1281167 (28%)]	Loss: 1.198828
[2022-06-08 23:34:49 | train] - Train Epoch: [42] [371200/1281167 (29%)]	Loss: 1.243757
[2022-06-08 23:35:08 | train] - Train Epoch: [42] [384000/1281167 (30%)]	Loss: 1.423007
[2022-06-08 23:35:29 | train] - Train Epoch: [42] [396800/1281167 (31%)]	Loss: 1.256130
[2022-06-08 23:35:50 | train] - Train Epoch: [42] [409600/1281167 (32%)]	Loss: 1.233586
[2022-06-08 23:36:11 | train] - Train Epoch: [42] [422400/1281167 (33%)]	Loss: 1.313410
[2022-06-08 23:36:32 | train] - Train Epoch: [42] [435200/1281167 (34%)]	Loss: 1.310953
[2022-06-08 23:36:52 | train] - Train Epoch: [42] [448000/1281167 (35%)]	Loss: 1.260439
[2022-06-08 23:37:13 | train] - Train Epoch: [42] [460800/1281167 (36%)]	Loss: 1.424510
[2022-06-08 23:37:34 | train] - Train Epoch: [42] [473600/1281167 (37%)]	Loss: 1.813713
[2022-06-08 23:37:55 | train] - Train Epoch: [42] [486400/1281167 (38%)]	Loss: 1.604493
[2022-06-08 23:38:17 | train] - Train Epoch: [42] [499200/1281167 (39%)]	Loss: 1.402546
[2022-06-08 23:38:37 | train] - Train Epoch: [42] [512000/1281167 (40%)]	Loss: 1.488542
[2022-06-08 23:38:58 | train] - Train Epoch: [42] [524800/1281167 (41%)]	Loss: 1.154314
[2022-06-08 23:39:20 | train] - Train Epoch: [42] [537600/1281167 (42%)]	Loss: 1.649498
[2022-06-08 23:39:40 | train] - Train Epoch: [42] [550400/1281167 (43%)]	Loss: 1.500875
[2022-06-08 23:40:01 | train] - Train Epoch: [42] [563200/1281167 (44%)]	Loss: 1.411174
[2022-06-08 23:40:22 | train] - Train Epoch: [42] [576000/1281167 (45%)]	Loss: 1.000742
[2022-06-08 23:40:43 | train] - Train Epoch: [42] [588800/1281167 (46%)]	Loss: 1.363485
[2022-06-08 23:41:04 | train] - Train Epoch: [42] [601600/1281167 (47%)]	Loss: 1.121823
[2022-06-08 23:41:25 | train] - Train Epoch: [42] [614400/1281167 (48%)]	Loss: 1.082536
[2022-06-08 23:41:45 | train] - Train Epoch: [42] [627200/1281167 (49%)]	Loss: 1.465987
[2022-06-08 23:42:06 | train] - Train Epoch: [42] [640000/1281167 (50%)]	Loss: 1.359707
[2022-06-08 23:42:27 | train] - Train Epoch: [42] [652800/1281167 (51%)]	Loss: 1.054069
[2022-06-08 23:42:48 | train] - Train Epoch: [42] [665600/1281167 (52%)]	Loss: 1.424920
[2022-06-08 23:43:09 | train] - Train Epoch: [42] [678400/1281167 (53%)]	Loss: 1.260143
[2022-06-08 23:43:30 | train] - Train Epoch: [42] [691200/1281167 (54%)]	Loss: 0.941892
[2022-06-08 23:43:50 | train] - Train Epoch: [42] [704000/1281167 (55%)]	Loss: 1.127393
[2022-06-08 23:44:11 | train] - Train Epoch: [42] [716800/1281167 (56%)]	Loss: 1.287914
[2022-06-08 23:44:31 | train] - Train Epoch: [42] [729600/1281167 (57%)]	Loss: 1.521907
[2022-06-08 23:44:52 | train] - Train Epoch: [42] [742400/1281167 (58%)]	Loss: 1.137914
[2022-06-08 23:45:12 | train] - Train Epoch: [42] [755200/1281167 (59%)]	Loss: 1.338838
[2022-06-08 23:45:34 | train] - Train Epoch: [42] [768000/1281167 (60%)]	Loss: 1.376088
[2022-06-08 23:45:55 | train] - Train Epoch: [42] [780800/1281167 (61%)]	Loss: 1.310780
[2022-06-08 23:46:16 | train] - Train Epoch: [42] [793600/1281167 (62%)]	Loss: 1.596238
[2022-06-08 23:46:36 | train] - Train Epoch: [42] [806400/1281167 (63%)]	Loss: 1.540292
[2022-06-08 23:46:57 | train] - Train Epoch: [42] [819200/1281167 (64%)]	Loss: 1.227562
[2022-06-08 23:47:17 | train] - Train Epoch: [42] [832000/1281167 (65%)]	Loss: 1.644333
[2022-06-08 23:47:38 | train] - Train Epoch: [42] [844800/1281167 (66%)]	Loss: 1.261553
[2022-06-08 23:48:00 | train] - Train Epoch: [42] [857600/1281167 (67%)]	Loss: 1.323936
[2022-06-08 23:48:22 | train] - Train Epoch: [42] [870400/1281167 (68%)]	Loss: 1.034075
[2022-06-08 23:48:44 | train] - Train Epoch: [42] [883200/1281167 (69%)]	Loss: 1.490638
[2022-06-08 23:49:06 | train] - Train Epoch: [42] [896000/1281167 (70%)]	Loss: 1.061211
[2022-06-08 23:49:26 | train] - Train Epoch: [42] [908800/1281167 (71%)]	Loss: 1.163680
[2022-06-08 23:49:47 | train] - Train Epoch: [42] [921600/1281167 (72%)]	Loss: 1.288418
[2022-06-08 23:50:08 | train] - Train Epoch: [42] [934400/1281167 (73%)]	Loss: 1.229137
[2022-06-08 23:50:29 | train] - Train Epoch: [42] [947200/1281167 (74%)]	Loss: 1.142379
[2022-06-08 23:50:50 | train] - Train Epoch: [42] [960000/1281167 (75%)]	Loss: 1.555230
[2022-06-08 23:51:11 | train] - Train Epoch: [42] [972800/1281167 (76%)]	Loss: 1.433846
[2022-06-08 23:51:32 | train] - Train Epoch: [42] [985600/1281167 (77%)]	Loss: 1.541058
[2022-06-08 23:51:53 | train] - Train Epoch: [42] [998400/1281167 (78%)]	Loss: 1.485605
[2022-06-08 23:52:15 | train] - Train Epoch: [42] [1011200/1281167 (79%)]	Loss: 1.682557
[2022-06-08 23:52:35 | train] - Train Epoch: [42] [1024000/1281167 (80%)]	Loss: 1.491269
[2022-06-08 23:52:55 | train] - Train Epoch: [42] [1036800/1281167 (81%)]	Loss: 1.343035
[2022-06-08 23:53:15 | train] - Train Epoch: [42] [1049600/1281167 (82%)]	Loss: 1.163373
[2022-06-08 23:53:35 | train] - Train Epoch: [42] [1062400/1281167 (83%)]	Loss: 1.225626
[2022-06-08 23:53:56 | train] - Train Epoch: [42] [1075200/1281167 (84%)]	Loss: 1.381795
[2022-06-08 23:54:16 | train] - Train Epoch: [42] [1088000/1281167 (85%)]	Loss: 1.235336
[2022-06-08 23:54:36 | train] - Train Epoch: [42] [1100800/1281167 (86%)]	Loss: 1.312884
[2022-06-08 23:54:56 | train] - Train Epoch: [42] [1113600/1281167 (87%)]	Loss: 1.460152
[2022-06-08 23:55:18 | train] - Train Epoch: [42] [1126400/1281167 (88%)]	Loss: 1.278314
[2022-06-08 23:55:39 | train] - Train Epoch: [42] [1139200/1281167 (89%)]	Loss: 1.307576
[2022-06-08 23:56:01 | train] - Train Epoch: [42] [1152000/1281167 (90%)]	Loss: 1.264202
[2022-06-08 23:56:21 | train] - Train Epoch: [42] [1164800/1281167 (91%)]	Loss: 1.124695
[2022-06-08 23:56:41 | train] - Train Epoch: [42] [1177600/1281167 (92%)]	Loss: 1.305951
[2022-06-08 23:57:02 | train] - Train Epoch: [42] [1190400/1281167 (93%)]	Loss: 1.270020
[2022-06-08 23:57:22 | train] - Train Epoch: [42] [1203200/1281167 (94%)]	Loss: 1.378885
[2022-06-08 23:57:43 | train] - Train Epoch: [42] [1216000/1281167 (95%)]	Loss: 1.108874
[2022-06-08 23:58:03 | train] - Train Epoch: [42] [1228800/1281167 (96%)]	Loss: 1.125607
[2022-06-08 23:58:24 | train] - Train Epoch: [42] [1241600/1281167 (97%)]	Loss: 1.223276
[2022-06-08 23:58:45 | train] - Train Epoch: [42] [1254400/1281167 (98%)]	Loss: 1.238942
[2022-06-08 23:59:06 | train] - Train Epoch: [42] [1267200/1281167 (99%)]	Loss: 1.229156
[2022-06-08 23:59:27 | train] - Train Epoch: [42] [1280000/1281167 (100%)]	Loss: 1.038235
[2022-06-08 23:59:29 | train] - Train Epoch: [42]	 Average Loss: 1.316610	 Total Acc : 68.4961	 Total Top5 Acc : 87.0613
[2022-06-08 23:59:29 | train] - -------42 epoch end-----------
========================================
-------42 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 00:00:59 | train] - 
Epoch [42] Test set: Average loss: 1.3596, Accuracy: 33809/50000 (67.5795%), Top-5 Accuracy: 87.8988%

[2022-06-09 00:00:59 | train] - save intermediate epoch [42] result


[2022-06-09 00:01:09 | train] - logging best performance 42 epoch
[2022-06-09 00:01:11 | train] - -------43 epoch start-----------
========================================
----- test end -------------------------


logging best performance 42 epoch
[2022-06-09 00:01:12 | train] - Train Epoch: [43] [0/1281167 (0%)]	Loss: 1.401341
[2022-06-09 00:01:34 | train] - Train Epoch: [43] [12800/1281167 (1%)]	Loss: 1.277827
[2022-06-09 00:01:54 | train] - Train Epoch: [43] [25600/1281167 (2%)]	Loss: 1.050489
[2022-06-09 00:02:15 | train] - Train Epoch: [43] [38400/1281167 (3%)]	Loss: 1.419777
[2022-06-09 00:02:36 | train] - Train Epoch: [43] [51200/1281167 (4%)]	Loss: 0.953845
[2022-06-09 00:02:57 | train] - Train Epoch: [43] [64000/1281167 (5%)]	Loss: 1.195342
[2022-06-09 00:03:18 | train] - Train Epoch: [43] [76800/1281167 (6%)]	Loss: 1.443061
[2022-06-09 00:03:39 | train] - Train Epoch: [43] [89600/1281167 (7%)]	Loss: 1.058053
[2022-06-09 00:03:59 | train] - Train Epoch: [43] [102400/1281167 (8%)]	Loss: 1.253897
[2022-06-09 00:04:20 | train] - Train Epoch: [43] [115200/1281167 (9%)]	Loss: 0.838335
[2022-06-09 00:04:41 | train] - Train Epoch: [43] [128000/1281167 (10%)]	Loss: 1.129796
[2022-06-09 00:05:03 | train] - Train Epoch: [43] [140800/1281167 (11%)]	Loss: 1.300257
[2022-06-09 00:05:24 | train] - Train Epoch: [43] [153600/1281167 (12%)]	Loss: 1.273368
[2022-06-09 00:05:44 | train] - Train Epoch: [43] [166400/1281167 (13%)]	Loss: 1.318645
[2022-06-09 00:06:04 | train] - Train Epoch: [43] [179200/1281167 (14%)]	Loss: 1.243040
[2022-06-09 00:06:25 | train] - Train Epoch: [43] [192000/1281167 (15%)]	Loss: 1.177085
[2022-06-09 00:06:45 | train] - Train Epoch: [43] [204800/1281167 (16%)]	Loss: 1.497893
[2022-06-09 00:07:06 | train] - Train Epoch: [43] [217600/1281167 (17%)]	Loss: 1.614006
[2022-06-09 00:07:27 | train] - Train Epoch: [43] [230400/1281167 (18%)]	Loss: 1.195865
[2022-06-09 00:07:47 | train] - Train Epoch: [43] [243200/1281167 (19%)]	Loss: 1.281442
[2022-06-09 00:08:07 | train] - Train Epoch: [43] [256000/1281167 (20%)]	Loss: 1.559165
[2022-06-09 00:08:27 | train] - Train Epoch: [43] [268800/1281167 (21%)]	Loss: 1.269001
[2022-06-09 00:08:47 | train] - Train Epoch: [43] [281600/1281167 (22%)]	Loss: 1.150367
[2022-06-09 00:09:09 | train] - Train Epoch: [43] [294400/1281167 (23%)]	Loss: 1.128357
[2022-06-09 00:09:29 | train] - Train Epoch: [43] [307200/1281167 (24%)]	Loss: 1.387296
[2022-06-09 00:09:49 | train] - Train Epoch: [43] [320000/1281167 (25%)]	Loss: 1.139807
[2022-06-09 00:10:09 | train] - Train Epoch: [43] [332800/1281167 (26%)]	Loss: 1.422293
[2022-06-09 00:10:30 | train] - Train Epoch: [43] [345600/1281167 (27%)]	Loss: 1.223029
[2022-06-09 00:10:51 | train] - Train Epoch: [43] [358400/1281167 (28%)]	Loss: 1.322171
[2022-06-09 00:11:11 | train] - Train Epoch: [43] [371200/1281167 (29%)]	Loss: 1.163186
[2022-06-09 00:11:32 | train] - Train Epoch: [43] [384000/1281167 (30%)]	Loss: 1.240773
[2022-06-09 00:11:53 | train] - Train Epoch: [43] [396800/1281167 (31%)]	Loss: 1.450274
[2022-06-09 00:12:13 | train] - Train Epoch: [43] [409600/1281167 (32%)]	Loss: 1.098198
[2022-06-09 00:12:33 | train] - Train Epoch: [43] [422400/1281167 (33%)]	Loss: 1.322296
[2022-06-09 00:12:53 | train] - Train Epoch: [43] [435200/1281167 (34%)]	Loss: 1.257243
[2022-06-09 00:13:14 | train] - Train Epoch: [43] [448000/1281167 (35%)]	Loss: 1.132426
[2022-06-09 00:13:35 | train] - Train Epoch: [43] [460800/1281167 (36%)]	Loss: 1.532994
[2022-06-09 00:13:55 | train] - Train Epoch: [43] [473600/1281167 (37%)]	Loss: 1.150927
[2022-06-09 00:14:16 | train] - Train Epoch: [43] [486400/1281167 (38%)]	Loss: 1.496098
[2022-06-09 00:14:36 | train] - Train Epoch: [43] [499200/1281167 (39%)]	Loss: 1.308981
[2022-06-09 00:14:57 | train] - Train Epoch: [43] [512000/1281167 (40%)]	Loss: 1.089028
[2022-06-09 00:15:18 | train] - Train Epoch: [43] [524800/1281167 (41%)]	Loss: 1.277428
[2022-06-09 00:15:38 | train] - Train Epoch: [43] [537600/1281167 (42%)]	Loss: 1.424478
[2022-06-09 00:15:59 | train] - Train Epoch: [43] [550400/1281167 (43%)]	Loss: 0.924576
[2022-06-09 00:16:19 | train] - Train Epoch: [43] [563200/1281167 (44%)]	Loss: 1.306863
[2022-06-09 00:16:40 | train] - Train Epoch: [43] [576000/1281167 (45%)]	Loss: 1.153331
[2022-06-09 00:17:00 | train] - Train Epoch: [43] [588800/1281167 (46%)]	Loss: 1.306776
[2022-06-09 00:17:20 | train] - Train Epoch: [43] [601600/1281167 (47%)]	Loss: 1.059357
[2022-06-09 00:17:41 | train] - Train Epoch: [43] [614400/1281167 (48%)]	Loss: 1.412022
[2022-06-09 00:18:02 | train] - Train Epoch: [43] [627200/1281167 (49%)]	Loss: 1.310853
[2022-06-09 00:18:23 | train] - Train Epoch: [43] [640000/1281167 (50%)]	Loss: 1.505741
[2022-06-09 00:18:43 | train] - Train Epoch: [43] [652800/1281167 (51%)]	Loss: 1.186399
[2022-06-09 00:19:03 | train] - Train Epoch: [43] [665600/1281167 (52%)]	Loss: 1.281173
[2022-06-09 00:19:24 | train] - Train Epoch: [43] [678400/1281167 (53%)]	Loss: 1.697599
[2022-06-09 00:19:44 | train] - Train Epoch: [43] [691200/1281167 (54%)]	Loss: 1.360742
[2022-06-09 00:20:05 | train] - Train Epoch: [43] [704000/1281167 (55%)]	Loss: 1.341895
[2022-06-09 00:20:25 | train] - Train Epoch: [43] [716800/1281167 (56%)]	Loss: 1.045681
[2022-06-09 00:20:46 | train] - Train Epoch: [43] [729600/1281167 (57%)]	Loss: 1.292547
[2022-06-09 00:21:06 | train] - Train Epoch: [43] [742400/1281167 (58%)]	Loss: 1.395436
[2022-06-09 00:21:27 | train] - Train Epoch: [43] [755200/1281167 (59%)]	Loss: 1.476849
[2022-06-09 00:21:48 | train] - Train Epoch: [43] [768000/1281167 (60%)]	Loss: 1.335764
[2022-06-09 00:22:08 | train] - Train Epoch: [43] [780800/1281167 (61%)]	Loss: 1.162606
[2022-06-09 00:22:29 | train] - Train Epoch: [43] [793600/1281167 (62%)]	Loss: 1.126809
[2022-06-09 00:22:50 | train] - Train Epoch: [43] [806400/1281167 (63%)]	Loss: 1.407424
[2022-06-09 00:23:11 | train] - Train Epoch: [43] [819200/1281167 (64%)]	Loss: 1.200836
[2022-06-09 00:23:32 | train] - Train Epoch: [43] [832000/1281167 (65%)]	Loss: 1.278240
[2022-06-09 00:23:52 | train] - Train Epoch: [43] [844800/1281167 (66%)]	Loss: 1.249464
[2022-06-09 00:24:13 | train] - Train Epoch: [43] [857600/1281167 (67%)]	Loss: 1.125292
[2022-06-09 00:24:33 | train] - Train Epoch: [43] [870400/1281167 (68%)]	Loss: 1.473677
[2022-06-09 00:24:54 | train] - Train Epoch: [43] [883200/1281167 (69%)]	Loss: 1.462312
[2022-06-09 00:25:14 | train] - Train Epoch: [43] [896000/1281167 (70%)]	Loss: 1.372366
[2022-06-09 00:25:35 | train] - Train Epoch: [43] [908800/1281167 (71%)]	Loss: 1.480235
[2022-06-09 00:25:55 | train] - Train Epoch: [43] [921600/1281167 (72%)]	Loss: 1.300753
[2022-06-09 00:26:16 | train] - Train Epoch: [43] [934400/1281167 (73%)]	Loss: 1.541336
[2022-06-09 00:26:36 | train] - Train Epoch: [43] [947200/1281167 (74%)]	Loss: 1.362191
[2022-06-09 00:26:56 | train] - Train Epoch: [43] [960000/1281167 (75%)]	Loss: 1.597643
[2022-06-09 00:27:16 | train] - Train Epoch: [43] [972800/1281167 (76%)]	Loss: 1.324750
[2022-06-09 00:27:37 | train] - Train Epoch: [43] [985600/1281167 (77%)]	Loss: 1.139223
[2022-06-09 00:27:58 | train] - Train Epoch: [43] [998400/1281167 (78%)]	Loss: 1.274967
[2022-06-09 00:28:18 | train] - Train Epoch: [43] [1011200/1281167 (79%)]	Loss: 1.251965
[2022-06-09 00:28:39 | train] - Train Epoch: [43] [1024000/1281167 (80%)]	Loss: 1.089497
[2022-06-09 00:29:01 | train] - Train Epoch: [43] [1036800/1281167 (81%)]	Loss: 1.144048
[2022-06-09 00:29:21 | train] - Train Epoch: [43] [1049600/1281167 (82%)]	Loss: 1.604910
[2022-06-09 00:29:42 | train] - Train Epoch: [43] [1062400/1281167 (83%)]	Loss: 1.117437
[2022-06-09 00:30:03 | train] - Train Epoch: [43] [1075200/1281167 (84%)]	Loss: 1.092444
[2022-06-09 00:30:23 | train] - Train Epoch: [43] [1088000/1281167 (85%)]	Loss: 1.582702
[2022-06-09 00:30:42 | train] - Train Epoch: [43] [1100800/1281167 (86%)]	Loss: 1.304114
[2022-06-09 00:31:02 | train] - Train Epoch: [43] [1113600/1281167 (87%)]	Loss: 1.295932
[2022-06-09 00:31:22 | train] - Train Epoch: [43] [1126400/1281167 (88%)]	Loss: 1.472189
[2022-06-09 00:31:42 | train] - Train Epoch: [43] [1139200/1281167 (89%)]	Loss: 1.530919
[2022-06-09 00:32:04 | train] - Train Epoch: [43] [1152000/1281167 (90%)]	Loss: 1.349752
[2022-06-09 00:32:25 | train] - Train Epoch: [43] [1164800/1281167 (91%)]	Loss: 1.382247
[2022-06-09 00:32:46 | train] - Train Epoch: [43] [1177600/1281167 (92%)]	Loss: 1.438100
[2022-06-09 00:33:06 | train] - Train Epoch: [43] [1190400/1281167 (93%)]	Loss: 1.328468
[2022-06-09 00:33:27 | train] - Train Epoch: [43] [1203200/1281167 (94%)]	Loss: 1.053270
[2022-06-09 00:33:49 | train] - Train Epoch: [43] [1216000/1281167 (95%)]	Loss: 1.291297
[2022-06-09 00:34:09 | train] - Train Epoch: [43] [1228800/1281167 (96%)]	Loss: 1.543436
[2022-06-09 00:34:30 | train] - Train Epoch: [43] [1241600/1281167 (97%)]	Loss: 1.434711
[2022-06-09 00:34:51 | train] - Train Epoch: [43] [1254400/1281167 (98%)]	Loss: 1.447171
[2022-06-09 00:35:11 | train] - Train Epoch: [43] [1267200/1281167 (99%)]	Loss: 1.417181
[2022-06-09 00:35:33 | train] - Train Epoch: [43] [1280000/1281167 (100%)]	Loss: 1.119524
[2022-06-09 00:35:34 | train] - Train Epoch: [43]	 Average Loss: 1.304924	 Total Acc : 68.7457	 Total Top5 Acc : 87.1895
[2022-06-09 00:35:34 | train] - -------43 epoch end-----------
========================================
-------43 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 00:37:04 | train] - 
Epoch [43] Test set: Average loss: 1.3926, Accuracy: 33650/50000 (67.2714%), Top-5 Accuracy: 87.6630%

[2022-06-09 00:37:04 | train] - save intermediate epoch [43] result


[2022-06-09 00:37:15 | train] - -------44 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 00:37:17 | train] - Train Epoch: [44] [0/1281167 (0%)]	Loss: 1.191958
[2022-06-09 00:37:38 | train] - Train Epoch: [44] [12800/1281167 (1%)]	Loss: 1.081025
[2022-06-09 00:37:59 | train] - Train Epoch: [44] [25600/1281167 (2%)]	Loss: 1.183572
[2022-06-09 00:38:19 | train] - Train Epoch: [44] [38400/1281167 (3%)]	Loss: 1.161488
[2022-06-09 00:38:40 | train] - Train Epoch: [44] [51200/1281167 (4%)]	Loss: 1.116218
[2022-06-09 00:39:00 | train] - Train Epoch: [44] [64000/1281167 (5%)]	Loss: 1.117278
[2022-06-09 00:39:21 | train] - Train Epoch: [44] [76800/1281167 (6%)]	Loss: 1.276316
[2022-06-09 00:39:41 | train] - Train Epoch: [44] [89600/1281167 (7%)]	Loss: 1.308197
[2022-06-09 00:40:01 | train] - Train Epoch: [44] [102400/1281167 (8%)]	Loss: 0.936184
[2022-06-09 00:40:22 | train] - Train Epoch: [44] [115200/1281167 (9%)]	Loss: 1.571357
[2022-06-09 00:40:42 | train] - Train Epoch: [44] [128000/1281167 (10%)]	Loss: 1.185001
[2022-06-09 00:41:02 | train] - Train Epoch: [44] [140800/1281167 (11%)]	Loss: 1.090961
[2022-06-09 00:41:22 | train] - Train Epoch: [44] [153600/1281167 (12%)]	Loss: 1.263381
[2022-06-09 00:41:43 | train] - Train Epoch: [44] [166400/1281167 (13%)]	Loss: 1.219381
[2022-06-09 00:42:04 | train] - Train Epoch: [44] [179200/1281167 (14%)]	Loss: 1.046386
[2022-06-09 00:42:25 | train] - Train Epoch: [44] [192000/1281167 (15%)]	Loss: 1.236137
[2022-06-09 00:42:45 | train] - Train Epoch: [44] [204800/1281167 (16%)]	Loss: 1.219185
[2022-06-09 00:43:07 | train] - Train Epoch: [44] [217600/1281167 (17%)]	Loss: 1.305368
[2022-06-09 00:43:27 | train] - Train Epoch: [44] [230400/1281167 (18%)]	Loss: 1.085976
[2022-06-09 00:43:47 | train] - Train Epoch: [44] [243200/1281167 (19%)]	Loss: 1.229156
[2022-06-09 00:44:06 | train] - Train Epoch: [44] [256000/1281167 (20%)]	Loss: 1.260960
[2022-06-09 00:44:28 | train] - Train Epoch: [44] [268800/1281167 (21%)]	Loss: 1.017782
[2022-06-09 00:44:47 | train] - Train Epoch: [44] [281600/1281167 (22%)]	Loss: 1.652913
[2022-06-09 00:45:08 | train] - Train Epoch: [44] [294400/1281167 (23%)]	Loss: 1.309450
[2022-06-09 00:45:29 | train] - Train Epoch: [44] [307200/1281167 (24%)]	Loss: 1.579621
[2022-06-09 00:45:49 | train] - Train Epoch: [44] [320000/1281167 (25%)]	Loss: 1.420259
[2022-06-09 00:46:09 | train] - Train Epoch: [44] [332800/1281167 (26%)]	Loss: 1.718513
[2022-06-09 00:46:30 | train] - Train Epoch: [44] [345600/1281167 (27%)]	Loss: 1.136815
[2022-06-09 00:46:50 | train] - Train Epoch: [44] [358400/1281167 (28%)]	Loss: 1.400738
[2022-06-09 00:47:10 | train] - Train Epoch: [44] [371200/1281167 (29%)]	Loss: 1.385547
[2022-06-09 00:47:31 | train] - Train Epoch: [44] [384000/1281167 (30%)]	Loss: 1.017739
[2022-06-09 00:47:51 | train] - Train Epoch: [44] [396800/1281167 (31%)]	Loss: 1.290650
[2022-06-09 00:48:12 | train] - Train Epoch: [44] [409600/1281167 (32%)]	Loss: 1.474357
[2022-06-09 00:48:32 | train] - Train Epoch: [44] [422400/1281167 (33%)]	Loss: 1.138381
[2022-06-09 00:48:52 | train] - Train Epoch: [44] [435200/1281167 (34%)]	Loss: 0.924425
[2022-06-09 00:49:13 | train] - Train Epoch: [44] [448000/1281167 (35%)]	Loss: 1.251289
[2022-06-09 00:49:33 | train] - Train Epoch: [44] [460800/1281167 (36%)]	Loss: 1.277700
[2022-06-09 00:49:52 | train] - Train Epoch: [44] [473600/1281167 (37%)]	Loss: 1.103307
[2022-06-09 00:50:13 | train] - Train Epoch: [44] [486400/1281167 (38%)]	Loss: 1.500255
[2022-06-09 00:50:33 | train] - Train Epoch: [44] [499200/1281167 (39%)]	Loss: 1.332983
[2022-06-09 00:50:53 | train] - Train Epoch: [44] [512000/1281167 (40%)]	Loss: 1.214531
[2022-06-09 00:51:13 | train] - Train Epoch: [44] [524800/1281167 (41%)]	Loss: 1.121631
[2022-06-09 00:51:34 | train] - Train Epoch: [44] [537600/1281167 (42%)]	Loss: 1.428919
[2022-06-09 00:51:55 | train] - Train Epoch: [44] [550400/1281167 (43%)]	Loss: 1.366740
[2022-06-09 00:52:15 | train] - Train Epoch: [44] [563200/1281167 (44%)]	Loss: 1.739946
[2022-06-09 00:52:36 | train] - Train Epoch: [44] [576000/1281167 (45%)]	Loss: 1.402250
[2022-06-09 00:52:57 | train] - Train Epoch: [44] [588800/1281167 (46%)]	Loss: 1.166797
[2022-06-09 00:53:17 | train] - Train Epoch: [44] [601600/1281167 (47%)]	Loss: 1.344521
[2022-06-09 00:53:37 | train] - Train Epoch: [44] [614400/1281167 (48%)]	Loss: 1.400208
[2022-06-09 00:53:57 | train] - Train Epoch: [44] [627200/1281167 (49%)]	Loss: 1.254389
[2022-06-09 00:54:17 | train] - Train Epoch: [44] [640000/1281167 (50%)]	Loss: 1.222640
[2022-06-09 00:54:38 | train] - Train Epoch: [44] [652800/1281167 (51%)]	Loss: 1.584737
[2022-06-09 00:54:58 | train] - Train Epoch: [44] [665600/1281167 (52%)]	Loss: 1.306934
[2022-06-09 00:55:20 | train] - Train Epoch: [44] [678400/1281167 (53%)]	Loss: 1.323187
[2022-06-09 00:55:39 | train] - Train Epoch: [44] [691200/1281167 (54%)]	Loss: 1.490842
[2022-06-09 00:55:59 | train] - Train Epoch: [44] [704000/1281167 (55%)]	Loss: 1.093337
[2022-06-09 00:56:19 | train] - Train Epoch: [44] [716800/1281167 (56%)]	Loss: 1.258080
[2022-06-09 00:56:39 | train] - Train Epoch: [44] [729600/1281167 (57%)]	Loss: 1.160171
[2022-06-09 00:57:00 | train] - Train Epoch: [44] [742400/1281167 (58%)]	Loss: 1.600191
[2022-06-09 00:57:20 | train] - Train Epoch: [44] [755200/1281167 (59%)]	Loss: 1.610219
[2022-06-09 00:57:41 | train] - Train Epoch: [44] [768000/1281167 (60%)]	Loss: 1.260794
[2022-06-09 00:58:00 | train] - Train Epoch: [44] [780800/1281167 (61%)]	Loss: 1.301888
[2022-06-09 00:58:21 | train] - Train Epoch: [44] [793600/1281167 (62%)]	Loss: 1.509567
[2022-06-09 00:58:41 | train] - Train Epoch: [44] [806400/1281167 (63%)]	Loss: 1.598036
[2022-06-09 00:59:01 | train] - Train Epoch: [44] [819200/1281167 (64%)]	Loss: 1.314670
[2022-06-09 00:59:21 | train] - Train Epoch: [44] [832000/1281167 (65%)]	Loss: 1.157946
[2022-06-09 00:59:41 | train] - Train Epoch: [44] [844800/1281167 (66%)]	Loss: 1.423121
[2022-06-09 01:00:02 | train] - Train Epoch: [44] [857600/1281167 (67%)]	Loss: 1.290577
[2022-06-09 01:00:23 | train] - Train Epoch: [44] [870400/1281167 (68%)]	Loss: 1.299942
[2022-06-09 01:00:43 | train] - Train Epoch: [44] [883200/1281167 (69%)]	Loss: 1.229960
[2022-06-09 01:01:04 | train] - Train Epoch: [44] [896000/1281167 (70%)]	Loss: 1.312471
[2022-06-09 01:01:24 | train] - Train Epoch: [44] [908800/1281167 (71%)]	Loss: 1.359212
[2022-06-09 01:01:45 | train] - Train Epoch: [44] [921600/1281167 (72%)]	Loss: 1.317393
[2022-06-09 01:02:05 | train] - Train Epoch: [44] [934400/1281167 (73%)]	Loss: 1.164991
[2022-06-09 01:02:26 | train] - Train Epoch: [44] [947200/1281167 (74%)]	Loss: 1.023007
[2022-06-09 01:02:47 | train] - Train Epoch: [44] [960000/1281167 (75%)]	Loss: 1.184953
[2022-06-09 01:03:07 | train] - Train Epoch: [44] [972800/1281167 (76%)]	Loss: 1.286378
[2022-06-09 01:03:27 | train] - Train Epoch: [44] [985600/1281167 (77%)]	Loss: 1.474778
[2022-06-09 01:03:47 | train] - Train Epoch: [44] [998400/1281167 (78%)]	Loss: 1.227664
[2022-06-09 01:04:08 | train] - Train Epoch: [44] [1011200/1281167 (79%)]	Loss: 1.262246
[2022-06-09 01:04:28 | train] - Train Epoch: [44] [1024000/1281167 (80%)]	Loss: 1.303419
[2022-06-09 01:04:49 | train] - Train Epoch: [44] [1036800/1281167 (81%)]	Loss: 1.057059
[2022-06-09 01:05:09 | train] - Train Epoch: [44] [1049600/1281167 (82%)]	Loss: 1.605484
[2022-06-09 01:05:30 | train] - Train Epoch: [44] [1062400/1281167 (83%)]	Loss: 1.225411
[2022-06-09 01:05:51 | train] - Train Epoch: [44] [1075200/1281167 (84%)]	Loss: 1.438058
[2022-06-09 01:06:11 | train] - Train Epoch: [44] [1088000/1281167 (85%)]	Loss: 1.360070
[2022-06-09 01:06:31 | train] - Train Epoch: [44] [1100800/1281167 (86%)]	Loss: 1.387975
[2022-06-09 01:06:51 | train] - Train Epoch: [44] [1113600/1281167 (87%)]	Loss: 1.375989
[2022-06-09 01:07:12 | train] - Train Epoch: [44] [1126400/1281167 (88%)]	Loss: 1.452660
[2022-06-09 01:07:32 | train] - Train Epoch: [44] [1139200/1281167 (89%)]	Loss: 1.412692
[2022-06-09 01:07:53 | train] - Train Epoch: [44] [1152000/1281167 (90%)]	Loss: 1.292184
[2022-06-09 01:08:13 | train] - Train Epoch: [44] [1164800/1281167 (91%)]	Loss: 1.585354
[2022-06-09 01:08:34 | train] - Train Epoch: [44] [1177600/1281167 (92%)]	Loss: 0.974755
[2022-06-09 01:08:55 | train] - Train Epoch: [44] [1190400/1281167 (93%)]	Loss: 1.332319
[2022-06-09 01:09:15 | train] - Train Epoch: [44] [1203200/1281167 (94%)]	Loss: 1.070143
[2022-06-09 01:09:35 | train] - Train Epoch: [44] [1216000/1281167 (95%)]	Loss: 1.258438
[2022-06-09 01:09:55 | train] - Train Epoch: [44] [1228800/1281167 (96%)]	Loss: 1.169139
[2022-06-09 01:10:16 | train] - Train Epoch: [44] [1241600/1281167 (97%)]	Loss: 1.599488
[2022-06-09 01:10:36 | train] - Train Epoch: [44] [1254400/1281167 (98%)]	Loss: 1.370541
[2022-06-09 01:10:56 | train] - Train Epoch: [44] [1267200/1281167 (99%)]	Loss: 1.214584
[2022-06-09 01:11:17 | train] - Train Epoch: [44] [1280000/1281167 (100%)]	Loss: 1.170965
[2022-06-09 01:11:19 | train] - Train Epoch: [44]	 Average Loss: 1.293539	 Total Acc : 69.0096	 Total Top5 Acc : 87.3516
[2022-06-09 01:11:19 | train] - -------44 epoch end-----------
========================================
-------44 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 01:12:51 | train] - 
Epoch [44] Test set: Average loss: 1.3655, Accuracy: 33909/50000 (67.7817%), Top-5 Accuracy: 88.0639%

[2022-06-09 01:12:51 | train] - save intermediate epoch [44] result


[2022-06-09 01:13:03 | train] - logging best performance 44 epoch
[2022-06-09 01:13:04 | train] - -------45 epoch start-----------
========================================
----- test end -------------------------


logging best performance 44 epoch
[2022-06-09 01:13:06 | train] - Train Epoch: [45] [0/1281167 (0%)]	Loss: 1.006359
[2022-06-09 01:13:27 | train] - Train Epoch: [45] [12800/1281167 (1%)]	Loss: 1.374081
[2022-06-09 01:13:48 | train] - Train Epoch: [45] [25600/1281167 (2%)]	Loss: 1.374727
[2022-06-09 01:14:08 | train] - Train Epoch: [45] [38400/1281167 (3%)]	Loss: 1.257558
[2022-06-09 01:14:29 | train] - Train Epoch: [45] [51200/1281167 (4%)]	Loss: 1.283378
[2022-06-09 01:14:51 | train] - Train Epoch: [45] [64000/1281167 (5%)]	Loss: 0.977913
[2022-06-09 01:15:12 | train] - Train Epoch: [45] [76800/1281167 (6%)]	Loss: 1.132926
[2022-06-09 01:15:33 | train] - Train Epoch: [45] [89600/1281167 (7%)]	Loss: 1.079302
[2022-06-09 01:15:53 | train] - Train Epoch: [45] [102400/1281167 (8%)]	Loss: 1.153018
[2022-06-09 01:16:13 | train] - Train Epoch: [45] [115200/1281167 (9%)]	Loss: 1.316086
[2022-06-09 01:16:34 | train] - Train Epoch: [45] [128000/1281167 (10%)]	Loss: 0.979409
[2022-06-09 01:16:55 | train] - Train Epoch: [45] [140800/1281167 (11%)]	Loss: 1.223015
[2022-06-09 01:17:16 | train] - Train Epoch: [45] [153600/1281167 (12%)]	Loss: 1.251813
[2022-06-09 01:17:38 | train] - Train Epoch: [45] [166400/1281167 (13%)]	Loss: 1.479002
[2022-06-09 01:18:00 | train] - Train Epoch: [45] [179200/1281167 (14%)]	Loss: 1.101356
[2022-06-09 01:18:20 | train] - Train Epoch: [45] [192000/1281167 (15%)]	Loss: 1.259782
[2022-06-09 01:18:42 | train] - Train Epoch: [45] [204800/1281167 (16%)]	Loss: 1.271374
[2022-06-09 01:19:03 | train] - Train Epoch: [45] [217600/1281167 (17%)]	Loss: 1.340870
[2022-06-09 01:19:24 | train] - Train Epoch: [45] [230400/1281167 (18%)]	Loss: 1.093151
[2022-06-09 01:19:44 | train] - Train Epoch: [45] [243200/1281167 (19%)]	Loss: 1.692378
[2022-06-09 01:20:05 | train] - Train Epoch: [45] [256000/1281167 (20%)]	Loss: 1.030434
[2022-06-09 01:20:26 | train] - Train Epoch: [45] [268800/1281167 (21%)]	Loss: 1.374671
[2022-06-09 01:20:48 | train] - Train Epoch: [45] [281600/1281167 (22%)]	Loss: 1.299207
[2022-06-09 01:21:08 | train] - Train Epoch: [45] [294400/1281167 (23%)]	Loss: 1.227766
[2022-06-09 01:21:29 | train] - Train Epoch: [45] [307200/1281167 (24%)]	Loss: 1.149846
[2022-06-09 01:21:49 | train] - Train Epoch: [45] [320000/1281167 (25%)]	Loss: 1.386244
[2022-06-09 01:22:09 | train] - Train Epoch: [45] [332800/1281167 (26%)]	Loss: 1.045633
[2022-06-09 01:22:31 | train] - Train Epoch: [45] [345600/1281167 (27%)]	Loss: 1.064362
[2022-06-09 01:22:52 | train] - Train Epoch: [45] [358400/1281167 (28%)]	Loss: 1.235052
[2022-06-09 01:23:13 | train] - Train Epoch: [45] [371200/1281167 (29%)]	Loss: 1.173826
[2022-06-09 01:23:33 | train] - Train Epoch: [45] [384000/1281167 (30%)]	Loss: 1.135826
[2022-06-09 01:23:54 | train] - Train Epoch: [45] [396800/1281167 (31%)]	Loss: 1.142445
[2022-06-09 01:24:15 | train] - Train Epoch: [45] [409600/1281167 (32%)]	Loss: 1.182808
[2022-06-09 01:24:35 | train] - Train Epoch: [45] [422400/1281167 (33%)]	Loss: 1.128119
[2022-06-09 01:24:57 | train] - Train Epoch: [45] [435200/1281167 (34%)]	Loss: 1.265370
[2022-06-09 01:25:18 | train] - Train Epoch: [45] [448000/1281167 (35%)]	Loss: 1.351552
[2022-06-09 01:25:38 | train] - Train Epoch: [45] [460800/1281167 (36%)]	Loss: 1.205715
[2022-06-09 01:25:59 | train] - Train Epoch: [45] [473600/1281167 (37%)]	Loss: 1.424556
[2022-06-09 01:26:20 | train] - Train Epoch: [45] [486400/1281167 (38%)]	Loss: 0.863483
[2022-06-09 01:26:41 | train] - Train Epoch: [45] [499200/1281167 (39%)]	Loss: 1.457985
[2022-06-09 01:27:02 | train] - Train Epoch: [45] [512000/1281167 (40%)]	Loss: 1.155401
[2022-06-09 01:27:22 | train] - Train Epoch: [45] [524800/1281167 (41%)]	Loss: 1.180681
[2022-06-09 01:27:44 | train] - Train Epoch: [45] [537600/1281167 (42%)]	Loss: 0.923026
[2022-06-09 01:28:05 | train] - Train Epoch: [45] [550400/1281167 (43%)]	Loss: 1.248544
[2022-06-09 01:28:26 | train] - Train Epoch: [45] [563200/1281167 (44%)]	Loss: 1.211553
[2022-06-09 01:28:47 | train] - Train Epoch: [45] [576000/1281167 (45%)]	Loss: 1.133463
[2022-06-09 01:29:09 | train] - Train Epoch: [45] [588800/1281167 (46%)]	Loss: 1.171013
[2022-06-09 01:29:30 | train] - Train Epoch: [45] [601600/1281167 (47%)]	Loss: 1.293202
[2022-06-09 01:29:50 | train] - Train Epoch: [45] [614400/1281167 (48%)]	Loss: 1.396129
[2022-06-09 01:30:11 | train] - Train Epoch: [45] [627200/1281167 (49%)]	Loss: 1.203361
[2022-06-09 01:30:32 | train] - Train Epoch: [45] [640000/1281167 (50%)]	Loss: 1.267511
[2022-06-09 01:30:53 | train] - Train Epoch: [45] [652800/1281167 (51%)]	Loss: 1.554163
[2022-06-09 01:31:14 | train] - Train Epoch: [45] [665600/1281167 (52%)]	Loss: 1.057811
[2022-06-09 01:31:36 | train] - Train Epoch: [45] [678400/1281167 (53%)]	Loss: 1.281648
[2022-06-09 01:31:57 | train] - Train Epoch: [45] [691200/1281167 (54%)]	Loss: 1.505930
[2022-06-09 01:32:18 | train] - Train Epoch: [45] [704000/1281167 (55%)]	Loss: 1.230052
[2022-06-09 01:32:39 | train] - Train Epoch: [45] [716800/1281167 (56%)]	Loss: 1.330110
[2022-06-09 01:33:00 | train] - Train Epoch: [45] [729600/1281167 (57%)]	Loss: 1.538834
[2022-06-09 01:33:22 | train] - Train Epoch: [45] [742400/1281167 (58%)]	Loss: 1.282881
[2022-06-09 01:33:43 | train] - Train Epoch: [45] [755200/1281167 (59%)]	Loss: 1.479384
[2022-06-09 01:34:04 | train] - Train Epoch: [45] [768000/1281167 (60%)]	Loss: 1.002194
[2022-06-09 01:34:26 | train] - Train Epoch: [45] [780800/1281167 (61%)]	Loss: 1.117250
[2022-06-09 01:34:47 | train] - Train Epoch: [45] [793600/1281167 (62%)]	Loss: 1.333635
[2022-06-09 01:35:08 | train] - Train Epoch: [45] [806400/1281167 (63%)]	Loss: 1.415336
[2022-06-09 01:35:30 | train] - Train Epoch: [45] [819200/1281167 (64%)]	Loss: 1.493619
[2022-06-09 01:35:50 | train] - Train Epoch: [45] [832000/1281167 (65%)]	Loss: 1.281484
[2022-06-09 01:36:10 | train] - Train Epoch: [45] [844800/1281167 (66%)]	Loss: 1.560963
[2022-06-09 01:36:31 | train] - Train Epoch: [45] [857600/1281167 (67%)]	Loss: 1.300428
[2022-06-09 01:36:52 | train] - Train Epoch: [45] [870400/1281167 (68%)]	Loss: 1.307372
[2022-06-09 01:37:13 | train] - Train Epoch: [45] [883200/1281167 (69%)]	Loss: 1.556559
[2022-06-09 01:37:34 | train] - Train Epoch: [45] [896000/1281167 (70%)]	Loss: 1.311795
[2022-06-09 01:37:55 | train] - Train Epoch: [45] [908800/1281167 (71%)]	Loss: 1.120184
[2022-06-09 01:38:16 | train] - Train Epoch: [45] [921600/1281167 (72%)]	Loss: 1.152221
[2022-06-09 01:38:36 | train] - Train Epoch: [45] [934400/1281167 (73%)]	Loss: 1.122613
[2022-06-09 01:38:57 | train] - Train Epoch: [45] [947200/1281167 (74%)]	Loss: 1.294112
[2022-06-09 01:39:17 | train] - Train Epoch: [45] [960000/1281167 (75%)]	Loss: 1.339415
[2022-06-09 01:39:38 | train] - Train Epoch: [45] [972800/1281167 (76%)]	Loss: 1.207678
[2022-06-09 01:39:59 | train] - Train Epoch: [45] [985600/1281167 (77%)]	Loss: 1.253559
[2022-06-09 01:40:20 | train] - Train Epoch: [45] [998400/1281167 (78%)]	Loss: 0.944952
[2022-06-09 01:40:42 | train] - Train Epoch: [45] [1011200/1281167 (79%)]	Loss: 1.387995
[2022-06-09 01:41:03 | train] - Train Epoch: [45] [1024000/1281167 (80%)]	Loss: 1.390090
[2022-06-09 01:41:24 | train] - Train Epoch: [45] [1036800/1281167 (81%)]	Loss: 1.202062
[2022-06-09 01:41:45 | train] - Train Epoch: [45] [1049600/1281167 (82%)]	Loss: 1.102866
[2022-06-09 01:42:07 | train] - Train Epoch: [45] [1062400/1281167 (83%)]	Loss: 1.378587
[2022-06-09 01:42:29 | train] - Train Epoch: [45] [1075200/1281167 (84%)]	Loss: 1.059143
[2022-06-09 01:42:49 | train] - Train Epoch: [45] [1088000/1281167 (85%)]	Loss: 1.055305
[2022-06-09 01:43:09 | train] - Train Epoch: [45] [1100800/1281167 (86%)]	Loss: 1.311748
[2022-06-09 01:43:29 | train] - Train Epoch: [45] [1113600/1281167 (87%)]	Loss: 1.347562
[2022-06-09 01:43:50 | train] - Train Epoch: [45] [1126400/1281167 (88%)]	Loss: 1.295380
[2022-06-09 01:44:11 | train] - Train Epoch: [45] [1139200/1281167 (89%)]	Loss: 1.400698
[2022-06-09 01:44:31 | train] - Train Epoch: [45] [1152000/1281167 (90%)]	Loss: 1.446612
[2022-06-09 01:44:53 | train] - Train Epoch: [45] [1164800/1281167 (91%)]	Loss: 1.513888
[2022-06-09 01:45:14 | train] - Train Epoch: [45] [1177600/1281167 (92%)]	Loss: 1.456800
[2022-06-09 01:45:34 | train] - Train Epoch: [45] [1190400/1281167 (93%)]	Loss: 1.267707
[2022-06-09 01:45:55 | train] - Train Epoch: [45] [1203200/1281167 (94%)]	Loss: 1.155249
[2022-06-09 01:46:16 | train] - Train Epoch: [45] [1216000/1281167 (95%)]	Loss: 1.343640
[2022-06-09 01:46:36 | train] - Train Epoch: [45] [1228800/1281167 (96%)]	Loss: 1.231910
[2022-06-09 01:46:58 | train] - Train Epoch: [45] [1241600/1281167 (97%)]	Loss: 1.461966
[2022-06-09 01:47:19 | train] - Train Epoch: [45] [1254400/1281167 (98%)]	Loss: 1.161074
[2022-06-09 01:47:40 | train] - Train Epoch: [45] [1267200/1281167 (99%)]	Loss: 1.369891
[2022-06-09 01:48:00 | train] - Train Epoch: [45] [1280000/1281167 (100%)]	Loss: 1.303695
[2022-06-09 01:48:02 | train] - Train Epoch: [45]	 Average Loss: 1.282538	 Total Acc : 69.2289	 Total Top5 Acc : 87.4857
[2022-06-09 01:48:02 | train] - -------45 epoch end-----------
========================================
-------45 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 01:49:34 | train] - 
Epoch [45] Test set: Average loss: 1.3614, Accuracy: 33887/50000 (67.7498%), Top-5 Accuracy: 88.0415%

[2022-06-09 01:49:34 | train] - save intermediate epoch [45] result


[2022-06-09 01:49:49 | train] - -------46 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 01:49:50 | train] - Train Epoch: [46] [0/1281167 (0%)]	Loss: 1.149197
[2022-06-09 01:50:13 | train] - Train Epoch: [46] [12800/1281167 (1%)]	Loss: 0.918469
[2022-06-09 01:50:35 | train] - Train Epoch: [46] [25600/1281167 (2%)]	Loss: 1.476767
[2022-06-09 01:50:57 | train] - Train Epoch: [46] [38400/1281167 (3%)]	Loss: 1.061943
[2022-06-09 01:51:19 | train] - Train Epoch: [46] [51200/1281167 (4%)]	Loss: 1.099236
[2022-06-09 01:51:40 | train] - Train Epoch: [46] [64000/1281167 (5%)]	Loss: 1.064509
[2022-06-09 01:52:01 | train] - Train Epoch: [46] [76800/1281167 (6%)]	Loss: 1.202712
[2022-06-09 01:52:22 | train] - Train Epoch: [46] [89600/1281167 (7%)]	Loss: 1.275773
[2022-06-09 01:52:45 | train] - Train Epoch: [46] [102400/1281167 (8%)]	Loss: 1.051186
[2022-06-09 01:53:06 | train] - Train Epoch: [46] [115200/1281167 (9%)]	Loss: 1.086721
[2022-06-09 01:53:27 | train] - Train Epoch: [46] [128000/1281167 (10%)]	Loss: 1.281049
[2022-06-09 01:53:48 | train] - Train Epoch: [46] [140800/1281167 (11%)]	Loss: 1.181478
[2022-06-09 01:54:09 | train] - Train Epoch: [46] [153600/1281167 (12%)]	Loss: 1.298029
[2022-06-09 01:54:31 | train] - Train Epoch: [46] [166400/1281167 (13%)]	Loss: 1.279685
[2022-06-09 01:54:52 | train] - Train Epoch: [46] [179200/1281167 (14%)]	Loss: 1.027308
[2022-06-09 01:55:14 | train] - Train Epoch: [46] [192000/1281167 (15%)]	Loss: 1.631397
[2022-06-09 01:55:36 | train] - Train Epoch: [46] [204800/1281167 (16%)]	Loss: 1.070753
[2022-06-09 01:55:57 | train] - Train Epoch: [46] [217600/1281167 (17%)]	Loss: 1.419949
[2022-06-09 01:56:19 | train] - Train Epoch: [46] [230400/1281167 (18%)]	Loss: 1.087707
[2022-06-09 01:56:40 | train] - Train Epoch: [46] [243200/1281167 (19%)]	Loss: 1.369310
[2022-06-09 01:57:02 | train] - Train Epoch: [46] [256000/1281167 (20%)]	Loss: 1.144475
[2022-06-09 01:57:24 | train] - Train Epoch: [46] [268800/1281167 (21%)]	Loss: 1.485673
[2022-06-09 01:57:46 | train] - Train Epoch: [46] [281600/1281167 (22%)]	Loss: 1.121223
[2022-06-09 01:58:07 | train] - Train Epoch: [46] [294400/1281167 (23%)]	Loss: 1.125761
[2022-06-09 01:58:28 | train] - Train Epoch: [46] [307200/1281167 (24%)]	Loss: 1.176317
[2022-06-09 01:58:51 | train] - Train Epoch: [46] [320000/1281167 (25%)]	Loss: 1.160029
[2022-06-09 01:59:12 | train] - Train Epoch: [46] [332800/1281167 (26%)]	Loss: 1.440851
[2022-06-09 01:59:33 | train] - Train Epoch: [46] [345600/1281167 (27%)]	Loss: 1.004943
[2022-06-09 01:59:55 | train] - Train Epoch: [46] [358400/1281167 (28%)]	Loss: 1.509075
[2022-06-09 02:00:17 | train] - Train Epoch: [46] [371200/1281167 (29%)]	Loss: 1.186852
[2022-06-09 02:00:40 | train] - Train Epoch: [46] [384000/1281167 (30%)]	Loss: 1.302111
[2022-06-09 02:01:00 | train] - Train Epoch: [46] [396800/1281167 (31%)]	Loss: 0.992757
[2022-06-09 02:01:22 | train] - Train Epoch: [46] [409600/1281167 (32%)]	Loss: 1.312016
[2022-06-09 02:01:44 | train] - Train Epoch: [46] [422400/1281167 (33%)]	Loss: 1.453017
[2022-06-09 02:02:06 | train] - Train Epoch: [46] [435200/1281167 (34%)]	Loss: 1.240412
[2022-06-09 02:02:27 | train] - Train Epoch: [46] [448000/1281167 (35%)]	Loss: 1.218759
[2022-06-09 02:02:48 | train] - Train Epoch: [46] [460800/1281167 (36%)]	Loss: 1.400356
[2022-06-09 02:03:10 | train] - Train Epoch: [46] [473600/1281167 (37%)]	Loss: 1.325990
[2022-06-09 02:03:32 | train] - Train Epoch: [46] [486400/1281167 (38%)]	Loss: 1.318976
[2022-06-09 02:03:55 | train] - Train Epoch: [46] [499200/1281167 (39%)]	Loss: 1.561165
[2022-06-09 02:04:15 | train] - Train Epoch: [46] [512000/1281167 (40%)]	Loss: 1.380708
[2022-06-09 02:04:38 | train] - Train Epoch: [46] [524800/1281167 (41%)]	Loss: 1.059920
[2022-06-09 02:05:00 | train] - Train Epoch: [46] [537600/1281167 (42%)]	Loss: 1.245573
[2022-06-09 02:05:21 | train] - Train Epoch: [46] [550400/1281167 (43%)]	Loss: 1.394119
[2022-06-09 02:05:44 | train] - Train Epoch: [46] [563200/1281167 (44%)]	Loss: 1.490122
[2022-06-09 02:06:04 | train] - Train Epoch: [46] [576000/1281167 (45%)]	Loss: 1.172542
[2022-06-09 02:06:26 | train] - Train Epoch: [46] [588800/1281167 (46%)]	Loss: 1.285090
[2022-06-09 02:06:47 | train] - Train Epoch: [46] [601600/1281167 (47%)]	Loss: 1.512872
[2022-06-09 02:07:09 | train] - Train Epoch: [46] [614400/1281167 (48%)]	Loss: 1.425748
[2022-06-09 02:07:30 | train] - Train Epoch: [46] [627200/1281167 (49%)]	Loss: 1.495133
[2022-06-09 02:07:52 | train] - Train Epoch: [46] [640000/1281167 (50%)]	Loss: 1.416837
[2022-06-09 02:08:14 | train] - Train Epoch: [46] [652800/1281167 (51%)]	Loss: 1.051539
[2022-06-09 02:08:35 | train] - Train Epoch: [46] [665600/1281167 (52%)]	Loss: 1.155935
[2022-06-09 02:08:57 | train] - Train Epoch: [46] [678400/1281167 (53%)]	Loss: 1.266109
[2022-06-09 02:09:19 | train] - Train Epoch: [46] [691200/1281167 (54%)]	Loss: 1.120409
[2022-06-09 02:09:41 | train] - Train Epoch: [46] [704000/1281167 (55%)]	Loss: 1.230024
[2022-06-09 02:10:02 | train] - Train Epoch: [46] [716800/1281167 (56%)]	Loss: 1.075900
[2022-06-09 02:10:24 | train] - Train Epoch: [46] [729600/1281167 (57%)]	Loss: 1.534456
[2022-06-09 02:10:45 | train] - Train Epoch: [46] [742400/1281167 (58%)]	Loss: 1.340906
[2022-06-09 02:11:07 | train] - Train Epoch: [46] [755200/1281167 (59%)]	Loss: 1.457663
[2022-06-09 02:11:27 | train] - Train Epoch: [46] [768000/1281167 (60%)]	Loss: 1.129221
[2022-06-09 02:11:49 | train] - Train Epoch: [46] [780800/1281167 (61%)]	Loss: 1.329179
[2022-06-09 02:12:11 | train] - Train Epoch: [46] [793600/1281167 (62%)]	Loss: 1.641193
[2022-06-09 02:12:33 | train] - Train Epoch: [46] [806400/1281167 (63%)]	Loss: 1.213678
[2022-06-09 02:12:55 | train] - Train Epoch: [46] [819200/1281167 (64%)]	Loss: 1.299572
[2022-06-09 02:13:16 | train] - Train Epoch: [46] [832000/1281167 (65%)]	Loss: 1.168377
[2022-06-09 02:13:38 | train] - Train Epoch: [46] [844800/1281167 (66%)]	Loss: 1.120849
[2022-06-09 02:14:00 | train] - Train Epoch: [46] [857600/1281167 (67%)]	Loss: 1.270074
[2022-06-09 02:14:21 | train] - Train Epoch: [46] [870400/1281167 (68%)]	Loss: 1.275153
[2022-06-09 02:14:43 | train] - Train Epoch: [46] [883200/1281167 (69%)]	Loss: 1.236862
[2022-06-09 02:15:04 | train] - Train Epoch: [46] [896000/1281167 (70%)]	Loss: 1.501395
[2022-06-09 02:15:25 | train] - Train Epoch: [46] [908800/1281167 (71%)]	Loss: 1.460784
[2022-06-09 02:15:47 | train] - Train Epoch: [46] [921600/1281167 (72%)]	Loss: 1.131949
[2022-06-09 02:16:08 | train] - Train Epoch: [46] [934400/1281167 (73%)]	Loss: 1.358066
[2022-06-09 02:16:29 | train] - Train Epoch: [46] [947200/1281167 (74%)]	Loss: 1.288098
[2022-06-09 02:16:51 | train] - Train Epoch: [46] [960000/1281167 (75%)]	Loss: 1.490686
[2022-06-09 02:17:13 | train] - Train Epoch: [46] [972800/1281167 (76%)]	Loss: 1.116976
[2022-06-09 02:17:36 | train] - Train Epoch: [46] [985600/1281167 (77%)]	Loss: 1.244120
[2022-06-09 02:17:58 | train] - Train Epoch: [46] [998400/1281167 (78%)]	Loss: 1.275342
[2022-06-09 02:18:20 | train] - Train Epoch: [46] [1011200/1281167 (79%)]	Loss: 1.254639
[2022-06-09 02:18:42 | train] - Train Epoch: [46] [1024000/1281167 (80%)]	Loss: 1.033458
[2022-06-09 02:19:04 | train] - Train Epoch: [46] [1036800/1281167 (81%)]	Loss: 1.026203
[2022-06-09 02:19:26 | train] - Train Epoch: [46] [1049600/1281167 (82%)]	Loss: 1.304842
[2022-06-09 02:19:48 | train] - Train Epoch: [46] [1062400/1281167 (83%)]	Loss: 1.214605
[2022-06-09 02:20:10 | train] - Train Epoch: [46] [1075200/1281167 (84%)]	Loss: 1.059922
[2022-06-09 02:20:32 | train] - Train Epoch: [46] [1088000/1281167 (85%)]	Loss: 1.392059
[2022-06-09 02:20:54 | train] - Train Epoch: [46] [1100800/1281167 (86%)]	Loss: 1.200357
[2022-06-09 02:21:16 | train] - Train Epoch: [46] [1113600/1281167 (87%)]	Loss: 1.489056
[2022-06-09 02:21:38 | train] - Train Epoch: [46] [1126400/1281167 (88%)]	Loss: 1.201934
[2022-06-09 02:22:00 | train] - Train Epoch: [46] [1139200/1281167 (89%)]	Loss: 1.235992
[2022-06-09 02:22:23 | train] - Train Epoch: [46] [1152000/1281167 (90%)]	Loss: 1.412107
[2022-06-09 02:22:44 | train] - Train Epoch: [46] [1164800/1281167 (91%)]	Loss: 1.415773
[2022-06-09 02:23:06 | train] - Train Epoch: [46] [1177600/1281167 (92%)]	Loss: 1.324055
[2022-06-09 02:23:28 | train] - Train Epoch: [46] [1190400/1281167 (93%)]	Loss: 1.126673
[2022-06-09 02:23:50 | train] - Train Epoch: [46] [1203200/1281167 (94%)]	Loss: 1.430665
[2022-06-09 02:24:12 | train] - Train Epoch: [46] [1216000/1281167 (95%)]	Loss: 1.354552
[2022-06-09 02:24:34 | train] - Train Epoch: [46] [1228800/1281167 (96%)]	Loss: 1.100796
[2022-06-09 02:24:56 | train] - Train Epoch: [46] [1241600/1281167 (97%)]	Loss: 1.092098
[2022-06-09 02:25:19 | train] - Train Epoch: [46] [1254400/1281167 (98%)]	Loss: 1.182873
[2022-06-09 02:25:41 | train] - Train Epoch: [46] [1267200/1281167 (99%)]	Loss: 1.101187
[2022-06-09 02:26:03 | train] - Train Epoch: [46] [1280000/1281167 (100%)]	Loss: 1.365771
[2022-06-09 02:26:04 | train] - Train Epoch: [46]	 Average Loss: 1.270751	 Total Acc : 69.4512	 Total Top5 Acc : 87.6329
[2022-06-09 02:26:04 | train] - -------46 epoch end-----------
========================================
-------46 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 02:27:39 | train] - 
Epoch [46] Test set: Average loss: 1.3843, Accuracy: 33829/50000 (67.6195%), Top-5 Accuracy: 87.8565%

[2022-06-09 02:27:39 | train] - save intermediate epoch [46] result


[2022-06-09 02:27:51 | train] - -------47 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 02:27:52 | train] - Train Epoch: [47] [0/1281167 (0%)]	Loss: 1.329364
[2022-06-09 02:28:14 | train] - Train Epoch: [47] [12800/1281167 (1%)]	Loss: 1.307696
[2022-06-09 02:28:37 | train] - Train Epoch: [47] [25600/1281167 (2%)]	Loss: 1.084794
[2022-06-09 02:28:59 | train] - Train Epoch: [47] [38400/1281167 (3%)]	Loss: 1.075063
[2022-06-09 02:29:21 | train] - Train Epoch: [47] [51200/1281167 (4%)]	Loss: 1.129963
[2022-06-09 02:29:44 | train] - Train Epoch: [47] [64000/1281167 (5%)]	Loss: 1.398726
[2022-06-09 02:30:07 | train] - Train Epoch: [47] [76800/1281167 (6%)]	Loss: 1.321704
[2022-06-09 02:30:29 | train] - Train Epoch: [47] [89600/1281167 (7%)]	Loss: 1.165605
[2022-06-09 02:30:51 | train] - Train Epoch: [47] [102400/1281167 (8%)]	Loss: 1.342059
[2022-06-09 02:31:13 | train] - Train Epoch: [47] [115200/1281167 (9%)]	Loss: 1.187099
[2022-06-09 02:31:35 | train] - Train Epoch: [47] [128000/1281167 (10%)]	Loss: 1.648119
[2022-06-09 02:31:57 | train] - Train Epoch: [47] [140800/1281167 (11%)]	Loss: 1.176521
[2022-06-09 02:32:18 | train] - Train Epoch: [47] [153600/1281167 (12%)]	Loss: 1.079580
[2022-06-09 02:32:41 | train] - Train Epoch: [47] [166400/1281167 (13%)]	Loss: 1.047413
[2022-06-09 02:33:03 | train] - Train Epoch: [47] [179200/1281167 (14%)]	Loss: 1.065316
[2022-06-09 02:33:24 | train] - Train Epoch: [47] [192000/1281167 (15%)]	Loss: 1.267734
[2022-06-09 02:33:46 | train] - Train Epoch: [47] [204800/1281167 (16%)]	Loss: 1.119510
[2022-06-09 02:34:09 | train] - Train Epoch: [47] [217600/1281167 (17%)]	Loss: 1.286415
[2022-06-09 02:34:31 | train] - Train Epoch: [47] [230400/1281167 (18%)]	Loss: 1.307150
[2022-06-09 02:34:53 | train] - Train Epoch: [47] [243200/1281167 (19%)]	Loss: 1.455732
[2022-06-09 02:35:14 | train] - Train Epoch: [47] [256000/1281167 (20%)]	Loss: 0.758384
[2022-06-09 02:35:36 | train] - Train Epoch: [47] [268800/1281167 (21%)]	Loss: 1.073887
[2022-06-09 02:35:58 | train] - Train Epoch: [47] [281600/1281167 (22%)]	Loss: 1.059845
[2022-06-09 02:36:20 | train] - Train Epoch: [47] [294400/1281167 (23%)]	Loss: 1.310430
[2022-06-09 02:36:42 | train] - Train Epoch: [47] [307200/1281167 (24%)]	Loss: 1.292984
[2022-06-09 02:37:03 | train] - Train Epoch: [47] [320000/1281167 (25%)]	Loss: 1.009411
[2022-06-09 02:37:25 | train] - Train Epoch: [47] [332800/1281167 (26%)]	Loss: 1.235149
[2022-06-09 02:37:48 | train] - Train Epoch: [47] [345600/1281167 (27%)]	Loss: 1.398119
[2022-06-09 02:38:10 | train] - Train Epoch: [47] [358400/1281167 (28%)]	Loss: 1.136015
[2022-06-09 02:38:32 | train] - Train Epoch: [47] [371200/1281167 (29%)]	Loss: 1.340716
[2022-06-09 02:38:54 | train] - Train Epoch: [47] [384000/1281167 (30%)]	Loss: 1.080460
[2022-06-09 02:39:17 | train] - Train Epoch: [47] [396800/1281167 (31%)]	Loss: 1.519650
[2022-06-09 02:39:38 | train] - Train Epoch: [47] [409600/1281167 (32%)]	Loss: 1.217545
[2022-06-09 02:40:00 | train] - Train Epoch: [47] [422400/1281167 (33%)]	Loss: 1.014997
[2022-06-09 02:40:22 | train] - Train Epoch: [47] [435200/1281167 (34%)]	Loss: 1.273115
[2022-06-09 02:40:44 | train] - Train Epoch: [47] [448000/1281167 (35%)]	Loss: 1.275905
[2022-06-09 02:41:06 | train] - Train Epoch: [47] [460800/1281167 (36%)]	Loss: 0.932551
[2022-06-09 02:41:29 | train] - Train Epoch: [47] [473600/1281167 (37%)]	Loss: 1.093241
[2022-06-09 02:41:50 | train] - Train Epoch: [47] [486400/1281167 (38%)]	Loss: 1.154487
[2022-06-09 02:42:12 | train] - Train Epoch: [47] [499200/1281167 (39%)]	Loss: 1.240392
[2022-06-09 02:42:34 | train] - Train Epoch: [47] [512000/1281167 (40%)]	Loss: 1.321419
[2022-06-09 02:42:56 | train] - Train Epoch: [47] [524800/1281167 (41%)]	Loss: 1.020296
[2022-06-09 02:43:18 | train] - Train Epoch: [47] [537600/1281167 (42%)]	Loss: 1.036155
[2022-06-09 02:43:39 | train] - Train Epoch: [47] [550400/1281167 (43%)]	Loss: 1.331012
[2022-06-09 02:44:01 | train] - Train Epoch: [47] [563200/1281167 (44%)]	Loss: 0.859067
[2022-06-09 02:44:24 | train] - Train Epoch: [47] [576000/1281167 (45%)]	Loss: 1.243610
[2022-06-09 02:44:45 | train] - Train Epoch: [47] [588800/1281167 (46%)]	Loss: 1.228021
[2022-06-09 02:45:07 | train] - Train Epoch: [47] [601600/1281167 (47%)]	Loss: 1.152345
[2022-06-09 02:45:30 | train] - Train Epoch: [47] [614400/1281167 (48%)]	Loss: 1.079294
[2022-06-09 02:45:52 | train] - Train Epoch: [47] [627200/1281167 (49%)]	Loss: 1.267638
[2022-06-09 02:46:14 | train] - Train Epoch: [47] [640000/1281167 (50%)]	Loss: 1.462000
[2022-06-09 02:46:36 | train] - Train Epoch: [47] [652800/1281167 (51%)]	Loss: 1.416591
[2022-06-09 02:46:58 | train] - Train Epoch: [47] [665600/1281167 (52%)]	Loss: 1.306229
[2022-06-09 02:47:20 | train] - Train Epoch: [47] [678400/1281167 (53%)]	Loss: 1.096302
[2022-06-09 02:47:42 | train] - Train Epoch: [47] [691200/1281167 (54%)]	Loss: 1.244394
[2022-06-09 02:48:05 | train] - Train Epoch: [47] [704000/1281167 (55%)]	Loss: 1.192079
[2022-06-09 02:48:27 | train] - Train Epoch: [47] [716800/1281167 (56%)]	Loss: 1.690998
[2022-06-09 02:48:50 | train] - Train Epoch: [47] [729600/1281167 (57%)]	Loss: 1.422828
[2022-06-09 02:49:12 | train] - Train Epoch: [47] [742400/1281167 (58%)]	Loss: 1.265152
[2022-06-09 02:49:34 | train] - Train Epoch: [47] [755200/1281167 (59%)]	Loss: 0.929500
[2022-06-09 02:49:55 | train] - Train Epoch: [47] [768000/1281167 (60%)]	Loss: 1.497080
[2022-06-09 02:50:18 | train] - Train Epoch: [47] [780800/1281167 (61%)]	Loss: 1.233279
[2022-06-09 02:50:40 | train] - Train Epoch: [47] [793600/1281167 (62%)]	Loss: 1.234747
[2022-06-09 02:51:02 | train] - Train Epoch: [47] [806400/1281167 (63%)]	Loss: 1.372568
[2022-06-09 02:51:23 | train] - Train Epoch: [47] [819200/1281167 (64%)]	Loss: 1.282840
[2022-06-09 02:51:45 | train] - Train Epoch: [47] [832000/1281167 (65%)]	Loss: 1.140689
[2022-06-09 02:52:06 | train] - Train Epoch: [47] [844800/1281167 (66%)]	Loss: 1.370386
[2022-06-09 02:52:28 | train] - Train Epoch: [47] [857600/1281167 (67%)]	Loss: 1.472276
[2022-06-09 02:52:51 | train] - Train Epoch: [47] [870400/1281167 (68%)]	Loss: 1.251763
[2022-06-09 02:53:13 | train] - Train Epoch: [47] [883200/1281167 (69%)]	Loss: 1.176182
[2022-06-09 02:53:35 | train] - Train Epoch: [47] [896000/1281167 (70%)]	Loss: 1.153719
[2022-06-09 02:53:57 | train] - Train Epoch: [47] [908800/1281167 (71%)]	Loss: 1.015034
[2022-06-09 02:54:19 | train] - Train Epoch: [47] [921600/1281167 (72%)]	Loss: 1.303093
[2022-06-09 02:54:42 | train] - Train Epoch: [47] [934400/1281167 (73%)]	Loss: 1.089653
[2022-06-09 02:55:04 | train] - Train Epoch: [47] [947200/1281167 (74%)]	Loss: 1.173044
[2022-06-09 02:55:26 | train] - Train Epoch: [47] [960000/1281167 (75%)]	Loss: 1.141505
[2022-06-09 02:55:48 | train] - Train Epoch: [47] [972800/1281167 (76%)]	Loss: 1.000205
[2022-06-09 02:56:12 | train] - Train Epoch: [47] [985600/1281167 (77%)]	Loss: 1.407731
[2022-06-09 02:56:34 | train] - Train Epoch: [47] [998400/1281167 (78%)]	Loss: 1.277485
[2022-06-09 02:56:56 | train] - Train Epoch: [47] [1011200/1281167 (79%)]	Loss: 1.258522
[2022-06-09 02:57:18 | train] - Train Epoch: [47] [1024000/1281167 (80%)]	Loss: 1.161007
[2022-06-09 02:57:40 | train] - Train Epoch: [47] [1036800/1281167 (81%)]	Loss: 1.272268
[2022-06-09 02:58:02 | train] - Train Epoch: [47] [1049600/1281167 (82%)]	Loss: 1.608285
[2022-06-09 02:58:25 | train] - Train Epoch: [47] [1062400/1281167 (83%)]	Loss: 1.308393
[2022-06-09 02:58:46 | train] - Train Epoch: [47] [1075200/1281167 (84%)]	Loss: 1.360980
[2022-06-09 02:59:08 | train] - Train Epoch: [47] [1088000/1281167 (85%)]	Loss: 0.984511
[2022-06-09 02:59:30 | train] - Train Epoch: [47] [1100800/1281167 (86%)]	Loss: 1.449411
[2022-06-09 02:59:52 | train] - Train Epoch: [47] [1113600/1281167 (87%)]	Loss: 1.252062
[2022-06-09 03:00:15 | train] - Train Epoch: [47] [1126400/1281167 (88%)]	Loss: 1.063100
[2022-06-09 03:00:37 | train] - Train Epoch: [47] [1139200/1281167 (89%)]	Loss: 1.303020
[2022-06-09 03:00:59 | train] - Train Epoch: [47] [1152000/1281167 (90%)]	Loss: 1.212048
[2022-06-09 03:01:21 | train] - Train Epoch: [47] [1164800/1281167 (91%)]	Loss: 1.276010
[2022-06-09 03:01:43 | train] - Train Epoch: [47] [1177600/1281167 (92%)]	Loss: 0.907237
[2022-06-09 03:02:05 | train] - Train Epoch: [47] [1190400/1281167 (93%)]	Loss: 1.043873
[2022-06-09 03:02:27 | train] - Train Epoch: [47] [1203200/1281167 (94%)]	Loss: 1.285078
[2022-06-09 03:02:49 | train] - Train Epoch: [47] [1216000/1281167 (95%)]	Loss: 1.395989
[2022-06-09 03:03:11 | train] - Train Epoch: [47] [1228800/1281167 (96%)]	Loss: 1.218151
[2022-06-09 03:03:33 | train] - Train Epoch: [47] [1241600/1281167 (97%)]	Loss: 1.390999
[2022-06-09 03:03:55 | train] - Train Epoch: [47] [1254400/1281167 (98%)]	Loss: 1.274451
[2022-06-09 03:04:17 | train] - Train Epoch: [47] [1267200/1281167 (99%)]	Loss: 1.571573
[2022-06-09 03:04:39 | train] - Train Epoch: [47] [1280000/1281167 (100%)]	Loss: 1.224584
[2022-06-09 03:04:41 | train] - Train Epoch: [47]	 Average Loss: 1.258904	 Total Acc : 69.7013	 Total Top5 Acc : 87.7622
[2022-06-09 03:04:41 | train] - -------47 epoch end-----------
========================================
-------47 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 03:06:16 | train] - 
Epoch [47] Test set: Average loss: 1.3705, Accuracy: 34036/50000 (68.0415%), Top-5 Accuracy: 87.8968%

[2022-06-09 03:06:16 | train] - save intermediate epoch [47] result


[2022-06-09 03:06:27 | train] - logging best performance 47 epoch
[2022-06-09 03:06:28 | train] - -------48 epoch start-----------
========================================
----- test end -------------------------


logging best performance 47 epoch
[2022-06-09 03:06:30 | train] - Train Epoch: [48] [0/1281167 (0%)]	Loss: 1.599544
[2022-06-09 03:06:52 | train] - Train Epoch: [48] [12800/1281167 (1%)]	Loss: 1.154891
[2022-06-09 03:07:14 | train] - Train Epoch: [48] [25600/1281167 (2%)]	Loss: 1.388204
[2022-06-09 03:07:36 | train] - Train Epoch: [48] [38400/1281167 (3%)]	Loss: 1.189891
[2022-06-09 03:07:58 | train] - Train Epoch: [48] [51200/1281167 (4%)]	Loss: 1.060693
[2022-06-09 03:08:20 | train] - Train Epoch: [48] [64000/1281167 (5%)]	Loss: 1.189900
[2022-06-09 03:08:42 | train] - Train Epoch: [48] [76800/1281167 (6%)]	Loss: 1.145693
[2022-06-09 03:09:04 | train] - Train Epoch: [48] [89600/1281167 (7%)]	Loss: 1.206065
[2022-06-09 03:09:27 | train] - Train Epoch: [48] [102400/1281167 (8%)]	Loss: 0.981395
[2022-06-09 03:09:49 | train] - Train Epoch: [48] [115200/1281167 (9%)]	Loss: 1.432182
[2022-06-09 03:10:12 | train] - Train Epoch: [48] [128000/1281167 (10%)]	Loss: 1.489619
[2022-06-09 03:10:35 | train] - Train Epoch: [48] [140800/1281167 (11%)]	Loss: 1.080068
[2022-06-09 03:10:58 | train] - Train Epoch: [48] [153600/1281167 (12%)]	Loss: 1.183119
[2022-06-09 03:11:19 | train] - Train Epoch: [48] [166400/1281167 (13%)]	Loss: 1.244606
[2022-06-09 03:11:42 | train] - Train Epoch: [48] [179200/1281167 (14%)]	Loss: 1.165708
[2022-06-09 03:12:04 | train] - Train Epoch: [48] [192000/1281167 (15%)]	Loss: 1.143220
[2022-06-09 03:12:26 | train] - Train Epoch: [48] [204800/1281167 (16%)]	Loss: 1.159168
[2022-06-09 03:12:48 | train] - Train Epoch: [48] [217600/1281167 (17%)]	Loss: 1.135099
[2022-06-09 03:13:10 | train] - Train Epoch: [48] [230400/1281167 (18%)]	Loss: 1.074100
[2022-06-09 03:13:33 | train] - Train Epoch: [48] [243200/1281167 (19%)]	Loss: 1.122889
[2022-06-09 03:13:55 | train] - Train Epoch: [48] [256000/1281167 (20%)]	Loss: 0.938966
[2022-06-09 03:14:17 | train] - Train Epoch: [48] [268800/1281167 (21%)]	Loss: 1.445782
[2022-06-09 03:14:39 | train] - Train Epoch: [48] [281600/1281167 (22%)]	Loss: 1.263073
[2022-06-09 03:15:01 | train] - Train Epoch: [48] [294400/1281167 (23%)]	Loss: 0.955222
[2022-06-09 03:15:23 | train] - Train Epoch: [48] [307200/1281167 (24%)]	Loss: 1.200861
[2022-06-09 03:15:46 | train] - Train Epoch: [48] [320000/1281167 (25%)]	Loss: 1.275019
[2022-06-09 03:16:09 | train] - Train Epoch: [48] [332800/1281167 (26%)]	Loss: 1.287092
[2022-06-09 03:16:31 | train] - Train Epoch: [48] [345600/1281167 (27%)]	Loss: 1.468977
[2022-06-09 03:16:53 | train] - Train Epoch: [48] [358400/1281167 (28%)]	Loss: 1.328740
[2022-06-09 03:17:16 | train] - Train Epoch: [48] [371200/1281167 (29%)]	Loss: 1.354281
[2022-06-09 03:17:39 | train] - Train Epoch: [48] [384000/1281167 (30%)]	Loss: 1.437548
[2022-06-09 03:18:02 | train] - Train Epoch: [48] [396800/1281167 (31%)]	Loss: 1.385711
[2022-06-09 03:18:24 | train] - Train Epoch: [48] [409600/1281167 (32%)]	Loss: 1.425757
[2022-06-09 03:18:46 | train] - Train Epoch: [48] [422400/1281167 (33%)]	Loss: 1.318258
[2022-06-09 03:19:08 | train] - Train Epoch: [48] [435200/1281167 (34%)]	Loss: 1.294145
[2022-06-09 03:19:31 | train] - Train Epoch: [48] [448000/1281167 (35%)]	Loss: 1.044835
[2022-06-09 03:19:54 | train] - Train Epoch: [48] [460800/1281167 (36%)]	Loss: 1.048692
[2022-06-09 03:20:16 | train] - Train Epoch: [48] [473600/1281167 (37%)]	Loss: 1.365336
[2022-06-09 03:20:38 | train] - Train Epoch: [48] [486400/1281167 (38%)]	Loss: 1.581328
[2022-06-09 03:21:01 | train] - Train Epoch: [48] [499200/1281167 (39%)]	Loss: 1.044831
[2022-06-09 03:21:24 | train] - Train Epoch: [48] [512000/1281167 (40%)]	Loss: 1.424305
[2022-06-09 03:21:47 | train] - Train Epoch: [48] [524800/1281167 (41%)]	Loss: 1.201564
[2022-06-09 03:22:09 | train] - Train Epoch: [48] [537600/1281167 (42%)]	Loss: 1.266455
[2022-06-09 03:22:31 | train] - Train Epoch: [48] [550400/1281167 (43%)]	Loss: 1.447803
[2022-06-09 03:22:54 | train] - Train Epoch: [48] [563200/1281167 (44%)]	Loss: 1.466718
[2022-06-09 03:23:16 | train] - Train Epoch: [48] [576000/1281167 (45%)]	Loss: 1.144571
[2022-06-09 03:23:38 | train] - Train Epoch: [48] [588800/1281167 (46%)]	Loss: 1.324043
[2022-06-09 03:24:00 | train] - Train Epoch: [48] [601600/1281167 (47%)]	Loss: 1.026723
[2022-06-09 03:24:22 | train] - Train Epoch: [48] [614400/1281167 (48%)]	Loss: 0.824097
[2022-06-09 03:24:44 | train] - Train Epoch: [48] [627200/1281167 (49%)]	Loss: 1.336451
[2022-06-09 03:25:07 | train] - Train Epoch: [48] [640000/1281167 (50%)]	Loss: 1.418803
[2022-06-09 03:25:30 | train] - Train Epoch: [48] [652800/1281167 (51%)]	Loss: 1.329309
[2022-06-09 03:25:52 | train] - Train Epoch: [48] [665600/1281167 (52%)]	Loss: 1.365786
[2022-06-09 03:26:14 | train] - Train Epoch: [48] [678400/1281167 (53%)]	Loss: 1.422072
[2022-06-09 03:26:37 | train] - Train Epoch: [48] [691200/1281167 (54%)]	Loss: 1.336669
[2022-06-09 03:26:59 | train] - Train Epoch: [48] [704000/1281167 (55%)]	Loss: 1.164782
[2022-06-09 03:27:22 | train] - Train Epoch: [48] [716800/1281167 (56%)]	Loss: 1.364579
[2022-06-09 03:27:44 | train] - Train Epoch: [48] [729600/1281167 (57%)]	Loss: 1.435321
[2022-06-09 03:28:06 | train] - Train Epoch: [48] [742400/1281167 (58%)]	Loss: 1.380896
[2022-06-09 03:28:29 | train] - Train Epoch: [48] [755200/1281167 (59%)]	Loss: 1.138427
[2022-06-09 03:28:50 | train] - Train Epoch: [48] [768000/1281167 (60%)]	Loss: 1.313272
[2022-06-09 03:29:14 | train] - Train Epoch: [48] [780800/1281167 (61%)]	Loss: 1.162991
[2022-06-09 03:29:35 | train] - Train Epoch: [48] [793600/1281167 (62%)]	Loss: 1.351457
[2022-06-09 03:29:57 | train] - Train Epoch: [48] [806400/1281167 (63%)]	Loss: 1.226392
[2022-06-09 03:30:20 | train] - Train Epoch: [48] [819200/1281167 (64%)]	Loss: 1.310284
[2022-06-09 03:30:42 | train] - Train Epoch: [48] [832000/1281167 (65%)]	Loss: 1.060460
[2022-06-09 03:31:04 | train] - Train Epoch: [48] [844800/1281167 (66%)]	Loss: 1.350371
[2022-06-09 03:31:27 | train] - Train Epoch: [48] [857600/1281167 (67%)]	Loss: 0.964250
[2022-06-09 03:31:49 | train] - Train Epoch: [48] [870400/1281167 (68%)]	Loss: 1.234884
[2022-06-09 03:32:11 | train] - Train Epoch: [48] [883200/1281167 (69%)]	Loss: 1.232407
[2022-06-09 03:32:34 | train] - Train Epoch: [48] [896000/1281167 (70%)]	Loss: 1.391697
[2022-06-09 03:32:56 | train] - Train Epoch: [48] [908800/1281167 (71%)]	Loss: 1.109282
[2022-06-09 03:33:19 | train] - Train Epoch: [48] [921600/1281167 (72%)]	Loss: 1.505681
[2022-06-09 03:33:42 | train] - Train Epoch: [48] [934400/1281167 (73%)]	Loss: 1.129682
[2022-06-09 03:34:03 | train] - Train Epoch: [48] [947200/1281167 (74%)]	Loss: 1.283619
[2022-06-09 03:34:26 | train] - Train Epoch: [48] [960000/1281167 (75%)]	Loss: 1.254081
[2022-06-09 03:34:48 | train] - Train Epoch: [48] [972800/1281167 (76%)]	Loss: 1.545371
[2022-06-09 03:35:10 | train] - Train Epoch: [48] [985600/1281167 (77%)]	Loss: 1.168591
[2022-06-09 03:35:32 | train] - Train Epoch: [48] [998400/1281167 (78%)]	Loss: 1.447150
[2022-06-09 03:35:55 | train] - Train Epoch: [48] [1011200/1281167 (79%)]	Loss: 1.293190
[2022-06-09 03:36:17 | train] - Train Epoch: [48] [1024000/1281167 (80%)]	Loss: 1.055116
[2022-06-09 03:36:39 | train] - Train Epoch: [48] [1036800/1281167 (81%)]	Loss: 1.147174
[2022-06-09 03:37:01 | train] - Train Epoch: [48] [1049600/1281167 (82%)]	Loss: 1.392321
[2022-06-09 03:37:23 | train] - Train Epoch: [48] [1062400/1281167 (83%)]	Loss: 0.939565
[2022-06-09 03:37:46 | train] - Train Epoch: [48] [1075200/1281167 (84%)]	Loss: 1.282815
[2022-06-09 03:38:08 | train] - Train Epoch: [48] [1088000/1281167 (85%)]	Loss: 1.098921
[2022-06-09 03:38:31 | train] - Train Epoch: [48] [1100800/1281167 (86%)]	Loss: 1.184696
[2022-06-09 03:38:53 | train] - Train Epoch: [48] [1113600/1281167 (87%)]	Loss: 1.496065
[2022-06-09 03:39:17 | train] - Train Epoch: [48] [1126400/1281167 (88%)]	Loss: 1.666102
[2022-06-09 03:39:39 | train] - Train Epoch: [48] [1139200/1281167 (89%)]	Loss: 1.139094
[2022-06-09 03:40:02 | train] - Train Epoch: [48] [1152000/1281167 (90%)]	Loss: 1.174320
[2022-06-09 03:40:24 | train] - Train Epoch: [48] [1164800/1281167 (91%)]	Loss: 1.371890
[2022-06-09 03:40:46 | train] - Train Epoch: [48] [1177600/1281167 (92%)]	Loss: 1.397071
[2022-06-09 03:41:08 | train] - Train Epoch: [48] [1190400/1281167 (93%)]	Loss: 1.208431
[2022-06-09 03:41:31 | train] - Train Epoch: [48] [1203200/1281167 (94%)]	Loss: 0.908437
[2022-06-09 03:41:53 | train] - Train Epoch: [48] [1216000/1281167 (95%)]	Loss: 1.417058
[2022-06-09 03:42:15 | train] - Train Epoch: [48] [1228800/1281167 (96%)]	Loss: 1.357299
[2022-06-09 03:42:37 | train] - Train Epoch: [48] [1241600/1281167 (97%)]	Loss: 1.037415
[2022-06-09 03:43:01 | train] - Train Epoch: [48] [1254400/1281167 (98%)]	Loss: 1.393335
[2022-06-09 03:43:23 | train] - Train Epoch: [48] [1267200/1281167 (99%)]	Loss: 1.431184
[2022-06-09 03:43:46 | train] - Train Epoch: [48] [1280000/1281167 (100%)]	Loss: 1.002384
[2022-06-09 03:43:48 | train] - Train Epoch: [48]	 Average Loss: 1.250962	 Total Acc : 69.8872	 Total Top5 Acc : 87.8696
[2022-06-09 03:43:48 | train] - -------48 epoch end-----------
========================================
-------48 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 03:45:25 | train] - 
Epoch [48] Test set: Average loss: 1.3750, Accuracy: 33902/50000 (67.7749%), Top-5 Accuracy: 87.9224%

[2022-06-09 03:45:25 | train] - save intermediate epoch [48] result


[2022-06-09 03:45:38 | train] - -------49 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 03:45:39 | train] - Train Epoch: [49] [0/1281167 (0%)]	Loss: 1.068257
[2022-06-09 03:46:02 | train] - Train Epoch: [49] [12800/1281167 (1%)]	Loss: 1.210232
[2022-06-09 03:46:23 | train] - Train Epoch: [49] [25600/1281167 (2%)]	Loss: 1.305536
[2022-06-09 03:46:46 | train] - Train Epoch: [49] [38400/1281167 (3%)]	Loss: 1.137396
[2022-06-09 03:47:08 | train] - Train Epoch: [49] [51200/1281167 (4%)]	Loss: 0.890998
[2022-06-09 03:47:31 | train] - Train Epoch: [49] [64000/1281167 (5%)]	Loss: 1.212819
[2022-06-09 03:47:53 | train] - Train Epoch: [49] [76800/1281167 (6%)]	Loss: 0.861726
[2022-06-09 03:48:16 | train] - Train Epoch: [49] [89600/1281167 (7%)]	Loss: 1.384899
[2022-06-09 03:48:38 | train] - Train Epoch: [49] [102400/1281167 (8%)]	Loss: 1.422148
[2022-06-09 03:49:01 | train] - Train Epoch: [49] [115200/1281167 (9%)]	Loss: 1.059478
[2022-06-09 03:49:23 | train] - Train Epoch: [49] [128000/1281167 (10%)]	Loss: 1.168304
[2022-06-09 03:49:45 | train] - Train Epoch: [49] [140800/1281167 (11%)]	Loss: 1.062262
[2022-06-09 03:50:07 | train] - Train Epoch: [49] [153600/1281167 (12%)]	Loss: 1.086910
[2022-06-09 03:50:29 | train] - Train Epoch: [49] [166400/1281167 (13%)]	Loss: 1.379821
[2022-06-09 03:50:52 | train] - Train Epoch: [49] [179200/1281167 (14%)]	Loss: 1.409625
[2022-06-09 03:51:14 | train] - Train Epoch: [49] [192000/1281167 (15%)]	Loss: 1.131645
[2022-06-09 03:51:37 | train] - Train Epoch: [49] [204800/1281167 (16%)]	Loss: 1.190592
[2022-06-09 03:51:59 | train] - Train Epoch: [49] [217600/1281167 (17%)]	Loss: 0.836004
[2022-06-09 03:52:21 | train] - Train Epoch: [49] [230400/1281167 (18%)]	Loss: 0.927963
[2022-06-09 03:52:44 | train] - Train Epoch: [49] [243200/1281167 (19%)]	Loss: 1.372148
[2022-06-09 03:53:07 | train] - Train Epoch: [49] [256000/1281167 (20%)]	Loss: 1.225267
[2022-06-09 03:53:29 | train] - Train Epoch: [49] [268800/1281167 (21%)]	Loss: 1.141378
[2022-06-09 03:53:52 | train] - Train Epoch: [49] [281600/1281167 (22%)]	Loss: 1.399842
[2022-06-09 03:54:14 | train] - Train Epoch: [49] [294400/1281167 (23%)]	Loss: 0.912690
[2022-06-09 03:54:36 | train] - Train Epoch: [49] [307200/1281167 (24%)]	Loss: 1.239462
[2022-06-09 03:54:58 | train] - Train Epoch: [49] [320000/1281167 (25%)]	Loss: 0.995064
[2022-06-09 03:55:20 | train] - Train Epoch: [49] [332800/1281167 (26%)]	Loss: 1.161830
[2022-06-09 03:55:43 | train] - Train Epoch: [49] [345600/1281167 (27%)]	Loss: 1.004575
[2022-06-09 03:56:06 | train] - Train Epoch: [49] [358400/1281167 (28%)]	Loss: 1.005775
[2022-06-09 03:56:28 | train] - Train Epoch: [49] [371200/1281167 (29%)]	Loss: 1.213634
[2022-06-09 03:56:51 | train] - Train Epoch: [49] [384000/1281167 (30%)]	Loss: 1.194417
[2022-06-09 03:57:13 | train] - Train Epoch: [49] [396800/1281167 (31%)]	Loss: 1.375005
[2022-06-09 03:57:35 | train] - Train Epoch: [49] [409600/1281167 (32%)]	Loss: 1.406752
[2022-06-09 03:57:57 | train] - Train Epoch: [49] [422400/1281167 (33%)]	Loss: 1.055208
[2022-06-09 03:58:20 | train] - Train Epoch: [49] [435200/1281167 (34%)]	Loss: 0.944204
[2022-06-09 03:58:42 | train] - Train Epoch: [49] [448000/1281167 (35%)]	Loss: 1.122510
[2022-06-09 03:59:04 | train] - Train Epoch: [49] [460800/1281167 (36%)]	Loss: 1.106771
[2022-06-09 03:59:27 | train] - Train Epoch: [49] [473600/1281167 (37%)]	Loss: 1.010320
[2022-06-09 03:59:49 | train] - Train Epoch: [49] [486400/1281167 (38%)]	Loss: 1.065279
[2022-06-09 04:00:11 | train] - Train Epoch: [49] [499200/1281167 (39%)]	Loss: 1.276039
[2022-06-09 04:00:34 | train] - Train Epoch: [49] [512000/1281167 (40%)]	Loss: 1.187006
[2022-06-09 04:00:56 | train] - Train Epoch: [49] [524800/1281167 (41%)]	Loss: 1.173738
[2022-06-09 04:01:18 | train] - Train Epoch: [49] [537600/1281167 (42%)]	Loss: 1.146726
[2022-06-09 04:01:40 | train] - Train Epoch: [49] [550400/1281167 (43%)]	Loss: 1.412815
[2022-06-09 04:02:02 | train] - Train Epoch: [49] [563200/1281167 (44%)]	Loss: 1.003860
[2022-06-09 04:02:24 | train] - Train Epoch: [49] [576000/1281167 (45%)]	Loss: 1.371819
[2022-06-09 04:02:46 | train] - Train Epoch: [49] [588800/1281167 (46%)]	Loss: 1.304884
[2022-06-09 04:03:09 | train] - Train Epoch: [49] [601600/1281167 (47%)]	Loss: 1.223381
[2022-06-09 04:03:31 | train] - Train Epoch: [49] [614400/1281167 (48%)]	Loss: 1.193049
[2022-06-09 04:03:54 | train] - Train Epoch: [49] [627200/1281167 (49%)]	Loss: 1.126910
[2022-06-09 04:04:15 | train] - Train Epoch: [49] [640000/1281167 (50%)]	Loss: 1.327215
[2022-06-09 04:04:37 | train] - Train Epoch: [49] [652800/1281167 (51%)]	Loss: 1.072492
[2022-06-09 04:04:59 | train] - Train Epoch: [49] [665600/1281167 (52%)]	Loss: 0.959943
[2022-06-09 04:05:22 | train] - Train Epoch: [49] [678400/1281167 (53%)]	Loss: 1.228647
[2022-06-09 04:05:44 | train] - Train Epoch: [49] [691200/1281167 (54%)]	Loss: 1.412436
[2022-06-09 04:06:06 | train] - Train Epoch: [49] [704000/1281167 (55%)]	Loss: 1.384375
[2022-06-09 04:06:28 | train] - Train Epoch: [49] [716800/1281167 (56%)]	Loss: 1.265641
[2022-06-09 04:06:50 | train] - Train Epoch: [49] [729600/1281167 (57%)]	Loss: 1.249942
[2022-06-09 04:07:12 | train] - Train Epoch: [49] [742400/1281167 (58%)]	Loss: 1.415047
[2022-06-09 04:07:35 | train] - Train Epoch: [49] [755200/1281167 (59%)]	Loss: 1.355655
[2022-06-09 04:07:57 | train] - Train Epoch: [49] [768000/1281167 (60%)]	Loss: 1.148794
[2022-06-09 04:08:18 | train] - Train Epoch: [49] [780800/1281167 (61%)]	Loss: 1.573563
[2022-06-09 04:08:40 | train] - Train Epoch: [49] [793600/1281167 (62%)]	Loss: 1.431049
[2022-06-09 04:09:02 | train] - Train Epoch: [49] [806400/1281167 (63%)]	Loss: 1.034508
[2022-06-09 04:09:24 | train] - Train Epoch: [49] [819200/1281167 (64%)]	Loss: 1.224940
[2022-06-09 04:09:47 | train] - Train Epoch: [49] [832000/1281167 (65%)]	Loss: 0.970807
[2022-06-09 04:10:08 | train] - Train Epoch: [49] [844800/1281167 (66%)]	Loss: 1.150131
[2022-06-09 04:10:30 | train] - Train Epoch: [49] [857600/1281167 (67%)]	Loss: 1.201354
[2022-06-09 04:10:52 | train] - Train Epoch: [49] [870400/1281167 (68%)]	Loss: 1.450896
[2022-06-09 04:11:14 | train] - Train Epoch: [49] [883200/1281167 (69%)]	Loss: 1.187777
[2022-06-09 04:11:36 | train] - Train Epoch: [49] [896000/1281167 (70%)]	Loss: 1.138397
[2022-06-09 04:11:58 | train] - Train Epoch: [49] [908800/1281167 (71%)]	Loss: 1.008726
[2022-06-09 04:12:19 | train] - Train Epoch: [49] [921600/1281167 (72%)]	Loss: 1.399881
[2022-06-09 04:12:42 | train] - Train Epoch: [49] [934400/1281167 (73%)]	Loss: 1.366146
[2022-06-09 04:13:03 | train] - Train Epoch: [49] [947200/1281167 (74%)]	Loss: 1.121602
[2022-06-09 04:13:25 | train] - Train Epoch: [49] [960000/1281167 (75%)]	Loss: 1.346732
[2022-06-09 04:13:47 | train] - Train Epoch: [49] [972800/1281167 (76%)]	Loss: 1.209571
[2022-06-09 04:14:09 | train] - Train Epoch: [49] [985600/1281167 (77%)]	Loss: 1.052933
[2022-06-09 04:14:32 | train] - Train Epoch: [49] [998400/1281167 (78%)]	Loss: 1.233815
[2022-06-09 04:14:54 | train] - Train Epoch: [49] [1011200/1281167 (79%)]	Loss: 1.122250
[2022-06-09 04:15:16 | train] - Train Epoch: [49] [1024000/1281167 (80%)]	Loss: 1.104059
[2022-06-09 04:15:38 | train] - Train Epoch: [49] [1036800/1281167 (81%)]	Loss: 1.073787
[2022-06-09 04:16:00 | train] - Train Epoch: [49] [1049600/1281167 (82%)]	Loss: 1.440969
[2022-06-09 04:16:22 | train] - Train Epoch: [49] [1062400/1281167 (83%)]	Loss: 1.110810
[2022-06-09 04:16:44 | train] - Train Epoch: [49] [1075200/1281167 (84%)]	Loss: 1.224525
[2022-06-09 04:17:06 | train] - Train Epoch: [49] [1088000/1281167 (85%)]	Loss: 1.295632
[2022-06-09 04:17:27 | train] - Train Epoch: [49] [1100800/1281167 (86%)]	Loss: 1.502233
[2022-06-09 04:17:49 | train] - Train Epoch: [49] [1113600/1281167 (87%)]	Loss: 1.375067
[2022-06-09 04:18:11 | train] - Train Epoch: [49] [1126400/1281167 (88%)]	Loss: 1.244524
[2022-06-09 04:18:33 | train] - Train Epoch: [49] [1139200/1281167 (89%)]	Loss: 1.473729
[2022-06-09 04:18:55 | train] - Train Epoch: [49] [1152000/1281167 (90%)]	Loss: 0.861567
[2022-06-09 04:19:17 | train] - Train Epoch: [49] [1164800/1281167 (91%)]	Loss: 1.387024
[2022-06-09 04:19:40 | train] - Train Epoch: [49] [1177600/1281167 (92%)]	Loss: 1.126363
[2022-06-09 04:20:02 | train] - Train Epoch: [49] [1190400/1281167 (93%)]	Loss: 1.155719
[2022-06-09 04:20:23 | train] - Train Epoch: [49] [1203200/1281167 (94%)]	Loss: 1.446815
[2022-06-09 04:20:45 | train] - Train Epoch: [49] [1216000/1281167 (95%)]	Loss: 1.356367
[2022-06-09 04:21:07 | train] - Train Epoch: [49] [1228800/1281167 (96%)]	Loss: 1.095652
[2022-06-09 04:21:29 | train] - Train Epoch: [49] [1241600/1281167 (97%)]	Loss: 0.906921
[2022-06-09 04:21:52 | train] - Train Epoch: [49] [1254400/1281167 (98%)]	Loss: 1.090007
[2022-06-09 04:22:13 | train] - Train Epoch: [49] [1267200/1281167 (99%)]	Loss: 1.205297
[2022-06-09 04:22:36 | train] - Train Epoch: [49] [1280000/1281167 (100%)]	Loss: 1.122485
[2022-06-09 04:22:38 | train] - Train Epoch: [49]	 Average Loss: 1.237463	 Total Acc : 70.1755	 Total Top5 Acc : 88.0777
[2022-06-09 04:22:38 | train] - -------49 epoch end-----------
========================================
-------49 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 04:24:16 | train] - 
Epoch [49] Test set: Average loss: 1.3600, Accuracy: 34108/50000 (68.1817%), Top-5 Accuracy: 88.0858%

[2022-06-09 04:24:16 | train] - save intermediate epoch [49] result


[2022-06-09 04:24:28 | train] - logging best performance 49 epoch
[2022-06-09 04:24:30 | train] - -------50 epoch start-----------
========================================
----- test end -------------------------


logging best performance 49 epoch
[2022-06-09 04:24:32 | train] - Train Epoch: [50] [0/1281167 (0%)]	Loss: 1.221268
[2022-06-09 04:24:54 | train] - Train Epoch: [50] [12800/1281167 (1%)]	Loss: 1.537024
[2022-06-09 04:25:16 | train] - Train Epoch: [50] [25600/1281167 (2%)]	Loss: 1.172429
[2022-06-09 04:25:40 | train] - Train Epoch: [50] [38400/1281167 (3%)]	Loss: 0.952027
[2022-06-09 04:26:02 | train] - Train Epoch: [50] [51200/1281167 (4%)]	Loss: 1.477436
[2022-06-09 04:26:24 | train] - Train Epoch: [50] [64000/1281167 (5%)]	Loss: 1.197849
[2022-06-09 04:26:47 | train] - Train Epoch: [50] [76800/1281167 (6%)]	Loss: 1.156399
[2022-06-09 04:27:09 | train] - Train Epoch: [50] [89600/1281167 (7%)]	Loss: 1.435703
[2022-06-09 04:27:31 | train] - Train Epoch: [50] [102400/1281167 (8%)]	Loss: 1.337372
[2022-06-09 04:27:53 | train] - Train Epoch: [50] [115200/1281167 (9%)]	Loss: 1.264016
[2022-06-09 04:28:15 | train] - Train Epoch: [50] [128000/1281167 (10%)]	Loss: 1.036029
[2022-06-09 04:28:37 | train] - Train Epoch: [50] [140800/1281167 (11%)]	Loss: 1.101601
[2022-06-09 04:28:59 | train] - Train Epoch: [50] [153600/1281167 (12%)]	Loss: 1.128001
[2022-06-09 04:29:21 | train] - Train Epoch: [50] [166400/1281167 (13%)]	Loss: 1.089640
[2022-06-09 04:29:43 | train] - Train Epoch: [50] [179200/1281167 (14%)]	Loss: 1.093503
[2022-06-09 04:30:06 | train] - Train Epoch: [50] [192000/1281167 (15%)]	Loss: 1.233718
[2022-06-09 04:30:28 | train] - Train Epoch: [50] [204800/1281167 (16%)]	Loss: 1.157470
[2022-06-09 04:30:50 | train] - Train Epoch: [50] [217600/1281167 (17%)]	Loss: 1.111718
[2022-06-09 04:31:12 | train] - Train Epoch: [50] [230400/1281167 (18%)]	Loss: 1.158996
[2022-06-09 04:31:35 | train] - Train Epoch: [50] [243200/1281167 (19%)]	Loss: 1.079133
[2022-06-09 04:31:57 | train] - Train Epoch: [50] [256000/1281167 (20%)]	Loss: 1.484138
[2022-06-09 04:32:19 | train] - Train Epoch: [50] [268800/1281167 (21%)]	Loss: 1.061154
[2022-06-09 04:32:41 | train] - Train Epoch: [50] [281600/1281167 (22%)]	Loss: 1.075943
[2022-06-09 04:33:03 | train] - Train Epoch: [50] [294400/1281167 (23%)]	Loss: 1.463377
[2022-06-09 04:33:26 | train] - Train Epoch: [50] [307200/1281167 (24%)]	Loss: 1.389666
[2022-06-09 04:33:48 | train] - Train Epoch: [50] [320000/1281167 (25%)]	Loss: 1.393648
[2022-06-09 04:34:10 | train] - Train Epoch: [50] [332800/1281167 (26%)]	Loss: 1.311331
[2022-06-09 04:34:32 | train] - Train Epoch: [50] [345600/1281167 (27%)]	Loss: 1.347457
[2022-06-09 04:34:55 | train] - Train Epoch: [50] [358400/1281167 (28%)]	Loss: 1.231846
[2022-06-09 04:35:18 | train] - Train Epoch: [50] [371200/1281167 (29%)]	Loss: 1.251545
[2022-06-09 04:35:42 | train] - Train Epoch: [50] [384000/1281167 (30%)]	Loss: 0.856812
[2022-06-09 04:36:04 | train] - Train Epoch: [50] [396800/1281167 (31%)]	Loss: 0.996208
[2022-06-09 04:36:27 | train] - Train Epoch: [50] [409600/1281167 (32%)]	Loss: 1.096292
[2022-06-09 04:36:49 | train] - Train Epoch: [50] [422400/1281167 (33%)]	Loss: 1.401592
[2022-06-09 04:37:11 | train] - Train Epoch: [50] [435200/1281167 (34%)]	Loss: 1.291633
[2022-06-09 04:37:35 | train] - Train Epoch: [50] [448000/1281167 (35%)]	Loss: 1.100535
[2022-06-09 04:37:57 | train] - Train Epoch: [50] [460800/1281167 (36%)]	Loss: 1.156005
[2022-06-09 04:38:20 | train] - Train Epoch: [50] [473600/1281167 (37%)]	Loss: 1.382828
[2022-06-09 04:38:42 | train] - Train Epoch: [50] [486400/1281167 (38%)]	Loss: 1.183641
[2022-06-09 04:39:05 | train] - Train Epoch: [50] [499200/1281167 (39%)]	Loss: 1.086497
[2022-06-09 04:39:27 | train] - Train Epoch: [50] [512000/1281167 (40%)]	Loss: 1.107399
[2022-06-09 04:39:49 | train] - Train Epoch: [50] [524800/1281167 (41%)]	Loss: 1.324720
[2022-06-09 04:40:12 | train] - Train Epoch: [50] [537600/1281167 (42%)]	Loss: 1.025023
[2022-06-09 04:40:35 | train] - Train Epoch: [50] [550400/1281167 (43%)]	Loss: 1.276487
[2022-06-09 04:40:57 | train] - Train Epoch: [50] [563200/1281167 (44%)]	Loss: 1.258434
[2022-06-09 04:41:21 | train] - Train Epoch: [50] [576000/1281167 (45%)]	Loss: 1.299216
[2022-06-09 04:41:44 | train] - Train Epoch: [50] [588800/1281167 (46%)]	Loss: 0.986310
[2022-06-09 04:42:07 | train] - Train Epoch: [50] [601600/1281167 (47%)]	Loss: 1.286635
[2022-06-09 04:42:29 | train] - Train Epoch: [50] [614400/1281167 (48%)]	Loss: 1.161176
[2022-06-09 04:42:51 | train] - Train Epoch: [50] [627200/1281167 (49%)]	Loss: 1.008317
[2022-06-09 04:43:13 | train] - Train Epoch: [50] [640000/1281167 (50%)]	Loss: 1.143805
[2022-06-09 04:43:36 | train] - Train Epoch: [50] [652800/1281167 (51%)]	Loss: 1.377461
[2022-06-09 04:43:59 | train] - Train Epoch: [50] [665600/1281167 (52%)]	Loss: 1.290647
[2022-06-09 04:44:21 | train] - Train Epoch: [50] [678400/1281167 (53%)]	Loss: 1.291383
[2022-06-09 04:44:44 | train] - Train Epoch: [50] [691200/1281167 (54%)]	Loss: 1.035562
[2022-06-09 04:45:08 | train] - Train Epoch: [50] [704000/1281167 (55%)]	Loss: 1.089383
[2022-06-09 04:45:31 | train] - Train Epoch: [50] [716800/1281167 (56%)]	Loss: 1.206835
[2022-06-09 04:45:53 | train] - Train Epoch: [50] [729600/1281167 (57%)]	Loss: 1.167590
[2022-06-09 04:46:15 | train] - Train Epoch: [50] [742400/1281167 (58%)]	Loss: 1.442894
[2022-06-09 04:46:37 | train] - Train Epoch: [50] [755200/1281167 (59%)]	Loss: 1.170025
[2022-06-09 04:46:59 | train] - Train Epoch: [50] [768000/1281167 (60%)]	Loss: 1.183704
[2022-06-09 04:47:21 | train] - Train Epoch: [50] [780800/1281167 (61%)]	Loss: 1.455174
[2022-06-09 04:47:43 | train] - Train Epoch: [50] [793600/1281167 (62%)]	Loss: 1.072633
[2022-06-09 04:48:06 | train] - Train Epoch: [50] [806400/1281167 (63%)]	Loss: 1.032232
[2022-06-09 04:48:28 | train] - Train Epoch: [50] [819200/1281167 (64%)]	Loss: 1.124762
[2022-06-09 04:48:50 | train] - Train Epoch: [50] [832000/1281167 (65%)]	Loss: 1.647144
[2022-06-09 04:49:12 | train] - Train Epoch: [50] [844800/1281167 (66%)]	Loss: 1.132742
[2022-06-09 04:49:34 | train] - Train Epoch: [50] [857600/1281167 (67%)]	Loss: 1.451940
[2022-06-09 04:49:56 | train] - Train Epoch: [50] [870400/1281167 (68%)]	Loss: 1.359140
[2022-06-09 04:50:18 | train] - Train Epoch: [50] [883200/1281167 (69%)]	Loss: 1.110842
[2022-06-09 04:50:40 | train] - Train Epoch: [50] [896000/1281167 (70%)]	Loss: 0.965723
[2022-06-09 04:51:02 | train] - Train Epoch: [50] [908800/1281167 (71%)]	Loss: 1.263670
[2022-06-09 04:51:24 | train] - Train Epoch: [50] [921600/1281167 (72%)]	Loss: 1.617678
[2022-06-09 04:51:47 | train] - Train Epoch: [50] [934400/1281167 (73%)]	Loss: 1.086234
[2022-06-09 04:52:10 | train] - Train Epoch: [50] [947200/1281167 (74%)]	Loss: 0.996244
[2022-06-09 04:52:33 | train] - Train Epoch: [50] [960000/1281167 (75%)]	Loss: 1.400155
[2022-06-09 04:52:56 | train] - Train Epoch: [50] [972800/1281167 (76%)]	Loss: 1.166006
[2022-06-09 04:53:19 | train] - Train Epoch: [50] [985600/1281167 (77%)]	Loss: 1.332420
[2022-06-09 04:53:40 | train] - Train Epoch: [50] [998400/1281167 (78%)]	Loss: 1.576423
[2022-06-09 04:54:02 | train] - Train Epoch: [50] [1011200/1281167 (79%)]	Loss: 1.276371
[2022-06-09 04:54:24 | train] - Train Epoch: [50] [1024000/1281167 (80%)]	Loss: 1.343950
[2022-06-09 04:54:46 | train] - Train Epoch: [50] [1036800/1281167 (81%)]	Loss: 1.030751
[2022-06-09 04:55:08 | train] - Train Epoch: [50] [1049600/1281167 (82%)]	Loss: 1.287736
[2022-06-09 04:55:30 | train] - Train Epoch: [50] [1062400/1281167 (83%)]	Loss: 1.286109
[2022-06-09 04:55:52 | train] - Train Epoch: [50] [1075200/1281167 (84%)]	Loss: 1.389910
[2022-06-09 04:56:13 | train] - Train Epoch: [50] [1088000/1281167 (85%)]	Loss: 1.334999
[2022-06-09 04:56:36 | train] - Train Epoch: [50] [1100800/1281167 (86%)]	Loss: 1.397279
[2022-06-09 04:56:58 | train] - Train Epoch: [50] [1113600/1281167 (87%)]	Loss: 1.030002
[2022-06-09 04:57:20 | train] - Train Epoch: [50] [1126400/1281167 (88%)]	Loss: 1.172728
[2022-06-09 04:57:41 | train] - Train Epoch: [50] [1139200/1281167 (89%)]	Loss: 1.109790
[2022-06-09 04:58:03 | train] - Train Epoch: [50] [1152000/1281167 (90%)]	Loss: 1.155844
[2022-06-09 04:58:25 | train] - Train Epoch: [50] [1164800/1281167 (91%)]	Loss: 1.027696
[2022-06-09 04:58:46 | train] - Train Epoch: [50] [1177600/1281167 (92%)]	Loss: 1.340418
[2022-06-09 04:59:08 | train] - Train Epoch: [50] [1190400/1281167 (93%)]	Loss: 1.077631
[2022-06-09 04:59:30 | train] - Train Epoch: [50] [1203200/1281167 (94%)]	Loss: 1.203365
[2022-06-09 04:59:52 | train] - Train Epoch: [50] [1216000/1281167 (95%)]	Loss: 1.129339
[2022-06-09 05:00:13 | train] - Train Epoch: [50] [1228800/1281167 (96%)]	Loss: 1.246986
[2022-06-09 05:00:36 | train] - Train Epoch: [50] [1241600/1281167 (97%)]	Loss: 1.032146
[2022-06-09 05:00:57 | train] - Train Epoch: [50] [1254400/1281167 (98%)]	Loss: 1.208747
[2022-06-09 05:01:18 | train] - Train Epoch: [50] [1267200/1281167 (99%)]	Loss: 1.461972
[2022-06-09 05:01:40 | train] - Train Epoch: [50] [1280000/1281167 (100%)]	Loss: 1.393705
[2022-06-09 05:01:42 | train] - Train Epoch: [50]	 Average Loss: 1.229144	 Total Acc : 70.3894	 Total Top5 Acc : 88.1486
[2022-06-09 05:01:42 | train] - -------50 epoch end-----------
========================================
-------50 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 05:03:18 | train] - 
Epoch [50] Test set: Average loss: 1.3811, Accuracy: 34097/50000 (68.1598%), Top-5 Accuracy: 87.9088%

[2022-06-09 05:03:18 | train] - save intermediate epoch [50] result


[2022-06-09 05:03:33 | train] - -------51 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 05:03:35 | train] - Train Epoch: [51] [0/1281167 (0%)]	Loss: 1.104129
[2022-06-09 05:03:57 | train] - Train Epoch: [51] [12800/1281167 (1%)]	Loss: 1.333114
[2022-06-09 05:04:19 | train] - Train Epoch: [51] [25600/1281167 (2%)]	Loss: 1.332670
[2022-06-09 05:04:41 | train] - Train Epoch: [51] [38400/1281167 (3%)]	Loss: 1.174851
[2022-06-09 05:05:04 | train] - Train Epoch: [51] [51200/1281167 (4%)]	Loss: 1.305216
[2022-06-09 05:05:26 | train] - Train Epoch: [51] [64000/1281167 (5%)]	Loss: 0.989363
[2022-06-09 05:05:48 | train] - Train Epoch: [51] [76800/1281167 (6%)]	Loss: 1.197982
[2022-06-09 05:06:10 | train] - Train Epoch: [51] [89600/1281167 (7%)]	Loss: 1.071107
[2022-06-09 05:06:32 | train] - Train Epoch: [51] [102400/1281167 (8%)]	Loss: 1.113132
[2022-06-09 05:06:54 | train] - Train Epoch: [51] [115200/1281167 (9%)]	Loss: 1.078943
[2022-06-09 05:07:16 | train] - Train Epoch: [51] [128000/1281167 (10%)]	Loss: 1.463195
[2022-06-09 05:07:38 | train] - Train Epoch: [51] [140800/1281167 (11%)]	Loss: 1.092979
[2022-06-09 05:08:00 | train] - Train Epoch: [51] [153600/1281167 (12%)]	Loss: 1.352443
[2022-06-09 05:08:22 | train] - Train Epoch: [51] [166400/1281167 (13%)]	Loss: 1.234355
[2022-06-09 05:08:44 | train] - Train Epoch: [51] [179200/1281167 (14%)]	Loss: 1.450631
[2022-06-09 05:09:06 | train] - Train Epoch: [51] [192000/1281167 (15%)]	Loss: 1.177490
[2022-06-09 05:09:28 | train] - Train Epoch: [51] [204800/1281167 (16%)]	Loss: 1.070925
[2022-06-09 05:09:49 | train] - Train Epoch: [51] [217600/1281167 (17%)]	Loss: 1.075654
[2022-06-09 05:10:12 | train] - Train Epoch: [51] [230400/1281167 (18%)]	Loss: 1.143866
[2022-06-09 05:10:33 | train] - Train Epoch: [51] [243200/1281167 (19%)]	Loss: 1.048385
[2022-06-09 05:10:56 | train] - Train Epoch: [51] [256000/1281167 (20%)]	Loss: 1.136355
[2022-06-09 05:11:18 | train] - Train Epoch: [51] [268800/1281167 (21%)]	Loss: 1.272697
[2022-06-09 05:11:40 | train] - Train Epoch: [51] [281600/1281167 (22%)]	Loss: 1.157019
[2022-06-09 05:12:02 | train] - Train Epoch: [51] [294400/1281167 (23%)]	Loss: 0.965990
[2022-06-09 05:12:24 | train] - Train Epoch: [51] [307200/1281167 (24%)]	Loss: 1.292973
[2022-06-09 05:12:46 | train] - Train Epoch: [51] [320000/1281167 (25%)]	Loss: 0.904870
[2022-06-09 05:13:08 | train] - Train Epoch: [51] [332800/1281167 (26%)]	Loss: 1.247548
[2022-06-09 05:13:30 | train] - Train Epoch: [51] [345600/1281167 (27%)]	Loss: 1.172056
[2022-06-09 05:13:52 | train] - Train Epoch: [51] [358400/1281167 (28%)]	Loss: 1.113297
[2022-06-09 05:14:15 | train] - Train Epoch: [51] [371200/1281167 (29%)]	Loss: 1.463543
[2022-06-09 05:14:36 | train] - Train Epoch: [51] [384000/1281167 (30%)]	Loss: 1.225930
[2022-06-09 05:14:59 | train] - Train Epoch: [51] [396800/1281167 (31%)]	Loss: 1.076646
[2022-06-09 05:15:21 | train] - Train Epoch: [51] [409600/1281167 (32%)]	Loss: 1.033882
[2022-06-09 05:15:42 | train] - Train Epoch: [51] [422400/1281167 (33%)]	Loss: 1.219624
[2022-06-09 05:16:04 | train] - Train Epoch: [51] [435200/1281167 (34%)]	Loss: 1.259019
[2022-06-09 05:16:26 | train] - Train Epoch: [51] [448000/1281167 (35%)]	Loss: 1.258094
[2022-06-09 05:16:48 | train] - Train Epoch: [51] [460800/1281167 (36%)]	Loss: 1.222820
[2022-06-09 05:17:10 | train] - Train Epoch: [51] [473600/1281167 (37%)]	Loss: 1.368277
[2022-06-09 05:17:32 | train] - Train Epoch: [51] [486400/1281167 (38%)]	Loss: 1.268235
[2022-06-09 05:17:54 | train] - Train Epoch: [51] [499200/1281167 (39%)]	Loss: 1.437437
[2022-06-09 05:18:16 | train] - Train Epoch: [51] [512000/1281167 (40%)]	Loss: 0.924453
[2022-06-09 05:18:38 | train] - Train Epoch: [51] [524800/1281167 (41%)]	Loss: 1.250850
[2022-06-09 05:18:59 | train] - Train Epoch: [51] [537600/1281167 (42%)]	Loss: 1.320497
[2022-06-09 05:19:21 | train] - Train Epoch: [51] [550400/1281167 (43%)]	Loss: 1.064542
[2022-06-09 05:19:43 | train] - Train Epoch: [51] [563200/1281167 (44%)]	Loss: 1.236849
[2022-06-09 05:20:05 | train] - Train Epoch: [51] [576000/1281167 (45%)]	Loss: 0.897522
[2022-06-09 05:20:27 | train] - Train Epoch: [51] [588800/1281167 (46%)]	Loss: 1.639840
[2022-06-09 05:20:49 | train] - Train Epoch: [51] [601600/1281167 (47%)]	Loss: 1.077894
[2022-06-09 05:21:12 | train] - Train Epoch: [51] [614400/1281167 (48%)]	Loss: 1.087876
[2022-06-09 05:21:33 | train] - Train Epoch: [51] [627200/1281167 (49%)]	Loss: 1.174222
[2022-06-09 05:21:55 | train] - Train Epoch: [51] [640000/1281167 (50%)]	Loss: 0.992541
[2022-06-09 05:22:16 | train] - Train Epoch: [51] [652800/1281167 (51%)]	Loss: 1.434717
[2022-06-09 05:22:38 | train] - Train Epoch: [51] [665600/1281167 (52%)]	Loss: 1.216955
[2022-06-09 05:23:00 | train] - Train Epoch: [51] [678400/1281167 (53%)]	Loss: 1.172843
[2022-06-09 05:23:22 | train] - Train Epoch: [51] [691200/1281167 (54%)]	Loss: 1.101714
[2022-06-09 05:23:43 | train] - Train Epoch: [51] [704000/1281167 (55%)]	Loss: 1.326251
[2022-06-09 05:24:06 | train] - Train Epoch: [51] [716800/1281167 (56%)]	Loss: 1.051567
[2022-06-09 05:24:27 | train] - Train Epoch: [51] [729600/1281167 (57%)]	Loss: 1.173689
[2022-06-09 05:24:49 | train] - Train Epoch: [51] [742400/1281167 (58%)]	Loss: 1.226122
[2022-06-09 05:25:11 | train] - Train Epoch: [51] [755200/1281167 (59%)]	Loss: 1.309069
[2022-06-09 05:25:33 | train] - Train Epoch: [51] [768000/1281167 (60%)]	Loss: 1.173856
[2022-06-09 05:25:55 | train] - Train Epoch: [51] [780800/1281167 (61%)]	Loss: 1.361513
[2022-06-09 05:26:17 | train] - Train Epoch: [51] [793600/1281167 (62%)]	Loss: 1.276784
[2022-06-09 05:26:40 | train] - Train Epoch: [51] [806400/1281167 (63%)]	Loss: 1.425608
[2022-06-09 05:27:02 | train] - Train Epoch: [51] [819200/1281167 (64%)]	Loss: 1.204143
[2022-06-09 05:27:24 | train] - Train Epoch: [51] [832000/1281167 (65%)]	Loss: 1.177854
[2022-06-09 05:27:46 | train] - Train Epoch: [51] [844800/1281167 (66%)]	Loss: 1.308768
[2022-06-09 05:28:09 | train] - Train Epoch: [51] [857600/1281167 (67%)]	Loss: 1.091448
[2022-06-09 05:28:31 | train] - Train Epoch: [51] [870400/1281167 (68%)]	Loss: 1.090376
[2022-06-09 05:28:53 | train] - Train Epoch: [51] [883200/1281167 (69%)]	Loss: 1.253311
[2022-06-09 05:29:15 | train] - Train Epoch: [51] [896000/1281167 (70%)]	Loss: 1.437362
[2022-06-09 05:29:38 | train] - Train Epoch: [51] [908800/1281167 (71%)]	Loss: 1.076319
[2022-06-09 05:30:00 | train] - Train Epoch: [51] [921600/1281167 (72%)]	Loss: 1.209107
[2022-06-09 05:30:22 | train] - Train Epoch: [51] [934400/1281167 (73%)]	Loss: 1.285021
[2022-06-09 05:30:44 | train] - Train Epoch: [51] [947200/1281167 (74%)]	Loss: 1.406576
[2022-06-09 05:31:06 | train] - Train Epoch: [51] [960000/1281167 (75%)]	Loss: 1.277907
[2022-06-09 05:31:29 | train] - Train Epoch: [51] [972800/1281167 (76%)]	Loss: 1.144907
[2022-06-09 05:31:50 | train] - Train Epoch: [51] [985600/1281167 (77%)]	Loss: 1.185761
[2022-06-09 05:32:12 | train] - Train Epoch: [51] [998400/1281167 (78%)]	Loss: 1.163645
[2022-06-09 05:32:34 | train] - Train Epoch: [51] [1011200/1281167 (79%)]	Loss: 1.337668
[2022-06-09 05:32:56 | train] - Train Epoch: [51] [1024000/1281167 (80%)]	Loss: 1.579714
[2022-06-09 05:33:18 | train] - Train Epoch: [51] [1036800/1281167 (81%)]	Loss: 0.903672
[2022-06-09 05:33:40 | train] - Train Epoch: [51] [1049600/1281167 (82%)]	Loss: 1.052650
[2022-06-09 05:34:02 | train] - Train Epoch: [51] [1062400/1281167 (83%)]	Loss: 1.156585
[2022-06-09 05:34:24 | train] - Train Epoch: [51] [1075200/1281167 (84%)]	Loss: 1.096825
[2022-06-09 05:34:46 | train] - Train Epoch: [51] [1088000/1281167 (85%)]	Loss: 1.452724
[2022-06-09 05:35:09 | train] - Train Epoch: [51] [1100800/1281167 (86%)]	Loss: 1.192849
[2022-06-09 05:35:31 | train] - Train Epoch: [51] [1113600/1281167 (87%)]	Loss: 0.982842
[2022-06-09 05:35:53 | train] - Train Epoch: [51] [1126400/1281167 (88%)]	Loss: 1.439597
[2022-06-09 05:36:15 | train] - Train Epoch: [51] [1139200/1281167 (89%)]	Loss: 1.337514
[2022-06-09 05:36:38 | train] - Train Epoch: [51] [1152000/1281167 (90%)]	Loss: 1.270996
[2022-06-09 05:37:00 | train] - Train Epoch: [51] [1164800/1281167 (91%)]	Loss: 1.265652
[2022-06-09 05:37:22 | train] - Train Epoch: [51] [1177600/1281167 (92%)]	Loss: 1.171348
[2022-06-09 05:37:44 | train] - Train Epoch: [51] [1190400/1281167 (93%)]	Loss: 1.002039
[2022-06-09 05:38:06 | train] - Train Epoch: [51] [1203200/1281167 (94%)]	Loss: 1.101265
[2022-06-09 05:38:28 | train] - Train Epoch: [51] [1216000/1281167 (95%)]	Loss: 1.207586
[2022-06-09 05:38:51 | train] - Train Epoch: [51] [1228800/1281167 (96%)]	Loss: 1.100319
[2022-06-09 05:39:13 | train] - Train Epoch: [51] [1241600/1281167 (97%)]	Loss: 1.285439
[2022-06-09 05:39:35 | train] - Train Epoch: [51] [1254400/1281167 (98%)]	Loss: 1.147565
[2022-06-09 05:39:57 | train] - Train Epoch: [51] [1267200/1281167 (99%)]	Loss: 1.219799
[2022-06-09 05:40:19 | train] - Train Epoch: [51] [1280000/1281167 (100%)]	Loss: 1.098168
[2022-06-09 05:40:20 | train] - Train Epoch: [51]	 Average Loss: 1.218588	 Total Acc : 70.5641	 Total Top5 Acc : 88.2774
[2022-06-09 05:40:20 | train] - -------51 epoch end-----------
========================================
-------51 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 05:41:55 | train] - 
Epoch [51] Test set: Average loss: 1.3961, Accuracy: 33965/50000 (67.9044%), Top-5 Accuracy: 87.7845%

[2022-06-09 05:41:55 | train] - save intermediate epoch [51] result


[2022-06-09 05:42:08 | train] - -------52 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 05:42:09 | train] - Train Epoch: [52] [0/1281167 (0%)]	Loss: 1.299130
[2022-06-09 05:42:32 | train] - Train Epoch: [52] [12800/1281167 (1%)]	Loss: 1.281817
[2022-06-09 05:42:54 | train] - Train Epoch: [52] [25600/1281167 (2%)]	Loss: 1.409323
[2022-06-09 05:43:16 | train] - Train Epoch: [52] [38400/1281167 (3%)]	Loss: 1.452604
[2022-06-09 05:43:37 | train] - Train Epoch: [52] [51200/1281167 (4%)]	Loss: 1.016920
[2022-06-09 05:43:59 | train] - Train Epoch: [52] [64000/1281167 (5%)]	Loss: 1.145755
[2022-06-09 05:44:20 | train] - Train Epoch: [52] [76800/1281167 (6%)]	Loss: 1.267807
[2022-06-09 05:44:42 | train] - Train Epoch: [52] [89600/1281167 (7%)]	Loss: 1.218702
[2022-06-09 05:45:04 | train] - Train Epoch: [52] [102400/1281167 (8%)]	Loss: 1.089316
[2022-06-09 05:45:26 | train] - Train Epoch: [52] [115200/1281167 (9%)]	Loss: 1.045362
[2022-06-09 05:45:48 | train] - Train Epoch: [52] [128000/1281167 (10%)]	Loss: 1.113186
[2022-06-09 05:46:09 | train] - Train Epoch: [52] [140800/1281167 (11%)]	Loss: 0.962599
[2022-06-09 05:46:31 | train] - Train Epoch: [52] [153600/1281167 (12%)]	Loss: 0.867067
[2022-06-09 05:46:53 | train] - Train Epoch: [52] [166400/1281167 (13%)]	Loss: 1.215081
[2022-06-09 05:47:15 | train] - Train Epoch: [52] [179200/1281167 (14%)]	Loss: 1.112057
[2022-06-09 05:47:36 | train] - Train Epoch: [52] [192000/1281167 (15%)]	Loss: 0.849888
[2022-06-09 05:47:58 | train] - Train Epoch: [52] [204800/1281167 (16%)]	Loss: 1.148415
[2022-06-09 05:48:20 | train] - Train Epoch: [52] [217600/1281167 (17%)]	Loss: 1.538118
[2022-06-09 05:48:41 | train] - Train Epoch: [52] [230400/1281167 (18%)]	Loss: 1.414267
[2022-06-09 05:49:03 | train] - Train Epoch: [52] [243200/1281167 (19%)]	Loss: 0.901357
[2022-06-09 05:49:26 | train] - Train Epoch: [52] [256000/1281167 (20%)]	Loss: 1.115809
[2022-06-09 05:49:48 | train] - Train Epoch: [52] [268800/1281167 (21%)]	Loss: 0.970195
[2022-06-09 05:50:09 | train] - Train Epoch: [52] [281600/1281167 (22%)]	Loss: 1.108883
[2022-06-09 05:50:31 | train] - Train Epoch: [52] [294400/1281167 (23%)]	Loss: 1.306158
[2022-06-09 05:50:53 | train] - Train Epoch: [52] [307200/1281167 (24%)]	Loss: 1.168314
[2022-06-09 05:51:15 | train] - Train Epoch: [52] [320000/1281167 (25%)]	Loss: 1.327973
[2022-06-09 05:51:37 | train] - Train Epoch: [52] [332800/1281167 (26%)]	Loss: 1.215558
[2022-06-09 05:51:58 | train] - Train Epoch: [52] [345600/1281167 (27%)]	Loss: 1.066834
[2022-06-09 05:52:20 | train] - Train Epoch: [52] [358400/1281167 (28%)]	Loss: 0.977548
[2022-06-09 05:52:41 | train] - Train Epoch: [52] [371200/1281167 (29%)]	Loss: 0.948804
[2022-06-09 05:53:03 | train] - Train Epoch: [52] [384000/1281167 (30%)]	Loss: 1.250677
[2022-06-09 05:53:25 | train] - Train Epoch: [52] [396800/1281167 (31%)]	Loss: 1.101635
[2022-06-09 05:53:47 | train] - Train Epoch: [52] [409600/1281167 (32%)]	Loss: 1.205342
[2022-06-09 05:54:09 | train] - Train Epoch: [52] [422400/1281167 (33%)]	Loss: 1.353923
[2022-06-09 05:54:32 | train] - Train Epoch: [52] [435200/1281167 (34%)]	Loss: 1.248645
[2022-06-09 05:54:53 | train] - Train Epoch: [52] [448000/1281167 (35%)]	Loss: 1.255443
[2022-06-09 05:55:14 | train] - Train Epoch: [52] [460800/1281167 (36%)]	Loss: 1.113637
[2022-06-09 05:55:36 | train] - Train Epoch: [52] [473600/1281167 (37%)]	Loss: 1.134364
[2022-06-09 05:55:59 | train] - Train Epoch: [52] [486400/1281167 (38%)]	Loss: 1.073167
[2022-06-09 05:56:21 | train] - Train Epoch: [52] [499200/1281167 (39%)]	Loss: 0.974794
[2022-06-09 05:56:43 | train] - Train Epoch: [52] [512000/1281167 (40%)]	Loss: 1.037883
[2022-06-09 05:57:05 | train] - Train Epoch: [52] [524800/1281167 (41%)]	Loss: 1.425588
[2022-06-09 05:57:27 | train] - Train Epoch: [52] [537600/1281167 (42%)]	Loss: 1.036413
[2022-06-09 05:57:49 | train] - Train Epoch: [52] [550400/1281167 (43%)]	Loss: 0.954585
[2022-06-09 05:58:11 | train] - Train Epoch: [52] [563200/1281167 (44%)]	Loss: 1.594438
[2022-06-09 05:58:33 | train] - Train Epoch: [52] [576000/1281167 (45%)]	Loss: 1.441335
[2022-06-09 05:58:54 | train] - Train Epoch: [52] [588800/1281167 (46%)]	Loss: 1.071905
[2022-06-09 05:59:17 | train] - Train Epoch: [52] [601600/1281167 (47%)]	Loss: 1.392671
[2022-06-09 05:59:39 | train] - Train Epoch: [52] [614400/1281167 (48%)]	Loss: 1.067549
[2022-06-09 06:00:01 | train] - Train Epoch: [52] [627200/1281167 (49%)]	Loss: 1.295565
[2022-06-09 06:00:23 | train] - Train Epoch: [52] [640000/1281167 (50%)]	Loss: 1.091149
[2022-06-09 06:00:45 | train] - Train Epoch: [52] [652800/1281167 (51%)]	Loss: 1.412776
[2022-06-09 06:01:06 | train] - Train Epoch: [52] [665600/1281167 (52%)]	Loss: 1.183565
[2022-06-09 06:01:28 | train] - Train Epoch: [52] [678400/1281167 (53%)]	Loss: 1.228093
[2022-06-09 06:01:50 | train] - Train Epoch: [52] [691200/1281167 (54%)]	Loss: 1.268199
[2022-06-09 06:02:12 | train] - Train Epoch: [52] [704000/1281167 (55%)]	Loss: 1.030980
[2022-06-09 06:02:34 | train] - Train Epoch: [52] [716800/1281167 (56%)]	Loss: 1.277431
[2022-06-09 06:02:56 | train] - Train Epoch: [52] [729600/1281167 (57%)]	Loss: 1.274636
[2022-06-09 06:03:18 | train] - Train Epoch: [52] [742400/1281167 (58%)]	Loss: 1.203775
[2022-06-09 06:03:40 | train] - Train Epoch: [52] [755200/1281167 (59%)]	Loss: 1.162433
[2022-06-09 06:04:01 | train] - Train Epoch: [52] [768000/1281167 (60%)]	Loss: 1.451157
[2022-06-09 06:04:23 | train] - Train Epoch: [52] [780800/1281167 (61%)]	Loss: 1.157760
[2022-06-09 06:04:45 | train] - Train Epoch: [52] [793600/1281167 (62%)]	Loss: 1.152013
[2022-06-09 06:05:06 | train] - Train Epoch: [52] [806400/1281167 (63%)]	Loss: 1.059271
[2022-06-09 06:05:29 | train] - Train Epoch: [52] [819200/1281167 (64%)]	Loss: 1.429716
[2022-06-09 06:05:51 | train] - Train Epoch: [52] [832000/1281167 (65%)]	Loss: 1.342457
[2022-06-09 06:06:13 | train] - Train Epoch: [52] [844800/1281167 (66%)]	Loss: 1.117006
[2022-06-09 06:06:35 | train] - Train Epoch: [52] [857600/1281167 (67%)]	Loss: 1.351865
[2022-06-09 06:06:57 | train] - Train Epoch: [52] [870400/1281167 (68%)]	Loss: 1.253659
[2022-06-09 06:07:19 | train] - Train Epoch: [52] [883200/1281167 (69%)]	Loss: 1.151830
[2022-06-09 06:07:41 | train] - Train Epoch: [52] [896000/1281167 (70%)]	Loss: 1.297705
[2022-06-09 06:08:06 | train] - Train Epoch: [52] [908800/1281167 (71%)]	Loss: 1.063227
[2022-06-09 06:08:32 | train] - Train Epoch: [52] [921600/1281167 (72%)]	Loss: 1.364253
[2022-06-09 06:08:54 | train] - Train Epoch: [52] [934400/1281167 (73%)]	Loss: 1.189692
[2022-06-09 06:09:16 | train] - Train Epoch: [52] [947200/1281167 (74%)]	Loss: 1.282019
[2022-06-09 06:09:38 | train] - Train Epoch: [52] [960000/1281167 (75%)]	Loss: 1.242952
[2022-06-09 06:10:00 | train] - Train Epoch: [52] [972800/1281167 (76%)]	Loss: 1.370678
[2022-06-09 06:10:22 | train] - Train Epoch: [52] [985600/1281167 (77%)]	Loss: 1.282434
[2022-06-09 06:10:44 | train] - Train Epoch: [52] [998400/1281167 (78%)]	Loss: 1.130916
[2022-06-09 06:11:05 | train] - Train Epoch: [52] [1011200/1281167 (79%)]	Loss: 1.399223
[2022-06-09 06:11:27 | train] - Train Epoch: [52] [1024000/1281167 (80%)]	Loss: 1.131449
[2022-06-09 06:11:49 | train] - Train Epoch: [52] [1036800/1281167 (81%)]	Loss: 1.198129
[2022-06-09 06:12:11 | train] - Train Epoch: [52] [1049600/1281167 (82%)]	Loss: 1.057858
[2022-06-09 06:12:33 | train] - Train Epoch: [52] [1062400/1281167 (83%)]	Loss: 1.588969
[2022-06-09 06:12:55 | train] - Train Epoch: [52] [1075200/1281167 (84%)]	Loss: 1.166491
[2022-06-09 06:13:17 | train] - Train Epoch: [52] [1088000/1281167 (85%)]	Loss: 1.088617
[2022-06-09 06:13:39 | train] - Train Epoch: [52] [1100800/1281167 (86%)]	Loss: 1.371799
[2022-06-09 06:14:01 | train] - Train Epoch: [52] [1113600/1281167 (87%)]	Loss: 1.105184
[2022-06-09 06:14:23 | train] - Train Epoch: [52] [1126400/1281167 (88%)]	Loss: 1.081083
[2022-06-09 06:14:45 | train] - Train Epoch: [52] [1139200/1281167 (89%)]	Loss: 1.228062
[2022-06-09 06:15:06 | train] - Train Epoch: [52] [1152000/1281167 (90%)]	Loss: 1.239591
[2022-06-09 06:15:28 | train] - Train Epoch: [52] [1164800/1281167 (91%)]	Loss: 1.170442
[2022-06-09 06:15:50 | train] - Train Epoch: [52] [1177600/1281167 (92%)]	Loss: 1.412124
[2022-06-09 06:16:12 | train] - Train Epoch: [52] [1190400/1281167 (93%)]	Loss: 1.317408
[2022-06-09 06:16:33 | train] - Train Epoch: [52] [1203200/1281167 (94%)]	Loss: 1.664704
[2022-06-09 06:16:55 | train] - Train Epoch: [52] [1216000/1281167 (95%)]	Loss: 1.014957
[2022-06-09 06:17:18 | train] - Train Epoch: [52] [1228800/1281167 (96%)]	Loss: 1.028666
[2022-06-09 06:17:39 | train] - Train Epoch: [52] [1241600/1281167 (97%)]	Loss: 1.021495
[2022-06-09 06:18:02 | train] - Train Epoch: [52] [1254400/1281167 (98%)]	Loss: 1.415014
[2022-06-09 06:18:24 | train] - Train Epoch: [52] [1267200/1281167 (99%)]	Loss: 1.224438
[2022-06-09 06:18:46 | train] - Train Epoch: [52] [1280000/1281167 (100%)]	Loss: 1.165543
[2022-06-09 06:18:48 | train] - Train Epoch: [52]	 Average Loss: 1.209361	 Total Acc : 70.7688	 Total Top5 Acc : 88.4096
[2022-06-09 06:18:48 | train] - -------52 epoch end-----------
========================================
-------52 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 06:20:23 | train] - 
Epoch [52] Test set: Average loss: 1.3765, Accuracy: 34096/50000 (68.1674%), Top-5 Accuracy: 87.9931%

[2022-06-09 06:20:23 | train] - save intermediate epoch [52] result


[2022-06-09 06:20:39 | train] - -------53 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 06:20:40 | train] - Train Epoch: [53] [0/1281167 (0%)]	Loss: 1.023670
[2022-06-09 06:21:02 | train] - Train Epoch: [53] [12800/1281167 (1%)]	Loss: 1.015716
[2022-06-09 06:21:24 | train] - Train Epoch: [53] [25600/1281167 (2%)]	Loss: 0.894952
[2022-06-09 06:21:46 | train] - Train Epoch: [53] [38400/1281167 (3%)]	Loss: 1.254415
[2022-06-09 06:22:08 | train] - Train Epoch: [53] [51200/1281167 (4%)]	Loss: 1.394803
[2022-06-09 06:22:30 | train] - Train Epoch: [53] [64000/1281167 (5%)]	Loss: 1.428072
[2022-06-09 06:22:52 | train] - Train Epoch: [53] [76800/1281167 (6%)]	Loss: 1.282010
[2022-06-09 06:23:14 | train] - Train Epoch: [53] [89600/1281167 (7%)]	Loss: 1.373823
[2022-06-09 06:23:36 | train] - Train Epoch: [53] [102400/1281167 (8%)]	Loss: 0.932973
[2022-06-09 06:23:58 | train] - Train Epoch: [53] [115200/1281167 (9%)]	Loss: 1.177696
[2022-06-09 06:24:19 | train] - Train Epoch: [53] [128000/1281167 (10%)]	Loss: 1.128633
[2022-06-09 06:24:41 | train] - Train Epoch: [53] [140800/1281167 (11%)]	Loss: 1.309981
[2022-06-09 06:25:03 | train] - Train Epoch: [53] [153600/1281167 (12%)]	Loss: 1.355626
[2022-06-09 06:25:25 | train] - Train Epoch: [53] [166400/1281167 (13%)]	Loss: 1.082916
[2022-06-09 06:25:47 | train] - Train Epoch: [53] [179200/1281167 (14%)]	Loss: 1.142606
[2022-06-09 06:26:09 | train] - Train Epoch: [53] [192000/1281167 (15%)]	Loss: 1.159242
[2022-06-09 06:26:31 | train] - Train Epoch: [53] [204800/1281167 (16%)]	Loss: 0.874935
[2022-06-09 06:26:53 | train] - Train Epoch: [53] [217600/1281167 (17%)]	Loss: 1.662593
[2022-06-09 06:27:15 | train] - Train Epoch: [53] [230400/1281167 (18%)]	Loss: 1.234395
[2022-06-09 06:27:37 | train] - Train Epoch: [53] [243200/1281167 (19%)]	Loss: 1.447231
[2022-06-09 06:28:00 | train] - Train Epoch: [53] [256000/1281167 (20%)]	Loss: 1.215599
[2022-06-09 06:28:22 | train] - Train Epoch: [53] [268800/1281167 (21%)]	Loss: 1.329475
[2022-06-09 06:28:44 | train] - Train Epoch: [53] [281600/1281167 (22%)]	Loss: 1.156576
[2022-06-09 06:29:06 | train] - Train Epoch: [53] [294400/1281167 (23%)]	Loss: 0.985351
[2022-06-09 06:29:28 | train] - Train Epoch: [53] [307200/1281167 (24%)]	Loss: 1.122685
[2022-06-09 06:29:50 | train] - Train Epoch: [53] [320000/1281167 (25%)]	Loss: 0.946348
[2022-06-09 06:30:13 | train] - Train Epoch: [53] [332800/1281167 (26%)]	Loss: 1.438573
[2022-06-09 06:30:34 | train] - Train Epoch: [53] [345600/1281167 (27%)]	Loss: 1.237407
[2022-06-09 06:30:56 | train] - Train Epoch: [53] [358400/1281167 (28%)]	Loss: 0.970601
[2022-06-09 06:31:18 | train] - Train Epoch: [53] [371200/1281167 (29%)]	Loss: 1.391541
[2022-06-09 06:31:41 | train] - Train Epoch: [53] [384000/1281167 (30%)]	Loss: 1.301940
[2022-06-09 06:32:03 | train] - Train Epoch: [53] [396800/1281167 (31%)]	Loss: 1.463529
[2022-06-09 06:32:25 | train] - Train Epoch: [53] [409600/1281167 (32%)]	Loss: 1.179790
[2022-06-09 06:32:47 | train] - Train Epoch: [53] [422400/1281167 (33%)]	Loss: 1.235907
[2022-06-09 06:33:09 | train] - Train Epoch: [53] [435200/1281167 (34%)]	Loss: 1.037648
[2022-06-09 06:33:30 | train] - Train Epoch: [53] [448000/1281167 (35%)]	Loss: 0.855039
[2022-06-09 06:33:52 | train] - Train Epoch: [53] [460800/1281167 (36%)]	Loss: 1.559836
[2022-06-09 06:34:14 | train] - Train Epoch: [53] [473600/1281167 (37%)]	Loss: 1.022988
[2022-06-09 06:34:36 | train] - Train Epoch: [53] [486400/1281167 (38%)]	Loss: 1.155189
[2022-06-09 06:34:58 | train] - Train Epoch: [53] [499200/1281167 (39%)]	Loss: 1.180889
[2022-06-09 06:35:20 | train] - Train Epoch: [53] [512000/1281167 (40%)]	Loss: 1.134526
[2022-06-09 06:35:42 | train] - Train Epoch: [53] [524800/1281167 (41%)]	Loss: 1.166667
[2022-06-09 06:36:04 | train] - Train Epoch: [53] [537600/1281167 (42%)]	Loss: 1.132336
[2022-06-09 06:36:26 | train] - Train Epoch: [53] [550400/1281167 (43%)]	Loss: 0.984400
[2022-06-09 06:36:48 | train] - Train Epoch: [53] [563200/1281167 (44%)]	Loss: 1.250107
[2022-06-09 06:37:10 | train] - Train Epoch: [53] [576000/1281167 (45%)]	Loss: 1.173295
[2022-06-09 06:37:32 | train] - Train Epoch: [53] [588800/1281167 (46%)]	Loss: 1.204010
[2022-06-09 06:37:54 | train] - Train Epoch: [53] [601600/1281167 (47%)]	Loss: 1.129420
[2022-06-09 06:38:16 | train] - Train Epoch: [53] [614400/1281167 (48%)]	Loss: 1.399503
[2022-06-09 06:38:39 | train] - Train Epoch: [53] [627200/1281167 (49%)]	Loss: 1.416224
[2022-06-09 06:39:00 | train] - Train Epoch: [53] [640000/1281167 (50%)]	Loss: 1.001152
[2022-06-09 06:39:22 | train] - Train Epoch: [53] [652800/1281167 (51%)]	Loss: 0.908727
[2022-06-09 06:39:44 | train] - Train Epoch: [53] [665600/1281167 (52%)]	Loss: 1.110291
[2022-06-09 06:40:06 | train] - Train Epoch: [53] [678400/1281167 (53%)]	Loss: 1.179716
[2022-06-09 06:40:28 | train] - Train Epoch: [53] [691200/1281167 (54%)]	Loss: 1.202047
[2022-06-09 06:40:50 | train] - Train Epoch: [53] [704000/1281167 (55%)]	Loss: 1.146846
[2022-06-09 06:41:12 | train] - Train Epoch: [53] [716800/1281167 (56%)]	Loss: 1.423883
[2022-06-09 06:41:34 | train] - Train Epoch: [53] [729600/1281167 (57%)]	Loss: 1.427503
[2022-06-09 06:41:56 | train] - Train Epoch: [53] [742400/1281167 (58%)]	Loss: 0.935270
[2022-06-09 06:42:18 | train] - Train Epoch: [53] [755200/1281167 (59%)]	Loss: 1.228815
[2022-06-09 06:42:40 | train] - Train Epoch: [53] [768000/1281167 (60%)]	Loss: 1.498870
[2022-06-09 06:43:02 | train] - Train Epoch: [53] [780800/1281167 (61%)]	Loss: 1.284482
[2022-06-09 06:43:24 | train] - Train Epoch: [53] [793600/1281167 (62%)]	Loss: 1.193840
[2022-06-09 06:43:45 | train] - Train Epoch: [53] [806400/1281167 (63%)]	Loss: 1.313359
[2022-06-09 06:44:08 | train] - Train Epoch: [53] [819200/1281167 (64%)]	Loss: 1.358016
[2022-06-09 06:44:30 | train] - Train Epoch: [53] [832000/1281167 (65%)]	Loss: 1.147312
[2022-06-09 06:44:52 | train] - Train Epoch: [53] [844800/1281167 (66%)]	Loss: 0.972257
[2022-06-09 06:45:15 | train] - Train Epoch: [53] [857600/1281167 (67%)]	Loss: 1.257392
[2022-06-09 06:45:36 | train] - Train Epoch: [53] [870400/1281167 (68%)]	Loss: 1.240703
[2022-06-09 06:45:58 | train] - Train Epoch: [53] [883200/1281167 (69%)]	Loss: 1.507252
[2022-06-09 06:46:20 | train] - Train Epoch: [53] [896000/1281167 (70%)]	Loss: 1.044825
[2022-06-09 06:46:43 | train] - Train Epoch: [53] [908800/1281167 (71%)]	Loss: 0.949526
[2022-06-09 06:47:05 | train] - Train Epoch: [53] [921600/1281167 (72%)]	Loss: 1.018457
[2022-06-09 06:47:27 | train] - Train Epoch: [53] [934400/1281167 (73%)]	Loss: 1.027995
[2022-06-09 06:47:49 | train] - Train Epoch: [53] [947200/1281167 (74%)]	Loss: 0.988611
[2022-06-09 06:48:11 | train] - Train Epoch: [53] [960000/1281167 (75%)]	Loss: 1.182569
[2022-06-09 06:48:33 | train] - Train Epoch: [53] [972800/1281167 (76%)]	Loss: 1.118773
[2022-06-09 06:48:55 | train] - Train Epoch: [53] [985600/1281167 (77%)]	Loss: 0.874348
[2022-06-09 06:49:17 | train] - Train Epoch: [53] [998400/1281167 (78%)]	Loss: 1.287826
[2022-06-09 06:49:39 | train] - Train Epoch: [53] [1011200/1281167 (79%)]	Loss: 0.938076
[2022-06-09 06:50:01 | train] - Train Epoch: [53] [1024000/1281167 (80%)]	Loss: 1.255225
[2022-06-09 06:50:23 | train] - Train Epoch: [53] [1036800/1281167 (81%)]	Loss: 1.352386
[2022-06-09 06:50:45 | train] - Train Epoch: [53] [1049600/1281167 (82%)]	Loss: 1.561629
[2022-06-09 06:51:07 | train] - Train Epoch: [53] [1062400/1281167 (83%)]	Loss: 1.107965
[2022-06-09 06:51:29 | train] - Train Epoch: [53] [1075200/1281167 (84%)]	Loss: 1.203084
[2022-06-09 06:51:51 | train] - Train Epoch: [53] [1088000/1281167 (85%)]	Loss: 1.331979
[2022-06-09 06:52:12 | train] - Train Epoch: [53] [1100800/1281167 (86%)]	Loss: 1.237524
[2022-06-09 06:52:35 | train] - Train Epoch: [53] [1113600/1281167 (87%)]	Loss: 1.010894
[2022-06-09 06:52:57 | train] - Train Epoch: [53] [1126400/1281167 (88%)]	Loss: 1.305883
[2022-06-09 06:53:18 | train] - Train Epoch: [53] [1139200/1281167 (89%)]	Loss: 1.019367
[2022-06-09 06:53:41 | train] - Train Epoch: [53] [1152000/1281167 (90%)]	Loss: 1.301231
[2022-06-09 06:54:03 | train] - Train Epoch: [53] [1164800/1281167 (91%)]	Loss: 1.339588
[2022-06-09 06:54:25 | train] - Train Epoch: [53] [1177600/1281167 (92%)]	Loss: 1.702727
[2022-06-09 06:54:47 | train] - Train Epoch: [53] [1190400/1281167 (93%)]	Loss: 1.562252
[2022-06-09 06:55:09 | train] - Train Epoch: [53] [1203200/1281167 (94%)]	Loss: 1.290888
[2022-06-09 06:55:31 | train] - Train Epoch: [53] [1216000/1281167 (95%)]	Loss: 1.308548
[2022-06-09 06:55:53 | train] - Train Epoch: [53] [1228800/1281167 (96%)]	Loss: 1.309841
[2022-06-09 06:56:15 | train] - Train Epoch: [53] [1241600/1281167 (97%)]	Loss: 0.976033
[2022-06-09 06:56:37 | train] - Train Epoch: [53] [1254400/1281167 (98%)]	Loss: 1.112144
[2022-06-09 06:57:00 | train] - Train Epoch: [53] [1267200/1281167 (99%)]	Loss: 1.897038
[2022-06-09 06:57:21 | train] - Train Epoch: [53] [1280000/1281167 (100%)]	Loss: 1.149980
[2022-06-09 06:57:23 | train] - Train Epoch: [53]	 Average Loss: 1.201092	 Total Acc : 70.9578	 Total Top5 Acc : 88.4998
[2022-06-09 06:57:23 | train] - -------53 epoch end-----------
========================================
-------53 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 06:58:59 | train] - 
Epoch [53] Test set: Average loss: 1.3769, Accuracy: 34088/50000 (68.1442%), Top-5 Accuracy: 88.0507%

[2022-06-09 06:58:59 | train] - save intermediate epoch [53] result


[2022-06-09 06:59:14 | train] - -------54 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 06:59:15 | train] - Train Epoch: [54] [0/1281167 (0%)]	Loss: 0.936814
[2022-06-09 06:59:38 | train] - Train Epoch: [54] [12800/1281167 (1%)]	Loss: 0.874660
[2022-06-09 07:00:00 | train] - Train Epoch: [54] [25600/1281167 (2%)]	Loss: 1.248664
[2022-06-09 07:00:22 | train] - Train Epoch: [54] [38400/1281167 (3%)]	Loss: 1.416163
[2022-06-09 07:00:45 | train] - Train Epoch: [54] [51200/1281167 (4%)]	Loss: 1.047122
[2022-06-09 07:01:07 | train] - Train Epoch: [54] [64000/1281167 (5%)]	Loss: 1.063282
[2022-06-09 07:01:29 | train] - Train Epoch: [54] [76800/1281167 (6%)]	Loss: 1.245413
[2022-06-09 07:01:51 | train] - Train Epoch: [54] [89600/1281167 (7%)]	Loss: 1.217174
[2022-06-09 07:02:13 | train] - Train Epoch: [54] [102400/1281167 (8%)]	Loss: 1.268707
[2022-06-09 07:02:35 | train] - Train Epoch: [54] [115200/1281167 (9%)]	Loss: 1.111754
[2022-06-09 07:02:58 | train] - Train Epoch: [54] [128000/1281167 (10%)]	Loss: 1.163832
[2022-06-09 07:03:20 | train] - Train Epoch: [54] [140800/1281167 (11%)]	Loss: 1.134769
[2022-06-09 07:03:42 | train] - Train Epoch: [54] [153600/1281167 (12%)]	Loss: 1.048425
[2022-06-09 07:04:04 | train] - Train Epoch: [54] [166400/1281167 (13%)]	Loss: 1.212074
[2022-06-09 07:04:27 | train] - Train Epoch: [54] [179200/1281167 (14%)]	Loss: 1.241100
[2022-06-09 07:04:49 | train] - Train Epoch: [54] [192000/1281167 (15%)]	Loss: 1.249059
[2022-06-09 07:05:12 | train] - Train Epoch: [54] [204800/1281167 (16%)]	Loss: 1.029625
[2022-06-09 07:05:35 | train] - Train Epoch: [54] [217600/1281167 (17%)]	Loss: 0.928484
[2022-06-09 07:05:57 | train] - Train Epoch: [54] [230400/1281167 (18%)]	Loss: 1.221781
[2022-06-09 07:06:20 | train] - Train Epoch: [54] [243200/1281167 (19%)]	Loss: 1.253690
[2022-06-09 07:06:42 | train] - Train Epoch: [54] [256000/1281167 (20%)]	Loss: 1.077837
[2022-06-09 07:07:04 | train] - Train Epoch: [54] [268800/1281167 (21%)]	Loss: 1.080391
[2022-06-09 07:07:27 | train] - Train Epoch: [54] [281600/1281167 (22%)]	Loss: 1.213579
[2022-06-09 07:07:49 | train] - Train Epoch: [54] [294400/1281167 (23%)]	Loss: 1.209053
[2022-06-09 07:08:11 | train] - Train Epoch: [54] [307200/1281167 (24%)]	Loss: 1.020758
[2022-06-09 07:08:33 | train] - Train Epoch: [54] [320000/1281167 (25%)]	Loss: 1.242444
[2022-06-09 07:08:56 | train] - Train Epoch: [54] [332800/1281167 (26%)]	Loss: 1.350842
[2022-06-09 07:09:17 | train] - Train Epoch: [54] [345600/1281167 (27%)]	Loss: 1.125182
[2022-06-09 07:09:40 | train] - Train Epoch: [54] [358400/1281167 (28%)]	Loss: 0.852170
[2022-06-09 07:10:01 | train] - Train Epoch: [54] [371200/1281167 (29%)]	Loss: 1.215983
[2022-06-09 07:10:24 | train] - Train Epoch: [54] [384000/1281167 (30%)]	Loss: 1.119656
[2022-06-09 07:10:46 | train] - Train Epoch: [54] [396800/1281167 (31%)]	Loss: 1.021896
[2022-06-09 07:11:08 | train] - Train Epoch: [54] [409600/1281167 (32%)]	Loss: 1.149996
[2022-06-09 07:11:30 | train] - Train Epoch: [54] [422400/1281167 (33%)]	Loss: 1.214154
[2022-06-09 07:11:51 | train] - Train Epoch: [54] [435200/1281167 (34%)]	Loss: 1.358209
[2022-06-09 07:12:14 | train] - Train Epoch: [54] [448000/1281167 (35%)]	Loss: 0.992273
[2022-06-09 07:12:36 | train] - Train Epoch: [54] [460800/1281167 (36%)]	Loss: 1.349353
[2022-06-09 07:12:58 | train] - Train Epoch: [54] [473600/1281167 (37%)]	Loss: 1.244660
[2022-06-09 07:13:21 | train] - Train Epoch: [54] [486400/1281167 (38%)]	Loss: 1.456438
[2022-06-09 07:13:43 | train] - Train Epoch: [54] [499200/1281167 (39%)]	Loss: 1.282579
[2022-06-09 07:14:05 | train] - Train Epoch: [54] [512000/1281167 (40%)]	Loss: 1.129961
[2022-06-09 07:14:27 | train] - Train Epoch: [54] [524800/1281167 (41%)]	Loss: 1.224988
[2022-06-09 07:14:49 | train] - Train Epoch: [54] [537600/1281167 (42%)]	Loss: 1.097662
[2022-06-09 07:15:11 | train] - Train Epoch: [54] [550400/1281167 (43%)]	Loss: 0.970912
[2022-06-09 07:15:33 | train] - Train Epoch: [54] [563200/1281167 (44%)]	Loss: 0.913509
[2022-06-09 07:15:56 | train] - Train Epoch: [54] [576000/1281167 (45%)]	Loss: 1.064696
[2022-06-09 07:16:18 | train] - Train Epoch: [54] [588800/1281167 (46%)]	Loss: 1.257219
[2022-06-09 07:16:41 | train] - Train Epoch: [54] [601600/1281167 (47%)]	Loss: 0.971748
[2022-06-09 07:17:03 | train] - Train Epoch: [54] [614400/1281167 (48%)]	Loss: 1.434791
[2022-06-09 07:17:25 | train] - Train Epoch: [54] [627200/1281167 (49%)]	Loss: 1.132079
[2022-06-09 07:17:47 | train] - Train Epoch: [54] [640000/1281167 (50%)]	Loss: 1.170915
[2022-06-09 07:18:09 | train] - Train Epoch: [54] [652800/1281167 (51%)]	Loss: 1.392139
[2022-06-09 07:18:32 | train] - Train Epoch: [54] [665600/1281167 (52%)]	Loss: 1.147060
[2022-06-09 07:18:55 | train] - Train Epoch: [54] [678400/1281167 (53%)]	Loss: 1.137063
[2022-06-09 07:19:17 | train] - Train Epoch: [54] [691200/1281167 (54%)]	Loss: 1.184719
[2022-06-09 07:19:39 | train] - Train Epoch: [54] [704000/1281167 (55%)]	Loss: 1.041789
[2022-06-09 07:20:00 | train] - Train Epoch: [54] [716800/1281167 (56%)]	Loss: 1.200390
[2022-06-09 07:20:23 | train] - Train Epoch: [54] [729600/1281167 (57%)]	Loss: 1.222391
[2022-06-09 07:20:45 | train] - Train Epoch: [54] [742400/1281167 (58%)]	Loss: 0.924452
[2022-06-09 07:21:07 | train] - Train Epoch: [54] [755200/1281167 (59%)]	Loss: 1.021771
[2022-06-09 07:21:30 | train] - Train Epoch: [54] [768000/1281167 (60%)]	Loss: 1.025354
[2022-06-09 07:21:53 | train] - Train Epoch: [54] [780800/1281167 (61%)]	Loss: 1.398554
[2022-06-09 07:22:15 | train] - Train Epoch: [54] [793600/1281167 (62%)]	Loss: 1.365898
[2022-06-09 07:22:37 | train] - Train Epoch: [54] [806400/1281167 (63%)]	Loss: 1.306931
[2022-06-09 07:23:00 | train] - Train Epoch: [54] [819200/1281167 (64%)]	Loss: 1.119970
[2022-06-09 07:23:23 | train] - Train Epoch: [54] [832000/1281167 (65%)]	Loss: 1.109674
[2022-06-09 07:23:45 | train] - Train Epoch: [54] [844800/1281167 (66%)]	Loss: 1.005614
[2022-06-09 07:24:07 | train] - Train Epoch: [54] [857600/1281167 (67%)]	Loss: 1.290329
[2022-06-09 07:24:29 | train] - Train Epoch: [54] [870400/1281167 (68%)]	Loss: 1.319623
[2022-06-09 07:24:52 | train] - Train Epoch: [54] [883200/1281167 (69%)]	Loss: 1.586165
[2022-06-09 07:25:15 | train] - Train Epoch: [54] [896000/1281167 (70%)]	Loss: 0.987102
[2022-06-09 07:25:37 | train] - Train Epoch: [54] [908800/1281167 (71%)]	Loss: 1.257048
[2022-06-09 07:25:59 | train] - Train Epoch: [54] [921600/1281167 (72%)]	Loss: 1.005852
[2022-06-09 07:26:22 | train] - Train Epoch: [54] [934400/1281167 (73%)]	Loss: 1.073526
[2022-06-09 07:26:44 | train] - Train Epoch: [54] [947200/1281167 (74%)]	Loss: 1.407161
[2022-06-09 07:27:05 | train] - Train Epoch: [54] [960000/1281167 (75%)]	Loss: 1.148839
[2022-06-09 07:27:28 | train] - Train Epoch: [54] [972800/1281167 (76%)]	Loss: 1.262445
[2022-06-09 07:27:50 | train] - Train Epoch: [54] [985600/1281167 (77%)]	Loss: 0.965849
[2022-06-09 07:28:13 | train] - Train Epoch: [54] [998400/1281167 (78%)]	Loss: 0.856676
[2022-06-09 07:28:34 | train] - Train Epoch: [54] [1011200/1281167 (79%)]	Loss: 1.201887
[2022-06-09 07:28:57 | train] - Train Epoch: [54] [1024000/1281167 (80%)]	Loss: 1.239616
[2022-06-09 07:29:19 | train] - Train Epoch: [54] [1036800/1281167 (81%)]	Loss: 1.490756
[2022-06-09 07:29:42 | train] - Train Epoch: [54] [1049600/1281167 (82%)]	Loss: 1.065623
[2022-06-09 07:30:04 | train] - Train Epoch: [54] [1062400/1281167 (83%)]	Loss: 1.233948
[2022-06-09 07:30:26 | train] - Train Epoch: [54] [1075200/1281167 (84%)]	Loss: 1.252264
[2022-06-09 07:30:48 | train] - Train Epoch: [54] [1088000/1281167 (85%)]	Loss: 1.394806
[2022-06-09 07:31:10 | train] - Train Epoch: [54] [1100800/1281167 (86%)]	Loss: 1.154106
[2022-06-09 07:31:33 | train] - Train Epoch: [54] [1113600/1281167 (87%)]	Loss: 1.242199
[2022-06-09 07:31:55 | train] - Train Epoch: [54] [1126400/1281167 (88%)]	Loss: 1.251644
[2022-06-09 07:32:17 | train] - Train Epoch: [54] [1139200/1281167 (89%)]	Loss: 1.399857
[2022-06-09 07:32:40 | train] - Train Epoch: [54] [1152000/1281167 (90%)]	Loss: 1.269566
[2022-06-09 07:33:02 | train] - Train Epoch: [54] [1164800/1281167 (91%)]	Loss: 1.345775
[2022-06-09 07:33:24 | train] - Train Epoch: [54] [1177600/1281167 (92%)]	Loss: 1.165596
[2022-06-09 07:33:47 | train] - Train Epoch: [54] [1190400/1281167 (93%)]	Loss: 1.153483
[2022-06-09 07:34:09 | train] - Train Epoch: [54] [1203200/1281167 (94%)]	Loss: 1.505745
[2022-06-09 07:34:31 | train] - Train Epoch: [54] [1216000/1281167 (95%)]	Loss: 0.953212
[2022-06-09 07:34:53 | train] - Train Epoch: [54] [1228800/1281167 (96%)]	Loss: 1.093978
[2022-06-09 07:35:15 | train] - Train Epoch: [54] [1241600/1281167 (97%)]	Loss: 1.261038
[2022-06-09 07:35:38 | train] - Train Epoch: [54] [1254400/1281167 (98%)]	Loss: 1.144784
[2022-06-09 07:36:00 | train] - Train Epoch: [54] [1267200/1281167 (99%)]	Loss: 1.022694
[2022-06-09 07:36:23 | train] - Train Epoch: [54] [1280000/1281167 (100%)]	Loss: 1.238728
[2022-06-09 07:36:24 | train] - Train Epoch: [54]	 Average Loss: 1.190132	 Total Acc : 71.1848	 Total Top5 Acc : 88.6419
[2022-06-09 07:36:24 | train] - -------54 epoch end-----------
========================================
-------54 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 07:37:59 | train] - 
Epoch [54] Test set: Average loss: 1.3705, Accuracy: 34173/50000 (68.3164%), Top-5 Accuracy: 88.1893%

[2022-06-09 07:37:59 | train] - save intermediate epoch [54] result


[2022-06-09 07:38:13 | train] - logging best performance 54 epoch
[2022-06-09 07:38:14 | train] - -------55 epoch start-----------
========================================
----- test end -------------------------


logging best performance 54 epoch
[2022-06-09 07:38:16 | train] - Train Epoch: [55] [0/1281167 (0%)]	Loss: 1.145932
[2022-06-09 07:38:38 | train] - Train Epoch: [55] [12800/1281167 (1%)]	Loss: 1.108543
[2022-06-09 07:39:00 | train] - Train Epoch: [55] [25600/1281167 (2%)]	Loss: 1.196924
[2022-06-09 07:39:22 | train] - Train Epoch: [55] [38400/1281167 (3%)]	Loss: 1.495759
[2022-06-09 07:39:44 | train] - Train Epoch: [55] [51200/1281167 (4%)]	Loss: 1.197737
[2022-06-09 07:40:06 | train] - Train Epoch: [55] [64000/1281167 (5%)]	Loss: 1.155409
[2022-06-09 07:40:27 | train] - Train Epoch: [55] [76800/1281167 (6%)]	Loss: 1.069542
[2022-06-09 07:40:49 | train] - Train Epoch: [55] [89600/1281167 (7%)]	Loss: 1.111122
[2022-06-09 07:41:12 | train] - Train Epoch: [55] [102400/1281167 (8%)]	Loss: 1.155026
[2022-06-09 07:41:34 | train] - Train Epoch: [55] [115200/1281167 (9%)]	Loss: 1.198398
[2022-06-09 07:41:56 | train] - Train Epoch: [55] [128000/1281167 (10%)]	Loss: 1.006779
[2022-06-09 07:42:18 | train] - Train Epoch: [55] [140800/1281167 (11%)]	Loss: 0.934977
[2022-06-09 07:42:40 | train] - Train Epoch: [55] [153600/1281167 (12%)]	Loss: 1.622672
[2022-06-09 07:43:02 | train] - Train Epoch: [55] [166400/1281167 (13%)]	Loss: 1.010547
[2022-06-09 07:43:24 | train] - Train Epoch: [55] [179200/1281167 (14%)]	Loss: 1.136978
[2022-06-09 07:43:47 | train] - Train Epoch: [55] [192000/1281167 (15%)]	Loss: 1.121899
[2022-06-09 07:44:09 | train] - Train Epoch: [55] [204800/1281167 (16%)]	Loss: 0.905647
[2022-06-09 07:44:30 | train] - Train Epoch: [55] [217600/1281167 (17%)]	Loss: 1.239574
[2022-06-09 07:44:53 | train] - Train Epoch: [55] [230400/1281167 (18%)]	Loss: 1.011856
[2022-06-09 07:45:15 | train] - Train Epoch: [55] [243200/1281167 (19%)]	Loss: 1.055218
[2022-06-09 07:45:37 | train] - Train Epoch: [55] [256000/1281167 (20%)]	Loss: 1.522307
[2022-06-09 07:45:59 | train] - Train Epoch: [55] [268800/1281167 (21%)]	Loss: 1.153185
[2022-06-09 07:46:21 | train] - Train Epoch: [55] [281600/1281167 (22%)]	Loss: 1.111428
[2022-06-09 07:46:43 | train] - Train Epoch: [55] [294400/1281167 (23%)]	Loss: 1.317087
[2022-06-09 07:47:05 | train] - Train Epoch: [55] [307200/1281167 (24%)]	Loss: 1.091601
[2022-06-09 07:47:27 | train] - Train Epoch: [55] [320000/1281167 (25%)]	Loss: 1.243880
[2022-06-09 07:47:49 | train] - Train Epoch: [55] [332800/1281167 (26%)]	Loss: 1.111854
[2022-06-09 07:48:10 | train] - Train Epoch: [55] [345600/1281167 (27%)]	Loss: 0.885142
[2022-06-09 07:48:32 | train] - Train Epoch: [55] [358400/1281167 (28%)]	Loss: 1.034617
[2022-06-09 07:48:55 | train] - Train Epoch: [55] [371200/1281167 (29%)]	Loss: 1.307724
[2022-06-09 07:49:16 | train] - Train Epoch: [55] [384000/1281167 (30%)]	Loss: 1.226014
[2022-06-09 07:49:39 | train] - Train Epoch: [55] [396800/1281167 (31%)]	Loss: 0.814554
[2022-06-09 07:50:00 | train] - Train Epoch: [55] [409600/1281167 (32%)]	Loss: 1.149529
[2022-06-09 07:50:23 | train] - Train Epoch: [55] [422400/1281167 (33%)]	Loss: 0.988345
[2022-06-09 07:50:45 | train] - Train Epoch: [55] [435200/1281167 (34%)]	Loss: 1.311791
[2022-06-09 07:51:07 | train] - Train Epoch: [55] [448000/1281167 (35%)]	Loss: 1.627641
[2022-06-09 07:51:29 | train] - Train Epoch: [55] [460800/1281167 (36%)]	Loss: 1.144709
[2022-06-09 07:51:51 | train] - Train Epoch: [55] [473600/1281167 (37%)]	Loss: 1.211790
[2022-06-09 07:52:13 | train] - Train Epoch: [55] [486400/1281167 (38%)]	Loss: 1.148477
[2022-06-09 07:52:35 | train] - Train Epoch: [55] [499200/1281167 (39%)]	Loss: 0.970231
[2022-06-09 07:52:57 | train] - Train Epoch: [55] [512000/1281167 (40%)]	Loss: 1.353208
[2022-06-09 07:53:19 | train] - Train Epoch: [55] [524800/1281167 (41%)]	Loss: 1.189139
[2022-06-09 07:53:41 | train] - Train Epoch: [55] [537600/1281167 (42%)]	Loss: 1.331690
[2022-06-09 07:54:02 | train] - Train Epoch: [55] [550400/1281167 (43%)]	Loss: 1.460569
[2022-06-09 07:54:25 | train] - Train Epoch: [55] [563200/1281167 (44%)]	Loss: 1.021179
[2022-06-09 07:54:47 | train] - Train Epoch: [55] [576000/1281167 (45%)]	Loss: 1.236004
[2022-06-09 07:55:09 | train] - Train Epoch: [55] [588800/1281167 (46%)]	Loss: 1.286125
[2022-06-09 07:55:31 | train] - Train Epoch: [55] [601600/1281167 (47%)]	Loss: 1.230850
[2022-06-09 07:55:52 | train] - Train Epoch: [55] [614400/1281167 (48%)]	Loss: 1.315115
[2022-06-09 07:56:15 | train] - Train Epoch: [55] [627200/1281167 (49%)]	Loss: 1.104391
[2022-06-09 07:56:36 | train] - Train Epoch: [55] [640000/1281167 (50%)]	Loss: 1.376905
[2022-06-09 07:56:58 | train] - Train Epoch: [55] [652800/1281167 (51%)]	Loss: 1.455980
[2022-06-09 07:57:20 | train] - Train Epoch: [55] [665600/1281167 (52%)]	Loss: 1.115794
[2022-06-09 07:57:42 | train] - Train Epoch: [55] [678400/1281167 (53%)]	Loss: 1.316391
[2022-06-09 07:58:04 | train] - Train Epoch: [55] [691200/1281167 (54%)]	Loss: 1.027334
[2022-06-09 07:58:26 | train] - Train Epoch: [55] [704000/1281167 (55%)]	Loss: 0.965694
[2022-06-09 07:58:48 | train] - Train Epoch: [55] [716800/1281167 (56%)]	Loss: 1.233862
[2022-06-09 07:59:11 | train] - Train Epoch: [55] [729600/1281167 (57%)]	Loss: 0.959515
[2022-06-09 07:59:32 | train] - Train Epoch: [55] [742400/1281167 (58%)]	Loss: 1.194738
[2022-06-09 07:59:55 | train] - Train Epoch: [55] [755200/1281167 (59%)]	Loss: 1.253597
[2022-06-09 08:00:17 | train] - Train Epoch: [55] [768000/1281167 (60%)]	Loss: 0.974623
[2022-06-09 08:00:39 | train] - Train Epoch: [55] [780800/1281167 (61%)]	Loss: 1.451326
[2022-06-09 08:01:01 | train] - Train Epoch: [55] [793600/1281167 (62%)]	Loss: 1.160031
[2022-06-09 08:01:22 | train] - Train Epoch: [55] [806400/1281167 (63%)]	Loss: 1.058151
[2022-06-09 08:01:44 | train] - Train Epoch: [55] [819200/1281167 (64%)]	Loss: 1.593490
[2022-06-09 08:02:06 | train] - Train Epoch: [55] [832000/1281167 (65%)]	Loss: 0.979331
[2022-06-09 08:02:28 | train] - Train Epoch: [55] [844800/1281167 (66%)]	Loss: 1.291288
[2022-06-09 08:02:50 | train] - Train Epoch: [55] [857600/1281167 (67%)]	Loss: 1.279881
[2022-06-09 08:03:12 | train] - Train Epoch: [55] [870400/1281167 (68%)]	Loss: 1.287974
[2022-06-09 08:03:34 | train] - Train Epoch: [55] [883200/1281167 (69%)]	Loss: 1.054901
[2022-06-09 08:03:57 | train] - Train Epoch: [55] [896000/1281167 (70%)]	Loss: 1.293686
[2022-06-09 08:04:18 | train] - Train Epoch: [55] [908800/1281167 (71%)]	Loss: 1.154493
[2022-06-09 08:04:40 | train] - Train Epoch: [55] [921600/1281167 (72%)]	Loss: 1.416553
[2022-06-09 08:05:03 | train] - Train Epoch: [55] [934400/1281167 (73%)]	Loss: 1.090664
[2022-06-09 08:05:25 | train] - Train Epoch: [55] [947200/1281167 (74%)]	Loss: 1.401371
[2022-06-09 08:05:47 | train] - Train Epoch: [55] [960000/1281167 (75%)]	Loss: 1.261438
[2022-06-09 08:06:09 | train] - Train Epoch: [55] [972800/1281167 (76%)]	Loss: 1.098244
[2022-06-09 08:06:31 | train] - Train Epoch: [55] [985600/1281167 (77%)]	Loss: 1.306947
[2022-06-09 08:06:53 | train] - Train Epoch: [55] [998400/1281167 (78%)]	Loss: 1.219582
[2022-06-09 08:07:15 | train] - Train Epoch: [55] [1011200/1281167 (79%)]	Loss: 1.181283
[2022-06-09 08:07:37 | train] - Train Epoch: [55] [1024000/1281167 (80%)]	Loss: 0.961010
[2022-06-09 08:07:59 | train] - Train Epoch: [55] [1036800/1281167 (81%)]	Loss: 1.127123
[2022-06-09 08:08:21 | train] - Train Epoch: [55] [1049600/1281167 (82%)]	Loss: 0.682035
[2022-06-09 08:08:43 | train] - Train Epoch: [55] [1062400/1281167 (83%)]	Loss: 1.414146
[2022-06-09 08:09:06 | train] - Train Epoch: [55] [1075200/1281167 (84%)]	Loss: 0.957390
[2022-06-09 08:09:27 | train] - Train Epoch: [55] [1088000/1281167 (85%)]	Loss: 1.582531
[2022-06-09 08:09:49 | train] - Train Epoch: [55] [1100800/1281167 (86%)]	Loss: 1.186023
[2022-06-09 08:10:11 | train] - Train Epoch: [55] [1113600/1281167 (87%)]	Loss: 1.463963
[2022-06-09 08:10:33 | train] - Train Epoch: [55] [1126400/1281167 (88%)]	Loss: 1.306046
[2022-06-09 08:10:54 | train] - Train Epoch: [55] [1139200/1281167 (89%)]	Loss: 1.438675
[2022-06-09 08:11:17 | train] - Train Epoch: [55] [1152000/1281167 (90%)]	Loss: 1.138794
[2022-06-09 08:11:39 | train] - Train Epoch: [55] [1164800/1281167 (91%)]	Loss: 1.445731
[2022-06-09 08:12:01 | train] - Train Epoch: [55] [1177600/1281167 (92%)]	Loss: 1.193628
[2022-06-09 08:12:23 | train] - Train Epoch: [55] [1190400/1281167 (93%)]	Loss: 1.072328
[2022-06-09 08:12:44 | train] - Train Epoch: [55] [1203200/1281167 (94%)]	Loss: 1.249228
[2022-06-09 08:13:06 | train] - Train Epoch: [55] [1216000/1281167 (95%)]	Loss: 1.280647
[2022-06-09 08:13:28 | train] - Train Epoch: [55] [1228800/1281167 (96%)]	Loss: 1.229019
[2022-06-09 08:13:50 | train] - Train Epoch: [55] [1241600/1281167 (97%)]	Loss: 1.512959
[2022-06-09 08:14:12 | train] - Train Epoch: [55] [1254400/1281167 (98%)]	Loss: 1.179579
[2022-06-09 08:14:34 | train] - Train Epoch: [55] [1267200/1281167 (99%)]	Loss: 1.197220
[2022-06-09 08:14:56 | train] - Train Epoch: [55] [1280000/1281167 (100%)]	Loss: 1.270767
[2022-06-09 08:14:57 | train] - Train Epoch: [55]	 Average Loss: 1.180123	 Total Acc : 71.4054	 Total Top5 Acc : 88.7608
[2022-06-09 08:14:57 | train] - -------55 epoch end-----------
========================================
-------55 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 08:16:31 | train] - 
Epoch [55] Test set: Average loss: 1.3659, Accuracy: 34262/50000 (68.5038%), Top-5 Accuracy: 88.2237%

[2022-06-09 08:16:31 | train] - save intermediate epoch [55] result


[2022-06-09 08:16:44 | train] - logging best performance 55 epoch
[2022-06-09 08:16:45 | train] - -------56 epoch start-----------
========================================
----- test end -------------------------


logging best performance 55 epoch
[2022-06-09 08:16:47 | train] - Train Epoch: [56] [0/1281167 (0%)]	Loss: 0.855919
[2022-06-09 08:17:09 | train] - Train Epoch: [56] [12800/1281167 (1%)]	Loss: 1.166141
[2022-06-09 08:17:31 | train] - Train Epoch: [56] [25600/1281167 (2%)]	Loss: 0.949724
[2022-06-09 08:17:53 | train] - Train Epoch: [56] [38400/1281167 (3%)]	Loss: 1.193048
[2022-06-09 08:18:15 | train] - Train Epoch: [56] [51200/1281167 (4%)]	Loss: 1.299406
[2022-06-09 08:18:37 | train] - Train Epoch: [56] [64000/1281167 (5%)]	Loss: 1.166677
[2022-06-09 08:19:00 | train] - Train Epoch: [56] [76800/1281167 (6%)]	Loss: 1.445583
[2022-06-09 08:19:22 | train] - Train Epoch: [56] [89600/1281167 (7%)]	Loss: 1.191529
[2022-06-09 08:19:44 | train] - Train Epoch: [56] [102400/1281167 (8%)]	Loss: 1.057599
[2022-06-09 08:20:06 | train] - Train Epoch: [56] [115200/1281167 (9%)]	Loss: 1.191014
[2022-06-09 08:20:29 | train] - Train Epoch: [56] [128000/1281167 (10%)]	Loss: 0.895287
[2022-06-09 08:20:51 | train] - Train Epoch: [56] [140800/1281167 (11%)]	Loss: 1.227987
[2022-06-09 08:21:13 | train] - Train Epoch: [56] [153600/1281167 (12%)]	Loss: 1.491209
[2022-06-09 08:21:35 | train] - Train Epoch: [56] [166400/1281167 (13%)]	Loss: 0.862518
[2022-06-09 08:21:58 | train] - Train Epoch: [56] [179200/1281167 (14%)]	Loss: 1.412587
[2022-06-09 08:22:20 | train] - Train Epoch: [56] [192000/1281167 (15%)]	Loss: 1.506119
[2022-06-09 08:22:42 | train] - Train Epoch: [56] [204800/1281167 (16%)]	Loss: 1.115081
[2022-06-09 08:23:04 | train] - Train Epoch: [56] [217600/1281167 (17%)]	Loss: 0.899055
[2022-06-09 08:23:26 | train] - Train Epoch: [56] [230400/1281167 (18%)]	Loss: 0.974087
[2022-06-09 08:23:48 | train] - Train Epoch: [56] [243200/1281167 (19%)]	Loss: 1.465275
[2022-06-09 08:24:10 | train] - Train Epoch: [56] [256000/1281167 (20%)]	Loss: 0.940460
[2022-06-09 08:24:32 | train] - Train Epoch: [56] [268800/1281167 (21%)]	Loss: 1.146393
[2022-06-09 08:24:54 | train] - Train Epoch: [56] [281600/1281167 (22%)]	Loss: 1.102048
[2022-06-09 08:25:17 | train] - Train Epoch: [56] [294400/1281167 (23%)]	Loss: 0.931171
[2022-06-09 08:25:39 | train] - Train Epoch: [56] [307200/1281167 (24%)]	Loss: 1.111399
[2022-06-09 08:26:01 | train] - Train Epoch: [56] [320000/1281167 (25%)]	Loss: 1.326014
[2022-06-09 08:26:23 | train] - Train Epoch: [56] [332800/1281167 (26%)]	Loss: 1.059425
[2022-06-09 08:26:45 | train] - Train Epoch: [56] [345600/1281167 (27%)]	Loss: 1.400670
[2022-06-09 08:27:08 | train] - Train Epoch: [56] [358400/1281167 (28%)]	Loss: 0.979062
[2022-06-09 08:27:30 | train] - Train Epoch: [56] [371200/1281167 (29%)]	Loss: 1.167505
[2022-06-09 08:27:53 | train] - Train Epoch: [56] [384000/1281167 (30%)]	Loss: 1.125683
[2022-06-09 08:28:15 | train] - Train Epoch: [56] [396800/1281167 (31%)]	Loss: 1.027269
[2022-06-09 08:28:37 | train] - Train Epoch: [56] [409600/1281167 (32%)]	Loss: 1.260875
[2022-06-09 08:29:00 | train] - Train Epoch: [56] [422400/1281167 (33%)]	Loss: 1.334640
[2022-06-09 08:29:21 | train] - Train Epoch: [56] [435200/1281167 (34%)]	Loss: 1.119694
[2022-06-09 08:29:44 | train] - Train Epoch: [56] [448000/1281167 (35%)]	Loss: 1.244512
[2022-06-09 08:30:06 | train] - Train Epoch: [56] [460800/1281167 (36%)]	Loss: 0.943258
[2022-06-09 08:30:28 | train] - Train Epoch: [56] [473600/1281167 (37%)]	Loss: 0.861118
[2022-06-09 08:30:50 | train] - Train Epoch: [56] [486400/1281167 (38%)]	Loss: 1.220520
[2022-06-09 08:31:12 | train] - Train Epoch: [56] [499200/1281167 (39%)]	Loss: 0.942820
[2022-06-09 08:31:34 | train] - Train Epoch: [56] [512000/1281167 (40%)]	Loss: 1.119491
[2022-06-09 08:31:56 | train] - Train Epoch: [56] [524800/1281167 (41%)]	Loss: 1.195577
[2022-06-09 08:32:18 | train] - Train Epoch: [56] [537600/1281167 (42%)]	Loss: 1.159101
[2022-06-09 08:32:41 | train] - Train Epoch: [56] [550400/1281167 (43%)]	Loss: 1.214247
[2022-06-09 08:33:03 | train] - Train Epoch: [56] [563200/1281167 (44%)]	Loss: 0.986723
[2022-06-09 08:33:25 | train] - Train Epoch: [56] [576000/1281167 (45%)]	Loss: 1.109552
[2022-06-09 08:33:48 | train] - Train Epoch: [56] [588800/1281167 (46%)]	Loss: 1.187167
[2022-06-09 08:34:10 | train] - Train Epoch: [56] [601600/1281167 (47%)]	Loss: 1.358167
[2022-06-09 08:34:33 | train] - Train Epoch: [56] [614400/1281167 (48%)]	Loss: 1.035937
[2022-06-09 08:34:55 | train] - Train Epoch: [56] [627200/1281167 (49%)]	Loss: 0.933765
[2022-06-09 08:35:17 | train] - Train Epoch: [56] [640000/1281167 (50%)]	Loss: 1.479450
[2022-06-09 08:35:40 | train] - Train Epoch: [56] [652800/1281167 (51%)]	Loss: 1.288682
[2022-06-09 08:36:01 | train] - Train Epoch: [56] [665600/1281167 (52%)]	Loss: 1.262265
[2022-06-09 08:36:24 | train] - Train Epoch: [56] [678400/1281167 (53%)]	Loss: 1.556011
[2022-06-09 08:36:46 | train] - Train Epoch: [56] [691200/1281167 (54%)]	Loss: 0.953254
[2022-06-09 08:37:09 | train] - Train Epoch: [56] [704000/1281167 (55%)]	Loss: 0.991598
[2022-06-09 08:37:31 | train] - Train Epoch: [56] [716800/1281167 (56%)]	Loss: 1.367380
[2022-06-09 08:37:53 | train] - Train Epoch: [56] [729600/1281167 (57%)]	Loss: 1.343394
[2022-06-09 08:38:15 | train] - Train Epoch: [56] [742400/1281167 (58%)]	Loss: 1.217040
[2022-06-09 08:38:37 | train] - Train Epoch: [56] [755200/1281167 (59%)]	Loss: 1.139634
[2022-06-09 08:38:59 | train] - Train Epoch: [56] [768000/1281167 (60%)]	Loss: 1.212311
[2022-06-09 08:39:21 | train] - Train Epoch: [56] [780800/1281167 (61%)]	Loss: 1.229954
[2022-06-09 08:39:44 | train] - Train Epoch: [56] [793600/1281167 (62%)]	Loss: 1.029663
[2022-06-09 08:40:06 | train] - Train Epoch: [56] [806400/1281167 (63%)]	Loss: 1.462537
[2022-06-09 08:40:29 | train] - Train Epoch: [56] [819200/1281167 (64%)]	Loss: 1.150993
[2022-06-09 08:40:51 | train] - Train Epoch: [56] [832000/1281167 (65%)]	Loss: 1.059287
[2022-06-09 08:41:13 | train] - Train Epoch: [56] [844800/1281167 (66%)]	Loss: 0.958280
[2022-06-09 08:41:36 | train] - Train Epoch: [56] [857600/1281167 (67%)]	Loss: 0.983791
[2022-06-09 08:41:58 | train] - Train Epoch: [56] [870400/1281167 (68%)]	Loss: 0.860560
[2022-06-09 08:42:20 | train] - Train Epoch: [56] [883200/1281167 (69%)]	Loss: 0.991169
[2022-06-09 08:42:42 | train] - Train Epoch: [56] [896000/1281167 (70%)]	Loss: 0.941472
[2022-06-09 08:43:04 | train] - Train Epoch: [56] [908800/1281167 (71%)]	Loss: 1.447414
[2022-06-09 08:43:26 | train] - Train Epoch: [56] [921600/1281167 (72%)]	Loss: 1.035167
[2022-06-09 08:43:48 | train] - Train Epoch: [56] [934400/1281167 (73%)]	Loss: 1.165255
[2022-06-09 08:44:11 | train] - Train Epoch: [56] [947200/1281167 (74%)]	Loss: 0.905165
[2022-06-09 08:44:33 | train] - Train Epoch: [56] [960000/1281167 (75%)]	Loss: 1.042901
[2022-06-09 08:44:55 | train] - Train Epoch: [56] [972800/1281167 (76%)]	Loss: 1.158572
[2022-06-09 08:45:17 | train] - Train Epoch: [56] [985600/1281167 (77%)]	Loss: 1.167065
[2022-06-09 08:45:39 | train] - Train Epoch: [56] [998400/1281167 (78%)]	Loss: 0.952408
[2022-06-09 08:46:01 | train] - Train Epoch: [56] [1011200/1281167 (79%)]	Loss: 1.227660
[2022-06-09 08:46:24 | train] - Train Epoch: [56] [1024000/1281167 (80%)]	Loss: 0.931720
[2022-06-09 08:46:46 | train] - Train Epoch: [56] [1036800/1281167 (81%)]	Loss: 1.131420
[2022-06-09 08:47:08 | train] - Train Epoch: [56] [1049600/1281167 (82%)]	Loss: 1.032513
[2022-06-09 08:47:30 | train] - Train Epoch: [56] [1062400/1281167 (83%)]	Loss: 1.539993
[2022-06-09 08:47:53 | train] - Train Epoch: [56] [1075200/1281167 (84%)]	Loss: 1.118693
[2022-06-09 08:48:15 | train] - Train Epoch: [56] [1088000/1281167 (85%)]	Loss: 1.447881
[2022-06-09 08:48:37 | train] - Train Epoch: [56] [1100800/1281167 (86%)]	Loss: 1.380975
[2022-06-09 08:49:00 | train] - Train Epoch: [56] [1113600/1281167 (87%)]	Loss: 1.039935
[2022-06-09 08:49:22 | train] - Train Epoch: [56] [1126400/1281167 (88%)]	Loss: 1.280576
[2022-06-09 08:49:44 | train] - Train Epoch: [56] [1139200/1281167 (89%)]	Loss: 1.293775
[2022-06-09 08:50:07 | train] - Train Epoch: [56] [1152000/1281167 (90%)]	Loss: 1.290452
[2022-06-09 08:50:28 | train] - Train Epoch: [56] [1164800/1281167 (91%)]	Loss: 1.487556
[2022-06-09 08:50:51 | train] - Train Epoch: [56] [1177600/1281167 (92%)]	Loss: 1.259744
[2022-06-09 08:51:13 | train] - Train Epoch: [56] [1190400/1281167 (93%)]	Loss: 1.313993
[2022-06-09 08:51:35 | train] - Train Epoch: [56] [1203200/1281167 (94%)]	Loss: 1.193094
[2022-06-09 08:51:57 | train] - Train Epoch: [56] [1216000/1281167 (95%)]	Loss: 1.150727
[2022-06-09 08:52:20 | train] - Train Epoch: [56] [1228800/1281167 (96%)]	Loss: 1.051996
[2022-06-09 08:52:42 | train] - Train Epoch: [56] [1241600/1281167 (97%)]	Loss: 1.236759
[2022-06-09 08:53:04 | train] - Train Epoch: [56] [1254400/1281167 (98%)]	Loss: 1.143565
[2022-06-09 08:53:26 | train] - Train Epoch: [56] [1267200/1281167 (99%)]	Loss: 1.230032
[2022-06-09 08:53:49 | train] - Train Epoch: [56] [1280000/1281167 (100%)]	Loss: 1.029511
[2022-06-09 08:53:51 | train] - Train Epoch: [56]	 Average Loss: 1.171406	 Total Acc : 71.5939	 Total Top5 Acc : 88.8882
[2022-06-09 08:53:51 | train] - -------56 epoch end-----------
========================================
-------56 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 08:55:26 | train] - 
Epoch [56] Test set: Average loss: 1.3682, Accuracy: 34122/50000 (68.2145%), Top-5 Accuracy: 88.1526%

[2022-06-09 08:55:26 | train] - save intermediate epoch [56] result


[2022-06-09 08:55:41 | train] - -------57 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 08:55:43 | train] - Train Epoch: [57] [0/1281167 (0%)]	Loss: 1.148476
[2022-06-09 08:56:05 | train] - Train Epoch: [57] [12800/1281167 (1%)]	Loss: 0.968735
[2022-06-09 08:56:27 | train] - Train Epoch: [57] [25600/1281167 (2%)]	Loss: 1.210191
[2022-06-09 08:56:49 | train] - Train Epoch: [57] [38400/1281167 (3%)]	Loss: 1.174614
[2022-06-09 08:57:11 | train] - Train Epoch: [57] [51200/1281167 (4%)]	Loss: 0.911861
[2022-06-09 08:57:34 | train] - Train Epoch: [57] [64000/1281167 (5%)]	Loss: 1.218829
[2022-06-09 08:57:55 | train] - Train Epoch: [57] [76800/1281167 (6%)]	Loss: 1.238420
[2022-06-09 08:58:17 | train] - Train Epoch: [57] [89600/1281167 (7%)]	Loss: 1.484076
[2022-06-09 08:58:39 | train] - Train Epoch: [57] [102400/1281167 (8%)]	Loss: 1.456393
[2022-06-09 08:59:01 | train] - Train Epoch: [57] [115200/1281167 (9%)]	Loss: 1.259916
[2022-06-09 08:59:24 | train] - Train Epoch: [57] [128000/1281167 (10%)]	Loss: 1.121459
[2022-06-09 08:59:46 | train] - Train Epoch: [57] [140800/1281167 (11%)]	Loss: 1.119054
[2022-06-09 09:00:08 | train] - Train Epoch: [57] [153600/1281167 (12%)]	Loss: 0.837816
[2022-06-09 09:00:30 | train] - Train Epoch: [57] [166400/1281167 (13%)]	Loss: 0.982115
[2022-06-09 09:00:52 | train] - Train Epoch: [57] [179200/1281167 (14%)]	Loss: 1.111877
[2022-06-09 09:01:15 | train] - Train Epoch: [57] [192000/1281167 (15%)]	Loss: 0.970575
[2022-06-09 09:01:36 | train] - Train Epoch: [57] [204800/1281167 (16%)]	Loss: 0.986689
[2022-06-09 09:01:59 | train] - Train Epoch: [57] [217600/1281167 (17%)]	Loss: 1.148745
[2022-06-09 09:02:21 | train] - Train Epoch: [57] [230400/1281167 (18%)]	Loss: 0.953274
[2022-06-09 09:02:43 | train] - Train Epoch: [57] [243200/1281167 (19%)]	Loss: 1.347164
[2022-06-09 09:03:05 | train] - Train Epoch: [57] [256000/1281167 (20%)]	Loss: 1.167546
[2022-06-09 09:03:28 | train] - Train Epoch: [57] [268800/1281167 (21%)]	Loss: 1.047439
[2022-06-09 09:03:50 | train] - Train Epoch: [57] [281600/1281167 (22%)]	Loss: 1.202015
[2022-06-09 09:04:12 | train] - Train Epoch: [57] [294400/1281167 (23%)]	Loss: 0.938548
[2022-06-09 09:04:35 | train] - Train Epoch: [57] [307200/1281167 (24%)]	Loss: 1.105467
[2022-06-09 09:04:57 | train] - Train Epoch: [57] [320000/1281167 (25%)]	Loss: 1.219514
[2022-06-09 09:05:19 | train] - Train Epoch: [57] [332800/1281167 (26%)]	Loss: 1.215737
[2022-06-09 09:05:41 | train] - Train Epoch: [57] [345600/1281167 (27%)]	Loss: 1.765728
[2022-06-09 09:06:04 | train] - Train Epoch: [57] [358400/1281167 (28%)]	Loss: 1.234473
[2022-06-09 09:06:26 | train] - Train Epoch: [57] [371200/1281167 (29%)]	Loss: 1.186098
[2022-06-09 09:06:49 | train] - Train Epoch: [57] [384000/1281167 (30%)]	Loss: 1.222064
[2022-06-09 09:07:11 | train] - Train Epoch: [57] [396800/1281167 (31%)]	Loss: 1.455336
[2022-06-09 09:07:33 | train] - Train Epoch: [57] [409600/1281167 (32%)]	Loss: 1.186108
[2022-06-09 09:07:56 | train] - Train Epoch: [57] [422400/1281167 (33%)]	Loss: 1.302374
[2022-06-09 09:08:17 | train] - Train Epoch: [57] [435200/1281167 (34%)]	Loss: 1.433033
[2022-06-09 09:08:40 | train] - Train Epoch: [57] [448000/1281167 (35%)]	Loss: 1.606749
[2022-06-09 09:09:02 | train] - Train Epoch: [57] [460800/1281167 (36%)]	Loss: 0.774956
[2022-06-09 09:09:24 | train] - Train Epoch: [57] [473600/1281167 (37%)]	Loss: 1.106610
[2022-06-09 09:09:46 | train] - Train Epoch: [57] [486400/1281167 (38%)]	Loss: 1.269145
[2022-06-09 09:10:08 | train] - Train Epoch: [57] [499200/1281167 (39%)]	Loss: 1.426400
[2022-06-09 09:10:30 | train] - Train Epoch: [57] [512000/1281167 (40%)]	Loss: 1.309195
[2022-06-09 09:10:52 | train] - Train Epoch: [57] [524800/1281167 (41%)]	Loss: 1.504942
[2022-06-09 09:11:14 | train] - Train Epoch: [57] [537600/1281167 (42%)]	Loss: 1.385732
[2022-06-09 09:11:37 | train] - Train Epoch: [57] [550400/1281167 (43%)]	Loss: 1.397283
[2022-06-09 09:12:00 | train] - Train Epoch: [57] [563200/1281167 (44%)]	Loss: 1.061275
[2022-06-09 09:12:22 | train] - Train Epoch: [57] [576000/1281167 (45%)]	Loss: 1.177939
[2022-06-09 09:12:44 | train] - Train Epoch: [57] [588800/1281167 (46%)]	Loss: 1.210658
[2022-06-09 09:13:06 | train] - Train Epoch: [57] [601600/1281167 (47%)]	Loss: 1.144190
[2022-06-09 09:13:28 | train] - Train Epoch: [57] [614400/1281167 (48%)]	Loss: 1.300026
[2022-06-09 09:13:50 | train] - Train Epoch: [57] [627200/1281167 (49%)]	Loss: 1.054398
[2022-06-09 09:14:12 | train] - Train Epoch: [57] [640000/1281167 (50%)]	Loss: 1.197165
[2022-06-09 09:14:35 | train] - Train Epoch: [57] [652800/1281167 (51%)]	Loss: 1.239412
[2022-06-09 09:14:57 | train] - Train Epoch: [57] [665600/1281167 (52%)]	Loss: 0.944887
[2022-06-09 09:15:19 | train] - Train Epoch: [57] [678400/1281167 (53%)]	Loss: 0.841780
[2022-06-09 09:15:41 | train] - Train Epoch: [57] [691200/1281167 (54%)]	Loss: 1.011719
[2022-06-09 09:16:04 | train] - Train Epoch: [57] [704000/1281167 (55%)]	Loss: 0.905019
[2022-06-09 09:16:26 | train] - Train Epoch: [57] [716800/1281167 (56%)]	Loss: 1.069966
[2022-06-09 09:16:48 | train] - Train Epoch: [57] [729600/1281167 (57%)]	Loss: 1.029976
[2022-06-09 09:17:10 | train] - Train Epoch: [57] [742400/1281167 (58%)]	Loss: 1.152182
[2022-06-09 09:17:32 | train] - Train Epoch: [57] [755200/1281167 (59%)]	Loss: 1.025189
[2022-06-09 09:17:55 | train] - Train Epoch: [57] [768000/1281167 (60%)]	Loss: 1.075225
[2022-06-09 09:18:17 | train] - Train Epoch: [57] [780800/1281167 (61%)]	Loss: 1.253348
[2022-06-09 09:18:40 | train] - Train Epoch: [57] [793600/1281167 (62%)]	Loss: 1.165049
[2022-06-09 09:19:02 | train] - Train Epoch: [57] [806400/1281167 (63%)]	Loss: 1.119590
[2022-06-09 09:19:25 | train] - Train Epoch: [57] [819200/1281167 (64%)]	Loss: 1.175142
[2022-06-09 09:19:47 | train] - Train Epoch: [57] [832000/1281167 (65%)]	Loss: 1.294165
[2022-06-09 09:20:08 | train] - Train Epoch: [57] [844800/1281167 (66%)]	Loss: 1.371706
[2022-06-09 09:20:31 | train] - Train Epoch: [57] [857600/1281167 (67%)]	Loss: 1.394483
[2022-06-09 09:20:53 | train] - Train Epoch: [57] [870400/1281167 (68%)]	Loss: 1.217687
[2022-06-09 09:21:16 | train] - Train Epoch: [57] [883200/1281167 (69%)]	Loss: 0.930792
[2022-06-09 09:21:39 | train] - Train Epoch: [57] [896000/1281167 (70%)]	Loss: 1.224580
[2022-06-09 09:22:01 | train] - Train Epoch: [57] [908800/1281167 (71%)]	Loss: 1.410938
[2022-06-09 09:22:23 | train] - Train Epoch: [57] [921600/1281167 (72%)]	Loss: 1.141221
[2022-06-09 09:22:46 | train] - Train Epoch: [57] [934400/1281167 (73%)]	Loss: 0.914826
[2022-06-09 09:23:08 | train] - Train Epoch: [57] [947200/1281167 (74%)]	Loss: 1.025629
[2022-06-09 09:23:30 | train] - Train Epoch: [57] [960000/1281167 (75%)]	Loss: 1.190345
[2022-06-09 09:23:52 | train] - Train Epoch: [57] [972800/1281167 (76%)]	Loss: 1.326871
[2022-06-09 09:24:15 | train] - Train Epoch: [57] [985600/1281167 (77%)]	Loss: 1.548326
[2022-06-09 09:24:37 | train] - Train Epoch: [57] [998400/1281167 (78%)]	Loss: 1.323203
[2022-06-09 09:24:59 | train] - Train Epoch: [57] [1011200/1281167 (79%)]	Loss: 1.291983
[2022-06-09 09:25:22 | train] - Train Epoch: [57] [1024000/1281167 (80%)]	Loss: 1.130750
[2022-06-09 09:25:44 | train] - Train Epoch: [57] [1036800/1281167 (81%)]	Loss: 1.165566
[2022-06-09 09:26:06 | train] - Train Epoch: [57] [1049600/1281167 (82%)]	Loss: 0.957790
[2022-06-09 09:26:29 | train] - Train Epoch: [57] [1062400/1281167 (83%)]	Loss: 1.281748
[2022-06-09 09:26:51 | train] - Train Epoch: [57] [1075200/1281167 (84%)]	Loss: 1.143589
[2022-06-09 09:27:13 | train] - Train Epoch: [57] [1088000/1281167 (85%)]	Loss: 0.879500
[2022-06-09 09:27:35 | train] - Train Epoch: [57] [1100800/1281167 (86%)]	Loss: 1.164181
[2022-06-09 09:27:56 | train] - Train Epoch: [57] [1113600/1281167 (87%)]	Loss: 1.157693
[2022-06-09 09:28:18 | train] - Train Epoch: [57] [1126400/1281167 (88%)]	Loss: 1.395649
[2022-06-09 09:28:41 | train] - Train Epoch: [57] [1139200/1281167 (89%)]	Loss: 1.243186
[2022-06-09 09:29:02 | train] - Train Epoch: [57] [1152000/1281167 (90%)]	Loss: 1.382577
[2022-06-09 09:29:25 | train] - Train Epoch: [57] [1164800/1281167 (91%)]	Loss: 1.117583
[2022-06-09 09:29:47 | train] - Train Epoch: [57] [1177600/1281167 (92%)]	Loss: 1.202241
[2022-06-09 09:30:09 | train] - Train Epoch: [57] [1190400/1281167 (93%)]	Loss: 1.206343
[2022-06-09 09:30:32 | train] - Train Epoch: [57] [1203200/1281167 (94%)]	Loss: 1.385469
[2022-06-09 09:30:54 | train] - Train Epoch: [57] [1216000/1281167 (95%)]	Loss: 0.912837
[2022-06-09 09:31:16 | train] - Train Epoch: [57] [1228800/1281167 (96%)]	Loss: 1.206653
[2022-06-09 09:31:38 | train] - Train Epoch: [57] [1241600/1281167 (97%)]	Loss: 1.255589
[2022-06-09 09:32:01 | train] - Train Epoch: [57] [1254400/1281167 (98%)]	Loss: 1.136336
[2022-06-09 09:32:23 | train] - Train Epoch: [57] [1267200/1281167 (99%)]	Loss: 1.088397
[2022-06-09 09:32:46 | train] - Train Epoch: [57] [1280000/1281167 (100%)]	Loss: 1.137527
[2022-06-09 09:32:47 | train] - Train Epoch: [57]	 Average Loss: 1.163551	 Total Acc : 71.7757	 Total Top5 Acc : 88.9599
[2022-06-09 09:32:47 | train] - -------57 epoch end-----------
========================================
-------57 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 09:34:23 | train] - 
Epoch [57] Test set: Average loss: 1.3624, Accuracy: 34248/50000 (68.4615%), Top-5 Accuracy: 88.1266%

[2022-06-09 09:34:23 | train] - save intermediate epoch [57] result


[2022-06-09 09:34:38 | train] - -------58 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 09:34:40 | train] - Train Epoch: [58] [0/1281167 (0%)]	Loss: 0.877877
[2022-06-09 09:35:02 | train] - Train Epoch: [58] [12800/1281167 (1%)]	Loss: 1.111825
[2022-06-09 09:35:24 | train] - Train Epoch: [58] [25600/1281167 (2%)]	Loss: 1.107054
[2022-06-09 09:35:46 | train] - Train Epoch: [58] [38400/1281167 (3%)]	Loss: 1.065663
[2022-06-09 09:36:08 | train] - Train Epoch: [58] [51200/1281167 (4%)]	Loss: 1.034639
[2022-06-09 09:36:31 | train] - Train Epoch: [58] [64000/1281167 (5%)]	Loss: 1.531707
[2022-06-09 09:36:53 | train] - Train Epoch: [58] [76800/1281167 (6%)]	Loss: 1.015220
[2022-06-09 09:37:15 | train] - Train Epoch: [58] [89600/1281167 (7%)]	Loss: 0.908255
[2022-06-09 09:37:37 | train] - Train Epoch: [58] [102400/1281167 (8%)]	Loss: 1.100235
[2022-06-09 09:37:59 | train] - Train Epoch: [58] [115200/1281167 (9%)]	Loss: 1.256486
[2022-06-09 09:38:21 | train] - Train Epoch: [58] [128000/1281167 (10%)]	Loss: 1.029939
[2022-06-09 09:38:43 | train] - Train Epoch: [58] [140800/1281167 (11%)]	Loss: 1.125237
[2022-06-09 09:39:05 | train] - Train Epoch: [58] [153600/1281167 (12%)]	Loss: 1.669816
[2022-06-09 09:39:27 | train] - Train Epoch: [58] [166400/1281167 (13%)]	Loss: 0.957170
[2022-06-09 09:39:49 | train] - Train Epoch: [58] [179200/1281167 (14%)]	Loss: 1.220976
[2022-06-09 09:40:11 | train] - Train Epoch: [58] [192000/1281167 (15%)]	Loss: 1.162565
[2022-06-09 09:40:34 | train] - Train Epoch: [58] [204800/1281167 (16%)]	Loss: 1.378108
[2022-06-09 09:40:56 | train] - Train Epoch: [58] [217600/1281167 (17%)]	Loss: 0.854258
[2022-06-09 09:41:18 | train] - Train Epoch: [58] [230400/1281167 (18%)]	Loss: 1.056568
[2022-06-09 09:41:41 | train] - Train Epoch: [58] [243200/1281167 (19%)]	Loss: 1.060702
[2022-06-09 09:42:04 | train] - Train Epoch: [58] [256000/1281167 (20%)]	Loss: 0.819474
[2022-06-09 09:42:25 | train] - Train Epoch: [58] [268800/1281167 (21%)]	Loss: 1.445443
[2022-06-09 09:42:48 | train] - Train Epoch: [58] [281600/1281167 (22%)]	Loss: 0.981080
[2022-06-09 09:43:11 | train] - Train Epoch: [58] [294400/1281167 (23%)]	Loss: 1.198969
[2022-06-09 09:43:33 | train] - Train Epoch: [58] [307200/1281167 (24%)]	Loss: 1.031930
[2022-06-09 09:43:56 | train] - Train Epoch: [58] [320000/1281167 (25%)]	Loss: 1.397050
[2022-06-09 09:44:18 | train] - Train Epoch: [58] [332800/1281167 (26%)]	Loss: 1.140558
[2022-06-09 09:44:40 | train] - Train Epoch: [58] [345600/1281167 (27%)]	Loss: 1.443879
[2022-06-09 09:45:02 | train] - Train Epoch: [58] [358400/1281167 (28%)]	Loss: 1.203482
[2022-06-09 09:45:25 | train] - Train Epoch: [58] [371200/1281167 (29%)]	Loss: 1.112304
[2022-06-09 09:45:47 | train] - Train Epoch: [58] [384000/1281167 (30%)]	Loss: 1.422100
[2022-06-09 09:46:10 | train] - Train Epoch: [58] [396800/1281167 (31%)]	Loss: 1.045382
[2022-06-09 09:46:32 | train] - Train Epoch: [58] [409600/1281167 (32%)]	Loss: 1.137688
[2022-06-09 09:46:54 | train] - Train Epoch: [58] [422400/1281167 (33%)]	Loss: 1.267213
[2022-06-09 09:47:16 | train] - Train Epoch: [58] [435200/1281167 (34%)]	Loss: 1.157557
[2022-06-09 09:47:38 | train] - Train Epoch: [58] [448000/1281167 (35%)]	Loss: 1.339819
[2022-06-09 09:48:00 | train] - Train Epoch: [58] [460800/1281167 (36%)]	Loss: 1.016852
[2022-06-09 09:48:23 | train] - Train Epoch: [58] [473600/1281167 (37%)]	Loss: 1.112464
[2022-06-09 09:48:45 | train] - Train Epoch: [58] [486400/1281167 (38%)]	Loss: 1.089993
[2022-06-09 09:49:07 | train] - Train Epoch: [58] [499200/1281167 (39%)]	Loss: 0.924978
[2022-06-09 09:49:29 | train] - Train Epoch: [58] [512000/1281167 (40%)]	Loss: 0.935822
[2022-06-09 09:49:52 | train] - Train Epoch: [58] [524800/1281167 (41%)]	Loss: 1.061982
[2022-06-09 09:50:15 | train] - Train Epoch: [58] [537600/1281167 (42%)]	Loss: 1.128409
[2022-06-09 09:50:37 | train] - Train Epoch: [58] [550400/1281167 (43%)]	Loss: 1.183280
[2022-06-09 09:50:59 | train] - Train Epoch: [58] [563200/1281167 (44%)]	Loss: 1.008916
[2022-06-09 09:51:21 | train] - Train Epoch: [58] [576000/1281167 (45%)]	Loss: 1.017136
[2022-06-09 09:51:43 | train] - Train Epoch: [58] [588800/1281167 (46%)]	Loss: 1.326621
[2022-06-09 09:52:06 | train] - Train Epoch: [58] [601600/1281167 (47%)]	Loss: 1.429108
[2022-06-09 09:52:28 | train] - Train Epoch: [58] [614400/1281167 (48%)]	Loss: 0.889671
[2022-06-09 09:52:51 | train] - Train Epoch: [58] [627200/1281167 (49%)]	Loss: 1.146535
[2022-06-09 09:53:13 | train] - Train Epoch: [58] [640000/1281167 (50%)]	Loss: 1.128090
[2022-06-09 09:53:35 | train] - Train Epoch: [58] [652800/1281167 (51%)]	Loss: 1.344851
[2022-06-09 09:53:56 | train] - Train Epoch: [58] [665600/1281167 (52%)]	Loss: 1.035753
[2022-06-09 09:54:19 | train] - Train Epoch: [58] [678400/1281167 (53%)]	Loss: 1.158462
[2022-06-09 09:54:41 | train] - Train Epoch: [58] [691200/1281167 (54%)]	Loss: 1.475373
[2022-06-09 09:55:03 | train] - Train Epoch: [58] [704000/1281167 (55%)]	Loss: 1.071863
[2022-06-09 09:55:25 | train] - Train Epoch: [58] [716800/1281167 (56%)]	Loss: 0.837103
[2022-06-09 09:55:48 | train] - Train Epoch: [58] [729600/1281167 (57%)]	Loss: 0.909662
[2022-06-09 09:56:10 | train] - Train Epoch: [58] [742400/1281167 (58%)]	Loss: 1.193845
[2022-06-09 09:56:32 | train] - Train Epoch: [58] [755200/1281167 (59%)]	Loss: 1.225489
[2022-06-09 09:56:54 | train] - Train Epoch: [58] [768000/1281167 (60%)]	Loss: 1.041091
[2022-06-09 09:57:16 | train] - Train Epoch: [58] [780800/1281167 (61%)]	Loss: 1.144091
[2022-06-09 09:57:38 | train] - Train Epoch: [58] [793600/1281167 (62%)]	Loss: 1.430469
[2022-06-09 09:58:00 | train] - Train Epoch: [58] [806400/1281167 (63%)]	Loss: 1.062081
[2022-06-09 09:58:23 | train] - Train Epoch: [58] [819200/1281167 (64%)]	Loss: 1.157474
[2022-06-09 09:58:46 | train] - Train Epoch: [58] [832000/1281167 (65%)]	Loss: 1.198825
[2022-06-09 09:59:08 | train] - Train Epoch: [58] [844800/1281167 (66%)]	Loss: 1.403131
[2022-06-09 09:59:30 | train] - Train Epoch: [58] [857600/1281167 (67%)]	Loss: 1.043723
[2022-06-09 09:59:52 | train] - Train Epoch: [58] [870400/1281167 (68%)]	Loss: 1.148734
[2022-06-09 10:00:14 | train] - Train Epoch: [58] [883200/1281167 (69%)]	Loss: 1.208882
[2022-06-09 10:00:36 | train] - Train Epoch: [58] [896000/1281167 (70%)]	Loss: 0.981853
[2022-06-09 10:00:59 | train] - Train Epoch: [58] [908800/1281167 (71%)]	Loss: 1.289018
[2022-06-09 10:01:21 | train] - Train Epoch: [58] [921600/1281167 (72%)]	Loss: 1.196514
[2022-06-09 10:01:43 | train] - Train Epoch: [58] [934400/1281167 (73%)]	Loss: 0.990228
[2022-06-09 10:02:05 | train] - Train Epoch: [58] [947200/1281167 (74%)]	Loss: 1.166685
[2022-06-09 10:02:27 | train] - Train Epoch: [58] [960000/1281167 (75%)]	Loss: 1.297572
[2022-06-09 10:02:50 | train] - Train Epoch: [58] [972800/1281167 (76%)]	Loss: 0.896177
[2022-06-09 10:03:12 | train] - Train Epoch: [58] [985600/1281167 (77%)]	Loss: 1.074857
[2022-06-09 10:03:34 | train] - Train Epoch: [58] [998400/1281167 (78%)]	Loss: 1.443320
[2022-06-09 10:03:57 | train] - Train Epoch: [58] [1011200/1281167 (79%)]	Loss: 1.037985
[2022-06-09 10:04:19 | train] - Train Epoch: [58] [1024000/1281167 (80%)]	Loss: 1.051514
[2022-06-09 10:04:41 | train] - Train Epoch: [58] [1036800/1281167 (81%)]	Loss: 1.266941
[2022-06-09 10:05:03 | train] - Train Epoch: [58] [1049600/1281167 (82%)]	Loss: 1.276781
[2022-06-09 10:05:26 | train] - Train Epoch: [58] [1062400/1281167 (83%)]	Loss: 1.344260
[2022-06-09 10:05:48 | train] - Train Epoch: [58] [1075200/1281167 (84%)]	Loss: 0.979877
[2022-06-09 10:06:10 | train] - Train Epoch: [58] [1088000/1281167 (85%)]	Loss: 1.161511
[2022-06-09 10:06:32 | train] - Train Epoch: [58] [1100800/1281167 (86%)]	Loss: 1.079020
[2022-06-09 10:06:54 | train] - Train Epoch: [58] [1113600/1281167 (87%)]	Loss: 1.117946
[2022-06-09 10:07:16 | train] - Train Epoch: [58] [1126400/1281167 (88%)]	Loss: 1.404286
[2022-06-09 10:07:38 | train] - Train Epoch: [58] [1139200/1281167 (89%)]	Loss: 1.086964
[2022-06-09 10:08:00 | train] - Train Epoch: [58] [1152000/1281167 (90%)]	Loss: 1.420089
[2022-06-09 10:08:22 | train] - Train Epoch: [58] [1164800/1281167 (91%)]	Loss: 0.895585
[2022-06-09 10:08:44 | train] - Train Epoch: [58] [1177600/1281167 (92%)]	Loss: 1.164175
[2022-06-09 10:09:07 | train] - Train Epoch: [58] [1190400/1281167 (93%)]	Loss: 0.863771
[2022-06-09 10:09:29 | train] - Train Epoch: [58] [1203200/1281167 (94%)]	Loss: 1.071240
[2022-06-09 10:09:51 | train] - Train Epoch: [58] [1216000/1281167 (95%)]	Loss: 1.116962
[2022-06-09 10:10:13 | train] - Train Epoch: [58] [1228800/1281167 (96%)]	Loss: 1.327909
[2022-06-09 10:10:35 | train] - Train Epoch: [58] [1241600/1281167 (97%)]	Loss: 1.244755
[2022-06-09 10:10:57 | train] - Train Epoch: [58] [1254400/1281167 (98%)]	Loss: 0.930212
[2022-06-09 10:11:19 | train] - Train Epoch: [58] [1267200/1281167 (99%)]	Loss: 1.234854
[2022-06-09 10:11:42 | train] - Train Epoch: [58] [1280000/1281167 (100%)]	Loss: 1.023180
[2022-06-09 10:11:43 | train] - Train Epoch: [58]	 Average Loss: 1.155655	 Total Acc : 71.9231	 Total Top5 Acc : 89.0467
[2022-06-09 10:11:43 | train] - -------58 epoch end-----------
========================================
-------58 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 10:13:18 | train] - 
Epoch [58] Test set: Average loss: 1.3887, Accuracy: 34161/50000 (68.3068%), Top-5 Accuracy: 88.2537%

[2022-06-09 10:13:18 | train] - save intermediate epoch [58] result


[2022-06-09 10:13:34 | train] - -------59 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 10:13:35 | train] - Train Epoch: [59] [0/1281167 (0%)]	Loss: 1.359665
[2022-06-09 10:13:58 | train] - Train Epoch: [59] [12800/1281167 (1%)]	Loss: 0.862334
[2022-06-09 10:14:20 | train] - Train Epoch: [59] [25600/1281167 (2%)]	Loss: 1.085256
[2022-06-09 10:14:42 | train] - Train Epoch: [59] [38400/1281167 (3%)]	Loss: 1.170627
[2022-06-09 10:15:05 | train] - Train Epoch: [59] [51200/1281167 (4%)]	Loss: 1.123455
[2022-06-09 10:15:27 | train] - Train Epoch: [59] [64000/1281167 (5%)]	Loss: 1.196068
[2022-06-09 10:15:49 | train] - Train Epoch: [59] [76800/1281167 (6%)]	Loss: 1.294947
[2022-06-09 10:16:12 | train] - Train Epoch: [59] [89600/1281167 (7%)]	Loss: 1.087691
[2022-06-09 10:16:35 | train] - Train Epoch: [59] [102400/1281167 (8%)]	Loss: 0.993899
[2022-06-09 10:16:57 | train] - Train Epoch: [59] [115200/1281167 (9%)]	Loss: 1.125005
[2022-06-09 10:17:19 | train] - Train Epoch: [59] [128000/1281167 (10%)]	Loss: 1.283502
[2022-06-09 10:17:42 | train] - Train Epoch: [59] [140800/1281167 (11%)]	Loss: 0.902022
[2022-06-09 10:18:05 | train] - Train Epoch: [59] [153600/1281167 (12%)]	Loss: 1.085611
[2022-06-09 10:18:27 | train] - Train Epoch: [59] [166400/1281167 (13%)]	Loss: 0.960729
[2022-06-09 10:18:49 | train] - Train Epoch: [59] [179200/1281167 (14%)]	Loss: 0.916566
[2022-06-09 10:19:11 | train] - Train Epoch: [59] [192000/1281167 (15%)]	Loss: 1.277846
[2022-06-09 10:19:34 | train] - Train Epoch: [59] [204800/1281167 (16%)]	Loss: 1.148431
[2022-06-09 10:19:56 | train] - Train Epoch: [59] [217600/1281167 (17%)]	Loss: 1.268878
[2022-06-09 10:20:18 | train] - Train Epoch: [59] [230400/1281167 (18%)]	Loss: 1.261056
[2022-06-09 10:20:40 | train] - Train Epoch: [59] [243200/1281167 (19%)]	Loss: 0.928542
[2022-06-09 10:21:02 | train] - Train Epoch: [59] [256000/1281167 (20%)]	Loss: 1.185462
[2022-06-09 10:21:25 | train] - Train Epoch: [59] [268800/1281167 (21%)]	Loss: 0.926632
[2022-06-09 10:21:47 | train] - Train Epoch: [59] [281600/1281167 (22%)]	Loss: 1.276049
[2022-06-09 10:22:09 | train] - Train Epoch: [59] [294400/1281167 (23%)]	Loss: 1.072936
[2022-06-09 10:22:31 | train] - Train Epoch: [59] [307200/1281167 (24%)]	Loss: 1.435599
[2022-06-09 10:22:53 | train] - Train Epoch: [59] [320000/1281167 (25%)]	Loss: 1.436870
[2022-06-09 10:23:16 | train] - Train Epoch: [59] [332800/1281167 (26%)]	Loss: 1.206625
[2022-06-09 10:23:39 | train] - Train Epoch: [59] [345600/1281167 (27%)]	Loss: 0.966900
[2022-06-09 10:24:01 | train] - Train Epoch: [59] [358400/1281167 (28%)]	Loss: 1.206001
[2022-06-09 10:24:24 | train] - Train Epoch: [59] [371200/1281167 (29%)]	Loss: 1.018037
[2022-06-09 10:24:46 | train] - Train Epoch: [59] [384000/1281167 (30%)]	Loss: 1.105869
[2022-06-09 10:25:08 | train] - Train Epoch: [59] [396800/1281167 (31%)]	Loss: 1.232791
[2022-06-09 10:25:30 | train] - Train Epoch: [59] [409600/1281167 (32%)]	Loss: 0.980883
[2022-06-09 10:25:52 | train] - Train Epoch: [59] [422400/1281167 (33%)]	Loss: 0.717549
[2022-06-09 10:26:14 | train] - Train Epoch: [59] [435200/1281167 (34%)]	Loss: 1.360667
[2022-06-09 10:26:37 | train] - Train Epoch: [59] [448000/1281167 (35%)]	Loss: 1.130334
[2022-06-09 10:26:59 | train] - Train Epoch: [59] [460800/1281167 (36%)]	Loss: 1.405441
[2022-06-09 10:27:22 | train] - Train Epoch: [59] [473600/1281167 (37%)]	Loss: 1.051469
[2022-06-09 10:27:44 | train] - Train Epoch: [59] [486400/1281167 (38%)]	Loss: 1.259932
[2022-06-09 10:28:07 | train] - Train Epoch: [59] [499200/1281167 (39%)]	Loss: 0.862619
[2022-06-09 10:28:29 | train] - Train Epoch: [59] [512000/1281167 (40%)]	Loss: 1.069634
[2022-06-09 10:28:51 | train] - Train Epoch: [59] [524800/1281167 (41%)]	Loss: 0.802442
[2022-06-09 10:29:14 | train] - Train Epoch: [59] [537600/1281167 (42%)]	Loss: 1.058416
[2022-06-09 10:29:36 | train] - Train Epoch: [59] [550400/1281167 (43%)]	Loss: 0.901336
[2022-06-09 10:29:59 | train] - Train Epoch: [59] [563200/1281167 (44%)]	Loss: 1.126475
[2022-06-09 10:30:21 | train] - Train Epoch: [59] [576000/1281167 (45%)]	Loss: 1.093289
[2022-06-09 10:30:43 | train] - Train Epoch: [59] [588800/1281167 (46%)]	Loss: 1.250077
[2022-06-09 10:31:05 | train] - Train Epoch: [59] [601600/1281167 (47%)]	Loss: 1.311029
[2022-06-09 10:31:28 | train] - Train Epoch: [59] [614400/1281167 (48%)]	Loss: 1.158236
[2022-06-09 10:31:50 | train] - Train Epoch: [59] [627200/1281167 (49%)]	Loss: 1.285132
[2022-06-09 10:32:13 | train] - Train Epoch: [59] [640000/1281167 (50%)]	Loss: 1.380143
[2022-06-09 10:32:35 | train] - Train Epoch: [59] [652800/1281167 (51%)]	Loss: 1.206629
[2022-06-09 10:32:57 | train] - Train Epoch: [59] [665600/1281167 (52%)]	Loss: 1.228404
[2022-06-09 10:33:20 | train] - Train Epoch: [59] [678400/1281167 (53%)]	Loss: 0.976235
[2022-06-09 10:33:42 | train] - Train Epoch: [59] [691200/1281167 (54%)]	Loss: 1.110337
[2022-06-09 10:34:04 | train] - Train Epoch: [59] [704000/1281167 (55%)]	Loss: 1.031687
[2022-06-09 10:34:27 | train] - Train Epoch: [59] [716800/1281167 (56%)]	Loss: 1.352617
[2022-06-09 10:34:49 | train] - Train Epoch: [59] [729600/1281167 (57%)]	Loss: 1.011855
[2022-06-09 10:35:11 | train] - Train Epoch: [59] [742400/1281167 (58%)]	Loss: 1.201633
[2022-06-09 10:35:34 | train] - Train Epoch: [59] [755200/1281167 (59%)]	Loss: 1.521711
[2022-06-09 10:35:56 | train] - Train Epoch: [59] [768000/1281167 (60%)]	Loss: 1.229415
[2022-06-09 10:36:18 | train] - Train Epoch: [59] [780800/1281167 (61%)]	Loss: 1.300100
[2022-06-09 10:36:41 | train] - Train Epoch: [59] [793600/1281167 (62%)]	Loss: 1.264400
[2022-06-09 10:37:04 | train] - Train Epoch: [59] [806400/1281167 (63%)]	Loss: 1.493940
[2022-06-09 10:37:26 | train] - Train Epoch: [59] [819200/1281167 (64%)]	Loss: 1.226771
[2022-06-09 10:37:48 | train] - Train Epoch: [59] [832000/1281167 (65%)]	Loss: 1.328235
[2022-06-09 10:38:09 | train] - Train Epoch: [59] [844800/1281167 (66%)]	Loss: 0.858119
[2022-06-09 10:38:32 | train] - Train Epoch: [59] [857600/1281167 (67%)]	Loss: 1.050193
[2022-06-09 10:38:54 | train] - Train Epoch: [59] [870400/1281167 (68%)]	Loss: 1.192783
[2022-06-09 10:39:16 | train] - Train Epoch: [59] [883200/1281167 (69%)]	Loss: 0.886793
[2022-06-09 10:39:39 | train] - Train Epoch: [59] [896000/1281167 (70%)]	Loss: 1.226616
[2022-06-09 10:40:01 | train] - Train Epoch: [59] [908800/1281167 (71%)]	Loss: 1.206946
[2022-06-09 10:40:23 | train] - Train Epoch: [59] [921600/1281167 (72%)]	Loss: 1.087065
[2022-06-09 10:40:46 | train] - Train Epoch: [59] [934400/1281167 (73%)]	Loss: 1.076396
[2022-06-09 10:41:08 | train] - Train Epoch: [59] [947200/1281167 (74%)]	Loss: 1.130699
[2022-06-09 10:41:30 | train] - Train Epoch: [59] [960000/1281167 (75%)]	Loss: 1.175885
[2022-06-09 10:41:52 | train] - Train Epoch: [59] [972800/1281167 (76%)]	Loss: 1.191490
[2022-06-09 10:42:14 | train] - Train Epoch: [59] [985600/1281167 (77%)]	Loss: 1.323505
[2022-06-09 10:42:36 | train] - Train Epoch: [59] [998400/1281167 (78%)]	Loss: 1.352581
[2022-06-09 10:42:59 | train] - Train Epoch: [59] [1011200/1281167 (79%)]	Loss: 1.183232
[2022-06-09 10:43:21 | train] - Train Epoch: [59] [1024000/1281167 (80%)]	Loss: 0.943521
[2022-06-09 10:43:43 | train] - Train Epoch: [59] [1036800/1281167 (81%)]	Loss: 0.761442
[2022-06-09 10:44:06 | train] - Train Epoch: [59] [1049600/1281167 (82%)]	Loss: 1.208206
[2022-06-09 10:44:27 | train] - Train Epoch: [59] [1062400/1281167 (83%)]	Loss: 0.670131
[2022-06-09 10:44:50 | train] - Train Epoch: [59] [1075200/1281167 (84%)]	Loss: 0.819746
[2022-06-09 10:45:12 | train] - Train Epoch: [59] [1088000/1281167 (85%)]	Loss: 1.101743
[2022-06-09 10:45:35 | train] - Train Epoch: [59] [1100800/1281167 (86%)]	Loss: 1.320052
[2022-06-09 10:45:57 | train] - Train Epoch: [59] [1113600/1281167 (87%)]	Loss: 1.387592
[2022-06-09 10:46:20 | train] - Train Epoch: [59] [1126400/1281167 (88%)]	Loss: 0.999891
[2022-06-09 10:46:42 | train] - Train Epoch: [59] [1139200/1281167 (89%)]	Loss: 0.971053
[2022-06-09 10:47:04 | train] - Train Epoch: [59] [1152000/1281167 (90%)]	Loss: 1.403189
[2022-06-09 10:47:27 | train] - Train Epoch: [59] [1164800/1281167 (91%)]	Loss: 1.291649
[2022-06-09 10:47:49 | train] - Train Epoch: [59] [1177600/1281167 (92%)]	Loss: 1.077918
[2022-06-09 10:48:11 | train] - Train Epoch: [59] [1190400/1281167 (93%)]	Loss: 1.511427
[2022-06-09 10:48:33 | train] - Train Epoch: [59] [1203200/1281167 (94%)]	Loss: 0.790063
[2022-06-09 10:48:56 | train] - Train Epoch: [59] [1216000/1281167 (95%)]	Loss: 1.408215
[2022-06-09 10:49:19 | train] - Train Epoch: [59] [1228800/1281167 (96%)]	Loss: 1.221008
[2022-06-09 10:49:41 | train] - Train Epoch: [59] [1241600/1281167 (97%)]	Loss: 1.013942
[2022-06-09 10:50:03 | train] - Train Epoch: [59] [1254400/1281167 (98%)]	Loss: 1.065779
[2022-06-09 10:50:25 | train] - Train Epoch: [59] [1267200/1281167 (99%)]	Loss: 1.197304
[2022-06-09 10:50:46 | train] - Train Epoch: [59] [1280000/1281167 (100%)]	Loss: 1.202905
[2022-06-09 10:50:48 | train] - Train Epoch: [59]	 Average Loss: 1.147966	 Total Acc : 72.1101	 Total Top5 Acc : 89.1415
[2022-06-09 10:50:48 | train] - -------59 epoch end-----------
========================================
-------59 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 10:52:22 | train] - 
Epoch [59] Test set: Average loss: 1.3879, Accuracy: 34105/50000 (68.1829%), Top-5 Accuracy: 87.9276%

[2022-06-09 10:52:22 | train] - save intermediate epoch [59] result


[2022-06-09 10:52:38 | train] - -------60 epoch start-----------
[2022-06-09 10:52:38 | train] - -------- logging 60 batch layer input tensor ------------------
[2022-06-09 10:53:08 | train] - -------- logging end 60 --------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-09 10:53:10 | train] - Train Epoch: [60] [0/1281167 (0%)]	Loss: 1.108757
[2022-06-09 10:53:31 | train] - Train Epoch: [60] [12800/1281167 (1%)]	Loss: 1.051886
[2022-06-09 10:53:51 | train] - Train Epoch: [60] [25600/1281167 (2%)]	Loss: 1.041507
[2022-06-09 10:54:12 | train] - Train Epoch: [60] [38400/1281167 (3%)]	Loss: 1.403420
[2022-06-09 10:54:33 | train] - Train Epoch: [60] [51200/1281167 (4%)]	Loss: 1.053243
[2022-06-09 10:54:53 | train] - Train Epoch: [60] [64000/1281167 (5%)]	Loss: 1.181338
[2022-06-09 10:55:14 | train] - Train Epoch: [60] [76800/1281167 (6%)]	Loss: 0.914876
[2022-06-09 10:55:35 | train] - Train Epoch: [60] [89600/1281167 (7%)]	Loss: 1.039469
[2022-06-09 10:55:55 | train] - Train Epoch: [60] [102400/1281167 (8%)]	Loss: 1.019881
[2022-06-09 10:56:16 | train] - Train Epoch: [60] [115200/1281167 (9%)]	Loss: 0.967461
[2022-06-09 10:56:37 | train] - Train Epoch: [60] [128000/1281167 (10%)]	Loss: 1.122769
[2022-06-09 10:56:58 | train] - Train Epoch: [60] [140800/1281167 (11%)]	Loss: 1.179608
[2022-06-09 10:57:19 | train] - Train Epoch: [60] [153600/1281167 (12%)]	Loss: 0.967692
[2022-06-09 10:57:39 | train] - Train Epoch: [60] [166400/1281167 (13%)]	Loss: 1.098756
[2022-06-09 10:58:00 | train] - Train Epoch: [60] [179200/1281167 (14%)]	Loss: 1.025614
[2022-06-09 10:58:20 | train] - Train Epoch: [60] [192000/1281167 (15%)]	Loss: 0.911787
[2022-06-09 10:58:41 | train] - Train Epoch: [60] [204800/1281167 (16%)]	Loss: 1.127411
[2022-06-09 10:59:01 | train] - Train Epoch: [60] [217600/1281167 (17%)]	Loss: 1.107307
[2022-06-09 10:59:21 | train] - Train Epoch: [60] [230400/1281167 (18%)]	Loss: 1.120748
[2022-06-09 10:59:43 | train] - Train Epoch: [60] [243200/1281167 (19%)]	Loss: 0.945158
[2022-06-09 11:00:03 | train] - Train Epoch: [60] [256000/1281167 (20%)]	Loss: 1.010532
[2022-06-09 11:00:24 | train] - Train Epoch: [60] [268800/1281167 (21%)]	Loss: 0.691643
[2022-06-09 11:00:45 | train] - Train Epoch: [60] [281600/1281167 (22%)]	Loss: 1.094887
[2022-06-09 11:01:07 | train] - Train Epoch: [60] [294400/1281167 (23%)]	Loss: 0.898446
[2022-06-09 11:01:28 | train] - Train Epoch: [60] [307200/1281167 (24%)]	Loss: 0.795387
[2022-06-09 11:01:48 | train] - Train Epoch: [60] [320000/1281167 (25%)]	Loss: 0.951626
[2022-06-09 11:02:09 | train] - Train Epoch: [60] [332800/1281167 (26%)]	Loss: 1.043008
[2022-06-09 11:02:30 | train] - Train Epoch: [60] [345600/1281167 (27%)]	Loss: 1.099220
[2022-06-09 11:02:52 | train] - Train Epoch: [60] [358400/1281167 (28%)]	Loss: 0.796372
[2022-06-09 11:03:11 | train] - Train Epoch: [60] [371200/1281167 (29%)]	Loss: 1.286070
[2022-06-09 11:03:32 | train] - Train Epoch: [60] [384000/1281167 (30%)]	Loss: 1.072395
[2022-06-09 11:03:54 | train] - Train Epoch: [60] [396800/1281167 (31%)]	Loss: 1.236262
[2022-06-09 11:04:14 | train] - Train Epoch: [60] [409600/1281167 (32%)]	Loss: 0.873441
[2022-06-09 11:04:35 | train] - Train Epoch: [60] [422400/1281167 (33%)]	Loss: 1.016864
[2022-06-09 11:04:57 | train] - Train Epoch: [60] [435200/1281167 (34%)]	Loss: 0.811272
[2022-06-09 11:05:18 | train] - Train Epoch: [60] [448000/1281167 (35%)]	Loss: 0.983257
[2022-06-09 11:05:39 | train] - Train Epoch: [60] [460800/1281167 (36%)]	Loss: 0.862687
[2022-06-09 11:06:00 | train] - Train Epoch: [60] [473600/1281167 (37%)]	Loss: 1.093873
[2022-06-09 11:06:21 | train] - Train Epoch: [60] [486400/1281167 (38%)]	Loss: 0.812563
[2022-06-09 11:06:42 | train] - Train Epoch: [60] [499200/1281167 (39%)]	Loss: 1.195786
[2022-06-09 11:07:03 | train] - Train Epoch: [60] [512000/1281167 (40%)]	Loss: 1.103172
[2022-06-09 11:07:24 | train] - Train Epoch: [60] [524800/1281167 (41%)]	Loss: 1.155637
[2022-06-09 11:07:45 | train] - Train Epoch: [60] [537600/1281167 (42%)]	Loss: 1.030455
[2022-06-09 11:08:07 | train] - Train Epoch: [60] [550400/1281167 (43%)]	Loss: 1.068047
[2022-06-09 11:08:28 | train] - Train Epoch: [60] [563200/1281167 (44%)]	Loss: 1.132996
[2022-06-09 11:08:48 | train] - Train Epoch: [60] [576000/1281167 (45%)]	Loss: 0.764793
[2022-06-09 11:09:09 | train] - Train Epoch: [60] [588800/1281167 (46%)]	Loss: 0.952888
[2022-06-09 11:09:31 | train] - Train Epoch: [60] [601600/1281167 (47%)]	Loss: 0.795621
[2022-06-09 11:09:52 | train] - Train Epoch: [60] [614400/1281167 (48%)]	Loss: 1.231400
[2022-06-09 11:10:13 | train] - Train Epoch: [60] [627200/1281167 (49%)]	Loss: 1.148172
[2022-06-09 11:10:36 | train] - Train Epoch: [60] [640000/1281167 (50%)]	Loss: 1.001285
[2022-06-09 11:10:57 | train] - Train Epoch: [60] [652800/1281167 (51%)]	Loss: 1.015785
[2022-06-09 11:11:18 | train] - Train Epoch: [60] [665600/1281167 (52%)]	Loss: 0.970676
[2022-06-09 11:11:40 | train] - Train Epoch: [60] [678400/1281167 (53%)]	Loss: 1.154091
[2022-06-09 11:12:01 | train] - Train Epoch: [60] [691200/1281167 (54%)]	Loss: 0.945529
[2022-06-09 11:12:23 | train] - Train Epoch: [60] [704000/1281167 (55%)]	Loss: 1.209998
[2022-06-09 11:12:45 | train] - Train Epoch: [60] [716800/1281167 (56%)]	Loss: 0.870847
[2022-06-09 11:13:06 | train] - Train Epoch: [60] [729600/1281167 (57%)]	Loss: 0.977487
[2022-06-09 11:13:27 | train] - Train Epoch: [60] [742400/1281167 (58%)]	Loss: 0.829140
[2022-06-09 11:13:47 | train] - Train Epoch: [60] [755200/1281167 (59%)]	Loss: 1.189266
[2022-06-09 11:14:08 | train] - Train Epoch: [60] [768000/1281167 (60%)]	Loss: 0.894459
[2022-06-09 11:14:30 | train] - Train Epoch: [60] [780800/1281167 (61%)]	Loss: 0.897885
[2022-06-09 11:14:51 | train] - Train Epoch: [60] [793600/1281167 (62%)]	Loss: 0.890623
[2022-06-09 11:15:12 | train] - Train Epoch: [60] [806400/1281167 (63%)]	Loss: 1.063659
[2022-06-09 11:15:33 | train] - Train Epoch: [60] [819200/1281167 (64%)]	Loss: 0.979319
[2022-06-09 11:15:54 | train] - Train Epoch: [60] [832000/1281167 (65%)]	Loss: 1.018493
[2022-06-09 11:16:15 | train] - Train Epoch: [60] [844800/1281167 (66%)]	Loss: 0.787728
[2022-06-09 11:16:36 | train] - Train Epoch: [60] [857600/1281167 (67%)]	Loss: 1.126796
[2022-06-09 11:16:58 | train] - Train Epoch: [60] [870400/1281167 (68%)]	Loss: 1.149690
[2022-06-09 11:17:18 | train] - Train Epoch: [60] [883200/1281167 (69%)]	Loss: 1.185687
[2022-06-09 11:17:39 | train] - Train Epoch: [60] [896000/1281167 (70%)]	Loss: 1.128805
[2022-06-09 11:18:01 | train] - Train Epoch: [60] [908800/1281167 (71%)]	Loss: 0.996192
[2022-06-09 11:18:22 | train] - Train Epoch: [60] [921600/1281167 (72%)]	Loss: 0.954852
[2022-06-09 11:18:43 | train] - Train Epoch: [60] [934400/1281167 (73%)]	Loss: 1.229555
[2022-06-09 11:19:05 | train] - Train Epoch: [60] [947200/1281167 (74%)]	Loss: 1.000989
[2022-06-09 11:19:27 | train] - Train Epoch: [60] [960000/1281167 (75%)]	Loss: 0.982255
[2022-06-09 11:19:49 | train] - Train Epoch: [60] [972800/1281167 (76%)]	Loss: 1.225999
[2022-06-09 11:20:10 | train] - Train Epoch: [60] [985600/1281167 (77%)]	Loss: 0.855153
[2022-06-09 11:20:32 | train] - Train Epoch: [60] [998400/1281167 (78%)]	Loss: 1.206035
[2022-06-09 11:20:53 | train] - Train Epoch: [60] [1011200/1281167 (79%)]	Loss: 1.200257
[2022-06-09 11:21:15 | train] - Train Epoch: [60] [1024000/1281167 (80%)]	Loss: 0.958697
[2022-06-09 11:21:37 | train] - Train Epoch: [60] [1036800/1281167 (81%)]	Loss: 1.160409
[2022-06-09 11:21:58 | train] - Train Epoch: [60] [1049600/1281167 (82%)]	Loss: 1.178934
[2022-06-09 11:22:19 | train] - Train Epoch: [60] [1062400/1281167 (83%)]	Loss: 0.729358
[2022-06-09 11:22:40 | train] - Train Epoch: [60] [1075200/1281167 (84%)]	Loss: 1.041748
[2022-06-09 11:23:00 | train] - Train Epoch: [60] [1088000/1281167 (85%)]	Loss: 0.918083
[2022-06-09 11:23:21 | train] - Train Epoch: [60] [1100800/1281167 (86%)]	Loss: 1.021177
[2022-06-09 11:23:43 | train] - Train Epoch: [60] [1113600/1281167 (87%)]	Loss: 1.104437
[2022-06-09 11:24:04 | train] - Train Epoch: [60] [1126400/1281167 (88%)]	Loss: 1.105335
[2022-06-09 11:24:25 | train] - Train Epoch: [60] [1139200/1281167 (89%)]	Loss: 0.943528
[2022-06-09 11:24:47 | train] - Train Epoch: [60] [1152000/1281167 (90%)]	Loss: 1.061892
[2022-06-09 11:25:08 | train] - Train Epoch: [60] [1164800/1281167 (91%)]	Loss: 0.894081
[2022-06-09 11:25:29 | train] - Train Epoch: [60] [1177600/1281167 (92%)]	Loss: 0.971287
[2022-06-09 11:25:50 | train] - Train Epoch: [60] [1190400/1281167 (93%)]	Loss: 1.109744
[2022-06-09 11:26:12 | train] - Train Epoch: [60] [1203200/1281167 (94%)]	Loss: 1.132941
[2022-06-09 11:26:33 | train] - Train Epoch: [60] [1216000/1281167 (95%)]	Loss: 0.986900
[2022-06-09 11:26:54 | train] - Train Epoch: [60] [1228800/1281167 (96%)]	Loss: 0.745084
[2022-06-09 11:27:15 | train] - Train Epoch: [60] [1241600/1281167 (97%)]	Loss: 0.783501
[2022-06-09 11:27:36 | train] - Train Epoch: [60] [1254400/1281167 (98%)]	Loss: 0.979368
[2022-06-09 11:27:58 | train] - Train Epoch: [60] [1267200/1281167 (99%)]	Loss: 0.744886
[2022-06-09 11:28:19 | train] - Train Epoch: [60] [1280000/1281167 (100%)]	Loss: 1.156250
[2022-06-09 11:28:21 | train] - Train Epoch: [60]	 Average Loss: 1.018112	 Total Acc : 75.3402	 Total Top5 Acc : 90.5752
[2022-06-09 11:28:21 | train] - -------60 epoch end-----------
========================================
-------60 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 11:29:57 | train] - 
Epoch [60] Test set: Average loss: 1.2950, Accuracy: 35147/50000 (70.2673%), Top-5 Accuracy: 89.1144%

[2022-06-09 11:29:57 | train] - save intermediate epoch [60] result


[2022-06-09 11:30:12 | train] - logging best performance 60 epoch
[2022-06-09 11:30:14 | train] - -------61 epoch start-----------
========================================
----- test end -------------------------


logging best performance 60 epoch
[2022-06-09 11:30:15 | train] - Train Epoch: [61] [0/1281167 (0%)]	Loss: 0.979612
[2022-06-09 11:30:36 | train] - Train Epoch: [61] [12800/1281167 (1%)]	Loss: 1.246739
[2022-06-09 11:30:58 | train] - Train Epoch: [61] [25600/1281167 (2%)]	Loss: 0.713130
[2022-06-09 11:31:18 | train] - Train Epoch: [61] [38400/1281167 (3%)]	Loss: 1.006473
[2022-06-09 11:31:40 | train] - Train Epoch: [61] [51200/1281167 (4%)]	Loss: 1.000564
[2022-06-09 11:32:00 | train] - Train Epoch: [61] [64000/1281167 (5%)]	Loss: 0.681037
[2022-06-09 11:32:21 | train] - Train Epoch: [61] [76800/1281167 (6%)]	Loss: 0.816481
[2022-06-09 11:32:42 | train] - Train Epoch: [61] [89600/1281167 (7%)]	Loss: 0.911599
[2022-06-09 11:33:02 | train] - Train Epoch: [61] [102400/1281167 (8%)]	Loss: 1.022379
[2022-06-09 11:33:23 | train] - Train Epoch: [61] [115200/1281167 (9%)]	Loss: 0.864330
[2022-06-09 11:33:44 | train] - Train Epoch: [61] [128000/1281167 (10%)]	Loss: 1.056291
[2022-06-09 11:34:05 | train] - Train Epoch: [61] [140800/1281167 (11%)]	Loss: 1.087989
[2022-06-09 11:34:26 | train] - Train Epoch: [61] [153600/1281167 (12%)]	Loss: 1.034705
[2022-06-09 11:34:48 | train] - Train Epoch: [61] [166400/1281167 (13%)]	Loss: 1.106420
[2022-06-09 11:35:09 | train] - Train Epoch: [61] [179200/1281167 (14%)]	Loss: 1.341832
[2022-06-09 11:35:30 | train] - Train Epoch: [61] [192000/1281167 (15%)]	Loss: 1.059385
[2022-06-09 11:35:52 | train] - Train Epoch: [61] [204800/1281167 (16%)]	Loss: 1.005148
[2022-06-09 11:36:13 | train] - Train Epoch: [61] [217600/1281167 (17%)]	Loss: 1.262481
[2022-06-09 11:36:35 | train] - Train Epoch: [61] [230400/1281167 (18%)]	Loss: 1.197273
[2022-06-09 11:36:56 | train] - Train Epoch: [61] [243200/1281167 (19%)]	Loss: 0.905628
[2022-06-09 11:37:17 | train] - Train Epoch: [61] [256000/1281167 (20%)]	Loss: 0.990451
[2022-06-09 11:37:38 | train] - Train Epoch: [61] [268800/1281167 (21%)]	Loss: 1.051407
[2022-06-09 11:38:00 | train] - Train Epoch: [61] [281600/1281167 (22%)]	Loss: 0.892462
[2022-06-09 11:38:21 | train] - Train Epoch: [61] [294400/1281167 (23%)]	Loss: 0.907332
[2022-06-09 11:38:42 | train] - Train Epoch: [61] [307200/1281167 (24%)]	Loss: 1.335836
[2022-06-09 11:39:04 | train] - Train Epoch: [61] [320000/1281167 (25%)]	Loss: 1.083620
[2022-06-09 11:39:25 | train] - Train Epoch: [61] [332800/1281167 (26%)]	Loss: 1.233230
[2022-06-09 11:39:45 | train] - Train Epoch: [61] [345600/1281167 (27%)]	Loss: 0.806109
[2022-06-09 11:40:06 | train] - Train Epoch: [61] [358400/1281167 (28%)]	Loss: 1.212412
[2022-06-09 11:40:27 | train] - Train Epoch: [61] [371200/1281167 (29%)]	Loss: 0.813963
[2022-06-09 11:40:48 | train] - Train Epoch: [61] [384000/1281167 (30%)]	Loss: 0.928669
[2022-06-09 11:41:10 | train] - Train Epoch: [61] [396800/1281167 (31%)]	Loss: 0.984778
[2022-06-09 11:41:30 | train] - Train Epoch: [61] [409600/1281167 (32%)]	Loss: 0.974306
[2022-06-09 11:41:51 | train] - Train Epoch: [61] [422400/1281167 (33%)]	Loss: 0.748941
[2022-06-09 11:42:13 | train] - Train Epoch: [61] [435200/1281167 (34%)]	Loss: 1.133012
[2022-06-09 11:42:34 | train] - Train Epoch: [61] [448000/1281167 (35%)]	Loss: 0.955772
[2022-06-09 11:42:56 | train] - Train Epoch: [61] [460800/1281167 (36%)]	Loss: 1.182154
[2022-06-09 11:43:17 | train] - Train Epoch: [61] [473600/1281167 (37%)]	Loss: 1.208563
[2022-06-09 11:43:37 | train] - Train Epoch: [61] [486400/1281167 (38%)]	Loss: 1.230658
[2022-06-09 11:43:59 | train] - Train Epoch: [61] [499200/1281167 (39%)]	Loss: 1.049882
[2022-06-09 11:44:21 | train] - Train Epoch: [61] [512000/1281167 (40%)]	Loss: 0.830789
[2022-06-09 11:44:42 | train] - Train Epoch: [61] [524800/1281167 (41%)]	Loss: 0.933622
[2022-06-09 11:45:03 | train] - Train Epoch: [61] [537600/1281167 (42%)]	Loss: 1.176464
[2022-06-09 11:45:25 | train] - Train Epoch: [61] [550400/1281167 (43%)]	Loss: 1.067363
[2022-06-09 11:45:46 | train] - Train Epoch: [61] [563200/1281167 (44%)]	Loss: 0.795938
[2022-06-09 11:46:06 | train] - Train Epoch: [61] [576000/1281167 (45%)]	Loss: 0.951358
[2022-06-09 11:46:27 | train] - Train Epoch: [61] [588800/1281167 (46%)]	Loss: 1.167780
[2022-06-09 11:46:49 | train] - Train Epoch: [61] [601600/1281167 (47%)]	Loss: 0.942441
[2022-06-09 11:47:10 | train] - Train Epoch: [61] [614400/1281167 (48%)]	Loss: 1.050115
[2022-06-09 11:47:33 | train] - Train Epoch: [61] [627200/1281167 (49%)]	Loss: 0.905785
[2022-06-09 11:47:54 | train] - Train Epoch: [61] [640000/1281167 (50%)]	Loss: 0.962151
[2022-06-09 11:48:15 | train] - Train Epoch: [61] [652800/1281167 (51%)]	Loss: 0.933453
[2022-06-09 11:48:37 | train] - Train Epoch: [61] [665600/1281167 (52%)]	Loss: 1.019934
[2022-06-09 11:48:58 | train] - Train Epoch: [61] [678400/1281167 (53%)]	Loss: 1.020966
[2022-06-09 11:49:20 | train] - Train Epoch: [61] [691200/1281167 (54%)]	Loss: 1.163207
[2022-06-09 11:49:41 | train] - Train Epoch: [61] [704000/1281167 (55%)]	Loss: 0.864951
[2022-06-09 11:50:02 | train] - Train Epoch: [61] [716800/1281167 (56%)]	Loss: 1.148727
[2022-06-09 11:50:23 | train] - Train Epoch: [61] [729600/1281167 (57%)]	Loss: 0.888267
[2022-06-09 11:50:43 | train] - Train Epoch: [61] [742400/1281167 (58%)]	Loss: 0.645324
[2022-06-09 11:51:05 | train] - Train Epoch: [61] [755200/1281167 (59%)]	Loss: 1.034606
[2022-06-09 11:51:26 | train] - Train Epoch: [61] [768000/1281167 (60%)]	Loss: 0.996021
[2022-06-09 11:51:48 | train] - Train Epoch: [61] [780800/1281167 (61%)]	Loss: 0.954196
[2022-06-09 11:52:09 | train] - Train Epoch: [61] [793600/1281167 (62%)]	Loss: 1.089085
[2022-06-09 11:52:30 | train] - Train Epoch: [61] [806400/1281167 (63%)]	Loss: 0.698502
[2022-06-09 11:52:52 | train] - Train Epoch: [61] [819200/1281167 (64%)]	Loss: 1.134162
[2022-06-09 11:53:13 | train] - Train Epoch: [61] [832000/1281167 (65%)]	Loss: 0.901775
[2022-06-09 11:53:34 | train] - Train Epoch: [61] [844800/1281167 (66%)]	Loss: 0.894807
[2022-06-09 11:53:54 | train] - Train Epoch: [61] [857600/1281167 (67%)]	Loss: 1.099144
[2022-06-09 11:54:15 | train] - Train Epoch: [61] [870400/1281167 (68%)]	Loss: 0.845484
[2022-06-09 11:54:37 | train] - Train Epoch: [61] [883200/1281167 (69%)]	Loss: 1.014089
[2022-06-09 11:54:58 | train] - Train Epoch: [61] [896000/1281167 (70%)]	Loss: 1.015852
[2022-06-09 11:55:19 | train] - Train Epoch: [61] [908800/1281167 (71%)]	Loss: 0.791082
[2022-06-09 11:55:40 | train] - Train Epoch: [61] [921600/1281167 (72%)]	Loss: 0.914592
[2022-06-09 11:56:01 | train] - Train Epoch: [61] [934400/1281167 (73%)]	Loss: 1.131532
[2022-06-09 11:56:22 | train] - Train Epoch: [61] [947200/1281167 (74%)]	Loss: 0.897506
[2022-06-09 11:56:43 | train] - Train Epoch: [61] [960000/1281167 (75%)]	Loss: 1.236569
[2022-06-09 11:57:04 | train] - Train Epoch: [61] [972800/1281167 (76%)]	Loss: 1.077488
[2022-06-09 11:57:25 | train] - Train Epoch: [61] [985600/1281167 (77%)]	Loss: 1.123824
[2022-06-09 11:57:46 | train] - Train Epoch: [61] [998400/1281167 (78%)]	Loss: 1.234207
[2022-06-09 11:58:07 | train] - Train Epoch: [61] [1011200/1281167 (79%)]	Loss: 0.936529
[2022-06-09 11:58:29 | train] - Train Epoch: [61] [1024000/1281167 (80%)]	Loss: 0.960091
[2022-06-09 11:58:50 | train] - Train Epoch: [61] [1036800/1281167 (81%)]	Loss: 1.140605
[2022-06-09 11:59:12 | train] - Train Epoch: [61] [1049600/1281167 (82%)]	Loss: 1.378295
[2022-06-09 11:59:32 | train] - Train Epoch: [61] [1062400/1281167 (83%)]	Loss: 0.995924
[2022-06-09 11:59:53 | train] - Train Epoch: [61] [1075200/1281167 (84%)]	Loss: 1.038655
[2022-06-09 12:00:15 | train] - Train Epoch: [61] [1088000/1281167 (85%)]	Loss: 0.719866
[2022-06-09 12:00:35 | train] - Train Epoch: [61] [1100800/1281167 (86%)]	Loss: 0.998466
[2022-06-09 12:00:56 | train] - Train Epoch: [61] [1113600/1281167 (87%)]	Loss: 1.083801
[2022-06-09 12:01:17 | train] - Train Epoch: [61] [1126400/1281167 (88%)]	Loss: 1.077888
[2022-06-09 12:01:38 | train] - Train Epoch: [61] [1139200/1281167 (89%)]	Loss: 0.748315
[2022-06-09 12:02:00 | train] - Train Epoch: [61] [1152000/1281167 (90%)]	Loss: 0.664918
[2022-06-09 12:02:21 | train] - Train Epoch: [61] [1164800/1281167 (91%)]	Loss: 0.907862
[2022-06-09 12:02:42 | train] - Train Epoch: [61] [1177600/1281167 (92%)]	Loss: 0.971549
[2022-06-09 12:03:04 | train] - Train Epoch: [61] [1190400/1281167 (93%)]	Loss: 0.830261
[2022-06-09 12:03:23 | train] - Train Epoch: [61] [1203200/1281167 (94%)]	Loss: 0.738091
[2022-06-09 12:03:44 | train] - Train Epoch: [61] [1216000/1281167 (95%)]	Loss: 1.012190
[2022-06-09 12:04:06 | train] - Train Epoch: [61] [1228800/1281167 (96%)]	Loss: 1.237206
[2022-06-09 12:04:27 | train] - Train Epoch: [61] [1241600/1281167 (97%)]	Loss: 0.678559
[2022-06-09 12:04:49 | train] - Train Epoch: [61] [1254400/1281167 (98%)]	Loss: 0.927553
[2022-06-09 12:05:11 | train] - Train Epoch: [61] [1267200/1281167 (99%)]	Loss: 1.129871
[2022-06-09 12:05:32 | train] - Train Epoch: [61] [1280000/1281167 (100%)]	Loss: 0.864697
[2022-06-09 12:05:34 | train] - Train Epoch: [61]	 Average Loss: 0.990368	 Total Acc : 76.0111	 Total Top5 Acc : 90.8694
[2022-06-09 12:05:34 | train] - -------61 epoch end-----------
========================================
-------61 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 12:07:08 | train] - 
Epoch [61] Test set: Average loss: 1.3018, Accuracy: 35171/50000 (70.3141%), Top-5 Accuracy: 89.1592%

[2022-06-09 12:07:08 | train] - save intermediate epoch [61] result


[2022-06-09 12:07:24 | train] - logging best performance 61 epoch
[2022-06-09 12:07:25 | train] - -------62 epoch start-----------
========================================
----- test end -------------------------


logging best performance 61 epoch
[2022-06-09 12:07:27 | train] - Train Epoch: [62] [0/1281167 (0%)]	Loss: 0.905169
[2022-06-09 12:07:48 | train] - Train Epoch: [62] [12800/1281167 (1%)]	Loss: 1.002499
[2022-06-09 12:08:09 | train] - Train Epoch: [62] [25600/1281167 (2%)]	Loss: 1.296465
[2022-06-09 12:08:30 | train] - Train Epoch: [62] [38400/1281167 (3%)]	Loss: 1.314693
[2022-06-09 12:08:51 | train] - Train Epoch: [62] [51200/1281167 (4%)]	Loss: 0.942291
[2022-06-09 12:09:12 | train] - Train Epoch: [62] [64000/1281167 (5%)]	Loss: 1.065213
[2022-06-09 12:09:33 | train] - Train Epoch: [62] [76800/1281167 (6%)]	Loss: 1.181267
[2022-06-09 12:09:54 | train] - Train Epoch: [62] [89600/1281167 (7%)]	Loss: 1.145434
[2022-06-09 12:10:16 | train] - Train Epoch: [62] [102400/1281167 (8%)]	Loss: 0.877346
[2022-06-09 12:10:37 | train] - Train Epoch: [62] [115200/1281167 (9%)]	Loss: 1.099573
[2022-06-09 12:10:58 | train] - Train Epoch: [62] [128000/1281167 (10%)]	Loss: 0.982987
[2022-06-09 12:11:19 | train] - Train Epoch: [62] [140800/1281167 (11%)]	Loss: 1.000475
[2022-06-09 12:11:40 | train] - Train Epoch: [62] [153600/1281167 (12%)]	Loss: 0.952994
[2022-06-09 12:12:01 | train] - Train Epoch: [62] [166400/1281167 (13%)]	Loss: 1.140727
[2022-06-09 12:12:22 | train] - Train Epoch: [62] [179200/1281167 (14%)]	Loss: 0.840624
[2022-06-09 12:12:43 | train] - Train Epoch: [62] [192000/1281167 (15%)]	Loss: 0.909226
[2022-06-09 12:13:05 | train] - Train Epoch: [62] [204800/1281167 (16%)]	Loss: 1.235929
[2022-06-09 12:13:26 | train] - Train Epoch: [62] [217600/1281167 (17%)]	Loss: 1.078441
[2022-06-09 12:13:48 | train] - Train Epoch: [62] [230400/1281167 (18%)]	Loss: 0.675292
[2022-06-09 12:14:09 | train] - Train Epoch: [62] [243200/1281167 (19%)]	Loss: 1.053111
[2022-06-09 12:14:29 | train] - Train Epoch: [62] [256000/1281167 (20%)]	Loss: 1.044300
[2022-06-09 12:14:50 | train] - Train Epoch: [62] [268800/1281167 (21%)]	Loss: 0.960361
[2022-06-09 12:15:12 | train] - Train Epoch: [62] [281600/1281167 (22%)]	Loss: 0.783949
[2022-06-09 12:15:33 | train] - Train Epoch: [62] [294400/1281167 (23%)]	Loss: 0.997830
[2022-06-09 12:15:54 | train] - Train Epoch: [62] [307200/1281167 (24%)]	Loss: 0.819775
[2022-06-09 12:16:15 | train] - Train Epoch: [62] [320000/1281167 (25%)]	Loss: 0.890370
[2022-06-09 12:16:36 | train] - Train Epoch: [62] [332800/1281167 (26%)]	Loss: 0.825730
[2022-06-09 12:16:58 | train] - Train Epoch: [62] [345600/1281167 (27%)]	Loss: 1.324016
[2022-06-09 12:17:18 | train] - Train Epoch: [62] [358400/1281167 (28%)]	Loss: 0.755393
[2022-06-09 12:17:40 | train] - Train Epoch: [62] [371200/1281167 (29%)]	Loss: 0.693804
[2022-06-09 12:18:01 | train] - Train Epoch: [62] [384000/1281167 (30%)]	Loss: 0.931664
[2022-06-09 12:18:23 | train] - Train Epoch: [62] [396800/1281167 (31%)]	Loss: 1.047747
[2022-06-09 12:18:45 | train] - Train Epoch: [62] [409600/1281167 (32%)]	Loss: 0.945920
[2022-06-09 12:19:06 | train] - Train Epoch: [62] [422400/1281167 (33%)]	Loss: 1.114691
[2022-06-09 12:19:28 | train] - Train Epoch: [62] [435200/1281167 (34%)]	Loss: 0.805042
[2022-06-09 12:19:50 | train] - Train Epoch: [62] [448000/1281167 (35%)]	Loss: 1.225521
[2022-06-09 12:20:11 | train] - Train Epoch: [62] [460800/1281167 (36%)]	Loss: 0.691918
[2022-06-09 12:20:33 | train] - Train Epoch: [62] [473600/1281167 (37%)]	Loss: 1.237507
[2022-06-09 12:20:54 | train] - Train Epoch: [62] [486400/1281167 (38%)]	Loss: 0.729406
[2022-06-09 12:21:16 | train] - Train Epoch: [62] [499200/1281167 (39%)]	Loss: 1.089375
[2022-06-09 12:21:36 | train] - Train Epoch: [62] [512000/1281167 (40%)]	Loss: 1.347538
[2022-06-09 12:21:57 | train] - Train Epoch: [62] [524800/1281167 (41%)]	Loss: 1.283398
[2022-06-09 12:22:17 | train] - Train Epoch: [62] [537600/1281167 (42%)]	Loss: 1.131450
[2022-06-09 12:22:39 | train] - Train Epoch: [62] [550400/1281167 (43%)]	Loss: 0.853723
[2022-06-09 12:23:00 | train] - Train Epoch: [62] [563200/1281167 (44%)]	Loss: 1.006595
[2022-06-09 12:23:22 | train] - Train Epoch: [62] [576000/1281167 (45%)]	Loss: 1.022169
[2022-06-09 12:23:42 | train] - Train Epoch: [62] [588800/1281167 (46%)]	Loss: 0.914288
[2022-06-09 12:24:03 | train] - Train Epoch: [62] [601600/1281167 (47%)]	Loss: 1.075439
[2022-06-09 12:24:23 | train] - Train Epoch: [62] [614400/1281167 (48%)]	Loss: 0.777565
[2022-06-09 12:24:44 | train] - Train Epoch: [62] [627200/1281167 (49%)]	Loss: 0.944458
[2022-06-09 12:25:06 | train] - Train Epoch: [62] [640000/1281167 (50%)]	Loss: 1.161994
[2022-06-09 12:25:27 | train] - Train Epoch: [62] [652800/1281167 (51%)]	Loss: 1.300994
[2022-06-09 12:25:47 | train] - Train Epoch: [62] [665600/1281167 (52%)]	Loss: 0.961328
[2022-06-09 12:26:07 | train] - Train Epoch: [62] [678400/1281167 (53%)]	Loss: 1.019222
[2022-06-09 12:26:29 | train] - Train Epoch: [62] [691200/1281167 (54%)]	Loss: 0.686716
[2022-06-09 12:26:49 | train] - Train Epoch: [62] [704000/1281167 (55%)]	Loss: 1.055580
[2022-06-09 12:27:10 | train] - Train Epoch: [62] [716800/1281167 (56%)]	Loss: 0.961105
[2022-06-09 12:27:32 | train] - Train Epoch: [62] [729600/1281167 (57%)]	Loss: 1.001749
[2022-06-09 12:27:53 | train] - Train Epoch: [62] [742400/1281167 (58%)]	Loss: 1.201393
[2022-06-09 12:28:15 | train] - Train Epoch: [62] [755200/1281167 (59%)]	Loss: 1.039310
[2022-06-09 12:28:37 | train] - Train Epoch: [62] [768000/1281167 (60%)]	Loss: 1.144365
[2022-06-09 12:28:59 | train] - Train Epoch: [62] [780800/1281167 (61%)]	Loss: 0.914803
[2022-06-09 12:29:20 | train] - Train Epoch: [62] [793600/1281167 (62%)]	Loss: 1.086126
[2022-06-09 12:29:41 | train] - Train Epoch: [62] [806400/1281167 (63%)]	Loss: 1.044785
[2022-06-09 12:30:02 | train] - Train Epoch: [62] [819200/1281167 (64%)]	Loss: 0.903232
[2022-06-09 12:30:23 | train] - Train Epoch: [62] [832000/1281167 (65%)]	Loss: 1.326573
[2022-06-09 12:30:45 | train] - Train Epoch: [62] [844800/1281167 (66%)]	Loss: 1.140644
[2022-06-09 12:31:06 | train] - Train Epoch: [62] [857600/1281167 (67%)]	Loss: 1.111150
[2022-06-09 12:31:26 | train] - Train Epoch: [62] [870400/1281167 (68%)]	Loss: 0.776249
[2022-06-09 12:31:48 | train] - Train Epoch: [62] [883200/1281167 (69%)]	Loss: 0.991908
[2022-06-09 12:32:09 | train] - Train Epoch: [62] [896000/1281167 (70%)]	Loss: 0.970066
[2022-06-09 12:32:30 | train] - Train Epoch: [62] [908800/1281167 (71%)]	Loss: 0.910487
[2022-06-09 12:32:52 | train] - Train Epoch: [62] [921600/1281167 (72%)]	Loss: 0.924155
[2022-06-09 12:33:12 | train] - Train Epoch: [62] [934400/1281167 (73%)]	Loss: 0.911510
[2022-06-09 12:33:34 | train] - Train Epoch: [62] [947200/1281167 (74%)]	Loss: 1.164895
[2022-06-09 12:33:56 | train] - Train Epoch: [62] [960000/1281167 (75%)]	Loss: 0.924337
[2022-06-09 12:34:17 | train] - Train Epoch: [62] [972800/1281167 (76%)]	Loss: 1.122586
[2022-06-09 12:34:38 | train] - Train Epoch: [62] [985600/1281167 (77%)]	Loss: 0.825031
[2022-06-09 12:34:59 | train] - Train Epoch: [62] [998400/1281167 (78%)]	Loss: 0.930014
[2022-06-09 12:35:20 | train] - Train Epoch: [62] [1011200/1281167 (79%)]	Loss: 1.091196
[2022-06-09 12:35:41 | train] - Train Epoch: [62] [1024000/1281167 (80%)]	Loss: 1.067096
[2022-06-09 12:36:02 | train] - Train Epoch: [62] [1036800/1281167 (81%)]	Loss: 0.805086
[2022-06-09 12:36:24 | train] - Train Epoch: [62] [1049600/1281167 (82%)]	Loss: 0.939393
[2022-06-09 12:36:43 | train] - Train Epoch: [62] [1062400/1281167 (83%)]	Loss: 1.435602
[2022-06-09 12:37:03 | train] - Train Epoch: [62] [1075200/1281167 (84%)]	Loss: 0.975985
[2022-06-09 12:37:23 | train] - Train Epoch: [62] [1088000/1281167 (85%)]	Loss: 0.961493
[2022-06-09 12:37:43 | train] - Train Epoch: [62] [1100800/1281167 (86%)]	Loss: 1.013565
[2022-06-09 12:38:03 | train] - Train Epoch: [62] [1113600/1281167 (87%)]	Loss: 1.090775
[2022-06-09 12:38:23 | train] - Train Epoch: [62] [1126400/1281167 (88%)]	Loss: 1.033094
[2022-06-09 12:38:42 | train] - Train Epoch: [62] [1139200/1281167 (89%)]	Loss: 0.973993
[2022-06-09 12:39:03 | train] - Train Epoch: [62] [1152000/1281167 (90%)]	Loss: 1.062920
[2022-06-09 12:39:22 | train] - Train Epoch: [62] [1164800/1281167 (91%)]	Loss: 1.167822
[2022-06-09 12:39:42 | train] - Train Epoch: [62] [1177600/1281167 (92%)]	Loss: 0.815131
[2022-06-09 12:40:02 | train] - Train Epoch: [62] [1190400/1281167 (93%)]	Loss: 1.314537
[2022-06-09 12:40:22 | train] - Train Epoch: [62] [1203200/1281167 (94%)]	Loss: 0.868759
[2022-06-09 12:40:42 | train] - Train Epoch: [62] [1216000/1281167 (95%)]	Loss: 0.994668
[2022-06-09 12:41:01 | train] - Train Epoch: [62] [1228800/1281167 (96%)]	Loss: 1.082685
[2022-06-09 12:41:21 | train] - Train Epoch: [62] [1241600/1281167 (97%)]	Loss: 0.952272
[2022-06-09 12:41:41 | train] - Train Epoch: [62] [1254400/1281167 (98%)]	Loss: 1.039707
[2022-06-09 12:42:00 | train] - Train Epoch: [62] [1267200/1281167 (99%)]	Loss: 1.001464
[2022-06-09 12:42:20 | train] - Train Epoch: [62] [1280000/1281167 (100%)]	Loss: 0.903099
[2022-06-09 12:42:22 | train] - Train Epoch: [62]	 Average Loss: 0.977817	 Total Acc : 76.3255	 Total Top5 Acc : 90.9970
[2022-06-09 12:42:22 | train] - -------62 epoch end-----------
========================================
-------62 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 12:43:53 | train] - 
Epoch [62] Test set: Average loss: 1.3035, Accuracy: 35141/50000 (70.2530%), Top-5 Accuracy: 89.2199%

[2022-06-09 12:43:53 | train] - save intermediate epoch [62] result


[2022-06-09 12:44:11 | train] - -------63 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 12:44:13 | train] - Train Epoch: [63] [0/1281167 (0%)]	Loss: 1.287489
[2022-06-09 12:44:32 | train] - Train Epoch: [63] [12800/1281167 (1%)]	Loss: 0.890980
[2022-06-09 12:44:52 | train] - Train Epoch: [63] [25600/1281167 (2%)]	Loss: 0.960376
[2022-06-09 12:45:12 | train] - Train Epoch: [63] [38400/1281167 (3%)]	Loss: 0.988388
[2022-06-09 12:45:31 | train] - Train Epoch: [63] [51200/1281167 (4%)]	Loss: 1.124936
[2022-06-09 12:45:51 | train] - Train Epoch: [63] [64000/1281167 (5%)]	Loss: 0.860777
[2022-06-09 12:46:11 | train] - Train Epoch: [63] [76800/1281167 (6%)]	Loss: 0.711738
[2022-06-09 12:46:31 | train] - Train Epoch: [63] [89600/1281167 (7%)]	Loss: 0.996102
[2022-06-09 12:46:51 | train] - Train Epoch: [63] [102400/1281167 (8%)]	Loss: 1.018875
[2022-06-09 12:47:12 | train] - Train Epoch: [63] [115200/1281167 (9%)]	Loss: 1.148466
[2022-06-09 12:47:32 | train] - Train Epoch: [63] [128000/1281167 (10%)]	Loss: 0.839209
[2022-06-09 12:47:52 | train] - Train Epoch: [63] [140800/1281167 (11%)]	Loss: 1.101281
[2022-06-09 12:48:12 | train] - Train Epoch: [63] [153600/1281167 (12%)]	Loss: 1.198360
[2022-06-09 12:48:32 | train] - Train Epoch: [63] [166400/1281167 (13%)]	Loss: 0.929832
[2022-06-09 12:48:52 | train] - Train Epoch: [63] [179200/1281167 (14%)]	Loss: 0.973751
[2022-06-09 12:49:12 | train] - Train Epoch: [63] [192000/1281167 (15%)]	Loss: 0.798588
[2022-06-09 12:49:31 | train] - Train Epoch: [63] [204800/1281167 (16%)]	Loss: 0.857389
[2022-06-09 12:49:51 | train] - Train Epoch: [63] [217600/1281167 (17%)]	Loss: 1.237000
[2022-06-09 12:50:11 | train] - Train Epoch: [63] [230400/1281167 (18%)]	Loss: 0.574146
[2022-06-09 12:50:30 | train] - Train Epoch: [63] [243200/1281167 (19%)]	Loss: 1.192908
[2022-06-09 12:50:50 | train] - Train Epoch: [63] [256000/1281167 (20%)]	Loss: 0.809245
[2022-06-09 12:51:10 | train] - Train Epoch: [63] [268800/1281167 (21%)]	Loss: 1.130434
[2022-06-09 12:51:30 | train] - Train Epoch: [63] [281600/1281167 (22%)]	Loss: 0.994918
[2022-06-09 12:51:49 | train] - Train Epoch: [63] [294400/1281167 (23%)]	Loss: 0.848217
[2022-06-09 12:52:09 | train] - Train Epoch: [63] [307200/1281167 (24%)]	Loss: 1.112841
[2022-06-09 12:52:28 | train] - Train Epoch: [63] [320000/1281167 (25%)]	Loss: 1.060802
[2022-06-09 12:52:48 | train] - Train Epoch: [63] [332800/1281167 (26%)]	Loss: 1.040484
[2022-06-09 12:53:08 | train] - Train Epoch: [63] [345600/1281167 (27%)]	Loss: 1.015971
[2022-06-09 12:53:27 | train] - Train Epoch: [63] [358400/1281167 (28%)]	Loss: 1.044242
[2022-06-09 12:53:47 | train] - Train Epoch: [63] [371200/1281167 (29%)]	Loss: 1.254879
[2022-06-09 12:54:06 | train] - Train Epoch: [63] [384000/1281167 (30%)]	Loss: 1.060254
[2022-06-09 12:54:26 | train] - Train Epoch: [63] [396800/1281167 (31%)]	Loss: 1.128442
[2022-06-09 12:54:46 | train] - Train Epoch: [63] [409600/1281167 (32%)]	Loss: 0.650085
[2022-06-09 12:55:05 | train] - Train Epoch: [63] [422400/1281167 (33%)]	Loss: 0.900171
[2022-06-09 12:55:25 | train] - Train Epoch: [63] [435200/1281167 (34%)]	Loss: 0.942031
[2022-06-09 12:55:45 | train] - Train Epoch: [63] [448000/1281167 (35%)]	Loss: 0.825703
[2022-06-09 12:56:05 | train] - Train Epoch: [63] [460800/1281167 (36%)]	Loss: 0.987766
[2022-06-09 12:56:24 | train] - Train Epoch: [63] [473600/1281167 (37%)]	Loss: 1.004186
[2022-06-09 12:56:44 | train] - Train Epoch: [63] [486400/1281167 (38%)]	Loss: 0.904250
[2022-06-09 12:57:04 | train] - Train Epoch: [63] [499200/1281167 (39%)]	Loss: 0.929906
[2022-06-09 12:57:23 | train] - Train Epoch: [63] [512000/1281167 (40%)]	Loss: 0.999778
[2022-06-09 12:57:42 | train] - Train Epoch: [63] [524800/1281167 (41%)]	Loss: 1.052455
[2022-06-09 12:58:03 | train] - Train Epoch: [63] [537600/1281167 (42%)]	Loss: 1.243378
[2022-06-09 12:58:22 | train] - Train Epoch: [63] [550400/1281167 (43%)]	Loss: 1.030373
[2022-06-09 12:58:42 | train] - Train Epoch: [63] [563200/1281167 (44%)]	Loss: 0.726613
[2022-06-09 12:59:02 | train] - Train Epoch: [63] [576000/1281167 (45%)]	Loss: 1.089032
[2022-06-09 12:59:22 | train] - Train Epoch: [63] [588800/1281167 (46%)]	Loss: 0.987622
[2022-06-09 12:59:41 | train] - Train Epoch: [63] [601600/1281167 (47%)]	Loss: 0.964035
[2022-06-09 13:00:01 | train] - Train Epoch: [63] [614400/1281167 (48%)]	Loss: 0.959729
[2022-06-09 13:00:20 | train] - Train Epoch: [63] [627200/1281167 (49%)]	Loss: 0.986537
[2022-06-09 13:00:40 | train] - Train Epoch: [63] [640000/1281167 (50%)]	Loss: 1.087081
[2022-06-09 13:01:00 | train] - Train Epoch: [63] [652800/1281167 (51%)]	Loss: 0.989662
[2022-06-09 13:01:20 | train] - Train Epoch: [63] [665600/1281167 (52%)]	Loss: 0.847643
[2022-06-09 13:01:39 | train] - Train Epoch: [63] [678400/1281167 (53%)]	Loss: 0.946844
[2022-06-09 13:01:58 | train] - Train Epoch: [63] [691200/1281167 (54%)]	Loss: 0.894345
[2022-06-09 13:02:18 | train] - Train Epoch: [63] [704000/1281167 (55%)]	Loss: 0.723744
[2022-06-09 13:02:37 | train] - Train Epoch: [63] [716800/1281167 (56%)]	Loss: 0.987634
[2022-06-09 13:02:57 | train] - Train Epoch: [63] [729600/1281167 (57%)]	Loss: 1.062993
[2022-06-09 13:03:17 | train] - Train Epoch: [63] [742400/1281167 (58%)]	Loss: 0.813440
[2022-06-09 13:03:37 | train] - Train Epoch: [63] [755200/1281167 (59%)]	Loss: 0.886579
[2022-06-09 13:03:56 | train] - Train Epoch: [63] [768000/1281167 (60%)]	Loss: 0.750322
[2022-06-09 13:04:17 | train] - Train Epoch: [63] [780800/1281167 (61%)]	Loss: 0.737194
[2022-06-09 13:04:37 | train] - Train Epoch: [63] [793600/1281167 (62%)]	Loss: 0.963979
[2022-06-09 13:04:57 | train] - Train Epoch: [63] [806400/1281167 (63%)]	Loss: 0.864521
[2022-06-09 13:05:16 | train] - Train Epoch: [63] [819200/1281167 (64%)]	Loss: 0.854161
[2022-06-09 13:05:36 | train] - Train Epoch: [63] [832000/1281167 (65%)]	Loss: 1.119972
[2022-06-09 13:05:56 | train] - Train Epoch: [63] [844800/1281167 (66%)]	Loss: 0.743248
[2022-06-09 13:06:15 | train] - Train Epoch: [63] [857600/1281167 (67%)]	Loss: 0.877871
[2022-06-09 13:06:35 | train] - Train Epoch: [63] [870400/1281167 (68%)]	Loss: 0.906608
[2022-06-09 13:06:55 | train] - Train Epoch: [63] [883200/1281167 (69%)]	Loss: 0.989243
[2022-06-09 13:07:15 | train] - Train Epoch: [63] [896000/1281167 (70%)]	Loss: 1.332675
[2022-06-09 13:07:35 | train] - Train Epoch: [63] [908800/1281167 (71%)]	Loss: 0.981334
[2022-06-09 13:07:54 | train] - Train Epoch: [63] [921600/1281167 (72%)]	Loss: 0.580396
[2022-06-09 13:08:14 | train] - Train Epoch: [63] [934400/1281167 (73%)]	Loss: 0.920197
[2022-06-09 13:08:33 | train] - Train Epoch: [63] [947200/1281167 (74%)]	Loss: 0.903003
[2022-06-09 13:08:53 | train] - Train Epoch: [63] [960000/1281167 (75%)]	Loss: 0.844087
[2022-06-09 13:09:13 | train] - Train Epoch: [63] [972800/1281167 (76%)]	Loss: 0.825744
[2022-06-09 13:09:32 | train] - Train Epoch: [63] [985600/1281167 (77%)]	Loss: 0.909321
[2022-06-09 13:09:51 | train] - Train Epoch: [63] [998400/1281167 (78%)]	Loss: 0.823540
[2022-06-09 13:10:12 | train] - Train Epoch: [63] [1011200/1281167 (79%)]	Loss: 0.758152
[2022-06-09 13:10:31 | train] - Train Epoch: [63] [1024000/1281167 (80%)]	Loss: 1.017991
[2022-06-09 13:10:51 | train] - Train Epoch: [63] [1036800/1281167 (81%)]	Loss: 1.053366
[2022-06-09 13:11:10 | train] - Train Epoch: [63] [1049600/1281167 (82%)]	Loss: 0.967854
[2022-06-09 13:11:31 | train] - Train Epoch: [63] [1062400/1281167 (83%)]	Loss: 1.077914
[2022-06-09 13:11:50 | train] - Train Epoch: [63] [1075200/1281167 (84%)]	Loss: 0.743117
[2022-06-09 13:12:10 | train] - Train Epoch: [63] [1088000/1281167 (85%)]	Loss: 0.944593
[2022-06-09 13:12:29 | train] - Train Epoch: [63] [1100800/1281167 (86%)]	Loss: 0.835279
[2022-06-09 13:12:49 | train] - Train Epoch: [63] [1113600/1281167 (87%)]	Loss: 1.134813
[2022-06-09 13:13:08 | train] - Train Epoch: [63] [1126400/1281167 (88%)]	Loss: 0.816897
[2022-06-09 13:13:28 | train] - Train Epoch: [63] [1139200/1281167 (89%)]	Loss: 0.991571
[2022-06-09 13:13:47 | train] - Train Epoch: [63] [1152000/1281167 (90%)]	Loss: 1.148632
[2022-06-09 13:14:07 | train] - Train Epoch: [63] [1164800/1281167 (91%)]	Loss: 0.986535
[2022-06-09 13:14:27 | train] - Train Epoch: [63] [1177600/1281167 (92%)]	Loss: 0.726062
[2022-06-09 13:14:47 | train] - Train Epoch: [63] [1190400/1281167 (93%)]	Loss: 0.875783
[2022-06-09 13:15:06 | train] - Train Epoch: [63] [1203200/1281167 (94%)]	Loss: 0.875845
[2022-06-09 13:15:26 | train] - Train Epoch: [63] [1216000/1281167 (95%)]	Loss: 1.035538
[2022-06-09 13:15:45 | train] - Train Epoch: [63] [1228800/1281167 (96%)]	Loss: 0.924642
[2022-06-09 13:16:05 | train] - Train Epoch: [63] [1241600/1281167 (97%)]	Loss: 0.930349
[2022-06-09 13:16:25 | train] - Train Epoch: [63] [1254400/1281167 (98%)]	Loss: 0.732795
[2022-06-09 13:16:45 | train] - Train Epoch: [63] [1267200/1281167 (99%)]	Loss: 0.914155
[2022-06-09 13:17:05 | train] - Train Epoch: [63] [1280000/1281167 (100%)]	Loss: 1.016384
[2022-06-09 13:17:06 | train] - Train Epoch: [63]	 Average Loss: 0.970281	 Total Acc : 76.4966	 Total Top5 Acc : 91.0913
[2022-06-09 13:17:06 | train] - -------63 epoch end-----------
========================================
-------63 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 13:18:41 | train] - 
Epoch [63] Test set: Average loss: 1.3017, Accuracy: 35191/50000 (70.3517%), Top-5 Accuracy: 89.1480%

[2022-06-09 13:18:41 | train] - save intermediate epoch [63] result


[2022-06-09 13:18:57 | train] - logging best performance 63 epoch
[2022-06-09 13:18:58 | train] - -------64 epoch start-----------
========================================
----- test end -------------------------


logging best performance 63 epoch
[2022-06-09 13:19:00 | train] - Train Epoch: [64] [0/1281167 (0%)]	Loss: 0.848316
[2022-06-09 13:19:22 | train] - Train Epoch: [64] [12800/1281167 (1%)]	Loss: 0.769348
[2022-06-09 13:19:44 | train] - Train Epoch: [64] [25600/1281167 (2%)]	Loss: 0.674526
[2022-06-09 13:20:05 | train] - Train Epoch: [64] [38400/1281167 (3%)]	Loss: 0.883109
[2022-06-09 13:20:27 | train] - Train Epoch: [64] [51200/1281167 (4%)]	Loss: 0.841301
[2022-06-09 13:20:49 | train] - Train Epoch: [64] [64000/1281167 (5%)]	Loss: 0.973670
[2022-06-09 13:21:11 | train] - Train Epoch: [64] [76800/1281167 (6%)]	Loss: 1.097573
[2022-06-09 13:21:33 | train] - Train Epoch: [64] [89600/1281167 (7%)]	Loss: 0.715495
[2022-06-09 13:21:55 | train] - Train Epoch: [64] [102400/1281167 (8%)]	Loss: 0.918756
[2022-06-09 13:22:16 | train] - Train Epoch: [64] [115200/1281167 (9%)]	Loss: 0.796668
[2022-06-09 13:22:38 | train] - Train Epoch: [64] [128000/1281167 (10%)]	Loss: 0.653390
[2022-06-09 13:23:00 | train] - Train Epoch: [64] [140800/1281167 (11%)]	Loss: 0.996719
[2022-06-09 13:23:21 | train] - Train Epoch: [64] [153600/1281167 (12%)]	Loss: 0.994877
[2022-06-09 13:23:43 | train] - Train Epoch: [64] [166400/1281167 (13%)]	Loss: 1.252355
[2022-06-09 13:24:05 | train] - Train Epoch: [64] [179200/1281167 (14%)]	Loss: 1.033864
[2022-06-09 13:24:26 | train] - Train Epoch: [64] [192000/1281167 (15%)]	Loss: 1.186674
[2022-06-09 13:24:48 | train] - Train Epoch: [64] [204800/1281167 (16%)]	Loss: 0.932682
[2022-06-09 13:25:10 | train] - Train Epoch: [64] [217600/1281167 (17%)]	Loss: 1.067663
[2022-06-09 13:25:33 | train] - Train Epoch: [64] [230400/1281167 (18%)]	Loss: 1.029427
[2022-06-09 13:25:54 | train] - Train Epoch: [64] [243200/1281167 (19%)]	Loss: 1.050621
[2022-06-09 13:26:16 | train] - Train Epoch: [64] [256000/1281167 (20%)]	Loss: 0.749863
[2022-06-09 13:26:38 | train] - Train Epoch: [64] [268800/1281167 (21%)]	Loss: 1.205928
[2022-06-09 13:27:00 | train] - Train Epoch: [64] [281600/1281167 (22%)]	Loss: 0.899459
[2022-06-09 13:27:22 | train] - Train Epoch: [64] [294400/1281167 (23%)]	Loss: 1.494143
[2022-06-09 13:27:45 | train] - Train Epoch: [64] [307200/1281167 (24%)]	Loss: 0.975194
[2022-06-09 13:28:06 | train] - Train Epoch: [64] [320000/1281167 (25%)]	Loss: 0.805683
[2022-06-09 13:28:28 | train] - Train Epoch: [64] [332800/1281167 (26%)]	Loss: 0.816626
[2022-06-09 13:28:50 | train] - Train Epoch: [64] [345600/1281167 (27%)]	Loss: 1.200313
[2022-06-09 13:29:12 | train] - Train Epoch: [64] [358400/1281167 (28%)]	Loss: 1.039575
[2022-06-09 13:29:34 | train] - Train Epoch: [64] [371200/1281167 (29%)]	Loss: 1.256817
[2022-06-09 13:29:55 | train] - Train Epoch: [64] [384000/1281167 (30%)]	Loss: 0.667481
[2022-06-09 13:30:17 | train] - Train Epoch: [64] [396800/1281167 (31%)]	Loss: 1.165029
[2022-06-09 13:30:39 | train] - Train Epoch: [64] [409600/1281167 (32%)]	Loss: 1.103610
[2022-06-09 13:31:01 | train] - Train Epoch: [64] [422400/1281167 (33%)]	Loss: 0.784950
[2022-06-09 13:31:22 | train] - Train Epoch: [64] [435200/1281167 (34%)]	Loss: 0.952029
[2022-06-09 13:31:45 | train] - Train Epoch: [64] [448000/1281167 (35%)]	Loss: 0.977411
[2022-06-09 13:32:07 | train] - Train Epoch: [64] [460800/1281167 (36%)]	Loss: 1.215645
[2022-06-09 13:32:29 | train] - Train Epoch: [64] [473600/1281167 (37%)]	Loss: 1.061395
[2022-06-09 13:32:51 | train] - Train Epoch: [64] [486400/1281167 (38%)]	Loss: 1.132391
[2022-06-09 13:33:12 | train] - Train Epoch: [64] [499200/1281167 (39%)]	Loss: 0.918714
[2022-06-09 13:33:33 | train] - Train Epoch: [64] [512000/1281167 (40%)]	Loss: 1.261251
[2022-06-09 13:33:55 | train] - Train Epoch: [64] [524800/1281167 (41%)]	Loss: 1.003097
[2022-06-09 13:34:17 | train] - Train Epoch: [64] [537600/1281167 (42%)]	Loss: 0.913975
[2022-06-09 13:34:39 | train] - Train Epoch: [64] [550400/1281167 (43%)]	Loss: 0.862078
[2022-06-09 13:35:01 | train] - Train Epoch: [64] [563200/1281167 (44%)]	Loss: 1.187080
[2022-06-09 13:35:23 | train] - Train Epoch: [64] [576000/1281167 (45%)]	Loss: 0.980062
[2022-06-09 13:35:45 | train] - Train Epoch: [64] [588800/1281167 (46%)]	Loss: 0.808272
[2022-06-09 13:36:06 | train] - Train Epoch: [64] [601600/1281167 (47%)]	Loss: 1.063131
[2022-06-09 13:36:28 | train] - Train Epoch: [64] [614400/1281167 (48%)]	Loss: 0.982589
[2022-06-09 13:36:51 | train] - Train Epoch: [64] [627200/1281167 (49%)]	Loss: 1.006830
[2022-06-09 13:37:12 | train] - Train Epoch: [64] [640000/1281167 (50%)]	Loss: 1.412323
[2022-06-09 13:37:34 | train] - Train Epoch: [64] [652800/1281167 (51%)]	Loss: 1.053188
[2022-06-09 13:37:56 | train] - Train Epoch: [64] [665600/1281167 (52%)]	Loss: 0.923531
[2022-06-09 13:38:18 | train] - Train Epoch: [64] [678400/1281167 (53%)]	Loss: 0.866393
[2022-06-09 13:38:40 | train] - Train Epoch: [64] [691200/1281167 (54%)]	Loss: 1.022178
[2022-06-09 13:39:02 | train] - Train Epoch: [64] [704000/1281167 (55%)]	Loss: 1.091190
[2022-06-09 13:39:24 | train] - Train Epoch: [64] [716800/1281167 (56%)]	Loss: 1.024791
[2022-06-09 13:39:46 | train] - Train Epoch: [64] [729600/1281167 (57%)]	Loss: 1.017714
[2022-06-09 13:40:07 | train] - Train Epoch: [64] [742400/1281167 (58%)]	Loss: 0.933754
[2022-06-09 13:40:28 | train] - Train Epoch: [64] [755200/1281167 (59%)]	Loss: 0.938135
[2022-06-09 13:40:50 | train] - Train Epoch: [64] [768000/1281167 (60%)]	Loss: 0.749485
[2022-06-09 13:41:12 | train] - Train Epoch: [64] [780800/1281167 (61%)]	Loss: 0.902787
[2022-06-09 13:41:34 | train] - Train Epoch: [64] [793600/1281167 (62%)]	Loss: 1.208295
[2022-06-09 13:41:56 | train] - Train Epoch: [64] [806400/1281167 (63%)]	Loss: 1.040047
[2022-06-09 13:42:19 | train] - Train Epoch: [64] [819200/1281167 (64%)]	Loss: 0.862289
[2022-06-09 13:42:41 | train] - Train Epoch: [64] [832000/1281167 (65%)]	Loss: 0.910779
[2022-06-09 13:43:03 | train] - Train Epoch: [64] [844800/1281167 (66%)]	Loss: 1.005907
[2022-06-09 13:43:25 | train] - Train Epoch: [64] [857600/1281167 (67%)]	Loss: 0.598072
[2022-06-09 13:43:46 | train] - Train Epoch: [64] [870400/1281167 (68%)]	Loss: 0.736049
[2022-06-09 13:44:09 | train] - Train Epoch: [64] [883200/1281167 (69%)]	Loss: 0.995873
[2022-06-09 13:44:30 | train] - Train Epoch: [64] [896000/1281167 (70%)]	Loss: 0.894453
[2022-06-09 13:44:52 | train] - Train Epoch: [64] [908800/1281167 (71%)]	Loss: 0.791574
[2022-06-09 13:45:13 | train] - Train Epoch: [64] [921600/1281167 (72%)]	Loss: 0.975854
[2022-06-09 13:45:34 | train] - Train Epoch: [64] [934400/1281167 (73%)]	Loss: 1.031803
[2022-06-09 13:45:56 | train] - Train Epoch: [64] [947200/1281167 (74%)]	Loss: 1.066508
[2022-06-09 13:46:18 | train] - Train Epoch: [64] [960000/1281167 (75%)]	Loss: 1.046092
[2022-06-09 13:46:40 | train] - Train Epoch: [64] [972800/1281167 (76%)]	Loss: 1.052869
[2022-06-09 13:47:02 | train] - Train Epoch: [64] [985600/1281167 (77%)]	Loss: 0.998727
[2022-06-09 13:47:24 | train] - Train Epoch: [64] [998400/1281167 (78%)]	Loss: 0.943778
[2022-06-09 13:47:46 | train] - Train Epoch: [64] [1011200/1281167 (79%)]	Loss: 0.880907
[2022-06-09 13:48:08 | train] - Train Epoch: [64] [1024000/1281167 (80%)]	Loss: 0.961842
[2022-06-09 13:48:30 | train] - Train Epoch: [64] [1036800/1281167 (81%)]	Loss: 1.021021
[2022-06-09 13:48:52 | train] - Train Epoch: [64] [1049600/1281167 (82%)]	Loss: 1.183841
[2022-06-09 13:49:14 | train] - Train Epoch: [64] [1062400/1281167 (83%)]	Loss: 0.809958
[2022-06-09 13:49:36 | train] - Train Epoch: [64] [1075200/1281167 (84%)]	Loss: 0.898607
[2022-06-09 13:49:58 | train] - Train Epoch: [64] [1088000/1281167 (85%)]	Loss: 0.931031
[2022-06-09 13:50:21 | train] - Train Epoch: [64] [1100800/1281167 (86%)]	Loss: 0.962206
[2022-06-09 13:50:43 | train] - Train Epoch: [64] [1113600/1281167 (87%)]	Loss: 0.872732
[2022-06-09 13:51:05 | train] - Train Epoch: [64] [1126400/1281167 (88%)]	Loss: 1.200748
[2022-06-09 13:51:26 | train] - Train Epoch: [64] [1139200/1281167 (89%)]	Loss: 0.846295
[2022-06-09 13:51:49 | train] - Train Epoch: [64] [1152000/1281167 (90%)]	Loss: 0.926136
[2022-06-09 13:52:10 | train] - Train Epoch: [64] [1164800/1281167 (91%)]	Loss: 0.774620
[2022-06-09 13:52:33 | train] - Train Epoch: [64] [1177600/1281167 (92%)]	Loss: 1.058359
[2022-06-09 13:52:55 | train] - Train Epoch: [64] [1190400/1281167 (93%)]	Loss: 0.916377
[2022-06-09 13:53:16 | train] - Train Epoch: [64] [1203200/1281167 (94%)]	Loss: 0.928679
[2022-06-09 13:53:38 | train] - Train Epoch: [64] [1216000/1281167 (95%)]	Loss: 1.217424
[2022-06-09 13:54:00 | train] - Train Epoch: [64] [1228800/1281167 (96%)]	Loss: 0.774673
[2022-06-09 13:54:21 | train] - Train Epoch: [64] [1241600/1281167 (97%)]	Loss: 0.877961
[2022-06-09 13:54:44 | train] - Train Epoch: [64] [1254400/1281167 (98%)]	Loss: 0.900171
[2022-06-09 13:55:06 | train] - Train Epoch: [64] [1267200/1281167 (99%)]	Loss: 1.133308
[2022-06-09 13:55:28 | train] - Train Epoch: [64] [1280000/1281167 (100%)]	Loss: 1.187025
[2022-06-09 13:55:30 | train] - Train Epoch: [64]	 Average Loss: 0.962377	 Total Acc : 76.6277	 Total Top5 Acc : 91.1780
[2022-06-09 13:55:30 | train] - -------64 epoch end-----------
========================================
-------64 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 13:57:03 | train] - 
Epoch [64] Test set: Average loss: 1.3060, Accuracy: 35158/50000 (70.2809%), Top-5 Accuracy: 89.1824%

[2022-06-09 13:57:03 | train] - save intermediate epoch [64] result


[2022-06-09 13:57:20 | train] - -------65 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 13:57:22 | train] - Train Epoch: [65] [0/1281167 (0%)]	Loss: 0.855166
[2022-06-09 13:57:44 | train] - Train Epoch: [65] [12800/1281167 (1%)]	Loss: 0.946655
[2022-06-09 13:58:06 | train] - Train Epoch: [65] [25600/1281167 (2%)]	Loss: 1.035407
[2022-06-09 13:58:28 | train] - Train Epoch: [65] [38400/1281167 (3%)]	Loss: 1.124544
[2022-06-09 13:58:50 | train] - Train Epoch: [65] [51200/1281167 (4%)]	Loss: 1.072634
[2022-06-09 13:59:12 | train] - Train Epoch: [65] [64000/1281167 (5%)]	Loss: 0.844405
[2022-06-09 13:59:34 | train] - Train Epoch: [65] [76800/1281167 (6%)]	Loss: 0.756197
[2022-06-09 13:59:56 | train] - Train Epoch: [65] [89600/1281167 (7%)]	Loss: 0.748571
[2022-06-09 14:00:17 | train] - Train Epoch: [65] [102400/1281167 (8%)]	Loss: 1.132343
[2022-06-09 14:00:39 | train] - Train Epoch: [65] [115200/1281167 (9%)]	Loss: 1.159540
[2022-06-09 14:01:01 | train] - Train Epoch: [65] [128000/1281167 (10%)]	Loss: 0.958503
[2022-06-09 14:01:24 | train] - Train Epoch: [65] [140800/1281167 (11%)]	Loss: 0.775927
[2022-06-09 14:01:46 | train] - Train Epoch: [65] [153600/1281167 (12%)]	Loss: 0.721134
[2022-06-09 14:02:07 | train] - Train Epoch: [65] [166400/1281167 (13%)]	Loss: 0.884781
[2022-06-09 14:02:29 | train] - Train Epoch: [65] [179200/1281167 (14%)]	Loss: 0.913434
[2022-06-09 14:02:51 | train] - Train Epoch: [65] [192000/1281167 (15%)]	Loss: 0.978162
[2022-06-09 14:03:13 | train] - Train Epoch: [65] [204800/1281167 (16%)]	Loss: 0.887631
[2022-06-09 14:03:35 | train] - Train Epoch: [65] [217600/1281167 (17%)]	Loss: 0.980851
[2022-06-09 14:03:57 | train] - Train Epoch: [65] [230400/1281167 (18%)]	Loss: 0.813559
[2022-06-09 14:04:18 | train] - Train Epoch: [65] [243200/1281167 (19%)]	Loss: 0.964912
[2022-06-09 14:04:41 | train] - Train Epoch: [65] [256000/1281167 (20%)]	Loss: 0.980214
[2022-06-09 14:05:02 | train] - Train Epoch: [65] [268800/1281167 (21%)]	Loss: 0.776572
[2022-06-09 14:05:23 | train] - Train Epoch: [65] [281600/1281167 (22%)]	Loss: 1.377744
[2022-06-09 14:05:45 | train] - Train Epoch: [65] [294400/1281167 (23%)]	Loss: 0.897226
[2022-06-09 14:06:07 | train] - Train Epoch: [65] [307200/1281167 (24%)]	Loss: 1.045609
[2022-06-09 14:06:29 | train] - Train Epoch: [65] [320000/1281167 (25%)]	Loss: 0.861862
[2022-06-09 14:06:51 | train] - Train Epoch: [65] [332800/1281167 (26%)]	Loss: 0.888757
[2022-06-09 14:07:13 | train] - Train Epoch: [65] [345600/1281167 (27%)]	Loss: 1.051056
[2022-06-09 14:07:35 | train] - Train Epoch: [65] [358400/1281167 (28%)]	Loss: 1.003038
[2022-06-09 14:07:57 | train] - Train Epoch: [65] [371200/1281167 (29%)]	Loss: 0.863991
[2022-06-09 14:08:19 | train] - Train Epoch: [65] [384000/1281167 (30%)]	Loss: 0.910340
[2022-06-09 14:08:41 | train] - Train Epoch: [65] [396800/1281167 (31%)]	Loss: 1.132997
[2022-06-09 14:09:03 | train] - Train Epoch: [65] [409600/1281167 (32%)]	Loss: 1.038717
[2022-06-09 14:09:24 | train] - Train Epoch: [65] [422400/1281167 (33%)]	Loss: 0.882877
[2022-06-09 14:09:46 | train] - Train Epoch: [65] [435200/1281167 (34%)]	Loss: 0.995519
[2022-06-09 14:10:08 | train] - Train Epoch: [65] [448000/1281167 (35%)]	Loss: 1.106116
[2022-06-09 14:10:30 | train] - Train Epoch: [65] [460800/1281167 (36%)]	Loss: 0.987029
[2022-06-09 14:10:52 | train] - Train Epoch: [65] [473600/1281167 (37%)]	Loss: 0.944963
[2022-06-09 14:11:14 | train] - Train Epoch: [65] [486400/1281167 (38%)]	Loss: 0.994494
[2022-06-09 14:11:36 | train] - Train Epoch: [65] [499200/1281167 (39%)]	Loss: 1.192414
[2022-06-09 14:11:59 | train] - Train Epoch: [65] [512000/1281167 (40%)]	Loss: 1.049171
[2022-06-09 14:12:21 | train] - Train Epoch: [65] [524800/1281167 (41%)]	Loss: 0.676171
[2022-06-09 14:12:43 | train] - Train Epoch: [65] [537600/1281167 (42%)]	Loss: 0.829592
[2022-06-09 14:13:05 | train] - Train Epoch: [65] [550400/1281167 (43%)]	Loss: 1.106833
[2022-06-09 14:13:26 | train] - Train Epoch: [65] [563200/1281167 (44%)]	Loss: 0.996277
[2022-06-09 14:13:48 | train] - Train Epoch: [65] [576000/1281167 (45%)]	Loss: 0.987423
[2022-06-09 14:14:10 | train] - Train Epoch: [65] [588800/1281167 (46%)]	Loss: 0.938065
[2022-06-09 14:14:32 | train] - Train Epoch: [65] [601600/1281167 (47%)]	Loss: 1.390989
[2022-06-09 14:14:54 | train] - Train Epoch: [65] [614400/1281167 (48%)]	Loss: 1.129138
[2022-06-09 14:15:16 | train] - Train Epoch: [65] [627200/1281167 (49%)]	Loss: 0.887061
[2022-06-09 14:15:38 | train] - Train Epoch: [65] [640000/1281167 (50%)]	Loss: 0.951204
[2022-06-09 14:16:00 | train] - Train Epoch: [65] [652800/1281167 (51%)]	Loss: 1.009742
[2022-06-09 14:16:22 | train] - Train Epoch: [65] [665600/1281167 (52%)]	Loss: 1.160897
[2022-06-09 14:16:44 | train] - Train Epoch: [65] [678400/1281167 (53%)]	Loss: 0.834808
[2022-06-09 14:17:05 | train] - Train Epoch: [65] [691200/1281167 (54%)]	Loss: 0.771800
[2022-06-09 14:17:28 | train] - Train Epoch: [65] [704000/1281167 (55%)]	Loss: 1.020955
[2022-06-09 14:17:49 | train] - Train Epoch: [65] [716800/1281167 (56%)]	Loss: 0.987460
[2022-06-09 14:18:12 | train] - Train Epoch: [65] [729600/1281167 (57%)]	Loss: 0.896618
[2022-06-09 14:18:34 | train] - Train Epoch: [65] [742400/1281167 (58%)]	Loss: 1.221071
[2022-06-09 14:18:56 | train] - Train Epoch: [65] [755200/1281167 (59%)]	Loss: 0.993389
[2022-06-09 14:19:19 | train] - Train Epoch: [65] [768000/1281167 (60%)]	Loss: 1.015118
[2022-06-09 14:19:41 | train] - Train Epoch: [65] [780800/1281167 (61%)]	Loss: 1.002493
[2022-06-09 14:20:03 | train] - Train Epoch: [65] [793600/1281167 (62%)]	Loss: 1.272151
[2022-06-09 14:20:24 | train] - Train Epoch: [65] [806400/1281167 (63%)]	Loss: 0.890408
[2022-06-09 14:20:46 | train] - Train Epoch: [65] [819200/1281167 (64%)]	Loss: 0.828309
[2022-06-09 14:21:08 | train] - Train Epoch: [65] [832000/1281167 (65%)]	Loss: 0.732691
[2022-06-09 14:21:29 | train] - Train Epoch: [65] [844800/1281167 (66%)]	Loss: 0.917282
[2022-06-09 14:21:51 | train] - Train Epoch: [65] [857600/1281167 (67%)]	Loss: 1.017165
[2022-06-09 14:22:12 | train] - Train Epoch: [65] [870400/1281167 (68%)]	Loss: 1.090792
[2022-06-09 14:22:34 | train] - Train Epoch: [65] [883200/1281167 (69%)]	Loss: 0.877614
[2022-06-09 14:22:54 | train] - Train Epoch: [65] [896000/1281167 (70%)]	Loss: 0.870084
[2022-06-09 14:23:15 | train] - Train Epoch: [65] [908800/1281167 (71%)]	Loss: 1.089858
[2022-06-09 14:23:36 | train] - Train Epoch: [65] [921600/1281167 (72%)]	Loss: 1.027716
[2022-06-09 14:23:57 | train] - Train Epoch: [65] [934400/1281167 (73%)]	Loss: 0.971806
[2022-06-09 14:24:18 | train] - Train Epoch: [65] [947200/1281167 (74%)]	Loss: 1.017173
[2022-06-09 14:24:39 | train] - Train Epoch: [65] [960000/1281167 (75%)]	Loss: 1.121841
[2022-06-09 14:25:02 | train] - Train Epoch: [65] [972800/1281167 (76%)]	Loss: 0.766605
[2022-06-09 14:25:24 | train] - Train Epoch: [65] [985600/1281167 (77%)]	Loss: 1.048769
[2022-06-09 14:25:45 | train] - Train Epoch: [65] [998400/1281167 (78%)]	Loss: 1.020291
[2022-06-09 14:26:07 | train] - Train Epoch: [65] [1011200/1281167 (79%)]	Loss: 0.873125
[2022-06-09 14:26:29 | train] - Train Epoch: [65] [1024000/1281167 (80%)]	Loss: 0.779573
[2022-06-09 14:26:51 | train] - Train Epoch: [65] [1036800/1281167 (81%)]	Loss: 1.172373
[2022-06-09 14:27:13 | train] - Train Epoch: [65] [1049600/1281167 (82%)]	Loss: 1.130636
[2022-06-09 14:27:35 | train] - Train Epoch: [65] [1062400/1281167 (83%)]	Loss: 0.923383
[2022-06-09 14:27:57 | train] - Train Epoch: [65] [1075200/1281167 (84%)]	Loss: 0.965711
[2022-06-09 14:28:19 | train] - Train Epoch: [65] [1088000/1281167 (85%)]	Loss: 0.843728
[2022-06-09 14:28:40 | train] - Train Epoch: [65] [1100800/1281167 (86%)]	Loss: 1.056825
[2022-06-09 14:29:02 | train] - Train Epoch: [65] [1113600/1281167 (87%)]	Loss: 0.955662
[2022-06-09 14:29:24 | train] - Train Epoch: [65] [1126400/1281167 (88%)]	Loss: 1.006935
[2022-06-09 14:29:46 | train] - Train Epoch: [65] [1139200/1281167 (89%)]	Loss: 0.737195
[2022-06-09 14:30:08 | train] - Train Epoch: [65] [1152000/1281167 (90%)]	Loss: 0.906536
[2022-06-09 14:30:30 | train] - Train Epoch: [65] [1164800/1281167 (91%)]	Loss: 0.862860
[2022-06-09 14:30:53 | train] - Train Epoch: [65] [1177600/1281167 (92%)]	Loss: 0.925385
[2022-06-09 14:31:15 | train] - Train Epoch: [65] [1190400/1281167 (93%)]	Loss: 0.994618
[2022-06-09 14:31:37 | train] - Train Epoch: [65] [1203200/1281167 (94%)]	Loss: 1.093379
[2022-06-09 14:31:59 | train] - Train Epoch: [65] [1216000/1281167 (95%)]	Loss: 0.956718
[2022-06-09 14:32:21 | train] - Train Epoch: [65] [1228800/1281167 (96%)]	Loss: 0.992299
[2022-06-09 14:32:43 | train] - Train Epoch: [65] [1241600/1281167 (97%)]	Loss: 0.977581
[2022-06-09 14:33:05 | train] - Train Epoch: [65] [1254400/1281167 (98%)]	Loss: 0.994147
[2022-06-09 14:33:27 | train] - Train Epoch: [65] [1267200/1281167 (99%)]	Loss: 0.930835
[2022-06-09 14:33:49 | train] - Train Epoch: [65] [1280000/1281167 (100%)]	Loss: 1.142833
[2022-06-09 14:33:51 | train] - Train Epoch: [65]	 Average Loss: 0.955954	 Total Acc : 76.7654	 Total Top5 Acc : 91.2267
[2022-06-09 14:33:51 | train] - -------65 epoch end-----------
========================================
-------65 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 14:35:26 | train] - 
Epoch [65] Test set: Average loss: 1.3016, Accuracy: 35194/50000 (70.3649%), Top-5 Accuracy: 89.2048%

[2022-06-09 14:35:26 | train] - save intermediate epoch [65] result


[2022-06-09 14:35:42 | train] - logging best performance 65 epoch
[2022-06-09 14:35:43 | train] - -------66 epoch start-----------
========================================
----- test end -------------------------


logging best performance 65 epoch
[2022-06-09 14:35:45 | train] - Train Epoch: [66] [0/1281167 (0%)]	Loss: 0.981444
[2022-06-09 14:36:07 | train] - Train Epoch: [66] [12800/1281167 (1%)]	Loss: 0.975809
[2022-06-09 14:36:28 | train] - Train Epoch: [66] [25600/1281167 (2%)]	Loss: 0.878967
[2022-06-09 14:36:50 | train] - Train Epoch: [66] [38400/1281167 (3%)]	Loss: 0.892589
[2022-06-09 14:37:12 | train] - Train Epoch: [66] [51200/1281167 (4%)]	Loss: 1.101377
[2022-06-09 14:37:34 | train] - Train Epoch: [66] [64000/1281167 (5%)]	Loss: 1.230724
[2022-06-09 14:37:56 | train] - Train Epoch: [66] [76800/1281167 (6%)]	Loss: 1.139658
[2022-06-09 14:38:18 | train] - Train Epoch: [66] [89600/1281167 (7%)]	Loss: 0.939478
[2022-06-09 14:38:39 | train] - Train Epoch: [66] [102400/1281167 (8%)]	Loss: 1.081710
[2022-06-09 14:39:02 | train] - Train Epoch: [66] [115200/1281167 (9%)]	Loss: 0.754152
[2022-06-09 14:39:23 | train] - Train Epoch: [66] [128000/1281167 (10%)]	Loss: 0.733454
[2022-06-09 14:39:45 | train] - Train Epoch: [66] [140800/1281167 (11%)]	Loss: 1.079788
[2022-06-09 14:40:07 | train] - Train Epoch: [66] [153600/1281167 (12%)]	Loss: 1.108235
[2022-06-09 14:40:29 | train] - Train Epoch: [66] [166400/1281167 (13%)]	Loss: 1.143557
[2022-06-09 14:40:50 | train] - Train Epoch: [66] [179200/1281167 (14%)]	Loss: 0.914126
[2022-06-09 14:41:11 | train] - Train Epoch: [66] [192000/1281167 (15%)]	Loss: 1.020084
[2022-06-09 14:41:33 | train] - Train Epoch: [66] [204800/1281167 (16%)]	Loss: 0.844405
[2022-06-09 14:41:55 | train] - Train Epoch: [66] [217600/1281167 (17%)]	Loss: 1.228223
[2022-06-09 14:42:17 | train] - Train Epoch: [66] [230400/1281167 (18%)]	Loss: 0.893748
[2022-06-09 14:42:39 | train] - Train Epoch: [66] [243200/1281167 (19%)]	Loss: 1.139578
[2022-06-09 14:43:01 | train] - Train Epoch: [66] [256000/1281167 (20%)]	Loss: 0.940924
[2022-06-09 14:43:23 | train] - Train Epoch: [66] [268800/1281167 (21%)]	Loss: 0.835345
[2022-06-09 14:43:45 | train] - Train Epoch: [66] [281600/1281167 (22%)]	Loss: 0.996696
[2022-06-09 14:44:07 | train] - Train Epoch: [66] [294400/1281167 (23%)]	Loss: 0.801975
[2022-06-09 14:44:28 | train] - Train Epoch: [66] [307200/1281167 (24%)]	Loss: 0.803048
[2022-06-09 14:44:51 | train] - Train Epoch: [66] [320000/1281167 (25%)]	Loss: 1.029079
[2022-06-09 14:45:13 | train] - Train Epoch: [66] [332800/1281167 (26%)]	Loss: 0.989735
[2022-06-09 14:45:35 | train] - Train Epoch: [66] [345600/1281167 (27%)]	Loss: 1.093634
[2022-06-09 14:45:57 | train] - Train Epoch: [66] [358400/1281167 (28%)]	Loss: 1.199645
[2022-06-09 14:46:20 | train] - Train Epoch: [66] [371200/1281167 (29%)]	Loss: 1.117131
[2022-06-09 14:46:42 | train] - Train Epoch: [66] [384000/1281167 (30%)]	Loss: 0.989058
[2022-06-09 14:47:04 | train] - Train Epoch: [66] [396800/1281167 (31%)]	Loss: 0.828684
[2022-06-09 14:47:25 | train] - Train Epoch: [66] [409600/1281167 (32%)]	Loss: 1.122187
[2022-06-09 14:47:47 | train] - Train Epoch: [66] [422400/1281167 (33%)]	Loss: 1.087068
[2022-06-09 14:48:09 | train] - Train Epoch: [66] [435200/1281167 (34%)]	Loss: 1.137950
[2022-06-09 14:48:31 | train] - Train Epoch: [66] [448000/1281167 (35%)]	Loss: 1.298530
[2022-06-09 14:48:52 | train] - Train Epoch: [66] [460800/1281167 (36%)]	Loss: 0.741500
[2022-06-09 14:49:15 | train] - Train Epoch: [66] [473600/1281167 (37%)]	Loss: 0.900242
[2022-06-09 14:49:37 | train] - Train Epoch: [66] [486400/1281167 (38%)]	Loss: 0.971290
[2022-06-09 14:49:59 | train] - Train Epoch: [66] [499200/1281167 (39%)]	Loss: 0.984369
[2022-06-09 14:50:21 | train] - Train Epoch: [66] [512000/1281167 (40%)]	Loss: 0.821360
[2022-06-09 14:50:43 | train] - Train Epoch: [66] [524800/1281167 (41%)]	Loss: 1.163715
[2022-06-09 14:51:04 | train] - Train Epoch: [66] [537600/1281167 (42%)]	Loss: 0.546578
[2022-06-09 14:51:26 | train] - Train Epoch: [66] [550400/1281167 (43%)]	Loss: 0.986915
[2022-06-09 14:51:48 | train] - Train Epoch: [66] [563200/1281167 (44%)]	Loss: 0.933096
[2022-06-09 14:52:11 | train] - Train Epoch: [66] [576000/1281167 (45%)]	Loss: 0.843193
[2022-06-09 14:52:33 | train] - Train Epoch: [66] [588800/1281167 (46%)]	Loss: 0.933902
[2022-06-09 14:52:55 | train] - Train Epoch: [66] [601600/1281167 (47%)]	Loss: 1.401502
[2022-06-09 14:53:17 | train] - Train Epoch: [66] [614400/1281167 (48%)]	Loss: 1.027269
[2022-06-09 14:53:39 | train] - Train Epoch: [66] [627200/1281167 (49%)]	Loss: 1.136305
[2022-06-09 14:54:01 | train] - Train Epoch: [66] [640000/1281167 (50%)]	Loss: 0.956381
[2022-06-09 14:54:22 | train] - Train Epoch: [66] [652800/1281167 (51%)]	Loss: 0.887962
[2022-06-09 14:54:45 | train] - Train Epoch: [66] [665600/1281167 (52%)]	Loss: 0.907401
[2022-06-09 14:55:07 | train] - Train Epoch: [66] [678400/1281167 (53%)]	Loss: 0.938247
[2022-06-09 14:55:29 | train] - Train Epoch: [66] [691200/1281167 (54%)]	Loss: 0.840874
[2022-06-09 14:55:51 | train] - Train Epoch: [66] [704000/1281167 (55%)]	Loss: 0.992733
[2022-06-09 14:56:13 | train] - Train Epoch: [66] [716800/1281167 (56%)]	Loss: 0.637918
[2022-06-09 14:56:35 | train] - Train Epoch: [66] [729600/1281167 (57%)]	Loss: 1.067772
[2022-06-09 14:56:57 | train] - Train Epoch: [66] [742400/1281167 (58%)]	Loss: 0.865454
[2022-06-09 14:57:19 | train] - Train Epoch: [66] [755200/1281167 (59%)]	Loss: 0.919574
[2022-06-09 14:57:42 | train] - Train Epoch: [66] [768000/1281167 (60%)]	Loss: 0.993261
[2022-06-09 14:58:03 | train] - Train Epoch: [66] [780800/1281167 (61%)]	Loss: 1.027595
[2022-06-09 14:58:25 | train] - Train Epoch: [66] [793600/1281167 (62%)]	Loss: 0.876513
[2022-06-09 14:58:47 | train] - Train Epoch: [66] [806400/1281167 (63%)]	Loss: 0.826259
[2022-06-09 14:59:09 | train] - Train Epoch: [66] [819200/1281167 (64%)]	Loss: 0.869129
[2022-06-09 14:59:31 | train] - Train Epoch: [66] [832000/1281167 (65%)]	Loss: 0.935409
[2022-06-09 14:59:53 | train] - Train Epoch: [66] [844800/1281167 (66%)]	Loss: 0.995959
[2022-06-09 15:00:15 | train] - Train Epoch: [66] [857600/1281167 (67%)]	Loss: 0.711998
[2022-06-09 15:00:37 | train] - Train Epoch: [66] [870400/1281167 (68%)]	Loss: 0.914538
[2022-06-09 15:00:59 | train] - Train Epoch: [66] [883200/1281167 (69%)]	Loss: 1.021825
[2022-06-09 15:01:21 | train] - Train Epoch: [66] [896000/1281167 (70%)]	Loss: 0.739092
[2022-06-09 15:01:43 | train] - Train Epoch: [66] [908800/1281167 (71%)]	Loss: 0.866563
[2022-06-09 15:02:05 | train] - Train Epoch: [66] [921600/1281167 (72%)]	Loss: 1.097838
[2022-06-09 15:02:27 | train] - Train Epoch: [66] [934400/1281167 (73%)]	Loss: 1.073127
[2022-06-09 15:02:49 | train] - Train Epoch: [66] [947200/1281167 (74%)]	Loss: 1.017726
[2022-06-09 15:03:11 | train] - Train Epoch: [66] [960000/1281167 (75%)]	Loss: 1.017135
[2022-06-09 15:03:33 | train] - Train Epoch: [66] [972800/1281167 (76%)]	Loss: 0.919565
[2022-06-09 15:03:55 | train] - Train Epoch: [66] [985600/1281167 (77%)]	Loss: 0.860831
[2022-06-09 15:04:18 | train] - Train Epoch: [66] [998400/1281167 (78%)]	Loss: 1.066456
[2022-06-09 15:04:39 | train] - Train Epoch: [66] [1011200/1281167 (79%)]	Loss: 1.155603
[2022-06-09 15:05:01 | train] - Train Epoch: [66] [1024000/1281167 (80%)]	Loss: 0.740516
[2022-06-09 15:05:24 | train] - Train Epoch: [66] [1036800/1281167 (81%)]	Loss: 1.016319
[2022-06-09 15:05:46 | train] - Train Epoch: [66] [1049600/1281167 (82%)]	Loss: 0.904357
[2022-06-09 15:06:07 | train] - Train Epoch: [66] [1062400/1281167 (83%)]	Loss: 0.900922
[2022-06-09 15:06:28 | train] - Train Epoch: [66] [1075200/1281167 (84%)]	Loss: 1.058109
[2022-06-09 15:06:51 | train] - Train Epoch: [66] [1088000/1281167 (85%)]	Loss: 0.979827
[2022-06-09 15:07:13 | train] - Train Epoch: [66] [1100800/1281167 (86%)]	Loss: 0.849144
[2022-06-09 15:07:35 | train] - Train Epoch: [66] [1113600/1281167 (87%)]	Loss: 0.874452
[2022-06-09 15:07:57 | train] - Train Epoch: [66] [1126400/1281167 (88%)]	Loss: 0.848937
[2022-06-09 15:08:19 | train] - Train Epoch: [66] [1139200/1281167 (89%)]	Loss: 0.863426
[2022-06-09 15:08:40 | train] - Train Epoch: [66] [1152000/1281167 (90%)]	Loss: 0.967617
[2022-06-09 15:09:02 | train] - Train Epoch: [66] [1164800/1281167 (91%)]	Loss: 0.891830
[2022-06-09 15:09:24 | train] - Train Epoch: [66] [1177600/1281167 (92%)]	Loss: 1.176876
[2022-06-09 15:09:46 | train] - Train Epoch: [66] [1190400/1281167 (93%)]	Loss: 1.347431
[2022-06-09 15:10:08 | train] - Train Epoch: [66] [1203200/1281167 (94%)]	Loss: 0.794786
[2022-06-09 15:10:30 | train] - Train Epoch: [66] [1216000/1281167 (95%)]	Loss: 0.970218
[2022-06-09 15:10:52 | train] - Train Epoch: [66] [1228800/1281167 (96%)]	Loss: 1.001334
[2022-06-09 15:11:13 | train] - Train Epoch: [66] [1241600/1281167 (97%)]	Loss: 0.878962
[2022-06-09 15:11:35 | train] - Train Epoch: [66] [1254400/1281167 (98%)]	Loss: 1.158678
[2022-06-09 15:11:57 | train] - Train Epoch: [66] [1267200/1281167 (99%)]	Loss: 1.034484
[2022-06-09 15:12:19 | train] - Train Epoch: [66] [1280000/1281167 (100%)]	Loss: 1.146787
[2022-06-09 15:12:20 | train] - Train Epoch: [66]	 Average Loss: 0.951288	 Total Acc : 76.9200	 Total Top5 Acc : 91.3102
[2022-06-09 15:12:20 | train] - -------66 epoch end-----------
========================================
-------66 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 15:13:53 | train] - 
Epoch [66] Test set: Average loss: 1.3043, Accuracy: 35211/50000 (70.3964%), Top-5 Accuracy: 89.2211%

[2022-06-09 15:13:53 | train] - save intermediate epoch [66] result


[2022-06-09 15:14:10 | train] - logging best performance 66 epoch
[2022-06-09 15:14:11 | train] - -------67 epoch start-----------
========================================
----- test end -------------------------


logging best performance 66 epoch
[2022-06-09 15:14:13 | train] - Train Epoch: [67] [0/1281167 (0%)]	Loss: 1.273486
[2022-06-09 15:14:35 | train] - Train Epoch: [67] [12800/1281167 (1%)]	Loss: 0.930286
[2022-06-09 15:14:57 | train] - Train Epoch: [67] [25600/1281167 (2%)]	Loss: 1.155033
[2022-06-09 15:15:20 | train] - Train Epoch: [67] [38400/1281167 (3%)]	Loss: 0.779481
[2022-06-09 15:15:42 | train] - Train Epoch: [67] [51200/1281167 (4%)]	Loss: 1.017678
[2022-06-09 15:16:04 | train] - Train Epoch: [67] [64000/1281167 (5%)]	Loss: 0.805182
[2022-06-09 15:16:26 | train] - Train Epoch: [67] [76800/1281167 (6%)]	Loss: 0.875194
[2022-06-09 15:16:47 | train] - Train Epoch: [67] [89600/1281167 (7%)]	Loss: 0.863889
[2022-06-09 15:17:09 | train] - Train Epoch: [67] [102400/1281167 (8%)]	Loss: 1.137630
[2022-06-09 15:17:30 | train] - Train Epoch: [67] [115200/1281167 (9%)]	Loss: 0.787601
[2022-06-09 15:17:52 | train] - Train Epoch: [67] [128000/1281167 (10%)]	Loss: 1.230990
[2022-06-09 15:18:15 | train] - Train Epoch: [67] [140800/1281167 (11%)]	Loss: 0.591343
[2022-06-09 15:18:37 | train] - Train Epoch: [67] [153600/1281167 (12%)]	Loss: 0.863050
[2022-06-09 15:18:59 | train] - Train Epoch: [67] [166400/1281167 (13%)]	Loss: 0.842353
[2022-06-09 15:19:21 | train] - Train Epoch: [67] [179200/1281167 (14%)]	Loss: 1.100410
[2022-06-09 15:19:42 | train] - Train Epoch: [67] [192000/1281167 (15%)]	Loss: 0.991600
[2022-06-09 15:20:04 | train] - Train Epoch: [67] [204800/1281167 (16%)]	Loss: 1.193455
[2022-06-09 15:20:27 | train] - Train Epoch: [67] [217600/1281167 (17%)]	Loss: 0.887678
[2022-06-09 15:20:49 | train] - Train Epoch: [67] [230400/1281167 (18%)]	Loss: 0.922895
[2022-06-09 15:21:10 | train] - Train Epoch: [67] [243200/1281167 (19%)]	Loss: 0.824636
[2022-06-09 15:21:32 | train] - Train Epoch: [67] [256000/1281167 (20%)]	Loss: 0.936337
[2022-06-09 15:21:54 | train] - Train Epoch: [67] [268800/1281167 (21%)]	Loss: 0.912725
[2022-06-09 15:22:16 | train] - Train Epoch: [67] [281600/1281167 (22%)]	Loss: 0.967169
[2022-06-09 15:22:39 | train] - Train Epoch: [67] [294400/1281167 (23%)]	Loss: 0.672160
[2022-06-09 15:23:01 | train] - Train Epoch: [67] [307200/1281167 (24%)]	Loss: 0.943503
[2022-06-09 15:23:23 | train] - Train Epoch: [67] [320000/1281167 (25%)]	Loss: 1.046125
[2022-06-09 15:23:44 | train] - Train Epoch: [67] [332800/1281167 (26%)]	Loss: 1.196210
[2022-06-09 15:24:07 | train] - Train Epoch: [67] [345600/1281167 (27%)]	Loss: 0.573838
[2022-06-09 15:24:29 | train] - Train Epoch: [67] [358400/1281167 (28%)]	Loss: 1.104212
[2022-06-09 15:24:50 | train] - Train Epoch: [67] [371200/1281167 (29%)]	Loss: 1.011197
[2022-06-09 15:25:12 | train] - Train Epoch: [67] [384000/1281167 (30%)]	Loss: 1.056373
[2022-06-09 15:25:35 | train] - Train Epoch: [67] [396800/1281167 (31%)]	Loss: 0.981067
[2022-06-09 15:25:57 | train] - Train Epoch: [67] [409600/1281167 (32%)]	Loss: 1.009462
[2022-06-09 15:26:19 | train] - Train Epoch: [67] [422400/1281167 (33%)]	Loss: 1.005705
[2022-06-09 15:26:41 | train] - Train Epoch: [67] [435200/1281167 (34%)]	Loss: 0.931982
[2022-06-09 15:27:03 | train] - Train Epoch: [67] [448000/1281167 (35%)]	Loss: 1.002055
[2022-06-09 15:27:24 | train] - Train Epoch: [67] [460800/1281167 (36%)]	Loss: 1.190516
[2022-06-09 15:27:46 | train] - Train Epoch: [67] [473600/1281167 (37%)]	Loss: 0.587591
[2022-06-09 15:28:07 | train] - Train Epoch: [67] [486400/1281167 (38%)]	Loss: 1.060030
[2022-06-09 15:28:29 | train] - Train Epoch: [67] [499200/1281167 (39%)]	Loss: 0.879976
[2022-06-09 15:28:51 | train] - Train Epoch: [67] [512000/1281167 (40%)]	Loss: 0.804899
[2022-06-09 15:29:12 | train] - Train Epoch: [67] [524800/1281167 (41%)]	Loss: 0.817896
[2022-06-09 15:29:35 | train] - Train Epoch: [67] [537600/1281167 (42%)]	Loss: 1.043791
[2022-06-09 15:29:57 | train] - Train Epoch: [67] [550400/1281167 (43%)]	Loss: 1.097772
[2022-06-09 15:30:19 | train] - Train Epoch: [67] [563200/1281167 (44%)]	Loss: 0.990525
[2022-06-09 15:30:41 | train] - Train Epoch: [67] [576000/1281167 (45%)]	Loss: 0.907809
[2022-06-09 15:31:03 | train] - Train Epoch: [67] [588800/1281167 (46%)]	Loss: 0.919297
[2022-06-09 15:31:24 | train] - Train Epoch: [67] [601600/1281167 (47%)]	Loss: 0.945077
[2022-06-09 15:31:46 | train] - Train Epoch: [67] [614400/1281167 (48%)]	Loss: 1.201566
[2022-06-09 15:32:09 | train] - Train Epoch: [67] [627200/1281167 (49%)]	Loss: 0.980751
[2022-06-09 15:32:30 | train] - Train Epoch: [67] [640000/1281167 (50%)]	Loss: 0.967440
[2022-06-09 15:32:53 | train] - Train Epoch: [67] [652800/1281167 (51%)]	Loss: 1.144029
[2022-06-09 15:33:13 | train] - Train Epoch: [67] [665600/1281167 (52%)]	Loss: 0.921587
[2022-06-09 15:33:36 | train] - Train Epoch: [67] [678400/1281167 (53%)]	Loss: 0.704590
[2022-06-09 15:33:58 | train] - Train Epoch: [67] [691200/1281167 (54%)]	Loss: 1.014185
[2022-06-09 15:34:19 | train] - Train Epoch: [67] [704000/1281167 (55%)]	Loss: 0.920822
[2022-06-09 15:34:41 | train] - Train Epoch: [67] [716800/1281167 (56%)]	Loss: 0.812960
[2022-06-09 15:35:03 | train] - Train Epoch: [67] [729600/1281167 (57%)]	Loss: 0.904886
[2022-06-09 15:35:25 | train] - Train Epoch: [67] [742400/1281167 (58%)]	Loss: 0.762743
[2022-06-09 15:35:47 | train] - Train Epoch: [67] [755200/1281167 (59%)]	Loss: 1.012131
[2022-06-09 15:36:09 | train] - Train Epoch: [67] [768000/1281167 (60%)]	Loss: 0.848237
[2022-06-09 15:36:30 | train] - Train Epoch: [67] [780800/1281167 (61%)]	Loss: 1.093503
[2022-06-09 15:36:52 | train] - Train Epoch: [67] [793600/1281167 (62%)]	Loss: 0.912706
[2022-06-09 15:37:13 | train] - Train Epoch: [67] [806400/1281167 (63%)]	Loss: 0.937537
[2022-06-09 15:37:35 | train] - Train Epoch: [67] [819200/1281167 (64%)]	Loss: 0.729654
[2022-06-09 15:37:57 | train] - Train Epoch: [67] [832000/1281167 (65%)]	Loss: 0.850241
[2022-06-09 15:38:19 | train] - Train Epoch: [67] [844800/1281167 (66%)]	Loss: 1.167700
[2022-06-09 15:38:41 | train] - Train Epoch: [67] [857600/1281167 (67%)]	Loss: 1.041963
[2022-06-09 15:39:02 | train] - Train Epoch: [67] [870400/1281167 (68%)]	Loss: 0.799493
[2022-06-09 15:39:24 | train] - Train Epoch: [67] [883200/1281167 (69%)]	Loss: 0.858874
[2022-06-09 15:39:47 | train] - Train Epoch: [67] [896000/1281167 (70%)]	Loss: 0.780750
[2022-06-09 15:40:09 | train] - Train Epoch: [67] [908800/1281167 (71%)]	Loss: 0.846442
[2022-06-09 15:40:31 | train] - Train Epoch: [67] [921600/1281167 (72%)]	Loss: 0.968960
[2022-06-09 15:40:53 | train] - Train Epoch: [67] [934400/1281167 (73%)]	Loss: 1.010364
[2022-06-09 15:41:15 | train] - Train Epoch: [67] [947200/1281167 (74%)]	Loss: 1.144054
[2022-06-09 15:41:37 | train] - Train Epoch: [67] [960000/1281167 (75%)]	Loss: 1.047794
[2022-06-09 15:41:58 | train] - Train Epoch: [67] [972800/1281167 (76%)]	Loss: 1.262352
[2022-06-09 15:42:20 | train] - Train Epoch: [67] [985600/1281167 (77%)]	Loss: 1.163641
[2022-06-09 15:42:43 | train] - Train Epoch: [67] [998400/1281167 (78%)]	Loss: 0.807444
[2022-06-09 15:43:04 | train] - Train Epoch: [67] [1011200/1281167 (79%)]	Loss: 1.082908
[2022-06-09 15:43:26 | train] - Train Epoch: [67] [1024000/1281167 (80%)]	Loss: 1.011507
[2022-06-09 15:43:49 | train] - Train Epoch: [67] [1036800/1281167 (81%)]	Loss: 1.028342
[2022-06-09 15:44:11 | train] - Train Epoch: [67] [1049600/1281167 (82%)]	Loss: 1.230236
[2022-06-09 15:44:33 | train] - Train Epoch: [67] [1062400/1281167 (83%)]	Loss: 0.952760
[2022-06-09 15:44:55 | train] - Train Epoch: [67] [1075200/1281167 (84%)]	Loss: 0.905637
[2022-06-09 15:45:17 | train] - Train Epoch: [67] [1088000/1281167 (85%)]	Loss: 0.831089
[2022-06-09 15:45:39 | train] - Train Epoch: [67] [1100800/1281167 (86%)]	Loss: 0.857959
[2022-06-09 15:46:01 | train] - Train Epoch: [67] [1113600/1281167 (87%)]	Loss: 0.893318
[2022-06-09 15:46:23 | train] - Train Epoch: [67] [1126400/1281167 (88%)]	Loss: 1.072741
[2022-06-09 15:46:45 | train] - Train Epoch: [67] [1139200/1281167 (89%)]	Loss: 0.665722
[2022-06-09 15:47:07 | train] - Train Epoch: [67] [1152000/1281167 (90%)]	Loss: 0.702443
[2022-06-09 15:47:29 | train] - Train Epoch: [67] [1164800/1281167 (91%)]	Loss: 0.729794
[2022-06-09 15:47:51 | train] - Train Epoch: [67] [1177600/1281167 (92%)]	Loss: 1.040379
[2022-06-09 15:48:13 | train] - Train Epoch: [67] [1190400/1281167 (93%)]	Loss: 0.823900
[2022-06-09 15:48:35 | train] - Train Epoch: [67] [1203200/1281167 (94%)]	Loss: 0.983593
[2022-06-09 15:48:57 | train] - Train Epoch: [67] [1216000/1281167 (95%)]	Loss: 0.858726
[2022-06-09 15:49:20 | train] - Train Epoch: [67] [1228800/1281167 (96%)]	Loss: 0.923822
[2022-06-09 15:49:42 | train] - Train Epoch: [67] [1241600/1281167 (97%)]	Loss: 1.101950
[2022-06-09 15:50:04 | train] - Train Epoch: [67] [1254400/1281167 (98%)]	Loss: 0.938220
[2022-06-09 15:50:26 | train] - Train Epoch: [67] [1267200/1281167 (99%)]	Loss: 1.126655
[2022-06-09 15:50:48 | train] - Train Epoch: [67] [1280000/1281167 (100%)]	Loss: 0.836132
[2022-06-09 15:50:50 | train] - Train Epoch: [67]	 Average Loss: 0.948436	 Total Acc : 76.9764	 Total Top5 Acc : 91.3082
[2022-06-09 15:50:50 | train] - -------67 epoch end-----------
========================================
-------67 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 15:52:24 | train] - 
Epoch [67] Test set: Average loss: 1.3079, Accuracy: 35153/50000 (70.2721%), Top-5 Accuracy: 89.1832%

[2022-06-09 15:52:24 | train] - save intermediate epoch [67] result


[2022-06-09 15:52:42 | train] - -------68 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 15:52:43 | train] - Train Epoch: [68] [0/1281167 (0%)]	Loss: 1.158208
[2022-06-09 15:53:06 | train] - Train Epoch: [68] [12800/1281167 (1%)]	Loss: 0.864206
[2022-06-09 15:53:28 | train] - Train Epoch: [68] [25600/1281167 (2%)]	Loss: 0.556125
[2022-06-09 15:53:49 | train] - Train Epoch: [68] [38400/1281167 (3%)]	Loss: 1.032072
[2022-06-09 15:54:11 | train] - Train Epoch: [68] [51200/1281167 (4%)]	Loss: 0.916279
[2022-06-09 15:54:33 | train] - Train Epoch: [68] [64000/1281167 (5%)]	Loss: 1.088866
[2022-06-09 15:54:54 | train] - Train Epoch: [68] [76800/1281167 (6%)]	Loss: 0.964291
[2022-06-09 15:55:16 | train] - Train Epoch: [68] [89600/1281167 (7%)]	Loss: 1.115194
[2022-06-09 15:55:37 | train] - Train Epoch: [68] [102400/1281167 (8%)]	Loss: 0.930718
[2022-06-09 15:55:58 | train] - Train Epoch: [68] [115200/1281167 (9%)]	Loss: 0.876092
[2022-06-09 15:56:20 | train] - Train Epoch: [68] [128000/1281167 (10%)]	Loss: 1.118400
[2022-06-09 15:56:43 | train] - Train Epoch: [68] [140800/1281167 (11%)]	Loss: 1.021358
[2022-06-09 15:57:05 | train] - Train Epoch: [68] [153600/1281167 (12%)]	Loss: 1.101394
[2022-06-09 15:57:27 | train] - Train Epoch: [68] [166400/1281167 (13%)]	Loss: 0.827718
[2022-06-09 15:57:49 | train] - Train Epoch: [68] [179200/1281167 (14%)]	Loss: 0.940327
[2022-06-09 15:58:11 | train] - Train Epoch: [68] [192000/1281167 (15%)]	Loss: 0.872300
[2022-06-09 15:58:33 | train] - Train Epoch: [68] [204800/1281167 (16%)]	Loss: 0.795828
[2022-06-09 15:58:55 | train] - Train Epoch: [68] [217600/1281167 (17%)]	Loss: 1.089152
[2022-06-09 15:59:16 | train] - Train Epoch: [68] [230400/1281167 (18%)]	Loss: 0.912490
[2022-06-09 15:59:39 | train] - Train Epoch: [68] [243200/1281167 (19%)]	Loss: 0.754773
[2022-06-09 16:00:00 | train] - Train Epoch: [68] [256000/1281167 (20%)]	Loss: 0.905616
[2022-06-09 16:00:22 | train] - Train Epoch: [68] [268800/1281167 (21%)]	Loss: 0.725122
[2022-06-09 16:00:44 | train] - Train Epoch: [68] [281600/1281167 (22%)]	Loss: 1.015270
[2022-06-09 16:01:06 | train] - Train Epoch: [68] [294400/1281167 (23%)]	Loss: 0.952529
[2022-06-09 16:01:28 | train] - Train Epoch: [68] [307200/1281167 (24%)]	Loss: 1.391589
[2022-06-09 16:01:49 | train] - Train Epoch: [68] [320000/1281167 (25%)]	Loss: 0.782189
[2022-06-09 16:02:11 | train] - Train Epoch: [68] [332800/1281167 (26%)]	Loss: 0.903376
[2022-06-09 16:02:33 | train] - Train Epoch: [68] [345600/1281167 (27%)]	Loss: 0.794420
[2022-06-09 16:02:55 | train] - Train Epoch: [68] [358400/1281167 (28%)]	Loss: 0.949189
[2022-06-09 16:03:16 | train] - Train Epoch: [68] [371200/1281167 (29%)]	Loss: 1.194370
[2022-06-09 16:03:39 | train] - Train Epoch: [68] [384000/1281167 (30%)]	Loss: 0.871146
[2022-06-09 16:04:01 | train] - Train Epoch: [68] [396800/1281167 (31%)]	Loss: 0.776326
[2022-06-09 16:04:23 | train] - Train Epoch: [68] [409600/1281167 (32%)]	Loss: 0.801631
[2022-06-09 16:04:45 | train] - Train Epoch: [68] [422400/1281167 (33%)]	Loss: 1.080369
[2022-06-09 16:05:07 | train] - Train Epoch: [68] [435200/1281167 (34%)]	Loss: 1.013727
[2022-06-09 16:05:29 | train] - Train Epoch: [68] [448000/1281167 (35%)]	Loss: 1.003499
[2022-06-09 16:05:50 | train] - Train Epoch: [68] [460800/1281167 (36%)]	Loss: 1.058765
[2022-06-09 16:06:12 | train] - Train Epoch: [68] [473600/1281167 (37%)]	Loss: 0.835996
[2022-06-09 16:06:34 | train] - Train Epoch: [68] [486400/1281167 (38%)]	Loss: 1.038223
[2022-06-09 16:06:57 | train] - Train Epoch: [68] [499200/1281167 (39%)]	Loss: 0.919692
[2022-06-09 16:07:19 | train] - Train Epoch: [68] [512000/1281167 (40%)]	Loss: 0.859379
[2022-06-09 16:07:40 | train] - Train Epoch: [68] [524800/1281167 (41%)]	Loss: 0.991551
[2022-06-09 16:08:02 | train] - Train Epoch: [68] [537600/1281167 (42%)]	Loss: 1.068240
[2022-06-09 16:08:24 | train] - Train Epoch: [68] [550400/1281167 (43%)]	Loss: 1.176258
[2022-06-09 16:08:46 | train] - Train Epoch: [68] [563200/1281167 (44%)]	Loss: 0.716405
[2022-06-09 16:09:08 | train] - Train Epoch: [68] [576000/1281167 (45%)]	Loss: 0.945768
[2022-06-09 16:09:30 | train] - Train Epoch: [68] [588800/1281167 (46%)]	Loss: 0.967492
[2022-06-09 16:09:51 | train] - Train Epoch: [68] [601600/1281167 (47%)]	Loss: 1.221359
[2022-06-09 16:10:13 | train] - Train Epoch: [68] [614400/1281167 (48%)]	Loss: 0.863720
[2022-06-09 16:10:35 | train] - Train Epoch: [68] [627200/1281167 (49%)]	Loss: 0.913567
[2022-06-09 16:10:56 | train] - Train Epoch: [68] [640000/1281167 (50%)]	Loss: 0.995772
[2022-06-09 16:11:18 | train] - Train Epoch: [68] [652800/1281167 (51%)]	Loss: 0.901826
[2022-06-09 16:11:40 | train] - Train Epoch: [68] [665600/1281167 (52%)]	Loss: 0.922509
[2022-06-09 16:12:02 | train] - Train Epoch: [68] [678400/1281167 (53%)]	Loss: 0.810476
[2022-06-09 16:12:24 | train] - Train Epoch: [68] [691200/1281167 (54%)]	Loss: 0.677018
[2022-06-09 16:12:46 | train] - Train Epoch: [68] [704000/1281167 (55%)]	Loss: 0.797292
[2022-06-09 16:13:07 | train] - Train Epoch: [68] [716800/1281167 (56%)]	Loss: 0.856828
[2022-06-09 16:13:29 | train] - Train Epoch: [68] [729600/1281167 (57%)]	Loss: 1.020165
[2022-06-09 16:13:51 | train] - Train Epoch: [68] [742400/1281167 (58%)]	Loss: 0.736206
[2022-06-09 16:14:13 | train] - Train Epoch: [68] [755200/1281167 (59%)]	Loss: 0.794606
[2022-06-09 16:14:35 | train] - Train Epoch: [68] [768000/1281167 (60%)]	Loss: 0.963115
[2022-06-09 16:14:57 | train] - Train Epoch: [68] [780800/1281167 (61%)]	Loss: 0.872247
[2022-06-09 16:15:18 | train] - Train Epoch: [68] [793600/1281167 (62%)]	Loss: 0.895126
[2022-06-09 16:15:40 | train] - Train Epoch: [68] [806400/1281167 (63%)]	Loss: 0.812631
[2022-06-09 16:16:02 | train] - Train Epoch: [68] [819200/1281167 (64%)]	Loss: 1.118759
[2022-06-09 16:16:23 | train] - Train Epoch: [68] [832000/1281167 (65%)]	Loss: 0.979728
[2022-06-09 16:16:45 | train] - Train Epoch: [68] [844800/1281167 (66%)]	Loss: 1.074199
[2022-06-09 16:17:07 | train] - Train Epoch: [68] [857600/1281167 (67%)]	Loss: 1.201476
[2022-06-09 16:17:29 | train] - Train Epoch: [68] [870400/1281167 (68%)]	Loss: 0.930175
[2022-06-09 16:17:51 | train] - Train Epoch: [68] [883200/1281167 (69%)]	Loss: 0.838042
[2022-06-09 16:18:13 | train] - Train Epoch: [68] [896000/1281167 (70%)]	Loss: 1.022917
[2022-06-09 16:18:34 | train] - Train Epoch: [68] [908800/1281167 (71%)]	Loss: 0.703176
[2022-06-09 16:18:57 | train] - Train Epoch: [68] [921600/1281167 (72%)]	Loss: 0.712860
[2022-06-09 16:19:19 | train] - Train Epoch: [68] [934400/1281167 (73%)]	Loss: 0.934487
[2022-06-09 16:19:40 | train] - Train Epoch: [68] [947200/1281167 (74%)]	Loss: 0.828729
[2022-06-09 16:20:02 | train] - Train Epoch: [68] [960000/1281167 (75%)]	Loss: 0.790494
[2022-06-09 16:20:23 | train] - Train Epoch: [68] [972800/1281167 (76%)]	Loss: 0.691677
[2022-06-09 16:20:45 | train] - Train Epoch: [68] [985600/1281167 (77%)]	Loss: 1.184901
[2022-06-09 16:21:07 | train] - Train Epoch: [68] [998400/1281167 (78%)]	Loss: 0.812482
[2022-06-09 16:21:29 | train] - Train Epoch: [68] [1011200/1281167 (79%)]	Loss: 0.983681
[2022-06-09 16:21:51 | train] - Train Epoch: [68] [1024000/1281167 (80%)]	Loss: 1.242477
[2022-06-09 16:22:13 | train] - Train Epoch: [68] [1036800/1281167 (81%)]	Loss: 0.855344
[2022-06-09 16:22:35 | train] - Train Epoch: [68] [1049600/1281167 (82%)]	Loss: 0.976403
[2022-06-09 16:22:57 | train] - Train Epoch: [68] [1062400/1281167 (83%)]	Loss: 1.101097
[2022-06-09 16:23:18 | train] - Train Epoch: [68] [1075200/1281167 (84%)]	Loss: 0.773938
[2022-06-09 16:23:40 | train] - Train Epoch: [68] [1088000/1281167 (85%)]	Loss: 0.788054
[2022-06-09 16:24:02 | train] - Train Epoch: [68] [1100800/1281167 (86%)]	Loss: 0.877243
[2022-06-09 16:24:25 | train] - Train Epoch: [68] [1113600/1281167 (87%)]	Loss: 0.781010
[2022-06-09 16:24:47 | train] - Train Epoch: [68] [1126400/1281167 (88%)]	Loss: 1.374247
[2022-06-09 16:25:09 | train] - Train Epoch: [68] [1139200/1281167 (89%)]	Loss: 0.798536
[2022-06-09 16:25:31 | train] - Train Epoch: [68] [1152000/1281167 (90%)]	Loss: 0.996692
[2022-06-09 16:25:53 | train] - Train Epoch: [68] [1164800/1281167 (91%)]	Loss: 1.139767
[2022-06-09 16:26:15 | train] - Train Epoch: [68] [1177600/1281167 (92%)]	Loss: 0.737077
[2022-06-09 16:26:37 | train] - Train Epoch: [68] [1190400/1281167 (93%)]	Loss: 0.995591
[2022-06-09 16:26:59 | train] - Train Epoch: [68] [1203200/1281167 (94%)]	Loss: 1.168554
[2022-06-09 16:27:21 | train] - Train Epoch: [68] [1216000/1281167 (95%)]	Loss: 0.826992
[2022-06-09 16:27:43 | train] - Train Epoch: [68] [1228800/1281167 (96%)]	Loss: 1.185172
[2022-06-09 16:28:05 | train] - Train Epoch: [68] [1241600/1281167 (97%)]	Loss: 0.732996
[2022-06-09 16:28:27 | train] - Train Epoch: [68] [1254400/1281167 (98%)]	Loss: 1.180399
[2022-06-09 16:28:49 | train] - Train Epoch: [68] [1267200/1281167 (99%)]	Loss: 1.253114
[2022-06-09 16:29:11 | train] - Train Epoch: [68] [1280000/1281167 (100%)]	Loss: 1.017807
[2022-06-09 16:29:13 | train] - Train Epoch: [68]	 Average Loss: 0.943554	 Total Acc : 77.0795	 Total Top5 Acc : 91.3860
[2022-06-09 16:29:13 | train] - -------68 epoch end-----------
========================================
-------68 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 16:30:47 | train] - 
Epoch [68] Test set: Average loss: 1.3162, Accuracy: 35121/50000 (70.2166%), Top-5 Accuracy: 89.2076%

[2022-06-09 16:30:47 | train] - save intermediate epoch [68] result


[2022-06-09 16:31:05 | train] - -------69 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 16:31:07 | train] - Train Epoch: [69] [0/1281167 (0%)]	Loss: 0.826599
[2022-06-09 16:31:29 | train] - Train Epoch: [69] [12800/1281167 (1%)]	Loss: 0.945820
[2022-06-09 16:31:50 | train] - Train Epoch: [69] [25600/1281167 (2%)]	Loss: 0.776712
[2022-06-09 16:32:12 | train] - Train Epoch: [69] [38400/1281167 (3%)]	Loss: 0.905203
[2022-06-09 16:32:34 | train] - Train Epoch: [69] [51200/1281167 (4%)]	Loss: 1.122450
[2022-06-09 16:32:56 | train] - Train Epoch: [69] [64000/1281167 (5%)]	Loss: 1.188869
[2022-06-09 16:33:18 | train] - Train Epoch: [69] [76800/1281167 (6%)]	Loss: 0.516677
[2022-06-09 16:33:39 | train] - Train Epoch: [69] [89600/1281167 (7%)]	Loss: 1.278687
[2022-06-09 16:34:00 | train] - Train Epoch: [69] [102400/1281167 (8%)]	Loss: 0.917263
[2022-06-09 16:34:22 | train] - Train Epoch: [69] [115200/1281167 (9%)]	Loss: 0.809506
[2022-06-09 16:34:44 | train] - Train Epoch: [69] [128000/1281167 (10%)]	Loss: 0.875221
[2022-06-09 16:35:06 | train] - Train Epoch: [69] [140800/1281167 (11%)]	Loss: 0.979818
[2022-06-09 16:35:28 | train] - Train Epoch: [69] [153600/1281167 (12%)]	Loss: 0.882579
[2022-06-09 16:35:50 | train] - Train Epoch: [69] [166400/1281167 (13%)]	Loss: 1.049464
[2022-06-09 16:36:12 | train] - Train Epoch: [69] [179200/1281167 (14%)]	Loss: 0.897005
[2022-06-09 16:36:33 | train] - Train Epoch: [69] [192000/1281167 (15%)]	Loss: 0.977961
[2022-06-09 16:36:54 | train] - Train Epoch: [69] [204800/1281167 (16%)]	Loss: 0.945968
[2022-06-09 16:37:16 | train] - Train Epoch: [69] [217600/1281167 (17%)]	Loss: 0.903736
[2022-06-09 16:37:38 | train] - Train Epoch: [69] [230400/1281167 (18%)]	Loss: 1.092982
[2022-06-09 16:37:59 | train] - Train Epoch: [69] [243200/1281167 (19%)]	Loss: 1.244036
[2022-06-09 16:38:21 | train] - Train Epoch: [69] [256000/1281167 (20%)]	Loss: 0.966901
[2022-06-09 16:38:43 | train] - Train Epoch: [69] [268800/1281167 (21%)]	Loss: 0.858983
[2022-06-09 16:39:05 | train] - Train Epoch: [69] [281600/1281167 (22%)]	Loss: 1.141005
[2022-06-09 16:39:27 | train] - Train Epoch: [69] [294400/1281167 (23%)]	Loss: 1.073005
[2022-06-09 16:39:48 | train] - Train Epoch: [69] [307200/1281167 (24%)]	Loss: 0.974843
[2022-06-09 16:40:10 | train] - Train Epoch: [69] [320000/1281167 (25%)]	Loss: 0.972293
[2022-06-09 16:40:33 | train] - Train Epoch: [69] [332800/1281167 (26%)]	Loss: 0.923642
[2022-06-09 16:40:54 | train] - Train Epoch: [69] [345600/1281167 (27%)]	Loss: 0.793559
[2022-06-09 16:41:16 | train] - Train Epoch: [69] [358400/1281167 (28%)]	Loss: 0.803787
[2022-06-09 16:41:38 | train] - Train Epoch: [69] [371200/1281167 (29%)]	Loss: 0.963655
[2022-06-09 16:42:01 | train] - Train Epoch: [69] [384000/1281167 (30%)]	Loss: 0.810490
[2022-06-09 16:42:22 | train] - Train Epoch: [69] [396800/1281167 (31%)]	Loss: 1.032171
[2022-06-09 16:42:44 | train] - Train Epoch: [69] [409600/1281167 (32%)]	Loss: 1.088876
[2022-06-09 16:43:06 | train] - Train Epoch: [69] [422400/1281167 (33%)]	Loss: 1.320673
[2022-06-09 16:43:28 | train] - Train Epoch: [69] [435200/1281167 (34%)]	Loss: 1.029082
[2022-06-09 16:43:50 | train] - Train Epoch: [69] [448000/1281167 (35%)]	Loss: 0.983010
[2022-06-09 16:44:11 | train] - Train Epoch: [69] [460800/1281167 (36%)]	Loss: 1.072471
[2022-06-09 16:44:34 | train] - Train Epoch: [69] [473600/1281167 (37%)]	Loss: 0.991891
[2022-06-09 16:44:55 | train] - Train Epoch: [69] [486400/1281167 (38%)]	Loss: 0.695486
[2022-06-09 16:45:16 | train] - Train Epoch: [69] [499200/1281167 (39%)]	Loss: 1.190778
[2022-06-09 16:45:38 | train] - Train Epoch: [69] [512000/1281167 (40%)]	Loss: 0.948729
[2022-06-09 16:45:59 | train] - Train Epoch: [69] [524800/1281167 (41%)]	Loss: 1.088126
[2022-06-09 16:46:21 | train] - Train Epoch: [69] [537600/1281167 (42%)]	Loss: 0.944237
[2022-06-09 16:46:43 | train] - Train Epoch: [69] [550400/1281167 (43%)]	Loss: 0.597833
[2022-06-09 16:47:05 | train] - Train Epoch: [69] [563200/1281167 (44%)]	Loss: 1.042078
[2022-06-09 16:47:26 | train] - Train Epoch: [69] [576000/1281167 (45%)]	Loss: 0.767220
[2022-06-09 16:47:48 | train] - Train Epoch: [69] [588800/1281167 (46%)]	Loss: 1.014257
[2022-06-09 16:48:09 | train] - Train Epoch: [69] [601600/1281167 (47%)]	Loss: 1.021429
[2022-06-09 16:48:31 | train] - Train Epoch: [69] [614400/1281167 (48%)]	Loss: 0.819869
[2022-06-09 16:48:53 | train] - Train Epoch: [69] [627200/1281167 (49%)]	Loss: 1.070049
[2022-06-09 16:49:14 | train] - Train Epoch: [69] [640000/1281167 (50%)]	Loss: 1.331580
[2022-06-09 16:49:36 | train] - Train Epoch: [69] [652800/1281167 (51%)]	Loss: 0.973019
[2022-06-09 16:49:57 | train] - Train Epoch: [69] [665600/1281167 (52%)]	Loss: 1.071318
[2022-06-09 16:50:19 | train] - Train Epoch: [69] [678400/1281167 (53%)]	Loss: 0.933172
[2022-06-09 16:50:41 | train] - Train Epoch: [69] [691200/1281167 (54%)]	Loss: 0.752603
[2022-06-09 16:51:03 | train] - Train Epoch: [69] [704000/1281167 (55%)]	Loss: 0.700339
[2022-06-09 16:51:25 | train] - Train Epoch: [69] [716800/1281167 (56%)]	Loss: 1.075159
[2022-06-09 16:51:46 | train] - Train Epoch: [69] [729600/1281167 (57%)]	Loss: 1.179127
[2022-06-09 16:52:08 | train] - Train Epoch: [69] [742400/1281167 (58%)]	Loss: 0.795506
[2022-06-09 16:52:30 | train] - Train Epoch: [69] [755200/1281167 (59%)]	Loss: 1.000566
[2022-06-09 16:52:52 | train] - Train Epoch: [69] [768000/1281167 (60%)]	Loss: 0.844740
[2022-06-09 16:53:14 | train] - Train Epoch: [69] [780800/1281167 (61%)]	Loss: 1.079754
[2022-06-09 16:53:35 | train] - Train Epoch: [69] [793600/1281167 (62%)]	Loss: 1.068963
[2022-06-09 16:53:57 | train] - Train Epoch: [69] [806400/1281167 (63%)]	Loss: 1.144739
[2022-06-09 16:54:18 | train] - Train Epoch: [69] [819200/1281167 (64%)]	Loss: 0.603971
[2022-06-09 16:54:40 | train] - Train Epoch: [69] [832000/1281167 (65%)]	Loss: 0.914534
[2022-06-09 16:55:02 | train] - Train Epoch: [69] [844800/1281167 (66%)]	Loss: 0.928238
[2022-06-09 16:55:24 | train] - Train Epoch: [69] [857600/1281167 (67%)]	Loss: 1.200711
[2022-06-09 16:55:45 | train] - Train Epoch: [69] [870400/1281167 (68%)]	Loss: 0.992246
[2022-06-09 16:56:07 | train] - Train Epoch: [69] [883200/1281167 (69%)]	Loss: 1.063968
[2022-06-09 16:56:29 | train] - Train Epoch: [69] [896000/1281167 (70%)]	Loss: 0.833485
[2022-06-09 16:56:50 | train] - Train Epoch: [69] [908800/1281167 (71%)]	Loss: 0.984992
[2022-06-09 16:57:12 | train] - Train Epoch: [69] [921600/1281167 (72%)]	Loss: 0.786460
[2022-06-09 16:57:34 | train] - Train Epoch: [69] [934400/1281167 (73%)]	Loss: 0.856387
[2022-06-09 16:57:56 | train] - Train Epoch: [69] [947200/1281167 (74%)]	Loss: 0.959618
[2022-06-09 16:58:18 | train] - Train Epoch: [69] [960000/1281167 (75%)]	Loss: 0.992015
[2022-06-09 16:58:39 | train] - Train Epoch: [69] [972800/1281167 (76%)]	Loss: 0.834480
[2022-06-09 16:59:01 | train] - Train Epoch: [69] [985600/1281167 (77%)]	Loss: 0.747736
[2022-06-09 16:59:23 | train] - Train Epoch: [69] [998400/1281167 (78%)]	Loss: 0.834556
[2022-06-09 16:59:45 | train] - Train Epoch: [69] [1011200/1281167 (79%)]	Loss: 0.949425
[2022-06-09 17:00:06 | train] - Train Epoch: [69] [1024000/1281167 (80%)]	Loss: 0.915344
[2022-06-09 17:00:28 | train] - Train Epoch: [69] [1036800/1281167 (81%)]	Loss: 0.910248
[2022-06-09 17:00:50 | train] - Train Epoch: [69] [1049600/1281167 (82%)]	Loss: 0.791541
[2022-06-09 17:01:11 | train] - Train Epoch: [69] [1062400/1281167 (83%)]	Loss: 0.772870
[2022-06-09 17:01:32 | train] - Train Epoch: [69] [1075200/1281167 (84%)]	Loss: 0.710494
[2022-06-09 17:01:54 | train] - Train Epoch: [69] [1088000/1281167 (85%)]	Loss: 0.966506
[2022-06-09 17:02:15 | train] - Train Epoch: [69] [1100800/1281167 (86%)]	Loss: 0.867763
[2022-06-09 17:02:37 | train] - Train Epoch: [69] [1113600/1281167 (87%)]	Loss: 0.832229
[2022-06-09 17:02:59 | train] - Train Epoch: [69] [1126400/1281167 (88%)]	Loss: 0.940982
[2022-06-09 17:03:21 | train] - Train Epoch: [69] [1139200/1281167 (89%)]	Loss: 1.102478
[2022-06-09 17:03:41 | train] - Train Epoch: [69] [1152000/1281167 (90%)]	Loss: 1.176727
[2022-06-09 17:04:03 | train] - Train Epoch: [69] [1164800/1281167 (91%)]	Loss: 0.764096
[2022-06-09 17:04:25 | train] - Train Epoch: [69] [1177600/1281167 (92%)]	Loss: 0.810355
[2022-06-09 17:04:46 | train] - Train Epoch: [69] [1190400/1281167 (93%)]	Loss: 0.794950
[2022-06-09 17:05:09 | train] - Train Epoch: [69] [1203200/1281167 (94%)]	Loss: 0.862989
[2022-06-09 17:05:30 | train] - Train Epoch: [69] [1216000/1281167 (95%)]	Loss: 0.806061
[2022-06-09 17:05:52 | train] - Train Epoch: [69] [1228800/1281167 (96%)]	Loss: 0.920938
[2022-06-09 17:06:14 | train] - Train Epoch: [69] [1241600/1281167 (97%)]	Loss: 0.800471
[2022-06-09 17:06:36 | train] - Train Epoch: [69] [1254400/1281167 (98%)]	Loss: 0.813512
[2022-06-09 17:06:58 | train] - Train Epoch: [69] [1267200/1281167 (99%)]	Loss: 0.780189
[2022-06-09 17:07:19 | train] - Train Epoch: [69] [1280000/1281167 (100%)]	Loss: 0.631426
[2022-06-09 17:07:21 | train] - Train Epoch: [69]	 Average Loss: 0.940028	 Total Acc : 77.1880	 Total Top5 Acc : 91.4163
[2022-06-09 17:07:21 | train] - -------69 epoch end-----------
========================================
-------69 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 17:08:57 | train] - 
Epoch [69] Test set: Average loss: 1.3170, Accuracy: 35088/50000 (70.1399%), Top-5 Accuracy: 89.0909%

[2022-06-09 17:08:57 | train] - save intermediate epoch [69] result


[2022-06-09 17:09:17 | train] - -------70 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 17:09:19 | train] - Train Epoch: [70] [0/1281167 (0%)]	Loss: 0.849141
[2022-06-09 17:09:41 | train] - Train Epoch: [70] [12800/1281167 (1%)]	Loss: 0.805542
[2022-06-09 17:10:03 | train] - Train Epoch: [70] [25600/1281167 (2%)]	Loss: 1.048594
[2022-06-09 17:10:25 | train] - Train Epoch: [70] [38400/1281167 (3%)]	Loss: 0.760580
[2022-06-09 17:10:47 | train] - Train Epoch: [70] [51200/1281167 (4%)]	Loss: 0.669103
[2022-06-09 17:11:09 | train] - Train Epoch: [70] [64000/1281167 (5%)]	Loss: 0.890456
[2022-06-09 17:11:32 | train] - Train Epoch: [70] [76800/1281167 (6%)]	Loss: 1.149875
[2022-06-09 17:11:55 | train] - Train Epoch: [70] [89600/1281167 (7%)]	Loss: 1.007464
[2022-06-09 17:12:18 | train] - Train Epoch: [70] [102400/1281167 (8%)]	Loss: 1.072179
[2022-06-09 17:12:40 | train] - Train Epoch: [70] [115200/1281167 (9%)]	Loss: 1.014155
[2022-06-09 17:13:02 | train] - Train Epoch: [70] [128000/1281167 (10%)]	Loss: 0.890576
[2022-06-09 17:13:24 | train] - Train Epoch: [70] [140800/1281167 (11%)]	Loss: 0.981273
[2022-06-09 17:13:46 | train] - Train Epoch: [70] [153600/1281167 (12%)]	Loss: 0.997448
[2022-06-09 17:14:08 | train] - Train Epoch: [70] [166400/1281167 (13%)]	Loss: 1.087471
[2022-06-09 17:14:29 | train] - Train Epoch: [70] [179200/1281167 (14%)]	Loss: 0.891662
[2022-06-09 17:14:51 | train] - Train Epoch: [70] [192000/1281167 (15%)]	Loss: 1.080613
[2022-06-09 17:15:13 | train] - Train Epoch: [70] [204800/1281167 (16%)]	Loss: 1.050196
[2022-06-09 17:15:35 | train] - Train Epoch: [70] [217600/1281167 (17%)]	Loss: 0.862123
[2022-06-09 17:15:57 | train] - Train Epoch: [70] [230400/1281167 (18%)]	Loss: 0.930236
[2022-06-09 17:16:18 | train] - Train Epoch: [70] [243200/1281167 (19%)]	Loss: 0.898095
[2022-06-09 17:16:40 | train] - Train Epoch: [70] [256000/1281167 (20%)]	Loss: 1.166861
[2022-06-09 17:17:02 | train] - Train Epoch: [70] [268800/1281167 (21%)]	Loss: 0.953652
[2022-06-09 17:17:24 | train] - Train Epoch: [70] [281600/1281167 (22%)]	Loss: 0.885301
[2022-06-09 17:17:45 | train] - Train Epoch: [70] [294400/1281167 (23%)]	Loss: 0.941006
[2022-06-09 17:18:08 | train] - Train Epoch: [70] [307200/1281167 (24%)]	Loss: 0.885757
[2022-06-09 17:18:30 | train] - Train Epoch: [70] [320000/1281167 (25%)]	Loss: 0.809381
[2022-06-09 17:18:51 | train] - Train Epoch: [70] [332800/1281167 (26%)]	Loss: 0.929713
[2022-06-09 17:19:13 | train] - Train Epoch: [70] [345600/1281167 (27%)]	Loss: 0.912791
[2022-06-09 17:19:35 | train] - Train Epoch: [70] [358400/1281167 (28%)]	Loss: 0.993590
[2022-06-09 17:19:57 | train] - Train Epoch: [70] [371200/1281167 (29%)]	Loss: 1.001694
[2022-06-09 17:20:18 | train] - Train Epoch: [70] [384000/1281167 (30%)]	Loss: 0.907917
[2022-06-09 17:20:40 | train] - Train Epoch: [70] [396800/1281167 (31%)]	Loss: 0.805954
[2022-06-09 17:21:02 | train] - Train Epoch: [70] [409600/1281167 (32%)]	Loss: 1.123270
[2022-06-09 17:21:23 | train] - Train Epoch: [70] [422400/1281167 (33%)]	Loss: 1.220515
[2022-06-09 17:21:46 | train] - Train Epoch: [70] [435200/1281167 (34%)]	Loss: 0.899274
[2022-06-09 17:22:07 | train] - Train Epoch: [70] [448000/1281167 (35%)]	Loss: 0.884900
[2022-06-09 17:22:29 | train] - Train Epoch: [70] [460800/1281167 (36%)]	Loss: 1.103369
[2022-06-09 17:22:49 | train] - Train Epoch: [70] [473600/1281167 (37%)]	Loss: 0.981326
[2022-06-09 17:23:12 | train] - Train Epoch: [70] [486400/1281167 (38%)]	Loss: 1.243813
[2022-06-09 17:23:33 | train] - Train Epoch: [70] [499200/1281167 (39%)]	Loss: 0.823517
[2022-06-09 17:23:55 | train] - Train Epoch: [70] [512000/1281167 (40%)]	Loss: 0.917710
[2022-06-09 17:24:17 | train] - Train Epoch: [70] [524800/1281167 (41%)]	Loss: 1.092829
[2022-06-09 17:24:38 | train] - Train Epoch: [70] [537600/1281167 (42%)]	Loss: 0.979066
[2022-06-09 17:25:00 | train] - Train Epoch: [70] [550400/1281167 (43%)]	Loss: 0.877051
[2022-06-09 17:25:22 | train] - Train Epoch: [70] [563200/1281167 (44%)]	Loss: 0.981013
[2022-06-09 17:25:44 | train] - Train Epoch: [70] [576000/1281167 (45%)]	Loss: 1.025649
[2022-06-09 17:26:06 | train] - Train Epoch: [70] [588800/1281167 (46%)]	Loss: 0.826155
[2022-06-09 17:26:28 | train] - Train Epoch: [70] [601600/1281167 (47%)]	Loss: 1.076528
[2022-06-09 17:26:50 | train] - Train Epoch: [70] [614400/1281167 (48%)]	Loss: 0.626008
[2022-06-09 17:27:12 | train] - Train Epoch: [70] [627200/1281167 (49%)]	Loss: 0.898997
[2022-06-09 17:27:34 | train] - Train Epoch: [70] [640000/1281167 (50%)]	Loss: 0.982309
[2022-06-09 17:27:55 | train] - Train Epoch: [70] [652800/1281167 (51%)]	Loss: 0.755909
[2022-06-09 17:28:17 | train] - Train Epoch: [70] [665600/1281167 (52%)]	Loss: 0.878572
[2022-06-09 17:28:39 | train] - Train Epoch: [70] [678400/1281167 (53%)]	Loss: 0.847125
[2022-06-09 17:29:01 | train] - Train Epoch: [70] [691200/1281167 (54%)]	Loss: 0.975281
[2022-06-09 17:29:23 | train] - Train Epoch: [70] [704000/1281167 (55%)]	Loss: 0.861430
[2022-06-09 17:29:45 | train] - Train Epoch: [70] [716800/1281167 (56%)]	Loss: 0.804293
[2022-06-09 17:30:08 | train] - Train Epoch: [70] [729600/1281167 (57%)]	Loss: 1.027542
[2022-06-09 17:30:30 | train] - Train Epoch: [70] [742400/1281167 (58%)]	Loss: 1.163977
[2022-06-09 17:30:52 | train] - Train Epoch: [70] [755200/1281167 (59%)]	Loss: 1.154586
[2022-06-09 17:31:14 | train] - Train Epoch: [70] [768000/1281167 (60%)]	Loss: 1.025689
[2022-06-09 17:31:36 | train] - Train Epoch: [70] [780800/1281167 (61%)]	Loss: 0.841880
[2022-06-09 17:31:59 | train] - Train Epoch: [70] [793600/1281167 (62%)]	Loss: 0.892546
[2022-06-09 17:32:20 | train] - Train Epoch: [70] [806400/1281167 (63%)]	Loss: 0.948098
[2022-06-09 17:32:42 | train] - Train Epoch: [70] [819200/1281167 (64%)]	Loss: 1.055601
[2022-06-09 17:33:04 | train] - Train Epoch: [70] [832000/1281167 (65%)]	Loss: 0.803048
[2022-06-09 17:33:26 | train] - Train Epoch: [70] [844800/1281167 (66%)]	Loss: 0.879820
[2022-06-09 17:33:47 | train] - Train Epoch: [70] [857600/1281167 (67%)]	Loss: 1.019685
[2022-06-09 17:34:10 | train] - Train Epoch: [70] [870400/1281167 (68%)]	Loss: 0.924393
[2022-06-09 17:34:32 | train] - Train Epoch: [70] [883200/1281167 (69%)]	Loss: 0.670776
[2022-06-09 17:34:54 | train] - Train Epoch: [70] [896000/1281167 (70%)]	Loss: 0.843446
[2022-06-09 17:35:16 | train] - Train Epoch: [70] [908800/1281167 (71%)]	Loss: 0.948681
[2022-06-09 17:35:38 | train] - Train Epoch: [70] [921600/1281167 (72%)]	Loss: 1.076872
[2022-06-09 17:36:00 | train] - Train Epoch: [70] [934400/1281167 (73%)]	Loss: 1.062312
[2022-06-09 17:36:23 | train] - Train Epoch: [70] [947200/1281167 (74%)]	Loss: 0.985035
[2022-06-09 17:36:44 | train] - Train Epoch: [70] [960000/1281167 (75%)]	Loss: 1.160058
[2022-06-09 17:37:05 | train] - Train Epoch: [70] [972800/1281167 (76%)]	Loss: 0.694999
[2022-06-09 17:37:27 | train] - Train Epoch: [70] [985600/1281167 (77%)]	Loss: 0.858622
[2022-06-09 17:37:50 | train] - Train Epoch: [70] [998400/1281167 (78%)]	Loss: 0.959337
[2022-06-09 17:38:12 | train] - Train Epoch: [70] [1011200/1281167 (79%)]	Loss: 0.785059
[2022-06-09 17:38:33 | train] - Train Epoch: [70] [1024000/1281167 (80%)]	Loss: 1.023994
[2022-06-09 17:38:55 | train] - Train Epoch: [70] [1036800/1281167 (81%)]	Loss: 1.105630
[2022-06-09 17:39:16 | train] - Train Epoch: [70] [1049600/1281167 (82%)]	Loss: 0.738288
[2022-06-09 17:39:37 | train] - Train Epoch: [70] [1062400/1281167 (83%)]	Loss: 0.882727
[2022-06-09 17:39:59 | train] - Train Epoch: [70] [1075200/1281167 (84%)]	Loss: 0.763641
[2022-06-09 17:40:21 | train] - Train Epoch: [70] [1088000/1281167 (85%)]	Loss: 0.597791
[2022-06-09 17:40:43 | train] - Train Epoch: [70] [1100800/1281167 (86%)]	Loss: 0.715238
[2022-06-09 17:41:04 | train] - Train Epoch: [70] [1113600/1281167 (87%)]	Loss: 0.934263
[2022-06-09 17:41:26 | train] - Train Epoch: [70] [1126400/1281167 (88%)]	Loss: 0.845230
[2022-06-09 17:41:48 | train] - Train Epoch: [70] [1139200/1281167 (89%)]	Loss: 0.825908
[2022-06-09 17:42:10 | train] - Train Epoch: [70] [1152000/1281167 (90%)]	Loss: 0.991197
[2022-06-09 17:42:30 | train] - Train Epoch: [70] [1164800/1281167 (91%)]	Loss: 0.816967
[2022-06-09 17:42:53 | train] - Train Epoch: [70] [1177600/1281167 (92%)]	Loss: 0.874581
[2022-06-09 17:43:15 | train] - Train Epoch: [70] [1190400/1281167 (93%)]	Loss: 0.780625
[2022-06-09 17:43:36 | train] - Train Epoch: [70] [1203200/1281167 (94%)]	Loss: 0.931622
[2022-06-09 17:43:58 | train] - Train Epoch: [70] [1216000/1281167 (95%)]	Loss: 0.887296
[2022-06-09 17:44:20 | train] - Train Epoch: [70] [1228800/1281167 (96%)]	Loss: 1.030997
[2022-06-09 17:44:43 | train] - Train Epoch: [70] [1241600/1281167 (97%)]	Loss: 0.700569
[2022-06-09 17:45:04 | train] - Train Epoch: [70] [1254400/1281167 (98%)]	Loss: 0.764020
[2022-06-09 17:45:26 | train] - Train Epoch: [70] [1267200/1281167 (99%)]	Loss: 1.362181
[2022-06-09 17:45:49 | train] - Train Epoch: [70] [1280000/1281167 (100%)]	Loss: 0.941709
[2022-06-09 17:45:51 | train] - Train Epoch: [70]	 Average Loss: 0.935114	 Total Acc : 77.3107	 Total Top5 Acc : 91.4482
[2022-06-09 17:45:51 | train] - -------70 epoch end-----------
========================================
-------70 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 17:47:26 | train] - 
Epoch [70] Test set: Average loss: 1.3170, Accuracy: 35193/50000 (70.3545%), Top-5 Accuracy: 89.1856%

[2022-06-09 17:47:26 | train] - save intermediate epoch [70] result


[2022-06-09 17:47:45 | train] - -------71 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 17:47:46 | train] - Train Epoch: [71] [0/1281167 (0%)]	Loss: 0.914116
[2022-06-09 17:48:08 | train] - Train Epoch: [71] [12800/1281167 (1%)]	Loss: 0.993431
[2022-06-09 17:48:30 | train] - Train Epoch: [71] [25600/1281167 (2%)]	Loss: 1.406331
[2022-06-09 17:48:52 | train] - Train Epoch: [71] [38400/1281167 (3%)]	Loss: 1.039818
[2022-06-09 17:49:14 | train] - Train Epoch: [71] [51200/1281167 (4%)]	Loss: 1.111910
[2022-06-09 17:49:36 | train] - Train Epoch: [71] [64000/1281167 (5%)]	Loss: 1.013898
[2022-06-09 17:49:57 | train] - Train Epoch: [71] [76800/1281167 (6%)]	Loss: 1.087163
[2022-06-09 17:50:19 | train] - Train Epoch: [71] [89600/1281167 (7%)]	Loss: 0.965537
[2022-06-09 17:50:40 | train] - Train Epoch: [71] [102400/1281167 (8%)]	Loss: 0.911873
[2022-06-09 17:51:02 | train] - Train Epoch: [71] [115200/1281167 (9%)]	Loss: 1.018240
[2022-06-09 17:51:24 | train] - Train Epoch: [71] [128000/1281167 (10%)]	Loss: 0.745028
[2022-06-09 17:51:46 | train] - Train Epoch: [71] [140800/1281167 (11%)]	Loss: 1.342193
[2022-06-09 17:52:08 | train] - Train Epoch: [71] [153600/1281167 (12%)]	Loss: 0.584500
[2022-06-09 17:52:30 | train] - Train Epoch: [71] [166400/1281167 (13%)]	Loss: 0.978805
[2022-06-09 17:52:52 | train] - Train Epoch: [71] [179200/1281167 (14%)]	Loss: 0.869094
[2022-06-09 17:53:13 | train] - Train Epoch: [71] [192000/1281167 (15%)]	Loss: 0.740503
[2022-06-09 17:53:36 | train] - Train Epoch: [71] [204800/1281167 (16%)]	Loss: 0.667351
[2022-06-09 17:53:58 | train] - Train Epoch: [71] [217600/1281167 (17%)]	Loss: 0.984389
[2022-06-09 17:54:20 | train] - Train Epoch: [71] [230400/1281167 (18%)]	Loss: 0.824814
[2022-06-09 17:54:42 | train] - Train Epoch: [71] [243200/1281167 (19%)]	Loss: 0.554814
[2022-06-09 17:55:04 | train] - Train Epoch: [71] [256000/1281167 (20%)]	Loss: 0.794413
[2022-06-09 17:55:26 | train] - Train Epoch: [71] [268800/1281167 (21%)]	Loss: 1.168852
[2022-06-09 17:55:48 | train] - Train Epoch: [71] [281600/1281167 (22%)]	Loss: 0.820602
[2022-06-09 17:56:09 | train] - Train Epoch: [71] [294400/1281167 (23%)]	Loss: 1.048109
[2022-06-09 17:56:31 | train] - Train Epoch: [71] [307200/1281167 (24%)]	Loss: 0.657232
[2022-06-09 17:56:53 | train] - Train Epoch: [71] [320000/1281167 (25%)]	Loss: 0.915848
[2022-06-09 17:57:15 | train] - Train Epoch: [71] [332800/1281167 (26%)]	Loss: 0.913477
[2022-06-09 17:57:38 | train] - Train Epoch: [71] [345600/1281167 (27%)]	Loss: 0.979112
[2022-06-09 17:58:00 | train] - Train Epoch: [71] [358400/1281167 (28%)]	Loss: 0.697476
[2022-06-09 17:58:22 | train] - Train Epoch: [71] [371200/1281167 (29%)]	Loss: 0.801461
[2022-06-09 17:58:44 | train] - Train Epoch: [71] [384000/1281167 (30%)]	Loss: 0.784639
[2022-06-09 17:59:06 | train] - Train Epoch: [71] [396800/1281167 (31%)]	Loss: 1.071668
[2022-06-09 17:59:27 | train] - Train Epoch: [71] [409600/1281167 (32%)]	Loss: 1.047885
[2022-06-09 17:59:49 | train] - Train Epoch: [71] [422400/1281167 (33%)]	Loss: 1.169709
[2022-06-09 18:00:11 | train] - Train Epoch: [71] [435200/1281167 (34%)]	Loss: 0.862462
[2022-06-09 18:00:34 | train] - Train Epoch: [71] [448000/1281167 (35%)]	Loss: 1.170969
[2022-06-09 18:00:56 | train] - Train Epoch: [71] [460800/1281167 (36%)]	Loss: 0.813868
[2022-06-09 18:01:18 | train] - Train Epoch: [71] [473600/1281167 (37%)]	Loss: 0.599828
[2022-06-09 18:01:41 | train] - Train Epoch: [71] [486400/1281167 (38%)]	Loss: 0.848266
[2022-06-09 18:02:03 | train] - Train Epoch: [71] [499200/1281167 (39%)]	Loss: 0.867988
[2022-06-09 18:02:24 | train] - Train Epoch: [71] [512000/1281167 (40%)]	Loss: 1.031502
[2022-06-09 18:02:47 | train] - Train Epoch: [71] [524800/1281167 (41%)]	Loss: 1.256772
[2022-06-09 18:03:09 | train] - Train Epoch: [71] [537600/1281167 (42%)]	Loss: 0.868303
[2022-06-09 18:03:31 | train] - Train Epoch: [71] [550400/1281167 (43%)]	Loss: 0.917843
[2022-06-09 18:03:52 | train] - Train Epoch: [71] [563200/1281167 (44%)]	Loss: 1.002004
[2022-06-09 18:04:14 | train] - Train Epoch: [71] [576000/1281167 (45%)]	Loss: 0.922991
[2022-06-09 18:04:35 | train] - Train Epoch: [71] [588800/1281167 (46%)]	Loss: 0.800729
[2022-06-09 18:04:58 | train] - Train Epoch: [71] [601600/1281167 (47%)]	Loss: 1.031173
[2022-06-09 18:05:19 | train] - Train Epoch: [71] [614400/1281167 (48%)]	Loss: 0.889900
[2022-06-09 18:05:41 | train] - Train Epoch: [71] [627200/1281167 (49%)]	Loss: 0.920023
[2022-06-09 18:06:03 | train] - Train Epoch: [71] [640000/1281167 (50%)]	Loss: 1.087913
[2022-06-09 18:06:26 | train] - Train Epoch: [71] [652800/1281167 (51%)]	Loss: 1.019734
[2022-06-09 18:06:47 | train] - Train Epoch: [71] [665600/1281167 (52%)]	Loss: 0.677877
[2022-06-09 18:07:09 | train] - Train Epoch: [71] [678400/1281167 (53%)]	Loss: 0.924468
[2022-06-09 18:07:31 | train] - Train Epoch: [71] [691200/1281167 (54%)]	Loss: 1.167475
[2022-06-09 18:07:53 | train] - Train Epoch: [71] [704000/1281167 (55%)]	Loss: 1.312577
[2022-06-09 18:08:15 | train] - Train Epoch: [71] [716800/1281167 (56%)]	Loss: 0.999504
[2022-06-09 18:08:37 | train] - Train Epoch: [71] [729600/1281167 (57%)]	Loss: 1.216326
[2022-06-09 18:08:58 | train] - Train Epoch: [71] [742400/1281167 (58%)]	Loss: 1.025720
[2022-06-09 18:09:20 | train] - Train Epoch: [71] [755200/1281167 (59%)]	Loss: 0.975198
[2022-06-09 18:09:42 | train] - Train Epoch: [71] [768000/1281167 (60%)]	Loss: 0.977877
[2022-06-09 18:10:05 | train] - Train Epoch: [71] [780800/1281167 (61%)]	Loss: 1.001448
[2022-06-09 18:10:26 | train] - Train Epoch: [71] [793600/1281167 (62%)]	Loss: 0.825670
[2022-06-09 18:10:48 | train] - Train Epoch: [71] [806400/1281167 (63%)]	Loss: 0.945645
[2022-06-09 18:11:10 | train] - Train Epoch: [71] [819200/1281167 (64%)]	Loss: 1.121953
[2022-06-09 18:11:32 | train] - Train Epoch: [71] [832000/1281167 (65%)]	Loss: 0.787654
[2022-06-09 18:11:54 | train] - Train Epoch: [71] [844800/1281167 (66%)]	Loss: 1.032149
[2022-06-09 18:12:16 | train] - Train Epoch: [71] [857600/1281167 (67%)]	Loss: 0.719229
[2022-06-09 18:12:38 | train] - Train Epoch: [71] [870400/1281167 (68%)]	Loss: 0.936693
[2022-06-09 18:13:00 | train] - Train Epoch: [71] [883200/1281167 (69%)]	Loss: 1.068767
[2022-06-09 18:13:21 | train] - Train Epoch: [71] [896000/1281167 (70%)]	Loss: 1.048700
[2022-06-09 18:13:43 | train] - Train Epoch: [71] [908800/1281167 (71%)]	Loss: 0.983675
[2022-06-09 18:14:06 | train] - Train Epoch: [71] [921600/1281167 (72%)]	Loss: 0.868387
[2022-06-09 18:14:28 | train] - Train Epoch: [71] [934400/1281167 (73%)]	Loss: 0.783522
[2022-06-09 18:14:49 | train] - Train Epoch: [71] [947200/1281167 (74%)]	Loss: 0.908013
[2022-06-09 18:15:11 | train] - Train Epoch: [71] [960000/1281167 (75%)]	Loss: 1.020055
[2022-06-09 18:15:33 | train] - Train Epoch: [71] [972800/1281167 (76%)]	Loss: 1.228059
[2022-06-09 18:15:55 | train] - Train Epoch: [71] [985600/1281167 (77%)]	Loss: 0.882140
[2022-06-09 18:16:16 | train] - Train Epoch: [71] [998400/1281167 (78%)]	Loss: 0.888747
[2022-06-09 18:16:38 | train] - Train Epoch: [71] [1011200/1281167 (79%)]	Loss: 1.023478
[2022-06-09 18:17:00 | train] - Train Epoch: [71] [1024000/1281167 (80%)]	Loss: 0.966291
[2022-06-09 18:17:22 | train] - Train Epoch: [71] [1036800/1281167 (81%)]	Loss: 0.895230
[2022-06-09 18:17:44 | train] - Train Epoch: [71] [1049600/1281167 (82%)]	Loss: 1.164025
[2022-06-09 18:18:06 | train] - Train Epoch: [71] [1062400/1281167 (83%)]	Loss: 0.866688
[2022-06-09 18:18:28 | train] - Train Epoch: [71] [1075200/1281167 (84%)]	Loss: 0.763525
[2022-06-09 18:18:49 | train] - Train Epoch: [71] [1088000/1281167 (85%)]	Loss: 0.960638
[2022-06-09 18:19:11 | train] - Train Epoch: [71] [1100800/1281167 (86%)]	Loss: 0.934505
[2022-06-09 18:19:33 | train] - Train Epoch: [71] [1113600/1281167 (87%)]	Loss: 1.025044
[2022-06-09 18:19:55 | train] - Train Epoch: [71] [1126400/1281167 (88%)]	Loss: 0.922777
[2022-06-09 18:20:17 | train] - Train Epoch: [71] [1139200/1281167 (89%)]	Loss: 0.945061
[2022-06-09 18:20:39 | train] - Train Epoch: [71] [1152000/1281167 (90%)]	Loss: 1.207690
[2022-06-09 18:21:01 | train] - Train Epoch: [71] [1164800/1281167 (91%)]	Loss: 1.116769
[2022-06-09 18:21:23 | train] - Train Epoch: [71] [1177600/1281167 (92%)]	Loss: 0.956416
[2022-06-09 18:21:45 | train] - Train Epoch: [71] [1190400/1281167 (93%)]	Loss: 1.011054
[2022-06-09 18:22:07 | train] - Train Epoch: [71] [1203200/1281167 (94%)]	Loss: 1.003237
[2022-06-09 18:22:29 | train] - Train Epoch: [71] [1216000/1281167 (95%)]	Loss: 1.098316
[2022-06-09 18:22:51 | train] - Train Epoch: [71] [1228800/1281167 (96%)]	Loss: 0.967486
[2022-06-09 18:23:13 | train] - Train Epoch: [71] [1241600/1281167 (97%)]	Loss: 1.177120
[2022-06-09 18:23:36 | train] - Train Epoch: [71] [1254400/1281167 (98%)]	Loss: 0.945108
[2022-06-09 18:23:57 | train] - Train Epoch: [71] [1267200/1281167 (99%)]	Loss: 1.077087
[2022-06-09 18:24:19 | train] - Train Epoch: [71] [1280000/1281167 (100%)]	Loss: 1.059229
[2022-06-09 18:24:21 | train] - Train Epoch: [71]	 Average Loss: 0.931131	 Total Acc : 77.3859	 Total Top5 Acc : 91.5493
[2022-06-09 18:24:21 | train] - -------71 epoch end-----------
========================================
-------71 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 18:25:55 | train] - 
Epoch [71] Test set: Average loss: 1.3281, Accuracy: 35085/50000 (70.1387%), Top-5 Accuracy: 89.0521%

[2022-06-09 18:25:55 | train] - save intermediate epoch [71] result


[2022-06-09 18:26:14 | train] - -------72 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 18:26:16 | train] - Train Epoch: [72] [0/1281167 (0%)]	Loss: 1.030056
[2022-06-09 18:26:38 | train] - Train Epoch: [72] [12800/1281167 (1%)]	Loss: 0.952360
[2022-06-09 18:27:00 | train] - Train Epoch: [72] [25600/1281167 (2%)]	Loss: 0.934393
[2022-06-09 18:27:22 | train] - Train Epoch: [72] [38400/1281167 (3%)]	Loss: 0.796740
[2022-06-09 18:27:44 | train] - Train Epoch: [72] [51200/1281167 (4%)]	Loss: 1.091672
[2022-06-09 18:28:05 | train] - Train Epoch: [72] [64000/1281167 (5%)]	Loss: 0.867712
[2022-06-09 18:28:27 | train] - Train Epoch: [72] [76800/1281167 (6%)]	Loss: 0.622135
[2022-06-09 18:28:49 | train] - Train Epoch: [72] [89600/1281167 (7%)]	Loss: 1.237958
[2022-06-09 18:29:10 | train] - Train Epoch: [72] [102400/1281167 (8%)]	Loss: 0.748174
[2022-06-09 18:29:32 | train] - Train Epoch: [72] [115200/1281167 (9%)]	Loss: 0.793408
[2022-06-09 18:29:54 | train] - Train Epoch: [72] [128000/1281167 (10%)]	Loss: 0.982760
[2022-06-09 18:30:17 | train] - Train Epoch: [72] [140800/1281167 (11%)]	Loss: 0.966319
[2022-06-09 18:30:38 | train] - Train Epoch: [72] [153600/1281167 (12%)]	Loss: 0.646674
[2022-06-09 18:31:01 | train] - Train Epoch: [72] [166400/1281167 (13%)]	Loss: 0.729053
[2022-06-09 18:31:23 | train] - Train Epoch: [72] [179200/1281167 (14%)]	Loss: 1.069062
[2022-06-09 18:31:45 | train] - Train Epoch: [72] [192000/1281167 (15%)]	Loss: 1.091387
[2022-06-09 18:32:07 | train] - Train Epoch: [72] [204800/1281167 (16%)]	Loss: 0.943562
[2022-06-09 18:32:29 | train] - Train Epoch: [72] [217600/1281167 (17%)]	Loss: 0.914388
[2022-06-09 18:32:51 | train] - Train Epoch: [72] [230400/1281167 (18%)]	Loss: 0.878638
[2022-06-09 18:33:12 | train] - Train Epoch: [72] [243200/1281167 (19%)]	Loss: 0.546352
[2022-06-09 18:33:35 | train] - Train Epoch: [72] [256000/1281167 (20%)]	Loss: 0.950132
[2022-06-09 18:33:56 | train] - Train Epoch: [72] [268800/1281167 (21%)]	Loss: 1.058259
[2022-06-09 18:34:18 | train] - Train Epoch: [72] [281600/1281167 (22%)]	Loss: 0.943198
[2022-06-09 18:34:39 | train] - Train Epoch: [72] [294400/1281167 (23%)]	Loss: 0.855859
[2022-06-09 18:35:01 | train] - Train Epoch: [72] [307200/1281167 (24%)]	Loss: 0.781377
[2022-06-09 18:35:23 | train] - Train Epoch: [72] [320000/1281167 (25%)]	Loss: 0.809261
[2022-06-09 18:35:45 | train] - Train Epoch: [72] [332800/1281167 (26%)]	Loss: 0.961626
[2022-06-09 18:36:06 | train] - Train Epoch: [72] [345600/1281167 (27%)]	Loss: 0.817242
[2022-06-09 18:36:28 | train] - Train Epoch: [72] [358400/1281167 (28%)]	Loss: 0.928307
[2022-06-09 18:36:49 | train] - Train Epoch: [72] [371200/1281167 (29%)]	Loss: 1.113859
[2022-06-09 18:37:10 | train] - Train Epoch: [72] [384000/1281167 (30%)]	Loss: 1.000924
[2022-06-09 18:37:32 | train] - Train Epoch: [72] [396800/1281167 (31%)]	Loss: 0.844104
[2022-06-09 18:37:54 | train] - Train Epoch: [72] [409600/1281167 (32%)]	Loss: 0.881522
[2022-06-09 18:38:16 | train] - Train Epoch: [72] [422400/1281167 (33%)]	Loss: 0.974096
[2022-06-09 18:38:38 | train] - Train Epoch: [72] [435200/1281167 (34%)]	Loss: 0.871399
[2022-06-09 18:38:59 | train] - Train Epoch: [72] [448000/1281167 (35%)]	Loss: 1.026240
[2022-06-09 18:39:21 | train] - Train Epoch: [72] [460800/1281167 (36%)]	Loss: 0.754855
[2022-06-09 18:39:43 | train] - Train Epoch: [72] [473600/1281167 (37%)]	Loss: 0.713362
[2022-06-09 18:40:05 | train] - Train Epoch: [72] [486400/1281167 (38%)]	Loss: 0.743251
[2022-06-09 18:40:26 | train] - Train Epoch: [72] [499200/1281167 (39%)]	Loss: 0.962481
[2022-06-09 18:40:48 | train] - Train Epoch: [72] [512000/1281167 (40%)]	Loss: 0.831255
[2022-06-09 18:41:10 | train] - Train Epoch: [72] [524800/1281167 (41%)]	Loss: 0.925797
[2022-06-09 18:41:32 | train] - Train Epoch: [72] [537600/1281167 (42%)]	Loss: 0.998942
[2022-06-09 18:41:54 | train] - Train Epoch: [72] [550400/1281167 (43%)]	Loss: 0.975678
[2022-06-09 18:42:16 | train] - Train Epoch: [72] [563200/1281167 (44%)]	Loss: 0.688957
[2022-06-09 18:42:38 | train] - Train Epoch: [72] [576000/1281167 (45%)]	Loss: 1.099118
[2022-06-09 18:43:00 | train] - Train Epoch: [72] [588800/1281167 (46%)]	Loss: 1.118964
[2022-06-09 18:43:22 | train] - Train Epoch: [72] [601600/1281167 (47%)]	Loss: 1.020088
[2022-06-09 18:43:44 | train] - Train Epoch: [72] [614400/1281167 (48%)]	Loss: 1.083750
[2022-06-09 18:44:05 | train] - Train Epoch: [72] [627200/1281167 (49%)]	Loss: 0.711329
[2022-06-09 18:44:27 | train] - Train Epoch: [72] [640000/1281167 (50%)]	Loss: 1.125712
[2022-06-09 18:44:49 | train] - Train Epoch: [72] [652800/1281167 (51%)]	Loss: 0.836435
[2022-06-09 18:45:11 | train] - Train Epoch: [72] [665600/1281167 (52%)]	Loss: 0.939940
[2022-06-09 18:45:32 | train] - Train Epoch: [72] [678400/1281167 (53%)]	Loss: 0.975973
[2022-06-09 18:45:55 | train] - Train Epoch: [72] [691200/1281167 (54%)]	Loss: 0.785345
[2022-06-09 18:46:17 | train] - Train Epoch: [72] [704000/1281167 (55%)]	Loss: 1.125309
[2022-06-09 18:46:38 | train] - Train Epoch: [72] [716800/1281167 (56%)]	Loss: 0.681470
[2022-06-09 18:47:00 | train] - Train Epoch: [72] [729600/1281167 (57%)]	Loss: 1.156980
[2022-06-09 18:47:22 | train] - Train Epoch: [72] [742400/1281167 (58%)]	Loss: 1.101039
[2022-06-09 18:47:44 | train] - Train Epoch: [72] [755200/1281167 (59%)]	Loss: 1.146278
[2022-06-09 18:48:07 | train] - Train Epoch: [72] [768000/1281167 (60%)]	Loss: 0.763823
[2022-06-09 18:48:29 | train] - Train Epoch: [72] [780800/1281167 (61%)]	Loss: 0.977343
[2022-06-09 18:48:51 | train] - Train Epoch: [72] [793600/1281167 (62%)]	Loss: 0.819114
[2022-06-09 18:49:13 | train] - Train Epoch: [72] [806400/1281167 (63%)]	Loss: 1.254236
[2022-06-09 18:49:35 | train] - Train Epoch: [72] [819200/1281167 (64%)]	Loss: 0.848559
[2022-06-09 18:49:56 | train] - Train Epoch: [72] [832000/1281167 (65%)]	Loss: 1.297499
[2022-06-09 18:50:18 | train] - Train Epoch: [72] [844800/1281167 (66%)]	Loss: 0.950619
[2022-06-09 18:50:40 | train] - Train Epoch: [72] [857600/1281167 (67%)]	Loss: 1.265141
[2022-06-09 18:51:02 | train] - Train Epoch: [72] [870400/1281167 (68%)]	Loss: 0.795753
[2022-06-09 18:51:24 | train] - Train Epoch: [72] [883200/1281167 (69%)]	Loss: 0.994158
[2022-06-09 18:51:46 | train] - Train Epoch: [72] [896000/1281167 (70%)]	Loss: 1.072749
[2022-06-09 18:52:09 | train] - Train Epoch: [72] [908800/1281167 (71%)]	Loss: 1.022474
[2022-06-09 18:52:31 | train] - Train Epoch: [72] [921600/1281167 (72%)]	Loss: 0.569513
[2022-06-09 18:52:52 | train] - Train Epoch: [72] [934400/1281167 (73%)]	Loss: 0.943051
[2022-06-09 18:53:15 | train] - Train Epoch: [72] [947200/1281167 (74%)]	Loss: 0.949469
[2022-06-09 18:53:37 | train] - Train Epoch: [72] [960000/1281167 (75%)]	Loss: 0.947060
[2022-06-09 18:54:00 | train] - Train Epoch: [72] [972800/1281167 (76%)]	Loss: 0.845587
[2022-06-09 18:54:22 | train] - Train Epoch: [72] [985600/1281167 (77%)]	Loss: 0.777180
[2022-06-09 18:54:43 | train] - Train Epoch: [72] [998400/1281167 (78%)]	Loss: 1.066482
[2022-06-09 18:55:06 | train] - Train Epoch: [72] [1011200/1281167 (79%)]	Loss: 0.989610
[2022-06-09 18:55:28 | train] - Train Epoch: [72] [1024000/1281167 (80%)]	Loss: 1.061068
[2022-06-09 18:55:50 | train] - Train Epoch: [72] [1036800/1281167 (81%)]	Loss: 0.863360
[2022-06-09 18:56:12 | train] - Train Epoch: [72] [1049600/1281167 (82%)]	Loss: 0.962572
[2022-06-09 18:56:35 | train] - Train Epoch: [72] [1062400/1281167 (83%)]	Loss: 1.238892
[2022-06-09 18:56:57 | train] - Train Epoch: [72] [1075200/1281167 (84%)]	Loss: 0.812907
[2022-06-09 18:57:18 | train] - Train Epoch: [72] [1088000/1281167 (85%)]	Loss: 0.868060
[2022-06-09 18:57:40 | train] - Train Epoch: [72] [1100800/1281167 (86%)]	Loss: 1.007075
[2022-06-09 18:58:02 | train] - Train Epoch: [72] [1113600/1281167 (87%)]	Loss: 1.018221
[2022-06-09 18:58:24 | train] - Train Epoch: [72] [1126400/1281167 (88%)]	Loss: 1.062136
[2022-06-09 18:58:46 | train] - Train Epoch: [72] [1139200/1281167 (89%)]	Loss: 0.860262
[2022-06-09 18:59:08 | train] - Train Epoch: [72] [1152000/1281167 (90%)]	Loss: 0.901585
[2022-06-09 18:59:30 | train] - Train Epoch: [72] [1164800/1281167 (91%)]	Loss: 1.046333
[2022-06-09 18:59:52 | train] - Train Epoch: [72] [1177600/1281167 (92%)]	Loss: 0.697527
[2022-06-09 19:00:14 | train] - Train Epoch: [72] [1190400/1281167 (93%)]	Loss: 0.988555
[2022-06-09 19:00:36 | train] - Train Epoch: [72] [1203200/1281167 (94%)]	Loss: 0.939347
[2022-06-09 19:00:59 | train] - Train Epoch: [72] [1216000/1281167 (95%)]	Loss: 1.177439
[2022-06-09 19:01:20 | train] - Train Epoch: [72] [1228800/1281167 (96%)]	Loss: 0.999381
[2022-06-09 19:01:41 | train] - Train Epoch: [72] [1241600/1281167 (97%)]	Loss: 0.796251
[2022-06-09 19:02:04 | train] - Train Epoch: [72] [1254400/1281167 (98%)]	Loss: 0.934992
[2022-06-09 19:02:25 | train] - Train Epoch: [72] [1267200/1281167 (99%)]	Loss: 1.008478
[2022-06-09 19:02:47 | train] - Train Epoch: [72] [1280000/1281167 (100%)]	Loss: 0.875387
[2022-06-09 19:02:49 | train] - Train Epoch: [72]	 Average Loss: 0.928948	 Total Acc : 77.3866	 Total Top5 Acc : 91.5663
[2022-06-09 19:02:49 | train] - -------72 epoch end-----------
========================================
-------72 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 19:04:22 | train] - 
Epoch [72] Test set: Average loss: 1.3159, Accuracy: 35029/50000 (70.0328%), Top-5 Accuracy: 89.0901%

[2022-06-09 19:04:22 | train] - save intermediate epoch [72] result


[2022-06-09 19:04:41 | train] - -------73 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 19:04:43 | train] - Train Epoch: [73] [0/1281167 (0%)]	Loss: 0.890229
[2022-06-09 19:05:04 | train] - Train Epoch: [73] [12800/1281167 (1%)]	Loss: 0.960173
[2022-06-09 19:05:26 | train] - Train Epoch: [73] [25600/1281167 (2%)]	Loss: 0.980945
[2022-06-09 19:05:48 | train] - Train Epoch: [73] [38400/1281167 (3%)]	Loss: 0.951307
[2022-06-09 19:06:10 | train] - Train Epoch: [73] [51200/1281167 (4%)]	Loss: 1.185618
[2022-06-09 19:06:32 | train] - Train Epoch: [73] [64000/1281167 (5%)]	Loss: 0.785650
[2022-06-09 19:06:53 | train] - Train Epoch: [73] [76800/1281167 (6%)]	Loss: 0.849302
[2022-06-09 19:07:15 | train] - Train Epoch: [73] [89600/1281167 (7%)]	Loss: 1.009542
[2022-06-09 19:07:37 | train] - Train Epoch: [73] [102400/1281167 (8%)]	Loss: 0.837020
[2022-06-09 19:07:58 | train] - Train Epoch: [73] [115200/1281167 (9%)]	Loss: 0.994808
[2022-06-09 19:08:20 | train] - Train Epoch: [73] [128000/1281167 (10%)]	Loss: 0.882755
[2022-06-09 19:08:42 | train] - Train Epoch: [73] [140800/1281167 (11%)]	Loss: 0.791088
[2022-06-09 19:09:04 | train] - Train Epoch: [73] [153600/1281167 (12%)]	Loss: 0.857209
[2022-06-09 19:09:26 | train] - Train Epoch: [73] [166400/1281167 (13%)]	Loss: 1.159365
[2022-06-09 19:09:47 | train] - Train Epoch: [73] [179200/1281167 (14%)]	Loss: 0.993270
[2022-06-09 19:10:09 | train] - Train Epoch: [73] [192000/1281167 (15%)]	Loss: 0.690991
[2022-06-09 19:10:31 | train] - Train Epoch: [73] [204800/1281167 (16%)]	Loss: 0.964163
[2022-06-09 19:10:53 | train] - Train Epoch: [73] [217600/1281167 (17%)]	Loss: 0.895814
[2022-06-09 19:11:15 | train] - Train Epoch: [73] [230400/1281167 (18%)]	Loss: 1.019089
[2022-06-09 19:11:37 | train] - Train Epoch: [73] [243200/1281167 (19%)]	Loss: 0.919462
[2022-06-09 19:11:59 | train] - Train Epoch: [73] [256000/1281167 (20%)]	Loss: 0.762039
[2022-06-09 19:12:20 | train] - Train Epoch: [73] [268800/1281167 (21%)]	Loss: 1.069567
[2022-06-09 19:12:42 | train] - Train Epoch: [73] [281600/1281167 (22%)]	Loss: 0.832411
[2022-06-09 19:13:04 | train] - Train Epoch: [73] [294400/1281167 (23%)]	Loss: 0.685659
[2022-06-09 19:13:26 | train] - Train Epoch: [73] [307200/1281167 (24%)]	Loss: 1.086153
[2022-06-09 19:13:48 | train] - Train Epoch: [73] [320000/1281167 (25%)]	Loss: 0.794885
[2022-06-09 19:14:10 | train] - Train Epoch: [73] [332800/1281167 (26%)]	Loss: 1.028283
[2022-06-09 19:14:31 | train] - Train Epoch: [73] [345600/1281167 (27%)]	Loss: 1.026164
[2022-06-09 19:14:53 | train] - Train Epoch: [73] [358400/1281167 (28%)]	Loss: 0.774330
[2022-06-09 19:15:15 | train] - Train Epoch: [73] [371200/1281167 (29%)]	Loss: 0.608142
[2022-06-09 19:15:37 | train] - Train Epoch: [73] [384000/1281167 (30%)]	Loss: 0.925387
[2022-06-09 19:15:57 | train] - Train Epoch: [73] [396800/1281167 (31%)]	Loss: 0.747517
[2022-06-09 19:16:19 | train] - Train Epoch: [73] [409600/1281167 (32%)]	Loss: 0.865460
[2022-06-09 19:16:41 | train] - Train Epoch: [73] [422400/1281167 (33%)]	Loss: 0.600625
[2022-06-09 19:17:03 | train] - Train Epoch: [73] [435200/1281167 (34%)]	Loss: 1.207598
[2022-06-09 19:17:25 | train] - Train Epoch: [73] [448000/1281167 (35%)]	Loss: 1.245075
[2022-06-09 19:17:47 | train] - Train Epoch: [73] [460800/1281167 (36%)]	Loss: 1.107292
[2022-06-09 19:18:09 | train] - Train Epoch: [73] [473600/1281167 (37%)]	Loss: 0.678938
[2022-06-09 19:18:30 | train] - Train Epoch: [73] [486400/1281167 (38%)]	Loss: 1.225375
[2022-06-09 19:18:52 | train] - Train Epoch: [73] [499200/1281167 (39%)]	Loss: 0.833852
[2022-06-09 19:19:13 | train] - Train Epoch: [73] [512000/1281167 (40%)]	Loss: 1.125821
[2022-06-09 19:19:35 | train] - Train Epoch: [73] [524800/1281167 (41%)]	Loss: 0.880055
[2022-06-09 19:19:56 | train] - Train Epoch: [73] [537600/1281167 (42%)]	Loss: 1.052681
[2022-06-09 19:20:18 | train] - Train Epoch: [73] [550400/1281167 (43%)]	Loss: 1.197676
[2022-06-09 19:20:40 | train] - Train Epoch: [73] [563200/1281167 (44%)]	Loss: 1.081709
[2022-06-09 19:21:02 | train] - Train Epoch: [73] [576000/1281167 (45%)]	Loss: 0.807799
[2022-06-09 19:21:24 | train] - Train Epoch: [73] [588800/1281167 (46%)]	Loss: 0.678111
[2022-06-09 19:21:44 | train] - Train Epoch: [73] [601600/1281167 (47%)]	Loss: 0.847438
[2022-06-09 19:22:06 | train] - Train Epoch: [73] [614400/1281167 (48%)]	Loss: 0.783093
[2022-06-09 19:22:28 | train] - Train Epoch: [73] [627200/1281167 (49%)]	Loss: 0.771351
[2022-06-09 19:22:50 | train] - Train Epoch: [73] [640000/1281167 (50%)]	Loss: 1.145951
[2022-06-09 19:23:12 | train] - Train Epoch: [73] [652800/1281167 (51%)]	Loss: 0.738394
[2022-06-09 19:23:34 | train] - Train Epoch: [73] [665600/1281167 (52%)]	Loss: 1.056028
[2022-06-09 19:23:55 | train] - Train Epoch: [73] [678400/1281167 (53%)]	Loss: 0.943862
[2022-06-09 19:24:17 | train] - Train Epoch: [73] [691200/1281167 (54%)]	Loss: 1.128145
[2022-06-09 19:24:39 | train] - Train Epoch: [73] [704000/1281167 (55%)]	Loss: 0.916551
[2022-06-09 19:25:01 | train] - Train Epoch: [73] [716800/1281167 (56%)]	Loss: 1.025541
[2022-06-09 19:25:23 | train] - Train Epoch: [73] [729600/1281167 (57%)]	Loss: 0.960338
[2022-06-09 19:25:44 | train] - Train Epoch: [73] [742400/1281167 (58%)]	Loss: 0.731003
[2022-06-09 19:26:05 | train] - Train Epoch: [73] [755200/1281167 (59%)]	Loss: 1.004310
[2022-06-09 19:26:27 | train] - Train Epoch: [73] [768000/1281167 (60%)]	Loss: 0.874500
[2022-06-09 19:26:49 | train] - Train Epoch: [73] [780800/1281167 (61%)]	Loss: 0.865535
[2022-06-09 19:27:12 | train] - Train Epoch: [73] [793600/1281167 (62%)]	Loss: 0.976309
[2022-06-09 19:27:33 | train] - Train Epoch: [73] [806400/1281167 (63%)]	Loss: 1.312946
[2022-06-09 19:27:55 | train] - Train Epoch: [73] [819200/1281167 (64%)]	Loss: 0.904529
[2022-06-09 19:28:17 | train] - Train Epoch: [73] [832000/1281167 (65%)]	Loss: 0.726011
[2022-06-09 19:28:39 | train] - Train Epoch: [73] [844800/1281167 (66%)]	Loss: 0.925885
[2022-06-09 19:29:01 | train] - Train Epoch: [73] [857600/1281167 (67%)]	Loss: 1.057804
[2022-06-09 19:29:23 | train] - Train Epoch: [73] [870400/1281167 (68%)]	Loss: 1.131504
[2022-06-09 19:29:45 | train] - Train Epoch: [73] [883200/1281167 (69%)]	Loss: 0.970918
[2022-06-09 19:30:07 | train] - Train Epoch: [73] [896000/1281167 (70%)]	Loss: 0.938926
[2022-06-09 19:30:29 | train] - Train Epoch: [73] [908800/1281167 (71%)]	Loss: 0.959513
[2022-06-09 19:30:50 | train] - Train Epoch: [73] [921600/1281167 (72%)]	Loss: 0.987193
[2022-06-09 19:31:12 | train] - Train Epoch: [73] [934400/1281167 (73%)]	Loss: 1.077389
[2022-06-09 19:31:34 | train] - Train Epoch: [73] [947200/1281167 (74%)]	Loss: 0.958468
[2022-06-09 19:31:56 | train] - Train Epoch: [73] [960000/1281167 (75%)]	Loss: 0.739345
[2022-06-09 19:32:17 | train] - Train Epoch: [73] [972800/1281167 (76%)]	Loss: 1.014450
[2022-06-09 19:32:39 | train] - Train Epoch: [73] [985600/1281167 (77%)]	Loss: 0.782822
[2022-06-09 19:33:01 | train] - Train Epoch: [73] [998400/1281167 (78%)]	Loss: 0.816506
[2022-06-09 19:33:23 | train] - Train Epoch: [73] [1011200/1281167 (79%)]	Loss: 0.673015
[2022-06-09 19:33:45 | train] - Train Epoch: [73] [1024000/1281167 (80%)]	Loss: 1.157856
[2022-06-09 19:34:07 | train] - Train Epoch: [73] [1036800/1281167 (81%)]	Loss: 0.997068
[2022-06-09 19:34:29 | train] - Train Epoch: [73] [1049600/1281167 (82%)]	Loss: 0.869789
[2022-06-09 19:34:51 | train] - Train Epoch: [73] [1062400/1281167 (83%)]	Loss: 0.805912
[2022-06-09 19:35:13 | train] - Train Epoch: [73] [1075200/1281167 (84%)]	Loss: 0.889346
[2022-06-09 19:35:35 | train] - Train Epoch: [73] [1088000/1281167 (85%)]	Loss: 1.179816
[2022-06-09 19:35:57 | train] - Train Epoch: [73] [1100800/1281167 (86%)]	Loss: 0.861708
[2022-06-09 19:36:20 | train] - Train Epoch: [73] [1113600/1281167 (87%)]	Loss: 1.306258
[2022-06-09 19:36:42 | train] - Train Epoch: [73] [1126400/1281167 (88%)]	Loss: 0.863945
[2022-06-09 19:37:04 | train] - Train Epoch: [73] [1139200/1281167 (89%)]	Loss: 1.030736
[2022-06-09 19:37:26 | train] - Train Epoch: [73] [1152000/1281167 (90%)]	Loss: 1.158526
[2022-06-09 19:37:48 | train] - Train Epoch: [73] [1164800/1281167 (91%)]	Loss: 0.997022
[2022-06-09 19:38:09 | train] - Train Epoch: [73] [1177600/1281167 (92%)]	Loss: 0.835434
[2022-06-09 19:38:31 | train] - Train Epoch: [73] [1190400/1281167 (93%)]	Loss: 0.931950
[2022-06-09 19:38:53 | train] - Train Epoch: [73] [1203200/1281167 (94%)]	Loss: 0.712894
[2022-06-09 19:39:14 | train] - Train Epoch: [73] [1216000/1281167 (95%)]	Loss: 1.016596
[2022-06-09 19:39:35 | train] - Train Epoch: [73] [1228800/1281167 (96%)]	Loss: 0.905314
[2022-06-09 19:39:57 | train] - Train Epoch: [73] [1241600/1281167 (97%)]	Loss: 0.962723
[2022-06-09 19:40:19 | train] - Train Epoch: [73] [1254400/1281167 (98%)]	Loss: 0.912671
[2022-06-09 19:40:41 | train] - Train Epoch: [73] [1267200/1281167 (99%)]	Loss: 0.969093
[2022-06-09 19:41:02 | train] - Train Epoch: [73] [1280000/1281167 (100%)]	Loss: 0.769156
[2022-06-09 19:41:04 | train] - Train Epoch: [73]	 Average Loss: 0.923816	 Total Acc : 77.5180	 Total Top5 Acc : 91.5793
[2022-06-09 19:41:04 | train] - -------73 epoch end-----------
========================================
-------73 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 19:42:39 | train] - 
Epoch [73] Test set: Average loss: 1.3234, Accuracy: 35164/50000 (70.3001%), Top-5 Accuracy: 89.1312%

[2022-06-09 19:42:39 | train] - save intermediate epoch [73] result


[2022-06-09 19:42:59 | train] - -------74 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 19:43:01 | train] - Train Epoch: [74] [0/1281167 (0%)]	Loss: 0.778529
[2022-06-09 19:43:23 | train] - Train Epoch: [74] [12800/1281167 (1%)]	Loss: 0.872951
[2022-06-09 19:43:45 | train] - Train Epoch: [74] [25600/1281167 (2%)]	Loss: 0.848288
[2022-06-09 19:44:07 | train] - Train Epoch: [74] [38400/1281167 (3%)]	Loss: 0.798924
[2022-06-09 19:44:29 | train] - Train Epoch: [74] [51200/1281167 (4%)]	Loss: 0.719381
[2022-06-09 19:44:51 | train] - Train Epoch: [74] [64000/1281167 (5%)]	Loss: 0.809345
[2022-06-09 19:45:13 | train] - Train Epoch: [74] [76800/1281167 (6%)]	Loss: 1.023237
[2022-06-09 19:45:35 | train] - Train Epoch: [74] [89600/1281167 (7%)]	Loss: 1.245433
[2022-06-09 19:45:57 | train] - Train Epoch: [74] [102400/1281167 (8%)]	Loss: 0.838977
[2022-06-09 19:46:19 | train] - Train Epoch: [74] [115200/1281167 (9%)]	Loss: 0.800992
[2022-06-09 19:46:41 | train] - Train Epoch: [74] [128000/1281167 (10%)]	Loss: 0.728341
[2022-06-09 19:47:03 | train] - Train Epoch: [74] [140800/1281167 (11%)]	Loss: 0.983268
[2022-06-09 19:47:26 | train] - Train Epoch: [74] [153600/1281167 (12%)]	Loss: 0.775757
[2022-06-09 19:47:48 | train] - Train Epoch: [74] [166400/1281167 (13%)]	Loss: 1.367039
[2022-06-09 19:48:11 | train] - Train Epoch: [74] [179200/1281167 (14%)]	Loss: 0.932748
[2022-06-09 19:48:33 | train] - Train Epoch: [74] [192000/1281167 (15%)]	Loss: 0.846352
[2022-06-09 19:48:54 | train] - Train Epoch: [74] [204800/1281167 (16%)]	Loss: 0.882102
[2022-06-09 19:49:17 | train] - Train Epoch: [74] [217600/1281167 (17%)]	Loss: 0.827496
[2022-06-09 19:49:38 | train] - Train Epoch: [74] [230400/1281167 (18%)]	Loss: 0.873994
[2022-06-09 19:50:00 | train] - Train Epoch: [74] [243200/1281167 (19%)]	Loss: 0.752473
[2022-06-09 19:50:22 | train] - Train Epoch: [74] [256000/1281167 (20%)]	Loss: 0.949004
[2022-06-09 19:50:43 | train] - Train Epoch: [74] [268800/1281167 (21%)]	Loss: 1.380208
[2022-06-09 19:51:05 | train] - Train Epoch: [74] [281600/1281167 (22%)]	Loss: 1.143070
[2022-06-09 19:51:27 | train] - Train Epoch: [74] [294400/1281167 (23%)]	Loss: 0.768336
[2022-06-09 19:51:49 | train] - Train Epoch: [74] [307200/1281167 (24%)]	Loss: 1.187353
[2022-06-09 19:52:11 | train] - Train Epoch: [74] [320000/1281167 (25%)]	Loss: 0.652177
[2022-06-09 19:52:33 | train] - Train Epoch: [74] [332800/1281167 (26%)]	Loss: 0.999222
[2022-06-09 19:52:55 | train] - Train Epoch: [74] [345600/1281167 (27%)]	Loss: 0.933811
[2022-06-09 19:53:17 | train] - Train Epoch: [74] [358400/1281167 (28%)]	Loss: 0.757379
[2022-06-09 19:53:39 | train] - Train Epoch: [74] [371200/1281167 (29%)]	Loss: 0.961378
[2022-06-09 19:54:01 | train] - Train Epoch: [74] [384000/1281167 (30%)]	Loss: 1.218250
[2022-06-09 19:54:23 | train] - Train Epoch: [74] [396800/1281167 (31%)]	Loss: 0.720172
[2022-06-09 19:54:46 | train] - Train Epoch: [74] [409600/1281167 (32%)]	Loss: 1.076179
[2022-06-09 19:55:08 | train] - Train Epoch: [74] [422400/1281167 (33%)]	Loss: 0.950363
[2022-06-09 19:55:29 | train] - Train Epoch: [74] [435200/1281167 (34%)]	Loss: 0.628389
[2022-06-09 19:55:51 | train] - Train Epoch: [74] [448000/1281167 (35%)]	Loss: 0.697924
[2022-06-09 19:56:13 | train] - Train Epoch: [74] [460800/1281167 (36%)]	Loss: 0.874746
[2022-06-09 19:56:35 | train] - Train Epoch: [74] [473600/1281167 (37%)]	Loss: 1.045654
[2022-06-09 19:56:56 | train] - Train Epoch: [74] [486400/1281167 (38%)]	Loss: 0.717146
[2022-06-09 19:57:18 | train] - Train Epoch: [74] [499200/1281167 (39%)]	Loss: 0.836256
[2022-06-09 19:57:40 | train] - Train Epoch: [74] [512000/1281167 (40%)]	Loss: 0.905619
[2022-06-09 19:58:02 | train] - Train Epoch: [74] [524800/1281167 (41%)]	Loss: 0.887166
[2022-06-09 19:58:25 | train] - Train Epoch: [74] [537600/1281167 (42%)]	Loss: 0.849013
[2022-06-09 19:58:47 | train] - Train Epoch: [74] [550400/1281167 (43%)]	Loss: 0.858465
[2022-06-09 19:59:09 | train] - Train Epoch: [74] [563200/1281167 (44%)]	Loss: 1.067187
[2022-06-09 19:59:32 | train] - Train Epoch: [74] [576000/1281167 (45%)]	Loss: 0.704475
[2022-06-09 19:59:54 | train] - Train Epoch: [74] [588800/1281167 (46%)]	Loss: 0.713449
[2022-06-09 20:00:16 | train] - Train Epoch: [74] [601600/1281167 (47%)]	Loss: 1.241380
[2022-06-09 20:00:38 | train] - Train Epoch: [74] [614400/1281167 (48%)]	Loss: 0.946259
[2022-06-09 20:01:00 | train] - Train Epoch: [74] [627200/1281167 (49%)]	Loss: 0.862770
[2022-06-09 20:01:22 | train] - Train Epoch: [74] [640000/1281167 (50%)]	Loss: 0.783275
[2022-06-09 20:01:43 | train] - Train Epoch: [74] [652800/1281167 (51%)]	Loss: 0.685477
[2022-06-09 20:02:05 | train] - Train Epoch: [74] [665600/1281167 (52%)]	Loss: 1.238285
[2022-06-09 20:02:27 | train] - Train Epoch: [74] [678400/1281167 (53%)]	Loss: 0.812593
[2022-06-09 20:02:49 | train] - Train Epoch: [74] [691200/1281167 (54%)]	Loss: 0.901246
[2022-06-09 20:03:11 | train] - Train Epoch: [74] [704000/1281167 (55%)]	Loss: 1.017266
[2022-06-09 20:03:33 | train] - Train Epoch: [74] [716800/1281167 (56%)]	Loss: 0.932957
[2022-06-09 20:03:54 | train] - Train Epoch: [74] [729600/1281167 (57%)]	Loss: 0.847235
[2022-06-09 20:04:16 | train] - Train Epoch: [74] [742400/1281167 (58%)]	Loss: 1.032017
[2022-06-09 20:04:38 | train] - Train Epoch: [74] [755200/1281167 (59%)]	Loss: 1.085171
[2022-06-09 20:04:59 | train] - Train Epoch: [74] [768000/1281167 (60%)]	Loss: 0.824242
[2022-06-09 20:05:20 | train] - Train Epoch: [74] [780800/1281167 (61%)]	Loss: 1.548508
[2022-06-09 20:05:43 | train] - Train Epoch: [74] [793600/1281167 (62%)]	Loss: 1.079081
[2022-06-09 20:06:05 | train] - Train Epoch: [74] [806400/1281167 (63%)]	Loss: 0.717185
[2022-06-09 20:06:28 | train] - Train Epoch: [74] [819200/1281167 (64%)]	Loss: 1.054258
[2022-06-09 20:06:50 | train] - Train Epoch: [74] [832000/1281167 (65%)]	Loss: 1.008058
[2022-06-09 20:07:12 | train] - Train Epoch: [74] [844800/1281167 (66%)]	Loss: 0.584579
[2022-06-09 20:07:34 | train] - Train Epoch: [74] [857600/1281167 (67%)]	Loss: 0.927492
[2022-06-09 20:07:55 | train] - Train Epoch: [74] [870400/1281167 (68%)]	Loss: 1.090190
[2022-06-09 20:08:18 | train] - Train Epoch: [74] [883200/1281167 (69%)]	Loss: 0.951985
[2022-06-09 20:08:40 | train] - Train Epoch: [74] [896000/1281167 (70%)]	Loss: 0.736405
[2022-06-09 20:09:02 | train] - Train Epoch: [74] [908800/1281167 (71%)]	Loss: 0.700023
[2022-06-09 20:09:23 | train] - Train Epoch: [74] [921600/1281167 (72%)]	Loss: 1.313862
[2022-06-09 20:09:45 | train] - Train Epoch: [74] [934400/1281167 (73%)]	Loss: 1.148812
[2022-06-09 20:10:06 | train] - Train Epoch: [74] [947200/1281167 (74%)]	Loss: 0.759122
[2022-06-09 20:10:28 | train] - Train Epoch: [74] [960000/1281167 (75%)]	Loss: 0.979300
[2022-06-09 20:10:50 | train] - Train Epoch: [74] [972800/1281167 (76%)]	Loss: 1.030390
[2022-06-09 20:11:12 | train] - Train Epoch: [74] [985600/1281167 (77%)]	Loss: 1.145477
[2022-06-09 20:11:34 | train] - Train Epoch: [74] [998400/1281167 (78%)]	Loss: 0.968960
[2022-06-09 20:11:56 | train] - Train Epoch: [74] [1011200/1281167 (79%)]	Loss: 0.705519
[2022-06-09 20:12:18 | train] - Train Epoch: [74] [1024000/1281167 (80%)]	Loss: 0.943950
[2022-06-09 20:12:40 | train] - Train Epoch: [74] [1036800/1281167 (81%)]	Loss: 1.181052
[2022-06-09 20:13:01 | train] - Train Epoch: [74] [1049600/1281167 (82%)]	Loss: 0.921449
[2022-06-09 20:13:23 | train] - Train Epoch: [74] [1062400/1281167 (83%)]	Loss: 1.017900
[2022-06-09 20:13:45 | train] - Train Epoch: [74] [1075200/1281167 (84%)]	Loss: 0.867541
[2022-06-09 20:14:07 | train] - Train Epoch: [74] [1088000/1281167 (85%)]	Loss: 0.891344
[2022-06-09 20:14:29 | train] - Train Epoch: [74] [1100800/1281167 (86%)]	Loss: 0.546122
[2022-06-09 20:14:51 | train] - Train Epoch: [74] [1113600/1281167 (87%)]	Loss: 0.830973
[2022-06-09 20:15:13 | train] - Train Epoch: [74] [1126400/1281167 (88%)]	Loss: 0.816454
[2022-06-09 20:15:35 | train] - Train Epoch: [74] [1139200/1281167 (89%)]	Loss: 0.911475
[2022-06-09 20:15:57 | train] - Train Epoch: [74] [1152000/1281167 (90%)]	Loss: 1.156963
[2022-06-09 20:16:19 | train] - Train Epoch: [74] [1164800/1281167 (91%)]	Loss: 1.107336
[2022-06-09 20:16:41 | train] - Train Epoch: [74] [1177600/1281167 (92%)]	Loss: 1.057123
[2022-06-09 20:17:02 | train] - Train Epoch: [74] [1190400/1281167 (93%)]	Loss: 0.869743
[2022-06-09 20:17:25 | train] - Train Epoch: [74] [1203200/1281167 (94%)]	Loss: 0.788484
[2022-06-09 20:17:46 | train] - Train Epoch: [74] [1216000/1281167 (95%)]	Loss: 1.001041
[2022-06-09 20:18:09 | train] - Train Epoch: [74] [1228800/1281167 (96%)]	Loss: 1.024796
[2022-06-09 20:18:31 | train] - Train Epoch: [74] [1241600/1281167 (97%)]	Loss: 0.931770
[2022-06-09 20:18:53 | train] - Train Epoch: [74] [1254400/1281167 (98%)]	Loss: 0.863685
[2022-06-09 20:19:15 | train] - Train Epoch: [74] [1267200/1281167 (99%)]	Loss: 0.735036
[2022-06-09 20:19:37 | train] - Train Epoch: [74] [1280000/1281167 (100%)]	Loss: 0.941562
[2022-06-09 20:19:39 | train] - Train Epoch: [74]	 Average Loss: 0.920805	 Total Acc : 77.5795	 Total Top5 Acc : 91.5977
[2022-06-09 20:19:39 | train] - -------74 epoch end-----------
========================================
-------74 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 20:21:11 | train] - 
Epoch [74] Test set: Average loss: 1.3288, Accuracy: 35081/50000 (70.1331%), Top-5 Accuracy: 89.0905%

[2022-06-09 20:21:11 | train] - save intermediate epoch [74] result


[2022-06-09 20:21:33 | train] - -------75 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 20:21:35 | train] - Train Epoch: [75] [0/1281167 (0%)]	Loss: 0.792500
[2022-06-09 20:21:57 | train] - Train Epoch: [75] [12800/1281167 (1%)]	Loss: 0.856435
[2022-06-09 20:22:18 | train] - Train Epoch: [75] [25600/1281167 (2%)]	Loss: 0.821499
[2022-06-09 20:22:40 | train] - Train Epoch: [75] [38400/1281167 (3%)]	Loss: 1.035202
[2022-06-09 20:23:03 | train] - Train Epoch: [75] [51200/1281167 (4%)]	Loss: 0.652969
[2022-06-09 20:23:24 | train] - Train Epoch: [75] [64000/1281167 (5%)]	Loss: 0.782169
[2022-06-09 20:23:46 | train] - Train Epoch: [75] [76800/1281167 (6%)]	Loss: 0.774710
[2022-06-09 20:24:08 | train] - Train Epoch: [75] [89600/1281167 (7%)]	Loss: 1.007474
[2022-06-09 20:24:31 | train] - Train Epoch: [75] [102400/1281167 (8%)]	Loss: 1.223503
[2022-06-09 20:24:54 | train] - Train Epoch: [75] [115200/1281167 (9%)]	Loss: 1.065109
[2022-06-09 20:25:16 | train] - Train Epoch: [75] [128000/1281167 (10%)]	Loss: 0.875501
[2022-06-09 20:25:38 | train] - Train Epoch: [75] [140800/1281167 (11%)]	Loss: 0.838298
[2022-06-09 20:25:59 | train] - Train Epoch: [75] [153600/1281167 (12%)]	Loss: 0.917807
[2022-06-09 20:26:21 | train] - Train Epoch: [75] [166400/1281167 (13%)]	Loss: 1.006732
[2022-06-09 20:26:44 | train] - Train Epoch: [75] [179200/1281167 (14%)]	Loss: 1.016033
[2022-06-09 20:27:05 | train] - Train Epoch: [75] [192000/1281167 (15%)]	Loss: 0.940023
[2022-06-09 20:27:27 | train] - Train Epoch: [75] [204800/1281167 (16%)]	Loss: 0.675174
[2022-06-09 20:27:50 | train] - Train Epoch: [75] [217600/1281167 (17%)]	Loss: 1.405017
[2022-06-09 20:28:11 | train] - Train Epoch: [75] [230400/1281167 (18%)]	Loss: 0.686421
[2022-06-09 20:28:33 | train] - Train Epoch: [75] [243200/1281167 (19%)]	Loss: 1.025751
[2022-06-09 20:28:55 | train] - Train Epoch: [75] [256000/1281167 (20%)]	Loss: 0.770391
[2022-06-09 20:29:17 | train] - Train Epoch: [75] [268800/1281167 (21%)]	Loss: 1.105003
[2022-06-09 20:29:39 | train] - Train Epoch: [75] [281600/1281167 (22%)]	Loss: 0.910490
[2022-06-09 20:30:01 | train] - Train Epoch: [75] [294400/1281167 (23%)]	Loss: 0.964112
[2022-06-09 20:30:23 | train] - Train Epoch: [75] [307200/1281167 (24%)]	Loss: 1.006889
[2022-06-09 20:30:45 | train] - Train Epoch: [75] [320000/1281167 (25%)]	Loss: 1.265035
[2022-06-09 20:31:07 | train] - Train Epoch: [75] [332800/1281167 (26%)]	Loss: 0.944903
[2022-06-09 20:31:28 | train] - Train Epoch: [75] [345600/1281167 (27%)]	Loss: 0.902099
[2022-06-09 20:31:50 | train] - Train Epoch: [75] [358400/1281167 (28%)]	Loss: 0.821414
[2022-06-09 20:32:12 | train] - Train Epoch: [75] [371200/1281167 (29%)]	Loss: 0.978785
[2022-06-09 20:32:34 | train] - Train Epoch: [75] [384000/1281167 (30%)]	Loss: 0.783016
[2022-06-09 20:32:56 | train] - Train Epoch: [75] [396800/1281167 (31%)]	Loss: 0.749055
[2022-06-09 20:33:17 | train] - Train Epoch: [75] [409600/1281167 (32%)]	Loss: 0.918158
[2022-06-09 20:33:39 | train] - Train Epoch: [75] [422400/1281167 (33%)]	Loss: 0.821862
[2022-06-09 20:34:01 | train] - Train Epoch: [75] [435200/1281167 (34%)]	Loss: 0.872108
[2022-06-09 20:34:24 | train] - Train Epoch: [75] [448000/1281167 (35%)]	Loss: 1.095031
[2022-06-09 20:34:46 | train] - Train Epoch: [75] [460800/1281167 (36%)]	Loss: 1.161886
[2022-06-09 20:35:07 | train] - Train Epoch: [75] [473600/1281167 (37%)]	Loss: 0.851681
[2022-06-09 20:35:29 | train] - Train Epoch: [75] [486400/1281167 (38%)]	Loss: 1.303280
[2022-06-09 20:35:51 | train] - Train Epoch: [75] [499200/1281167 (39%)]	Loss: 0.860913
[2022-06-09 20:36:13 | train] - Train Epoch: [75] [512000/1281167 (40%)]	Loss: 1.113373
[2022-06-09 20:36:35 | train] - Train Epoch: [75] [524800/1281167 (41%)]	Loss: 0.784994
[2022-06-09 20:36:56 | train] - Train Epoch: [75] [537600/1281167 (42%)]	Loss: 0.918072
[2022-06-09 20:37:18 | train] - Train Epoch: [75] [550400/1281167 (43%)]	Loss: 0.963879
[2022-06-09 20:37:40 | train] - Train Epoch: [75] [563200/1281167 (44%)]	Loss: 0.900568
[2022-06-09 20:38:02 | train] - Train Epoch: [75] [576000/1281167 (45%)]	Loss: 0.863103
[2022-06-09 20:38:22 | train] - Train Epoch: [75] [588800/1281167 (46%)]	Loss: 1.270003
[2022-06-09 20:38:43 | train] - Train Epoch: [75] [601600/1281167 (47%)]	Loss: 0.779848
[2022-06-09 20:39:05 | train] - Train Epoch: [75] [614400/1281167 (48%)]	Loss: 0.937781
[2022-06-09 20:39:27 | train] - Train Epoch: [75] [627200/1281167 (49%)]	Loss: 0.937254
[2022-06-09 20:39:48 | train] - Train Epoch: [75] [640000/1281167 (50%)]	Loss: 0.967768
[2022-06-09 20:40:11 | train] - Train Epoch: [75] [652800/1281167 (51%)]	Loss: 1.063458
[2022-06-09 20:40:32 | train] - Train Epoch: [75] [665600/1281167 (52%)]	Loss: 1.012462
[2022-06-09 20:40:54 | train] - Train Epoch: [75] [678400/1281167 (53%)]	Loss: 0.957541
[2022-06-09 20:41:16 | train] - Train Epoch: [75] [691200/1281167 (54%)]	Loss: 0.930174
[2022-06-09 20:41:37 | train] - Train Epoch: [75] [704000/1281167 (55%)]	Loss: 0.804118
[2022-06-09 20:41:59 | train] - Train Epoch: [75] [716800/1281167 (56%)]	Loss: 0.962386
[2022-06-09 20:42:21 | train] - Train Epoch: [75] [729600/1281167 (57%)]	Loss: 0.976232
[2022-06-09 20:42:43 | train] - Train Epoch: [75] [742400/1281167 (58%)]	Loss: 0.747421
[2022-06-09 20:43:04 | train] - Train Epoch: [75] [755200/1281167 (59%)]	Loss: 0.798801
[2022-06-09 20:43:26 | train] - Train Epoch: [75] [768000/1281167 (60%)]	Loss: 0.840667
[2022-06-09 20:43:47 | train] - Train Epoch: [75] [780800/1281167 (61%)]	Loss: 0.880728
[2022-06-09 20:44:09 | train] - Train Epoch: [75] [793600/1281167 (62%)]	Loss: 0.954485
[2022-06-09 20:44:31 | train] - Train Epoch: [75] [806400/1281167 (63%)]	Loss: 0.979624
[2022-06-09 20:44:53 | train] - Train Epoch: [75] [819200/1281167 (64%)]	Loss: 0.810768
[2022-06-09 20:45:15 | train] - Train Epoch: [75] [832000/1281167 (65%)]	Loss: 0.871398
[2022-06-09 20:45:37 | train] - Train Epoch: [75] [844800/1281167 (66%)]	Loss: 0.731407
[2022-06-09 20:45:59 | train] - Train Epoch: [75] [857600/1281167 (67%)]	Loss: 0.959440
[2022-06-09 20:46:20 | train] - Train Epoch: [75] [870400/1281167 (68%)]	Loss: 1.054917
[2022-06-09 20:46:41 | train] - Train Epoch: [75] [883200/1281167 (69%)]	Loss: 0.991374
[2022-06-09 20:47:02 | train] - Train Epoch: [75] [896000/1281167 (70%)]	Loss: 1.046440
[2022-06-09 20:47:23 | train] - Train Epoch: [75] [908800/1281167 (71%)]	Loss: 1.037720
[2022-06-09 20:47:45 | train] - Train Epoch: [75] [921600/1281167 (72%)]	Loss: 0.910307
[2022-06-09 20:48:06 | train] - Train Epoch: [75] [934400/1281167 (73%)]	Loss: 1.178710
[2022-06-09 20:48:27 | train] - Train Epoch: [75] [947200/1281167 (74%)]	Loss: 0.806285
[2022-06-09 20:48:48 | train] - Train Epoch: [75] [960000/1281167 (75%)]	Loss: 0.717133
[2022-06-09 20:49:10 | train] - Train Epoch: [75] [972800/1281167 (76%)]	Loss: 0.891664
[2022-06-09 20:49:31 | train] - Train Epoch: [75] [985600/1281167 (77%)]	Loss: 0.881909
[2022-06-09 20:49:52 | train] - Train Epoch: [75] [998400/1281167 (78%)]	Loss: 0.884198
[2022-06-09 20:50:14 | train] - Train Epoch: [75] [1011200/1281167 (79%)]	Loss: 0.968998
[2022-06-09 20:50:36 | train] - Train Epoch: [75] [1024000/1281167 (80%)]	Loss: 0.978014
[2022-06-09 20:50:56 | train] - Train Epoch: [75] [1036800/1281167 (81%)]	Loss: 0.752419
[2022-06-09 20:51:18 | train] - Train Epoch: [75] [1049600/1281167 (82%)]	Loss: 0.790866
[2022-06-09 20:51:39 | train] - Train Epoch: [75] [1062400/1281167 (83%)]	Loss: 0.927943
[2022-06-09 20:52:01 | train] - Train Epoch: [75] [1075200/1281167 (84%)]	Loss: 0.861015
[2022-06-09 20:52:23 | train] - Train Epoch: [75] [1088000/1281167 (85%)]	Loss: 0.666186
[2022-06-09 20:52:44 | train] - Train Epoch: [75] [1100800/1281167 (86%)]	Loss: 0.965688
[2022-06-09 20:53:05 | train] - Train Epoch: [75] [1113600/1281167 (87%)]	Loss: 1.141316
[2022-06-09 20:53:25 | train] - Train Epoch: [75] [1126400/1281167 (88%)]	Loss: 0.798786
[2022-06-09 20:53:47 | train] - Train Epoch: [75] [1139200/1281167 (89%)]	Loss: 0.905115
[2022-06-09 20:54:08 | train] - Train Epoch: [75] [1152000/1281167 (90%)]	Loss: 0.851538
[2022-06-09 20:54:30 | train] - Train Epoch: [75] [1164800/1281167 (91%)]	Loss: 0.838612
[2022-06-09 20:54:52 | train] - Train Epoch: [75] [1177600/1281167 (92%)]	Loss: 1.382554
[2022-06-09 20:55:14 | train] - Train Epoch: [75] [1190400/1281167 (93%)]	Loss: 0.872454
[2022-06-09 20:55:36 | train] - Train Epoch: [75] [1203200/1281167 (94%)]	Loss: 1.022960
[2022-06-09 20:55:58 | train] - Train Epoch: [75] [1216000/1281167 (95%)]	Loss: 0.964510
[2022-06-09 20:56:20 | train] - Train Epoch: [75] [1228800/1281167 (96%)]	Loss: 0.818599
[2022-06-09 20:56:42 | train] - Train Epoch: [75] [1241600/1281167 (97%)]	Loss: 0.833066
[2022-06-09 20:57:03 | train] - Train Epoch: [75] [1254400/1281167 (98%)]	Loss: 0.630277
[2022-06-09 20:57:24 | train] - Train Epoch: [75] [1267200/1281167 (99%)]	Loss: 0.757780
[2022-06-09 20:57:45 | train] - Train Epoch: [75] [1280000/1281167 (100%)]	Loss: 0.714133
[2022-06-09 20:57:47 | train] - Train Epoch: [75]	 Average Loss: 0.917666	 Total Acc : 77.6298	 Total Top5 Acc : 91.6946
[2022-06-09 20:57:47 | train] - -------75 epoch end-----------
========================================
-------75 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 20:59:20 | train] - 
Epoch [75] Test set: Average loss: 1.3351, Accuracy: 35072/50000 (70.1151%), Top-5 Accuracy: 89.1516%

[2022-06-09 20:59:20 | train] - save intermediate epoch [75] result


[2022-06-09 20:59:43 | train] - -------76 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 20:59:44 | train] - Train Epoch: [76] [0/1281167 (0%)]	Loss: 0.895043
[2022-06-09 21:00:05 | train] - Train Epoch: [76] [12800/1281167 (1%)]	Loss: 1.058077
[2022-06-09 21:00:26 | train] - Train Epoch: [76] [25600/1281167 (2%)]	Loss: 0.884941
[2022-06-09 21:00:46 | train] - Train Epoch: [76] [38400/1281167 (3%)]	Loss: 0.815934
[2022-06-09 21:01:07 | train] - Train Epoch: [76] [51200/1281167 (4%)]	Loss: 0.774858
[2022-06-09 21:01:27 | train] - Train Epoch: [76] [64000/1281167 (5%)]	Loss: 0.693326
[2022-06-09 21:01:47 | train] - Train Epoch: [76] [76800/1281167 (6%)]	Loss: 0.785592
[2022-06-09 21:02:06 | train] - Train Epoch: [76] [89600/1281167 (7%)]	Loss: 1.039966
[2022-06-09 21:02:26 | train] - Train Epoch: [76] [102400/1281167 (8%)]	Loss: 0.578156
[2022-06-09 21:02:46 | train] - Train Epoch: [76] [115200/1281167 (9%)]	Loss: 1.088079
[2022-06-09 21:03:05 | train] - Train Epoch: [76] [128000/1281167 (10%)]	Loss: 0.839106
[2022-06-09 21:03:25 | train] - Train Epoch: [76] [140800/1281167 (11%)]	Loss: 0.915237
[2022-06-09 21:03:45 | train] - Train Epoch: [76] [153600/1281167 (12%)]	Loss: 0.938135
[2022-06-09 21:04:05 | train] - Train Epoch: [76] [166400/1281167 (13%)]	Loss: 0.967234
[2022-06-09 21:04:25 | train] - Train Epoch: [76] [179200/1281167 (14%)]	Loss: 0.951521
[2022-06-09 21:04:45 | train] - Train Epoch: [76] [192000/1281167 (15%)]	Loss: 0.889726
[2022-06-09 21:05:04 | train] - Train Epoch: [76] [204800/1281167 (16%)]	Loss: 0.848532
[2022-06-09 21:05:24 | train] - Train Epoch: [76] [217600/1281167 (17%)]	Loss: 0.851202
[2022-06-09 21:05:44 | train] - Train Epoch: [76] [230400/1281167 (18%)]	Loss: 0.594470
[2022-06-09 21:06:04 | train] - Train Epoch: [76] [243200/1281167 (19%)]	Loss: 0.987414
[2022-06-09 21:06:24 | train] - Train Epoch: [76] [256000/1281167 (20%)]	Loss: 1.069022
[2022-06-09 21:06:44 | train] - Train Epoch: [76] [268800/1281167 (21%)]	Loss: 0.894376
[2022-06-09 21:07:04 | train] - Train Epoch: [76] [281600/1281167 (22%)]	Loss: 0.979854
[2022-06-09 21:07:24 | train] - Train Epoch: [76] [294400/1281167 (23%)]	Loss: 0.853149
[2022-06-09 21:07:44 | train] - Train Epoch: [76] [307200/1281167 (24%)]	Loss: 0.998363
[2022-06-09 21:08:04 | train] - Train Epoch: [76] [320000/1281167 (25%)]	Loss: 0.591139
[2022-06-09 21:08:24 | train] - Train Epoch: [76] [332800/1281167 (26%)]	Loss: 1.050161
[2022-06-09 21:08:44 | train] - Train Epoch: [76] [345600/1281167 (27%)]	Loss: 1.211415
[2022-06-09 21:09:04 | train] - Train Epoch: [76] [358400/1281167 (28%)]	Loss: 0.997212
[2022-06-09 21:09:23 | train] - Train Epoch: [76] [371200/1281167 (29%)]	Loss: 0.735189
[2022-06-09 21:09:43 | train] - Train Epoch: [76] [384000/1281167 (30%)]	Loss: 0.931742
[2022-06-09 21:10:03 | train] - Train Epoch: [76] [396800/1281167 (31%)]	Loss: 0.642189
[2022-06-09 21:10:23 | train] - Train Epoch: [76] [409600/1281167 (32%)]	Loss: 0.844900
[2022-06-09 21:10:43 | train] - Train Epoch: [76] [422400/1281167 (33%)]	Loss: 0.976691
[2022-06-09 21:11:03 | train] - Train Epoch: [76] [435200/1281167 (34%)]	Loss: 0.826596
[2022-06-09 21:11:23 | train] - Train Epoch: [76] [448000/1281167 (35%)]	Loss: 1.088084
[2022-06-09 21:11:43 | train] - Train Epoch: [76] [460800/1281167 (36%)]	Loss: 0.772217
[2022-06-09 21:12:02 | train] - Train Epoch: [76] [473600/1281167 (37%)]	Loss: 1.297732
[2022-06-09 21:12:22 | train] - Train Epoch: [76] [486400/1281167 (38%)]	Loss: 0.862690
[2022-06-09 21:12:43 | train] - Train Epoch: [76] [499200/1281167 (39%)]	Loss: 0.908714
[2022-06-09 21:13:03 | train] - Train Epoch: [76] [512000/1281167 (40%)]	Loss: 0.980473
[2022-06-09 21:13:24 | train] - Train Epoch: [76] [524800/1281167 (41%)]	Loss: 0.860850
[2022-06-09 21:13:43 | train] - Train Epoch: [76] [537600/1281167 (42%)]	Loss: 0.817489
[2022-06-09 21:14:02 | train] - Train Epoch: [76] [550400/1281167 (43%)]	Loss: 0.714101
[2022-06-09 21:14:22 | train] - Train Epoch: [76] [563200/1281167 (44%)]	Loss: 0.819347
[2022-06-09 21:14:41 | train] - Train Epoch: [76] [576000/1281167 (45%)]	Loss: 1.167370
[2022-06-09 21:15:01 | train] - Train Epoch: [76] [588800/1281167 (46%)]	Loss: 1.104102
[2022-06-09 21:15:20 | train] - Train Epoch: [76] [601600/1281167 (47%)]	Loss: 0.911050
[2022-06-09 21:15:40 | train] - Train Epoch: [76] [614400/1281167 (48%)]	Loss: 0.897868
[2022-06-09 21:15:59 | train] - Train Epoch: [76] [627200/1281167 (49%)]	Loss: 0.893370
[2022-06-09 21:16:19 | train] - Train Epoch: [76] [640000/1281167 (50%)]	Loss: 1.007453
[2022-06-09 21:16:38 | train] - Train Epoch: [76] [652800/1281167 (51%)]	Loss: 0.732875
[2022-06-09 21:16:58 | train] - Train Epoch: [76] [665600/1281167 (52%)]	Loss: 0.918914
[2022-06-09 21:17:18 | train] - Train Epoch: [76] [678400/1281167 (53%)]	Loss: 0.871059
[2022-06-09 21:17:37 | train] - Train Epoch: [76] [691200/1281167 (54%)]	Loss: 0.848741
[2022-06-09 21:17:56 | train] - Train Epoch: [76] [704000/1281167 (55%)]	Loss: 0.894652
[2022-06-09 21:18:16 | train] - Train Epoch: [76] [716800/1281167 (56%)]	Loss: 0.988943
[2022-06-09 21:18:35 | train] - Train Epoch: [76] [729600/1281167 (57%)]	Loss: 0.593113
[2022-06-09 21:18:54 | train] - Train Epoch: [76] [742400/1281167 (58%)]	Loss: 0.899810
[2022-06-09 21:19:14 | train] - Train Epoch: [76] [755200/1281167 (59%)]	Loss: 0.971242
[2022-06-09 21:19:34 | train] - Train Epoch: [76] [768000/1281167 (60%)]	Loss: 0.830306
[2022-06-09 21:19:54 | train] - Train Epoch: [76] [780800/1281167 (61%)]	Loss: 0.951320
[2022-06-09 21:20:13 | train] - Train Epoch: [76] [793600/1281167 (62%)]	Loss: 1.035327
[2022-06-09 21:20:33 | train] - Train Epoch: [76] [806400/1281167 (63%)]	Loss: 1.279015
[2022-06-09 21:20:52 | train] - Train Epoch: [76] [819200/1281167 (64%)]	Loss: 1.082253
[2022-06-09 21:21:12 | train] - Train Epoch: [76] [832000/1281167 (65%)]	Loss: 0.716541
[2022-06-09 21:21:32 | train] - Train Epoch: [76] [844800/1281167 (66%)]	Loss: 0.620306
[2022-06-09 21:21:52 | train] - Train Epoch: [76] [857600/1281167 (67%)]	Loss: 0.941564
[2022-06-09 21:22:11 | train] - Train Epoch: [76] [870400/1281167 (68%)]	Loss: 0.900418
[2022-06-09 21:22:30 | train] - Train Epoch: [76] [883200/1281167 (69%)]	Loss: 0.840043
[2022-06-09 21:22:50 | train] - Train Epoch: [76] [896000/1281167 (70%)]	Loss: 0.986228
[2022-06-09 21:23:10 | train] - Train Epoch: [76] [908800/1281167 (71%)]	Loss: 1.146496
[2022-06-09 21:23:29 | train] - Train Epoch: [76] [921600/1281167 (72%)]	Loss: 0.921654
[2022-06-09 21:23:49 | train] - Train Epoch: [76] [934400/1281167 (73%)]	Loss: 0.971833
[2022-06-09 21:24:09 | train] - Train Epoch: [76] [947200/1281167 (74%)]	Loss: 1.344983
[2022-06-09 21:24:29 | train] - Train Epoch: [76] [960000/1281167 (75%)]	Loss: 0.824930
[2022-06-09 21:24:48 | train] - Train Epoch: [76] [972800/1281167 (76%)]	Loss: 0.716030
[2022-06-09 21:25:08 | train] - Train Epoch: [76] [985600/1281167 (77%)]	Loss: 0.757994
[2022-06-09 21:25:27 | train] - Train Epoch: [76] [998400/1281167 (78%)]	Loss: 0.698544
[2022-06-09 21:25:46 | train] - Train Epoch: [76] [1011200/1281167 (79%)]	Loss: 1.188889
[2022-06-09 21:26:06 | train] - Train Epoch: [76] [1024000/1281167 (80%)]	Loss: 0.874059
[2022-06-09 21:26:25 | train] - Train Epoch: [76] [1036800/1281167 (81%)]	Loss: 1.199142
[2022-06-09 21:26:45 | train] - Train Epoch: [76] [1049600/1281167 (82%)]	Loss: 0.911384
[2022-06-09 21:27:05 | train] - Train Epoch: [76] [1062400/1281167 (83%)]	Loss: 0.801068
[2022-06-09 21:27:24 | train] - Train Epoch: [76] [1075200/1281167 (84%)]	Loss: 1.026904
[2022-06-09 21:27:43 | train] - Train Epoch: [76] [1088000/1281167 (85%)]	Loss: 0.836169
[2022-06-09 21:28:02 | train] - Train Epoch: [76] [1100800/1281167 (86%)]	Loss: 1.226343
[2022-06-09 21:28:22 | train] - Train Epoch: [76] [1113600/1281167 (87%)]	Loss: 0.647206
[2022-06-09 21:28:42 | train] - Train Epoch: [76] [1126400/1281167 (88%)]	Loss: 1.117308
[2022-06-09 21:29:01 | train] - Train Epoch: [76] [1139200/1281167 (89%)]	Loss: 0.927340
[2022-06-09 21:29:21 | train] - Train Epoch: [76] [1152000/1281167 (90%)]	Loss: 1.099087
[2022-06-09 21:29:41 | train] - Train Epoch: [76] [1164800/1281167 (91%)]	Loss: 0.720227
[2022-06-09 21:30:00 | train] - Train Epoch: [76] [1177600/1281167 (92%)]	Loss: 1.341012
[2022-06-09 21:30:20 | train] - Train Epoch: [76] [1190400/1281167 (93%)]	Loss: 0.956282
[2022-06-09 21:30:39 | train] - Train Epoch: [76] [1203200/1281167 (94%)]	Loss: 1.105397
[2022-06-09 21:30:58 | train] - Train Epoch: [76] [1216000/1281167 (95%)]	Loss: 0.845090
[2022-06-09 21:31:18 | train] - Train Epoch: [76] [1228800/1281167 (96%)]	Loss: 0.946045
[2022-06-09 21:31:37 | train] - Train Epoch: [76] [1241600/1281167 (97%)]	Loss: 1.053690
[2022-06-09 21:31:56 | train] - Train Epoch: [76] [1254400/1281167 (98%)]	Loss: 0.766459
[2022-06-09 21:32:16 | train] - Train Epoch: [76] [1267200/1281167 (99%)]	Loss: 1.044103
[2022-06-09 21:32:35 | train] - Train Epoch: [76] [1280000/1281167 (100%)]	Loss: 0.877715
[2022-06-09 21:32:37 | train] - Train Epoch: [76]	 Average Loss: 0.915685	 Total Acc : 77.6957	 Total Top5 Acc : 91.7268
[2022-06-09 21:32:37 | train] - -------76 epoch end-----------
========================================
-------76 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 21:34:07 | train] - 
Epoch [76] Test set: Average loss: 1.3374, Accuracy: 35029/50000 (70.0280%), Top-5 Accuracy: 88.9746%

[2022-06-09 21:34:07 | train] - save intermediate epoch [76] result


[2022-06-09 21:34:28 | train] - -------77 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 21:34:29 | train] - Train Epoch: [77] [0/1281167 (0%)]	Loss: 0.978644
[2022-06-09 21:34:49 | train] - Train Epoch: [77] [12800/1281167 (1%)]	Loss: 0.741732
[2022-06-09 21:35:10 | train] - Train Epoch: [77] [25600/1281167 (2%)]	Loss: 0.886398
[2022-06-09 21:35:31 | train] - Train Epoch: [77] [38400/1281167 (3%)]	Loss: 0.873538
[2022-06-09 21:35:51 | train] - Train Epoch: [77] [51200/1281167 (4%)]	Loss: 0.741181
[2022-06-09 21:36:11 | train] - Train Epoch: [77] [64000/1281167 (5%)]	Loss: 0.928526
[2022-06-09 21:36:31 | train] - Train Epoch: [77] [76800/1281167 (6%)]	Loss: 1.023432
[2022-06-09 21:36:51 | train] - Train Epoch: [77] [89600/1281167 (7%)]	Loss: 0.773919
[2022-06-09 21:37:11 | train] - Train Epoch: [77] [102400/1281167 (8%)]	Loss: 0.854982
[2022-06-09 21:37:31 | train] - Train Epoch: [77] [115200/1281167 (9%)]	Loss: 0.913254
[2022-06-09 21:37:50 | train] - Train Epoch: [77] [128000/1281167 (10%)]	Loss: 0.760830
[2022-06-09 21:38:10 | train] - Train Epoch: [77] [140800/1281167 (11%)]	Loss: 0.892529
[2022-06-09 21:38:30 | train] - Train Epoch: [77] [153600/1281167 (12%)]	Loss: 0.947803
[2022-06-09 21:38:50 | train] - Train Epoch: [77] [166400/1281167 (13%)]	Loss: 0.828490
[2022-06-09 21:39:11 | train] - Train Epoch: [77] [179200/1281167 (14%)]	Loss: 0.864683
[2022-06-09 21:39:31 | train] - Train Epoch: [77] [192000/1281167 (15%)]	Loss: 1.080291
[2022-06-09 21:39:51 | train] - Train Epoch: [77] [204800/1281167 (16%)]	Loss: 1.277911
[2022-06-09 21:40:11 | train] - Train Epoch: [77] [217600/1281167 (17%)]	Loss: 0.649075
[2022-06-09 21:40:31 | train] - Train Epoch: [77] [230400/1281167 (18%)]	Loss: 0.705723
[2022-06-09 21:40:51 | train] - Train Epoch: [77] [243200/1281167 (19%)]	Loss: 0.904401
[2022-06-09 21:41:11 | train] - Train Epoch: [77] [256000/1281167 (20%)]	Loss: 1.105389
[2022-06-09 21:41:32 | train] - Train Epoch: [77] [268800/1281167 (21%)]	Loss: 0.897932
[2022-06-09 21:41:52 | train] - Train Epoch: [77] [281600/1281167 (22%)]	Loss: 0.986963
[2022-06-09 21:42:12 | train] - Train Epoch: [77] [294400/1281167 (23%)]	Loss: 0.804666
[2022-06-09 21:42:32 | train] - Train Epoch: [77] [307200/1281167 (24%)]	Loss: 1.012624
[2022-06-09 21:42:53 | train] - Train Epoch: [77] [320000/1281167 (25%)]	Loss: 0.995111
[2022-06-09 21:43:12 | train] - Train Epoch: [77] [332800/1281167 (26%)]	Loss: 1.200971
[2022-06-09 21:43:33 | train] - Train Epoch: [77] [345600/1281167 (27%)]	Loss: 1.114061
[2022-06-09 21:43:53 | train] - Train Epoch: [77] [358400/1281167 (28%)]	Loss: 0.818398
[2022-06-09 21:44:12 | train] - Train Epoch: [77] [371200/1281167 (29%)]	Loss: 0.995995
[2022-06-09 21:44:32 | train] - Train Epoch: [77] [384000/1281167 (30%)]	Loss: 0.865112
[2022-06-09 21:44:52 | train] - Train Epoch: [77] [396800/1281167 (31%)]	Loss: 0.845907
[2022-06-09 21:45:12 | train] - Train Epoch: [77] [409600/1281167 (32%)]	Loss: 0.887473
[2022-06-09 21:45:32 | train] - Train Epoch: [77] [422400/1281167 (33%)]	Loss: 0.733968
[2022-06-09 21:45:51 | train] - Train Epoch: [77] [435200/1281167 (34%)]	Loss: 0.651787
[2022-06-09 21:46:11 | train] - Train Epoch: [77] [448000/1281167 (35%)]	Loss: 0.870577
[2022-06-09 21:46:32 | train] - Train Epoch: [77] [460800/1281167 (36%)]	Loss: 0.576716
[2022-06-09 21:46:52 | train] - Train Epoch: [77] [473600/1281167 (37%)]	Loss: 0.831847
[2022-06-09 21:47:12 | train] - Train Epoch: [77] [486400/1281167 (38%)]	Loss: 1.108813
[2022-06-09 21:47:31 | train] - Train Epoch: [77] [499200/1281167 (39%)]	Loss: 0.981456
[2022-06-09 21:47:52 | train] - Train Epoch: [77] [512000/1281167 (40%)]	Loss: 0.788384
[2022-06-09 21:48:11 | train] - Train Epoch: [77] [524800/1281167 (41%)]	Loss: 0.941247
[2022-06-09 21:48:30 | train] - Train Epoch: [77] [537600/1281167 (42%)]	Loss: 0.792279
[2022-06-09 21:48:51 | train] - Train Epoch: [77] [550400/1281167 (43%)]	Loss: 1.150764
[2022-06-09 21:49:11 | train] - Train Epoch: [77] [563200/1281167 (44%)]	Loss: 0.928559
[2022-06-09 21:49:31 | train] - Train Epoch: [77] [576000/1281167 (45%)]	Loss: 0.874619
[2022-06-09 21:49:50 | train] - Train Epoch: [77] [588800/1281167 (46%)]	Loss: 1.028404
[2022-06-09 21:50:10 | train] - Train Epoch: [77] [601600/1281167 (47%)]	Loss: 1.217424
[2022-06-09 21:50:30 | train] - Train Epoch: [77] [614400/1281167 (48%)]	Loss: 1.010366
[2022-06-09 21:50:49 | train] - Train Epoch: [77] [627200/1281167 (49%)]	Loss: 0.715185
[2022-06-09 21:51:10 | train] - Train Epoch: [77] [640000/1281167 (50%)]	Loss: 0.801862
[2022-06-09 21:51:30 | train] - Train Epoch: [77] [652800/1281167 (51%)]	Loss: 1.050632
[2022-06-09 21:51:50 | train] - Train Epoch: [77] [665600/1281167 (52%)]	Loss: 0.891403
[2022-06-09 21:52:10 | train] - Train Epoch: [77] [678400/1281167 (53%)]	Loss: 0.711225
[2022-06-09 21:52:29 | train] - Train Epoch: [77] [691200/1281167 (54%)]	Loss: 1.059809
[2022-06-09 21:52:50 | train] - Train Epoch: [77] [704000/1281167 (55%)]	Loss: 0.743591
[2022-06-09 21:53:10 | train] - Train Epoch: [77] [716800/1281167 (56%)]	Loss: 0.853808
[2022-06-09 21:53:30 | train] - Train Epoch: [77] [729600/1281167 (57%)]	Loss: 0.942273
[2022-06-09 21:53:49 | train] - Train Epoch: [77] [742400/1281167 (58%)]	Loss: 1.049098
[2022-06-09 21:54:09 | train] - Train Epoch: [77] [755200/1281167 (59%)]	Loss: 1.023211
[2022-06-09 21:54:28 | train] - Train Epoch: [77] [768000/1281167 (60%)]	Loss: 0.951322
[2022-06-09 21:54:48 | train] - Train Epoch: [77] [780800/1281167 (61%)]	Loss: 0.890169
[2022-06-09 21:55:09 | train] - Train Epoch: [77] [793600/1281167 (62%)]	Loss: 0.956875
[2022-06-09 21:55:28 | train] - Train Epoch: [77] [806400/1281167 (63%)]	Loss: 0.872083
[2022-06-09 21:55:48 | train] - Train Epoch: [77] [819200/1281167 (64%)]	Loss: 1.064195
[2022-06-09 21:56:09 | train] - Train Epoch: [77] [832000/1281167 (65%)]	Loss: 1.051039
[2022-06-09 21:56:28 | train] - Train Epoch: [77] [844800/1281167 (66%)]	Loss: 1.191574
[2022-06-09 21:56:48 | train] - Train Epoch: [77] [857600/1281167 (67%)]	Loss: 0.951490
[2022-06-09 21:57:08 | train] - Train Epoch: [77] [870400/1281167 (68%)]	Loss: 0.862542
[2022-06-09 21:57:28 | train] - Train Epoch: [77] [883200/1281167 (69%)]	Loss: 0.885993
[2022-06-09 21:57:48 | train] - Train Epoch: [77] [896000/1281167 (70%)]	Loss: 0.878634
[2022-06-09 21:58:08 | train] - Train Epoch: [77] [908800/1281167 (71%)]	Loss: 0.698017
[2022-06-09 21:58:28 | train] - Train Epoch: [77] [921600/1281167 (72%)]	Loss: 0.788732
[2022-06-09 21:58:47 | train] - Train Epoch: [77] [934400/1281167 (73%)]	Loss: 1.035980
[2022-06-09 21:59:08 | train] - Train Epoch: [77] [947200/1281167 (74%)]	Loss: 0.959410
[2022-06-09 21:59:27 | train] - Train Epoch: [77] [960000/1281167 (75%)]	Loss: 1.056967
[2022-06-09 21:59:47 | train] - Train Epoch: [77] [972800/1281167 (76%)]	Loss: 1.106715
[2022-06-09 22:00:08 | train] - Train Epoch: [77] [985600/1281167 (77%)]	Loss: 0.742279
[2022-06-09 22:00:27 | train] - Train Epoch: [77] [998400/1281167 (78%)]	Loss: 1.021065
[2022-06-09 22:00:48 | train] - Train Epoch: [77] [1011200/1281167 (79%)]	Loss: 0.779873
[2022-06-09 22:01:08 | train] - Train Epoch: [77] [1024000/1281167 (80%)]	Loss: 0.876561
[2022-06-09 22:01:28 | train] - Train Epoch: [77] [1036800/1281167 (81%)]	Loss: 0.859180
[2022-06-09 22:01:48 | train] - Train Epoch: [77] [1049600/1281167 (82%)]	Loss: 0.923570
[2022-06-09 22:02:08 | train] - Train Epoch: [77] [1062400/1281167 (83%)]	Loss: 0.966951
[2022-06-09 22:02:28 | train] - Train Epoch: [77] [1075200/1281167 (84%)]	Loss: 0.796916
[2022-06-09 22:02:47 | train] - Train Epoch: [77] [1088000/1281167 (85%)]	Loss: 0.747202
[2022-06-09 22:03:08 | train] - Train Epoch: [77] [1100800/1281167 (86%)]	Loss: 0.738501
[2022-06-09 22:03:28 | train] - Train Epoch: [77] [1113600/1281167 (87%)]	Loss: 1.041744
[2022-06-09 22:03:49 | train] - Train Epoch: [77] [1126400/1281167 (88%)]	Loss: 0.833139
[2022-06-09 22:04:09 | train] - Train Epoch: [77] [1139200/1281167 (89%)]	Loss: 0.619304
[2022-06-09 22:04:28 | train] - Train Epoch: [77] [1152000/1281167 (90%)]	Loss: 0.939915
[2022-06-09 22:04:48 | train] - Train Epoch: [77] [1164800/1281167 (91%)]	Loss: 0.754219
[2022-06-09 22:05:09 | train] - Train Epoch: [77] [1177600/1281167 (92%)]	Loss: 0.817197
[2022-06-09 22:05:29 | train] - Train Epoch: [77] [1190400/1281167 (93%)]	Loss: 1.033485
[2022-06-09 22:05:49 | train] - Train Epoch: [77] [1203200/1281167 (94%)]	Loss: 0.832017
[2022-06-09 22:06:10 | train] - Train Epoch: [77] [1216000/1281167 (95%)]	Loss: 0.788274
[2022-06-09 22:06:29 | train] - Train Epoch: [77] [1228800/1281167 (96%)]	Loss: 0.891337
[2022-06-09 22:06:50 | train] - Train Epoch: [77] [1241600/1281167 (97%)]	Loss: 0.924032
[2022-06-09 22:07:09 | train] - Train Epoch: [77] [1254400/1281167 (98%)]	Loss: 0.860017
[2022-06-09 22:07:29 | train] - Train Epoch: [77] [1267200/1281167 (99%)]	Loss: 1.163165
[2022-06-09 22:07:49 | train] - Train Epoch: [77] [1280000/1281167 (100%)]	Loss: 0.956520
[2022-06-09 22:07:51 | train] - Train Epoch: [77]	 Average Loss: 0.913782	 Total Acc : 77.7651	 Total Top5 Acc : 91.7116
[2022-06-09 22:07:51 | train] - -------77 epoch end-----------
========================================
-------77 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 22:09:22 | train] - 
Epoch [77] Test set: Average loss: 1.3396, Accuracy: 35022/50000 (70.0164%), Top-5 Accuracy: 89.0409%

[2022-06-09 22:09:22 | train] - save intermediate epoch [77] result


[2022-06-09 22:09:45 | train] - -------78 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 22:09:47 | train] - Train Epoch: [78] [0/1281167 (0%)]	Loss: 1.157249
[2022-06-09 22:10:07 | train] - Train Epoch: [78] [12800/1281167 (1%)]	Loss: 0.867073
[2022-06-09 22:10:26 | train] - Train Epoch: [78] [25600/1281167 (2%)]	Loss: 1.026319
[2022-06-09 22:10:47 | train] - Train Epoch: [78] [38400/1281167 (3%)]	Loss: 0.656045
[2022-06-09 22:11:07 | train] - Train Epoch: [78] [51200/1281167 (4%)]	Loss: 0.834290
[2022-06-09 22:11:28 | train] - Train Epoch: [78] [64000/1281167 (5%)]	Loss: 0.628078
[2022-06-09 22:11:47 | train] - Train Epoch: [78] [76800/1281167 (6%)]	Loss: 1.002184
[2022-06-09 22:12:07 | train] - Train Epoch: [78] [89600/1281167 (7%)]	Loss: 1.025716
[2022-06-09 22:12:27 | train] - Train Epoch: [78] [102400/1281167 (8%)]	Loss: 0.906027
[2022-06-09 22:12:46 | train] - Train Epoch: [78] [115200/1281167 (9%)]	Loss: 1.292951
[2022-06-09 22:13:06 | train] - Train Epoch: [78] [128000/1281167 (10%)]	Loss: 1.003098
[2022-06-09 22:13:27 | train] - Train Epoch: [78] [140800/1281167 (11%)]	Loss: 0.810974
[2022-06-09 22:13:46 | train] - Train Epoch: [78] [153600/1281167 (12%)]	Loss: 0.846326
[2022-06-09 22:14:06 | train] - Train Epoch: [78] [166400/1281167 (13%)]	Loss: 0.809774
[2022-06-09 22:14:26 | train] - Train Epoch: [78] [179200/1281167 (14%)]	Loss: 0.891562
[2022-06-09 22:14:45 | train] - Train Epoch: [78] [192000/1281167 (15%)]	Loss: 1.028746
[2022-06-09 22:15:05 | train] - Train Epoch: [78] [204800/1281167 (16%)]	Loss: 0.986913
[2022-06-09 22:15:25 | train] - Train Epoch: [78] [217600/1281167 (17%)]	Loss: 0.698199
[2022-06-09 22:15:44 | train] - Train Epoch: [78] [230400/1281167 (18%)]	Loss: 0.848305
[2022-06-09 22:16:04 | train] - Train Epoch: [78] [243200/1281167 (19%)]	Loss: 0.925863
[2022-06-09 22:16:23 | train] - Train Epoch: [78] [256000/1281167 (20%)]	Loss: 1.016371
[2022-06-09 22:16:42 | train] - Train Epoch: [78] [268800/1281167 (21%)]	Loss: 0.873400
[2022-06-09 22:17:02 | train] - Train Epoch: [78] [281600/1281167 (22%)]	Loss: 1.171219
[2022-06-09 22:17:22 | train] - Train Epoch: [78] [294400/1281167 (23%)]	Loss: 0.918603
[2022-06-09 22:17:41 | train] - Train Epoch: [78] [307200/1281167 (24%)]	Loss: 1.019700
[2022-06-09 22:18:00 | train] - Train Epoch: [78] [320000/1281167 (25%)]	Loss: 0.964478
[2022-06-09 22:18:19 | train] - Train Epoch: [78] [332800/1281167 (26%)]	Loss: 0.990852
[2022-06-09 22:18:39 | train] - Train Epoch: [78] [345600/1281167 (27%)]	Loss: 0.807506
[2022-06-09 22:18:58 | train] - Train Epoch: [78] [358400/1281167 (28%)]	Loss: 0.987013
[2022-06-09 22:19:18 | train] - Train Epoch: [78] [371200/1281167 (29%)]	Loss: 0.917722
[2022-06-09 22:19:37 | train] - Train Epoch: [78] [384000/1281167 (30%)]	Loss: 0.782338
[2022-06-09 22:19:57 | train] - Train Epoch: [78] [396800/1281167 (31%)]	Loss: 0.972263
[2022-06-09 22:20:16 | train] - Train Epoch: [78] [409600/1281167 (32%)]	Loss: 0.957152
[2022-06-09 22:20:35 | train] - Train Epoch: [78] [422400/1281167 (33%)]	Loss: 0.994775
[2022-06-09 22:20:55 | train] - Train Epoch: [78] [435200/1281167 (34%)]	Loss: 0.870490
[2022-06-09 22:21:14 | train] - Train Epoch: [78] [448000/1281167 (35%)]	Loss: 1.155106
[2022-06-09 22:21:33 | train] - Train Epoch: [78] [460800/1281167 (36%)]	Loss: 1.007069
[2022-06-09 22:21:53 | train] - Train Epoch: [78] [473600/1281167 (37%)]	Loss: 0.970774
[2022-06-09 22:22:12 | train] - Train Epoch: [78] [486400/1281167 (38%)]	Loss: 0.836082
[2022-06-09 22:22:32 | train] - Train Epoch: [78] [499200/1281167 (39%)]	Loss: 1.055629
[2022-06-09 22:22:51 | train] - Train Epoch: [78] [512000/1281167 (40%)]	Loss: 1.022069
[2022-06-09 22:23:10 | train] - Train Epoch: [78] [524800/1281167 (41%)]	Loss: 0.732419
[2022-06-09 22:23:30 | train] - Train Epoch: [78] [537600/1281167 (42%)]	Loss: 0.753492
[2022-06-09 22:23:49 | train] - Train Epoch: [78] [550400/1281167 (43%)]	Loss: 1.094052
[2022-06-09 22:24:09 | train] - Train Epoch: [78] [563200/1281167 (44%)]	Loss: 0.854454
[2022-06-09 22:24:28 | train] - Train Epoch: [78] [576000/1281167 (45%)]	Loss: 0.821357
[2022-06-09 22:24:48 | train] - Train Epoch: [78] [588800/1281167 (46%)]	Loss: 0.972898
[2022-06-09 22:25:08 | train] - Train Epoch: [78] [601600/1281167 (47%)]	Loss: 1.192118
[2022-06-09 22:25:28 | train] - Train Epoch: [78] [614400/1281167 (48%)]	Loss: 0.915489
[2022-06-09 22:25:47 | train] - Train Epoch: [78] [627200/1281167 (49%)]	Loss: 1.129464
[2022-06-09 22:26:07 | train] - Train Epoch: [78] [640000/1281167 (50%)]	Loss: 0.888726
[2022-06-09 22:26:27 | train] - Train Epoch: [78] [652800/1281167 (51%)]	Loss: 0.616430
[2022-06-09 22:26:46 | train] - Train Epoch: [78] [665600/1281167 (52%)]	Loss: 0.641331
[2022-06-09 22:27:07 | train] - Train Epoch: [78] [678400/1281167 (53%)]	Loss: 0.871135
[2022-06-09 22:27:27 | train] - Train Epoch: [78] [691200/1281167 (54%)]	Loss: 0.744639
[2022-06-09 22:27:47 | train] - Train Epoch: [78] [704000/1281167 (55%)]	Loss: 0.643719
[2022-06-09 22:28:07 | train] - Train Epoch: [78] [716800/1281167 (56%)]	Loss: 0.900742
[2022-06-09 22:28:27 | train] - Train Epoch: [78] [729600/1281167 (57%)]	Loss: 0.688930
[2022-06-09 22:28:47 | train] - Train Epoch: [78] [742400/1281167 (58%)]	Loss: 1.205017
[2022-06-09 22:29:06 | train] - Train Epoch: [78] [755200/1281167 (59%)]	Loss: 0.846608
[2022-06-09 22:29:26 | train] - Train Epoch: [78] [768000/1281167 (60%)]	Loss: 0.812884
[2022-06-09 22:29:47 | train] - Train Epoch: [78] [780800/1281167 (61%)]	Loss: 1.095388
[2022-06-09 22:30:06 | train] - Train Epoch: [78] [793600/1281167 (62%)]	Loss: 0.770463
[2022-06-09 22:30:26 | train] - Train Epoch: [78] [806400/1281167 (63%)]	Loss: 1.072271
[2022-06-09 22:30:46 | train] - Train Epoch: [78] [819200/1281167 (64%)]	Loss: 1.132596
[2022-06-09 22:31:06 | train] - Train Epoch: [78] [832000/1281167 (65%)]	Loss: 0.929268
[2022-06-09 22:31:26 | train] - Train Epoch: [78] [844800/1281167 (66%)]	Loss: 0.619373
[2022-06-09 22:31:46 | train] - Train Epoch: [78] [857600/1281167 (67%)]	Loss: 0.706558
[2022-06-09 22:32:06 | train] - Train Epoch: [78] [870400/1281167 (68%)]	Loss: 0.931198
[2022-06-09 22:32:26 | train] - Train Epoch: [78] [883200/1281167 (69%)]	Loss: 0.757504
[2022-06-09 22:32:46 | train] - Train Epoch: [78] [896000/1281167 (70%)]	Loss: 0.961329
[2022-06-09 22:33:05 | train] - Train Epoch: [78] [908800/1281167 (71%)]	Loss: 0.985476
[2022-06-09 22:33:25 | train] - Train Epoch: [78] [921600/1281167 (72%)]	Loss: 0.875376
[2022-06-09 22:33:45 | train] - Train Epoch: [78] [934400/1281167 (73%)]	Loss: 1.040205
[2022-06-09 22:34:05 | train] - Train Epoch: [78] [947200/1281167 (74%)]	Loss: 1.164656
[2022-06-09 22:34:25 | train] - Train Epoch: [78] [960000/1281167 (75%)]	Loss: 1.033214
[2022-06-09 22:34:45 | train] - Train Epoch: [78] [972800/1281167 (76%)]	Loss: 0.933947
[2022-06-09 22:35:05 | train] - Train Epoch: [78] [985600/1281167 (77%)]	Loss: 0.858324
[2022-06-09 22:35:25 | train] - Train Epoch: [78] [998400/1281167 (78%)]	Loss: 0.882369
[2022-06-09 22:35:45 | train] - Train Epoch: [78] [1011200/1281167 (79%)]	Loss: 0.972849
[2022-06-09 22:36:05 | train] - Train Epoch: [78] [1024000/1281167 (80%)]	Loss: 1.039526
[2022-06-09 22:36:24 | train] - Train Epoch: [78] [1036800/1281167 (81%)]	Loss: 0.804012
[2022-06-09 22:36:44 | train] - Train Epoch: [78] [1049600/1281167 (82%)]	Loss: 1.263913
[2022-06-09 22:37:04 | train] - Train Epoch: [78] [1062400/1281167 (83%)]	Loss: 1.027510
[2022-06-09 22:37:24 | train] - Train Epoch: [78] [1075200/1281167 (84%)]	Loss: 0.833476
[2022-06-09 22:37:44 | train] - Train Epoch: [78] [1088000/1281167 (85%)]	Loss: 1.025199
[2022-06-09 22:38:04 | train] - Train Epoch: [78] [1100800/1281167 (86%)]	Loss: 0.816473
[2022-06-09 22:38:25 | train] - Train Epoch: [78] [1113600/1281167 (87%)]	Loss: 0.907289
[2022-06-09 22:38:45 | train] - Train Epoch: [78] [1126400/1281167 (88%)]	Loss: 0.863166
[2022-06-09 22:39:05 | train] - Train Epoch: [78] [1139200/1281167 (89%)]	Loss: 0.882762
[2022-06-09 22:39:25 | train] - Train Epoch: [78] [1152000/1281167 (90%)]	Loss: 0.947923
[2022-06-09 22:39:45 | train] - Train Epoch: [78] [1164800/1281167 (91%)]	Loss: 0.873752
[2022-06-09 22:40:04 | train] - Train Epoch: [78] [1177600/1281167 (92%)]	Loss: 0.840296
[2022-06-09 22:40:24 | train] - Train Epoch: [78] [1190400/1281167 (93%)]	Loss: 0.895340
[2022-06-09 22:40:44 | train] - Train Epoch: [78] [1203200/1281167 (94%)]	Loss: 0.953312
[2022-06-09 22:41:03 | train] - Train Epoch: [78] [1216000/1281167 (95%)]	Loss: 1.123837
[2022-06-09 22:41:23 | train] - Train Epoch: [78] [1228800/1281167 (96%)]	Loss: 0.679455
[2022-06-09 22:41:43 | train] - Train Epoch: [78] [1241600/1281167 (97%)]	Loss: 0.922719
[2022-06-09 22:42:03 | train] - Train Epoch: [78] [1254400/1281167 (98%)]	Loss: 0.808292
[2022-06-09 22:42:23 | train] - Train Epoch: [78] [1267200/1281167 (99%)]	Loss: 0.804262
[2022-06-09 22:42:42 | train] - Train Epoch: [78] [1280000/1281167 (100%)]	Loss: 0.868051
[2022-06-09 22:42:44 | train] - Train Epoch: [78]	 Average Loss: 0.911183	 Total Acc : 77.7984	 Total Top5 Acc : 91.7327
[2022-06-09 22:42:44 | train] - -------78 epoch end-----------
========================================
-------78 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 22:44:13 | train] - 
Epoch [78] Test set: Average loss: 1.3455, Accuracy: 35000/50000 (69.9748%), Top-5 Accuracy: 89.0409%

[2022-06-09 22:44:13 | train] - save intermediate epoch [78] result


[2022-06-09 22:44:34 | train] - -------79 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 22:44:36 | train] - Train Epoch: [79] [0/1281167 (0%)]	Loss: 0.982562
[2022-06-09 22:44:55 | train] - Train Epoch: [79] [12800/1281167 (1%)]	Loss: 0.841739
[2022-06-09 22:45:16 | train] - Train Epoch: [79] [25600/1281167 (2%)]	Loss: 1.076511
[2022-06-09 22:45:35 | train] - Train Epoch: [79] [38400/1281167 (3%)]	Loss: 0.821658
[2022-06-09 22:45:56 | train] - Train Epoch: [79] [51200/1281167 (4%)]	Loss: 0.812664
[2022-06-09 22:46:17 | train] - Train Epoch: [79] [64000/1281167 (5%)]	Loss: 0.796732
[2022-06-09 22:46:38 | train] - Train Epoch: [79] [76800/1281167 (6%)]	Loss: 0.853159
[2022-06-09 22:46:59 | train] - Train Epoch: [79] [89600/1281167 (7%)]	Loss: 0.700204
[2022-06-09 22:47:20 | train] - Train Epoch: [79] [102400/1281167 (8%)]	Loss: 0.955697
[2022-06-09 22:47:40 | train] - Train Epoch: [79] [115200/1281167 (9%)]	Loss: 0.848954
[2022-06-09 22:48:00 | train] - Train Epoch: [79] [128000/1281167 (10%)]	Loss: 0.788389
[2022-06-09 22:48:21 | train] - Train Epoch: [79] [140800/1281167 (11%)]	Loss: 0.680745
[2022-06-09 22:48:42 | train] - Train Epoch: [79] [153600/1281167 (12%)]	Loss: 0.721471
[2022-06-09 22:49:02 | train] - Train Epoch: [79] [166400/1281167 (13%)]	Loss: 0.932238
[2022-06-09 22:49:22 | train] - Train Epoch: [79] [179200/1281167 (14%)]	Loss: 0.905778
[2022-06-09 22:49:41 | train] - Train Epoch: [79] [192000/1281167 (15%)]	Loss: 0.829800
[2022-06-09 22:50:01 | train] - Train Epoch: [79] [204800/1281167 (16%)]	Loss: 0.838463
[2022-06-09 22:50:21 | train] - Train Epoch: [79] [217600/1281167 (17%)]	Loss: 1.159981
[2022-06-09 22:50:41 | train] - Train Epoch: [79] [230400/1281167 (18%)]	Loss: 0.780603
[2022-06-09 22:51:00 | train] - Train Epoch: [79] [243200/1281167 (19%)]	Loss: 0.667566
[2022-06-09 22:51:21 | train] - Train Epoch: [79] [256000/1281167 (20%)]	Loss: 1.107425
[2022-06-09 22:51:40 | train] - Train Epoch: [79] [268800/1281167 (21%)]	Loss: 0.858557
[2022-06-09 22:52:00 | train] - Train Epoch: [79] [281600/1281167 (22%)]	Loss: 0.878024
[2022-06-09 22:52:20 | train] - Train Epoch: [79] [294400/1281167 (23%)]	Loss: 0.758733
[2022-06-09 22:52:40 | train] - Train Epoch: [79] [307200/1281167 (24%)]	Loss: 0.705383
[2022-06-09 22:52:59 | train] - Train Epoch: [79] [320000/1281167 (25%)]	Loss: 0.649681
[2022-06-09 22:53:19 | train] - Train Epoch: [79] [332800/1281167 (26%)]	Loss: 0.836754
[2022-06-09 22:53:38 | train] - Train Epoch: [79] [345600/1281167 (27%)]	Loss: 0.812083
[2022-06-09 22:53:58 | train] - Train Epoch: [79] [358400/1281167 (28%)]	Loss: 1.116667
[2022-06-09 22:54:18 | train] - Train Epoch: [79] [371200/1281167 (29%)]	Loss: 0.869387
[2022-06-09 22:54:38 | train] - Train Epoch: [79] [384000/1281167 (30%)]	Loss: 0.816174
[2022-06-09 22:54:57 | train] - Train Epoch: [79] [396800/1281167 (31%)]	Loss: 0.767818
[2022-06-09 22:55:17 | train] - Train Epoch: [79] [409600/1281167 (32%)]	Loss: 1.028830
[2022-06-09 22:55:37 | train] - Train Epoch: [79] [422400/1281167 (33%)]	Loss: 0.734469
[2022-06-09 22:55:56 | train] - Train Epoch: [79] [435200/1281167 (34%)]	Loss: 0.997201
[2022-06-09 22:56:16 | train] - Train Epoch: [79] [448000/1281167 (35%)]	Loss: 0.828941
[2022-06-09 22:56:36 | train] - Train Epoch: [79] [460800/1281167 (36%)]	Loss: 0.638520
[2022-06-09 22:56:56 | train] - Train Epoch: [79] [473600/1281167 (37%)]	Loss: 1.030522
[2022-06-09 22:57:16 | train] - Train Epoch: [79] [486400/1281167 (38%)]	Loss: 0.933338
[2022-06-09 22:57:36 | train] - Train Epoch: [79] [499200/1281167 (39%)]	Loss: 0.811684
[2022-06-09 22:57:56 | train] - Train Epoch: [79] [512000/1281167 (40%)]	Loss: 0.924183
[2022-06-09 22:58:15 | train] - Train Epoch: [79] [524800/1281167 (41%)]	Loss: 0.763767
[2022-06-09 22:58:36 | train] - Train Epoch: [79] [537600/1281167 (42%)]	Loss: 1.013474
[2022-06-09 22:58:56 | train] - Train Epoch: [79] [550400/1281167 (43%)]	Loss: 0.908667
[2022-06-09 22:59:16 | train] - Train Epoch: [79] [563200/1281167 (44%)]	Loss: 0.785229
[2022-06-09 22:59:36 | train] - Train Epoch: [79] [576000/1281167 (45%)]	Loss: 0.734630
[2022-06-09 22:59:56 | train] - Train Epoch: [79] [588800/1281167 (46%)]	Loss: 0.857016
[2022-06-09 23:00:15 | train] - Train Epoch: [79] [601600/1281167 (47%)]	Loss: 0.699343
[2022-06-09 23:00:35 | train] - Train Epoch: [79] [614400/1281167 (48%)]	Loss: 1.041776
[2022-06-09 23:00:55 | train] - Train Epoch: [79] [627200/1281167 (49%)]	Loss: 0.911283
[2022-06-09 23:01:15 | train] - Train Epoch: [79] [640000/1281167 (50%)]	Loss: 0.586072
[2022-06-09 23:01:35 | train] - Train Epoch: [79] [652800/1281167 (51%)]	Loss: 0.784946
[2022-06-09 23:01:54 | train] - Train Epoch: [79] [665600/1281167 (52%)]	Loss: 0.934033
[2022-06-09 23:02:15 | train] - Train Epoch: [79] [678400/1281167 (53%)]	Loss: 0.625650
[2022-06-09 23:02:34 | train] - Train Epoch: [79] [691200/1281167 (54%)]	Loss: 0.904749
[2022-06-09 23:02:54 | train] - Train Epoch: [79] [704000/1281167 (55%)]	Loss: 0.868469
[2022-06-09 23:03:14 | train] - Train Epoch: [79] [716800/1281167 (56%)]	Loss: 1.054901
[2022-06-09 23:03:33 | train] - Train Epoch: [79] [729600/1281167 (57%)]	Loss: 0.931816
[2022-06-09 23:03:53 | train] - Train Epoch: [79] [742400/1281167 (58%)]	Loss: 0.876633
[2022-06-09 23:04:13 | train] - Train Epoch: [79] [755200/1281167 (59%)]	Loss: 0.997095
[2022-06-09 23:04:33 | train] - Train Epoch: [79] [768000/1281167 (60%)]	Loss: 0.840647
[2022-06-09 23:04:53 | train] - Train Epoch: [79] [780800/1281167 (61%)]	Loss: 0.872753
[2022-06-09 23:05:13 | train] - Train Epoch: [79] [793600/1281167 (62%)]	Loss: 0.861065
[2022-06-09 23:05:33 | train] - Train Epoch: [79] [806400/1281167 (63%)]	Loss: 0.750717
[2022-06-09 23:05:52 | train] - Train Epoch: [79] [819200/1281167 (64%)]	Loss: 0.957800
[2022-06-09 23:06:11 | train] - Train Epoch: [79] [832000/1281167 (65%)]	Loss: 0.779150
[2022-06-09 23:06:31 | train] - Train Epoch: [79] [844800/1281167 (66%)]	Loss: 0.669047
[2022-06-09 23:06:51 | train] - Train Epoch: [79] [857600/1281167 (67%)]	Loss: 0.970136
[2022-06-09 23:07:11 | train] - Train Epoch: [79] [870400/1281167 (68%)]	Loss: 0.849067
[2022-06-09 23:07:31 | train] - Train Epoch: [79] [883200/1281167 (69%)]	Loss: 0.810580
[2022-06-09 23:07:51 | train] - Train Epoch: [79] [896000/1281167 (70%)]	Loss: 0.893585
[2022-06-09 23:08:10 | train] - Train Epoch: [79] [908800/1281167 (71%)]	Loss: 0.710879
[2022-06-09 23:08:30 | train] - Train Epoch: [79] [921600/1281167 (72%)]	Loss: 0.820870
[2022-06-09 23:08:50 | train] - Train Epoch: [79] [934400/1281167 (73%)]	Loss: 0.862448
[2022-06-09 23:09:11 | train] - Train Epoch: [79] [947200/1281167 (74%)]	Loss: 0.676648
[2022-06-09 23:09:30 | train] - Train Epoch: [79] [960000/1281167 (75%)]	Loss: 0.895345
[2022-06-09 23:09:49 | train] - Train Epoch: [79] [972800/1281167 (76%)]	Loss: 0.704889
[2022-06-09 23:10:08 | train] - Train Epoch: [79] [985600/1281167 (77%)]	Loss: 0.784730
[2022-06-09 23:10:28 | train] - Train Epoch: [79] [998400/1281167 (78%)]	Loss: 0.723794
[2022-06-09 23:10:48 | train] - Train Epoch: [79] [1011200/1281167 (79%)]	Loss: 0.690692
[2022-06-09 23:11:07 | train] - Train Epoch: [79] [1024000/1281167 (80%)]	Loss: 1.005271
[2022-06-09 23:11:27 | train] - Train Epoch: [79] [1036800/1281167 (81%)]	Loss: 1.004413
[2022-06-09 23:11:46 | train] - Train Epoch: [79] [1049600/1281167 (82%)]	Loss: 1.204382
[2022-06-09 23:12:07 | train] - Train Epoch: [79] [1062400/1281167 (83%)]	Loss: 0.872585
[2022-06-09 23:12:27 | train] - Train Epoch: [79] [1075200/1281167 (84%)]	Loss: 0.759945
[2022-06-09 23:12:47 | train] - Train Epoch: [79] [1088000/1281167 (85%)]	Loss: 0.855179
[2022-06-09 23:13:07 | train] - Train Epoch: [79] [1100800/1281167 (86%)]	Loss: 0.942247
[2022-06-09 23:13:27 | train] - Train Epoch: [79] [1113600/1281167 (87%)]	Loss: 1.042656
[2022-06-09 23:13:47 | train] - Train Epoch: [79] [1126400/1281167 (88%)]	Loss: 0.997041
[2022-06-09 23:14:07 | train] - Train Epoch: [79] [1139200/1281167 (89%)]	Loss: 0.884262
[2022-06-09 23:14:26 | train] - Train Epoch: [79] [1152000/1281167 (90%)]	Loss: 0.897499
[2022-06-09 23:14:46 | train] - Train Epoch: [79] [1164800/1281167 (91%)]	Loss: 0.754981
[2022-06-09 23:15:06 | train] - Train Epoch: [79] [1177600/1281167 (92%)]	Loss: 0.747400
[2022-06-09 23:15:26 | train] - Train Epoch: [79] [1190400/1281167 (93%)]	Loss: 0.717500
[2022-06-09 23:15:47 | train] - Train Epoch: [79] [1203200/1281167 (94%)]	Loss: 0.894721
[2022-06-09 23:16:07 | train] - Train Epoch: [79] [1216000/1281167 (95%)]	Loss: 0.784728
[2022-06-09 23:16:27 | train] - Train Epoch: [79] [1228800/1281167 (96%)]	Loss: 1.074172
[2022-06-09 23:16:47 | train] - Train Epoch: [79] [1241600/1281167 (97%)]	Loss: 0.802208
[2022-06-09 23:17:08 | train] - Train Epoch: [79] [1254400/1281167 (98%)]	Loss: 0.836713
[2022-06-09 23:17:27 | train] - Train Epoch: [79] [1267200/1281167 (99%)]	Loss: 0.826591
[2022-06-09 23:17:47 | train] - Train Epoch: [79] [1280000/1281167 (100%)]	Loss: 0.750053
[2022-06-09 23:17:49 | train] - Train Epoch: [79]	 Average Loss: 0.908102	 Total Acc : 77.8711	 Total Top5 Acc : 91.7769
[2022-06-09 23:17:49 | train] - -------79 epoch end-----------
========================================
-------79 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 23:19:23 | train] - 
Epoch [79] Test set: Average loss: 1.3402, Accuracy: 35003/50000 (69.9760%), Top-5 Accuracy: 88.9950%

[2022-06-09 23:19:23 | train] - save intermediate epoch [79] result


[2022-06-09 23:19:46 | train] - -------80 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 23:19:47 | train] - Train Epoch: [80] [0/1281167 (0%)]	Loss: 0.677581
[2022-06-09 23:20:09 | train] - Train Epoch: [80] [12800/1281167 (1%)]	Loss: 0.850093
[2022-06-09 23:20:31 | train] - Train Epoch: [80] [25600/1281167 (2%)]	Loss: 0.804923
[2022-06-09 23:20:52 | train] - Train Epoch: [80] [38400/1281167 (3%)]	Loss: 0.926862
[2022-06-09 23:21:15 | train] - Train Epoch: [80] [51200/1281167 (4%)]	Loss: 0.764704
[2022-06-09 23:21:35 | train] - Train Epoch: [80] [64000/1281167 (5%)]	Loss: 0.874943
[2022-06-09 23:21:57 | train] - Train Epoch: [80] [76800/1281167 (6%)]	Loss: 0.642775
[2022-06-09 23:22:18 | train] - Train Epoch: [80] [89600/1281167 (7%)]	Loss: 0.923880
[2022-06-09 23:22:40 | train] - Train Epoch: [80] [102400/1281167 (8%)]	Loss: 0.759950
[2022-06-09 23:23:02 | train] - Train Epoch: [80] [115200/1281167 (9%)]	Loss: 0.949773
[2022-06-09 23:23:22 | train] - Train Epoch: [80] [128000/1281167 (10%)]	Loss: 0.837104
[2022-06-09 23:23:45 | train] - Train Epoch: [80] [140800/1281167 (11%)]	Loss: 0.920912
[2022-06-09 23:24:06 | train] - Train Epoch: [80] [153600/1281167 (12%)]	Loss: 0.928292
[2022-06-09 23:24:27 | train] - Train Epoch: [80] [166400/1281167 (13%)]	Loss: 0.656021
[2022-06-09 23:24:49 | train] - Train Epoch: [80] [179200/1281167 (14%)]	Loss: 1.115565
[2022-06-09 23:25:11 | train] - Train Epoch: [80] [192000/1281167 (15%)]	Loss: 0.959351
[2022-06-09 23:25:33 | train] - Train Epoch: [80] [204800/1281167 (16%)]	Loss: 0.782536
[2022-06-09 23:25:54 | train] - Train Epoch: [80] [217600/1281167 (17%)]	Loss: 0.724678
[2022-06-09 23:26:16 | train] - Train Epoch: [80] [230400/1281167 (18%)]	Loss: 1.150458
[2022-06-09 23:26:37 | train] - Train Epoch: [80] [243200/1281167 (19%)]	Loss: 1.294212
[2022-06-09 23:26:59 | train] - Train Epoch: [80] [256000/1281167 (20%)]	Loss: 0.839957
[2022-06-09 23:27:21 | train] - Train Epoch: [80] [268800/1281167 (21%)]	Loss: 1.047610
[2022-06-09 23:27:43 | train] - Train Epoch: [80] [281600/1281167 (22%)]	Loss: 0.948080
[2022-06-09 23:28:05 | train] - Train Epoch: [80] [294400/1281167 (23%)]	Loss: 0.898113
[2022-06-09 23:28:25 | train] - Train Epoch: [80] [307200/1281167 (24%)]	Loss: 0.812263
[2022-06-09 23:28:47 | train] - Train Epoch: [80] [320000/1281167 (25%)]	Loss: 0.784501
[2022-06-09 23:29:08 | train] - Train Epoch: [80] [332800/1281167 (26%)]	Loss: 0.873635
[2022-06-09 23:29:30 | train] - Train Epoch: [80] [345600/1281167 (27%)]	Loss: 0.989824
[2022-06-09 23:29:52 | train] - Train Epoch: [80] [358400/1281167 (28%)]	Loss: 0.673107
[2022-06-09 23:30:13 | train] - Train Epoch: [80] [371200/1281167 (29%)]	Loss: 0.928514
[2022-06-09 23:30:35 | train] - Train Epoch: [80] [384000/1281167 (30%)]	Loss: 1.034775
[2022-06-09 23:30:57 | train] - Train Epoch: [80] [396800/1281167 (31%)]	Loss: 0.905447
[2022-06-09 23:31:19 | train] - Train Epoch: [80] [409600/1281167 (32%)]	Loss: 0.797565
[2022-06-09 23:31:41 | train] - Train Epoch: [80] [422400/1281167 (33%)]	Loss: 0.955439
[2022-06-09 23:32:02 | train] - Train Epoch: [80] [435200/1281167 (34%)]	Loss: 0.820080
[2022-06-09 23:32:24 | train] - Train Epoch: [80] [448000/1281167 (35%)]	Loss: 0.845179
[2022-06-09 23:32:45 | train] - Train Epoch: [80] [460800/1281167 (36%)]	Loss: 0.706272
[2022-06-09 23:33:06 | train] - Train Epoch: [80] [473600/1281167 (37%)]	Loss: 0.953691
[2022-06-09 23:33:29 | train] - Train Epoch: [80] [486400/1281167 (38%)]	Loss: 1.152508
[2022-06-09 23:33:50 | train] - Train Epoch: [80] [499200/1281167 (39%)]	Loss: 1.022442
[2022-06-09 23:34:12 | train] - Train Epoch: [80] [512000/1281167 (40%)]	Loss: 0.852568
[2022-06-09 23:34:33 | train] - Train Epoch: [80] [524800/1281167 (41%)]	Loss: 1.027783
[2022-06-09 23:34:53 | train] - Train Epoch: [80] [537600/1281167 (42%)]	Loss: 0.874650
[2022-06-09 23:35:15 | train] - Train Epoch: [80] [550400/1281167 (43%)]	Loss: 1.242611
[2022-06-09 23:35:37 | train] - Train Epoch: [80] [563200/1281167 (44%)]	Loss: 0.770341
[2022-06-09 23:35:58 | train] - Train Epoch: [80] [576000/1281167 (45%)]	Loss: 0.656920
[2022-06-09 23:36:19 | train] - Train Epoch: [80] [588800/1281167 (46%)]	Loss: 0.790076
[2022-06-09 23:36:41 | train] - Train Epoch: [80] [601600/1281167 (47%)]	Loss: 0.867071
[2022-06-09 23:37:02 | train] - Train Epoch: [80] [614400/1281167 (48%)]	Loss: 1.105608
[2022-06-09 23:37:24 | train] - Train Epoch: [80] [627200/1281167 (49%)]	Loss: 0.750226
[2022-06-09 23:37:45 | train] - Train Epoch: [80] [640000/1281167 (50%)]	Loss: 0.993251
[2022-06-09 23:38:07 | train] - Train Epoch: [80] [652800/1281167 (51%)]	Loss: 1.037567
[2022-06-09 23:38:29 | train] - Train Epoch: [80] [665600/1281167 (52%)]	Loss: 0.985676
[2022-06-09 23:38:52 | train] - Train Epoch: [80] [678400/1281167 (53%)]	Loss: 0.852778
[2022-06-09 23:39:13 | train] - Train Epoch: [80] [691200/1281167 (54%)]	Loss: 1.003261
[2022-06-09 23:39:34 | train] - Train Epoch: [80] [704000/1281167 (55%)]	Loss: 0.851810
[2022-06-09 23:39:56 | train] - Train Epoch: [80] [716800/1281167 (56%)]	Loss: 1.134741
[2022-06-09 23:40:18 | train] - Train Epoch: [80] [729600/1281167 (57%)]	Loss: 0.823190
[2022-06-09 23:40:40 | train] - Train Epoch: [80] [742400/1281167 (58%)]	Loss: 0.773049
[2022-06-09 23:41:02 | train] - Train Epoch: [80] [755200/1281167 (59%)]	Loss: 0.767269
[2022-06-09 23:41:24 | train] - Train Epoch: [80] [768000/1281167 (60%)]	Loss: 0.706042
[2022-06-09 23:41:45 | train] - Train Epoch: [80] [780800/1281167 (61%)]	Loss: 0.833760
[2022-06-09 23:42:06 | train] - Train Epoch: [80] [793600/1281167 (62%)]	Loss: 0.840559
[2022-06-09 23:42:28 | train] - Train Epoch: [80] [806400/1281167 (63%)]	Loss: 1.123880
[2022-06-09 23:42:50 | train] - Train Epoch: [80] [819200/1281167 (64%)]	Loss: 0.774084
[2022-06-09 23:43:12 | train] - Train Epoch: [80] [832000/1281167 (65%)]	Loss: 1.260499
[2022-06-09 23:43:33 | train] - Train Epoch: [80] [844800/1281167 (66%)]	Loss: 0.992811
[2022-06-09 23:43:55 | train] - Train Epoch: [80] [857600/1281167 (67%)]	Loss: 0.840753
[2022-06-09 23:44:17 | train] - Train Epoch: [80] [870400/1281167 (68%)]	Loss: 1.101556
[2022-06-09 23:44:39 | train] - Train Epoch: [80] [883200/1281167 (69%)]	Loss: 1.181770
[2022-06-09 23:45:01 | train] - Train Epoch: [80] [896000/1281167 (70%)]	Loss: 0.860116
[2022-06-09 23:45:23 | train] - Train Epoch: [80] [908800/1281167 (71%)]	Loss: 1.102655
[2022-06-09 23:45:44 | train] - Train Epoch: [80] [921600/1281167 (72%)]	Loss: 1.141611
[2022-06-09 23:46:05 | train] - Train Epoch: [80] [934400/1281167 (73%)]	Loss: 0.859238
[2022-06-09 23:46:27 | train] - Train Epoch: [80] [947200/1281167 (74%)]	Loss: 0.680992
[2022-06-09 23:46:48 | train] - Train Epoch: [80] [960000/1281167 (75%)]	Loss: 0.947877
[2022-06-09 23:47:11 | train] - Train Epoch: [80] [972800/1281167 (76%)]	Loss: 1.078780
[2022-06-09 23:47:32 | train] - Train Epoch: [80] [985600/1281167 (77%)]	Loss: 0.863775
[2022-06-09 23:47:54 | train] - Train Epoch: [80] [998400/1281167 (78%)]	Loss: 0.961002
[2022-06-09 23:48:16 | train] - Train Epoch: [80] [1011200/1281167 (79%)]	Loss: 0.950895
[2022-06-09 23:48:38 | train] - Train Epoch: [80] [1024000/1281167 (80%)]	Loss: 0.915153
[2022-06-09 23:49:00 | train] - Train Epoch: [80] [1036800/1281167 (81%)]	Loss: 1.065699
[2022-06-09 23:49:22 | train] - Train Epoch: [80] [1049600/1281167 (82%)]	Loss: 0.565566
[2022-06-09 23:49:44 | train] - Train Epoch: [80] [1062400/1281167 (83%)]	Loss: 1.006977
[2022-06-09 23:50:05 | train] - Train Epoch: [80] [1075200/1281167 (84%)]	Loss: 1.153036
[2022-06-09 23:50:27 | train] - Train Epoch: [80] [1088000/1281167 (85%)]	Loss: 0.951824
[2022-06-09 23:50:48 | train] - Train Epoch: [80] [1100800/1281167 (86%)]	Loss: 0.777978
[2022-06-09 23:51:09 | train] - Train Epoch: [80] [1113600/1281167 (87%)]	Loss: 0.832154
[2022-06-09 23:51:31 | train] - Train Epoch: [80] [1126400/1281167 (88%)]	Loss: 0.870625
[2022-06-09 23:51:53 | train] - Train Epoch: [80] [1139200/1281167 (89%)]	Loss: 0.867425
[2022-06-09 23:52:14 | train] - Train Epoch: [80] [1152000/1281167 (90%)]	Loss: 0.957698
[2022-06-09 23:52:36 | train] - Train Epoch: [80] [1164800/1281167 (91%)]	Loss: 1.050963
[2022-06-09 23:52:58 | train] - Train Epoch: [80] [1177600/1281167 (92%)]	Loss: 1.198136
[2022-06-09 23:53:20 | train] - Train Epoch: [80] [1190400/1281167 (93%)]	Loss: 0.926674
[2022-06-09 23:53:42 | train] - Train Epoch: [80] [1203200/1281167 (94%)]	Loss: 0.838245
[2022-06-09 23:54:03 | train] - Train Epoch: [80] [1216000/1281167 (95%)]	Loss: 0.970688
[2022-06-09 23:54:25 | train] - Train Epoch: [80] [1228800/1281167 (96%)]	Loss: 1.064552
[2022-06-09 23:54:46 | train] - Train Epoch: [80] [1241600/1281167 (97%)]	Loss: 0.989146
[2022-06-09 23:55:08 | train] - Train Epoch: [80] [1254400/1281167 (98%)]	Loss: 0.906103
[2022-06-09 23:55:30 | train] - Train Epoch: [80] [1267200/1281167 (99%)]	Loss: 0.770082
[2022-06-09 23:55:51 | train] - Train Epoch: [80] [1280000/1281167 (100%)]	Loss: 1.159772
[2022-06-09 23:55:53 | train] - Train Epoch: [80]	 Average Loss: 0.905390	 Total Acc : 77.9159	 Total Top5 Acc : 91.8013
[2022-06-09 23:55:53 | train] - -------80 epoch end-----------
========================================
-------80 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-09 23:57:26 | train] - 
Epoch [80] Test set: Average loss: 1.3444, Accuracy: 35066/50000 (70.0995%), Top-5 Accuracy: 89.0285%

[2022-06-09 23:57:26 | train] - save intermediate epoch [80] result


[2022-06-09 23:57:50 | train] - -------81 epoch start-----------
========================================
----- test end -------------------------


[2022-06-09 23:57:51 | train] - Train Epoch: [81] [0/1281167 (0%)]	Loss: 1.094828
[2022-06-09 23:58:14 | train] - Train Epoch: [81] [12800/1281167 (1%)]	Loss: 0.912861
[2022-06-09 23:58:35 | train] - Train Epoch: [81] [25600/1281167 (2%)]	Loss: 1.075252
[2022-06-09 23:58:56 | train] - Train Epoch: [81] [38400/1281167 (3%)]	Loss: 0.698806
[2022-06-09 23:59:18 | train] - Train Epoch: [81] [51200/1281167 (4%)]	Loss: 1.112595
[2022-06-09 23:59:40 | train] - Train Epoch: [81] [64000/1281167 (5%)]	Loss: 0.931181
[2022-06-10 00:00:01 | train] - Train Epoch: [81] [76800/1281167 (6%)]	Loss: 0.794415
[2022-06-10 00:00:23 | train] - Train Epoch: [81] [89600/1281167 (7%)]	Loss: 0.953284
[2022-06-10 00:00:44 | train] - Train Epoch: [81] [102400/1281167 (8%)]	Loss: 0.998531
[2022-06-10 00:01:05 | train] - Train Epoch: [81] [115200/1281167 (9%)]	Loss: 0.935950
[2022-06-10 00:01:26 | train] - Train Epoch: [81] [128000/1281167 (10%)]	Loss: 1.018166
[2022-06-10 00:01:48 | train] - Train Epoch: [81] [140800/1281167 (11%)]	Loss: 0.929923
[2022-06-10 00:02:10 | train] - Train Epoch: [81] [153600/1281167 (12%)]	Loss: 0.952103
[2022-06-10 00:02:32 | train] - Train Epoch: [81] [166400/1281167 (13%)]	Loss: 0.855322
[2022-06-10 00:02:54 | train] - Train Epoch: [81] [179200/1281167 (14%)]	Loss: 1.048326
[2022-06-10 00:03:14 | train] - Train Epoch: [81] [192000/1281167 (15%)]	Loss: 0.928302
[2022-06-10 00:03:37 | train] - Train Epoch: [81] [204800/1281167 (16%)]	Loss: 1.251731
[2022-06-10 00:03:58 | train] - Train Epoch: [81] [217600/1281167 (17%)]	Loss: 0.862959
[2022-06-10 00:04:19 | train] - Train Epoch: [81] [230400/1281167 (18%)]	Loss: 0.883424
[2022-06-10 00:04:40 | train] - Train Epoch: [81] [243200/1281167 (19%)]	Loss: 0.862987
[2022-06-10 00:05:02 | train] - Train Epoch: [81] [256000/1281167 (20%)]	Loss: 0.989777
[2022-06-10 00:05:23 | train] - Train Epoch: [81] [268800/1281167 (21%)]	Loss: 0.884470
[2022-06-10 00:05:45 | train] - Train Epoch: [81] [281600/1281167 (22%)]	Loss: 0.916369
[2022-06-10 00:06:07 | train] - Train Epoch: [81] [294400/1281167 (23%)]	Loss: 0.946492
[2022-06-10 00:06:28 | train] - Train Epoch: [81] [307200/1281167 (24%)]	Loss: 0.774695
[2022-06-10 00:06:49 | train] - Train Epoch: [81] [320000/1281167 (25%)]	Loss: 0.861917
[2022-06-10 00:07:10 | train] - Train Epoch: [81] [332800/1281167 (26%)]	Loss: 0.949822
[2022-06-10 00:07:29 | train] - Train Epoch: [81] [345600/1281167 (27%)]	Loss: 0.834582
[2022-06-10 00:07:49 | train] - Train Epoch: [81] [358400/1281167 (28%)]	Loss: 0.731472
[2022-06-10 00:08:08 | train] - Train Epoch: [81] [371200/1281167 (29%)]	Loss: 0.965018
[2022-06-10 00:08:28 | train] - Train Epoch: [81] [384000/1281167 (30%)]	Loss: 1.137437
[2022-06-10 00:08:48 | train] - Train Epoch: [81] [396800/1281167 (31%)]	Loss: 1.065475
[2022-06-10 00:09:08 | train] - Train Epoch: [81] [409600/1281167 (32%)]	Loss: 0.755360
[2022-06-10 00:09:28 | train] - Train Epoch: [81] [422400/1281167 (33%)]	Loss: 1.012340
[2022-06-10 00:09:48 | train] - Train Epoch: [81] [435200/1281167 (34%)]	Loss: 0.926133
[2022-06-10 00:10:09 | train] - Train Epoch: [81] [448000/1281167 (35%)]	Loss: 0.774023
[2022-06-10 00:10:29 | train] - Train Epoch: [81] [460800/1281167 (36%)]	Loss: 0.838938
[2022-06-10 00:10:48 | train] - Train Epoch: [81] [473600/1281167 (37%)]	Loss: 1.160308
[2022-06-10 00:11:08 | train] - Train Epoch: [81] [486400/1281167 (38%)]	Loss: 0.978449
[2022-06-10 00:11:28 | train] - Train Epoch: [81] [499200/1281167 (39%)]	Loss: 0.981595
[2022-06-10 00:11:48 | train] - Train Epoch: [81] [512000/1281167 (40%)]	Loss: 1.096784
[2022-06-10 00:12:08 | train] - Train Epoch: [81] [524800/1281167 (41%)]	Loss: 1.024346
[2022-06-10 00:12:29 | train] - Train Epoch: [81] [537600/1281167 (42%)]	Loss: 0.637492
[2022-06-10 00:12:49 | train] - Train Epoch: [81] [550400/1281167 (43%)]	Loss: 0.783678
[2022-06-10 00:13:08 | train] - Train Epoch: [81] [563200/1281167 (44%)]	Loss: 0.760031
[2022-06-10 00:13:28 | train] - Train Epoch: [81] [576000/1281167 (45%)]	Loss: 0.945467
[2022-06-10 00:13:48 | train] - Train Epoch: [81] [588800/1281167 (46%)]	Loss: 0.701331
[2022-06-10 00:14:08 | train] - Train Epoch: [81] [601600/1281167 (47%)]	Loss: 1.137776
[2022-06-10 00:14:27 | train] - Train Epoch: [81] [614400/1281167 (48%)]	Loss: 1.118482
[2022-06-10 00:14:47 | train] - Train Epoch: [81] [627200/1281167 (49%)]	Loss: 1.106753
[2022-06-10 00:15:08 | train] - Train Epoch: [81] [640000/1281167 (50%)]	Loss: 0.894740
[2022-06-10 00:15:28 | train] - Train Epoch: [81] [652800/1281167 (51%)]	Loss: 0.848421
[2022-06-10 00:15:49 | train] - Train Epoch: [81] [665600/1281167 (52%)]	Loss: 0.949900
[2022-06-10 00:16:09 | train] - Train Epoch: [81] [678400/1281167 (53%)]	Loss: 0.779518
[2022-06-10 00:16:29 | train] - Train Epoch: [81] [691200/1281167 (54%)]	Loss: 0.938198
[2022-06-10 00:16:49 | train] - Train Epoch: [81] [704000/1281167 (55%)]	Loss: 0.791855
[2022-06-10 00:17:08 | train] - Train Epoch: [81] [716800/1281167 (56%)]	Loss: 1.057123
[2022-06-10 00:17:28 | train] - Train Epoch: [81] [729600/1281167 (57%)]	Loss: 1.087572
[2022-06-10 00:17:49 | train] - Train Epoch: [81] [742400/1281167 (58%)]	Loss: 0.860685
[2022-06-10 00:18:10 | train] - Train Epoch: [81] [755200/1281167 (59%)]	Loss: 1.115620
[2022-06-10 00:18:30 | train] - Train Epoch: [81] [768000/1281167 (60%)]	Loss: 1.268673
[2022-06-10 00:18:50 | train] - Train Epoch: [81] [780800/1281167 (61%)]	Loss: 0.713173
[2022-06-10 00:19:10 | train] - Train Epoch: [81] [793600/1281167 (62%)]	Loss: 1.003507
[2022-06-10 00:19:30 | train] - Train Epoch: [81] [806400/1281167 (63%)]	Loss: 1.016463
[2022-06-10 00:19:50 | train] - Train Epoch: [81] [819200/1281167 (64%)]	Loss: 1.157909
[2022-06-10 00:20:11 | train] - Train Epoch: [81] [832000/1281167 (65%)]	Loss: 1.005137
[2022-06-10 00:20:31 | train] - Train Epoch: [81] [844800/1281167 (66%)]	Loss: 0.937151
[2022-06-10 00:20:51 | train] - Train Epoch: [81] [857600/1281167 (67%)]	Loss: 0.953189
[2022-06-10 00:21:11 | train] - Train Epoch: [81] [870400/1281167 (68%)]	Loss: 0.852671
[2022-06-10 00:21:31 | train] - Train Epoch: [81] [883200/1281167 (69%)]	Loss: 1.125131
[2022-06-10 00:21:51 | train] - Train Epoch: [81] [896000/1281167 (70%)]	Loss: 1.024070
[2022-06-10 00:22:11 | train] - Train Epoch: [81] [908800/1281167 (71%)]	Loss: 0.899992
[2022-06-10 00:22:30 | train] - Train Epoch: [81] [921600/1281167 (72%)]	Loss: 1.017620
[2022-06-10 00:22:50 | train] - Train Epoch: [81] [934400/1281167 (73%)]	Loss: 1.477309
[2022-06-10 00:23:10 | train] - Train Epoch: [81] [947200/1281167 (74%)]	Loss: 0.982247
[2022-06-10 00:23:30 | train] - Train Epoch: [81] [960000/1281167 (75%)]	Loss: 0.998833
[2022-06-10 00:23:50 | train] - Train Epoch: [81] [972800/1281167 (76%)]	Loss: 1.112387
[2022-06-10 00:24:10 | train] - Train Epoch: [81] [985600/1281167 (77%)]	Loss: 0.905639
[2022-06-10 00:24:30 | train] - Train Epoch: [81] [998400/1281167 (78%)]	Loss: 1.120453
[2022-06-10 00:24:51 | train] - Train Epoch: [81] [1011200/1281167 (79%)]	Loss: 0.928189
[2022-06-10 00:25:10 | train] - Train Epoch: [81] [1024000/1281167 (80%)]	Loss: 1.126728
[2022-06-10 00:25:30 | train] - Train Epoch: [81] [1036800/1281167 (81%)]	Loss: 0.879918
[2022-06-10 00:25:51 | train] - Train Epoch: [81] [1049600/1281167 (82%)]	Loss: 0.640663
[2022-06-10 00:26:12 | train] - Train Epoch: [81] [1062400/1281167 (83%)]	Loss: 0.764942
[2022-06-10 00:26:32 | train] - Train Epoch: [81] [1075200/1281167 (84%)]	Loss: 1.038123
[2022-06-10 00:26:52 | train] - Train Epoch: [81] [1088000/1281167 (85%)]	Loss: 0.990953
[2022-06-10 00:27:13 | train] - Train Epoch: [81] [1100800/1281167 (86%)]	Loss: 1.018383
[2022-06-10 00:27:32 | train] - Train Epoch: [81] [1113600/1281167 (87%)]	Loss: 1.087762
[2022-06-10 00:27:52 | train] - Train Epoch: [81] [1126400/1281167 (88%)]	Loss: 0.823962
[2022-06-10 00:28:12 | train] - Train Epoch: [81] [1139200/1281167 (89%)]	Loss: 0.665483
[2022-06-10 00:28:32 | train] - Train Epoch: [81] [1152000/1281167 (90%)]	Loss: 0.988870
[2022-06-10 00:28:52 | train] - Train Epoch: [81] [1164800/1281167 (91%)]	Loss: 0.716012
[2022-06-10 00:29:12 | train] - Train Epoch: [81] [1177600/1281167 (92%)]	Loss: 0.817748
[2022-06-10 00:29:32 | train] - Train Epoch: [81] [1190400/1281167 (93%)]	Loss: 0.903205
[2022-06-10 00:29:54 | train] - Train Epoch: [81] [1203200/1281167 (94%)]	Loss: 0.875896
[2022-06-10 00:30:15 | train] - Train Epoch: [81] [1216000/1281167 (95%)]	Loss: 0.848880
[2022-06-10 00:30:35 | train] - Train Epoch: [81] [1228800/1281167 (96%)]	Loss: 1.218224
[2022-06-10 00:30:55 | train] - Train Epoch: [81] [1241600/1281167 (97%)]	Loss: 0.920000
[2022-06-10 00:31:14 | train] - Train Epoch: [81] [1254400/1281167 (98%)]	Loss: 1.052905
[2022-06-10 00:31:34 | train] - Train Epoch: [81] [1267200/1281167 (99%)]	Loss: 0.754708
[2022-06-10 00:31:54 | train] - Train Epoch: [81] [1280000/1281167 (100%)]	Loss: 0.782140
[2022-06-10 00:31:55 | train] - Train Epoch: [81]	 Average Loss: 0.902082	 Total Acc : 78.0199	 Total Top5 Acc : 91.8254
[2022-06-10 00:31:55 | train] - -------81 epoch end-----------
========================================
-------81 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 00:33:24 | train] - 
Epoch [81] Test set: Average loss: 1.3429, Accuracy: 35050/50000 (70.0639%), Top-5 Accuracy: 89.1180%

[2022-06-10 00:33:24 | train] - save intermediate epoch [81] result


[2022-06-10 00:33:46 | train] - -------82 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 00:33:48 | train] - Train Epoch: [82] [0/1281167 (0%)]	Loss: 0.747435
[2022-06-10 00:34:06 | train] - Train Epoch: [82] [12800/1281167 (1%)]	Loss: 1.045946
[2022-06-10 00:34:25 | train] - Train Epoch: [82] [25600/1281167 (2%)]	Loss: 1.047444
[2022-06-10 00:34:45 | train] - Train Epoch: [82] [38400/1281167 (3%)]	Loss: 1.055723
[2022-06-10 00:35:05 | train] - Train Epoch: [82] [51200/1281167 (4%)]	Loss: 0.927095
[2022-06-10 00:35:25 | train] - Train Epoch: [82] [64000/1281167 (5%)]	Loss: 1.155200
[2022-06-10 00:35:45 | train] - Train Epoch: [82] [76800/1281167 (6%)]	Loss: 0.855203
[2022-06-10 00:36:05 | train] - Train Epoch: [82] [89600/1281167 (7%)]	Loss: 1.090464
[2022-06-10 00:36:26 | train] - Train Epoch: [82] [102400/1281167 (8%)]	Loss: 0.735266
[2022-06-10 00:36:46 | train] - Train Epoch: [82] [115200/1281167 (9%)]	Loss: 0.852786
[2022-06-10 00:37:06 | train] - Train Epoch: [82] [128000/1281167 (10%)]	Loss: 0.837154
[2022-06-10 00:37:27 | train] - Train Epoch: [82] [140800/1281167 (11%)]	Loss: 0.867487
[2022-06-10 00:37:47 | train] - Train Epoch: [82] [153600/1281167 (12%)]	Loss: 0.842289
[2022-06-10 00:38:08 | train] - Train Epoch: [82] [166400/1281167 (13%)]	Loss: 0.708591
[2022-06-10 00:38:28 | train] - Train Epoch: [82] [179200/1281167 (14%)]	Loss: 1.010622
[2022-06-10 00:38:49 | train] - Train Epoch: [82] [192000/1281167 (15%)]	Loss: 0.915488
[2022-06-10 00:39:09 | train] - Train Epoch: [82] [204800/1281167 (16%)]	Loss: 0.966923
[2022-06-10 00:39:29 | train] - Train Epoch: [82] [217600/1281167 (17%)]	Loss: 0.899952
[2022-06-10 00:39:49 | train] - Train Epoch: [82] [230400/1281167 (18%)]	Loss: 0.727096
[2022-06-10 00:40:09 | train] - Train Epoch: [82] [243200/1281167 (19%)]	Loss: 0.894639
[2022-06-10 00:40:28 | train] - Train Epoch: [82] [256000/1281167 (20%)]	Loss: 1.021280
[2022-06-10 00:40:48 | train] - Train Epoch: [82] [268800/1281167 (21%)]	Loss: 0.735875
[2022-06-10 00:41:08 | train] - Train Epoch: [82] [281600/1281167 (22%)]	Loss: 0.834265
[2022-06-10 00:41:28 | train] - Train Epoch: [82] [294400/1281167 (23%)]	Loss: 0.977473
[2022-06-10 00:41:48 | train] - Train Epoch: [82] [307200/1281167 (24%)]	Loss: 0.898255
[2022-06-10 00:42:07 | train] - Train Epoch: [82] [320000/1281167 (25%)]	Loss: 0.841331
[2022-06-10 00:42:27 | train] - Train Epoch: [82] [332800/1281167 (26%)]	Loss: 0.725225
[2022-06-10 00:42:47 | train] - Train Epoch: [82] [345600/1281167 (27%)]	Loss: 1.017848
[2022-06-10 00:43:07 | train] - Train Epoch: [82] [358400/1281167 (28%)]	Loss: 0.874425
[2022-06-10 00:43:26 | train] - Train Epoch: [82] [371200/1281167 (29%)]	Loss: 1.050491
[2022-06-10 00:43:46 | train] - Train Epoch: [82] [384000/1281167 (30%)]	Loss: 0.865159
[2022-06-10 00:44:06 | train] - Train Epoch: [82] [396800/1281167 (31%)]	Loss: 1.106962
[2022-06-10 00:44:26 | train] - Train Epoch: [82] [409600/1281167 (32%)]	Loss: 0.937176
[2022-06-10 00:44:46 | train] - Train Epoch: [82] [422400/1281167 (33%)]	Loss: 0.837973
[2022-06-10 00:45:06 | train] - Train Epoch: [82] [435200/1281167 (34%)]	Loss: 0.895834
[2022-06-10 00:45:26 | train] - Train Epoch: [82] [448000/1281167 (35%)]	Loss: 0.954297
[2022-06-10 00:45:46 | train] - Train Epoch: [82] [460800/1281167 (36%)]	Loss: 0.877754
[2022-06-10 00:46:06 | train] - Train Epoch: [82] [473600/1281167 (37%)]	Loss: 0.760028
[2022-06-10 00:46:26 | train] - Train Epoch: [82] [486400/1281167 (38%)]	Loss: 0.846462
[2022-06-10 00:46:46 | train] - Train Epoch: [82] [499200/1281167 (39%)]	Loss: 0.930734
[2022-06-10 00:47:05 | train] - Train Epoch: [82] [512000/1281167 (40%)]	Loss: 0.754589
[2022-06-10 00:47:25 | train] - Train Epoch: [82] [524800/1281167 (41%)]	Loss: 0.736089
[2022-06-10 00:47:44 | train] - Train Epoch: [82] [537600/1281167 (42%)]	Loss: 0.986065
[2022-06-10 00:48:04 | train] - Train Epoch: [82] [550400/1281167 (43%)]	Loss: 0.756809
[2022-06-10 00:48:24 | train] - Train Epoch: [82] [563200/1281167 (44%)]	Loss: 0.802374
[2022-06-10 00:48:44 | train] - Train Epoch: [82] [576000/1281167 (45%)]	Loss: 0.974775
[2022-06-10 00:49:04 | train] - Train Epoch: [82] [588800/1281167 (46%)]	Loss: 1.096617
[2022-06-10 00:49:24 | train] - Train Epoch: [82] [601600/1281167 (47%)]	Loss: 0.868621
[2022-06-10 00:49:44 | train] - Train Epoch: [82] [614400/1281167 (48%)]	Loss: 1.002049
[2022-06-10 00:50:03 | train] - Train Epoch: [82] [627200/1281167 (49%)]	Loss: 0.918440
[2022-06-10 00:50:23 | train] - Train Epoch: [82] [640000/1281167 (50%)]	Loss: 0.915472
[2022-06-10 00:50:42 | train] - Train Epoch: [82] [652800/1281167 (51%)]	Loss: 0.990612
[2022-06-10 00:51:03 | train] - Train Epoch: [82] [665600/1281167 (52%)]	Loss: 0.827779
[2022-06-10 00:51:22 | train] - Train Epoch: [82] [678400/1281167 (53%)]	Loss: 1.058518
[2022-06-10 00:51:42 | train] - Train Epoch: [82] [691200/1281167 (54%)]	Loss: 0.935838
[2022-06-10 00:52:02 | train] - Train Epoch: [82] [704000/1281167 (55%)]	Loss: 0.896490
[2022-06-10 00:52:21 | train] - Train Epoch: [82] [716800/1281167 (56%)]	Loss: 0.879232
[2022-06-10 00:52:41 | train] - Train Epoch: [82] [729600/1281167 (57%)]	Loss: 1.004120
[2022-06-10 00:53:01 | train] - Train Epoch: [82] [742400/1281167 (58%)]	Loss: 0.769616
[2022-06-10 00:53:21 | train] - Train Epoch: [82] [755200/1281167 (59%)]	Loss: 1.218123
[2022-06-10 00:53:41 | train] - Train Epoch: [82] [768000/1281167 (60%)]	Loss: 1.256339
[2022-06-10 00:54:00 | train] - Train Epoch: [82] [780800/1281167 (61%)]	Loss: 0.830639
[2022-06-10 00:54:19 | train] - Train Epoch: [82] [793600/1281167 (62%)]	Loss: 0.881440
[2022-06-10 00:54:39 | train] - Train Epoch: [82] [806400/1281167 (63%)]	Loss: 1.018772
[2022-06-10 00:54:59 | train] - Train Epoch: [82] [819200/1281167 (64%)]	Loss: 0.796613
[2022-06-10 00:55:18 | train] - Train Epoch: [82] [832000/1281167 (65%)]	Loss: 0.857429
[2022-06-10 00:55:38 | train] - Train Epoch: [82] [844800/1281167 (66%)]	Loss: 0.680407
[2022-06-10 00:55:58 | train] - Train Epoch: [82] [857600/1281167 (67%)]	Loss: 0.906591
[2022-06-10 00:56:18 | train] - Train Epoch: [82] [870400/1281167 (68%)]	Loss: 0.861268
[2022-06-10 00:56:38 | train] - Train Epoch: [82] [883200/1281167 (69%)]	Loss: 0.904579
[2022-06-10 00:56:57 | train] - Train Epoch: [82] [896000/1281167 (70%)]	Loss: 1.117066
[2022-06-10 00:57:16 | train] - Train Epoch: [82] [908800/1281167 (71%)]	Loss: 0.770644
[2022-06-10 00:57:37 | train] - Train Epoch: [82] [921600/1281167 (72%)]	Loss: 1.037368
[2022-06-10 00:57:57 | train] - Train Epoch: [82] [934400/1281167 (73%)]	Loss: 0.800167
[2022-06-10 00:58:18 | train] - Train Epoch: [82] [947200/1281167 (74%)]	Loss: 0.948460
[2022-06-10 00:58:38 | train] - Train Epoch: [82] [960000/1281167 (75%)]	Loss: 0.775346
[2022-06-10 00:58:58 | train] - Train Epoch: [82] [972800/1281167 (76%)]	Loss: 1.059129
[2022-06-10 00:59:17 | train] - Train Epoch: [82] [985600/1281167 (77%)]	Loss: 0.699980
[2022-06-10 00:59:37 | train] - Train Epoch: [82] [998400/1281167 (78%)]	Loss: 0.742395
[2022-06-10 00:59:57 | train] - Train Epoch: [82] [1011200/1281167 (79%)]	Loss: 0.950105
[2022-06-10 01:00:17 | train] - Train Epoch: [82] [1024000/1281167 (80%)]	Loss: 0.861150
[2022-06-10 01:00:36 | train] - Train Epoch: [82] [1036800/1281167 (81%)]	Loss: 0.868480
[2022-06-10 01:00:56 | train] - Train Epoch: [82] [1049600/1281167 (82%)]	Loss: 1.132743
[2022-06-10 01:01:16 | train] - Train Epoch: [82] [1062400/1281167 (83%)]	Loss: 0.835881
[2022-06-10 01:01:36 | train] - Train Epoch: [82] [1075200/1281167 (84%)]	Loss: 0.909833
[2022-06-10 01:01:55 | train] - Train Epoch: [82] [1088000/1281167 (85%)]	Loss: 0.914717
[2022-06-10 01:02:15 | train] - Train Epoch: [82] [1100800/1281167 (86%)]	Loss: 1.021255
[2022-06-10 01:02:35 | train] - Train Epoch: [82] [1113600/1281167 (87%)]	Loss: 0.870944
[2022-06-10 01:02:55 | train] - Train Epoch: [82] [1126400/1281167 (88%)]	Loss: 1.057110
[2022-06-10 01:03:14 | train] - Train Epoch: [82] [1139200/1281167 (89%)]	Loss: 0.863541
[2022-06-10 01:03:34 | train] - Train Epoch: [82] [1152000/1281167 (90%)]	Loss: 1.100292
[2022-06-10 01:03:54 | train] - Train Epoch: [82] [1164800/1281167 (91%)]	Loss: 0.904843
[2022-06-10 01:04:14 | train] - Train Epoch: [82] [1177600/1281167 (92%)]	Loss: 0.993498
[2022-06-10 01:04:33 | train] - Train Epoch: [82] [1190400/1281167 (93%)]	Loss: 0.684781
[2022-06-10 01:04:54 | train] - Train Epoch: [82] [1203200/1281167 (94%)]	Loss: 0.829372
[2022-06-10 01:05:14 | train] - Train Epoch: [82] [1216000/1281167 (95%)]	Loss: 0.948254
[2022-06-10 01:05:34 | train] - Train Epoch: [82] [1228800/1281167 (96%)]	Loss: 1.020001
[2022-06-10 01:05:53 | train] - Train Epoch: [82] [1241600/1281167 (97%)]	Loss: 1.018651
[2022-06-10 01:06:13 | train] - Train Epoch: [82] [1254400/1281167 (98%)]	Loss: 0.938779
[2022-06-10 01:06:33 | train] - Train Epoch: [82] [1267200/1281167 (99%)]	Loss: 1.027313
[2022-06-10 01:06:52 | train] - Train Epoch: [82] [1280000/1281167 (100%)]	Loss: 1.090930
[2022-06-10 01:06:54 | train] - Train Epoch: [82]	 Average Loss: 0.897719	 Total Acc : 78.0774	 Total Top5 Acc : 91.9005
[2022-06-10 01:06:54 | train] - -------82 epoch end-----------
========================================
-------82 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 01:08:24 | train] - 
Epoch [82] Test set: Average loss: 1.3471, Accuracy: 35064/50000 (70.1039%), Top-5 Accuracy: 88.9818%

[2022-06-10 01:08:24 | train] - save intermediate epoch [82] result


[2022-06-10 01:08:46 | train] - -------83 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 01:08:48 | train] - Train Epoch: [83] [0/1281167 (0%)]	Loss: 1.005084
[2022-06-10 01:09:08 | train] - Train Epoch: [83] [12800/1281167 (1%)]	Loss: 0.800077
[2022-06-10 01:09:29 | train] - Train Epoch: [83] [25600/1281167 (2%)]	Loss: 0.833786
[2022-06-10 01:09:49 | train] - Train Epoch: [83] [38400/1281167 (3%)]	Loss: 0.554211
[2022-06-10 01:10:08 | train] - Train Epoch: [83] [51200/1281167 (4%)]	Loss: 0.866111
[2022-06-10 01:10:28 | train] - Train Epoch: [83] [64000/1281167 (5%)]	Loss: 0.988429
[2022-06-10 01:10:48 | train] - Train Epoch: [83] [76800/1281167 (6%)]	Loss: 0.866631
[2022-06-10 01:11:08 | train] - Train Epoch: [83] [89600/1281167 (7%)]	Loss: 0.919297
[2022-06-10 01:11:28 | train] - Train Epoch: [83] [102400/1281167 (8%)]	Loss: 0.804050
[2022-06-10 01:11:47 | train] - Train Epoch: [83] [115200/1281167 (9%)]	Loss: 0.698740
[2022-06-10 01:12:07 | train] - Train Epoch: [83] [128000/1281167 (10%)]	Loss: 0.910258
[2022-06-10 01:12:26 | train] - Train Epoch: [83] [140800/1281167 (11%)]	Loss: 1.005791
[2022-06-10 01:12:46 | train] - Train Epoch: [83] [153600/1281167 (12%)]	Loss: 0.886783
[2022-06-10 01:13:05 | train] - Train Epoch: [83] [166400/1281167 (13%)]	Loss: 0.916929
[2022-06-10 01:13:25 | train] - Train Epoch: [83] [179200/1281167 (14%)]	Loss: 0.879228
[2022-06-10 01:13:45 | train] - Train Epoch: [83] [192000/1281167 (15%)]	Loss: 0.625862
[2022-06-10 01:14:04 | train] - Train Epoch: [83] [204800/1281167 (16%)]	Loss: 0.915758
[2022-06-10 01:14:24 | train] - Train Epoch: [83] [217600/1281167 (17%)]	Loss: 0.898708
[2022-06-10 01:14:44 | train] - Train Epoch: [83] [230400/1281167 (18%)]	Loss: 0.996084
[2022-06-10 01:15:04 | train] - Train Epoch: [83] [243200/1281167 (19%)]	Loss: 0.750498
[2022-06-10 01:15:24 | train] - Train Epoch: [83] [256000/1281167 (20%)]	Loss: 0.963110
[2022-06-10 01:15:43 | train] - Train Epoch: [83] [268800/1281167 (21%)]	Loss: 0.875808
[2022-06-10 01:16:04 | train] - Train Epoch: [83] [281600/1281167 (22%)]	Loss: 0.826516
[2022-06-10 01:16:23 | train] - Train Epoch: [83] [294400/1281167 (23%)]	Loss: 0.924663
[2022-06-10 01:16:43 | train] - Train Epoch: [83] [307200/1281167 (24%)]	Loss: 0.995199
[2022-06-10 01:17:02 | train] - Train Epoch: [83] [320000/1281167 (25%)]	Loss: 0.938557
[2022-06-10 01:17:22 | train] - Train Epoch: [83] [332800/1281167 (26%)]	Loss: 0.909341
[2022-06-10 01:17:42 | train] - Train Epoch: [83] [345600/1281167 (27%)]	Loss: 0.800230
[2022-06-10 01:18:02 | train] - Train Epoch: [83] [358400/1281167 (28%)]	Loss: 0.847732
[2022-06-10 01:18:21 | train] - Train Epoch: [83] [371200/1281167 (29%)]	Loss: 0.783029
[2022-06-10 01:18:41 | train] - Train Epoch: [83] [384000/1281167 (30%)]	Loss: 0.655580
[2022-06-10 01:19:01 | train] - Train Epoch: [83] [396800/1281167 (31%)]	Loss: 0.824978
[2022-06-10 01:19:20 | train] - Train Epoch: [83] [409600/1281167 (32%)]	Loss: 0.934515
[2022-06-10 01:19:40 | train] - Train Epoch: [83] [422400/1281167 (33%)]	Loss: 1.129323
[2022-06-10 01:19:59 | train] - Train Epoch: [83] [435200/1281167 (34%)]	Loss: 0.892358
[2022-06-10 01:20:20 | train] - Train Epoch: [83] [448000/1281167 (35%)]	Loss: 0.614952
[2022-06-10 01:20:40 | train] - Train Epoch: [83] [460800/1281167 (36%)]	Loss: 0.934088
[2022-06-10 01:21:00 | train] - Train Epoch: [83] [473600/1281167 (37%)]	Loss: 0.966223
[2022-06-10 01:21:19 | train] - Train Epoch: [83] [486400/1281167 (38%)]	Loss: 0.853177
[2022-06-10 01:21:39 | train] - Train Epoch: [83] [499200/1281167 (39%)]	Loss: 0.831559
[2022-06-10 01:21:59 | train] - Train Epoch: [83] [512000/1281167 (40%)]	Loss: 0.706286
[2022-06-10 01:22:19 | train] - Train Epoch: [83] [524800/1281167 (41%)]	Loss: 1.091516
[2022-06-10 01:22:38 | train] - Train Epoch: [83] [537600/1281167 (42%)]	Loss: 0.699386
[2022-06-10 01:22:58 | train] - Train Epoch: [83] [550400/1281167 (43%)]	Loss: 0.648027
[2022-06-10 01:23:17 | train] - Train Epoch: [83] [563200/1281167 (44%)]	Loss: 0.944949
[2022-06-10 01:23:36 | train] - Train Epoch: [83] [576000/1281167 (45%)]	Loss: 0.653573
[2022-06-10 01:23:56 | train] - Train Epoch: [83] [588800/1281167 (46%)]	Loss: 0.828912
[2022-06-10 01:24:16 | train] - Train Epoch: [83] [601600/1281167 (47%)]	Loss: 0.742278
[2022-06-10 01:24:35 | train] - Train Epoch: [83] [614400/1281167 (48%)]	Loss: 0.803541
[2022-06-10 01:24:54 | train] - Train Epoch: [83] [627200/1281167 (49%)]	Loss: 0.876535
[2022-06-10 01:25:14 | train] - Train Epoch: [83] [640000/1281167 (50%)]	Loss: 0.953087
[2022-06-10 01:25:34 | train] - Train Epoch: [83] [652800/1281167 (51%)]	Loss: 1.116516
[2022-06-10 01:25:53 | train] - Train Epoch: [83] [665600/1281167 (52%)]	Loss: 0.995230
[2022-06-10 01:26:13 | train] - Train Epoch: [83] [678400/1281167 (53%)]	Loss: 1.072574
[2022-06-10 01:26:33 | train] - Train Epoch: [83] [691200/1281167 (54%)]	Loss: 0.737472
[2022-06-10 01:26:53 | train] - Train Epoch: [83] [704000/1281167 (55%)]	Loss: 0.731775
[2022-06-10 01:27:13 | train] - Train Epoch: [83] [716800/1281167 (56%)]	Loss: 0.947359
[2022-06-10 01:27:33 | train] - Train Epoch: [83] [729600/1281167 (57%)]	Loss: 0.981505
[2022-06-10 01:27:52 | train] - Train Epoch: [83] [742400/1281167 (58%)]	Loss: 0.925404
[2022-06-10 01:28:12 | train] - Train Epoch: [83] [755200/1281167 (59%)]	Loss: 0.789728
[2022-06-10 01:28:31 | train] - Train Epoch: [83] [768000/1281167 (60%)]	Loss: 1.108110
[2022-06-10 01:28:51 | train] - Train Epoch: [83] [780800/1281167 (61%)]	Loss: 0.872898
[2022-06-10 01:29:10 | train] - Train Epoch: [83] [793600/1281167 (62%)]	Loss: 1.119276
[2022-06-10 01:29:30 | train] - Train Epoch: [83] [806400/1281167 (63%)]	Loss: 1.017525
[2022-06-10 01:29:51 | train] - Train Epoch: [83] [819200/1281167 (64%)]	Loss: 1.025546
[2022-06-10 01:30:10 | train] - Train Epoch: [83] [832000/1281167 (65%)]	Loss: 1.054410
[2022-06-10 01:30:30 | train] - Train Epoch: [83] [844800/1281167 (66%)]	Loss: 0.854664
[2022-06-10 01:30:50 | train] - Train Epoch: [83] [857600/1281167 (67%)]	Loss: 0.829473
[2022-06-10 01:31:10 | train] - Train Epoch: [83] [870400/1281167 (68%)]	Loss: 0.791691
[2022-06-10 01:31:30 | train] - Train Epoch: [83] [883200/1281167 (69%)]	Loss: 0.714376
[2022-06-10 01:31:50 | train] - Train Epoch: [83] [896000/1281167 (70%)]	Loss: 0.652636
[2022-06-10 01:32:09 | train] - Train Epoch: [83] [908800/1281167 (71%)]	Loss: 0.972384
[2022-06-10 01:32:29 | train] - Train Epoch: [83] [921600/1281167 (72%)]	Loss: 1.250160
[2022-06-10 01:32:49 | train] - Train Epoch: [83] [934400/1281167 (73%)]	Loss: 0.853287
[2022-06-10 01:33:08 | train] - Train Epoch: [83] [947200/1281167 (74%)]	Loss: 0.798165
[2022-06-10 01:33:28 | train] - Train Epoch: [83] [960000/1281167 (75%)]	Loss: 0.945969
[2022-06-10 01:33:47 | train] - Train Epoch: [83] [972800/1281167 (76%)]	Loss: 0.792932
[2022-06-10 01:34:06 | train] - Train Epoch: [83] [985600/1281167 (77%)]	Loss: 0.900952
[2022-06-10 01:34:26 | train] - Train Epoch: [83] [998400/1281167 (78%)]	Loss: 1.063505
[2022-06-10 01:34:46 | train] - Train Epoch: [83] [1011200/1281167 (79%)]	Loss: 0.898178
[2022-06-10 01:35:06 | train] - Train Epoch: [83] [1024000/1281167 (80%)]	Loss: 0.700846
[2022-06-10 01:35:25 | train] - Train Epoch: [83] [1036800/1281167 (81%)]	Loss: 1.053268
[2022-06-10 01:35:45 | train] - Train Epoch: [83] [1049600/1281167 (82%)]	Loss: 0.563669
[2022-06-10 01:36:05 | train] - Train Epoch: [83] [1062400/1281167 (83%)]	Loss: 1.010583
[2022-06-10 01:36:25 | train] - Train Epoch: [83] [1075200/1281167 (84%)]	Loss: 0.794659
[2022-06-10 01:36:44 | train] - Train Epoch: [83] [1088000/1281167 (85%)]	Loss: 0.777067
[2022-06-10 01:37:04 | train] - Train Epoch: [83] [1100800/1281167 (86%)]	Loss: 1.066301
[2022-06-10 01:37:24 | train] - Train Epoch: [83] [1113600/1281167 (87%)]	Loss: 0.798506
[2022-06-10 01:37:43 | train] - Train Epoch: [83] [1126400/1281167 (88%)]	Loss: 1.196514
[2022-06-10 01:38:03 | train] - Train Epoch: [83] [1139200/1281167 (89%)]	Loss: 0.845871
[2022-06-10 01:38:22 | train] - Train Epoch: [83] [1152000/1281167 (90%)]	Loss: 0.503034
[2022-06-10 01:38:41 | train] - Train Epoch: [83] [1164800/1281167 (91%)]	Loss: 0.808525
[2022-06-10 01:39:02 | train] - Train Epoch: [83] [1177600/1281167 (92%)]	Loss: 0.814798
[2022-06-10 01:39:22 | train] - Train Epoch: [83] [1190400/1281167 (93%)]	Loss: 1.137965
[2022-06-10 01:39:41 | train] - Train Epoch: [83] [1203200/1281167 (94%)]	Loss: 0.994303
[2022-06-10 01:40:01 | train] - Train Epoch: [83] [1216000/1281167 (95%)]	Loss: 0.901320
[2022-06-10 01:40:21 | train] - Train Epoch: [83] [1228800/1281167 (96%)]	Loss: 0.947445
[2022-06-10 01:40:41 | train] - Train Epoch: [83] [1241600/1281167 (97%)]	Loss: 1.053888
[2022-06-10 01:41:01 | train] - Train Epoch: [83] [1254400/1281167 (98%)]	Loss: 1.068674
[2022-06-10 01:41:21 | train] - Train Epoch: [83] [1267200/1281167 (99%)]	Loss: 0.888940
[2022-06-10 01:41:40 | train] - Train Epoch: [83] [1280000/1281167 (100%)]	Loss: 0.868307
[2022-06-10 01:41:42 | train] - Train Epoch: [83]	 Average Loss: 0.895781	 Total Acc : 78.1277	 Total Top5 Acc : 91.9289
[2022-06-10 01:41:42 | train] - -------83 epoch end-----------
========================================
-------83 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 01:43:13 | train] - 
Epoch [83] Test set: Average loss: 1.3441, Accuracy: 35047/50000 (70.0687%), Top-5 Accuracy: 89.0441%

[2022-06-10 01:43:13 | train] - save intermediate epoch [83] result


[2022-06-10 01:43:38 | train] - -------84 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 01:43:40 | train] - Train Epoch: [84] [0/1281167 (0%)]	Loss: 0.932151
[2022-06-10 01:43:59 | train] - Train Epoch: [84] [12800/1281167 (1%)]	Loss: 0.996826
[2022-06-10 01:44:20 | train] - Train Epoch: [84] [25600/1281167 (2%)]	Loss: 0.695797
[2022-06-10 01:44:41 | train] - Train Epoch: [84] [38400/1281167 (3%)]	Loss: 0.653887
[2022-06-10 01:45:03 | train] - Train Epoch: [84] [51200/1281167 (4%)]	Loss: 1.121472
[2022-06-10 01:45:24 | train] - Train Epoch: [84] [64000/1281167 (5%)]	Loss: 0.890233
[2022-06-10 01:45:44 | train] - Train Epoch: [84] [76800/1281167 (6%)]	Loss: 0.809558
[2022-06-10 01:46:03 | train] - Train Epoch: [84] [89600/1281167 (7%)]	Loss: 0.796222
[2022-06-10 01:46:22 | train] - Train Epoch: [84] [102400/1281167 (8%)]	Loss: 0.635289
[2022-06-10 01:46:42 | train] - Train Epoch: [84] [115200/1281167 (9%)]	Loss: 1.018989
[2022-06-10 01:47:02 | train] - Train Epoch: [84] [128000/1281167 (10%)]	Loss: 0.930140
[2022-06-10 01:47:22 | train] - Train Epoch: [84] [140800/1281167 (11%)]	Loss: 1.137862
[2022-06-10 01:47:42 | train] - Train Epoch: [84] [153600/1281167 (12%)]	Loss: 1.036196
[2022-06-10 01:48:02 | train] - Train Epoch: [84] [166400/1281167 (13%)]	Loss: 0.787102
[2022-06-10 01:48:22 | train] - Train Epoch: [84] [179200/1281167 (14%)]	Loss: 0.735943
[2022-06-10 01:48:42 | train] - Train Epoch: [84] [192000/1281167 (15%)]	Loss: 1.024632
[2022-06-10 01:49:02 | train] - Train Epoch: [84] [204800/1281167 (16%)]	Loss: 0.786560
[2022-06-10 01:49:22 | train] - Train Epoch: [84] [217600/1281167 (17%)]	Loss: 1.035993
[2022-06-10 01:49:42 | train] - Train Epoch: [84] [230400/1281167 (18%)]	Loss: 1.067582
[2022-06-10 01:50:02 | train] - Train Epoch: [84] [243200/1281167 (19%)]	Loss: 1.011046
[2022-06-10 01:50:23 | train] - Train Epoch: [84] [256000/1281167 (20%)]	Loss: 1.167763
[2022-06-10 01:50:42 | train] - Train Epoch: [84] [268800/1281167 (21%)]	Loss: 0.916419
[2022-06-10 01:51:02 | train] - Train Epoch: [84] [281600/1281167 (22%)]	Loss: 0.760608
[2022-06-10 01:51:22 | train] - Train Epoch: [84] [294400/1281167 (23%)]	Loss: 0.811680
[2022-06-10 01:51:42 | train] - Train Epoch: [84] [307200/1281167 (24%)]	Loss: 1.040681
[2022-06-10 01:52:02 | train] - Train Epoch: [84] [320000/1281167 (25%)]	Loss: 0.789158
[2022-06-10 01:52:22 | train] - Train Epoch: [84] [332800/1281167 (26%)]	Loss: 1.013949
[2022-06-10 01:52:41 | train] - Train Epoch: [84] [345600/1281167 (27%)]	Loss: 0.936162
[2022-06-10 01:53:01 | train] - Train Epoch: [84] [358400/1281167 (28%)]	Loss: 1.152719
[2022-06-10 01:53:20 | train] - Train Epoch: [84] [371200/1281167 (29%)]	Loss: 0.915042
[2022-06-10 01:53:40 | train] - Train Epoch: [84] [384000/1281167 (30%)]	Loss: 0.924068
[2022-06-10 01:54:00 | train] - Train Epoch: [84] [396800/1281167 (31%)]	Loss: 1.092366
[2022-06-10 01:54:20 | train] - Train Epoch: [84] [409600/1281167 (32%)]	Loss: 1.037431
[2022-06-10 01:54:39 | train] - Train Epoch: [84] [422400/1281167 (33%)]	Loss: 0.888943
[2022-06-10 01:54:59 | train] - Train Epoch: [84] [435200/1281167 (34%)]	Loss: 0.544107
[2022-06-10 01:55:19 | train] - Train Epoch: [84] [448000/1281167 (35%)]	Loss: 0.891755
[2022-06-10 01:55:38 | train] - Train Epoch: [84] [460800/1281167 (36%)]	Loss: 0.742400
[2022-06-10 01:55:58 | train] - Train Epoch: [84] [473600/1281167 (37%)]	Loss: 0.744620
[2022-06-10 01:56:17 | train] - Train Epoch: [84] [486400/1281167 (38%)]	Loss: 1.072877
[2022-06-10 01:56:38 | train] - Train Epoch: [84] [499200/1281167 (39%)]	Loss: 0.709786
[2022-06-10 01:56:58 | train] - Train Epoch: [84] [512000/1281167 (40%)]	Loss: 0.997876
[2022-06-10 01:57:18 | train] - Train Epoch: [84] [524800/1281167 (41%)]	Loss: 1.057551
[2022-06-10 01:57:37 | train] - Train Epoch: [84] [537600/1281167 (42%)]	Loss: 0.887846
[2022-06-10 01:57:57 | train] - Train Epoch: [84] [550400/1281167 (43%)]	Loss: 1.184321
[2022-06-10 01:58:16 | train] - Train Epoch: [84] [563200/1281167 (44%)]	Loss: 0.943417
[2022-06-10 01:58:36 | train] - Train Epoch: [84] [576000/1281167 (45%)]	Loss: 0.735208
[2022-06-10 01:58:56 | train] - Train Epoch: [84] [588800/1281167 (46%)]	Loss: 0.590348
[2022-06-10 01:59:16 | train] - Train Epoch: [84] [601600/1281167 (47%)]	Loss: 1.112784
[2022-06-10 01:59:35 | train] - Train Epoch: [84] [614400/1281167 (48%)]	Loss: 0.949498
[2022-06-10 01:59:55 | train] - Train Epoch: [84] [627200/1281167 (49%)]	Loss: 1.044690
[2022-06-10 02:00:14 | train] - Train Epoch: [84] [640000/1281167 (50%)]	Loss: 1.012572
[2022-06-10 02:00:34 | train] - Train Epoch: [84] [652800/1281167 (51%)]	Loss: 0.834973
[2022-06-10 02:00:54 | train] - Train Epoch: [84] [665600/1281167 (52%)]	Loss: 0.775271
[2022-06-10 02:01:14 | train] - Train Epoch: [84] [678400/1281167 (53%)]	Loss: 1.217746
[2022-06-10 02:01:34 | train] - Train Epoch: [84] [691200/1281167 (54%)]	Loss: 0.642177
[2022-06-10 02:01:54 | train] - Train Epoch: [84] [704000/1281167 (55%)]	Loss: 0.756294
[2022-06-10 02:02:13 | train] - Train Epoch: [84] [716800/1281167 (56%)]	Loss: 0.879651
[2022-06-10 02:02:32 | train] - Train Epoch: [84] [729600/1281167 (57%)]	Loss: 1.143269
[2022-06-10 02:02:53 | train] - Train Epoch: [84] [742400/1281167 (58%)]	Loss: 0.846554
[2022-06-10 02:03:12 | train] - Train Epoch: [84] [755200/1281167 (59%)]	Loss: 0.768636
[2022-06-10 02:03:33 | train] - Train Epoch: [84] [768000/1281167 (60%)]	Loss: 0.990250
[2022-06-10 02:03:52 | train] - Train Epoch: [84] [780800/1281167 (61%)]	Loss: 0.689374
[2022-06-10 02:04:12 | train] - Train Epoch: [84] [793600/1281167 (62%)]	Loss: 0.756969
[2022-06-10 02:04:31 | train] - Train Epoch: [84] [806400/1281167 (63%)]	Loss: 0.984405
[2022-06-10 02:04:51 | train] - Train Epoch: [84] [819200/1281167 (64%)]	Loss: 0.928270
[2022-06-10 02:05:10 | train] - Train Epoch: [84] [832000/1281167 (65%)]	Loss: 0.870098
[2022-06-10 02:05:30 | train] - Train Epoch: [84] [844800/1281167 (66%)]	Loss: 0.890615
[2022-06-10 02:05:50 | train] - Train Epoch: [84] [857600/1281167 (67%)]	Loss: 0.999751
[2022-06-10 02:06:10 | train] - Train Epoch: [84] [870400/1281167 (68%)]	Loss: 0.705090
[2022-06-10 02:06:30 | train] - Train Epoch: [84] [883200/1281167 (69%)]	Loss: 0.832523
[2022-06-10 02:06:50 | train] - Train Epoch: [84] [896000/1281167 (70%)]	Loss: 0.726691
[2022-06-10 02:07:10 | train] - Train Epoch: [84] [908800/1281167 (71%)]	Loss: 0.878113
[2022-06-10 02:07:30 | train] - Train Epoch: [84] [921600/1281167 (72%)]	Loss: 0.964840
[2022-06-10 02:07:49 | train] - Train Epoch: [84] [934400/1281167 (73%)]	Loss: 0.837328
[2022-06-10 02:08:09 | train] - Train Epoch: [84] [947200/1281167 (74%)]	Loss: 0.945669
[2022-06-10 02:08:29 | train] - Train Epoch: [84] [960000/1281167 (75%)]	Loss: 0.769077
[2022-06-10 02:08:49 | train] - Train Epoch: [84] [972800/1281167 (76%)]	Loss: 0.775363
[2022-06-10 02:09:09 | train] - Train Epoch: [84] [985600/1281167 (77%)]	Loss: 1.025844
[2022-06-10 02:09:29 | train] - Train Epoch: [84] [998400/1281167 (78%)]	Loss: 0.885545
[2022-06-10 02:09:48 | train] - Train Epoch: [84] [1011200/1281167 (79%)]	Loss: 1.194936
[2022-06-10 02:10:08 | train] - Train Epoch: [84] [1024000/1281167 (80%)]	Loss: 1.022543
[2022-06-10 02:10:28 | train] - Train Epoch: [84] [1036800/1281167 (81%)]	Loss: 1.156995
[2022-06-10 02:10:48 | train] - Train Epoch: [84] [1049600/1281167 (82%)]	Loss: 1.093886
[2022-06-10 02:11:07 | train] - Train Epoch: [84] [1062400/1281167 (83%)]	Loss: 1.010997
[2022-06-10 02:11:27 | train] - Train Epoch: [84] [1075200/1281167 (84%)]	Loss: 0.949927
[2022-06-10 02:11:47 | train] - Train Epoch: [84] [1088000/1281167 (85%)]	Loss: 0.896865
[2022-06-10 02:12:07 | train] - Train Epoch: [84] [1100800/1281167 (86%)]	Loss: 0.922930
[2022-06-10 02:12:27 | train] - Train Epoch: [84] [1113600/1281167 (87%)]	Loss: 0.995418
[2022-06-10 02:12:46 | train] - Train Epoch: [84] [1126400/1281167 (88%)]	Loss: 1.001120
[2022-06-10 02:13:06 | train] - Train Epoch: [84] [1139200/1281167 (89%)]	Loss: 0.875948
[2022-06-10 02:13:25 | train] - Train Epoch: [84] [1152000/1281167 (90%)]	Loss: 0.960415
[2022-06-10 02:13:45 | train] - Train Epoch: [84] [1164800/1281167 (91%)]	Loss: 0.802274
[2022-06-10 02:14:05 | train] - Train Epoch: [84] [1177600/1281167 (92%)]	Loss: 1.065184
[2022-06-10 02:14:25 | train] - Train Epoch: [84] [1190400/1281167 (93%)]	Loss: 0.769912
[2022-06-10 02:14:45 | train] - Train Epoch: [84] [1203200/1281167 (94%)]	Loss: 1.088539
[2022-06-10 02:15:05 | train] - Train Epoch: [84] [1216000/1281167 (95%)]	Loss: 1.080076
[2022-06-10 02:15:25 | train] - Train Epoch: [84] [1228800/1281167 (96%)]	Loss: 0.850609
[2022-06-10 02:15:45 | train] - Train Epoch: [84] [1241600/1281167 (97%)]	Loss: 0.975636
[2022-06-10 02:16:04 | train] - Train Epoch: [84] [1254400/1281167 (98%)]	Loss: 0.894541
[2022-06-10 02:16:24 | train] - Train Epoch: [84] [1267200/1281167 (99%)]	Loss: 0.488749
[2022-06-10 02:16:44 | train] - Train Epoch: [84] [1280000/1281167 (100%)]	Loss: 0.799543
[2022-06-10 02:16:46 | train] - Train Epoch: [84]	 Average Loss: 0.894723	 Total Acc : 78.1546	 Total Top5 Acc : 91.8969
[2022-06-10 02:16:46 | train] - -------84 epoch end-----------
========================================
-------84 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 02:18:16 | train] - 
Epoch [84] Test set: Average loss: 1.3536, Accuracy: 35040/50000 (70.0559%), Top-5 Accuracy: 88.9826%

[2022-06-10 02:18:16 | train] - save intermediate epoch [84] result


[2022-06-10 02:18:41 | train] - -------85 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 02:18:43 | train] - Train Epoch: [85] [0/1281167 (0%)]	Loss: 0.925031
[2022-06-10 02:19:03 | train] - Train Epoch: [85] [12800/1281167 (1%)]	Loss: 0.710013
[2022-06-10 02:19:23 | train] - Train Epoch: [85] [25600/1281167 (2%)]	Loss: 0.859585
[2022-06-10 02:19:43 | train] - Train Epoch: [85] [38400/1281167 (3%)]	Loss: 0.649990
[2022-06-10 02:20:03 | train] - Train Epoch: [85] [51200/1281167 (4%)]	Loss: 0.663226
[2022-06-10 02:20:23 | train] - Train Epoch: [85] [64000/1281167 (5%)]	Loss: 1.055140
[2022-06-10 02:20:43 | train] - Train Epoch: [85] [76800/1281167 (6%)]	Loss: 0.986396
[2022-06-10 02:21:02 | train] - Train Epoch: [85] [89600/1281167 (7%)]	Loss: 0.935506
[2022-06-10 02:21:22 | train] - Train Epoch: [85] [102400/1281167 (8%)]	Loss: 0.938406
[2022-06-10 02:21:41 | train] - Train Epoch: [85] [115200/1281167 (9%)]	Loss: 1.242971
[2022-06-10 02:22:01 | train] - Train Epoch: [85] [128000/1281167 (10%)]	Loss: 0.719646
[2022-06-10 02:22:21 | train] - Train Epoch: [85] [140800/1281167 (11%)]	Loss: 1.098151
[2022-06-10 02:22:39 | train] - Train Epoch: [85] [153600/1281167 (12%)]	Loss: 0.902260
[2022-06-10 02:23:00 | train] - Train Epoch: [85] [166400/1281167 (13%)]	Loss: 0.905248
[2022-06-10 02:23:19 | train] - Train Epoch: [85] [179200/1281167 (14%)]	Loss: 0.877289
[2022-06-10 02:23:39 | train] - Train Epoch: [85] [192000/1281167 (15%)]	Loss: 0.925705
[2022-06-10 02:23:58 | train] - Train Epoch: [85] [204800/1281167 (16%)]	Loss: 0.717537
[2022-06-10 02:24:18 | train] - Train Epoch: [85] [217600/1281167 (17%)]	Loss: 0.844454
[2022-06-10 02:24:38 | train] - Train Epoch: [85] [230400/1281167 (18%)]	Loss: 0.693900
[2022-06-10 02:24:57 | train] - Train Epoch: [85] [243200/1281167 (19%)]	Loss: 0.757028
[2022-06-10 02:25:18 | train] - Train Epoch: [85] [256000/1281167 (20%)]	Loss: 0.913406
[2022-06-10 02:25:37 | train] - Train Epoch: [85] [268800/1281167 (21%)]	Loss: 0.707478
[2022-06-10 02:25:57 | train] - Train Epoch: [85] [281600/1281167 (22%)]	Loss: 0.829538
[2022-06-10 02:26:17 | train] - Train Epoch: [85] [294400/1281167 (23%)]	Loss: 0.751516
[2022-06-10 02:26:37 | train] - Train Epoch: [85] [307200/1281167 (24%)]	Loss: 0.819159
[2022-06-10 02:26:57 | train] - Train Epoch: [85] [320000/1281167 (25%)]	Loss: 0.883198
[2022-06-10 02:27:17 | train] - Train Epoch: [85] [332800/1281167 (26%)]	Loss: 0.776667
[2022-06-10 02:27:37 | train] - Train Epoch: [85] [345600/1281167 (27%)]	Loss: 1.145361
[2022-06-10 02:27:57 | train] - Train Epoch: [85] [358400/1281167 (28%)]	Loss: 1.079487
[2022-06-10 02:28:17 | train] - Train Epoch: [85] [371200/1281167 (29%)]	Loss: 0.978934
[2022-06-10 02:28:37 | train] - Train Epoch: [85] [384000/1281167 (30%)]	Loss: 0.955498
[2022-06-10 02:28:57 | train] - Train Epoch: [85] [396800/1281167 (31%)]	Loss: 0.872847
[2022-06-10 02:29:17 | train] - Train Epoch: [85] [409600/1281167 (32%)]	Loss: 0.772723
[2022-06-10 02:29:37 | train] - Train Epoch: [85] [422400/1281167 (33%)]	Loss: 0.671328
[2022-06-10 02:29:57 | train] - Train Epoch: [85] [435200/1281167 (34%)]	Loss: 1.259276
[2022-06-10 02:30:16 | train] - Train Epoch: [85] [448000/1281167 (35%)]	Loss: 0.955835
[2022-06-10 02:30:37 | train] - Train Epoch: [85] [460800/1281167 (36%)]	Loss: 0.822824
[2022-06-10 02:30:57 | train] - Train Epoch: [85] [473600/1281167 (37%)]	Loss: 0.814877
[2022-06-10 02:31:16 | train] - Train Epoch: [85] [486400/1281167 (38%)]	Loss: 0.887735
[2022-06-10 02:31:35 | train] - Train Epoch: [85] [499200/1281167 (39%)]	Loss: 0.975361
[2022-06-10 02:31:55 | train] - Train Epoch: [85] [512000/1281167 (40%)]	Loss: 0.821337
[2022-06-10 02:32:15 | train] - Train Epoch: [85] [524800/1281167 (41%)]	Loss: 1.099867
[2022-06-10 02:32:35 | train] - Train Epoch: [85] [537600/1281167 (42%)]	Loss: 1.079294
[2022-06-10 02:32:56 | train] - Train Epoch: [85] [550400/1281167 (43%)]	Loss: 0.900242
[2022-06-10 02:33:15 | train] - Train Epoch: [85] [563200/1281167 (44%)]	Loss: 0.748930
[2022-06-10 02:33:35 | train] - Train Epoch: [85] [576000/1281167 (45%)]	Loss: 0.610037
[2022-06-10 02:33:56 | train] - Train Epoch: [85] [588800/1281167 (46%)]	Loss: 0.672086
[2022-06-10 02:34:15 | train] - Train Epoch: [85] [601600/1281167 (47%)]	Loss: 0.809561
[2022-06-10 02:34:34 | train] - Train Epoch: [85] [614400/1281167 (48%)]	Loss: 0.887241
[2022-06-10 02:34:54 | train] - Train Epoch: [85] [627200/1281167 (49%)]	Loss: 0.901198
[2022-06-10 02:35:14 | train] - Train Epoch: [85] [640000/1281167 (50%)]	Loss: 0.851482
[2022-06-10 02:35:34 | train] - Train Epoch: [85] [652800/1281167 (51%)]	Loss: 0.962130
[2022-06-10 02:35:54 | train] - Train Epoch: [85] [665600/1281167 (52%)]	Loss: 1.200287
[2022-06-10 02:36:13 | train] - Train Epoch: [85] [678400/1281167 (53%)]	Loss: 0.901322
[2022-06-10 02:36:33 | train] - Train Epoch: [85] [691200/1281167 (54%)]	Loss: 0.926977
[2022-06-10 02:36:52 | train] - Train Epoch: [85] [704000/1281167 (55%)]	Loss: 0.936454
[2022-06-10 02:37:12 | train] - Train Epoch: [85] [716800/1281167 (56%)]	Loss: 0.800807
[2022-06-10 02:37:32 | train] - Train Epoch: [85] [729600/1281167 (57%)]	Loss: 1.016445
[2022-06-10 02:37:52 | train] - Train Epoch: [85] [742400/1281167 (58%)]	Loss: 1.060720
[2022-06-10 02:38:11 | train] - Train Epoch: [85] [755200/1281167 (59%)]	Loss: 0.791988
[2022-06-10 02:38:31 | train] - Train Epoch: [85] [768000/1281167 (60%)]	Loss: 0.792734
[2022-06-10 02:38:51 | train] - Train Epoch: [85] [780800/1281167 (61%)]	Loss: 1.281865
[2022-06-10 02:39:11 | train] - Train Epoch: [85] [793600/1281167 (62%)]	Loss: 1.222448
[2022-06-10 02:39:31 | train] - Train Epoch: [85] [806400/1281167 (63%)]	Loss: 0.759454
[2022-06-10 02:39:51 | train] - Train Epoch: [85] [819200/1281167 (64%)]	Loss: 1.125906
[2022-06-10 02:40:10 | train] - Train Epoch: [85] [832000/1281167 (65%)]	Loss: 0.925862
[2022-06-10 02:40:30 | train] - Train Epoch: [85] [844800/1281167 (66%)]	Loss: 0.867400
[2022-06-10 02:40:50 | train] - Train Epoch: [85] [857600/1281167 (67%)]	Loss: 0.671506
[2022-06-10 02:41:09 | train] - Train Epoch: [85] [870400/1281167 (68%)]	Loss: 0.799983
[2022-06-10 02:41:29 | train] - Train Epoch: [85] [883200/1281167 (69%)]	Loss: 0.817972
[2022-06-10 02:41:50 | train] - Train Epoch: [85] [896000/1281167 (70%)]	Loss: 1.020917
[2022-06-10 02:42:09 | train] - Train Epoch: [85] [908800/1281167 (71%)]	Loss: 1.052072
[2022-06-10 02:42:30 | train] - Train Epoch: [85] [921600/1281167 (72%)]	Loss: 0.880252
[2022-06-10 02:42:49 | train] - Train Epoch: [85] [934400/1281167 (73%)]	Loss: 0.882840
[2022-06-10 02:43:09 | train] - Train Epoch: [85] [947200/1281167 (74%)]	Loss: 0.751922
[2022-06-10 02:43:29 | train] - Train Epoch: [85] [960000/1281167 (75%)]	Loss: 1.024809
[2022-06-10 02:43:49 | train] - Train Epoch: [85] [972800/1281167 (76%)]	Loss: 1.065828
[2022-06-10 02:44:09 | train] - Train Epoch: [85] [985600/1281167 (77%)]	Loss: 1.149551
[2022-06-10 02:44:29 | train] - Train Epoch: [85] [998400/1281167 (78%)]	Loss: 0.953128
[2022-06-10 02:44:48 | train] - Train Epoch: [85] [1011200/1281167 (79%)]	Loss: 0.822254
[2022-06-10 02:45:09 | train] - Train Epoch: [85] [1024000/1281167 (80%)]	Loss: 0.777056
[2022-06-10 02:45:28 | train] - Train Epoch: [85] [1036800/1281167 (81%)]	Loss: 1.224363
[2022-06-10 02:45:48 | train] - Train Epoch: [85] [1049600/1281167 (82%)]	Loss: 1.058198
[2022-06-10 02:46:07 | train] - Train Epoch: [85] [1062400/1281167 (83%)]	Loss: 1.098736
[2022-06-10 02:46:27 | train] - Train Epoch: [85] [1075200/1281167 (84%)]	Loss: 0.885914
[2022-06-10 02:46:47 | train] - Train Epoch: [85] [1088000/1281167 (85%)]	Loss: 0.876606
[2022-06-10 02:47:07 | train] - Train Epoch: [85] [1100800/1281167 (86%)]	Loss: 0.986416
[2022-06-10 02:47:27 | train] - Train Epoch: [85] [1113600/1281167 (87%)]	Loss: 0.879570
[2022-06-10 02:47:46 | train] - Train Epoch: [85] [1126400/1281167 (88%)]	Loss: 0.920638
[2022-06-10 02:48:05 | train] - Train Epoch: [85] [1139200/1281167 (89%)]	Loss: 0.990059
[2022-06-10 02:48:26 | train] - Train Epoch: [85] [1152000/1281167 (90%)]	Loss: 0.927354
[2022-06-10 02:48:45 | train] - Train Epoch: [85] [1164800/1281167 (91%)]	Loss: 0.737453
[2022-06-10 02:49:05 | train] - Train Epoch: [85] [1177600/1281167 (92%)]	Loss: 0.779652
[2022-06-10 02:49:24 | train] - Train Epoch: [85] [1190400/1281167 (93%)]	Loss: 0.947381
[2022-06-10 02:49:44 | train] - Train Epoch: [85] [1203200/1281167 (94%)]	Loss: 0.768860
[2022-06-10 02:50:04 | train] - Train Epoch: [85] [1216000/1281167 (95%)]	Loss: 0.697524
[2022-06-10 02:50:24 | train] - Train Epoch: [85] [1228800/1281167 (96%)]	Loss: 0.887518
[2022-06-10 02:50:43 | train] - Train Epoch: [85] [1241600/1281167 (97%)]	Loss: 0.957154
[2022-06-10 02:51:03 | train] - Train Epoch: [85] [1254400/1281167 (98%)]	Loss: 0.837464
[2022-06-10 02:51:22 | train] - Train Epoch: [85] [1267200/1281167 (99%)]	Loss: 0.797823
[2022-06-10 02:51:43 | train] - Train Epoch: [85] [1280000/1281167 (100%)]	Loss: 0.613769
[2022-06-10 02:51:45 | train] - Train Epoch: [85]	 Average Loss: 0.891374	 Total Acc : 78.2429	 Total Top5 Acc : 91.9362
[2022-06-10 02:51:45 | train] - -------85 epoch end-----------
========================================
-------85 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 02:53:14 | train] - 
Epoch [85] Test set: Average loss: 1.3525, Accuracy: 35014/50000 (69.9968%), Top-5 Accuracy: 89.0329%

[2022-06-10 02:53:14 | train] - save intermediate epoch [85] result


[2022-06-10 02:53:37 | train] - -------86 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 02:53:39 | train] - Train Epoch: [86] [0/1281167 (0%)]	Loss: 0.766679
[2022-06-10 02:53:58 | train] - Train Epoch: [86] [12800/1281167 (1%)]	Loss: 0.670596
[2022-06-10 02:54:19 | train] - Train Epoch: [86] [25600/1281167 (2%)]	Loss: 0.968407
[2022-06-10 02:54:39 | train] - Train Epoch: [86] [38400/1281167 (3%)]	Loss: 1.026855
[2022-06-10 02:54:59 | train] - Train Epoch: [86] [51200/1281167 (4%)]	Loss: 1.077948
[2022-06-10 02:55:18 | train] - Train Epoch: [86] [64000/1281167 (5%)]	Loss: 0.857416
[2022-06-10 02:55:38 | train] - Train Epoch: [86] [76800/1281167 (6%)]	Loss: 0.976794
[2022-06-10 02:55:58 | train] - Train Epoch: [86] [89600/1281167 (7%)]	Loss: 0.675463
[2022-06-10 02:56:17 | train] - Train Epoch: [86] [102400/1281167 (8%)]	Loss: 0.515603
[2022-06-10 02:56:37 | train] - Train Epoch: [86] [115200/1281167 (9%)]	Loss: 0.969083
[2022-06-10 02:56:57 | train] - Train Epoch: [86] [128000/1281167 (10%)]	Loss: 0.752518
[2022-06-10 02:57:16 | train] - Train Epoch: [86] [140800/1281167 (11%)]	Loss: 0.725942
[2022-06-10 02:57:37 | train] - Train Epoch: [86] [153600/1281167 (12%)]	Loss: 0.687249
[2022-06-10 02:57:58 | train] - Train Epoch: [86] [166400/1281167 (13%)]	Loss: 0.975796
[2022-06-10 02:58:18 | train] - Train Epoch: [86] [179200/1281167 (14%)]	Loss: 0.878576
[2022-06-10 02:58:37 | train] - Train Epoch: [86] [192000/1281167 (15%)]	Loss: 0.745615
[2022-06-10 02:58:56 | train] - Train Epoch: [86] [204800/1281167 (16%)]	Loss: 0.942591
[2022-06-10 02:59:16 | train] - Train Epoch: [86] [217600/1281167 (17%)]	Loss: 1.171450
[2022-06-10 02:59:36 | train] - Train Epoch: [86] [230400/1281167 (18%)]	Loss: 0.823936
[2022-06-10 02:59:56 | train] - Train Epoch: [86] [243200/1281167 (19%)]	Loss: 0.780328
[2022-06-10 03:00:16 | train] - Train Epoch: [86] [256000/1281167 (20%)]	Loss: 1.069108
[2022-06-10 03:00:35 | train] - Train Epoch: [86] [268800/1281167 (21%)]	Loss: 1.071981
[2022-06-10 03:00:55 | train] - Train Epoch: [86] [281600/1281167 (22%)]	Loss: 0.851849
[2022-06-10 03:01:15 | train] - Train Epoch: [86] [294400/1281167 (23%)]	Loss: 0.555165
[2022-06-10 03:01:35 | train] - Train Epoch: [86] [307200/1281167 (24%)]	Loss: 0.962476
[2022-06-10 03:01:54 | train] - Train Epoch: [86] [320000/1281167 (25%)]	Loss: 1.108668
[2022-06-10 03:02:13 | train] - Train Epoch: [86] [332800/1281167 (26%)]	Loss: 0.919666
[2022-06-10 03:02:33 | train] - Train Epoch: [86] [345600/1281167 (27%)]	Loss: 0.760867
[2022-06-10 03:02:53 | train] - Train Epoch: [86] [358400/1281167 (28%)]	Loss: 0.771466
[2022-06-10 03:03:12 | train] - Train Epoch: [86] [371200/1281167 (29%)]	Loss: 0.851858
[2022-06-10 03:03:32 | train] - Train Epoch: [86] [384000/1281167 (30%)]	Loss: 0.902018
[2022-06-10 03:03:52 | train] - Train Epoch: [86] [396800/1281167 (31%)]	Loss: 0.643641
[2022-06-10 03:04:12 | train] - Train Epoch: [86] [409600/1281167 (32%)]	Loss: 0.925944
[2022-06-10 03:04:31 | train] - Train Epoch: [86] [422400/1281167 (33%)]	Loss: 1.030198
[2022-06-10 03:04:51 | train] - Train Epoch: [86] [435200/1281167 (34%)]	Loss: 1.006333
[2022-06-10 03:05:10 | train] - Train Epoch: [86] [448000/1281167 (35%)]	Loss: 0.732372
[2022-06-10 03:05:30 | train] - Train Epoch: [86] [460800/1281167 (36%)]	Loss: 0.873601
[2022-06-10 03:05:50 | train] - Train Epoch: [86] [473600/1281167 (37%)]	Loss: 0.795457
[2022-06-10 03:06:10 | train] - Train Epoch: [86] [486400/1281167 (38%)]	Loss: 0.919509
[2022-06-10 03:06:30 | train] - Train Epoch: [86] [499200/1281167 (39%)]	Loss: 0.927224
[2022-06-10 03:06:49 | train] - Train Epoch: [86] [512000/1281167 (40%)]	Loss: 1.016523
[2022-06-10 03:07:08 | train] - Train Epoch: [86] [524800/1281167 (41%)]	Loss: 1.043216
[2022-06-10 03:07:29 | train] - Train Epoch: [86] [537600/1281167 (42%)]	Loss: 1.002535
[2022-06-10 03:07:49 | train] - Train Epoch: [86] [550400/1281167 (43%)]	Loss: 0.823403
[2022-06-10 03:08:08 | train] - Train Epoch: [86] [563200/1281167 (44%)]	Loss: 0.997290
[2022-06-10 03:08:28 | train] - Train Epoch: [86] [576000/1281167 (45%)]	Loss: 1.020611
[2022-06-10 03:08:47 | train] - Train Epoch: [86] [588800/1281167 (46%)]	Loss: 0.775313
[2022-06-10 03:09:08 | train] - Train Epoch: [86] [601600/1281167 (47%)]	Loss: 0.895421
[2022-06-10 03:09:27 | train] - Train Epoch: [86] [614400/1281167 (48%)]	Loss: 1.314196
[2022-06-10 03:09:46 | train] - Train Epoch: [86] [627200/1281167 (49%)]	Loss: 0.759139
[2022-06-10 03:10:06 | train] - Train Epoch: [86] [640000/1281167 (50%)]	Loss: 0.937499
[2022-06-10 03:10:25 | train] - Train Epoch: [86] [652800/1281167 (51%)]	Loss: 0.690860
[2022-06-10 03:10:45 | train] - Train Epoch: [86] [665600/1281167 (52%)]	Loss: 1.030822
[2022-06-10 03:11:04 | train] - Train Epoch: [86] [678400/1281167 (53%)]	Loss: 0.877884
[2022-06-10 03:11:24 | train] - Train Epoch: [86] [691200/1281167 (54%)]	Loss: 0.837357
[2022-06-10 03:11:44 | train] - Train Epoch: [86] [704000/1281167 (55%)]	Loss: 0.772978
[2022-06-10 03:12:04 | train] - Train Epoch: [86] [716800/1281167 (56%)]	Loss: 1.018545
[2022-06-10 03:12:23 | train] - Train Epoch: [86] [729600/1281167 (57%)]	Loss: 0.667470
[2022-06-10 03:12:44 | train] - Train Epoch: [86] [742400/1281167 (58%)]	Loss: 0.845818
[2022-06-10 03:13:04 | train] - Train Epoch: [86] [755200/1281167 (59%)]	Loss: 0.877598
[2022-06-10 03:13:23 | train] - Train Epoch: [86] [768000/1281167 (60%)]	Loss: 0.957387
[2022-06-10 03:13:42 | train] - Train Epoch: [86] [780800/1281167 (61%)]	Loss: 0.873975
[2022-06-10 03:14:02 | train] - Train Epoch: [86] [793600/1281167 (62%)]	Loss: 1.413586
[2022-06-10 03:14:22 | train] - Train Epoch: [86] [806400/1281167 (63%)]	Loss: 1.143788
[2022-06-10 03:14:42 | train] - Train Epoch: [86] [819200/1281167 (64%)]	Loss: 0.917707
[2022-06-10 03:15:02 | train] - Train Epoch: [86] [832000/1281167 (65%)]	Loss: 1.005736
[2022-06-10 03:15:21 | train] - Train Epoch: [86] [844800/1281167 (66%)]	Loss: 0.850118
[2022-06-10 03:15:41 | train] - Train Epoch: [86] [857600/1281167 (67%)]	Loss: 0.827468
[2022-06-10 03:16:00 | train] - Train Epoch: [86] [870400/1281167 (68%)]	Loss: 0.898667
[2022-06-10 03:16:20 | train] - Train Epoch: [86] [883200/1281167 (69%)]	Loss: 0.910892
[2022-06-10 03:16:40 | train] - Train Epoch: [86] [896000/1281167 (70%)]	Loss: 1.062816
[2022-06-10 03:17:00 | train] - Train Epoch: [86] [908800/1281167 (71%)]	Loss: 0.866763
[2022-06-10 03:17:20 | train] - Train Epoch: [86] [921600/1281167 (72%)]	Loss: 0.794271
[2022-06-10 03:17:39 | train] - Train Epoch: [86] [934400/1281167 (73%)]	Loss: 0.887978
[2022-06-10 03:17:58 | train] - Train Epoch: [86] [947200/1281167 (74%)]	Loss: 0.894342
[2022-06-10 03:18:18 | train] - Train Epoch: [86] [960000/1281167 (75%)]	Loss: 1.032591
[2022-06-10 03:18:38 | train] - Train Epoch: [86] [972800/1281167 (76%)]	Loss: 0.919702
[2022-06-10 03:18:58 | train] - Train Epoch: [86] [985600/1281167 (77%)]	Loss: 0.843631
[2022-06-10 03:19:17 | train] - Train Epoch: [86] [998400/1281167 (78%)]	Loss: 1.022745
[2022-06-10 03:19:37 | train] - Train Epoch: [86] [1011200/1281167 (79%)]	Loss: 0.873174
[2022-06-10 03:19:56 | train] - Train Epoch: [86] [1024000/1281167 (80%)]	Loss: 1.009074
[2022-06-10 03:20:16 | train] - Train Epoch: [86] [1036800/1281167 (81%)]	Loss: 1.157067
[2022-06-10 03:20:36 | train] - Train Epoch: [86] [1049600/1281167 (82%)]	Loss: 0.788477
[2022-06-10 03:20:55 | train] - Train Epoch: [86] [1062400/1281167 (83%)]	Loss: 0.988439
[2022-06-10 03:21:16 | train] - Train Epoch: [86] [1075200/1281167 (84%)]	Loss: 0.820672
[2022-06-10 03:21:35 | train] - Train Epoch: [86] [1088000/1281167 (85%)]	Loss: 0.887850
[2022-06-10 03:21:55 | train] - Train Epoch: [86] [1100800/1281167 (86%)]	Loss: 0.891115
[2022-06-10 03:22:15 | train] - Train Epoch: [86] [1113600/1281167 (87%)]	Loss: 0.911176
[2022-06-10 03:22:35 | train] - Train Epoch: [86] [1126400/1281167 (88%)]	Loss: 0.821191
[2022-06-10 03:22:55 | train] - Train Epoch: [86] [1139200/1281167 (89%)]	Loss: 0.944512
[2022-06-10 03:23:15 | train] - Train Epoch: [86] [1152000/1281167 (90%)]	Loss: 0.863587
[2022-06-10 03:23:34 | train] - Train Epoch: [86] [1164800/1281167 (91%)]	Loss: 0.749032
[2022-06-10 03:23:54 | train] - Train Epoch: [86] [1177600/1281167 (92%)]	Loss: 0.765839
[2022-06-10 03:24:14 | train] - Train Epoch: [86] [1190400/1281167 (93%)]	Loss: 1.018248
[2022-06-10 03:24:34 | train] - Train Epoch: [86] [1203200/1281167 (94%)]	Loss: 0.992265
[2022-06-10 03:24:53 | train] - Train Epoch: [86] [1216000/1281167 (95%)]	Loss: 0.854829
[2022-06-10 03:25:12 | train] - Train Epoch: [86] [1228800/1281167 (96%)]	Loss: 0.917516
[2022-06-10 03:25:32 | train] - Train Epoch: [86] [1241600/1281167 (97%)]	Loss: 0.801126
[2022-06-10 03:25:52 | train] - Train Epoch: [86] [1254400/1281167 (98%)]	Loss: 1.153470
[2022-06-10 03:26:11 | train] - Train Epoch: [86] [1267200/1281167 (99%)]	Loss: 0.799441
[2022-06-10 03:26:31 | train] - Train Epoch: [86] [1280000/1281167 (100%)]	Loss: 1.003649
[2022-06-10 03:26:33 | train] - Train Epoch: [86]	 Average Loss: 0.889914	 Total Acc : 78.2797	 Total Top5 Acc : 91.9822
[2022-06-10 03:26:33 | train] - -------86 epoch end-----------
========================================
-------86 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 03:28:02 | train] - 
Epoch [86] Test set: Average loss: 1.3531, Accuracy: 34916/50000 (69.8010%), Top-5 Accuracy: 89.0717%

[2022-06-10 03:28:02 | train] - save intermediate epoch [86] result


[2022-06-10 03:28:25 | train] - -------87 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 03:28:27 | train] - Train Epoch: [87] [0/1281167 (0%)]	Loss: 0.822509
[2022-06-10 03:28:47 | train] - Train Epoch: [87] [12800/1281167 (1%)]	Loss: 1.065708
[2022-06-10 03:29:07 | train] - Train Epoch: [87] [25600/1281167 (2%)]	Loss: 0.849130
[2022-06-10 03:29:26 | train] - Train Epoch: [87] [38400/1281167 (3%)]	Loss: 0.858352
[2022-06-10 03:29:46 | train] - Train Epoch: [87] [51200/1281167 (4%)]	Loss: 1.086129
[2022-06-10 03:30:06 | train] - Train Epoch: [87] [64000/1281167 (5%)]	Loss: 0.899094
[2022-06-10 03:30:26 | train] - Train Epoch: [87] [76800/1281167 (6%)]	Loss: 1.085430
[2022-06-10 03:30:45 | train] - Train Epoch: [87] [89600/1281167 (7%)]	Loss: 1.003066
[2022-06-10 03:31:05 | train] - Train Epoch: [87] [102400/1281167 (8%)]	Loss: 0.973043
[2022-06-10 03:31:25 | train] - Train Epoch: [87] [115200/1281167 (9%)]	Loss: 1.148262
[2022-06-10 03:31:45 | train] - Train Epoch: [87] [128000/1281167 (10%)]	Loss: 1.055123
[2022-06-10 03:32:05 | train] - Train Epoch: [87] [140800/1281167 (11%)]	Loss: 0.745523
[2022-06-10 03:32:25 | train] - Train Epoch: [87] [153600/1281167 (12%)]	Loss: 0.641308
[2022-06-10 03:32:45 | train] - Train Epoch: [87] [166400/1281167 (13%)]	Loss: 0.778862
[2022-06-10 03:33:05 | train] - Train Epoch: [87] [179200/1281167 (14%)]	Loss: 0.953197
[2022-06-10 03:33:25 | train] - Train Epoch: [87] [192000/1281167 (15%)]	Loss: 0.671909
[2022-06-10 03:33:44 | train] - Train Epoch: [87] [204800/1281167 (16%)]	Loss: 0.887968
[2022-06-10 03:34:05 | train] - Train Epoch: [87] [217600/1281167 (17%)]	Loss: 0.905252
[2022-06-10 03:34:25 | train] - Train Epoch: [87] [230400/1281167 (18%)]	Loss: 0.863444
[2022-06-10 03:34:45 | train] - Train Epoch: [87] [243200/1281167 (19%)]	Loss: 0.846809
[2022-06-10 03:35:05 | train] - Train Epoch: [87] [256000/1281167 (20%)]	Loss: 0.737851
[2022-06-10 03:35:25 | train] - Train Epoch: [87] [268800/1281167 (21%)]	Loss: 0.677706
[2022-06-10 03:35:44 | train] - Train Epoch: [87] [281600/1281167 (22%)]	Loss: 1.132457
[2022-06-10 03:36:04 | train] - Train Epoch: [87] [294400/1281167 (23%)]	Loss: 1.211026
[2022-06-10 03:36:24 | train] - Train Epoch: [87] [307200/1281167 (24%)]	Loss: 0.797078
[2022-06-10 03:36:43 | train] - Train Epoch: [87] [320000/1281167 (25%)]	Loss: 0.727896
[2022-06-10 03:37:03 | train] - Train Epoch: [87] [332800/1281167 (26%)]	Loss: 1.137962
[2022-06-10 03:37:23 | train] - Train Epoch: [87] [345600/1281167 (27%)]	Loss: 0.672054
[2022-06-10 03:37:43 | train] - Train Epoch: [87] [358400/1281167 (28%)]	Loss: 1.167759
[2022-06-10 03:38:03 | train] - Train Epoch: [87] [371200/1281167 (29%)]	Loss: 0.966598
[2022-06-10 03:38:23 | train] - Train Epoch: [87] [384000/1281167 (30%)]	Loss: 0.833007
[2022-06-10 03:38:42 | train] - Train Epoch: [87] [396800/1281167 (31%)]	Loss: 0.787370
[2022-06-10 03:39:02 | train] - Train Epoch: [87] [409600/1281167 (32%)]	Loss: 1.024750
[2022-06-10 03:39:22 | train] - Train Epoch: [87] [422400/1281167 (33%)]	Loss: 0.942087
[2022-06-10 03:39:42 | train] - Train Epoch: [87] [435200/1281167 (34%)]	Loss: 0.615880
[2022-06-10 03:40:01 | train] - Train Epoch: [87] [448000/1281167 (35%)]	Loss: 0.981903
[2022-06-10 03:40:21 | train] - Train Epoch: [87] [460800/1281167 (36%)]	Loss: 0.683878
[2022-06-10 03:40:41 | train] - Train Epoch: [87] [473600/1281167 (37%)]	Loss: 0.549078
[2022-06-10 03:41:01 | train] - Train Epoch: [87] [486400/1281167 (38%)]	Loss: 0.669246
[2022-06-10 03:41:21 | train] - Train Epoch: [87] [499200/1281167 (39%)]	Loss: 1.007478
[2022-06-10 03:41:40 | train] - Train Epoch: [87] [512000/1281167 (40%)]	Loss: 0.891967
[2022-06-10 03:42:00 | train] - Train Epoch: [87] [524800/1281167 (41%)]	Loss: 0.817117
[2022-06-10 03:42:20 | train] - Train Epoch: [87] [537600/1281167 (42%)]	Loss: 1.114722
[2022-06-10 03:42:41 | train] - Train Epoch: [87] [550400/1281167 (43%)]	Loss: 1.297413
[2022-06-10 03:43:00 | train] - Train Epoch: [87] [563200/1281167 (44%)]	Loss: 0.956603
[2022-06-10 03:43:20 | train] - Train Epoch: [87] [576000/1281167 (45%)]	Loss: 0.999979
[2022-06-10 03:43:40 | train] - Train Epoch: [87] [588800/1281167 (46%)]	Loss: 1.047107
[2022-06-10 03:44:01 | train] - Train Epoch: [87] [601600/1281167 (47%)]	Loss: 0.741790
[2022-06-10 03:44:20 | train] - Train Epoch: [87] [614400/1281167 (48%)]	Loss: 1.135839
[2022-06-10 03:44:39 | train] - Train Epoch: [87] [627200/1281167 (49%)]	Loss: 0.722267
[2022-06-10 03:44:59 | train] - Train Epoch: [87] [640000/1281167 (50%)]	Loss: 0.854526
[2022-06-10 03:45:18 | train] - Train Epoch: [87] [652800/1281167 (51%)]	Loss: 0.946538
[2022-06-10 03:45:38 | train] - Train Epoch: [87] [665600/1281167 (52%)]	Loss: 0.926328
[2022-06-10 03:45:58 | train] - Train Epoch: [87] [678400/1281167 (53%)]	Loss: 0.845493
[2022-06-10 03:46:18 | train] - Train Epoch: [87] [691200/1281167 (54%)]	Loss: 0.997392
[2022-06-10 03:46:38 | train] - Train Epoch: [87] [704000/1281167 (55%)]	Loss: 0.615564
[2022-06-10 03:46:58 | train] - Train Epoch: [87] [716800/1281167 (56%)]	Loss: 0.916912
[2022-06-10 03:47:18 | train] - Train Epoch: [87] [729600/1281167 (57%)]	Loss: 1.085531
[2022-06-10 03:47:37 | train] - Train Epoch: [87] [742400/1281167 (58%)]	Loss: 0.943784
[2022-06-10 03:47:57 | train] - Train Epoch: [87] [755200/1281167 (59%)]	Loss: 0.730449
[2022-06-10 03:48:17 | train] - Train Epoch: [87] [768000/1281167 (60%)]	Loss: 1.031509
[2022-06-10 03:48:37 | train] - Train Epoch: [87] [780800/1281167 (61%)]	Loss: 0.985491
[2022-06-10 03:48:58 | train] - Train Epoch: [87] [793600/1281167 (62%)]	Loss: 0.910467
[2022-06-10 03:49:17 | train] - Train Epoch: [87] [806400/1281167 (63%)]	Loss: 0.926182
[2022-06-10 03:49:37 | train] - Train Epoch: [87] [819200/1281167 (64%)]	Loss: 0.928166
[2022-06-10 03:49:57 | train] - Train Epoch: [87] [832000/1281167 (65%)]	Loss: 0.942647
[2022-06-10 03:50:16 | train] - Train Epoch: [87] [844800/1281167 (66%)]	Loss: 0.901346
[2022-06-10 03:50:35 | train] - Train Epoch: [87] [857600/1281167 (67%)]	Loss: 0.752940
[2022-06-10 03:50:55 | train] - Train Epoch: [87] [870400/1281167 (68%)]	Loss: 1.004559
[2022-06-10 03:51:14 | train] - Train Epoch: [87] [883200/1281167 (69%)]	Loss: 0.580776
[2022-06-10 03:51:34 | train] - Train Epoch: [87] [896000/1281167 (70%)]	Loss: 0.720692
[2022-06-10 03:51:53 | train] - Train Epoch: [87] [908800/1281167 (71%)]	Loss: 0.997976
[2022-06-10 03:52:13 | train] - Train Epoch: [87] [921600/1281167 (72%)]	Loss: 0.989222
[2022-06-10 03:52:33 | train] - Train Epoch: [87] [934400/1281167 (73%)]	Loss: 0.808367
[2022-06-10 03:52:52 | train] - Train Epoch: [87] [947200/1281167 (74%)]	Loss: 1.165615
[2022-06-10 03:53:12 | train] - Train Epoch: [87] [960000/1281167 (75%)]	Loss: 1.109516
[2022-06-10 03:53:32 | train] - Train Epoch: [87] [972800/1281167 (76%)]	Loss: 0.751027
[2022-06-10 03:53:51 | train] - Train Epoch: [87] [985600/1281167 (77%)]	Loss: 0.971245
[2022-06-10 03:54:11 | train] - Train Epoch: [87] [998400/1281167 (78%)]	Loss: 0.979144
[2022-06-10 03:54:31 | train] - Train Epoch: [87] [1011200/1281167 (79%)]	Loss: 0.806311
[2022-06-10 03:54:51 | train] - Train Epoch: [87] [1024000/1281167 (80%)]	Loss: 0.780927
[2022-06-10 03:55:11 | train] - Train Epoch: [87] [1036800/1281167 (81%)]	Loss: 0.912068
[2022-06-10 03:55:30 | train] - Train Epoch: [87] [1049600/1281167 (82%)]	Loss: 0.944502
[2022-06-10 03:55:50 | train] - Train Epoch: [87] [1062400/1281167 (83%)]	Loss: 0.530358
[2022-06-10 03:56:10 | train] - Train Epoch: [87] [1075200/1281167 (84%)]	Loss: 0.800428
[2022-06-10 03:56:30 | train] - Train Epoch: [87] [1088000/1281167 (85%)]	Loss: 0.980230
[2022-06-10 03:56:50 | train] - Train Epoch: [87] [1100800/1281167 (86%)]	Loss: 1.089939
[2022-06-10 03:57:10 | train] - Train Epoch: [87] [1113600/1281167 (87%)]	Loss: 0.857724
[2022-06-10 03:57:29 | train] - Train Epoch: [87] [1126400/1281167 (88%)]	Loss: 0.748398
[2022-06-10 03:57:49 | train] - Train Epoch: [87] [1139200/1281167 (89%)]	Loss: 0.870078
[2022-06-10 03:58:09 | train] - Train Epoch: [87] [1152000/1281167 (90%)]	Loss: 0.754989
[2022-06-10 03:58:29 | train] - Train Epoch: [87] [1164800/1281167 (91%)]	Loss: 0.788375
[2022-06-10 03:58:48 | train] - Train Epoch: [87] [1177600/1281167 (92%)]	Loss: 0.958912
[2022-06-10 03:59:08 | train] - Train Epoch: [87] [1190400/1281167 (93%)]	Loss: 0.717327
[2022-06-10 03:59:28 | train] - Train Epoch: [87] [1203200/1281167 (94%)]	Loss: 0.666312
[2022-06-10 03:59:48 | train] - Train Epoch: [87] [1216000/1281167 (95%)]	Loss: 0.845427
[2022-06-10 04:00:08 | train] - Train Epoch: [87] [1228800/1281167 (96%)]	Loss: 1.084044
[2022-06-10 04:00:28 | train] - Train Epoch: [87] [1241600/1281167 (97%)]	Loss: 0.862082
[2022-06-10 04:00:48 | train] - Train Epoch: [87] [1254400/1281167 (98%)]	Loss: 0.898249
[2022-06-10 04:01:07 | train] - Train Epoch: [87] [1267200/1281167 (99%)]	Loss: 0.910267
[2022-06-10 04:01:28 | train] - Train Epoch: [87] [1280000/1281167 (100%)]	Loss: 1.302612
[2022-06-10 04:01:29 | train] - Train Epoch: [87]	 Average Loss: 0.885972	 Total Acc : 78.3877	 Total Top5 Acc : 91.9854
[2022-06-10 04:01:29 | train] - -------87 epoch end-----------
========================================
-------87 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 04:03:00 | train] - 
Epoch [87] Test set: Average loss: 1.3492, Accuracy: 35076/50000 (70.1243%), Top-5 Accuracy: 89.0109%

[2022-06-10 04:03:00 | train] - save intermediate epoch [87] result


[2022-06-10 04:03:24 | train] - -------88 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 04:03:25 | train] - Train Epoch: [88] [0/1281167 (0%)]	Loss: 0.651000
[2022-06-10 04:03:47 | train] - Train Epoch: [88] [12800/1281167 (1%)]	Loss: 0.903726
[2022-06-10 04:04:07 | train] - Train Epoch: [88] [25600/1281167 (2%)]	Loss: 0.652200
[2022-06-10 04:04:27 | train] - Train Epoch: [88] [38400/1281167 (3%)]	Loss: 0.853467
[2022-06-10 04:04:47 | train] - Train Epoch: [88] [51200/1281167 (4%)]	Loss: 0.673438
[2022-06-10 04:05:07 | train] - Train Epoch: [88] [64000/1281167 (5%)]	Loss: 0.938837
[2022-06-10 04:05:28 | train] - Train Epoch: [88] [76800/1281167 (6%)]	Loss: 0.742862
[2022-06-10 04:05:48 | train] - Train Epoch: [88] [89600/1281167 (7%)]	Loss: 0.729315
[2022-06-10 04:06:09 | train] - Train Epoch: [88] [102400/1281167 (8%)]	Loss: 0.800459
[2022-06-10 04:06:28 | train] - Train Epoch: [88] [115200/1281167 (9%)]	Loss: 0.836360
[2022-06-10 04:06:47 | train] - Train Epoch: [88] [128000/1281167 (10%)]	Loss: 0.840257
[2022-06-10 04:07:07 | train] - Train Epoch: [88] [140800/1281167 (11%)]	Loss: 0.964821
[2022-06-10 04:07:27 | train] - Train Epoch: [88] [153600/1281167 (12%)]	Loss: 0.997664
[2022-06-10 04:07:46 | train] - Train Epoch: [88] [166400/1281167 (13%)]	Loss: 0.938908
[2022-06-10 04:08:06 | train] - Train Epoch: [88] [179200/1281167 (14%)]	Loss: 1.085528
[2022-06-10 04:08:26 | train] - Train Epoch: [88] [192000/1281167 (15%)]	Loss: 0.823209
[2022-06-10 04:08:46 | train] - Train Epoch: [88] [204800/1281167 (16%)]	Loss: 0.962550
[2022-06-10 04:09:06 | train] - Train Epoch: [88] [217600/1281167 (17%)]	Loss: 0.890068
[2022-06-10 04:09:26 | train] - Train Epoch: [88] [230400/1281167 (18%)]	Loss: 1.084884
[2022-06-10 04:09:46 | train] - Train Epoch: [88] [243200/1281167 (19%)]	Loss: 0.857094
[2022-06-10 04:10:05 | train] - Train Epoch: [88] [256000/1281167 (20%)]	Loss: 0.868096
[2022-06-10 04:10:24 | train] - Train Epoch: [88] [268800/1281167 (21%)]	Loss: 0.982174
[2022-06-10 04:10:44 | train] - Train Epoch: [88] [281600/1281167 (22%)]	Loss: 0.735509
[2022-06-10 04:11:04 | train] - Train Epoch: [88] [294400/1281167 (23%)]	Loss: 0.889571
[2022-06-10 04:11:23 | train] - Train Epoch: [88] [307200/1281167 (24%)]	Loss: 0.790758
[2022-06-10 04:11:42 | train] - Train Epoch: [88] [320000/1281167 (25%)]	Loss: 0.897092
[2022-06-10 04:12:03 | train] - Train Epoch: [88] [332800/1281167 (26%)]	Loss: 0.717068
[2022-06-10 04:12:22 | train] - Train Epoch: [88] [345600/1281167 (27%)]	Loss: 0.996343
[2022-06-10 04:12:41 | train] - Train Epoch: [88] [358400/1281167 (28%)]	Loss: 0.962589
[2022-06-10 04:13:01 | train] - Train Epoch: [88] [371200/1281167 (29%)]	Loss: 0.958524
[2022-06-10 04:13:21 | train] - Train Epoch: [88] [384000/1281167 (30%)]	Loss: 0.835456
[2022-06-10 04:13:41 | train] - Train Epoch: [88] [396800/1281167 (31%)]	Loss: 0.726455
[2022-06-10 04:14:00 | train] - Train Epoch: [88] [409600/1281167 (32%)]	Loss: 1.144261
[2022-06-10 04:14:20 | train] - Train Epoch: [88] [422400/1281167 (33%)]	Loss: 1.064420
[2022-06-10 04:14:40 | train] - Train Epoch: [88] [435200/1281167 (34%)]	Loss: 1.155460
[2022-06-10 04:14:59 | train] - Train Epoch: [88] [448000/1281167 (35%)]	Loss: 0.842189
[2022-06-10 04:15:18 | train] - Train Epoch: [88] [460800/1281167 (36%)]	Loss: 0.682694
[2022-06-10 04:15:38 | train] - Train Epoch: [88] [473600/1281167 (37%)]	Loss: 1.095495
[2022-06-10 04:15:58 | train] - Train Epoch: [88] [486400/1281167 (38%)]	Loss: 0.865557
[2022-06-10 04:16:18 | train] - Train Epoch: [88] [499200/1281167 (39%)]	Loss: 0.901219
[2022-06-10 04:16:38 | train] - Train Epoch: [88] [512000/1281167 (40%)]	Loss: 1.233811
[2022-06-10 04:16:58 | train] - Train Epoch: [88] [524800/1281167 (41%)]	Loss: 0.871396
[2022-06-10 04:17:17 | train] - Train Epoch: [88] [537600/1281167 (42%)]	Loss: 1.052392
[2022-06-10 04:17:37 | train] - Train Epoch: [88] [550400/1281167 (43%)]	Loss: 0.885578
[2022-06-10 04:17:56 | train] - Train Epoch: [88] [563200/1281167 (44%)]	Loss: 0.875118
[2022-06-10 04:18:16 | train] - Train Epoch: [88] [576000/1281167 (45%)]	Loss: 0.638511
[2022-06-10 04:18:36 | train] - Train Epoch: [88] [588800/1281167 (46%)]	Loss: 1.061075
[2022-06-10 04:18:55 | train] - Train Epoch: [88] [601600/1281167 (47%)]	Loss: 1.119346
[2022-06-10 04:19:15 | train] - Train Epoch: [88] [614400/1281167 (48%)]	Loss: 0.999917
[2022-06-10 04:19:35 | train] - Train Epoch: [88] [627200/1281167 (49%)]	Loss: 1.148729
[2022-06-10 04:19:54 | train] - Train Epoch: [88] [640000/1281167 (50%)]	Loss: 0.983375
[2022-06-10 04:20:14 | train] - Train Epoch: [88] [652800/1281167 (51%)]	Loss: 0.983168
[2022-06-10 04:20:34 | train] - Train Epoch: [88] [665600/1281167 (52%)]	Loss: 0.741628
[2022-06-10 04:20:54 | train] - Train Epoch: [88] [678400/1281167 (53%)]	Loss: 0.884752
[2022-06-10 04:21:13 | train] - Train Epoch: [88] [691200/1281167 (54%)]	Loss: 0.964571
[2022-06-10 04:21:33 | train] - Train Epoch: [88] [704000/1281167 (55%)]	Loss: 1.098175
[2022-06-10 04:21:52 | train] - Train Epoch: [88] [716800/1281167 (56%)]	Loss: 0.941779
[2022-06-10 04:22:12 | train] - Train Epoch: [88] [729600/1281167 (57%)]	Loss: 0.815090
[2022-06-10 04:22:32 | train] - Train Epoch: [88] [742400/1281167 (58%)]	Loss: 0.888696
[2022-06-10 04:22:52 | train] - Train Epoch: [88] [755200/1281167 (59%)]	Loss: 0.691166
[2022-06-10 04:23:13 | train] - Train Epoch: [88] [768000/1281167 (60%)]	Loss: 1.003636
[2022-06-10 04:23:33 | train] - Train Epoch: [88] [780800/1281167 (61%)]	Loss: 0.838970
[2022-06-10 04:23:52 | train] - Train Epoch: [88] [793600/1281167 (62%)]	Loss: 0.930795
[2022-06-10 04:24:12 | train] - Train Epoch: [88] [806400/1281167 (63%)]	Loss: 0.914365
[2022-06-10 04:24:32 | train] - Train Epoch: [88] [819200/1281167 (64%)]	Loss: 1.022452
[2022-06-10 04:24:52 | train] - Train Epoch: [88] [832000/1281167 (65%)]	Loss: 0.747833
[2022-06-10 04:25:12 | train] - Train Epoch: [88] [844800/1281167 (66%)]	Loss: 0.996442
[2022-06-10 04:25:32 | train] - Train Epoch: [88] [857600/1281167 (67%)]	Loss: 0.895718
[2022-06-10 04:25:52 | train] - Train Epoch: [88] [870400/1281167 (68%)]	Loss: 0.820712
[2022-06-10 04:26:11 | train] - Train Epoch: [88] [883200/1281167 (69%)]	Loss: 0.687294
[2022-06-10 04:26:30 | train] - Train Epoch: [88] [896000/1281167 (70%)]	Loss: 0.818174
[2022-06-10 04:26:50 | train] - Train Epoch: [88] [908800/1281167 (71%)]	Loss: 0.673436
[2022-06-10 04:27:10 | train] - Train Epoch: [88] [921600/1281167 (72%)]	Loss: 0.668504
[2022-06-10 04:27:29 | train] - Train Epoch: [88] [934400/1281167 (73%)]	Loss: 0.831358
[2022-06-10 04:27:49 | train] - Train Epoch: [88] [947200/1281167 (74%)]	Loss: 0.680048
[2022-06-10 04:28:08 | train] - Train Epoch: [88] [960000/1281167 (75%)]	Loss: 0.867624
[2022-06-10 04:28:27 | train] - Train Epoch: [88] [972800/1281167 (76%)]	Loss: 0.782010
[2022-06-10 04:28:47 | train] - Train Epoch: [88] [985600/1281167 (77%)]	Loss: 0.763443
[2022-06-10 04:29:07 | train] - Train Epoch: [88] [998400/1281167 (78%)]	Loss: 0.754601
[2022-06-10 04:29:27 | train] - Train Epoch: [88] [1011200/1281167 (79%)]	Loss: 0.962351
[2022-06-10 04:29:47 | train] - Train Epoch: [88] [1024000/1281167 (80%)]	Loss: 0.914781
[2022-06-10 04:30:07 | train] - Train Epoch: [88] [1036800/1281167 (81%)]	Loss: 0.912212
[2022-06-10 04:30:27 | train] - Train Epoch: [88] [1049600/1281167 (82%)]	Loss: 0.845342
[2022-06-10 04:30:46 | train] - Train Epoch: [88] [1062400/1281167 (83%)]	Loss: 0.845714
[2022-06-10 04:31:06 | train] - Train Epoch: [88] [1075200/1281167 (84%)]	Loss: 1.154468
[2022-06-10 04:31:25 | train] - Train Epoch: [88] [1088000/1281167 (85%)]	Loss: 0.972309
[2022-06-10 04:31:45 | train] - Train Epoch: [88] [1100800/1281167 (86%)]	Loss: 0.930539
[2022-06-10 04:32:05 | train] - Train Epoch: [88] [1113600/1281167 (87%)]	Loss: 0.939305
[2022-06-10 04:32:25 | train] - Train Epoch: [88] [1126400/1281167 (88%)]	Loss: 0.803653
[2022-06-10 04:32:45 | train] - Train Epoch: [88] [1139200/1281167 (89%)]	Loss: 0.965729
[2022-06-10 04:33:04 | train] - Train Epoch: [88] [1152000/1281167 (90%)]	Loss: 0.943356
[2022-06-10 04:33:24 | train] - Train Epoch: [88] [1164800/1281167 (91%)]	Loss: 0.848681
[2022-06-10 04:33:43 | train] - Train Epoch: [88] [1177600/1281167 (92%)]	Loss: 0.864577
[2022-06-10 04:34:03 | train] - Train Epoch: [88] [1190400/1281167 (93%)]	Loss: 0.917608
[2022-06-10 04:34:23 | train] - Train Epoch: [88] [1203200/1281167 (94%)]	Loss: 0.733379
[2022-06-10 04:34:43 | train] - Train Epoch: [88] [1216000/1281167 (95%)]	Loss: 0.868424
[2022-06-10 04:35:03 | train] - Train Epoch: [88] [1228800/1281167 (96%)]	Loss: 0.953303
[2022-06-10 04:35:22 | train] - Train Epoch: [88] [1241600/1281167 (97%)]	Loss: 0.900129
[2022-06-10 04:35:42 | train] - Train Epoch: [88] [1254400/1281167 (98%)]	Loss: 1.092850
[2022-06-10 04:36:02 | train] - Train Epoch: [88] [1267200/1281167 (99%)]	Loss: 0.754902
[2022-06-10 04:36:22 | train] - Train Epoch: [88] [1280000/1281167 (100%)]	Loss: 0.781652
[2022-06-10 04:36:24 | train] - Train Epoch: [88]	 Average Loss: 0.884021	 Total Acc : 78.4195	 Total Top5 Acc : 92.0021
[2022-06-10 04:36:24 | train] - -------88 epoch end-----------
========================================
-------88 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 04:37:52 | train] - 
Epoch [88] Test set: Average loss: 1.3586, Accuracy: 34986/50000 (69.9457%), Top-5 Accuracy: 89.1129%

[2022-06-10 04:37:52 | train] - save intermediate epoch [88] result


[2022-06-10 04:38:16 | train] - -------89 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 04:38:18 | train] - Train Epoch: [89] [0/1281167 (0%)]	Loss: 0.803285
[2022-06-10 04:38:39 | train] - Train Epoch: [89] [12800/1281167 (1%)]	Loss: 0.921309
[2022-06-10 04:39:00 | train] - Train Epoch: [89] [25600/1281167 (2%)]	Loss: 0.793766
[2022-06-10 04:39:20 | train] - Train Epoch: [89] [38400/1281167 (3%)]	Loss: 0.811624
[2022-06-10 04:39:40 | train] - Train Epoch: [89] [51200/1281167 (4%)]	Loss: 0.996406
[2022-06-10 04:40:00 | train] - Train Epoch: [89] [64000/1281167 (5%)]	Loss: 0.882132
[2022-06-10 04:40:19 | train] - Train Epoch: [89] [76800/1281167 (6%)]	Loss: 0.909900
[2022-06-10 04:40:39 | train] - Train Epoch: [89] [89600/1281167 (7%)]	Loss: 0.962358
[2022-06-10 04:40:59 | train] - Train Epoch: [89] [102400/1281167 (8%)]	Loss: 1.139147
[2022-06-10 04:41:19 | train] - Train Epoch: [89] [115200/1281167 (9%)]	Loss: 0.614401
[2022-06-10 04:41:39 | train] - Train Epoch: [89] [128000/1281167 (10%)]	Loss: 0.784298
[2022-06-10 04:41:59 | train] - Train Epoch: [89] [140800/1281167 (11%)]	Loss: 1.007065
[2022-06-10 04:42:19 | train] - Train Epoch: [89] [153600/1281167 (12%)]	Loss: 0.800603
[2022-06-10 04:42:38 | train] - Train Epoch: [89] [166400/1281167 (13%)]	Loss: 0.957790
[2022-06-10 04:42:58 | train] - Train Epoch: [89] [179200/1281167 (14%)]	Loss: 1.078305
[2022-06-10 04:43:18 | train] - Train Epoch: [89] [192000/1281167 (15%)]	Loss: 0.629247
[2022-06-10 04:43:38 | train] - Train Epoch: [89] [204800/1281167 (16%)]	Loss: 0.852589
[2022-06-10 04:43:59 | train] - Train Epoch: [89] [217600/1281167 (17%)]	Loss: 0.652996
[2022-06-10 04:44:18 | train] - Train Epoch: [89] [230400/1281167 (18%)]	Loss: 0.711303
[2022-06-10 04:44:38 | train] - Train Epoch: [89] [243200/1281167 (19%)]	Loss: 0.619881
[2022-06-10 04:44:58 | train] - Train Epoch: [89] [256000/1281167 (20%)]	Loss: 0.850325
[2022-06-10 04:45:17 | train] - Train Epoch: [89] [268800/1281167 (21%)]	Loss: 1.010371
[2022-06-10 04:45:37 | train] - Train Epoch: [89] [281600/1281167 (22%)]	Loss: 0.816195
[2022-06-10 04:45:56 | train] - Train Epoch: [89] [294400/1281167 (23%)]	Loss: 0.957208
[2022-06-10 04:46:16 | train] - Train Epoch: [89] [307200/1281167 (24%)]	Loss: 0.607276
[2022-06-10 04:46:36 | train] - Train Epoch: [89] [320000/1281167 (25%)]	Loss: 0.949412
[2022-06-10 04:46:55 | train] - Train Epoch: [89] [332800/1281167 (26%)]	Loss: 1.119811
[2022-06-10 04:47:16 | train] - Train Epoch: [89] [345600/1281167 (27%)]	Loss: 0.902640
[2022-06-10 04:47:35 | train] - Train Epoch: [89] [358400/1281167 (28%)]	Loss: 0.731351
[2022-06-10 04:47:55 | train] - Train Epoch: [89] [371200/1281167 (29%)]	Loss: 0.702652
[2022-06-10 04:48:15 | train] - Train Epoch: [89] [384000/1281167 (30%)]	Loss: 1.184749
[2022-06-10 04:48:34 | train] - Train Epoch: [89] [396800/1281167 (31%)]	Loss: 1.177237
[2022-06-10 04:48:54 | train] - Train Epoch: [89] [409600/1281167 (32%)]	Loss: 0.872607
[2022-06-10 04:49:14 | train] - Train Epoch: [89] [422400/1281167 (33%)]	Loss: 0.790923
[2022-06-10 04:49:33 | train] - Train Epoch: [89] [435200/1281167 (34%)]	Loss: 0.650763
[2022-06-10 04:49:53 | train] - Train Epoch: [89] [448000/1281167 (35%)]	Loss: 1.020551
[2022-06-10 04:50:13 | train] - Train Epoch: [89] [460800/1281167 (36%)]	Loss: 1.088683
[2022-06-10 04:50:33 | train] - Train Epoch: [89] [473600/1281167 (37%)]	Loss: 0.729541
[2022-06-10 04:50:53 | train] - Train Epoch: [89] [486400/1281167 (38%)]	Loss: 0.856582
[2022-06-10 04:51:12 | train] - Train Epoch: [89] [499200/1281167 (39%)]	Loss: 0.846435
[2022-06-10 04:51:31 | train] - Train Epoch: [89] [512000/1281167 (40%)]	Loss: 0.885259
[2022-06-10 04:51:51 | train] - Train Epoch: [89] [524800/1281167 (41%)]	Loss: 0.895182
[2022-06-10 04:52:11 | train] - Train Epoch: [89] [537600/1281167 (42%)]	Loss: 0.649252
[2022-06-10 04:52:30 | train] - Train Epoch: [89] [550400/1281167 (43%)]	Loss: 0.728209
[2022-06-10 04:52:49 | train] - Train Epoch: [89] [563200/1281167 (44%)]	Loss: 1.004271
[2022-06-10 04:53:10 | train] - Train Epoch: [89] [576000/1281167 (45%)]	Loss: 1.036845
[2022-06-10 04:53:30 | train] - Train Epoch: [89] [588800/1281167 (46%)]	Loss: 0.788912
[2022-06-10 04:53:49 | train] - Train Epoch: [89] [601600/1281167 (47%)]	Loss: 0.884045
[2022-06-10 04:54:09 | train] - Train Epoch: [89] [614400/1281167 (48%)]	Loss: 0.952693
[2022-06-10 04:54:29 | train] - Train Epoch: [89] [627200/1281167 (49%)]	Loss: 1.143595
[2022-06-10 04:54:49 | train] - Train Epoch: [89] [640000/1281167 (50%)]	Loss: 1.106439
[2022-06-10 04:55:08 | train] - Train Epoch: [89] [652800/1281167 (51%)]	Loss: 0.645578
[2022-06-10 04:55:28 | train] - Train Epoch: [89] [665600/1281167 (52%)]	Loss: 0.908945
[2022-06-10 04:55:48 | train] - Train Epoch: [89] [678400/1281167 (53%)]	Loss: 1.089798
[2022-06-10 04:56:08 | train] - Train Epoch: [89] [691200/1281167 (54%)]	Loss: 0.875992
[2022-06-10 04:56:27 | train] - Train Epoch: [89] [704000/1281167 (55%)]	Loss: 0.824512
[2022-06-10 04:56:47 | train] - Train Epoch: [89] [716800/1281167 (56%)]	Loss: 0.854707
[2022-06-10 04:57:07 | train] - Train Epoch: [89] [729600/1281167 (57%)]	Loss: 0.732826
[2022-06-10 04:57:27 | train] - Train Epoch: [89] [742400/1281167 (58%)]	Loss: 0.880938
[2022-06-10 04:57:47 | train] - Train Epoch: [89] [755200/1281167 (59%)]	Loss: 1.076225
[2022-06-10 04:58:07 | train] - Train Epoch: [89] [768000/1281167 (60%)]	Loss: 0.786681
[2022-06-10 04:58:27 | train] - Train Epoch: [89] [780800/1281167 (61%)]	Loss: 0.769483
[2022-06-10 04:58:47 | train] - Train Epoch: [89] [793600/1281167 (62%)]	Loss: 0.881019
[2022-06-10 04:59:06 | train] - Train Epoch: [89] [806400/1281167 (63%)]	Loss: 0.840795
[2022-06-10 04:59:25 | train] - Train Epoch: [89] [819200/1281167 (64%)]	Loss: 0.906826
[2022-06-10 04:59:45 | train] - Train Epoch: [89] [832000/1281167 (65%)]	Loss: 0.960050
[2022-06-10 05:00:04 | train] - Train Epoch: [89] [844800/1281167 (66%)]	Loss: 0.731627
[2022-06-10 05:00:23 | train] - Train Epoch: [89] [857600/1281167 (67%)]	Loss: 0.835520
[2022-06-10 05:00:43 | train] - Train Epoch: [89] [870400/1281167 (68%)]	Loss: 0.732531
[2022-06-10 05:01:03 | train] - Train Epoch: [89] [883200/1281167 (69%)]	Loss: 0.701649
[2022-06-10 05:01:23 | train] - Train Epoch: [89] [896000/1281167 (70%)]	Loss: 1.255868
[2022-06-10 05:01:43 | train] - Train Epoch: [89] [908800/1281167 (71%)]	Loss: 0.697193
[2022-06-10 05:02:02 | train] - Train Epoch: [89] [921600/1281167 (72%)]	Loss: 0.992463
[2022-06-10 05:02:22 | train] - Train Epoch: [89] [934400/1281167 (73%)]	Loss: 1.019077
[2022-06-10 05:02:42 | train] - Train Epoch: [89] [947200/1281167 (74%)]	Loss: 1.067695
[2022-06-10 05:03:01 | train] - Train Epoch: [89] [960000/1281167 (75%)]	Loss: 0.883761
[2022-06-10 05:03:21 | train] - Train Epoch: [89] [972800/1281167 (76%)]	Loss: 1.026543
[2022-06-10 05:03:40 | train] - Train Epoch: [89] [985600/1281167 (77%)]	Loss: 0.729801
[2022-06-10 05:03:59 | train] - Train Epoch: [89] [998400/1281167 (78%)]	Loss: 0.800764
[2022-06-10 05:04:20 | train] - Train Epoch: [89] [1011200/1281167 (79%)]	Loss: 0.491222
[2022-06-10 05:04:39 | train] - Train Epoch: [89] [1024000/1281167 (80%)]	Loss: 0.821795
[2022-06-10 05:04:59 | train] - Train Epoch: [89] [1036800/1281167 (81%)]	Loss: 0.809865
[2022-06-10 05:05:19 | train] - Train Epoch: [89] [1049600/1281167 (82%)]	Loss: 0.946914
[2022-06-10 05:05:39 | train] - Train Epoch: [89] [1062400/1281167 (83%)]	Loss: 0.711627
[2022-06-10 05:05:59 | train] - Train Epoch: [89] [1075200/1281167 (84%)]	Loss: 1.071766
[2022-06-10 05:06:19 | train] - Train Epoch: [89] [1088000/1281167 (85%)]	Loss: 0.756106
[2022-06-10 05:06:38 | train] - Train Epoch: [89] [1100800/1281167 (86%)]	Loss: 0.858559
[2022-06-10 05:06:58 | train] - Train Epoch: [89] [1113600/1281167 (87%)]	Loss: 0.674425
[2022-06-10 05:07:17 | train] - Train Epoch: [89] [1126400/1281167 (88%)]	Loss: 1.200506
[2022-06-10 05:07:36 | train] - Train Epoch: [89] [1139200/1281167 (89%)]	Loss: 0.912739
[2022-06-10 05:07:57 | train] - Train Epoch: [89] [1152000/1281167 (90%)]	Loss: 1.014744
[2022-06-10 05:08:16 | train] - Train Epoch: [89] [1164800/1281167 (91%)]	Loss: 1.131542
[2022-06-10 05:08:36 | train] - Train Epoch: [89] [1177600/1281167 (92%)]	Loss: 0.716336
[2022-06-10 05:08:56 | train] - Train Epoch: [89] [1190400/1281167 (93%)]	Loss: 0.627030
[2022-06-10 05:09:16 | train] - Train Epoch: [89] [1203200/1281167 (94%)]	Loss: 0.852163
[2022-06-10 05:09:35 | train] - Train Epoch: [89] [1216000/1281167 (95%)]	Loss: 0.911973
[2022-06-10 05:09:54 | train] - Train Epoch: [89] [1228800/1281167 (96%)]	Loss: 0.852756
[2022-06-10 05:10:14 | train] - Train Epoch: [89] [1241600/1281167 (97%)]	Loss: 0.735185
[2022-06-10 05:10:34 | train] - Train Epoch: [89] [1254400/1281167 (98%)]	Loss: 0.850624
[2022-06-10 05:10:55 | train] - Train Epoch: [89] [1267200/1281167 (99%)]	Loss: 0.921618
[2022-06-10 05:11:15 | train] - Train Epoch: [89] [1280000/1281167 (100%)]	Loss: 0.865237
[2022-06-10 05:11:16 | train] - Train Epoch: [89]	 Average Loss: 0.882672	 Total Acc : 78.4517	 Total Top5 Acc : 92.0257
[2022-06-10 05:11:16 | train] - -------89 epoch end-----------
========================================
-------89 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 05:12:47 | train] - 
Epoch [89] Test set: Average loss: 1.3653, Accuracy: 34913/50000 (69.8010%), Top-5 Accuracy: 89.1448%

[2022-06-10 05:12:47 | train] - save intermediate epoch [89] result


[2022-06-10 05:13:13 | train] - -------90 epoch start-----------
[2022-06-10 05:13:13 | train] - -------- logging 90 batch layer input tensor ------------------
[2022-06-10 05:13:43 | train] - -------- logging end 90 --------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-10 05:13:44 | train] - Train Epoch: [90] [0/1281167 (0%)]	Loss: 1.060296
[2022-06-10 05:14:04 | train] - Train Epoch: [90] [12800/1281167 (1%)]	Loss: 0.916572
[2022-06-10 05:14:24 | train] - Train Epoch: [90] [25600/1281167 (2%)]	Loss: 0.954865
[2022-06-10 05:14:44 | train] - Train Epoch: [90] [38400/1281167 (3%)]	Loss: 0.804699
[2022-06-10 05:15:04 | train] - Train Epoch: [90] [51200/1281167 (4%)]	Loss: 1.041385
[2022-06-10 05:15:24 | train] - Train Epoch: [90] [64000/1281167 (5%)]	Loss: 0.791666
[2022-06-10 05:15:44 | train] - Train Epoch: [90] [76800/1281167 (6%)]	Loss: 1.081438
[2022-06-10 05:16:04 | train] - Train Epoch: [90] [89600/1281167 (7%)]	Loss: 1.034803
[2022-06-10 05:16:24 | train] - Train Epoch: [90] [102400/1281167 (8%)]	Loss: 0.869186
[2022-06-10 05:16:44 | train] - Train Epoch: [90] [115200/1281167 (9%)]	Loss: 1.002754
[2022-06-10 05:17:04 | train] - Train Epoch: [90] [128000/1281167 (10%)]	Loss: 0.765421
[2022-06-10 05:17:23 | train] - Train Epoch: [90] [140800/1281167 (11%)]	Loss: 0.836132
[2022-06-10 05:17:43 | train] - Train Epoch: [90] [153600/1281167 (12%)]	Loss: 1.131007
[2022-06-10 05:18:03 | train] - Train Epoch: [90] [166400/1281167 (13%)]	Loss: 0.816299
[2022-06-10 05:18:23 | train] - Train Epoch: [90] [179200/1281167 (14%)]	Loss: 0.695625
[2022-06-10 05:18:42 | train] - Train Epoch: [90] [192000/1281167 (15%)]	Loss: 1.089391
[2022-06-10 05:19:02 | train] - Train Epoch: [90] [204800/1281167 (16%)]	Loss: 0.987443
[2022-06-10 05:19:22 | train] - Train Epoch: [90] [217600/1281167 (17%)]	Loss: 0.786823
[2022-06-10 05:19:41 | train] - Train Epoch: [90] [230400/1281167 (18%)]	Loss: 0.729121
[2022-06-10 05:20:01 | train] - Train Epoch: [90] [243200/1281167 (19%)]	Loss: 0.686773
[2022-06-10 05:20:20 | train] - Train Epoch: [90] [256000/1281167 (20%)]	Loss: 1.031710
[2022-06-10 05:20:40 | train] - Train Epoch: [90] [268800/1281167 (21%)]	Loss: 0.658156
[2022-06-10 05:21:00 | train] - Train Epoch: [90] [281600/1281167 (22%)]	Loss: 0.979530
[2022-06-10 05:21:20 | train] - Train Epoch: [90] [294400/1281167 (23%)]	Loss: 0.513706
[2022-06-10 05:21:39 | train] - Train Epoch: [90] [307200/1281167 (24%)]	Loss: 0.991800
[2022-06-10 05:21:59 | train] - Train Epoch: [90] [320000/1281167 (25%)]	Loss: 0.889572
[2022-06-10 05:22:19 | train] - Train Epoch: [90] [332800/1281167 (26%)]	Loss: 0.764630
[2022-06-10 05:22:39 | train] - Train Epoch: [90] [345600/1281167 (27%)]	Loss: 1.001758
[2022-06-10 05:22:59 | train] - Train Epoch: [90] [358400/1281167 (28%)]	Loss: 0.831285
[2022-06-10 05:23:19 | train] - Train Epoch: [90] [371200/1281167 (29%)]	Loss: 0.561088
[2022-06-10 05:23:39 | train] - Train Epoch: [90] [384000/1281167 (30%)]	Loss: 1.167270
[2022-06-10 05:23:58 | train] - Train Epoch: [90] [396800/1281167 (31%)]	Loss: 1.021024
[2022-06-10 05:24:18 | train] - Train Epoch: [90] [409600/1281167 (32%)]	Loss: 0.845099
[2022-06-10 05:24:38 | train] - Train Epoch: [90] [422400/1281167 (33%)]	Loss: 0.778928
[2022-06-10 05:24:59 | train] - Train Epoch: [90] [435200/1281167 (34%)]	Loss: 0.949498
[2022-06-10 05:25:18 | train] - Train Epoch: [90] [448000/1281167 (35%)]	Loss: 1.039761
[2022-06-10 05:25:39 | train] - Train Epoch: [90] [460800/1281167 (36%)]	Loss: 0.930184
[2022-06-10 05:25:58 | train] - Train Epoch: [90] [473600/1281167 (37%)]	Loss: 1.051983
[2022-06-10 05:26:18 | train] - Train Epoch: [90] [486400/1281167 (38%)]	Loss: 0.848804
[2022-06-10 05:26:37 | train] - Train Epoch: [90] [499200/1281167 (39%)]	Loss: 0.971385
[2022-06-10 05:26:57 | train] - Train Epoch: [90] [512000/1281167 (40%)]	Loss: 0.804588
[2022-06-10 05:27:18 | train] - Train Epoch: [90] [524800/1281167 (41%)]	Loss: 0.809375
[2022-06-10 05:27:37 | train] - Train Epoch: [90] [537600/1281167 (42%)]	Loss: 0.977367
[2022-06-10 05:27:57 | train] - Train Epoch: [90] [550400/1281167 (43%)]	Loss: 0.741355
[2022-06-10 05:28:16 | train] - Train Epoch: [90] [563200/1281167 (44%)]	Loss: 0.740261
[2022-06-10 05:28:35 | train] - Train Epoch: [90] [576000/1281167 (45%)]	Loss: 0.703604
[2022-06-10 05:28:55 | train] - Train Epoch: [90] [588800/1281167 (46%)]	Loss: 0.939271
[2022-06-10 05:29:15 | train] - Train Epoch: [90] [601600/1281167 (47%)]	Loss: 0.735529
[2022-06-10 05:29:35 | train] - Train Epoch: [90] [614400/1281167 (48%)]	Loss: 0.868045
[2022-06-10 05:29:54 | train] - Train Epoch: [90] [627200/1281167 (49%)]	Loss: 1.021353
[2022-06-10 05:30:15 | train] - Train Epoch: [90] [640000/1281167 (50%)]	Loss: 0.833407
[2022-06-10 05:30:34 | train] - Train Epoch: [90] [652800/1281167 (51%)]	Loss: 0.994156
[2022-06-10 05:30:54 | train] - Train Epoch: [90] [665600/1281167 (52%)]	Loss: 0.681329
[2022-06-10 05:31:14 | train] - Train Epoch: [90] [678400/1281167 (53%)]	Loss: 1.106327
[2022-06-10 05:31:34 | train] - Train Epoch: [90] [691200/1281167 (54%)]	Loss: 0.819001
[2022-06-10 05:31:53 | train] - Train Epoch: [90] [704000/1281167 (55%)]	Loss: 0.953420
[2022-06-10 05:32:13 | train] - Train Epoch: [90] [716800/1281167 (56%)]	Loss: 0.779412
[2022-06-10 05:32:33 | train] - Train Epoch: [90] [729600/1281167 (57%)]	Loss: 0.919512
[2022-06-10 05:32:53 | train] - Train Epoch: [90] [742400/1281167 (58%)]	Loss: 0.953940
[2022-06-10 05:33:13 | train] - Train Epoch: [90] [755200/1281167 (59%)]	Loss: 0.873621
[2022-06-10 05:33:33 | train] - Train Epoch: [90] [768000/1281167 (60%)]	Loss: 0.819014
[2022-06-10 05:33:52 | train] - Train Epoch: [90] [780800/1281167 (61%)]	Loss: 0.770538
[2022-06-10 05:34:12 | train] - Train Epoch: [90] [793600/1281167 (62%)]	Loss: 0.666019
[2022-06-10 05:34:32 | train] - Train Epoch: [90] [806400/1281167 (63%)]	Loss: 0.912834
[2022-06-10 05:34:51 | train] - Train Epoch: [90] [819200/1281167 (64%)]	Loss: 0.900978
[2022-06-10 05:35:11 | train] - Train Epoch: [90] [832000/1281167 (65%)]	Loss: 0.748424
[2022-06-10 05:35:31 | train] - Train Epoch: [90] [844800/1281167 (66%)]	Loss: 0.846260
[2022-06-10 05:35:51 | train] - Train Epoch: [90] [857600/1281167 (67%)]	Loss: 1.072812
[2022-06-10 05:36:11 | train] - Train Epoch: [90] [870400/1281167 (68%)]	Loss: 1.047691
[2022-06-10 05:36:31 | train] - Train Epoch: [90] [883200/1281167 (69%)]	Loss: 1.015816
[2022-06-10 05:36:51 | train] - Train Epoch: [90] [896000/1281167 (70%)]	Loss: 0.600234
[2022-06-10 05:37:11 | train] - Train Epoch: [90] [908800/1281167 (71%)]	Loss: 0.762627
[2022-06-10 05:37:31 | train] - Train Epoch: [90] [921600/1281167 (72%)]	Loss: 0.865573
[2022-06-10 05:37:51 | train] - Train Epoch: [90] [934400/1281167 (73%)]	Loss: 1.117019
[2022-06-10 05:38:10 | train] - Train Epoch: [90] [947200/1281167 (74%)]	Loss: 1.071228
[2022-06-10 05:38:30 | train] - Train Epoch: [90] [960000/1281167 (75%)]	Loss: 0.723292
[2022-06-10 05:38:50 | train] - Train Epoch: [90] [972800/1281167 (76%)]	Loss: 0.962088
[2022-06-10 05:39:10 | train] - Train Epoch: [90] [985600/1281167 (77%)]	Loss: 0.992110
[2022-06-10 05:39:29 | train] - Train Epoch: [90] [998400/1281167 (78%)]	Loss: 0.851931
[2022-06-10 05:39:49 | train] - Train Epoch: [90] [1011200/1281167 (79%)]	Loss: 0.803347
[2022-06-10 05:40:10 | train] - Train Epoch: [90] [1024000/1281167 (80%)]	Loss: 0.911674
[2022-06-10 05:40:29 | train] - Train Epoch: [90] [1036800/1281167 (81%)]	Loss: 0.897686
[2022-06-10 05:40:48 | train] - Train Epoch: [90] [1049600/1281167 (82%)]	Loss: 0.907842
[2022-06-10 05:41:08 | train] - Train Epoch: [90] [1062400/1281167 (83%)]	Loss: 0.866171
[2022-06-10 05:41:28 | train] - Train Epoch: [90] [1075200/1281167 (84%)]	Loss: 0.880952
[2022-06-10 05:41:48 | train] - Train Epoch: [90] [1088000/1281167 (85%)]	Loss: 1.184049
[2022-06-10 05:42:08 | train] - Train Epoch: [90] [1100800/1281167 (86%)]	Loss: 1.092703
[2022-06-10 05:42:28 | train] - Train Epoch: [90] [1113600/1281167 (87%)]	Loss: 1.111879
[2022-06-10 05:42:48 | train] - Train Epoch: [90] [1126400/1281167 (88%)]	Loss: 0.932284
[2022-06-10 05:43:08 | train] - Train Epoch: [90] [1139200/1281167 (89%)]	Loss: 0.931913
[2022-06-10 05:43:27 | train] - Train Epoch: [90] [1152000/1281167 (90%)]	Loss: 0.814749
[2022-06-10 05:43:47 | train] - Train Epoch: [90] [1164800/1281167 (91%)]	Loss: 0.825649
[2022-06-10 05:44:06 | train] - Train Epoch: [90] [1177600/1281167 (92%)]	Loss: 1.001446
[2022-06-10 05:44:26 | train] - Train Epoch: [90] [1190400/1281167 (93%)]	Loss: 0.740263
[2022-06-10 05:44:46 | train] - Train Epoch: [90] [1203200/1281167 (94%)]	Loss: 1.112934
[2022-06-10 05:45:05 | train] - Train Epoch: [90] [1216000/1281167 (95%)]	Loss: 1.092455
[2022-06-10 05:45:26 | train] - Train Epoch: [90] [1228800/1281167 (96%)]	Loss: 0.714704
[2022-06-10 05:45:46 | train] - Train Epoch: [90] [1241600/1281167 (97%)]	Loss: 1.017256
[2022-06-10 05:46:06 | train] - Train Epoch: [90] [1254400/1281167 (98%)]	Loss: 0.659217
[2022-06-10 05:46:25 | train] - Train Epoch: [90] [1267200/1281167 (99%)]	Loss: 0.878980
[2022-06-10 05:46:46 | train] - Train Epoch: [90] [1280000/1281167 (100%)]	Loss: 0.686591
[2022-06-10 05:46:47 | train] - Train Epoch: [90]	 Average Loss: 0.881900	 Total Acc : 78.4963	 Total Top5 Acc : 92.0236
[2022-06-10 05:46:47 | train] - -------90 epoch end-----------
========================================
-------90 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 05:48:17 | train] - 
Epoch [90] Test set: Average loss: 1.3737, Accuracy: 34981/50000 (69.9309%), Top-5 Accuracy: 88.9890%

[2022-06-10 05:48:17 | train] - save intermediate epoch [90] result


[2022-06-10 05:48:46 | train] - -------91 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 05:48:48 | train] - Train Epoch: [91] [0/1281167 (0%)]	Loss: 0.929225
[2022-06-10 05:49:08 | train] - Train Epoch: [91] [12800/1281167 (1%)]	Loss: 0.977260
[2022-06-10 05:49:27 | train] - Train Epoch: [91] [25600/1281167 (2%)]	Loss: 0.963505
[2022-06-10 05:49:47 | train] - Train Epoch: [91] [38400/1281167 (3%)]	Loss: 1.108521
[2022-06-10 05:50:07 | train] - Train Epoch: [91] [51200/1281167 (4%)]	Loss: 0.842344
[2022-06-10 05:50:26 | train] - Train Epoch: [91] [64000/1281167 (5%)]	Loss: 0.793752
[2022-06-10 05:50:46 | train] - Train Epoch: [91] [76800/1281167 (6%)]	Loss: 0.984035
[2022-06-10 05:51:06 | train] - Train Epoch: [91] [89600/1281167 (7%)]	Loss: 0.824087
[2022-06-10 05:51:26 | train] - Train Epoch: [91] [102400/1281167 (8%)]	Loss: 0.894437
[2022-06-10 05:51:46 | train] - Train Epoch: [91] [115200/1281167 (9%)]	Loss: 0.862839
[2022-06-10 05:52:06 | train] - Train Epoch: [91] [128000/1281167 (10%)]	Loss: 1.003585
[2022-06-10 05:52:26 | train] - Train Epoch: [91] [140800/1281167 (11%)]	Loss: 1.133760
[2022-06-10 05:52:45 | train] - Train Epoch: [91] [153600/1281167 (12%)]	Loss: 1.054882
[2022-06-10 05:53:05 | train] - Train Epoch: [91] [166400/1281167 (13%)]	Loss: 0.709558
[2022-06-10 05:53:25 | train] - Train Epoch: [91] [179200/1281167 (14%)]	Loss: 0.775668
[2022-06-10 05:53:45 | train] - Train Epoch: [91] [192000/1281167 (15%)]	Loss: 0.894860
[2022-06-10 05:54:04 | train] - Train Epoch: [91] [204800/1281167 (16%)]	Loss: 0.841353
[2022-06-10 05:54:24 | train] - Train Epoch: [91] [217600/1281167 (17%)]	Loss: 0.752512
[2022-06-10 05:54:44 | train] - Train Epoch: [91] [230400/1281167 (18%)]	Loss: 0.716738
[2022-06-10 05:55:04 | train] - Train Epoch: [91] [243200/1281167 (19%)]	Loss: 1.135571
[2022-06-10 05:55:23 | train] - Train Epoch: [91] [256000/1281167 (20%)]	Loss: 1.166781
[2022-06-10 05:55:43 | train] - Train Epoch: [91] [268800/1281167 (21%)]	Loss: 0.866587
[2022-06-10 05:56:02 | train] - Train Epoch: [91] [281600/1281167 (22%)]	Loss: 0.767672
[2022-06-10 05:56:22 | train] - Train Epoch: [91] [294400/1281167 (23%)]	Loss: 0.819782
[2022-06-10 05:56:41 | train] - Train Epoch: [91] [307200/1281167 (24%)]	Loss: 0.826697
[2022-06-10 05:57:01 | train] - Train Epoch: [91] [320000/1281167 (25%)]	Loss: 0.966352
[2022-06-10 05:57:20 | train] - Train Epoch: [91] [332800/1281167 (26%)]	Loss: 0.643579
[2022-06-10 05:57:40 | train] - Train Epoch: [91] [345600/1281167 (27%)]	Loss: 0.834421
[2022-06-10 05:58:00 | train] - Train Epoch: [91] [358400/1281167 (28%)]	Loss: 0.859215
[2022-06-10 05:58:20 | train] - Train Epoch: [91] [371200/1281167 (29%)]	Loss: 0.726644
[2022-06-10 05:58:39 | train] - Train Epoch: [91] [384000/1281167 (30%)]	Loss: 0.925077
[2022-06-10 05:58:59 | train] - Train Epoch: [91] [396800/1281167 (31%)]	Loss: 0.890746
[2022-06-10 05:59:18 | train] - Train Epoch: [91] [409600/1281167 (32%)]	Loss: 0.747743
[2022-06-10 05:59:37 | train] - Train Epoch: [91] [422400/1281167 (33%)]	Loss: 1.034097
[2022-06-10 05:59:58 | train] - Train Epoch: [91] [435200/1281167 (34%)]	Loss: 0.951590
[2022-06-10 06:00:17 | train] - Train Epoch: [91] [448000/1281167 (35%)]	Loss: 0.998018
[2022-06-10 06:00:37 | train] - Train Epoch: [91] [460800/1281167 (36%)]	Loss: 0.750401
[2022-06-10 06:00:57 | train] - Train Epoch: [91] [473600/1281167 (37%)]	Loss: 0.745471
[2022-06-10 06:01:16 | train] - Train Epoch: [91] [486400/1281167 (38%)]	Loss: 1.076982
[2022-06-10 06:01:36 | train] - Train Epoch: [91] [499200/1281167 (39%)]	Loss: 0.921150
[2022-06-10 06:01:55 | train] - Train Epoch: [91] [512000/1281167 (40%)]	Loss: 0.978256
[2022-06-10 06:02:15 | train] - Train Epoch: [91] [524800/1281167 (41%)]	Loss: 0.820994
[2022-06-10 06:02:34 | train] - Train Epoch: [91] [537600/1281167 (42%)]	Loss: 0.914264
[2022-06-10 06:02:53 | train] - Train Epoch: [91] [550400/1281167 (43%)]	Loss: 1.354176
[2022-06-10 06:03:13 | train] - Train Epoch: [91] [563200/1281167 (44%)]	Loss: 0.819291
[2022-06-10 06:03:32 | train] - Train Epoch: [91] [576000/1281167 (45%)]	Loss: 0.641664
[2022-06-10 06:03:52 | train] - Train Epoch: [91] [588800/1281167 (46%)]	Loss: 0.861735
[2022-06-10 06:04:12 | train] - Train Epoch: [91] [601600/1281167 (47%)]	Loss: 0.867587
[2022-06-10 06:04:32 | train] - Train Epoch: [91] [614400/1281167 (48%)]	Loss: 0.981691
[2022-06-10 06:04:51 | train] - Train Epoch: [91] [627200/1281167 (49%)]	Loss: 0.977567
[2022-06-10 06:05:11 | train] - Train Epoch: [91] [640000/1281167 (50%)]	Loss: 1.050964
[2022-06-10 06:05:31 | train] - Train Epoch: [91] [652800/1281167 (51%)]	Loss: 0.946229
[2022-06-10 06:05:50 | train] - Train Epoch: [91] [665600/1281167 (52%)]	Loss: 0.852374
[2022-06-10 06:06:10 | train] - Train Epoch: [91] [678400/1281167 (53%)]	Loss: 0.915398
[2022-06-10 06:06:30 | train] - Train Epoch: [91] [691200/1281167 (54%)]	Loss: 0.865471
[2022-06-10 06:06:49 | train] - Train Epoch: [91] [704000/1281167 (55%)]	Loss: 0.939459
[2022-06-10 06:07:09 | train] - Train Epoch: [91] [716800/1281167 (56%)]	Loss: 0.863744
[2022-06-10 06:07:30 | train] - Train Epoch: [91] [729600/1281167 (57%)]	Loss: 0.954917
[2022-06-10 06:07:49 | train] - Train Epoch: [91] [742400/1281167 (58%)]	Loss: 1.082210
[2022-06-10 06:08:08 | train] - Train Epoch: [91] [755200/1281167 (59%)]	Loss: 0.720905
[2022-06-10 06:08:28 | train] - Train Epoch: [91] [768000/1281167 (60%)]	Loss: 1.021905
[2022-06-10 06:08:47 | train] - Train Epoch: [91] [780800/1281167 (61%)]	Loss: 0.759454
[2022-06-10 06:09:08 | train] - Train Epoch: [91] [793600/1281167 (62%)]	Loss: 0.713156
[2022-06-10 06:09:27 | train] - Train Epoch: [91] [806400/1281167 (63%)]	Loss: 1.091481
[2022-06-10 06:09:47 | train] - Train Epoch: [91] [819200/1281167 (64%)]	Loss: 1.127425
[2022-06-10 06:10:07 | train] - Train Epoch: [91] [832000/1281167 (65%)]	Loss: 0.864167
[2022-06-10 06:10:26 | train] - Train Epoch: [91] [844800/1281167 (66%)]	Loss: 1.113299
[2022-06-10 06:10:46 | train] - Train Epoch: [91] [857600/1281167 (67%)]	Loss: 0.894761
[2022-06-10 06:11:06 | train] - Train Epoch: [91] [870400/1281167 (68%)]	Loss: 0.844635
[2022-06-10 06:11:26 | train] - Train Epoch: [91] [883200/1281167 (69%)]	Loss: 0.852698
[2022-06-10 06:11:45 | train] - Train Epoch: [91] [896000/1281167 (70%)]	Loss: 1.010412
[2022-06-10 06:12:05 | train] - Train Epoch: [91] [908800/1281167 (71%)]	Loss: 0.807275
[2022-06-10 06:12:25 | train] - Train Epoch: [91] [921600/1281167 (72%)]	Loss: 0.784714
[2022-06-10 06:12:44 | train] - Train Epoch: [91] [934400/1281167 (73%)]	Loss: 0.801094
[2022-06-10 06:13:04 | train] - Train Epoch: [91] [947200/1281167 (74%)]	Loss: 0.783475
[2022-06-10 06:13:24 | train] - Train Epoch: [91] [960000/1281167 (75%)]	Loss: 0.947804
[2022-06-10 06:13:44 | train] - Train Epoch: [91] [972800/1281167 (76%)]	Loss: 0.826212
[2022-06-10 06:14:03 | train] - Train Epoch: [91] [985600/1281167 (77%)]	Loss: 0.734104
[2022-06-10 06:14:24 | train] - Train Epoch: [91] [998400/1281167 (78%)]	Loss: 0.843745
[2022-06-10 06:14:43 | train] - Train Epoch: [91] [1011200/1281167 (79%)]	Loss: 0.987758
[2022-06-10 06:15:03 | train] - Train Epoch: [91] [1024000/1281167 (80%)]	Loss: 0.768288
[2022-06-10 06:15:22 | train] - Train Epoch: [91] [1036800/1281167 (81%)]	Loss: 0.904379
[2022-06-10 06:15:42 | train] - Train Epoch: [91] [1049600/1281167 (82%)]	Loss: 0.687837
[2022-06-10 06:16:02 | train] - Train Epoch: [91] [1062400/1281167 (83%)]	Loss: 0.831606
[2022-06-10 06:16:22 | train] - Train Epoch: [91] [1075200/1281167 (84%)]	Loss: 0.992596
[2022-06-10 06:16:41 | train] - Train Epoch: [91] [1088000/1281167 (85%)]	Loss: 0.824046
[2022-06-10 06:17:01 | train] - Train Epoch: [91] [1100800/1281167 (86%)]	Loss: 0.890839
[2022-06-10 06:17:21 | train] - Train Epoch: [91] [1113600/1281167 (87%)]	Loss: 0.696109
[2022-06-10 06:17:40 | train] - Train Epoch: [91] [1126400/1281167 (88%)]	Loss: 0.707175
[2022-06-10 06:18:00 | train] - Train Epoch: [91] [1139200/1281167 (89%)]	Loss: 0.659423
[2022-06-10 06:18:19 | train] - Train Epoch: [91] [1152000/1281167 (90%)]	Loss: 0.796069
[2022-06-10 06:18:40 | train] - Train Epoch: [91] [1164800/1281167 (91%)]	Loss: 0.764235
[2022-06-10 06:18:59 | train] - Train Epoch: [91] [1177600/1281167 (92%)]	Loss: 0.840094
[2022-06-10 06:19:19 | train] - Train Epoch: [91] [1190400/1281167 (93%)]	Loss: 1.184714
[2022-06-10 06:19:40 | train] - Train Epoch: [91] [1203200/1281167 (94%)]	Loss: 0.847449
[2022-06-10 06:19:59 | train] - Train Epoch: [91] [1216000/1281167 (95%)]	Loss: 1.103693
[2022-06-10 06:20:18 | train] - Train Epoch: [91] [1228800/1281167 (96%)]	Loss: 0.991210
[2022-06-10 06:20:38 | train] - Train Epoch: [91] [1241600/1281167 (97%)]	Loss: 0.742655
[2022-06-10 06:20:58 | train] - Train Epoch: [91] [1254400/1281167 (98%)]	Loss: 0.914810
[2022-06-10 06:21:18 | train] - Train Epoch: [91] [1267200/1281167 (99%)]	Loss: 0.788214
[2022-06-10 06:21:37 | train] - Train Epoch: [91] [1280000/1281167 (100%)]	Loss: 0.771724
[2022-06-10 06:21:39 | train] - Train Epoch: [91]	 Average Loss: 0.878309	 Total Acc : 78.5658	 Total Top5 Acc : 92.0905
[2022-06-10 06:21:39 | train] - -------91 epoch end-----------
========================================
-------91 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 06:23:09 | train] - 
Epoch [91] Test set: Average loss: 1.3683, Accuracy: 34919/50000 (69.8082%), Top-5 Accuracy: 88.9462%

[2022-06-10 06:23:09 | train] - save intermediate epoch [91] result


[2022-06-10 06:23:34 | train] - -------92 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 06:23:36 | train] - Train Epoch: [92] [0/1281167 (0%)]	Loss: 0.679716
[2022-06-10 06:23:57 | train] - Train Epoch: [92] [12800/1281167 (1%)]	Loss: 0.736856
[2022-06-10 06:24:16 | train] - Train Epoch: [92] [25600/1281167 (2%)]	Loss: 0.753487
[2022-06-10 06:24:35 | train] - Train Epoch: [92] [38400/1281167 (3%)]	Loss: 0.878431
[2022-06-10 06:24:56 | train] - Train Epoch: [92] [51200/1281167 (4%)]	Loss: 0.733458
[2022-06-10 06:25:18 | train] - Train Epoch: [92] [64000/1281167 (5%)]	Loss: 0.933680
[2022-06-10 06:25:38 | train] - Train Epoch: [92] [76800/1281167 (6%)]	Loss: 0.817712
[2022-06-10 06:25:59 | train] - Train Epoch: [92] [89600/1281167 (7%)]	Loss: 0.814812
[2022-06-10 06:26:20 | train] - Train Epoch: [92] [102400/1281167 (8%)]	Loss: 1.084683
[2022-06-10 06:26:39 | train] - Train Epoch: [92] [115200/1281167 (9%)]	Loss: 1.109762
[2022-06-10 06:26:59 | train] - Train Epoch: [92] [128000/1281167 (10%)]	Loss: 0.731231
[2022-06-10 06:27:19 | train] - Train Epoch: [92] [140800/1281167 (11%)]	Loss: 0.952980
[2022-06-10 06:27:39 | train] - Train Epoch: [92] [153600/1281167 (12%)]	Loss: 0.919374
[2022-06-10 06:27:58 | train] - Train Epoch: [92] [166400/1281167 (13%)]	Loss: 1.041060
[2022-06-10 06:28:17 | train] - Train Epoch: [92] [179200/1281167 (14%)]	Loss: 0.777969
[2022-06-10 06:28:38 | train] - Train Epoch: [92] [192000/1281167 (15%)]	Loss: 0.979028
[2022-06-10 06:28:57 | train] - Train Epoch: [92] [204800/1281167 (16%)]	Loss: 0.975004
[2022-06-10 06:29:18 | train] - Train Epoch: [92] [217600/1281167 (17%)]	Loss: 0.723044
[2022-06-10 06:29:38 | train] - Train Epoch: [92] [230400/1281167 (18%)]	Loss: 1.021897
[2022-06-10 06:29:58 | train] - Train Epoch: [92] [243200/1281167 (19%)]	Loss: 0.884098
[2022-06-10 06:30:18 | train] - Train Epoch: [92] [256000/1281167 (20%)]	Loss: 0.934597
[2022-06-10 06:30:38 | train] - Train Epoch: [92] [268800/1281167 (21%)]	Loss: 1.067180
[2022-06-10 06:30:58 | train] - Train Epoch: [92] [281600/1281167 (22%)]	Loss: 0.746472
[2022-06-10 06:31:18 | train] - Train Epoch: [92] [294400/1281167 (23%)]	Loss: 0.871753
[2022-06-10 06:31:39 | train] - Train Epoch: [92] [307200/1281167 (24%)]	Loss: 0.760694
[2022-06-10 06:31:59 | train] - Train Epoch: [92] [320000/1281167 (25%)]	Loss: 1.002134
[2022-06-10 06:32:19 | train] - Train Epoch: [92] [332800/1281167 (26%)]	Loss: 1.126294
[2022-06-10 06:32:39 | train] - Train Epoch: [92] [345600/1281167 (27%)]	Loss: 0.726496
[2022-06-10 06:32:59 | train] - Train Epoch: [92] [358400/1281167 (28%)]	Loss: 0.864032
[2022-06-10 06:33:19 | train] - Train Epoch: [92] [371200/1281167 (29%)]	Loss: 1.009417
[2022-06-10 06:33:40 | train] - Train Epoch: [92] [384000/1281167 (30%)]	Loss: 0.930777
[2022-06-10 06:33:59 | train] - Train Epoch: [92] [396800/1281167 (31%)]	Loss: 0.865203
[2022-06-10 06:34:20 | train] - Train Epoch: [92] [409600/1281167 (32%)]	Loss: 1.047616
[2022-06-10 06:34:40 | train] - Train Epoch: [92] [422400/1281167 (33%)]	Loss: 0.887530
[2022-06-10 06:35:00 | train] - Train Epoch: [92] [435200/1281167 (34%)]	Loss: 0.942964
[2022-06-10 06:35:20 | train] - Train Epoch: [92] [448000/1281167 (35%)]	Loss: 1.079186
[2022-06-10 06:35:40 | train] - Train Epoch: [92] [460800/1281167 (36%)]	Loss: 0.804371
[2022-06-10 06:36:00 | train] - Train Epoch: [92] [473600/1281167 (37%)]	Loss: 0.778113
[2022-06-10 06:36:19 | train] - Train Epoch: [92] [486400/1281167 (38%)]	Loss: 0.901969
[2022-06-10 06:36:39 | train] - Train Epoch: [92] [499200/1281167 (39%)]	Loss: 0.894042
[2022-06-10 06:36:59 | train] - Train Epoch: [92] [512000/1281167 (40%)]	Loss: 1.012135
[2022-06-10 06:37:19 | train] - Train Epoch: [92] [524800/1281167 (41%)]	Loss: 0.888087
[2022-06-10 06:37:39 | train] - Train Epoch: [92] [537600/1281167 (42%)]	Loss: 0.854671
[2022-06-10 06:37:59 | train] - Train Epoch: [92] [550400/1281167 (43%)]	Loss: 0.977470
[2022-06-10 06:38:19 | train] - Train Epoch: [92] [563200/1281167 (44%)]	Loss: 1.046225
[2022-06-10 06:38:39 | train] - Train Epoch: [92] [576000/1281167 (45%)]	Loss: 0.966483
[2022-06-10 06:38:59 | train] - Train Epoch: [92] [588800/1281167 (46%)]	Loss: 0.776082
[2022-06-10 06:39:20 | train] - Train Epoch: [92] [601600/1281167 (47%)]	Loss: 1.176868
[2022-06-10 06:39:40 | train] - Train Epoch: [92] [614400/1281167 (48%)]	Loss: 0.883756
[2022-06-10 06:39:59 | train] - Train Epoch: [92] [627200/1281167 (49%)]	Loss: 0.876964
[2022-06-10 06:40:20 | train] - Train Epoch: [92] [640000/1281167 (50%)]	Loss: 0.731115
[2022-06-10 06:40:40 | train] - Train Epoch: [92] [652800/1281167 (51%)]	Loss: 0.921809
[2022-06-10 06:40:59 | train] - Train Epoch: [92] [665600/1281167 (52%)]	Loss: 0.907380
[2022-06-10 06:41:20 | train] - Train Epoch: [92] [678400/1281167 (53%)]	Loss: 1.001206
[2022-06-10 06:41:40 | train] - Train Epoch: [92] [691200/1281167 (54%)]	Loss: 1.026128
[2022-06-10 06:42:00 | train] - Train Epoch: [92] [704000/1281167 (55%)]	Loss: 0.998984
[2022-06-10 06:42:20 | train] - Train Epoch: [92] [716800/1281167 (56%)]	Loss: 0.826697
[2022-06-10 06:42:40 | train] - Train Epoch: [92] [729600/1281167 (57%)]	Loss: 0.888869
[2022-06-10 06:43:00 | train] - Train Epoch: [92] [742400/1281167 (58%)]	Loss: 0.634842
[2022-06-10 06:43:20 | train] - Train Epoch: [92] [755200/1281167 (59%)]	Loss: 1.004198
[2022-06-10 06:43:40 | train] - Train Epoch: [92] [768000/1281167 (60%)]	Loss: 0.861719
[2022-06-10 06:44:00 | train] - Train Epoch: [92] [780800/1281167 (61%)]	Loss: 0.729082
[2022-06-10 06:44:20 | train] - Train Epoch: [92] [793600/1281167 (62%)]	Loss: 0.840641
[2022-06-10 06:44:40 | train] - Train Epoch: [92] [806400/1281167 (63%)]	Loss: 0.875627
[2022-06-10 06:45:00 | train] - Train Epoch: [92] [819200/1281167 (64%)]	Loss: 0.833357
[2022-06-10 06:45:20 | train] - Train Epoch: [92] [832000/1281167 (65%)]	Loss: 0.968250
[2022-06-10 06:45:40 | train] - Train Epoch: [92] [844800/1281167 (66%)]	Loss: 0.983031
[2022-06-10 06:46:00 | train] - Train Epoch: [92] [857600/1281167 (67%)]	Loss: 0.756877
[2022-06-10 06:46:20 | train] - Train Epoch: [92] [870400/1281167 (68%)]	Loss: 1.089717
[2022-06-10 06:46:40 | train] - Train Epoch: [92] [883200/1281167 (69%)]	Loss: 0.803380
[2022-06-10 06:47:00 | train] - Train Epoch: [92] [896000/1281167 (70%)]	Loss: 0.736910
[2022-06-10 06:47:20 | train] - Train Epoch: [92] [908800/1281167 (71%)]	Loss: 0.937174
[2022-06-10 06:47:41 | train] - Train Epoch: [92] [921600/1281167 (72%)]	Loss: 1.042743
[2022-06-10 06:48:01 | train] - Train Epoch: [92] [934400/1281167 (73%)]	Loss: 0.827960
[2022-06-10 06:48:21 | train] - Train Epoch: [92] [947200/1281167 (74%)]	Loss: 0.992614
[2022-06-10 06:48:41 | train] - Train Epoch: [92] [960000/1281167 (75%)]	Loss: 0.965955
[2022-06-10 06:49:02 | train] - Train Epoch: [92] [972800/1281167 (76%)]	Loss: 0.699643
[2022-06-10 06:49:22 | train] - Train Epoch: [92] [985600/1281167 (77%)]	Loss: 0.894141
[2022-06-10 06:49:43 | train] - Train Epoch: [92] [998400/1281167 (78%)]	Loss: 0.841617
[2022-06-10 06:50:03 | train] - Train Epoch: [92] [1011200/1281167 (79%)]	Loss: 0.704321
[2022-06-10 06:50:23 | train] - Train Epoch: [92] [1024000/1281167 (80%)]	Loss: 1.149715
[2022-06-10 06:50:43 | train] - Train Epoch: [92] [1036800/1281167 (81%)]	Loss: 0.872361
[2022-06-10 06:51:03 | train] - Train Epoch: [92] [1049600/1281167 (82%)]	Loss: 0.658257
[2022-06-10 06:51:24 | train] - Train Epoch: [92] [1062400/1281167 (83%)]	Loss: 0.578981
[2022-06-10 06:51:43 | train] - Train Epoch: [92] [1075200/1281167 (84%)]	Loss: 1.021658
[2022-06-10 06:52:03 | train] - Train Epoch: [92] [1088000/1281167 (85%)]	Loss: 1.085702
[2022-06-10 06:52:23 | train] - Train Epoch: [92] [1100800/1281167 (86%)]	Loss: 0.895557
[2022-06-10 06:52:44 | train] - Train Epoch: [92] [1113600/1281167 (87%)]	Loss: 0.771915
[2022-06-10 06:53:04 | train] - Train Epoch: [92] [1126400/1281167 (88%)]	Loss: 0.856158
[2022-06-10 06:53:24 | train] - Train Epoch: [92] [1139200/1281167 (89%)]	Loss: 0.787477
[2022-06-10 06:53:44 | train] - Train Epoch: [92] [1152000/1281167 (90%)]	Loss: 1.024471
[2022-06-10 06:54:04 | train] - Train Epoch: [92] [1164800/1281167 (91%)]	Loss: 1.199864
[2022-06-10 06:54:24 | train] - Train Epoch: [92] [1177600/1281167 (92%)]	Loss: 0.887254
[2022-06-10 06:54:45 | train] - Train Epoch: [92] [1190400/1281167 (93%)]	Loss: 0.826259
[2022-06-10 06:55:05 | train] - Train Epoch: [92] [1203200/1281167 (94%)]	Loss: 0.883927
[2022-06-10 06:55:25 | train] - Train Epoch: [92] [1216000/1281167 (95%)]	Loss: 0.871301
[2022-06-10 06:55:45 | train] - Train Epoch: [92] [1228800/1281167 (96%)]	Loss: 1.095881
[2022-06-10 06:56:05 | train] - Train Epoch: [92] [1241600/1281167 (97%)]	Loss: 0.824396
[2022-06-10 06:56:25 | train] - Train Epoch: [92] [1254400/1281167 (98%)]	Loss: 0.623847
[2022-06-10 06:56:46 | train] - Train Epoch: [92] [1267200/1281167 (99%)]	Loss: 0.993499
[2022-06-10 06:57:06 | train] - Train Epoch: [92] [1280000/1281167 (100%)]	Loss: 0.899497
[2022-06-10 06:57:07 | train] - Train Epoch: [92]	 Average Loss: 0.875468	 Total Acc : 78.6428	 Total Top5 Acc : 92.1070
[2022-06-10 06:57:07 | train] - -------92 epoch end-----------
========================================
-------92 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 06:58:42 | train] - 
Epoch [92] Test set: Average loss: 1.3737, Accuracy: 34883/50000 (69.7374%), Top-5 Accuracy: 88.9434%

[2022-06-10 06:58:42 | train] - save intermediate epoch [92] result


[2022-06-10 06:59:07 | train] - -------93 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 06:59:09 | train] - Train Epoch: [93] [0/1281167 (0%)]	Loss: 0.699229
[2022-06-10 06:59:31 | train] - Train Epoch: [93] [12800/1281167 (1%)]	Loss: 0.975235
[2022-06-10 06:59:52 | train] - Train Epoch: [93] [25600/1281167 (2%)]	Loss: 1.096750
[2022-06-10 07:00:14 | train] - Train Epoch: [93] [38400/1281167 (3%)]	Loss: 1.119128
[2022-06-10 07:00:36 | train] - Train Epoch: [93] [51200/1281167 (4%)]	Loss: 0.644671
[2022-06-10 07:00:58 | train] - Train Epoch: [93] [64000/1281167 (5%)]	Loss: 1.057749
[2022-06-10 07:01:20 | train] - Train Epoch: [93] [76800/1281167 (6%)]	Loss: 0.724963
[2022-06-10 07:01:42 | train] - Train Epoch: [93] [89600/1281167 (7%)]	Loss: 0.978836
[2022-06-10 07:02:03 | train] - Train Epoch: [93] [102400/1281167 (8%)]	Loss: 0.706451
[2022-06-10 07:02:25 | train] - Train Epoch: [93] [115200/1281167 (9%)]	Loss: 0.851632
[2022-06-10 07:02:46 | train] - Train Epoch: [93] [128000/1281167 (10%)]	Loss: 1.051745
[2022-06-10 07:03:08 | train] - Train Epoch: [93] [140800/1281167 (11%)]	Loss: 0.890346
[2022-06-10 07:03:29 | train] - Train Epoch: [93] [153600/1281167 (12%)]	Loss: 0.883741
[2022-06-10 07:03:51 | train] - Train Epoch: [93] [166400/1281167 (13%)]	Loss: 0.816658
[2022-06-10 07:04:12 | train] - Train Epoch: [93] [179200/1281167 (14%)]	Loss: 0.724512
[2022-06-10 07:04:34 | train] - Train Epoch: [93] [192000/1281167 (15%)]	Loss: 0.917349
[2022-06-10 07:04:56 | train] - Train Epoch: [93] [204800/1281167 (16%)]	Loss: 0.850818
[2022-06-10 07:05:17 | train] - Train Epoch: [93] [217600/1281167 (17%)]	Loss: 1.000124
[2022-06-10 07:05:39 | train] - Train Epoch: [93] [230400/1281167 (18%)]	Loss: 0.768435
[2022-06-10 07:06:01 | train] - Train Epoch: [93] [243200/1281167 (19%)]	Loss: 0.891653
[2022-06-10 07:06:22 | train] - Train Epoch: [93] [256000/1281167 (20%)]	Loss: 0.888399
[2022-06-10 07:06:45 | train] - Train Epoch: [93] [268800/1281167 (21%)]	Loss: 0.717815
[2022-06-10 07:07:06 | train] - Train Epoch: [93] [281600/1281167 (22%)]	Loss: 0.853291
[2022-06-10 07:07:28 | train] - Train Epoch: [93] [294400/1281167 (23%)]	Loss: 0.556642
[2022-06-10 07:07:49 | train] - Train Epoch: [93] [307200/1281167 (24%)]	Loss: 1.029041
[2022-06-10 07:08:11 | train] - Train Epoch: [93] [320000/1281167 (25%)]	Loss: 0.868364
[2022-06-10 07:08:32 | train] - Train Epoch: [93] [332800/1281167 (26%)]	Loss: 0.802589
[2022-06-10 07:08:54 | train] - Train Epoch: [93] [345600/1281167 (27%)]	Loss: 0.823035
[2022-06-10 07:09:16 | train] - Train Epoch: [93] [358400/1281167 (28%)]	Loss: 0.706710
[2022-06-10 07:09:38 | train] - Train Epoch: [93] [371200/1281167 (29%)]	Loss: 0.715736
[2022-06-10 07:10:00 | train] - Train Epoch: [93] [384000/1281167 (30%)]	Loss: 0.753675
[2022-06-10 07:10:22 | train] - Train Epoch: [93] [396800/1281167 (31%)]	Loss: 0.947510
[2022-06-10 07:10:44 | train] - Train Epoch: [93] [409600/1281167 (32%)]	Loss: 0.665983
[2022-06-10 07:11:05 | train] - Train Epoch: [93] [422400/1281167 (33%)]	Loss: 0.904980
[2022-06-10 07:11:28 | train] - Train Epoch: [93] [435200/1281167 (34%)]	Loss: 0.608187
[2022-06-10 07:11:49 | train] - Train Epoch: [93] [448000/1281167 (35%)]	Loss: 0.716494
[2022-06-10 07:12:11 | train] - Train Epoch: [93] [460800/1281167 (36%)]	Loss: 0.703874
[2022-06-10 07:12:32 | train] - Train Epoch: [93] [473600/1281167 (37%)]	Loss: 0.822668
[2022-06-10 07:12:55 | train] - Train Epoch: [93] [486400/1281167 (38%)]	Loss: 1.014536
[2022-06-10 07:13:16 | train] - Train Epoch: [93] [499200/1281167 (39%)]	Loss: 0.893096
[2022-06-10 07:13:38 | train] - Train Epoch: [93] [512000/1281167 (40%)]	Loss: 0.670728
[2022-06-10 07:14:00 | train] - Train Epoch: [93] [524800/1281167 (41%)]	Loss: 1.180149
[2022-06-10 07:14:22 | train] - Train Epoch: [93] [537600/1281167 (42%)]	Loss: 1.187822
[2022-06-10 07:14:44 | train] - Train Epoch: [93] [550400/1281167 (43%)]	Loss: 0.664355
[2022-06-10 07:15:06 | train] - Train Epoch: [93] [563200/1281167 (44%)]	Loss: 0.762666
[2022-06-10 07:15:28 | train] - Train Epoch: [93] [576000/1281167 (45%)]	Loss: 0.994327
[2022-06-10 07:15:50 | train] - Train Epoch: [93] [588800/1281167 (46%)]	Loss: 0.784623
[2022-06-10 07:16:12 | train] - Train Epoch: [93] [601600/1281167 (47%)]	Loss: 0.999430
[2022-06-10 07:16:34 | train] - Train Epoch: [93] [614400/1281167 (48%)]	Loss: 0.824503
[2022-06-10 07:16:56 | train] - Train Epoch: [93] [627200/1281167 (49%)]	Loss: 0.903755
[2022-06-10 07:17:17 | train] - Train Epoch: [93] [640000/1281167 (50%)]	Loss: 1.037522
[2022-06-10 07:17:40 | train] - Train Epoch: [93] [652800/1281167 (51%)]	Loss: 0.977836
[2022-06-10 07:18:02 | train] - Train Epoch: [93] [665600/1281167 (52%)]	Loss: 0.988363
[2022-06-10 07:18:24 | train] - Train Epoch: [93] [678400/1281167 (53%)]	Loss: 0.875004
[2022-06-10 07:18:47 | train] - Train Epoch: [93] [691200/1281167 (54%)]	Loss: 1.120640
[2022-06-10 07:19:09 | train] - Train Epoch: [93] [704000/1281167 (55%)]	Loss: 1.004180
[2022-06-10 07:19:30 | train] - Train Epoch: [93] [716800/1281167 (56%)]	Loss: 0.979728
[2022-06-10 07:19:51 | train] - Train Epoch: [93] [729600/1281167 (57%)]	Loss: 0.636889
[2022-06-10 07:20:13 | train] - Train Epoch: [93] [742400/1281167 (58%)]	Loss: 0.825738
[2022-06-10 07:20:34 | train] - Train Epoch: [93] [755200/1281167 (59%)]	Loss: 0.871634
[2022-06-10 07:20:55 | train] - Train Epoch: [93] [768000/1281167 (60%)]	Loss: 0.953914
[2022-06-10 07:21:17 | train] - Train Epoch: [93] [780800/1281167 (61%)]	Loss: 1.062315
[2022-06-10 07:21:38 | train] - Train Epoch: [93] [793600/1281167 (62%)]	Loss: 0.968611
[2022-06-10 07:22:00 | train] - Train Epoch: [93] [806400/1281167 (63%)]	Loss: 1.147566
[2022-06-10 07:22:21 | train] - Train Epoch: [93] [819200/1281167 (64%)]	Loss: 0.880011
[2022-06-10 07:22:42 | train] - Train Epoch: [93] [832000/1281167 (65%)]	Loss: 0.816411
[2022-06-10 07:23:04 | train] - Train Epoch: [93] [844800/1281167 (66%)]	Loss: 1.037438
[2022-06-10 07:23:25 | train] - Train Epoch: [93] [857600/1281167 (67%)]	Loss: 1.102533
[2022-06-10 07:23:46 | train] - Train Epoch: [93] [870400/1281167 (68%)]	Loss: 0.817781
[2022-06-10 07:24:07 | train] - Train Epoch: [93] [883200/1281167 (69%)]	Loss: 0.925353
[2022-06-10 07:24:29 | train] - Train Epoch: [93] [896000/1281167 (70%)]	Loss: 0.863917
[2022-06-10 07:24:49 | train] - Train Epoch: [93] [908800/1281167 (71%)]	Loss: 0.790746
[2022-06-10 07:25:11 | train] - Train Epoch: [93] [921600/1281167 (72%)]	Loss: 1.075593
[2022-06-10 07:25:33 | train] - Train Epoch: [93] [934400/1281167 (73%)]	Loss: 0.842066
[2022-06-10 07:25:54 | train] - Train Epoch: [93] [947200/1281167 (74%)]	Loss: 1.181438
[2022-06-10 07:26:15 | train] - Train Epoch: [93] [960000/1281167 (75%)]	Loss: 1.082901
[2022-06-10 07:26:36 | train] - Train Epoch: [93] [972800/1281167 (76%)]	Loss: 0.948890
[2022-06-10 07:26:58 | train] - Train Epoch: [93] [985600/1281167 (77%)]	Loss: 0.774888
[2022-06-10 07:27:20 | train] - Train Epoch: [93] [998400/1281167 (78%)]	Loss: 0.759103
[2022-06-10 07:27:42 | train] - Train Epoch: [93] [1011200/1281167 (79%)]	Loss: 0.771555
[2022-06-10 07:28:03 | train] - Train Epoch: [93] [1024000/1281167 (80%)]	Loss: 0.847014
[2022-06-10 07:28:25 | train] - Train Epoch: [93] [1036800/1281167 (81%)]	Loss: 1.084043
[2022-06-10 07:28:45 | train] - Train Epoch: [93] [1049600/1281167 (82%)]	Loss: 0.774885
[2022-06-10 07:29:07 | train] - Train Epoch: [93] [1062400/1281167 (83%)]	Loss: 0.827135
[2022-06-10 07:29:29 | train] - Train Epoch: [93] [1075200/1281167 (84%)]	Loss: 0.875375
[2022-06-10 07:29:51 | train] - Train Epoch: [93] [1088000/1281167 (85%)]	Loss: 0.995379
[2022-06-10 07:30:13 | train] - Train Epoch: [93] [1100800/1281167 (86%)]	Loss: 0.844091
[2022-06-10 07:30:35 | train] - Train Epoch: [93] [1113600/1281167 (87%)]	Loss: 1.050964
[2022-06-10 07:30:57 | train] - Train Epoch: [93] [1126400/1281167 (88%)]	Loss: 0.734706
[2022-06-10 07:31:19 | train] - Train Epoch: [93] [1139200/1281167 (89%)]	Loss: 1.365593
[2022-06-10 07:31:41 | train] - Train Epoch: [93] [1152000/1281167 (90%)]	Loss: 0.969787
[2022-06-10 07:32:02 | train] - Train Epoch: [93] [1164800/1281167 (91%)]	Loss: 0.635410
[2022-06-10 07:32:23 | train] - Train Epoch: [93] [1177600/1281167 (92%)]	Loss: 0.748946
[2022-06-10 07:32:45 | train] - Train Epoch: [93] [1190400/1281167 (93%)]	Loss: 0.902060
[2022-06-10 07:33:06 | train] - Train Epoch: [93] [1203200/1281167 (94%)]	Loss: 0.713357
[2022-06-10 07:33:28 | train] - Train Epoch: [93] [1216000/1281167 (95%)]	Loss: 0.984933
[2022-06-10 07:33:50 | train] - Train Epoch: [93] [1228800/1281167 (96%)]	Loss: 0.879666
[2022-06-10 07:34:11 | train] - Train Epoch: [93] [1241600/1281167 (97%)]	Loss: 0.905044
[2022-06-10 07:34:32 | train] - Train Epoch: [93] [1254400/1281167 (98%)]	Loss: 0.781235
[2022-06-10 07:34:54 | train] - Train Epoch: [93] [1267200/1281167 (99%)]	Loss: 1.103912
[2022-06-10 07:35:15 | train] - Train Epoch: [93] [1280000/1281167 (100%)]	Loss: 1.101504
[2022-06-10 07:35:17 | train] - Train Epoch: [93]	 Average Loss: 0.874343	 Total Acc : 78.6132	 Total Top5 Acc : 92.1410
[2022-06-10 07:35:17 | train] - -------93 epoch end-----------
========================================
-------93 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 07:36:51 | train] - 
Epoch [93] Test set: Average loss: 1.3771, Accuracy: 35002/50000 (69.9728%), Top-5 Accuracy: 88.8775%

[2022-06-10 07:36:51 | train] - save intermediate epoch [93] result


[2022-06-10 07:37:19 | train] - -------94 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 07:37:20 | train] - Train Epoch: [94] [0/1281167 (0%)]	Loss: 0.599411
[2022-06-10 07:37:42 | train] - Train Epoch: [94] [12800/1281167 (1%)]	Loss: 0.924036
[2022-06-10 07:38:02 | train] - Train Epoch: [94] [25600/1281167 (2%)]	Loss: 1.038037
[2022-06-10 07:38:24 | train] - Train Epoch: [94] [38400/1281167 (3%)]	Loss: 0.799397
[2022-06-10 07:38:45 | train] - Train Epoch: [94] [51200/1281167 (4%)]	Loss: 0.801381
[2022-06-10 07:39:07 | train] - Train Epoch: [94] [64000/1281167 (5%)]	Loss: 0.724609
[2022-06-10 07:39:28 | train] - Train Epoch: [94] [76800/1281167 (6%)]	Loss: 1.003332
[2022-06-10 07:39:50 | train] - Train Epoch: [94] [89600/1281167 (7%)]	Loss: 0.911457
[2022-06-10 07:40:12 | train] - Train Epoch: [94] [102400/1281167 (8%)]	Loss: 0.897426
[2022-06-10 07:40:33 | train] - Train Epoch: [94] [115200/1281167 (9%)]	Loss: 1.080007
[2022-06-10 07:40:55 | train] - Train Epoch: [94] [128000/1281167 (10%)]	Loss: 0.985844
[2022-06-10 07:41:16 | train] - Train Epoch: [94] [140800/1281167 (11%)]	Loss: 0.570650
[2022-06-10 07:41:37 | train] - Train Epoch: [94] [153600/1281167 (12%)]	Loss: 0.785123
[2022-06-10 07:41:58 | train] - Train Epoch: [94] [166400/1281167 (13%)]	Loss: 0.805304
[2022-06-10 07:42:20 | train] - Train Epoch: [94] [179200/1281167 (14%)]	Loss: 0.812407
[2022-06-10 07:42:41 | train] - Train Epoch: [94] [192000/1281167 (15%)]	Loss: 0.603232
[2022-06-10 07:43:02 | train] - Train Epoch: [94] [204800/1281167 (16%)]	Loss: 1.106629
[2022-06-10 07:43:24 | train] - Train Epoch: [94] [217600/1281167 (17%)]	Loss: 0.690019
[2022-06-10 07:43:45 | train] - Train Epoch: [94] [230400/1281167 (18%)]	Loss: 0.872347
[2022-06-10 07:44:06 | train] - Train Epoch: [94] [243200/1281167 (19%)]	Loss: 1.053645
[2022-06-10 07:44:27 | train] - Train Epoch: [94] [256000/1281167 (20%)]	Loss: 0.918775
[2022-06-10 07:44:48 | train] - Train Epoch: [94] [268800/1281167 (21%)]	Loss: 0.981477
[2022-06-10 07:45:10 | train] - Train Epoch: [94] [281600/1281167 (22%)]	Loss: 0.981080
[2022-06-10 07:45:31 | train] - Train Epoch: [94] [294400/1281167 (23%)]	Loss: 0.949761
[2022-06-10 07:45:52 | train] - Train Epoch: [94] [307200/1281167 (24%)]	Loss: 1.084499
[2022-06-10 07:46:12 | train] - Train Epoch: [94] [320000/1281167 (25%)]	Loss: 0.722059
[2022-06-10 07:46:33 | train] - Train Epoch: [94] [332800/1281167 (26%)]	Loss: 0.780338
[2022-06-10 07:46:56 | train] - Train Epoch: [94] [345600/1281167 (27%)]	Loss: 1.142063
[2022-06-10 07:47:16 | train] - Train Epoch: [94] [358400/1281167 (28%)]	Loss: 0.715606
[2022-06-10 07:47:37 | train] - Train Epoch: [94] [371200/1281167 (29%)]	Loss: 0.853402
[2022-06-10 07:47:58 | train] - Train Epoch: [94] [384000/1281167 (30%)]	Loss: 0.767086
[2022-06-10 07:48:19 | train] - Train Epoch: [94] [396800/1281167 (31%)]	Loss: 0.893602
[2022-06-10 07:48:40 | train] - Train Epoch: [94] [409600/1281167 (32%)]	Loss: 0.933483
[2022-06-10 07:49:02 | train] - Train Epoch: [94] [422400/1281167 (33%)]	Loss: 0.696511
[2022-06-10 07:49:23 | train] - Train Epoch: [94] [435200/1281167 (34%)]	Loss: 0.730657
[2022-06-10 07:49:44 | train] - Train Epoch: [94] [448000/1281167 (35%)]	Loss: 1.034293
[2022-06-10 07:50:06 | train] - Train Epoch: [94] [460800/1281167 (36%)]	Loss: 0.923937
[2022-06-10 07:50:26 | train] - Train Epoch: [94] [473600/1281167 (37%)]	Loss: 1.030560
[2022-06-10 07:50:48 | train] - Train Epoch: [94] [486400/1281167 (38%)]	Loss: 0.970812
[2022-06-10 07:51:10 | train] - Train Epoch: [94] [499200/1281167 (39%)]	Loss: 0.876694
[2022-06-10 07:51:32 | train] - Train Epoch: [94] [512000/1281167 (40%)]	Loss: 0.761609
[2022-06-10 07:51:52 | train] - Train Epoch: [94] [524800/1281167 (41%)]	Loss: 0.961746
[2022-06-10 07:52:13 | train] - Train Epoch: [94] [537600/1281167 (42%)]	Loss: 0.941099
[2022-06-10 07:52:35 | train] - Train Epoch: [94] [550400/1281167 (43%)]	Loss: 1.017641
[2022-06-10 07:52:57 | train] - Train Epoch: [94] [563200/1281167 (44%)]	Loss: 0.918654
[2022-06-10 07:53:19 | train] - Train Epoch: [94] [576000/1281167 (45%)]	Loss: 0.938048
[2022-06-10 07:53:41 | train] - Train Epoch: [94] [588800/1281167 (46%)]	Loss: 0.947564
[2022-06-10 07:54:03 | train] - Train Epoch: [94] [601600/1281167 (47%)]	Loss: 0.945288
[2022-06-10 07:54:25 | train] - Train Epoch: [94] [614400/1281167 (48%)]	Loss: 0.793461
[2022-06-10 07:54:46 | train] - Train Epoch: [94] [627200/1281167 (49%)]	Loss: 0.694431
[2022-06-10 07:55:07 | train] - Train Epoch: [94] [640000/1281167 (50%)]	Loss: 1.084697
[2022-06-10 07:55:28 | train] - Train Epoch: [94] [652800/1281167 (51%)]	Loss: 0.905625
[2022-06-10 07:55:49 | train] - Train Epoch: [94] [665600/1281167 (52%)]	Loss: 1.140299
[2022-06-10 07:56:10 | train] - Train Epoch: [94] [678400/1281167 (53%)]	Loss: 0.752967
[2022-06-10 07:56:32 | train] - Train Epoch: [94] [691200/1281167 (54%)]	Loss: 0.787876
[2022-06-10 07:56:54 | train] - Train Epoch: [94] [704000/1281167 (55%)]	Loss: 1.151399
[2022-06-10 07:57:16 | train] - Train Epoch: [94] [716800/1281167 (56%)]	Loss: 0.854928
[2022-06-10 07:57:37 | train] - Train Epoch: [94] [729600/1281167 (57%)]	Loss: 0.737681
[2022-06-10 07:57:58 | train] - Train Epoch: [94] [742400/1281167 (58%)]	Loss: 1.077648
[2022-06-10 07:58:19 | train] - Train Epoch: [94] [755200/1281167 (59%)]	Loss: 0.921990
[2022-06-10 07:58:40 | train] - Train Epoch: [94] [768000/1281167 (60%)]	Loss: 0.871638
[2022-06-10 07:59:02 | train] - Train Epoch: [94] [780800/1281167 (61%)]	Loss: 0.723218
[2022-06-10 07:59:23 | train] - Train Epoch: [94] [793600/1281167 (62%)]	Loss: 1.050627
[2022-06-10 07:59:44 | train] - Train Epoch: [94] [806400/1281167 (63%)]	Loss: 0.809143
[2022-06-10 08:00:06 | train] - Train Epoch: [94] [819200/1281167 (64%)]	Loss: 0.879530
[2022-06-10 08:00:27 | train] - Train Epoch: [94] [832000/1281167 (65%)]	Loss: 1.086470
[2022-06-10 08:00:49 | train] - Train Epoch: [94] [844800/1281167 (66%)]	Loss: 0.730853
[2022-06-10 08:01:11 | train] - Train Epoch: [94] [857600/1281167 (67%)]	Loss: 0.833383
[2022-06-10 08:01:32 | train] - Train Epoch: [94] [870400/1281167 (68%)]	Loss: 0.937934
[2022-06-10 08:01:53 | train] - Train Epoch: [94] [883200/1281167 (69%)]	Loss: 1.003430
[2022-06-10 08:02:14 | train] - Train Epoch: [94] [896000/1281167 (70%)]	Loss: 1.194643
[2022-06-10 08:02:36 | train] - Train Epoch: [94] [908800/1281167 (71%)]	Loss: 0.515610
[2022-06-10 08:02:58 | train] - Train Epoch: [94] [921600/1281167 (72%)]	Loss: 0.992403
[2022-06-10 08:03:19 | train] - Train Epoch: [94] [934400/1281167 (73%)]	Loss: 0.630775
[2022-06-10 08:03:41 | train] - Train Epoch: [94] [947200/1281167 (74%)]	Loss: 0.837442
[2022-06-10 08:04:03 | train] - Train Epoch: [94] [960000/1281167 (75%)]	Loss: 1.161572
[2022-06-10 08:04:24 | train] - Train Epoch: [94] [972800/1281167 (76%)]	Loss: 0.908388
[2022-06-10 08:04:46 | train] - Train Epoch: [94] [985600/1281167 (77%)]	Loss: 0.775627
[2022-06-10 08:05:08 | train] - Train Epoch: [94] [998400/1281167 (78%)]	Loss: 0.546328
[2022-06-10 08:05:28 | train] - Train Epoch: [94] [1011200/1281167 (79%)]	Loss: 0.582062
[2022-06-10 08:05:50 | train] - Train Epoch: [94] [1024000/1281167 (80%)]	Loss: 0.920732
[2022-06-10 08:06:11 | train] - Train Epoch: [94] [1036800/1281167 (81%)]	Loss: 0.858973
[2022-06-10 08:06:33 | train] - Train Epoch: [94] [1049600/1281167 (82%)]	Loss: 1.017064
[2022-06-10 08:06:53 | train] - Train Epoch: [94] [1062400/1281167 (83%)]	Loss: 1.029517
[2022-06-10 08:07:15 | train] - Train Epoch: [94] [1075200/1281167 (84%)]	Loss: 0.857447
[2022-06-10 08:07:36 | train] - Train Epoch: [94] [1088000/1281167 (85%)]	Loss: 0.817897
[2022-06-10 08:07:58 | train] - Train Epoch: [94] [1100800/1281167 (86%)]	Loss: 0.798274
[2022-06-10 08:08:19 | train] - Train Epoch: [94] [1113600/1281167 (87%)]	Loss: 0.995441
[2022-06-10 08:08:40 | train] - Train Epoch: [94] [1126400/1281167 (88%)]	Loss: 0.738879
[2022-06-10 08:09:01 | train] - Train Epoch: [94] [1139200/1281167 (89%)]	Loss: 0.906218
[2022-06-10 08:09:23 | train] - Train Epoch: [94] [1152000/1281167 (90%)]	Loss: 0.899571
[2022-06-10 08:09:45 | train] - Train Epoch: [94] [1164800/1281167 (91%)]	Loss: 0.952205
[2022-06-10 08:10:06 | train] - Train Epoch: [94] [1177600/1281167 (92%)]	Loss: 0.816057
[2022-06-10 08:10:28 | train] - Train Epoch: [94] [1190400/1281167 (93%)]	Loss: 0.999734
[2022-06-10 08:10:49 | train] - Train Epoch: [94] [1203200/1281167 (94%)]	Loss: 0.786849
[2022-06-10 08:11:10 | train] - Train Epoch: [94] [1216000/1281167 (95%)]	Loss: 0.963849
[2022-06-10 08:11:32 | train] - Train Epoch: [94] [1228800/1281167 (96%)]	Loss: 0.844071
[2022-06-10 08:11:53 | train] - Train Epoch: [94] [1241600/1281167 (97%)]	Loss: 0.953204
[2022-06-10 08:12:14 | train] - Train Epoch: [94] [1254400/1281167 (98%)]	Loss: 0.737019
[2022-06-10 08:12:35 | train] - Train Epoch: [94] [1267200/1281167 (99%)]	Loss: 0.938088
[2022-06-10 08:12:56 | train] - Train Epoch: [94] [1280000/1281167 (100%)]	Loss: 0.979928
[2022-06-10 08:12:58 | train] - Train Epoch: [94]	 Average Loss: 0.871074	 Total Acc : 78.7473	 Total Top5 Acc : 92.1558
[2022-06-10 08:12:58 | train] - -------94 epoch end-----------
========================================
-------94 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 08:14:30 | train] - 
Epoch [94] Test set: Average loss: 1.3694, Accuracy: 34917/50000 (69.8090%), Top-5 Accuracy: 89.0133%

[2022-06-10 08:14:30 | train] - save intermediate epoch [94] result


[2022-06-10 08:14:56 | train] - -------95 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 08:14:58 | train] - Train Epoch: [95] [0/1281167 (0%)]	Loss: 0.717470
[2022-06-10 08:15:19 | train] - Train Epoch: [95] [12800/1281167 (1%)]	Loss: 1.078250
[2022-06-10 08:15:41 | train] - Train Epoch: [95] [25600/1281167 (2%)]	Loss: 0.842445
[2022-06-10 08:16:03 | train] - Train Epoch: [95] [38400/1281167 (3%)]	Loss: 0.929076
[2022-06-10 08:16:25 | train] - Train Epoch: [95] [51200/1281167 (4%)]	Loss: 0.813432
[2022-06-10 08:16:47 | train] - Train Epoch: [95] [64000/1281167 (5%)]	Loss: 0.941735
[2022-06-10 08:17:09 | train] - Train Epoch: [95] [76800/1281167 (6%)]	Loss: 0.976754
[2022-06-10 08:17:31 | train] - Train Epoch: [95] [89600/1281167 (7%)]	Loss: 1.078247
[2022-06-10 08:17:53 | train] - Train Epoch: [95] [102400/1281167 (8%)]	Loss: 0.722372
[2022-06-10 08:18:16 | train] - Train Epoch: [95] [115200/1281167 (9%)]	Loss: 1.010934
[2022-06-10 08:18:38 | train] - Train Epoch: [95] [128000/1281167 (10%)]	Loss: 1.146623
[2022-06-10 08:18:59 | train] - Train Epoch: [95] [140800/1281167 (11%)]	Loss: 0.875075
[2022-06-10 08:19:21 | train] - Train Epoch: [95] [153600/1281167 (12%)]	Loss: 0.968387
[2022-06-10 08:19:42 | train] - Train Epoch: [95] [166400/1281167 (13%)]	Loss: 0.629691
[2022-06-10 08:20:04 | train] - Train Epoch: [95] [179200/1281167 (14%)]	Loss: 0.674107
[2022-06-10 08:20:26 | train] - Train Epoch: [95] [192000/1281167 (15%)]	Loss: 0.714889
[2022-06-10 08:20:47 | train] - Train Epoch: [95] [204800/1281167 (16%)]	Loss: 0.919020
[2022-06-10 08:21:08 | train] - Train Epoch: [95] [217600/1281167 (17%)]	Loss: 0.751629
[2022-06-10 08:21:31 | train] - Train Epoch: [95] [230400/1281167 (18%)]	Loss: 0.864980
[2022-06-10 08:21:53 | train] - Train Epoch: [95] [243200/1281167 (19%)]	Loss: 0.878839
[2022-06-10 08:22:15 | train] - Train Epoch: [95] [256000/1281167 (20%)]	Loss: 0.973844
[2022-06-10 08:22:36 | train] - Train Epoch: [95] [268800/1281167 (21%)]	Loss: 1.006543
[2022-06-10 08:22:58 | train] - Train Epoch: [95] [281600/1281167 (22%)]	Loss: 1.044145
[2022-06-10 08:23:20 | train] - Train Epoch: [95] [294400/1281167 (23%)]	Loss: 1.079721
[2022-06-10 08:23:41 | train] - Train Epoch: [95] [307200/1281167 (24%)]	Loss: 0.866387
[2022-06-10 08:24:02 | train] - Train Epoch: [95] [320000/1281167 (25%)]	Loss: 0.949536
[2022-06-10 08:24:23 | train] - Train Epoch: [95] [332800/1281167 (26%)]	Loss: 0.720022
[2022-06-10 08:24:44 | train] - Train Epoch: [95] [345600/1281167 (27%)]	Loss: 0.631861
[2022-06-10 08:25:06 | train] - Train Epoch: [95] [358400/1281167 (28%)]	Loss: 0.957578
[2022-06-10 08:25:27 | train] - Train Epoch: [95] [371200/1281167 (29%)]	Loss: 0.953802
[2022-06-10 08:25:48 | train] - Train Epoch: [95] [384000/1281167 (30%)]	Loss: 0.794509
[2022-06-10 08:26:09 | train] - Train Epoch: [95] [396800/1281167 (31%)]	Loss: 0.860030
[2022-06-10 08:26:30 | train] - Train Epoch: [95] [409600/1281167 (32%)]	Loss: 0.868761
[2022-06-10 08:26:52 | train] - Train Epoch: [95] [422400/1281167 (33%)]	Loss: 0.927424
[2022-06-10 08:27:13 | train] - Train Epoch: [95] [435200/1281167 (34%)]	Loss: 0.846533
[2022-06-10 08:27:35 | train] - Train Epoch: [95] [448000/1281167 (35%)]	Loss: 0.822439
[2022-06-10 08:27:57 | train] - Train Epoch: [95] [460800/1281167 (36%)]	Loss: 0.816358
[2022-06-10 08:28:19 | train] - Train Epoch: [95] [473600/1281167 (37%)]	Loss: 0.932630
[2022-06-10 08:28:41 | train] - Train Epoch: [95] [486400/1281167 (38%)]	Loss: 0.729786
[2022-06-10 08:29:03 | train] - Train Epoch: [95] [499200/1281167 (39%)]	Loss: 0.891480
[2022-06-10 08:29:25 | train] - Train Epoch: [95] [512000/1281167 (40%)]	Loss: 0.814356
[2022-06-10 08:29:47 | train] - Train Epoch: [95] [524800/1281167 (41%)]	Loss: 0.796625
[2022-06-10 08:30:08 | train] - Train Epoch: [95] [537600/1281167 (42%)]	Loss: 0.664124
[2022-06-10 08:30:30 | train] - Train Epoch: [95] [550400/1281167 (43%)]	Loss: 0.915371
[2022-06-10 08:30:50 | train] - Train Epoch: [95] [563200/1281167 (44%)]	Loss: 0.943434
[2022-06-10 08:31:12 | train] - Train Epoch: [95] [576000/1281167 (45%)]	Loss: 1.006289
[2022-06-10 08:31:33 | train] - Train Epoch: [95] [588800/1281167 (46%)]	Loss: 0.730766
[2022-06-10 08:31:55 | train] - Train Epoch: [95] [601600/1281167 (47%)]	Loss: 0.889721
[2022-06-10 08:32:16 | train] - Train Epoch: [95] [614400/1281167 (48%)]	Loss: 0.646218
[2022-06-10 08:32:37 | train] - Train Epoch: [95] [627200/1281167 (49%)]	Loss: 0.809074
[2022-06-10 08:32:59 | train] - Train Epoch: [95] [640000/1281167 (50%)]	Loss: 1.009546
[2022-06-10 08:33:20 | train] - Train Epoch: [95] [652800/1281167 (51%)]	Loss: 0.687115
[2022-06-10 08:33:41 | train] - Train Epoch: [95] [665600/1281167 (52%)]	Loss: 0.857867
[2022-06-10 08:34:04 | train] - Train Epoch: [95] [678400/1281167 (53%)]	Loss: 0.600299
[2022-06-10 08:34:25 | train] - Train Epoch: [95] [691200/1281167 (54%)]	Loss: 0.624499
[2022-06-10 08:34:46 | train] - Train Epoch: [95] [704000/1281167 (55%)]	Loss: 1.110537
[2022-06-10 08:35:08 | train] - Train Epoch: [95] [716800/1281167 (56%)]	Loss: 0.872247
[2022-06-10 08:35:30 | train] - Train Epoch: [95] [729600/1281167 (57%)]	Loss: 0.854280
[2022-06-10 08:35:51 | train] - Train Epoch: [95] [742400/1281167 (58%)]	Loss: 0.631891
[2022-06-10 08:36:12 | train] - Train Epoch: [95] [755200/1281167 (59%)]	Loss: 0.824883
[2022-06-10 08:36:34 | train] - Train Epoch: [95] [768000/1281167 (60%)]	Loss: 0.829684
[2022-06-10 08:36:55 | train] - Train Epoch: [95] [780800/1281167 (61%)]	Loss: 0.723021
[2022-06-10 08:37:16 | train] - Train Epoch: [95] [793600/1281167 (62%)]	Loss: 1.128574
[2022-06-10 08:37:37 | train] - Train Epoch: [95] [806400/1281167 (63%)]	Loss: 1.133872
[2022-06-10 08:37:58 | train] - Train Epoch: [95] [819200/1281167 (64%)]	Loss: 0.868969
[2022-06-10 08:38:19 | train] - Train Epoch: [95] [832000/1281167 (65%)]	Loss: 0.804235
[2022-06-10 08:38:41 | train] - Train Epoch: [95] [844800/1281167 (66%)]	Loss: 0.631121
[2022-06-10 08:39:02 | train] - Train Epoch: [95] [857600/1281167 (67%)]	Loss: 0.694123
[2022-06-10 08:39:24 | train] - Train Epoch: [95] [870400/1281167 (68%)]	Loss: 0.957199
[2022-06-10 08:39:46 | train] - Train Epoch: [95] [883200/1281167 (69%)]	Loss: 0.823240
[2022-06-10 08:40:07 | train] - Train Epoch: [95] [896000/1281167 (70%)]	Loss: 0.889164
[2022-06-10 08:40:29 | train] - Train Epoch: [95] [908800/1281167 (71%)]	Loss: 0.844196
[2022-06-10 08:40:50 | train] - Train Epoch: [95] [921600/1281167 (72%)]	Loss: 0.951820
[2022-06-10 08:41:10 | train] - Train Epoch: [95] [934400/1281167 (73%)]	Loss: 0.733843
[2022-06-10 08:41:31 | train] - Train Epoch: [95] [947200/1281167 (74%)]	Loss: 0.951867
[2022-06-10 08:41:52 | train] - Train Epoch: [95] [960000/1281167 (75%)]	Loss: 0.914779
[2022-06-10 08:42:14 | train] - Train Epoch: [95] [972800/1281167 (76%)]	Loss: 0.937712
[2022-06-10 08:42:35 | train] - Train Epoch: [95] [985600/1281167 (77%)]	Loss: 1.027534
[2022-06-10 08:42:57 | train] - Train Epoch: [95] [998400/1281167 (78%)]	Loss: 0.894692
[2022-06-10 08:43:18 | train] - Train Epoch: [95] [1011200/1281167 (79%)]	Loss: 1.013082
[2022-06-10 08:43:40 | train] - Train Epoch: [95] [1024000/1281167 (80%)]	Loss: 0.896503
[2022-06-10 08:44:00 | train] - Train Epoch: [95] [1036800/1281167 (81%)]	Loss: 1.102153
[2022-06-10 08:44:22 | train] - Train Epoch: [95] [1049600/1281167 (82%)]	Loss: 0.817498
[2022-06-10 08:44:44 | train] - Train Epoch: [95] [1062400/1281167 (83%)]	Loss: 0.876974
[2022-06-10 08:45:06 | train] - Train Epoch: [95] [1075200/1281167 (84%)]	Loss: 0.967002
[2022-06-10 08:45:27 | train] - Train Epoch: [95] [1088000/1281167 (85%)]	Loss: 0.977899
[2022-06-10 08:45:49 | train] - Train Epoch: [95] [1100800/1281167 (86%)]	Loss: 0.973855
[2022-06-10 08:46:10 | train] - Train Epoch: [95] [1113600/1281167 (87%)]	Loss: 0.593215
[2022-06-10 08:46:31 | train] - Train Epoch: [95] [1126400/1281167 (88%)]	Loss: 1.124641
[2022-06-10 08:46:52 | train] - Train Epoch: [95] [1139200/1281167 (89%)]	Loss: 0.798260
[2022-06-10 08:47:14 | train] - Train Epoch: [95] [1152000/1281167 (90%)]	Loss: 0.799696
[2022-06-10 08:47:36 | train] - Train Epoch: [95] [1164800/1281167 (91%)]	Loss: 0.869791
[2022-06-10 08:47:58 | train] - Train Epoch: [95] [1177600/1281167 (92%)]	Loss: 0.853361
[2022-06-10 08:48:20 | train] - Train Epoch: [95] [1190400/1281167 (93%)]	Loss: 0.921135
[2022-06-10 08:48:41 | train] - Train Epoch: [95] [1203200/1281167 (94%)]	Loss: 0.702905
[2022-06-10 08:49:02 | train] - Train Epoch: [95] [1216000/1281167 (95%)]	Loss: 1.087997
[2022-06-10 08:49:23 | train] - Train Epoch: [95] [1228800/1281167 (96%)]	Loss: 0.855408
[2022-06-10 08:49:45 | train] - Train Epoch: [95] [1241600/1281167 (97%)]	Loss: 0.784164
[2022-06-10 08:50:08 | train] - Train Epoch: [95] [1254400/1281167 (98%)]	Loss: 1.211240
[2022-06-10 08:50:28 | train] - Train Epoch: [95] [1267200/1281167 (99%)]	Loss: 0.974832
[2022-06-10 08:50:50 | train] - Train Epoch: [95] [1280000/1281167 (100%)]	Loss: 0.811892
[2022-06-10 08:50:52 | train] - Train Epoch: [95]	 Average Loss: 0.867700	 Total Acc : 78.7741	 Total Top5 Acc : 92.1831
[2022-06-10 08:50:52 | train] - -------95 epoch end-----------
========================================
-------95 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 08:52:26 | train] - 
Epoch [95] Test set: Average loss: 1.3633, Accuracy: 34941/50000 (69.8509%), Top-5 Accuracy: 88.9142%

[2022-06-10 08:52:26 | train] - save intermediate epoch [95] result


[2022-06-10 08:52:54 | train] - -------96 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 08:52:56 | train] - Train Epoch: [96] [0/1281167 (0%)]	Loss: 0.720854
[2022-06-10 08:53:18 | train] - Train Epoch: [96] [12800/1281167 (1%)]	Loss: 1.284505
[2022-06-10 08:53:39 | train] - Train Epoch: [96] [25600/1281167 (2%)]	Loss: 0.900920
[2022-06-10 08:54:00 | train] - Train Epoch: [96] [38400/1281167 (3%)]	Loss: 0.866039
[2022-06-10 08:54:22 | train] - Train Epoch: [96] [51200/1281167 (4%)]	Loss: 0.673736
[2022-06-10 08:54:43 | train] - Train Epoch: [96] [64000/1281167 (5%)]	Loss: 0.621913
[2022-06-10 08:55:06 | train] - Train Epoch: [96] [76800/1281167 (6%)]	Loss: 1.037087
[2022-06-10 08:55:27 | train] - Train Epoch: [96] [89600/1281167 (7%)]	Loss: 0.954709
[2022-06-10 08:55:48 | train] - Train Epoch: [96] [102400/1281167 (8%)]	Loss: 0.722172
[2022-06-10 08:56:09 | train] - Train Epoch: [96] [115200/1281167 (9%)]	Loss: 1.039259
[2022-06-10 08:56:30 | train] - Train Epoch: [96] [128000/1281167 (10%)]	Loss: 0.882252
[2022-06-10 08:56:51 | train] - Train Epoch: [96] [140800/1281167 (11%)]	Loss: 0.617113
[2022-06-10 08:57:13 | train] - Train Epoch: [96] [153600/1281167 (12%)]	Loss: 0.756980
[2022-06-10 08:57:34 | train] - Train Epoch: [96] [166400/1281167 (13%)]	Loss: 1.018667
[2022-06-10 08:57:55 | train] - Train Epoch: [96] [179200/1281167 (14%)]	Loss: 0.908509
[2022-06-10 08:58:15 | train] - Train Epoch: [96] [192000/1281167 (15%)]	Loss: 0.499423
[2022-06-10 08:58:35 | train] - Train Epoch: [96] [204800/1281167 (16%)]	Loss: 1.200948
[2022-06-10 08:58:55 | train] - Train Epoch: [96] [217600/1281167 (17%)]	Loss: 0.876884
[2022-06-10 08:59:14 | train] - Train Epoch: [96] [230400/1281167 (18%)]	Loss: 1.104019
[2022-06-10 08:59:34 | train] - Train Epoch: [96] [243200/1281167 (19%)]	Loss: 1.038682
[2022-06-10 08:59:54 | train] - Train Epoch: [96] [256000/1281167 (20%)]	Loss: 0.929480
[2022-06-10 09:00:15 | train] - Train Epoch: [96] [268800/1281167 (21%)]	Loss: 0.700782
[2022-06-10 09:00:35 | train] - Train Epoch: [96] [281600/1281167 (22%)]	Loss: 0.904335
[2022-06-10 09:00:55 | train] - Train Epoch: [96] [294400/1281167 (23%)]	Loss: 0.732600
[2022-06-10 09:01:15 | train] - Train Epoch: [96] [307200/1281167 (24%)]	Loss: 0.650097
[2022-06-10 09:01:35 | train] - Train Epoch: [96] [320000/1281167 (25%)]	Loss: 0.916251
[2022-06-10 09:01:55 | train] - Train Epoch: [96] [332800/1281167 (26%)]	Loss: 1.041102
[2022-06-10 09:02:15 | train] - Train Epoch: [96] [345600/1281167 (27%)]	Loss: 1.112182
[2022-06-10 09:02:35 | train] - Train Epoch: [96] [358400/1281167 (28%)]	Loss: 0.878876
[2022-06-10 09:02:55 | train] - Train Epoch: [96] [371200/1281167 (29%)]	Loss: 0.887463
[2022-06-10 09:03:15 | train] - Train Epoch: [96] [384000/1281167 (30%)]	Loss: 0.628671
[2022-06-10 09:03:35 | train] - Train Epoch: [96] [396800/1281167 (31%)]	Loss: 0.989354
[2022-06-10 09:03:55 | train] - Train Epoch: [96] [409600/1281167 (32%)]	Loss: 0.546670
[2022-06-10 09:04:15 | train] - Train Epoch: [96] [422400/1281167 (33%)]	Loss: 0.844492
[2022-06-10 09:04:35 | train] - Train Epoch: [96] [435200/1281167 (34%)]	Loss: 0.865730
[2022-06-10 09:04:55 | train] - Train Epoch: [96] [448000/1281167 (35%)]	Loss: 1.021980
[2022-06-10 09:05:14 | train] - Train Epoch: [96] [460800/1281167 (36%)]	Loss: 1.224044
[2022-06-10 09:05:35 | train] - Train Epoch: [96] [473600/1281167 (37%)]	Loss: 0.865827
[2022-06-10 09:05:55 | train] - Train Epoch: [96] [486400/1281167 (38%)]	Loss: 0.965613
[2022-06-10 09:06:16 | train] - Train Epoch: [96] [499200/1281167 (39%)]	Loss: 0.858450
[2022-06-10 09:06:36 | train] - Train Epoch: [96] [512000/1281167 (40%)]	Loss: 0.980793
[2022-06-10 09:06:55 | train] - Train Epoch: [96] [524800/1281167 (41%)]	Loss: 1.113211
[2022-06-10 09:07:16 | train] - Train Epoch: [96] [537600/1281167 (42%)]	Loss: 0.674304
[2022-06-10 09:07:36 | train] - Train Epoch: [96] [550400/1281167 (43%)]	Loss: 1.146482
[2022-06-10 09:07:56 | train] - Train Epoch: [96] [563200/1281167 (44%)]	Loss: 0.886792
[2022-06-10 09:08:16 | train] - Train Epoch: [96] [576000/1281167 (45%)]	Loss: 0.836156
[2022-06-10 09:08:37 | train] - Train Epoch: [96] [588800/1281167 (46%)]	Loss: 0.667073
[2022-06-10 09:08:58 | train] - Train Epoch: [96] [601600/1281167 (47%)]	Loss: 0.951138
[2022-06-10 09:09:18 | train] - Train Epoch: [96] [614400/1281167 (48%)]	Loss: 0.907515
[2022-06-10 09:09:39 | train] - Train Epoch: [96] [627200/1281167 (49%)]	Loss: 1.001019
[2022-06-10 09:09:59 | train] - Train Epoch: [96] [640000/1281167 (50%)]	Loss: 0.909402
[2022-06-10 09:10:20 | train] - Train Epoch: [96] [652800/1281167 (51%)]	Loss: 0.843052
[2022-06-10 09:10:40 | train] - Train Epoch: [96] [665600/1281167 (52%)]	Loss: 0.840641
[2022-06-10 09:11:00 | train] - Train Epoch: [96] [678400/1281167 (53%)]	Loss: 0.807297
[2022-06-10 09:11:20 | train] - Train Epoch: [96] [691200/1281167 (54%)]	Loss: 1.029223
[2022-06-10 09:11:39 | train] - Train Epoch: [96] [704000/1281167 (55%)]	Loss: 0.682504
[2022-06-10 09:12:00 | train] - Train Epoch: [96] [716800/1281167 (56%)]	Loss: 0.874169
[2022-06-10 09:12:20 | train] - Train Epoch: [96] [729600/1281167 (57%)]	Loss: 0.859289
[2022-06-10 09:12:40 | train] - Train Epoch: [96] [742400/1281167 (58%)]	Loss: 1.013654
[2022-06-10 09:12:59 | train] - Train Epoch: [96] [755200/1281167 (59%)]	Loss: 1.095368
[2022-06-10 09:13:19 | train] - Train Epoch: [96] [768000/1281167 (60%)]	Loss: 0.894086
[2022-06-10 09:13:38 | train] - Train Epoch: [96] [780800/1281167 (61%)]	Loss: 0.898418
[2022-06-10 09:13:58 | train] - Train Epoch: [96] [793600/1281167 (62%)]	Loss: 0.702418
[2022-06-10 09:14:18 | train] - Train Epoch: [96] [806400/1281167 (63%)]	Loss: 0.929191
[2022-06-10 09:14:37 | train] - Train Epoch: [96] [819200/1281167 (64%)]	Loss: 0.885948
[2022-06-10 09:14:57 | train] - Train Epoch: [96] [832000/1281167 (65%)]	Loss: 0.805848
[2022-06-10 09:15:17 | train] - Train Epoch: [96] [844800/1281167 (66%)]	Loss: 0.800096
[2022-06-10 09:15:37 | train] - Train Epoch: [96] [857600/1281167 (67%)]	Loss: 0.975575
[2022-06-10 09:15:58 | train] - Train Epoch: [96] [870400/1281167 (68%)]	Loss: 0.806235
[2022-06-10 09:16:18 | train] - Train Epoch: [96] [883200/1281167 (69%)]	Loss: 0.675993
[2022-06-10 09:16:38 | train] - Train Epoch: [96] [896000/1281167 (70%)]	Loss: 0.855674
[2022-06-10 09:16:58 | train] - Train Epoch: [96] [908800/1281167 (71%)]	Loss: 0.875235
[2022-06-10 09:17:18 | train] - Train Epoch: [96] [921600/1281167 (72%)]	Loss: 0.710898
[2022-06-10 09:17:38 | train] - Train Epoch: [96] [934400/1281167 (73%)]	Loss: 0.544128
[2022-06-10 09:17:59 | train] - Train Epoch: [96] [947200/1281167 (74%)]	Loss: 0.911170
[2022-06-10 09:18:19 | train] - Train Epoch: [96] [960000/1281167 (75%)]	Loss: 0.764333
[2022-06-10 09:18:39 | train] - Train Epoch: [96] [972800/1281167 (76%)]	Loss: 0.774394
[2022-06-10 09:18:59 | train] - Train Epoch: [96] [985600/1281167 (77%)]	Loss: 1.098700
[2022-06-10 09:19:21 | train] - Train Epoch: [96] [998400/1281167 (78%)]	Loss: 0.964199
[2022-06-10 09:19:42 | train] - Train Epoch: [96] [1011200/1281167 (79%)]	Loss: 0.964644
[2022-06-10 09:20:00 | train] - Train Epoch: [96] [1024000/1281167 (80%)]	Loss: 0.777022
[2022-06-10 09:20:21 | train] - Train Epoch: [96] [1036800/1281167 (81%)]	Loss: 0.803678
[2022-06-10 09:20:41 | train] - Train Epoch: [96] [1049600/1281167 (82%)]	Loss: 0.689823
[2022-06-10 09:21:01 | train] - Train Epoch: [96] [1062400/1281167 (83%)]	Loss: 0.932697
[2022-06-10 09:21:21 | train] - Train Epoch: [96] [1075200/1281167 (84%)]	Loss: 0.805664
[2022-06-10 09:21:41 | train] - Train Epoch: [96] [1088000/1281167 (85%)]	Loss: 0.736064
[2022-06-10 09:21:59 | train] - Train Epoch: [96] [1100800/1281167 (86%)]	Loss: 0.926965
[2022-06-10 09:22:20 | train] - Train Epoch: [96] [1113600/1281167 (87%)]	Loss: 1.137191
[2022-06-10 09:22:41 | train] - Train Epoch: [96] [1126400/1281167 (88%)]	Loss: 0.687010
[2022-06-10 09:23:01 | train] - Train Epoch: [96] [1139200/1281167 (89%)]	Loss: 0.831974
[2022-06-10 09:23:21 | train] - Train Epoch: [96] [1152000/1281167 (90%)]	Loss: 0.937535
[2022-06-10 09:23:41 | train] - Train Epoch: [96] [1164800/1281167 (91%)]	Loss: 0.995653
[2022-06-10 09:24:01 | train] - Train Epoch: [96] [1177600/1281167 (92%)]	Loss: 0.987211
[2022-06-10 09:24:22 | train] - Train Epoch: [96] [1190400/1281167 (93%)]	Loss: 0.901544
[2022-06-10 09:24:43 | train] - Train Epoch: [96] [1203200/1281167 (94%)]	Loss: 0.806899
[2022-06-10 09:25:02 | train] - Train Epoch: [96] [1216000/1281167 (95%)]	Loss: 0.879047
[2022-06-10 09:25:21 | train] - Train Epoch: [96] [1228800/1281167 (96%)]	Loss: 0.785939
[2022-06-10 09:25:41 | train] - Train Epoch: [96] [1241600/1281167 (97%)]	Loss: 0.994796
[2022-06-10 09:26:01 | train] - Train Epoch: [96] [1254400/1281167 (98%)]	Loss: 0.942360
[2022-06-10 09:26:21 | train] - Train Epoch: [96] [1267200/1281167 (99%)]	Loss: 1.166424
[2022-06-10 09:26:41 | train] - Train Epoch: [96] [1280000/1281167 (100%)]	Loss: 1.139027
[2022-06-10 09:26:42 | train] - Train Epoch: [96]	 Average Loss: 0.866851	 Total Acc : 78.8144	 Total Top5 Acc : 92.1976
[2022-06-10 09:26:42 | train] - -------96 epoch end-----------
========================================
-------96 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 09:28:14 | train] - 
Epoch [96] Test set: Average loss: 1.3895, Accuracy: 34823/50000 (69.6188%), Top-5 Accuracy: 88.8031%

[2022-06-10 09:28:14 | train] - save intermediate epoch [96] result


[2022-06-10 09:28:40 | train] - -------97 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 09:28:41 | train] - Train Epoch: [97] [0/1281167 (0%)]	Loss: 1.087254
[2022-06-10 09:29:01 | train] - Train Epoch: [97] [12800/1281167 (1%)]	Loss: 0.833511
[2022-06-10 09:29:21 | train] - Train Epoch: [97] [25600/1281167 (2%)]	Loss: 0.666946
[2022-06-10 09:29:40 | train] - Train Epoch: [97] [38400/1281167 (3%)]	Loss: 0.880673
[2022-06-10 09:30:00 | train] - Train Epoch: [97] [51200/1281167 (4%)]	Loss: 0.695277
[2022-06-10 09:30:19 | train] - Train Epoch: [97] [64000/1281167 (5%)]	Loss: 0.891990
[2022-06-10 09:30:40 | train] - Train Epoch: [97] [76800/1281167 (6%)]	Loss: 1.030426
[2022-06-10 09:31:00 | train] - Train Epoch: [97] [89600/1281167 (7%)]	Loss: 0.770256
[2022-06-10 09:31:21 | train] - Train Epoch: [97] [102400/1281167 (8%)]	Loss: 0.644926
[2022-06-10 09:31:41 | train] - Train Epoch: [97] [115200/1281167 (9%)]	Loss: 0.821454
[2022-06-10 09:32:01 | train] - Train Epoch: [97] [128000/1281167 (10%)]	Loss: 1.013219
[2022-06-10 09:32:20 | train] - Train Epoch: [97] [140800/1281167 (11%)]	Loss: 0.785935
[2022-06-10 09:32:39 | train] - Train Epoch: [97] [153600/1281167 (12%)]	Loss: 1.026813
[2022-06-10 09:32:59 | train] - Train Epoch: [97] [166400/1281167 (13%)]	Loss: 0.888391
[2022-06-10 09:33:19 | train] - Train Epoch: [97] [179200/1281167 (14%)]	Loss: 0.751386
[2022-06-10 09:33:39 | train] - Train Epoch: [97] [192000/1281167 (15%)]	Loss: 1.060701
[2022-06-10 09:33:59 | train] - Train Epoch: [97] [204800/1281167 (16%)]	Loss: 0.664582
[2022-06-10 09:34:19 | train] - Train Epoch: [97] [217600/1281167 (17%)]	Loss: 0.961666
[2022-06-10 09:34:39 | train] - Train Epoch: [97] [230400/1281167 (18%)]	Loss: 0.845633
[2022-06-10 09:34:59 | train] - Train Epoch: [97] [243200/1281167 (19%)]	Loss: 0.866838
[2022-06-10 09:35:19 | train] - Train Epoch: [97] [256000/1281167 (20%)]	Loss: 0.947835
[2022-06-10 09:35:38 | train] - Train Epoch: [97] [268800/1281167 (21%)]	Loss: 1.259224
[2022-06-10 09:35:58 | train] - Train Epoch: [97] [281600/1281167 (22%)]	Loss: 0.886873
[2022-06-10 09:36:19 | train] - Train Epoch: [97] [294400/1281167 (23%)]	Loss: 1.141285
[2022-06-10 09:36:39 | train] - Train Epoch: [97] [307200/1281167 (24%)]	Loss: 0.965153
[2022-06-10 09:36:58 | train] - Train Epoch: [97] [320000/1281167 (25%)]	Loss: 0.932669
[2022-06-10 09:37:17 | train] - Train Epoch: [97] [332800/1281167 (26%)]	Loss: 0.895588
[2022-06-10 09:37:37 | train] - Train Epoch: [97] [345600/1281167 (27%)]	Loss: 0.800380
[2022-06-10 09:37:58 | train] - Train Epoch: [97] [358400/1281167 (28%)]	Loss: 0.846430
[2022-06-10 09:38:18 | train] - Train Epoch: [97] [371200/1281167 (29%)]	Loss: 0.709191
[2022-06-10 09:38:37 | train] - Train Epoch: [97] [384000/1281167 (30%)]	Loss: 1.011117
[2022-06-10 09:38:57 | train] - Train Epoch: [97] [396800/1281167 (31%)]	Loss: 0.978158
[2022-06-10 09:39:17 | train] - Train Epoch: [97] [409600/1281167 (32%)]	Loss: 1.015593
[2022-06-10 09:39:37 | train] - Train Epoch: [97] [422400/1281167 (33%)]	Loss: 1.253537
[2022-06-10 09:39:57 | train] - Train Epoch: [97] [435200/1281167 (34%)]	Loss: 1.035314
[2022-06-10 09:40:16 | train] - Train Epoch: [97] [448000/1281167 (35%)]	Loss: 0.599386
[2022-06-10 09:40:36 | train] - Train Epoch: [97] [460800/1281167 (36%)]	Loss: 0.690823
[2022-06-10 09:40:56 | train] - Train Epoch: [97] [473600/1281167 (37%)]	Loss: 0.611875
[2022-06-10 09:41:16 | train] - Train Epoch: [97] [486400/1281167 (38%)]	Loss: 0.803164
[2022-06-10 09:41:36 | train] - Train Epoch: [97] [499200/1281167 (39%)]	Loss: 1.041983
[2022-06-10 09:41:56 | train] - Train Epoch: [97] [512000/1281167 (40%)]	Loss: 0.811918
[2022-06-10 09:42:15 | train] - Train Epoch: [97] [524800/1281167 (41%)]	Loss: 1.015188
[2022-06-10 09:42:36 | train] - Train Epoch: [97] [537600/1281167 (42%)]	Loss: 1.018619
[2022-06-10 09:42:55 | train] - Train Epoch: [97] [550400/1281167 (43%)]	Loss: 1.057487
[2022-06-10 09:43:16 | train] - Train Epoch: [97] [563200/1281167 (44%)]	Loss: 0.893491
[2022-06-10 09:43:35 | train] - Train Epoch: [97] [576000/1281167 (45%)]	Loss: 0.972319
[2022-06-10 09:43:55 | train] - Train Epoch: [97] [588800/1281167 (46%)]	Loss: 0.745256
[2022-06-10 09:44:15 | train] - Train Epoch: [97] [601600/1281167 (47%)]	Loss: 0.584906
[2022-06-10 09:44:35 | train] - Train Epoch: [97] [614400/1281167 (48%)]	Loss: 0.854362
[2022-06-10 09:44:54 | train] - Train Epoch: [97] [627200/1281167 (49%)]	Loss: 0.875336
[2022-06-10 09:45:15 | train] - Train Epoch: [97] [640000/1281167 (50%)]	Loss: 0.893562
[2022-06-10 09:45:34 | train] - Train Epoch: [97] [652800/1281167 (51%)]	Loss: 0.816108
[2022-06-10 09:45:54 | train] - Train Epoch: [97] [665600/1281167 (52%)]	Loss: 0.956034
[2022-06-10 09:46:14 | train] - Train Epoch: [97] [678400/1281167 (53%)]	Loss: 0.909092
[2022-06-10 09:46:34 | train] - Train Epoch: [97] [691200/1281167 (54%)]	Loss: 0.700147
[2022-06-10 09:46:54 | train] - Train Epoch: [97] [704000/1281167 (55%)]	Loss: 1.000413
[2022-06-10 09:47:13 | train] - Train Epoch: [97] [716800/1281167 (56%)]	Loss: 0.778752
[2022-06-10 09:47:34 | train] - Train Epoch: [97] [729600/1281167 (57%)]	Loss: 0.965276
[2022-06-10 09:47:53 | train] - Train Epoch: [97] [742400/1281167 (58%)]	Loss: 1.055872
[2022-06-10 09:48:13 | train] - Train Epoch: [97] [755200/1281167 (59%)]	Loss: 1.003736
[2022-06-10 09:48:33 | train] - Train Epoch: [97] [768000/1281167 (60%)]	Loss: 0.752704
[2022-06-10 09:48:52 | train] - Train Epoch: [97] [780800/1281167 (61%)]	Loss: 0.467913
[2022-06-10 09:49:12 | train] - Train Epoch: [97] [793600/1281167 (62%)]	Loss: 0.820280
[2022-06-10 09:49:32 | train] - Train Epoch: [97] [806400/1281167 (63%)]	Loss: 0.964376
[2022-06-10 09:49:52 | train] - Train Epoch: [97] [819200/1281167 (64%)]	Loss: 0.824773
[2022-06-10 09:50:12 | train] - Train Epoch: [97] [832000/1281167 (65%)]	Loss: 1.042157
[2022-06-10 09:50:31 | train] - Train Epoch: [97] [844800/1281167 (66%)]	Loss: 0.638495
[2022-06-10 09:50:51 | train] - Train Epoch: [97] [857600/1281167 (67%)]	Loss: 1.099826
[2022-06-10 09:51:11 | train] - Train Epoch: [97] [870400/1281167 (68%)]	Loss: 0.950411
[2022-06-10 09:51:31 | train] - Train Epoch: [97] [883200/1281167 (69%)]	Loss: 0.663727
[2022-06-10 09:51:51 | train] - Train Epoch: [97] [896000/1281167 (70%)]	Loss: 0.852269
[2022-06-10 09:52:11 | train] - Train Epoch: [97] [908800/1281167 (71%)]	Loss: 0.966214
[2022-06-10 09:52:31 | train] - Train Epoch: [97] [921600/1281167 (72%)]	Loss: 0.880270
[2022-06-10 09:52:51 | train] - Train Epoch: [97] [934400/1281167 (73%)]	Loss: 1.068101
[2022-06-10 09:53:10 | train] - Train Epoch: [97] [947200/1281167 (74%)]	Loss: 1.019500
[2022-06-10 09:53:30 | train] - Train Epoch: [97] [960000/1281167 (75%)]	Loss: 0.785778
[2022-06-10 09:53:50 | train] - Train Epoch: [97] [972800/1281167 (76%)]	Loss: 0.879302
[2022-06-10 09:54:10 | train] - Train Epoch: [97] [985600/1281167 (77%)]	Loss: 0.712744
[2022-06-10 09:54:30 | train] - Train Epoch: [97] [998400/1281167 (78%)]	Loss: 1.050307
[2022-06-10 09:54:50 | train] - Train Epoch: [97] [1011200/1281167 (79%)]	Loss: 0.828124
[2022-06-10 09:55:10 | train] - Train Epoch: [97] [1024000/1281167 (80%)]	Loss: 0.978148
[2022-06-10 09:55:30 | train] - Train Epoch: [97] [1036800/1281167 (81%)]	Loss: 0.827860
[2022-06-10 09:55:50 | train] - Train Epoch: [97] [1049600/1281167 (82%)]	Loss: 0.870220
[2022-06-10 09:56:10 | train] - Train Epoch: [97] [1062400/1281167 (83%)]	Loss: 1.015538
[2022-06-10 09:56:29 | train] - Train Epoch: [97] [1075200/1281167 (84%)]	Loss: 0.928399
[2022-06-10 09:56:49 | train] - Train Epoch: [97] [1088000/1281167 (85%)]	Loss: 1.048965
[2022-06-10 09:57:10 | train] - Train Epoch: [97] [1100800/1281167 (86%)]	Loss: 0.843672
[2022-06-10 09:57:29 | train] - Train Epoch: [97] [1113600/1281167 (87%)]	Loss: 1.045913
[2022-06-10 09:57:49 | train] - Train Epoch: [97] [1126400/1281167 (88%)]	Loss: 1.043379
[2022-06-10 09:58:08 | train] - Train Epoch: [97] [1139200/1281167 (89%)]	Loss: 0.833762
[2022-06-10 09:58:28 | train] - Train Epoch: [97] [1152000/1281167 (90%)]	Loss: 1.015222
[2022-06-10 09:58:48 | train] - Train Epoch: [97] [1164800/1281167 (91%)]	Loss: 0.713077
[2022-06-10 09:59:08 | train] - Train Epoch: [97] [1177600/1281167 (92%)]	Loss: 0.639896
[2022-06-10 09:59:28 | train] - Train Epoch: [97] [1190400/1281167 (93%)]	Loss: 0.793106
[2022-06-10 09:59:47 | train] - Train Epoch: [97] [1203200/1281167 (94%)]	Loss: 1.102853
[2022-06-10 10:00:07 | train] - Train Epoch: [97] [1216000/1281167 (95%)]	Loss: 0.822189
[2022-06-10 10:00:27 | train] - Train Epoch: [97] [1228800/1281167 (96%)]	Loss: 0.769668
[2022-06-10 10:00:46 | train] - Train Epoch: [97] [1241600/1281167 (97%)]	Loss: 0.807599
[2022-06-10 10:01:06 | train] - Train Epoch: [97] [1254400/1281167 (98%)]	Loss: 1.044728
[2022-06-10 10:01:26 | train] - Train Epoch: [97] [1267200/1281167 (99%)]	Loss: 0.900750
[2022-06-10 10:01:47 | train] - Train Epoch: [97] [1280000/1281167 (100%)]	Loss: 0.783021
[2022-06-10 10:01:49 | train] - Train Epoch: [97]	 Average Loss: 0.864542	 Total Acc : 78.8595	 Total Top5 Acc : 92.2149
[2022-06-10 10:01:49 | train] - -------97 epoch end-----------
========================================
-------97 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 10:03:23 | train] - 
Epoch [97] Test set: Average loss: 1.3812, Accuracy: 34996/50000 (69.9620%), Top-5 Accuracy: 88.9422%

[2022-06-10 10:03:23 | train] - save intermediate epoch [97] result


[2022-06-10 10:03:50 | train] - -------98 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 10:03:51 | train] - Train Epoch: [98] [0/1281167 (0%)]	Loss: 0.991515
[2022-06-10 10:04:14 | train] - Train Epoch: [98] [12800/1281167 (1%)]	Loss: 0.937864
[2022-06-10 10:04:36 | train] - Train Epoch: [98] [25600/1281167 (2%)]	Loss: 1.201035
[2022-06-10 10:04:58 | train] - Train Epoch: [98] [38400/1281167 (3%)]	Loss: 0.661392
[2022-06-10 10:05:21 | train] - Train Epoch: [98] [51200/1281167 (4%)]	Loss: 0.655925
[2022-06-10 10:05:43 | train] - Train Epoch: [98] [64000/1281167 (5%)]	Loss: 0.935238
[2022-06-10 10:06:04 | train] - Train Epoch: [98] [76800/1281167 (6%)]	Loss: 0.838076
[2022-06-10 10:06:27 | train] - Train Epoch: [98] [89600/1281167 (7%)]	Loss: 1.031196
[2022-06-10 10:06:48 | train] - Train Epoch: [98] [102400/1281167 (8%)]	Loss: 0.787219
[2022-06-10 10:07:10 | train] - Train Epoch: [98] [115200/1281167 (9%)]	Loss: 0.953957
[2022-06-10 10:07:32 | train] - Train Epoch: [98] [128000/1281167 (10%)]	Loss: 1.037983
[2022-06-10 10:07:54 | train] - Train Epoch: [98] [140800/1281167 (11%)]	Loss: 1.009627
[2022-06-10 10:08:16 | train] - Train Epoch: [98] [153600/1281167 (12%)]	Loss: 0.843910
[2022-06-10 10:08:38 | train] - Train Epoch: [98] [166400/1281167 (13%)]	Loss: 0.856391
[2022-06-10 10:09:00 | train] - Train Epoch: [98] [179200/1281167 (14%)]	Loss: 0.930195
[2022-06-10 10:09:21 | train] - Train Epoch: [98] [192000/1281167 (15%)]	Loss: 0.903774
[2022-06-10 10:09:43 | train] - Train Epoch: [98] [204800/1281167 (16%)]	Loss: 0.620783
[2022-06-10 10:10:05 | train] - Train Epoch: [98] [217600/1281167 (17%)]	Loss: 0.856274
[2022-06-10 10:10:28 | train] - Train Epoch: [98] [230400/1281167 (18%)]	Loss: 0.761047
[2022-06-10 10:10:50 | train] - Train Epoch: [98] [243200/1281167 (19%)]	Loss: 1.021660
[2022-06-10 10:11:11 | train] - Train Epoch: [98] [256000/1281167 (20%)]	Loss: 1.027365
[2022-06-10 10:11:33 | train] - Train Epoch: [98] [268800/1281167 (21%)]	Loss: 0.891735
[2022-06-10 10:11:56 | train] - Train Epoch: [98] [281600/1281167 (22%)]	Loss: 0.906512
[2022-06-10 10:12:17 | train] - Train Epoch: [98] [294400/1281167 (23%)]	Loss: 0.916373
[2022-06-10 10:12:39 | train] - Train Epoch: [98] [307200/1281167 (24%)]	Loss: 0.915491
[2022-06-10 10:13:00 | train] - Train Epoch: [98] [320000/1281167 (25%)]	Loss: 0.906171
[2022-06-10 10:13:22 | train] - Train Epoch: [98] [332800/1281167 (26%)]	Loss: 0.817176
[2022-06-10 10:13:43 | train] - Train Epoch: [98] [345600/1281167 (27%)]	Loss: 0.719582
[2022-06-10 10:14:05 | train] - Train Epoch: [98] [358400/1281167 (28%)]	Loss: 0.615456
[2022-06-10 10:14:26 | train] - Train Epoch: [98] [371200/1281167 (29%)]	Loss: 0.491425
[2022-06-10 10:14:48 | train] - Train Epoch: [98] [384000/1281167 (30%)]	Loss: 1.007438
[2022-06-10 10:15:10 | train] - Train Epoch: [98] [396800/1281167 (31%)]	Loss: 0.633144
[2022-06-10 10:15:32 | train] - Train Epoch: [98] [409600/1281167 (32%)]	Loss: 0.918801
[2022-06-10 10:15:53 | train] - Train Epoch: [98] [422400/1281167 (33%)]	Loss: 0.840430
[2022-06-10 10:16:14 | train] - Train Epoch: [98] [435200/1281167 (34%)]	Loss: 0.880809
[2022-06-10 10:16:36 | train] - Train Epoch: [98] [448000/1281167 (35%)]	Loss: 0.739315
[2022-06-10 10:16:58 | train] - Train Epoch: [98] [460800/1281167 (36%)]	Loss: 1.023481
[2022-06-10 10:17:19 | train] - Train Epoch: [98] [473600/1281167 (37%)]	Loss: 0.981052
[2022-06-10 10:17:40 | train] - Train Epoch: [98] [486400/1281167 (38%)]	Loss: 0.739389
[2022-06-10 10:18:01 | train] - Train Epoch: [98] [499200/1281167 (39%)]	Loss: 0.509963
[2022-06-10 10:18:22 | train] - Train Epoch: [98] [512000/1281167 (40%)]	Loss: 0.906588
[2022-06-10 10:18:43 | train] - Train Epoch: [98] [524800/1281167 (41%)]	Loss: 1.000354
[2022-06-10 10:19:05 | train] - Train Epoch: [98] [537600/1281167 (42%)]	Loss: 0.912268
[2022-06-10 10:19:27 | train] - Train Epoch: [98] [550400/1281167 (43%)]	Loss: 0.811681
[2022-06-10 10:19:48 | train] - Train Epoch: [98] [563200/1281167 (44%)]	Loss: 0.956333
[2022-06-10 10:20:10 | train] - Train Epoch: [98] [576000/1281167 (45%)]	Loss: 1.022846
[2022-06-10 10:20:31 | train] - Train Epoch: [98] [588800/1281167 (46%)]	Loss: 0.926104
[2022-06-10 10:20:53 | train] - Train Epoch: [98] [601600/1281167 (47%)]	Loss: 0.777620
[2022-06-10 10:21:14 | train] - Train Epoch: [98] [614400/1281167 (48%)]	Loss: 0.915402
[2022-06-10 10:21:35 | train] - Train Epoch: [98] [627200/1281167 (49%)]	Loss: 0.821516
[2022-06-10 10:21:56 | train] - Train Epoch: [98] [640000/1281167 (50%)]	Loss: 0.907781
[2022-06-10 10:22:18 | train] - Train Epoch: [98] [652800/1281167 (51%)]	Loss: 0.704854
[2022-06-10 10:22:38 | train] - Train Epoch: [98] [665600/1281167 (52%)]	Loss: 1.105425
[2022-06-10 10:23:00 | train] - Train Epoch: [98] [678400/1281167 (53%)]	Loss: 0.792844
[2022-06-10 10:23:20 | train] - Train Epoch: [98] [691200/1281167 (54%)]	Loss: 0.678015
[2022-06-10 10:23:42 | train] - Train Epoch: [98] [704000/1281167 (55%)]	Loss: 1.056332
[2022-06-10 10:24:04 | train] - Train Epoch: [98] [716800/1281167 (56%)]	Loss: 0.836353
[2022-06-10 10:24:26 | train] - Train Epoch: [98] [729600/1281167 (57%)]	Loss: 1.070564
[2022-06-10 10:24:46 | train] - Train Epoch: [98] [742400/1281167 (58%)]	Loss: 1.054836
[2022-06-10 10:25:08 | train] - Train Epoch: [98] [755200/1281167 (59%)]	Loss: 0.762109
[2022-06-10 10:25:30 | train] - Train Epoch: [98] [768000/1281167 (60%)]	Loss: 0.615405
[2022-06-10 10:25:51 | train] - Train Epoch: [98] [780800/1281167 (61%)]	Loss: 1.065588
[2022-06-10 10:26:12 | train] - Train Epoch: [98] [793600/1281167 (62%)]	Loss: 1.068656
[2022-06-10 10:26:34 | train] - Train Epoch: [98] [806400/1281167 (63%)]	Loss: 1.002453
[2022-06-10 10:26:55 | train] - Train Epoch: [98] [819200/1281167 (64%)]	Loss: 0.811628
[2022-06-10 10:27:15 | train] - Train Epoch: [98] [832000/1281167 (65%)]	Loss: 0.765260
[2022-06-10 10:27:36 | train] - Train Epoch: [98] [844800/1281167 (66%)]	Loss: 1.093337
[2022-06-10 10:27:57 | train] - Train Epoch: [98] [857600/1281167 (67%)]	Loss: 1.025120
[2022-06-10 10:28:18 | train] - Train Epoch: [98] [870400/1281167 (68%)]	Loss: 0.904473
[2022-06-10 10:28:39 | train] - Train Epoch: [98] [883200/1281167 (69%)]	Loss: 0.784695
[2022-06-10 10:29:02 | train] - Train Epoch: [98] [896000/1281167 (70%)]	Loss: 0.867191
[2022-06-10 10:29:23 | train] - Train Epoch: [98] [908800/1281167 (71%)]	Loss: 0.696766
[2022-06-10 10:29:44 | train] - Train Epoch: [98] [921600/1281167 (72%)]	Loss: 0.969407
[2022-06-10 10:30:06 | train] - Train Epoch: [98] [934400/1281167 (73%)]	Loss: 0.721825
[2022-06-10 10:30:27 | train] - Train Epoch: [98] [947200/1281167 (74%)]	Loss: 0.822522
[2022-06-10 10:30:48 | train] - Train Epoch: [98] [960000/1281167 (75%)]	Loss: 0.847673
[2022-06-10 10:31:10 | train] - Train Epoch: [98] [972800/1281167 (76%)]	Loss: 0.708551
[2022-06-10 10:31:32 | train] - Train Epoch: [98] [985600/1281167 (77%)]	Loss: 0.663677
[2022-06-10 10:31:53 | train] - Train Epoch: [98] [998400/1281167 (78%)]	Loss: 0.919584
[2022-06-10 10:32:14 | train] - Train Epoch: [98] [1011200/1281167 (79%)]	Loss: 0.662524
[2022-06-10 10:32:36 | train] - Train Epoch: [98] [1024000/1281167 (80%)]	Loss: 0.762158
[2022-06-10 10:32:58 | train] - Train Epoch: [98] [1036800/1281167 (81%)]	Loss: 0.914879
[2022-06-10 10:33:19 | train] - Train Epoch: [98] [1049600/1281167 (82%)]	Loss: 1.039227
[2022-06-10 10:33:40 | train] - Train Epoch: [98] [1062400/1281167 (83%)]	Loss: 0.828952
[2022-06-10 10:34:01 | train] - Train Epoch: [98] [1075200/1281167 (84%)]	Loss: 0.963683
[2022-06-10 10:34:22 | train] - Train Epoch: [98] [1088000/1281167 (85%)]	Loss: 0.914835
[2022-06-10 10:34:44 | train] - Train Epoch: [98] [1100800/1281167 (86%)]	Loss: 0.828626
[2022-06-10 10:35:05 | train] - Train Epoch: [98] [1113600/1281167 (87%)]	Loss: 0.599245
[2022-06-10 10:35:27 | train] - Train Epoch: [98] [1126400/1281167 (88%)]	Loss: 0.782685
[2022-06-10 10:35:48 | train] - Train Epoch: [98] [1139200/1281167 (89%)]	Loss: 0.861715
[2022-06-10 10:36:10 | train] - Train Epoch: [98] [1152000/1281167 (90%)]	Loss: 1.046205
[2022-06-10 10:36:32 | train] - Train Epoch: [98] [1164800/1281167 (91%)]	Loss: 0.901240
[2022-06-10 10:36:54 | train] - Train Epoch: [98] [1177600/1281167 (92%)]	Loss: 0.689426
[2022-06-10 10:37:15 | train] - Train Epoch: [98] [1190400/1281167 (93%)]	Loss: 0.916613
[2022-06-10 10:37:36 | train] - Train Epoch: [98] [1203200/1281167 (94%)]	Loss: 1.076528
[2022-06-10 10:37:58 | train] - Train Epoch: [98] [1216000/1281167 (95%)]	Loss: 0.949082
[2022-06-10 10:38:19 | train] - Train Epoch: [98] [1228800/1281167 (96%)]	Loss: 0.823331
[2022-06-10 10:38:41 | train] - Train Epoch: [98] [1241600/1281167 (97%)]	Loss: 1.024737
[2022-06-10 10:39:02 | train] - Train Epoch: [98] [1254400/1281167 (98%)]	Loss: 0.886333
[2022-06-10 10:39:23 | train] - Train Epoch: [98] [1267200/1281167 (99%)]	Loss: 0.766667
[2022-06-10 10:39:44 | train] - Train Epoch: [98] [1280000/1281167 (100%)]	Loss: 0.860556
[2022-06-10 10:39:46 | train] - Train Epoch: [98]	 Average Loss: 0.861236	 Total Acc : 78.9115	 Total Top5 Acc : 92.2592
[2022-06-10 10:39:46 | train] - -------98 epoch end-----------
========================================
-------98 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 10:41:19 | train] - 
Epoch [98] Test set: Average loss: 1.3868, Accuracy: 34898/50000 (69.7698%), Top-5 Accuracy: 88.9007%

[2022-06-10 10:41:19 | train] - save intermediate epoch [98] result


[2022-06-10 10:41:46 | train] - -------99 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 10:41:48 | train] - Train Epoch: [99] [0/1281167 (0%)]	Loss: 0.766599
[2022-06-10 10:42:09 | train] - Train Epoch: [99] [12800/1281167 (1%)]	Loss: 1.022955
[2022-06-10 10:42:30 | train] - Train Epoch: [99] [25600/1281167 (2%)]	Loss: 0.752850
[2022-06-10 10:42:52 | train] - Train Epoch: [99] [38400/1281167 (3%)]	Loss: 0.867848
[2022-06-10 10:43:14 | train] - Train Epoch: [99] [51200/1281167 (4%)]	Loss: 0.873496
[2022-06-10 10:43:36 | train] - Train Epoch: [99] [64000/1281167 (5%)]	Loss: 0.685840
[2022-06-10 10:43:57 | train] - Train Epoch: [99] [76800/1281167 (6%)]	Loss: 1.069078
[2022-06-10 10:44:18 | train] - Train Epoch: [99] [89600/1281167 (7%)]	Loss: 0.774551
[2022-06-10 10:44:40 | train] - Train Epoch: [99] [102400/1281167 (8%)]	Loss: 0.845206
[2022-06-10 10:45:02 | train] - Train Epoch: [99] [115200/1281167 (9%)]	Loss: 1.123597
[2022-06-10 10:45:24 | train] - Train Epoch: [99] [128000/1281167 (10%)]	Loss: 0.900848
[2022-06-10 10:45:45 | train] - Train Epoch: [99] [140800/1281167 (11%)]	Loss: 0.791820
[2022-06-10 10:46:07 | train] - Train Epoch: [99] [153600/1281167 (12%)]	Loss: 0.930939
[2022-06-10 10:46:29 | train] - Train Epoch: [99] [166400/1281167 (13%)]	Loss: 0.840789
[2022-06-10 10:46:50 | train] - Train Epoch: [99] [179200/1281167 (14%)]	Loss: 0.716012
[2022-06-10 10:47:12 | train] - Train Epoch: [99] [192000/1281167 (15%)]	Loss: 0.908845
[2022-06-10 10:47:33 | train] - Train Epoch: [99] [204800/1281167 (16%)]	Loss: 1.079487
[2022-06-10 10:47:55 | train] - Train Epoch: [99] [217600/1281167 (17%)]	Loss: 0.647013
[2022-06-10 10:48:17 | train] - Train Epoch: [99] [230400/1281167 (18%)]	Loss: 0.719729
[2022-06-10 10:48:38 | train] - Train Epoch: [99] [243200/1281167 (19%)]	Loss: 1.251377
[2022-06-10 10:49:00 | train] - Train Epoch: [99] [256000/1281167 (20%)]	Loss: 0.934707
[2022-06-10 10:49:21 | train] - Train Epoch: [99] [268800/1281167 (21%)]	Loss: 0.944705
[2022-06-10 10:49:43 | train] - Train Epoch: [99] [281600/1281167 (22%)]	Loss: 0.910879
[2022-06-10 10:50:05 | train] - Train Epoch: [99] [294400/1281167 (23%)]	Loss: 0.804356
[2022-06-10 10:50:27 | train] - Train Epoch: [99] [307200/1281167 (24%)]	Loss: 0.544411
[2022-06-10 10:50:49 | train] - Train Epoch: [99] [320000/1281167 (25%)]	Loss: 0.887846
[2022-06-10 10:51:10 | train] - Train Epoch: [99] [332800/1281167 (26%)]	Loss: 0.634948
[2022-06-10 10:51:31 | train] - Train Epoch: [99] [345600/1281167 (27%)]	Loss: 0.715836
[2022-06-10 10:51:54 | train] - Train Epoch: [99] [358400/1281167 (28%)]	Loss: 0.748874
[2022-06-10 10:52:15 | train] - Train Epoch: [99] [371200/1281167 (29%)]	Loss: 0.887727
[2022-06-10 10:52:37 | train] - Train Epoch: [99] [384000/1281167 (30%)]	Loss: 0.826175
[2022-06-10 10:52:58 | train] - Train Epoch: [99] [396800/1281167 (31%)]	Loss: 0.951946
[2022-06-10 10:53:21 | train] - Train Epoch: [99] [409600/1281167 (32%)]	Loss: 0.770137
[2022-06-10 10:53:42 | train] - Train Epoch: [99] [422400/1281167 (33%)]	Loss: 0.557906
[2022-06-10 10:54:05 | train] - Train Epoch: [99] [435200/1281167 (34%)]	Loss: 0.779803
[2022-06-10 10:54:26 | train] - Train Epoch: [99] [448000/1281167 (35%)]	Loss: 0.891593
[2022-06-10 10:54:47 | train] - Train Epoch: [99] [460800/1281167 (36%)]	Loss: 0.725819
[2022-06-10 10:55:08 | train] - Train Epoch: [99] [473600/1281167 (37%)]	Loss: 0.752864
[2022-06-10 10:55:29 | train] - Train Epoch: [99] [486400/1281167 (38%)]	Loss: 0.738699
[2022-06-10 10:55:49 | train] - Train Epoch: [99] [499200/1281167 (39%)]	Loss: 0.818700
[2022-06-10 10:56:11 | train] - Train Epoch: [99] [512000/1281167 (40%)]	Loss: 0.900118
[2022-06-10 10:56:33 | train] - Train Epoch: [99] [524800/1281167 (41%)]	Loss: 1.005181
[2022-06-10 10:56:55 | train] - Train Epoch: [99] [537600/1281167 (42%)]	Loss: 1.016131
[2022-06-10 10:57:17 | train] - Train Epoch: [99] [550400/1281167 (43%)]	Loss: 0.872407
[2022-06-10 10:57:38 | train] - Train Epoch: [99] [563200/1281167 (44%)]	Loss: 0.726397
[2022-06-10 10:57:59 | train] - Train Epoch: [99] [576000/1281167 (45%)]	Loss: 1.001327
[2022-06-10 10:58:21 | train] - Train Epoch: [99] [588800/1281167 (46%)]	Loss: 0.654586
[2022-06-10 10:58:42 | train] - Train Epoch: [99] [601600/1281167 (47%)]	Loss: 0.726748
[2022-06-10 10:59:03 | train] - Train Epoch: [99] [614400/1281167 (48%)]	Loss: 0.859514
[2022-06-10 10:59:25 | train] - Train Epoch: [99] [627200/1281167 (49%)]	Loss: 0.948000
[2022-06-10 10:59:46 | train] - Train Epoch: [99] [640000/1281167 (50%)]	Loss: 0.733194
[2022-06-10 11:00:07 | train] - Train Epoch: [99] [652800/1281167 (51%)]	Loss: 0.937190
[2022-06-10 11:00:29 | train] - Train Epoch: [99] [665600/1281167 (52%)]	Loss: 0.983460
[2022-06-10 11:00:51 | train] - Train Epoch: [99] [678400/1281167 (53%)]	Loss: 0.617188
[2022-06-10 11:01:12 | train] - Train Epoch: [99] [691200/1281167 (54%)]	Loss: 1.181947
[2022-06-10 11:01:35 | train] - Train Epoch: [99] [704000/1281167 (55%)]	Loss: 0.780476
[2022-06-10 11:01:56 | train] - Train Epoch: [99] [716800/1281167 (56%)]	Loss: 0.897050
[2022-06-10 11:02:17 | train] - Train Epoch: [99] [729600/1281167 (57%)]	Loss: 1.036001
[2022-06-10 11:02:39 | train] - Train Epoch: [99] [742400/1281167 (58%)]	Loss: 0.979183
[2022-06-10 11:03:01 | train] - Train Epoch: [99] [755200/1281167 (59%)]	Loss: 0.718321
[2022-06-10 11:03:23 | train] - Train Epoch: [99] [768000/1281167 (60%)]	Loss: 1.077528
[2022-06-10 11:03:44 | train] - Train Epoch: [99] [780800/1281167 (61%)]	Loss: 1.020308
[2022-06-10 11:04:05 | train] - Train Epoch: [99] [793600/1281167 (62%)]	Loss: 0.915063
[2022-06-10 11:04:27 | train] - Train Epoch: [99] [806400/1281167 (63%)]	Loss: 0.972533
[2022-06-10 11:04:48 | train] - Train Epoch: [99] [819200/1281167 (64%)]	Loss: 0.745010
[2022-06-10 11:05:09 | train] - Train Epoch: [99] [832000/1281167 (65%)]	Loss: 0.911279
[2022-06-10 11:05:30 | train] - Train Epoch: [99] [844800/1281167 (66%)]	Loss: 1.126943
[2022-06-10 11:05:52 | train] - Train Epoch: [99] [857600/1281167 (67%)]	Loss: 0.792850
[2022-06-10 11:06:13 | train] - Train Epoch: [99] [870400/1281167 (68%)]	Loss: 0.806056
[2022-06-10 11:06:34 | train] - Train Epoch: [99] [883200/1281167 (69%)]	Loss: 0.923546
[2022-06-10 11:06:56 | train] - Train Epoch: [99] [896000/1281167 (70%)]	Loss: 1.107126
[2022-06-10 11:07:18 | train] - Train Epoch: [99] [908800/1281167 (71%)]	Loss: 0.884045
[2022-06-10 11:07:39 | train] - Train Epoch: [99] [921600/1281167 (72%)]	Loss: 1.004956
[2022-06-10 11:08:00 | train] - Train Epoch: [99] [934400/1281167 (73%)]	Loss: 1.009179
[2022-06-10 11:08:22 | train] - Train Epoch: [99] [947200/1281167 (74%)]	Loss: 1.004416
[2022-06-10 11:08:42 | train] - Train Epoch: [99] [960000/1281167 (75%)]	Loss: 0.943627
[2022-06-10 11:09:04 | train] - Train Epoch: [99] [972800/1281167 (76%)]	Loss: 0.856894
[2022-06-10 11:09:25 | train] - Train Epoch: [99] [985600/1281167 (77%)]	Loss: 0.823455
[2022-06-10 11:09:45 | train] - Train Epoch: [99] [998400/1281167 (78%)]	Loss: 0.784293
[2022-06-10 11:10:07 | train] - Train Epoch: [99] [1011200/1281167 (79%)]	Loss: 0.790697
[2022-06-10 11:10:28 | train] - Train Epoch: [99] [1024000/1281167 (80%)]	Loss: 0.938494
[2022-06-10 11:10:50 | train] - Train Epoch: [99] [1036800/1281167 (81%)]	Loss: 0.982589
[2022-06-10 11:11:12 | train] - Train Epoch: [99] [1049600/1281167 (82%)]	Loss: 0.985942
[2022-06-10 11:11:34 | train] - Train Epoch: [99] [1062400/1281167 (83%)]	Loss: 0.891945
[2022-06-10 11:11:55 | train] - Train Epoch: [99] [1075200/1281167 (84%)]	Loss: 0.821276
[2022-06-10 11:12:16 | train] - Train Epoch: [99] [1088000/1281167 (85%)]	Loss: 0.772476
[2022-06-10 11:12:37 | train] - Train Epoch: [99] [1100800/1281167 (86%)]	Loss: 0.877893
[2022-06-10 11:12:58 | train] - Train Epoch: [99] [1113600/1281167 (87%)]	Loss: 1.004586
[2022-06-10 11:13:20 | train] - Train Epoch: [99] [1126400/1281167 (88%)]	Loss: 0.887746
[2022-06-10 11:13:40 | train] - Train Epoch: [99] [1139200/1281167 (89%)]	Loss: 0.837092
[2022-06-10 11:14:01 | train] - Train Epoch: [99] [1152000/1281167 (90%)]	Loss: 0.782125
[2022-06-10 11:14:22 | train] - Train Epoch: [99] [1164800/1281167 (91%)]	Loss: 0.840275
[2022-06-10 11:14:44 | train] - Train Epoch: [99] [1177600/1281167 (92%)]	Loss: 0.891604
[2022-06-10 11:15:06 | train] - Train Epoch: [99] [1190400/1281167 (93%)]	Loss: 0.803205
[2022-06-10 11:15:27 | train] - Train Epoch: [99] [1203200/1281167 (94%)]	Loss: 0.649741
[2022-06-10 11:15:48 | train] - Train Epoch: [99] [1216000/1281167 (95%)]	Loss: 1.063284
[2022-06-10 11:16:09 | train] - Train Epoch: [99] [1228800/1281167 (96%)]	Loss: 0.778818
[2022-06-10 11:16:31 | train] - Train Epoch: [99] [1241600/1281167 (97%)]	Loss: 0.821767
[2022-06-10 11:16:52 | train] - Train Epoch: [99] [1254400/1281167 (98%)]	Loss: 1.009825
[2022-06-10 11:17:13 | train] - Train Epoch: [99] [1267200/1281167 (99%)]	Loss: 0.676831
[2022-06-10 11:17:34 | train] - Train Epoch: [99] [1280000/1281167 (100%)]	Loss: 0.676617
[2022-06-10 11:17:36 | train] - Train Epoch: [99]	 Average Loss: 0.858846	 Total Acc : 79.0119	 Total Top5 Acc : 92.2967
[2022-06-10 11:17:36 | train] - -------99 epoch end-----------
========================================
-------99 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 11:19:08 | train] - 
Epoch [99] Test set: Average loss: 1.3837, Accuracy: 34907/50000 (69.7890%), Top-5 Accuracy: 88.9390%

[2022-06-10 11:19:08 | train] - save intermediate epoch [99] result


[2022-06-10 11:19:35 | train] - -------100 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 11:19:37 | train] - Train Epoch: [100] [0/1281167 (0%)]	Loss: 0.951136
[2022-06-10 11:19:58 | train] - Train Epoch: [100] [12800/1281167 (1%)]	Loss: 1.175130
[2022-06-10 11:20:19 | train] - Train Epoch: [100] [25600/1281167 (2%)]	Loss: 0.830443
[2022-06-10 11:20:41 | train] - Train Epoch: [100] [38400/1281167 (3%)]	Loss: 1.032128
[2022-06-10 11:21:02 | train] - Train Epoch: [100] [51200/1281167 (4%)]	Loss: 0.950797
[2022-06-10 11:21:24 | train] - Train Epoch: [100] [64000/1281167 (5%)]	Loss: 0.935904
[2022-06-10 11:21:46 | train] - Train Epoch: [100] [76800/1281167 (6%)]	Loss: 0.920697
[2022-06-10 11:22:07 | train] - Train Epoch: [100] [89600/1281167 (7%)]	Loss: 0.964137
[2022-06-10 11:22:29 | train] - Train Epoch: [100] [102400/1281167 (8%)]	Loss: 1.317148
[2022-06-10 11:22:51 | train] - Train Epoch: [100] [115200/1281167 (9%)]	Loss: 0.653116
[2022-06-10 11:23:13 | train] - Train Epoch: [100] [128000/1281167 (10%)]	Loss: 0.624031
[2022-06-10 11:23:35 | train] - Train Epoch: [100] [140800/1281167 (11%)]	Loss: 0.788478
[2022-06-10 11:23:56 | train] - Train Epoch: [100] [153600/1281167 (12%)]	Loss: 0.890459
[2022-06-10 11:24:17 | train] - Train Epoch: [100] [166400/1281167 (13%)]	Loss: 0.670630
[2022-06-10 11:24:38 | train] - Train Epoch: [100] [179200/1281167 (14%)]	Loss: 1.056031
[2022-06-10 11:24:59 | train] - Train Epoch: [100] [192000/1281167 (15%)]	Loss: 0.780402
[2022-06-10 11:25:20 | train] - Train Epoch: [100] [204800/1281167 (16%)]	Loss: 0.632787
[2022-06-10 11:25:42 | train] - Train Epoch: [100] [217600/1281167 (17%)]	Loss: 0.833026
[2022-06-10 11:26:03 | train] - Train Epoch: [100] [230400/1281167 (18%)]	Loss: 1.055447
[2022-06-10 11:26:25 | train] - Train Epoch: [100] [243200/1281167 (19%)]	Loss: 0.777157
[2022-06-10 11:26:47 | train] - Train Epoch: [100] [256000/1281167 (20%)]	Loss: 0.819021
[2022-06-10 11:27:08 | train] - Train Epoch: [100] [268800/1281167 (21%)]	Loss: 0.510353
[2022-06-10 11:27:29 | train] - Train Epoch: [100] [281600/1281167 (22%)]	Loss: 0.997189
[2022-06-10 11:27:51 | train] - Train Epoch: [100] [294400/1281167 (23%)]	Loss: 0.662646
[2022-06-10 11:28:12 | train] - Train Epoch: [100] [307200/1281167 (24%)]	Loss: 0.794169
[2022-06-10 11:28:33 | train] - Train Epoch: [100] [320000/1281167 (25%)]	Loss: 0.753184
[2022-06-10 11:28:55 | train] - Train Epoch: [100] [332800/1281167 (26%)]	Loss: 0.761754
[2022-06-10 11:29:17 | train] - Train Epoch: [100] [345600/1281167 (27%)]	Loss: 0.933268
[2022-06-10 11:29:38 | train] - Train Epoch: [100] [358400/1281167 (28%)]	Loss: 0.739467
[2022-06-10 11:29:59 | train] - Train Epoch: [100] [371200/1281167 (29%)]	Loss: 0.705298
[2022-06-10 11:30:21 | train] - Train Epoch: [100] [384000/1281167 (30%)]	Loss: 0.729689
[2022-06-10 11:30:43 | train] - Train Epoch: [100] [396800/1281167 (31%)]	Loss: 0.895395
[2022-06-10 11:31:04 | train] - Train Epoch: [100] [409600/1281167 (32%)]	Loss: 1.127541
[2022-06-10 11:31:26 | train] - Train Epoch: [100] [422400/1281167 (33%)]	Loss: 0.635236
[2022-06-10 11:31:47 | train] - Train Epoch: [100] [435200/1281167 (34%)]	Loss: 0.847551
[2022-06-10 11:32:09 | train] - Train Epoch: [100] [448000/1281167 (35%)]	Loss: 0.770643
[2022-06-10 11:32:31 | train] - Train Epoch: [100] [460800/1281167 (36%)]	Loss: 0.933862
[2022-06-10 11:32:52 | train] - Train Epoch: [100] [473600/1281167 (37%)]	Loss: 0.917836
[2022-06-10 11:33:14 | train] - Train Epoch: [100] [486400/1281167 (38%)]	Loss: 0.637909
[2022-06-10 11:33:34 | train] - Train Epoch: [100] [499200/1281167 (39%)]	Loss: 0.950745
[2022-06-10 11:33:55 | train] - Train Epoch: [100] [512000/1281167 (40%)]	Loss: 0.968234
[2022-06-10 11:34:18 | train] - Train Epoch: [100] [524800/1281167 (41%)]	Loss: 0.836617
[2022-06-10 11:34:38 | train] - Train Epoch: [100] [537600/1281167 (42%)]	Loss: 0.865470
[2022-06-10 11:35:00 | train] - Train Epoch: [100] [550400/1281167 (43%)]	Loss: 0.946380
[2022-06-10 11:35:21 | train] - Train Epoch: [100] [563200/1281167 (44%)]	Loss: 0.774034
[2022-06-10 11:35:43 | train] - Train Epoch: [100] [576000/1281167 (45%)]	Loss: 0.884159
[2022-06-10 11:36:03 | train] - Train Epoch: [100] [588800/1281167 (46%)]	Loss: 0.763584
[2022-06-10 11:36:24 | train] - Train Epoch: [100] [601600/1281167 (47%)]	Loss: 0.788550
[2022-06-10 11:36:46 | train] - Train Epoch: [100] [614400/1281167 (48%)]	Loss: 0.828081
[2022-06-10 11:37:07 | train] - Train Epoch: [100] [627200/1281167 (49%)]	Loss: 1.148312
[2022-06-10 11:37:28 | train] - Train Epoch: [100] [640000/1281167 (50%)]	Loss: 1.061348
[2022-06-10 11:37:50 | train] - Train Epoch: [100] [652800/1281167 (51%)]	Loss: 0.813255
[2022-06-10 11:38:12 | train] - Train Epoch: [100] [665600/1281167 (52%)]	Loss: 0.956454
[2022-06-10 11:38:33 | train] - Train Epoch: [100] [678400/1281167 (53%)]	Loss: 0.616278
[2022-06-10 11:38:56 | train] - Train Epoch: [100] [691200/1281167 (54%)]	Loss: 1.033243
[2022-06-10 11:39:17 | train] - Train Epoch: [100] [704000/1281167 (55%)]	Loss: 1.068212
[2022-06-10 11:39:38 | train] - Train Epoch: [100] [716800/1281167 (56%)]	Loss: 0.796224
[2022-06-10 11:40:00 | train] - Train Epoch: [100] [729600/1281167 (57%)]	Loss: 0.791868
[2022-06-10 11:40:22 | train] - Train Epoch: [100] [742400/1281167 (58%)]	Loss: 0.798218
[2022-06-10 11:40:44 | train] - Train Epoch: [100] [755200/1281167 (59%)]	Loss: 1.062474
[2022-06-10 11:41:05 | train] - Train Epoch: [100] [768000/1281167 (60%)]	Loss: 0.862513
[2022-06-10 11:41:27 | train] - Train Epoch: [100] [780800/1281167 (61%)]	Loss: 0.978166
[2022-06-10 11:41:49 | train] - Train Epoch: [100] [793600/1281167 (62%)]	Loss: 0.869042
[2022-06-10 11:42:10 | train] - Train Epoch: [100] [806400/1281167 (63%)]	Loss: 0.673308
[2022-06-10 11:42:31 | train] - Train Epoch: [100] [819200/1281167 (64%)]	Loss: 0.919900
[2022-06-10 11:42:52 | train] - Train Epoch: [100] [832000/1281167 (65%)]	Loss: 0.802905
[2022-06-10 11:43:14 | train] - Train Epoch: [100] [844800/1281167 (66%)]	Loss: 0.863647
[2022-06-10 11:43:35 | train] - Train Epoch: [100] [857600/1281167 (67%)]	Loss: 1.136172
[2022-06-10 11:43:57 | train] - Train Epoch: [100] [870400/1281167 (68%)]	Loss: 0.733180
[2022-06-10 11:44:19 | train] - Train Epoch: [100] [883200/1281167 (69%)]	Loss: 0.963544
[2022-06-10 11:44:40 | train] - Train Epoch: [100] [896000/1281167 (70%)]	Loss: 1.092360
[2022-06-10 11:45:02 | train] - Train Epoch: [100] [908800/1281167 (71%)]	Loss: 0.992607
[2022-06-10 11:45:22 | train] - Train Epoch: [100] [921600/1281167 (72%)]	Loss: 0.904885
[2022-06-10 11:45:44 | train] - Train Epoch: [100] [934400/1281167 (73%)]	Loss: 0.840749
[2022-06-10 11:46:05 | train] - Train Epoch: [100] [947200/1281167 (74%)]	Loss: 0.896731
[2022-06-10 11:46:27 | train] - Train Epoch: [100] [960000/1281167 (75%)]	Loss: 0.926991
[2022-06-10 11:46:49 | train] - Train Epoch: [100] [972800/1281167 (76%)]	Loss: 1.207168
[2022-06-10 11:47:10 | train] - Train Epoch: [100] [985600/1281167 (77%)]	Loss: 0.720420
[2022-06-10 11:47:31 | train] - Train Epoch: [100] [998400/1281167 (78%)]	Loss: 1.117738
[2022-06-10 11:47:52 | train] - Train Epoch: [100] [1011200/1281167 (79%)]	Loss: 0.602785
[2022-06-10 11:48:14 | train] - Train Epoch: [100] [1024000/1281167 (80%)]	Loss: 0.567762
[2022-06-10 11:48:35 | train] - Train Epoch: [100] [1036800/1281167 (81%)]	Loss: 1.013222
[2022-06-10 11:48:57 | train] - Train Epoch: [100] [1049600/1281167 (82%)]	Loss: 0.742136
[2022-06-10 11:49:19 | train] - Train Epoch: [100] [1062400/1281167 (83%)]	Loss: 1.061996
[2022-06-10 11:49:40 | train] - Train Epoch: [100] [1075200/1281167 (84%)]	Loss: 0.735314
[2022-06-10 11:50:02 | train] - Train Epoch: [100] [1088000/1281167 (85%)]	Loss: 0.814081
[2022-06-10 11:50:24 | train] - Train Epoch: [100] [1100800/1281167 (86%)]	Loss: 0.648333
[2022-06-10 11:50:46 | train] - Train Epoch: [100] [1113600/1281167 (87%)]	Loss: 1.031474
[2022-06-10 11:51:07 | train] - Train Epoch: [100] [1126400/1281167 (88%)]	Loss: 0.918729
[2022-06-10 11:51:29 | train] - Train Epoch: [100] [1139200/1281167 (89%)]	Loss: 0.955536
[2022-06-10 11:51:50 | train] - Train Epoch: [100] [1152000/1281167 (90%)]	Loss: 0.810854
[2022-06-10 11:52:12 | train] - Train Epoch: [100] [1164800/1281167 (91%)]	Loss: 0.614648
[2022-06-10 11:52:34 | train] - Train Epoch: [100] [1177600/1281167 (92%)]	Loss: 0.912840
[2022-06-10 11:52:56 | train] - Train Epoch: [100] [1190400/1281167 (93%)]	Loss: 0.691354
[2022-06-10 11:53:17 | train] - Train Epoch: [100] [1203200/1281167 (94%)]	Loss: 0.956993
[2022-06-10 11:53:38 | train] - Train Epoch: [100] [1216000/1281167 (95%)]	Loss: 0.996604
[2022-06-10 11:53:58 | train] - Train Epoch: [100] [1228800/1281167 (96%)]	Loss: 1.155107
[2022-06-10 11:54:20 | train] - Train Epoch: [100] [1241600/1281167 (97%)]	Loss: 0.835313
[2022-06-10 11:54:42 | train] - Train Epoch: [100] [1254400/1281167 (98%)]	Loss: 1.032751
[2022-06-10 11:55:03 | train] - Train Epoch: [100] [1267200/1281167 (99%)]	Loss: 0.927587
[2022-06-10 11:55:24 | train] - Train Epoch: [100] [1280000/1281167 (100%)]	Loss: 0.720301
[2022-06-10 11:55:26 | train] - Train Epoch: [100]	 Average Loss: 0.858303	 Total Acc : 78.9736	 Total Top5 Acc : 92.2968
[2022-06-10 11:55:26 | train] - -------100 epoch end-----------
========================================
-------100 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 11:57:00 | train] - 
Epoch [100] Test set: Average loss: 1.3787, Accuracy: 34948/50000 (69.8673%), Top-5 Accuracy: 88.8791%

[2022-06-10 11:57:00 | train] - save intermediate epoch [100] result


[2022-06-10 11:57:31 | train] - -------101 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 11:57:32 | train] - Train Epoch: [101] [0/1281167 (0%)]	Loss: 0.864262
[2022-06-10 11:57:54 | train] - Train Epoch: [101] [12800/1281167 (1%)]	Loss: 0.799766
[2022-06-10 11:58:16 | train] - Train Epoch: [101] [25600/1281167 (2%)]	Loss: 0.712678
[2022-06-10 11:58:39 | train] - Train Epoch: [101] [38400/1281167 (3%)]	Loss: 1.066507
[2022-06-10 11:59:01 | train] - Train Epoch: [101] [51200/1281167 (4%)]	Loss: 0.684380
[2022-06-10 11:59:21 | train] - Train Epoch: [101] [64000/1281167 (5%)]	Loss: 0.707388
[2022-06-10 11:59:42 | train] - Train Epoch: [101] [76800/1281167 (6%)]	Loss: 1.230129
[2022-06-10 12:00:04 | train] - Train Epoch: [101] [89600/1281167 (7%)]	Loss: 0.821002
[2022-06-10 12:00:25 | train] - Train Epoch: [101] [102400/1281167 (8%)]	Loss: 1.052559
[2022-06-10 12:00:46 | train] - Train Epoch: [101] [115200/1281167 (9%)]	Loss: 1.018816
[2022-06-10 12:01:09 | train] - Train Epoch: [101] [128000/1281167 (10%)]	Loss: 0.782631
[2022-06-10 12:01:31 | train] - Train Epoch: [101] [140800/1281167 (11%)]	Loss: 0.883740
[2022-06-10 12:01:52 | train] - Train Epoch: [101] [153600/1281167 (12%)]	Loss: 0.896125
[2022-06-10 12:02:14 | train] - Train Epoch: [101] [166400/1281167 (13%)]	Loss: 0.804817
[2022-06-10 12:02:36 | train] - Train Epoch: [101] [179200/1281167 (14%)]	Loss: 0.664620
[2022-06-10 12:02:57 | train] - Train Epoch: [101] [192000/1281167 (15%)]	Loss: 0.933323
[2022-06-10 12:03:19 | train] - Train Epoch: [101] [204800/1281167 (16%)]	Loss: 1.072336
[2022-06-10 12:03:41 | train] - Train Epoch: [101] [217600/1281167 (17%)]	Loss: 0.669426
[2022-06-10 12:04:02 | train] - Train Epoch: [101] [230400/1281167 (18%)]	Loss: 0.865425
[2022-06-10 12:04:25 | train] - Train Epoch: [101] [243200/1281167 (19%)]	Loss: 0.758678
[2022-06-10 12:04:47 | train] - Train Epoch: [101] [256000/1281167 (20%)]	Loss: 0.888568
[2022-06-10 12:05:09 | train] - Train Epoch: [101] [268800/1281167 (21%)]	Loss: 0.978475
[2022-06-10 12:05:31 | train] - Train Epoch: [101] [281600/1281167 (22%)]	Loss: 0.795005
[2022-06-10 12:05:51 | train] - Train Epoch: [101] [294400/1281167 (23%)]	Loss: 0.750098
[2022-06-10 12:06:12 | train] - Train Epoch: [101] [307200/1281167 (24%)]	Loss: 1.045357
[2022-06-10 12:06:34 | train] - Train Epoch: [101] [320000/1281167 (25%)]	Loss: 0.819997
[2022-06-10 12:06:55 | train] - Train Epoch: [101] [332800/1281167 (26%)]	Loss: 0.869369
[2022-06-10 12:07:17 | train] - Train Epoch: [101] [345600/1281167 (27%)]	Loss: 1.042662
[2022-06-10 12:07:40 | train] - Train Epoch: [101] [358400/1281167 (28%)]	Loss: 0.762998
[2022-06-10 12:08:02 | train] - Train Epoch: [101] [371200/1281167 (29%)]	Loss: 0.708827
[2022-06-10 12:08:24 | train] - Train Epoch: [101] [384000/1281167 (30%)]	Loss: 1.279905
[2022-06-10 12:08:46 | train] - Train Epoch: [101] [396800/1281167 (31%)]	Loss: 1.019882
[2022-06-10 12:09:08 | train] - Train Epoch: [101] [409600/1281167 (32%)]	Loss: 0.832936
[2022-06-10 12:09:29 | train] - Train Epoch: [101] [422400/1281167 (33%)]	Loss: 0.784358
[2022-06-10 12:09:51 | train] - Train Epoch: [101] [435200/1281167 (34%)]	Loss: 0.939544
[2022-06-10 12:10:12 | train] - Train Epoch: [101] [448000/1281167 (35%)]	Loss: 0.824178
[2022-06-10 12:10:34 | train] - Train Epoch: [101] [460800/1281167 (36%)]	Loss: 0.657375
[2022-06-10 12:10:55 | train] - Train Epoch: [101] [473600/1281167 (37%)]	Loss: 0.864552
[2022-06-10 12:11:17 | train] - Train Epoch: [101] [486400/1281167 (38%)]	Loss: 0.606520
[2022-06-10 12:11:38 | train] - Train Epoch: [101] [499200/1281167 (39%)]	Loss: 0.760393
[2022-06-10 12:12:00 | train] - Train Epoch: [101] [512000/1281167 (40%)]	Loss: 0.853487
[2022-06-10 12:12:22 | train] - Train Epoch: [101] [524800/1281167 (41%)]	Loss: 0.817866
[2022-06-10 12:12:44 | train] - Train Epoch: [101] [537600/1281167 (42%)]	Loss: 1.118258
[2022-06-10 12:13:05 | train] - Train Epoch: [101] [550400/1281167 (43%)]	Loss: 0.921942
[2022-06-10 12:13:26 | train] - Train Epoch: [101] [563200/1281167 (44%)]	Loss: 0.902221
[2022-06-10 12:13:48 | train] - Train Epoch: [101] [576000/1281167 (45%)]	Loss: 0.877582
[2022-06-10 12:14:10 | train] - Train Epoch: [101] [588800/1281167 (46%)]	Loss: 0.882074
[2022-06-10 12:14:33 | train] - Train Epoch: [101] [601600/1281167 (47%)]	Loss: 0.815819
[2022-06-10 12:14:54 | train] - Train Epoch: [101] [614400/1281167 (48%)]	Loss: 0.772889
[2022-06-10 12:15:16 | train] - Train Epoch: [101] [627200/1281167 (49%)]	Loss: 0.715115
[2022-06-10 12:15:38 | train] - Train Epoch: [101] [640000/1281167 (50%)]	Loss: 0.901755
[2022-06-10 12:16:01 | train] - Train Epoch: [101] [652800/1281167 (51%)]	Loss: 0.652013
[2022-06-10 12:16:22 | train] - Train Epoch: [101] [665600/1281167 (52%)]	Loss: 0.914784
[2022-06-10 12:16:44 | train] - Train Epoch: [101] [678400/1281167 (53%)]	Loss: 0.979935
[2022-06-10 12:17:06 | train] - Train Epoch: [101] [691200/1281167 (54%)]	Loss: 1.194913
[2022-06-10 12:17:27 | train] - Train Epoch: [101] [704000/1281167 (55%)]	Loss: 0.919095
[2022-06-10 12:17:49 | train] - Train Epoch: [101] [716800/1281167 (56%)]	Loss: 0.984908
[2022-06-10 12:18:11 | train] - Train Epoch: [101] [729600/1281167 (57%)]	Loss: 1.005492
[2022-06-10 12:18:33 | train] - Train Epoch: [101] [742400/1281167 (58%)]	Loss: 1.003842
[2022-06-10 12:18:55 | train] - Train Epoch: [101] [755200/1281167 (59%)]	Loss: 0.729295
[2022-06-10 12:19:17 | train] - Train Epoch: [101] [768000/1281167 (60%)]	Loss: 0.713187
[2022-06-10 12:19:39 | train] - Train Epoch: [101] [780800/1281167 (61%)]	Loss: 1.006058
[2022-06-10 12:20:00 | train] - Train Epoch: [101] [793600/1281167 (62%)]	Loss: 0.835272
[2022-06-10 12:20:22 | train] - Train Epoch: [101] [806400/1281167 (63%)]	Loss: 0.708708
[2022-06-10 12:20:44 | train] - Train Epoch: [101] [819200/1281167 (64%)]	Loss: 0.717286
[2022-06-10 12:21:06 | train] - Train Epoch: [101] [832000/1281167 (65%)]	Loss: 0.891328
[2022-06-10 12:21:27 | train] - Train Epoch: [101] [844800/1281167 (66%)]	Loss: 0.710473
[2022-06-10 12:21:49 | train] - Train Epoch: [101] [857600/1281167 (67%)]	Loss: 0.716697
[2022-06-10 12:22:10 | train] - Train Epoch: [101] [870400/1281167 (68%)]	Loss: 0.860984
[2022-06-10 12:22:32 | train] - Train Epoch: [101] [883200/1281167 (69%)]	Loss: 0.749874
[2022-06-10 12:22:53 | train] - Train Epoch: [101] [896000/1281167 (70%)]	Loss: 0.862201
[2022-06-10 12:23:15 | train] - Train Epoch: [101] [908800/1281167 (71%)]	Loss: 0.717610
[2022-06-10 12:23:37 | train] - Train Epoch: [101] [921600/1281167 (72%)]	Loss: 0.869817
[2022-06-10 12:23:58 | train] - Train Epoch: [101] [934400/1281167 (73%)]	Loss: 0.961890
[2022-06-10 12:24:20 | train] - Train Epoch: [101] [947200/1281167 (74%)]	Loss: 0.875701
[2022-06-10 12:24:42 | train] - Train Epoch: [101] [960000/1281167 (75%)]	Loss: 0.921311
[2022-06-10 12:25:03 | train] - Train Epoch: [101] [972800/1281167 (76%)]	Loss: 0.925815
[2022-06-10 12:25:26 | train] - Train Epoch: [101] [985600/1281167 (77%)]	Loss: 1.069860
[2022-06-10 12:25:46 | train] - Train Epoch: [101] [998400/1281167 (78%)]	Loss: 0.838137
[2022-06-10 12:26:08 | train] - Train Epoch: [101] [1011200/1281167 (79%)]	Loss: 0.833590
[2022-06-10 12:26:29 | train] - Train Epoch: [101] [1024000/1281167 (80%)]	Loss: 0.879403
[2022-06-10 12:26:51 | train] - Train Epoch: [101] [1036800/1281167 (81%)]	Loss: 0.977290
[2022-06-10 12:27:12 | train] - Train Epoch: [101] [1049600/1281167 (82%)]	Loss: 0.863692
[2022-06-10 12:27:35 | train] - Train Epoch: [101] [1062400/1281167 (83%)]	Loss: 0.920940
[2022-06-10 12:27:56 | train] - Train Epoch: [101] [1075200/1281167 (84%)]	Loss: 0.773037
[2022-06-10 12:28:18 | train] - Train Epoch: [101] [1088000/1281167 (85%)]	Loss: 0.761215
[2022-06-10 12:28:41 | train] - Train Epoch: [101] [1100800/1281167 (86%)]	Loss: 0.640935
[2022-06-10 12:29:02 | train] - Train Epoch: [101] [1113600/1281167 (87%)]	Loss: 0.752211
[2022-06-10 12:29:24 | train] - Train Epoch: [101] [1126400/1281167 (88%)]	Loss: 0.917284
[2022-06-10 12:29:45 | train] - Train Epoch: [101] [1139200/1281167 (89%)]	Loss: 0.797431
[2022-06-10 12:30:07 | train] - Train Epoch: [101] [1152000/1281167 (90%)]	Loss: 0.853501
[2022-06-10 12:30:29 | train] - Train Epoch: [101] [1164800/1281167 (91%)]	Loss: 1.159613
[2022-06-10 12:30:51 | train] - Train Epoch: [101] [1177600/1281167 (92%)]	Loss: 0.747485
[2022-06-10 12:31:13 | train] - Train Epoch: [101] [1190400/1281167 (93%)]	Loss: 0.970976
[2022-06-10 12:31:35 | train] - Train Epoch: [101] [1203200/1281167 (94%)]	Loss: 0.942031
[2022-06-10 12:31:56 | train] - Train Epoch: [101] [1216000/1281167 (95%)]	Loss: 0.637195
[2022-06-10 12:32:18 | train] - Train Epoch: [101] [1228800/1281167 (96%)]	Loss: 0.979135
[2022-06-10 12:32:40 | train] - Train Epoch: [101] [1241600/1281167 (97%)]	Loss: 0.734486
[2022-06-10 12:33:01 | train] - Train Epoch: [101] [1254400/1281167 (98%)]	Loss: 0.815592
[2022-06-10 12:33:22 | train] - Train Epoch: [101] [1267200/1281167 (99%)]	Loss: 0.982934
[2022-06-10 12:33:44 | train] - Train Epoch: [101] [1280000/1281167 (100%)]	Loss: 0.681587
[2022-06-10 12:33:46 | train] - Train Epoch: [101]	 Average Loss: 0.856892	 Total Acc : 79.0594	 Total Top5 Acc : 92.3109
[2022-06-10 12:33:46 | train] - -------101 epoch end-----------
========================================
-------101 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 12:35:18 | train] - 
Epoch [101] Test set: Average loss: 1.3856, Accuracy: 34936/50000 (69.8410%), Top-5 Accuracy: 89.0034%

[2022-06-10 12:35:18 | train] - save intermediate epoch [101] result


[2022-06-10 12:35:50 | train] - -------102 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 12:35:52 | train] - Train Epoch: [102] [0/1281167 (0%)]	Loss: 0.693756
[2022-06-10 12:36:13 | train] - Train Epoch: [102] [12800/1281167 (1%)]	Loss: 0.703576
[2022-06-10 12:36:33 | train] - Train Epoch: [102] [25600/1281167 (2%)]	Loss: 0.837114
[2022-06-10 12:36:55 | train] - Train Epoch: [102] [38400/1281167 (3%)]	Loss: 0.613912
[2022-06-10 12:37:16 | train] - Train Epoch: [102] [51200/1281167 (4%)]	Loss: 0.732929
[2022-06-10 12:37:37 | train] - Train Epoch: [102] [64000/1281167 (5%)]	Loss: 0.894142
[2022-06-10 12:37:58 | train] - Train Epoch: [102] [76800/1281167 (6%)]	Loss: 1.007359
[2022-06-10 12:38:21 | train] - Train Epoch: [102] [89600/1281167 (7%)]	Loss: 0.685286
[2022-06-10 12:38:42 | train] - Train Epoch: [102] [102400/1281167 (8%)]	Loss: 0.645702
[2022-06-10 12:39:04 | train] - Train Epoch: [102] [115200/1281167 (9%)]	Loss: 0.886496
[2022-06-10 12:39:26 | train] - Train Epoch: [102] [128000/1281167 (10%)]	Loss: 0.734323
[2022-06-10 12:39:47 | train] - Train Epoch: [102] [140800/1281167 (11%)]	Loss: 1.045663
[2022-06-10 12:40:07 | train] - Train Epoch: [102] [153600/1281167 (12%)]	Loss: 0.787404
[2022-06-10 12:40:28 | train] - Train Epoch: [102] [166400/1281167 (13%)]	Loss: 0.845988
[2022-06-10 12:40:49 | train] - Train Epoch: [102] [179200/1281167 (14%)]	Loss: 0.828178
[2022-06-10 12:41:10 | train] - Train Epoch: [102] [192000/1281167 (15%)]	Loss: 0.834011
[2022-06-10 12:41:31 | train] - Train Epoch: [102] [204800/1281167 (16%)]	Loss: 0.697957
[2022-06-10 12:41:53 | train] - Train Epoch: [102] [217600/1281167 (17%)]	Loss: 0.492018
[2022-06-10 12:42:15 | train] - Train Epoch: [102] [230400/1281167 (18%)]	Loss: 0.850381
[2022-06-10 12:42:36 | train] - Train Epoch: [102] [243200/1281167 (19%)]	Loss: 0.901217
[2022-06-10 12:42:58 | train] - Train Epoch: [102] [256000/1281167 (20%)]	Loss: 0.705452
[2022-06-10 12:43:19 | train] - Train Epoch: [102] [268800/1281167 (21%)]	Loss: 0.736464
[2022-06-10 12:43:40 | train] - Train Epoch: [102] [281600/1281167 (22%)]	Loss: 0.852209
[2022-06-10 12:44:02 | train] - Train Epoch: [102] [294400/1281167 (23%)]	Loss: 0.865186
[2022-06-10 12:44:23 | train] - Train Epoch: [102] [307200/1281167 (24%)]	Loss: 0.840066
[2022-06-10 12:44:45 | train] - Train Epoch: [102] [320000/1281167 (25%)]	Loss: 0.490002
[2022-06-10 12:45:06 | train] - Train Epoch: [102] [332800/1281167 (26%)]	Loss: 0.740197
[2022-06-10 12:45:28 | train] - Train Epoch: [102] [345600/1281167 (27%)]	Loss: 1.099780
[2022-06-10 12:45:49 | train] - Train Epoch: [102] [358400/1281167 (28%)]	Loss: 0.812034
[2022-06-10 12:46:11 | train] - Train Epoch: [102] [371200/1281167 (29%)]	Loss: 1.093382
[2022-06-10 12:46:32 | train] - Train Epoch: [102] [384000/1281167 (30%)]	Loss: 0.870712
[2022-06-10 12:46:54 | train] - Train Epoch: [102] [396800/1281167 (31%)]	Loss: 0.880859
[2022-06-10 12:47:15 | train] - Train Epoch: [102] [409600/1281167 (32%)]	Loss: 0.968731
[2022-06-10 12:47:36 | train] - Train Epoch: [102] [422400/1281167 (33%)]	Loss: 0.810149
[2022-06-10 12:47:57 | train] - Train Epoch: [102] [435200/1281167 (34%)]	Loss: 0.777221
[2022-06-10 12:48:18 | train] - Train Epoch: [102] [448000/1281167 (35%)]	Loss: 0.785209
[2022-06-10 12:48:40 | train] - Train Epoch: [102] [460800/1281167 (36%)]	Loss: 0.699408
[2022-06-10 12:49:01 | train] - Train Epoch: [102] [473600/1281167 (37%)]	Loss: 0.960313
[2022-06-10 12:49:21 | train] - Train Epoch: [102] [486400/1281167 (38%)]	Loss: 0.945113
[2022-06-10 12:49:43 | train] - Train Epoch: [102] [499200/1281167 (39%)]	Loss: 0.961305
[2022-06-10 12:50:05 | train] - Train Epoch: [102] [512000/1281167 (40%)]	Loss: 0.803427
[2022-06-10 12:50:26 | train] - Train Epoch: [102] [524800/1281167 (41%)]	Loss: 0.865320
[2022-06-10 12:50:47 | train] - Train Epoch: [102] [537600/1281167 (42%)]	Loss: 1.039307
[2022-06-10 12:51:08 | train] - Train Epoch: [102] [550400/1281167 (43%)]	Loss: 0.671704
[2022-06-10 12:51:29 | train] - Train Epoch: [102] [563200/1281167 (44%)]	Loss: 1.092321
[2022-06-10 12:51:50 | train] - Train Epoch: [102] [576000/1281167 (45%)]	Loss: 1.039114
[2022-06-10 12:52:11 | train] - Train Epoch: [102] [588800/1281167 (46%)]	Loss: 0.752360
[2022-06-10 12:52:33 | train] - Train Epoch: [102] [601600/1281167 (47%)]	Loss: 0.734707
[2022-06-10 12:52:55 | train] - Train Epoch: [102] [614400/1281167 (48%)]	Loss: 0.948790
[2022-06-10 12:53:16 | train] - Train Epoch: [102] [627200/1281167 (49%)]	Loss: 0.810919
[2022-06-10 12:53:38 | train] - Train Epoch: [102] [640000/1281167 (50%)]	Loss: 1.053075
[2022-06-10 12:53:59 | train] - Train Epoch: [102] [652800/1281167 (51%)]	Loss: 0.946782
[2022-06-10 12:54:19 | train] - Train Epoch: [102] [665600/1281167 (52%)]	Loss: 0.721521
[2022-06-10 12:54:41 | train] - Train Epoch: [102] [678400/1281167 (53%)]	Loss: 0.833156
[2022-06-10 12:55:02 | train] - Train Epoch: [102] [691200/1281167 (54%)]	Loss: 1.025691
[2022-06-10 12:55:24 | train] - Train Epoch: [102] [704000/1281167 (55%)]	Loss: 1.021665
[2022-06-10 12:55:45 | train] - Train Epoch: [102] [716800/1281167 (56%)]	Loss: 1.061270
[2022-06-10 12:56:06 | train] - Train Epoch: [102] [729600/1281167 (57%)]	Loss: 0.908641
[2022-06-10 12:56:28 | train] - Train Epoch: [102] [742400/1281167 (58%)]	Loss: 1.074133
[2022-06-10 12:56:49 | train] - Train Epoch: [102] [755200/1281167 (59%)]	Loss: 1.013941
[2022-06-10 12:57:09 | train] - Train Epoch: [102] [768000/1281167 (60%)]	Loss: 0.923897
[2022-06-10 12:57:31 | train] - Train Epoch: [102] [780800/1281167 (61%)]	Loss: 1.072892
[2022-06-10 12:57:53 | train] - Train Epoch: [102] [793600/1281167 (62%)]	Loss: 0.497599
[2022-06-10 12:58:15 | train] - Train Epoch: [102] [806400/1281167 (63%)]	Loss: 0.675624
[2022-06-10 12:58:36 | train] - Train Epoch: [102] [819200/1281167 (64%)]	Loss: 1.154690
[2022-06-10 12:58:57 | train] - Train Epoch: [102] [832000/1281167 (65%)]	Loss: 0.932153
[2022-06-10 12:59:19 | train] - Train Epoch: [102] [844800/1281167 (66%)]	Loss: 0.942065
[2022-06-10 12:59:40 | train] - Train Epoch: [102] [857600/1281167 (67%)]	Loss: 1.050985
[2022-06-10 13:00:01 | train] - Train Epoch: [102] [870400/1281167 (68%)]	Loss: 0.858247
[2022-06-10 13:00:23 | train] - Train Epoch: [102] [883200/1281167 (69%)]	Loss: 1.167352
[2022-06-10 13:00:44 | train] - Train Epoch: [102] [896000/1281167 (70%)]	Loss: 0.911476
[2022-06-10 13:01:05 | train] - Train Epoch: [102] [908800/1281167 (71%)]	Loss: 0.886695
[2022-06-10 13:01:26 | train] - Train Epoch: [102] [921600/1281167 (72%)]	Loss: 0.614139
[2022-06-10 13:01:47 | train] - Train Epoch: [102] [934400/1281167 (73%)]	Loss: 0.957854
[2022-06-10 13:02:09 | train] - Train Epoch: [102] [947200/1281167 (74%)]	Loss: 0.827605
[2022-06-10 13:02:30 | train] - Train Epoch: [102] [960000/1281167 (75%)]	Loss: 0.974004
[2022-06-10 13:02:51 | train] - Train Epoch: [102] [972800/1281167 (76%)]	Loss: 1.029628
[2022-06-10 13:03:13 | train] - Train Epoch: [102] [985600/1281167 (77%)]	Loss: 0.950550
[2022-06-10 13:03:35 | train] - Train Epoch: [102] [998400/1281167 (78%)]	Loss: 0.976629
[2022-06-10 13:03:56 | train] - Train Epoch: [102] [1011200/1281167 (79%)]	Loss: 0.831566
[2022-06-10 13:04:17 | train] - Train Epoch: [102] [1024000/1281167 (80%)]	Loss: 0.874254
[2022-06-10 13:04:38 | train] - Train Epoch: [102] [1036800/1281167 (81%)]	Loss: 0.870285
[2022-06-10 13:04:59 | train] - Train Epoch: [102] [1049600/1281167 (82%)]	Loss: 0.761189
[2022-06-10 13:05:21 | train] - Train Epoch: [102] [1062400/1281167 (83%)]	Loss: 0.972641
[2022-06-10 13:05:42 | train] - Train Epoch: [102] [1075200/1281167 (84%)]	Loss: 0.992424
[2022-06-10 13:06:03 | train] - Train Epoch: [102] [1088000/1281167 (85%)]	Loss: 0.889856
[2022-06-10 13:06:23 | train] - Train Epoch: [102] [1100800/1281167 (86%)]	Loss: 0.765619
[2022-06-10 13:06:45 | train] - Train Epoch: [102] [1113600/1281167 (87%)]	Loss: 0.945786
[2022-06-10 13:07:07 | train] - Train Epoch: [102] [1126400/1281167 (88%)]	Loss: 0.840526
[2022-06-10 13:07:28 | train] - Train Epoch: [102] [1139200/1281167 (89%)]	Loss: 0.642919
[2022-06-10 13:07:50 | train] - Train Epoch: [102] [1152000/1281167 (90%)]	Loss: 0.929733
[2022-06-10 13:08:12 | train] - Train Epoch: [102] [1164800/1281167 (91%)]	Loss: 1.037628
[2022-06-10 13:08:33 | train] - Train Epoch: [102] [1177600/1281167 (92%)]	Loss: 1.251115
[2022-06-10 13:08:55 | train] - Train Epoch: [102] [1190400/1281167 (93%)]	Loss: 0.932952
[2022-06-10 13:09:17 | train] - Train Epoch: [102] [1203200/1281167 (94%)]	Loss: 0.730391
[2022-06-10 13:09:38 | train] - Train Epoch: [102] [1216000/1281167 (95%)]	Loss: 0.899514
[2022-06-10 13:10:00 | train] - Train Epoch: [102] [1228800/1281167 (96%)]	Loss: 0.923007
[2022-06-10 13:10:21 | train] - Train Epoch: [102] [1241600/1281167 (97%)]	Loss: 0.651360
[2022-06-10 13:10:42 | train] - Train Epoch: [102] [1254400/1281167 (98%)]	Loss: 0.650196
[2022-06-10 13:11:04 | train] - Train Epoch: [102] [1267200/1281167 (99%)]	Loss: 0.797797
[2022-06-10 13:11:26 | train] - Train Epoch: [102] [1280000/1281167 (100%)]	Loss: 0.722237
[2022-06-10 13:11:28 | train] - Train Epoch: [102]	 Average Loss: 0.852214	 Total Acc : 79.1426	 Total Top5 Acc : 92.3831
[2022-06-10 13:11:28 | train] - -------102 epoch end-----------
========================================
-------102 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 13:13:02 | train] - 
Epoch [102] Test set: Average loss: 1.3938, Accuracy: 34971/50000 (69.9133%), Top-5 Accuracy: 88.8019%

[2022-06-10 13:13:02 | train] - save intermediate epoch [102] result


[2022-06-10 13:13:32 | train] - -------103 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 13:13:34 | train] - Train Epoch: [103] [0/1281167 (0%)]	Loss: 0.779414
[2022-06-10 13:13:56 | train] - Train Epoch: [103] [12800/1281167 (1%)]	Loss: 0.829583
[2022-06-10 13:14:18 | train] - Train Epoch: [103] [25600/1281167 (2%)]	Loss: 0.675454
[2022-06-10 13:14:38 | train] - Train Epoch: [103] [38400/1281167 (3%)]	Loss: 0.801122
[2022-06-10 13:15:00 | train] - Train Epoch: [103] [51200/1281167 (4%)]	Loss: 0.915416
[2022-06-10 13:15:22 | train] - Train Epoch: [103] [64000/1281167 (5%)]	Loss: 0.800209
[2022-06-10 13:15:44 | train] - Train Epoch: [103] [76800/1281167 (6%)]	Loss: 0.797426
[2022-06-10 13:16:05 | train] - Train Epoch: [103] [89600/1281167 (7%)]	Loss: 0.994272
[2022-06-10 13:16:27 | train] - Train Epoch: [103] [102400/1281167 (8%)]	Loss: 0.972609
[2022-06-10 13:16:48 | train] - Train Epoch: [103] [115200/1281167 (9%)]	Loss: 0.887030
[2022-06-10 13:17:09 | train] - Train Epoch: [103] [128000/1281167 (10%)]	Loss: 0.858358
[2022-06-10 13:17:31 | train] - Train Epoch: [103] [140800/1281167 (11%)]	Loss: 0.775064
[2022-06-10 13:17:53 | train] - Train Epoch: [103] [153600/1281167 (12%)]	Loss: 0.544332
[2022-06-10 13:18:14 | train] - Train Epoch: [103] [166400/1281167 (13%)]	Loss: 0.742435
[2022-06-10 13:18:36 | train] - Train Epoch: [103] [179200/1281167 (14%)]	Loss: 0.842665
[2022-06-10 13:18:56 | train] - Train Epoch: [103] [192000/1281167 (15%)]	Loss: 0.699859
[2022-06-10 13:19:18 | train] - Train Epoch: [103] [204800/1281167 (16%)]	Loss: 0.836907
[2022-06-10 13:19:39 | train] - Train Epoch: [103] [217600/1281167 (17%)]	Loss: 0.624095
[2022-06-10 13:20:00 | train] - Train Epoch: [103] [230400/1281167 (18%)]	Loss: 0.817913
[2022-06-10 13:20:22 | train] - Train Epoch: [103] [243200/1281167 (19%)]	Loss: 1.012021
[2022-06-10 13:20:43 | train] - Train Epoch: [103] [256000/1281167 (20%)]	Loss: 0.912573
[2022-06-10 13:21:05 | train] - Train Epoch: [103] [268800/1281167 (21%)]	Loss: 1.004587
[2022-06-10 13:21:27 | train] - Train Epoch: [103] [281600/1281167 (22%)]	Loss: 0.895896
[2022-06-10 13:21:49 | train] - Train Epoch: [103] [294400/1281167 (23%)]	Loss: 0.983874
[2022-06-10 13:22:11 | train] - Train Epoch: [103] [307200/1281167 (24%)]	Loss: 0.712375
[2022-06-10 13:22:32 | train] - Train Epoch: [103] [320000/1281167 (25%)]	Loss: 1.018713
[2022-06-10 13:22:53 | train] - Train Epoch: [103] [332800/1281167 (26%)]	Loss: 0.809831
[2022-06-10 13:23:15 | train] - Train Epoch: [103] [345600/1281167 (27%)]	Loss: 1.002265
[2022-06-10 13:23:37 | train] - Train Epoch: [103] [358400/1281167 (28%)]	Loss: 0.694839
[2022-06-10 13:23:59 | train] - Train Epoch: [103] [371200/1281167 (29%)]	Loss: 1.046042
[2022-06-10 13:24:20 | train] - Train Epoch: [103] [384000/1281167 (30%)]	Loss: 0.841820
[2022-06-10 13:24:40 | train] - Train Epoch: [103] [396800/1281167 (31%)]	Loss: 0.793138
[2022-06-10 13:25:00 | train] - Train Epoch: [103] [409600/1281167 (32%)]	Loss: 0.702995
[2022-06-10 13:25:20 | train] - Train Epoch: [103] [422400/1281167 (33%)]	Loss: 0.963436
[2022-06-10 13:25:39 | train] - Train Epoch: [103] [435200/1281167 (34%)]	Loss: 0.866883
[2022-06-10 13:25:59 | train] - Train Epoch: [103] [448000/1281167 (35%)]	Loss: 1.082851
[2022-06-10 13:26:19 | train] - Train Epoch: [103] [460800/1281167 (36%)]	Loss: 0.981759
[2022-06-10 13:26:39 | train] - Train Epoch: [103] [473600/1281167 (37%)]	Loss: 0.764800
[2022-06-10 13:26:59 | train] - Train Epoch: [103] [486400/1281167 (38%)]	Loss: 0.971647
[2022-06-10 13:27:19 | train] - Train Epoch: [103] [499200/1281167 (39%)]	Loss: 0.922097
[2022-06-10 13:27:39 | train] - Train Epoch: [103] [512000/1281167 (40%)]	Loss: 1.152766
[2022-06-10 13:27:59 | train] - Train Epoch: [103] [524800/1281167 (41%)]	Loss: 0.600268
[2022-06-10 13:28:18 | train] - Train Epoch: [103] [537600/1281167 (42%)]	Loss: 0.938926
[2022-06-10 13:28:38 | train] - Train Epoch: [103] [550400/1281167 (43%)]	Loss: 0.794203
[2022-06-10 13:28:59 | train] - Train Epoch: [103] [563200/1281167 (44%)]	Loss: 0.806532
[2022-06-10 13:29:20 | train] - Train Epoch: [103] [576000/1281167 (45%)]	Loss: 1.001834
[2022-06-10 13:29:39 | train] - Train Epoch: [103] [588800/1281167 (46%)]	Loss: 0.867376
[2022-06-10 13:29:59 | train] - Train Epoch: [103] [601600/1281167 (47%)]	Loss: 0.922799
[2022-06-10 13:30:18 | train] - Train Epoch: [103] [614400/1281167 (48%)]	Loss: 0.939669
[2022-06-10 13:30:38 | train] - Train Epoch: [103] [627200/1281167 (49%)]	Loss: 0.735672
[2022-06-10 13:30:58 | train] - Train Epoch: [103] [640000/1281167 (50%)]	Loss: 0.996280
[2022-06-10 13:31:18 | train] - Train Epoch: [103] [652800/1281167 (51%)]	Loss: 0.977716
[2022-06-10 13:31:38 | train] - Train Epoch: [103] [665600/1281167 (52%)]	Loss: 0.764346
[2022-06-10 13:31:57 | train] - Train Epoch: [103] [678400/1281167 (53%)]	Loss: 0.919534
[2022-06-10 13:32:18 | train] - Train Epoch: [103] [691200/1281167 (54%)]	Loss: 0.945597
[2022-06-10 13:32:36 | train] - Train Epoch: [103] [704000/1281167 (55%)]	Loss: 0.759148
[2022-06-10 13:32:57 | train] - Train Epoch: [103] [716800/1281167 (56%)]	Loss: 0.782654
[2022-06-10 13:33:18 | train] - Train Epoch: [103] [729600/1281167 (57%)]	Loss: 0.748431
[2022-06-10 13:33:39 | train] - Train Epoch: [103] [742400/1281167 (58%)]	Loss: 0.705337
[2022-06-10 13:33:58 | train] - Train Epoch: [103] [755200/1281167 (59%)]	Loss: 0.547110
[2022-06-10 13:34:17 | train] - Train Epoch: [103] [768000/1281167 (60%)]	Loss: 1.042506
[2022-06-10 13:34:37 | train] - Train Epoch: [103] [780800/1281167 (61%)]	Loss: 0.663125
[2022-06-10 13:34:57 | train] - Train Epoch: [103] [793600/1281167 (62%)]	Loss: 0.929979
[2022-06-10 13:35:18 | train] - Train Epoch: [103] [806400/1281167 (63%)]	Loss: 0.727451
[2022-06-10 13:35:39 | train] - Train Epoch: [103] [819200/1281167 (64%)]	Loss: 0.956415
[2022-06-10 13:36:00 | train] - Train Epoch: [103] [832000/1281167 (65%)]	Loss: 0.964135
[2022-06-10 13:36:21 | train] - Train Epoch: [103] [844800/1281167 (66%)]	Loss: 0.707363
[2022-06-10 13:36:42 | train] - Train Epoch: [103] [857600/1281167 (67%)]	Loss: 0.679379
[2022-06-10 13:37:02 | train] - Train Epoch: [103] [870400/1281167 (68%)]	Loss: 0.879149
[2022-06-10 13:37:22 | train] - Train Epoch: [103] [883200/1281167 (69%)]	Loss: 1.084336
[2022-06-10 13:37:42 | train] - Train Epoch: [103] [896000/1281167 (70%)]	Loss: 0.603274
[2022-06-10 13:38:01 | train] - Train Epoch: [103] [908800/1281167 (71%)]	Loss: 0.754736
[2022-06-10 13:38:21 | train] - Train Epoch: [103] [921600/1281167 (72%)]	Loss: 0.913663
[2022-06-10 13:38:41 | train] - Train Epoch: [103] [934400/1281167 (73%)]	Loss: 0.758486
[2022-06-10 13:39:00 | train] - Train Epoch: [103] [947200/1281167 (74%)]	Loss: 0.892553
[2022-06-10 13:39:20 | train] - Train Epoch: [103] [960000/1281167 (75%)]	Loss: 0.773227
[2022-06-10 13:39:40 | train] - Train Epoch: [103] [972800/1281167 (76%)]	Loss: 0.721390
[2022-06-10 13:40:00 | train] - Train Epoch: [103] [985600/1281167 (77%)]	Loss: 0.802872
[2022-06-10 13:40:20 | train] - Train Epoch: [103] [998400/1281167 (78%)]	Loss: 0.672362
[2022-06-10 13:40:40 | train] - Train Epoch: [103] [1011200/1281167 (79%)]	Loss: 0.855528
[2022-06-10 13:41:00 | train] - Train Epoch: [103] [1024000/1281167 (80%)]	Loss: 1.061752
[2022-06-10 13:41:20 | train] - Train Epoch: [103] [1036800/1281167 (81%)]	Loss: 0.627407
[2022-06-10 13:41:39 | train] - Train Epoch: [103] [1049600/1281167 (82%)]	Loss: 0.831722
[2022-06-10 13:41:59 | train] - Train Epoch: [103] [1062400/1281167 (83%)]	Loss: 0.890643
[2022-06-10 13:42:19 | train] - Train Epoch: [103] [1075200/1281167 (84%)]	Loss: 0.735509
[2022-06-10 13:42:39 | train] - Train Epoch: [103] [1088000/1281167 (85%)]	Loss: 0.673291
[2022-06-10 13:43:00 | train] - Train Epoch: [103] [1100800/1281167 (86%)]	Loss: 0.934686
[2022-06-10 13:43:19 | train] - Train Epoch: [103] [1113600/1281167 (87%)]	Loss: 0.962035
[2022-06-10 13:43:39 | train] - Train Epoch: [103] [1126400/1281167 (88%)]	Loss: 0.946906
[2022-06-10 13:43:59 | train] - Train Epoch: [103] [1139200/1281167 (89%)]	Loss: 0.837896
[2022-06-10 13:44:19 | train] - Train Epoch: [103] [1152000/1281167 (90%)]	Loss: 0.940603
[2022-06-10 13:44:39 | train] - Train Epoch: [103] [1164800/1281167 (91%)]	Loss: 1.144208
[2022-06-10 13:44:59 | train] - Train Epoch: [103] [1177600/1281167 (92%)]	Loss: 0.888773
[2022-06-10 13:45:18 | train] - Train Epoch: [103] [1190400/1281167 (93%)]	Loss: 1.131674
[2022-06-10 13:45:38 | train] - Train Epoch: [103] [1203200/1281167 (94%)]	Loss: 0.937519
[2022-06-10 13:45:57 | train] - Train Epoch: [103] [1216000/1281167 (95%)]	Loss: 0.947235
[2022-06-10 13:46:17 | train] - Train Epoch: [103] [1228800/1281167 (96%)]	Loss: 0.697178
[2022-06-10 13:46:37 | train] - Train Epoch: [103] [1241600/1281167 (97%)]	Loss: 0.840890
[2022-06-10 13:46:57 | train] - Train Epoch: [103] [1254400/1281167 (98%)]	Loss: 0.792268
[2022-06-10 13:47:16 | train] - Train Epoch: [103] [1267200/1281167 (99%)]	Loss: 1.160756
[2022-06-10 13:47:36 | train] - Train Epoch: [103] [1280000/1281167 (100%)]	Loss: 0.788806
[2022-06-10 13:47:37 | train] - Train Epoch: [103]	 Average Loss: 0.852990	 Total Acc : 79.1365	 Total Top5 Acc : 92.3275
[2022-06-10 13:47:37 | train] - -------103 epoch end-----------
========================================
-------103 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 13:49:08 | train] - 
Epoch [103] Test set: Average loss: 1.3979, Accuracy: 34906/50000 (69.7810%), Top-5 Accuracy: 88.9046%

[2022-06-10 13:49:08 | train] - save intermediate epoch [103] result


[2022-06-10 13:49:39 | train] - -------104 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 13:49:40 | train] - Train Epoch: [104] [0/1281167 (0%)]	Loss: 0.789675
[2022-06-10 13:50:01 | train] - Train Epoch: [104] [12800/1281167 (1%)]	Loss: 0.916786
[2022-06-10 13:50:21 | train] - Train Epoch: [104] [25600/1281167 (2%)]	Loss: 0.855618
[2022-06-10 13:50:40 | train] - Train Epoch: [104] [38400/1281167 (3%)]	Loss: 0.715156
[2022-06-10 13:51:00 | train] - Train Epoch: [104] [51200/1281167 (4%)]	Loss: 0.892604
[2022-06-10 13:51:20 | train] - Train Epoch: [104] [64000/1281167 (5%)]	Loss: 0.908157
[2022-06-10 13:51:39 | train] - Train Epoch: [104] [76800/1281167 (6%)]	Loss: 0.590608
[2022-06-10 13:51:59 | train] - Train Epoch: [104] [89600/1281167 (7%)]	Loss: 0.662002
[2022-06-10 13:52:19 | train] - Train Epoch: [104] [102400/1281167 (8%)]	Loss: 0.771332
[2022-06-10 13:52:40 | train] - Train Epoch: [104] [115200/1281167 (9%)]	Loss: 0.712761
[2022-06-10 13:52:59 | train] - Train Epoch: [104] [128000/1281167 (10%)]	Loss: 0.745365
[2022-06-10 13:53:19 | train] - Train Epoch: [104] [140800/1281167 (11%)]	Loss: 0.874227
[2022-06-10 13:53:38 | train] - Train Epoch: [104] [153600/1281167 (12%)]	Loss: 0.724490
[2022-06-10 13:53:58 | train] - Train Epoch: [104] [166400/1281167 (13%)]	Loss: 0.727107
[2022-06-10 13:54:18 | train] - Train Epoch: [104] [179200/1281167 (14%)]	Loss: 0.849956
[2022-06-10 13:54:37 | train] - Train Epoch: [104] [192000/1281167 (15%)]	Loss: 0.606541
[2022-06-10 13:54:57 | train] - Train Epoch: [104] [204800/1281167 (16%)]	Loss: 0.922622
[2022-06-10 13:55:17 | train] - Train Epoch: [104] [217600/1281167 (17%)]	Loss: 0.799202
[2022-06-10 13:55:37 | train] - Train Epoch: [104] [230400/1281167 (18%)]	Loss: 0.729702
[2022-06-10 13:55:57 | train] - Train Epoch: [104] [243200/1281167 (19%)]	Loss: 0.925551
[2022-06-10 13:56:17 | train] - Train Epoch: [104] [256000/1281167 (20%)]	Loss: 0.951710
[2022-06-10 13:56:37 | train] - Train Epoch: [104] [268800/1281167 (21%)]	Loss: 0.964532
[2022-06-10 13:56:56 | train] - Train Epoch: [104] [281600/1281167 (22%)]	Loss: 0.987799
[2022-06-10 13:57:16 | train] - Train Epoch: [104] [294400/1281167 (23%)]	Loss: 0.886639
[2022-06-10 13:57:36 | train] - Train Epoch: [104] [307200/1281167 (24%)]	Loss: 0.904566
[2022-06-10 13:57:55 | train] - Train Epoch: [104] [320000/1281167 (25%)]	Loss: 0.976967
[2022-06-10 13:58:15 | train] - Train Epoch: [104] [332800/1281167 (26%)]	Loss: 0.862957
[2022-06-10 13:58:35 | train] - Train Epoch: [104] [345600/1281167 (27%)]	Loss: 1.051966
[2022-06-10 13:58:54 | train] - Train Epoch: [104] [358400/1281167 (28%)]	Loss: 0.461060
[2022-06-10 13:59:13 | train] - Train Epoch: [104] [371200/1281167 (29%)]	Loss: 1.288551
[2022-06-10 13:59:32 | train] - Train Epoch: [104] [384000/1281167 (30%)]	Loss: 0.764674
[2022-06-10 13:59:52 | train] - Train Epoch: [104] [396800/1281167 (31%)]	Loss: 0.626975
[2022-06-10 14:00:12 | train] - Train Epoch: [104] [409600/1281167 (32%)]	Loss: 0.587187
[2022-06-10 14:00:32 | train] - Train Epoch: [104] [422400/1281167 (33%)]	Loss: 0.802750
[2022-06-10 14:00:52 | train] - Train Epoch: [104] [435200/1281167 (34%)]	Loss: 0.650918
[2022-06-10 14:01:12 | train] - Train Epoch: [104] [448000/1281167 (35%)]	Loss: 1.013353
[2022-06-10 14:01:32 | train] - Train Epoch: [104] [460800/1281167 (36%)]	Loss: 1.035045
[2022-06-10 14:01:52 | train] - Train Epoch: [104] [473600/1281167 (37%)]	Loss: 0.888657
[2022-06-10 14:02:11 | train] - Train Epoch: [104] [486400/1281167 (38%)]	Loss: 0.803478
[2022-06-10 14:02:31 | train] - Train Epoch: [104] [499200/1281167 (39%)]	Loss: 0.792220
[2022-06-10 14:02:50 | train] - Train Epoch: [104] [512000/1281167 (40%)]	Loss: 0.906712
[2022-06-10 14:03:10 | train] - Train Epoch: [104] [524800/1281167 (41%)]	Loss: 0.752678
[2022-06-10 14:03:30 | train] - Train Epoch: [104] [537600/1281167 (42%)]	Loss: 0.999070
[2022-06-10 14:03:49 | train] - Train Epoch: [104] [550400/1281167 (43%)]	Loss: 0.896707
[2022-06-10 14:04:08 | train] - Train Epoch: [104] [563200/1281167 (44%)]	Loss: 0.829599
[2022-06-10 14:04:29 | train] - Train Epoch: [104] [576000/1281167 (45%)]	Loss: 1.068793
[2022-06-10 14:04:48 | train] - Train Epoch: [104] [588800/1281167 (46%)]	Loss: 0.949823
[2022-06-10 14:05:08 | train] - Train Epoch: [104] [601600/1281167 (47%)]	Loss: 1.203174
[2022-06-10 14:05:27 | train] - Train Epoch: [104] [614400/1281167 (48%)]	Loss: 0.932866
[2022-06-10 14:05:47 | train] - Train Epoch: [104] [627200/1281167 (49%)]	Loss: 0.657893
[2022-06-10 14:06:06 | train] - Train Epoch: [104] [640000/1281167 (50%)]	Loss: 0.916143
[2022-06-10 14:06:26 | train] - Train Epoch: [104] [652800/1281167 (51%)]	Loss: 0.643509
[2022-06-10 14:06:46 | train] - Train Epoch: [104] [665600/1281167 (52%)]	Loss: 0.780544
[2022-06-10 14:07:05 | train] - Train Epoch: [104] [678400/1281167 (53%)]	Loss: 0.916010
[2022-06-10 14:07:25 | train] - Train Epoch: [104] [691200/1281167 (54%)]	Loss: 0.622965
[2022-06-10 14:07:46 | train] - Train Epoch: [104] [704000/1281167 (55%)]	Loss: 0.918904
[2022-06-10 14:08:05 | train] - Train Epoch: [104] [716800/1281167 (56%)]	Loss: 0.814974
[2022-06-10 14:08:25 | train] - Train Epoch: [104] [729600/1281167 (57%)]	Loss: 0.785398
[2022-06-10 14:08:45 | train] - Train Epoch: [104] [742400/1281167 (58%)]	Loss: 0.868608
[2022-06-10 14:09:04 | train] - Train Epoch: [104] [755200/1281167 (59%)]	Loss: 0.814492
[2022-06-10 14:09:24 | train] - Train Epoch: [104] [768000/1281167 (60%)]	Loss: 1.014711
[2022-06-10 14:09:43 | train] - Train Epoch: [104] [780800/1281167 (61%)]	Loss: 0.785315
[2022-06-10 14:10:03 | train] - Train Epoch: [104] [793600/1281167 (62%)]	Loss: 0.727202
[2022-06-10 14:10:23 | train] - Train Epoch: [104] [806400/1281167 (63%)]	Loss: 0.891043
[2022-06-10 14:10:43 | train] - Train Epoch: [104] [819200/1281167 (64%)]	Loss: 0.802316
[2022-06-10 14:11:03 | train] - Train Epoch: [104] [832000/1281167 (65%)]	Loss: 0.857091
[2022-06-10 14:11:22 | train] - Train Epoch: [104] [844800/1281167 (66%)]	Loss: 0.800954
[2022-06-10 14:11:42 | train] - Train Epoch: [104] [857600/1281167 (67%)]	Loss: 0.819139
[2022-06-10 14:12:02 | train] - Train Epoch: [104] [870400/1281167 (68%)]	Loss: 0.742769
[2022-06-10 14:12:22 | train] - Train Epoch: [104] [883200/1281167 (69%)]	Loss: 1.122725
[2022-06-10 14:12:42 | train] - Train Epoch: [104] [896000/1281167 (70%)]	Loss: 0.717169
[2022-06-10 14:13:02 | train] - Train Epoch: [104] [908800/1281167 (71%)]	Loss: 0.898414
[2022-06-10 14:13:22 | train] - Train Epoch: [104] [921600/1281167 (72%)]	Loss: 0.718166
[2022-06-10 14:13:42 | train] - Train Epoch: [104] [934400/1281167 (73%)]	Loss: 0.779127
[2022-06-10 14:14:01 | train] - Train Epoch: [104] [947200/1281167 (74%)]	Loss: 0.783292
[2022-06-10 14:14:21 | train] - Train Epoch: [104] [960000/1281167 (75%)]	Loss: 0.858884
[2022-06-10 14:14:41 | train] - Train Epoch: [104] [972800/1281167 (76%)]	Loss: 0.892159
[2022-06-10 14:15:00 | train] - Train Epoch: [104] [985600/1281167 (77%)]	Loss: 0.777880
[2022-06-10 14:15:19 | train] - Train Epoch: [104] [998400/1281167 (78%)]	Loss: 0.911064
[2022-06-10 14:15:39 | train] - Train Epoch: [104] [1011200/1281167 (79%)]	Loss: 0.675198
[2022-06-10 14:15:59 | train] - Train Epoch: [104] [1024000/1281167 (80%)]	Loss: 0.851242
[2022-06-10 14:16:19 | train] - Train Epoch: [104] [1036800/1281167 (81%)]	Loss: 0.798465
[2022-06-10 14:16:39 | train] - Train Epoch: [104] [1049600/1281167 (82%)]	Loss: 0.602623
[2022-06-10 14:16:59 | train] - Train Epoch: [104] [1062400/1281167 (83%)]	Loss: 0.888604
[2022-06-10 14:17:19 | train] - Train Epoch: [104] [1075200/1281167 (84%)]	Loss: 0.795666
[2022-06-10 14:17:38 | train] - Train Epoch: [104] [1088000/1281167 (85%)]	Loss: 0.856714
[2022-06-10 14:17:58 | train] - Train Epoch: [104] [1100800/1281167 (86%)]	Loss: 0.735476
[2022-06-10 14:18:17 | train] - Train Epoch: [104] [1113600/1281167 (87%)]	Loss: 0.775805
[2022-06-10 14:18:37 | train] - Train Epoch: [104] [1126400/1281167 (88%)]	Loss: 0.903542
[2022-06-10 14:18:56 | train] - Train Epoch: [104] [1139200/1281167 (89%)]	Loss: 0.819999
[2022-06-10 14:19:15 | train] - Train Epoch: [104] [1152000/1281167 (90%)]	Loss: 1.050696
[2022-06-10 14:19:34 | train] - Train Epoch: [104] [1164800/1281167 (91%)]	Loss: 0.804807
[2022-06-10 14:19:55 | train] - Train Epoch: [104] [1177600/1281167 (92%)]	Loss: 0.925102
[2022-06-10 14:20:14 | train] - Train Epoch: [104] [1190400/1281167 (93%)]	Loss: 1.034542
[2022-06-10 14:20:34 | train] - Train Epoch: [104] [1203200/1281167 (94%)]	Loss: 0.814172
[2022-06-10 14:20:54 | train] - Train Epoch: [104] [1216000/1281167 (95%)]	Loss: 1.115957
[2022-06-10 14:21:13 | train] - Train Epoch: [104] [1228800/1281167 (96%)]	Loss: 0.860870
[2022-06-10 14:21:33 | train] - Train Epoch: [104] [1241600/1281167 (97%)]	Loss: 0.695330
[2022-06-10 14:21:53 | train] - Train Epoch: [104] [1254400/1281167 (98%)]	Loss: 0.768284
[2022-06-10 14:22:13 | train] - Train Epoch: [104] [1267200/1281167 (99%)]	Loss: 0.765004
[2022-06-10 14:22:33 | train] - Train Epoch: [104] [1280000/1281167 (100%)]	Loss: 0.913676
[2022-06-10 14:22:35 | train] - Train Epoch: [104]	 Average Loss: 0.851135	 Total Acc : 79.1836	 Total Top5 Acc : 92.3618
[2022-06-10 14:22:35 | train] - -------104 epoch end-----------
========================================
-------104 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 14:24:04 | train] - 
Epoch [104] Test set: Average loss: 1.3972, Accuracy: 34922/50000 (69.8082%), Top-5 Accuracy: 88.7824%

[2022-06-10 14:24:04 | train] - save intermediate epoch [104] result


[2022-06-10 14:24:36 | train] - -------105 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 14:24:37 | train] - Train Epoch: [105] [0/1281167 (0%)]	Loss: 0.934548
[2022-06-10 14:24:58 | train] - Train Epoch: [105] [12800/1281167 (1%)]	Loss: 1.021556
[2022-06-10 14:25:20 | train] - Train Epoch: [105] [25600/1281167 (2%)]	Loss: 0.725957
[2022-06-10 14:25:41 | train] - Train Epoch: [105] [38400/1281167 (3%)]	Loss: 0.812862
[2022-06-10 14:26:00 | train] - Train Epoch: [105] [51200/1281167 (4%)]	Loss: 0.871734
[2022-06-10 14:26:20 | train] - Train Epoch: [105] [64000/1281167 (5%)]	Loss: 0.711283
[2022-06-10 14:26:38 | train] - Train Epoch: [105] [76800/1281167 (6%)]	Loss: 0.751218
[2022-06-10 14:26:58 | train] - Train Epoch: [105] [89600/1281167 (7%)]	Loss: 1.032880
[2022-06-10 14:27:19 | train] - Train Epoch: [105] [102400/1281167 (8%)]	Loss: 0.849488
[2022-06-10 14:27:40 | train] - Train Epoch: [105] [115200/1281167 (9%)]	Loss: 0.649423
[2022-06-10 14:27:59 | train] - Train Epoch: [105] [128000/1281167 (10%)]	Loss: 0.686324
[2022-06-10 14:28:19 | train] - Train Epoch: [105] [140800/1281167 (11%)]	Loss: 0.762006
[2022-06-10 14:28:38 | train] - Train Epoch: [105] [153600/1281167 (12%)]	Loss: 0.884385
[2022-06-10 14:28:58 | train] - Train Epoch: [105] [166400/1281167 (13%)]	Loss: 0.918550
[2022-06-10 14:29:19 | train] - Train Epoch: [105] [179200/1281167 (14%)]	Loss: 1.015295
[2022-06-10 14:29:38 | train] - Train Epoch: [105] [192000/1281167 (15%)]	Loss: 0.812025
[2022-06-10 14:29:59 | train] - Train Epoch: [105] [204800/1281167 (16%)]	Loss: 0.846617
[2022-06-10 14:30:19 | train] - Train Epoch: [105] [217600/1281167 (17%)]	Loss: 0.834777
[2022-06-10 14:30:38 | train] - Train Epoch: [105] [230400/1281167 (18%)]	Loss: 0.765105
[2022-06-10 14:30:58 | train] - Train Epoch: [105] [243200/1281167 (19%)]	Loss: 0.820639
[2022-06-10 14:31:17 | train] - Train Epoch: [105] [256000/1281167 (20%)]	Loss: 0.978627
[2022-06-10 14:31:37 | train] - Train Epoch: [105] [268800/1281167 (21%)]	Loss: 0.707359
[2022-06-10 14:31:57 | train] - Train Epoch: [105] [281600/1281167 (22%)]	Loss: 0.745984
[2022-06-10 14:32:16 | train] - Train Epoch: [105] [294400/1281167 (23%)]	Loss: 0.795529
[2022-06-10 14:32:36 | train] - Train Epoch: [105] [307200/1281167 (24%)]	Loss: 0.764764
[2022-06-10 14:32:56 | train] - Train Epoch: [105] [320000/1281167 (25%)]	Loss: 0.764725
[2022-06-10 14:33:15 | train] - Train Epoch: [105] [332800/1281167 (26%)]	Loss: 1.094624
[2022-06-10 14:33:34 | train] - Train Epoch: [105] [345600/1281167 (27%)]	Loss: 0.826003
[2022-06-10 14:33:55 | train] - Train Epoch: [105] [358400/1281167 (28%)]	Loss: 0.695812
[2022-06-10 14:34:14 | train] - Train Epoch: [105] [371200/1281167 (29%)]	Loss: 0.730462
[2022-06-10 14:34:35 | train] - Train Epoch: [105] [384000/1281167 (30%)]	Loss: 0.878139
[2022-06-10 14:34:55 | train] - Train Epoch: [105] [396800/1281167 (31%)]	Loss: 0.842671
[2022-06-10 14:35:15 | train] - Train Epoch: [105] [409600/1281167 (32%)]	Loss: 0.746994
[2022-06-10 14:35:35 | train] - Train Epoch: [105] [422400/1281167 (33%)]	Loss: 0.788355
[2022-06-10 14:35:56 | train] - Train Epoch: [105] [435200/1281167 (34%)]	Loss: 0.664580
[2022-06-10 14:36:16 | train] - Train Epoch: [105] [448000/1281167 (35%)]	Loss: 1.085436
[2022-06-10 14:36:37 | train] - Train Epoch: [105] [460800/1281167 (36%)]	Loss: 0.972138
[2022-06-10 14:36:57 | train] - Train Epoch: [105] [473600/1281167 (37%)]	Loss: 0.916266
[2022-06-10 14:37:18 | train] - Train Epoch: [105] [486400/1281167 (38%)]	Loss: 0.821510
[2022-06-10 14:37:38 | train] - Train Epoch: [105] [499200/1281167 (39%)]	Loss: 0.705020
[2022-06-10 14:37:58 | train] - Train Epoch: [105] [512000/1281167 (40%)]	Loss: 0.912154
[2022-06-10 14:38:19 | train] - Train Epoch: [105] [524800/1281167 (41%)]	Loss: 0.819404
[2022-06-10 14:38:40 | train] - Train Epoch: [105] [537600/1281167 (42%)]	Loss: 0.832987
[2022-06-10 14:39:00 | train] - Train Epoch: [105] [550400/1281167 (43%)]	Loss: 0.936252
[2022-06-10 14:39:20 | train] - Train Epoch: [105] [563200/1281167 (44%)]	Loss: 0.857405
[2022-06-10 14:39:40 | train] - Train Epoch: [105] [576000/1281167 (45%)]	Loss: 1.023967
[2022-06-10 14:40:01 | train] - Train Epoch: [105] [588800/1281167 (46%)]	Loss: 0.955000
[2022-06-10 14:40:22 | train] - Train Epoch: [105] [601600/1281167 (47%)]	Loss: 0.988783
[2022-06-10 14:40:42 | train] - Train Epoch: [105] [614400/1281167 (48%)]	Loss: 0.931044
[2022-06-10 14:41:02 | train] - Train Epoch: [105] [627200/1281167 (49%)]	Loss: 0.995676
[2022-06-10 14:41:23 | train] - Train Epoch: [105] [640000/1281167 (50%)]	Loss: 0.814312
[2022-06-10 14:41:44 | train] - Train Epoch: [105] [652800/1281167 (51%)]	Loss: 1.126971
[2022-06-10 14:42:04 | train] - Train Epoch: [105] [665600/1281167 (52%)]	Loss: 0.800836
[2022-06-10 14:42:24 | train] - Train Epoch: [105] [678400/1281167 (53%)]	Loss: 0.933698
[2022-06-10 14:42:45 | train] - Train Epoch: [105] [691200/1281167 (54%)]	Loss: 0.640739
[2022-06-10 14:43:05 | train] - Train Epoch: [105] [704000/1281167 (55%)]	Loss: 0.784355
[2022-06-10 14:43:26 | train] - Train Epoch: [105] [716800/1281167 (56%)]	Loss: 0.753588
[2022-06-10 14:43:46 | train] - Train Epoch: [105] [729600/1281167 (57%)]	Loss: 0.697468
[2022-06-10 14:44:06 | train] - Train Epoch: [105] [742400/1281167 (58%)]	Loss: 0.849340
[2022-06-10 14:44:27 | train] - Train Epoch: [105] [755200/1281167 (59%)]	Loss: 0.593373
[2022-06-10 14:44:47 | train] - Train Epoch: [105] [768000/1281167 (60%)]	Loss: 0.516911
[2022-06-10 14:45:07 | train] - Train Epoch: [105] [780800/1281167 (61%)]	Loss: 0.976090
[2022-06-10 14:45:28 | train] - Train Epoch: [105] [793600/1281167 (62%)]	Loss: 0.796976
[2022-06-10 14:45:49 | train] - Train Epoch: [105] [806400/1281167 (63%)]	Loss: 0.966182
[2022-06-10 14:46:09 | train] - Train Epoch: [105] [819200/1281167 (64%)]	Loss: 0.834219
[2022-06-10 14:46:30 | train] - Train Epoch: [105] [832000/1281167 (65%)]	Loss: 0.988217
[2022-06-10 14:46:50 | train] - Train Epoch: [105] [844800/1281167 (66%)]	Loss: 0.827151
[2022-06-10 14:47:10 | train] - Train Epoch: [105] [857600/1281167 (67%)]	Loss: 0.781506
[2022-06-10 14:47:31 | train] - Train Epoch: [105] [870400/1281167 (68%)]	Loss: 0.637699
[2022-06-10 14:47:52 | train] - Train Epoch: [105] [883200/1281167 (69%)]	Loss: 1.016176
[2022-06-10 14:48:12 | train] - Train Epoch: [105] [896000/1281167 (70%)]	Loss: 0.956481
[2022-06-10 14:48:33 | train] - Train Epoch: [105] [908800/1281167 (71%)]	Loss: 0.815709
[2022-06-10 14:48:53 | train] - Train Epoch: [105] [921600/1281167 (72%)]	Loss: 1.069167
[2022-06-10 14:49:14 | train] - Train Epoch: [105] [934400/1281167 (73%)]	Loss: 0.985172
[2022-06-10 14:49:34 | train] - Train Epoch: [105] [947200/1281167 (74%)]	Loss: 0.660638
[2022-06-10 14:49:55 | train] - Train Epoch: [105] [960000/1281167 (75%)]	Loss: 0.996081
[2022-06-10 14:50:15 | train] - Train Epoch: [105] [972800/1281167 (76%)]	Loss: 0.785471
[2022-06-10 14:50:35 | train] - Train Epoch: [105] [985600/1281167 (77%)]	Loss: 0.848220
[2022-06-10 14:50:55 | train] - Train Epoch: [105] [998400/1281167 (78%)]	Loss: 0.986900
[2022-06-10 14:51:15 | train] - Train Epoch: [105] [1011200/1281167 (79%)]	Loss: 0.731738
[2022-06-10 14:51:36 | train] - Train Epoch: [105] [1024000/1281167 (80%)]	Loss: 0.848216
[2022-06-10 14:51:56 | train] - Train Epoch: [105] [1036800/1281167 (81%)]	Loss: 0.741797
[2022-06-10 14:52:16 | train] - Train Epoch: [105] [1049600/1281167 (82%)]	Loss: 0.948396
[2022-06-10 14:52:37 | train] - Train Epoch: [105] [1062400/1281167 (83%)]	Loss: 0.968511
[2022-06-10 14:52:57 | train] - Train Epoch: [105] [1075200/1281167 (84%)]	Loss: 0.890419
[2022-06-10 14:53:17 | train] - Train Epoch: [105] [1088000/1281167 (85%)]	Loss: 0.546641
[2022-06-10 14:53:38 | train] - Train Epoch: [105] [1100800/1281167 (86%)]	Loss: 1.121477
[2022-06-10 14:53:58 | train] - Train Epoch: [105] [1113600/1281167 (87%)]	Loss: 0.598668
[2022-06-10 14:54:19 | train] - Train Epoch: [105] [1126400/1281167 (88%)]	Loss: 0.997800
[2022-06-10 14:54:39 | train] - Train Epoch: [105] [1139200/1281167 (89%)]	Loss: 0.867341
[2022-06-10 14:55:00 | train] - Train Epoch: [105] [1152000/1281167 (90%)]	Loss: 0.872541
[2022-06-10 14:55:20 | train] - Train Epoch: [105] [1164800/1281167 (91%)]	Loss: 0.907797
[2022-06-10 14:55:40 | train] - Train Epoch: [105] [1177600/1281167 (92%)]	Loss: 0.617918
[2022-06-10 14:56:00 | train] - Train Epoch: [105] [1190400/1281167 (93%)]	Loss: 0.887708
[2022-06-10 14:56:20 | train] - Train Epoch: [105] [1203200/1281167 (94%)]	Loss: 0.941084
[2022-06-10 14:56:41 | train] - Train Epoch: [105] [1216000/1281167 (95%)]	Loss: 1.031563
[2022-06-10 14:57:02 | train] - Train Epoch: [105] [1228800/1281167 (96%)]	Loss: 0.639511
[2022-06-10 14:57:22 | train] - Train Epoch: [105] [1241600/1281167 (97%)]	Loss: 1.010138
[2022-06-10 14:57:43 | train] - Train Epoch: [105] [1254400/1281167 (98%)]	Loss: 0.583970
[2022-06-10 14:58:03 | train] - Train Epoch: [105] [1267200/1281167 (99%)]	Loss: 0.907271
[2022-06-10 14:58:24 | train] - Train Epoch: [105] [1280000/1281167 (100%)]	Loss: 0.950980
[2022-06-10 14:58:25 | train] - Train Epoch: [105]	 Average Loss: 0.849431	 Total Acc : 79.2305	 Total Top5 Acc : 92.3995
[2022-06-10 14:58:25 | train] - -------105 epoch end-----------
========================================
-------105 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 14:59:55 | train] - 
Epoch [105] Test set: Average loss: 1.3897, Accuracy: 34863/50000 (69.6951%), Top-5 Accuracy: 88.9242%

[2022-06-10 14:59:55 | train] - save intermediate epoch [105] result


[2022-06-10 15:00:26 | train] - -------106 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 15:00:27 | train] - Train Epoch: [106] [0/1281167 (0%)]	Loss: 0.914968
[2022-06-10 15:00:48 | train] - Train Epoch: [106] [12800/1281167 (1%)]	Loss: 0.700606
[2022-06-10 15:01:09 | train] - Train Epoch: [106] [25600/1281167 (2%)]	Loss: 0.799232
[2022-06-10 15:01:30 | train] - Train Epoch: [106] [38400/1281167 (3%)]	Loss: 0.820861
[2022-06-10 15:01:51 | train] - Train Epoch: [106] [51200/1281167 (4%)]	Loss: 0.777619
[2022-06-10 15:02:11 | train] - Train Epoch: [106] [64000/1281167 (5%)]	Loss: 0.797265
[2022-06-10 15:02:32 | train] - Train Epoch: [106] [76800/1281167 (6%)]	Loss: 0.918052
[2022-06-10 15:02:53 | train] - Train Epoch: [106] [89600/1281167 (7%)]	Loss: 1.132677
[2022-06-10 15:03:14 | train] - Train Epoch: [106] [102400/1281167 (8%)]	Loss: 0.768359
[2022-06-10 15:03:35 | train] - Train Epoch: [106] [115200/1281167 (9%)]	Loss: 0.711801
[2022-06-10 15:03:56 | train] - Train Epoch: [106] [128000/1281167 (10%)]	Loss: 0.720644
[2022-06-10 15:04:16 | train] - Train Epoch: [106] [140800/1281167 (11%)]	Loss: 0.954310
[2022-06-10 15:04:38 | train] - Train Epoch: [106] [153600/1281167 (12%)]	Loss: 0.489031
[2022-06-10 15:04:59 | train] - Train Epoch: [106] [166400/1281167 (13%)]	Loss: 0.943379
[2022-06-10 15:05:20 | train] - Train Epoch: [106] [179200/1281167 (14%)]	Loss: 1.456771
[2022-06-10 15:05:41 | train] - Train Epoch: [106] [192000/1281167 (15%)]	Loss: 0.811761
[2022-06-10 15:06:02 | train] - Train Epoch: [106] [204800/1281167 (16%)]	Loss: 1.151243
[2022-06-10 15:06:24 | train] - Train Epoch: [106] [217600/1281167 (17%)]	Loss: 0.658852
[2022-06-10 15:06:44 | train] - Train Epoch: [106] [230400/1281167 (18%)]	Loss: 0.934469
[2022-06-10 15:07:04 | train] - Train Epoch: [106] [243200/1281167 (19%)]	Loss: 0.769293
[2022-06-10 15:07:24 | train] - Train Epoch: [106] [256000/1281167 (20%)]	Loss: 0.667147
[2022-06-10 15:07:44 | train] - Train Epoch: [106] [268800/1281167 (21%)]	Loss: 1.055677
[2022-06-10 15:08:04 | train] - Train Epoch: [106] [281600/1281167 (22%)]	Loss: 0.903752
[2022-06-10 15:08:24 | train] - Train Epoch: [106] [294400/1281167 (23%)]	Loss: 0.896499
[2022-06-10 15:08:44 | train] - Train Epoch: [106] [307200/1281167 (24%)]	Loss: 0.716957
[2022-06-10 15:09:04 | train] - Train Epoch: [106] [320000/1281167 (25%)]	Loss: 0.862296
[2022-06-10 15:09:25 | train] - Train Epoch: [106] [332800/1281167 (26%)]	Loss: 0.878033
[2022-06-10 15:09:45 | train] - Train Epoch: [106] [345600/1281167 (27%)]	Loss: 1.012577
[2022-06-10 15:10:05 | train] - Train Epoch: [106] [358400/1281167 (28%)]	Loss: 0.828359
[2022-06-10 15:10:26 | train] - Train Epoch: [106] [371200/1281167 (29%)]	Loss: 0.761425
[2022-06-10 15:10:46 | train] - Train Epoch: [106] [384000/1281167 (30%)]	Loss: 0.754804
[2022-06-10 15:11:06 | train] - Train Epoch: [106] [396800/1281167 (31%)]	Loss: 0.633412
[2022-06-10 15:11:27 | train] - Train Epoch: [106] [409600/1281167 (32%)]	Loss: 0.820839
[2022-06-10 15:11:48 | train] - Train Epoch: [106] [422400/1281167 (33%)]	Loss: 1.011726
[2022-06-10 15:12:10 | train] - Train Epoch: [106] [435200/1281167 (34%)]	Loss: 0.668944
[2022-06-10 15:12:31 | train] - Train Epoch: [106] [448000/1281167 (35%)]	Loss: 1.011001
[2022-06-10 15:12:52 | train] - Train Epoch: [106] [460800/1281167 (36%)]	Loss: 0.829558
[2022-06-10 15:13:13 | train] - Train Epoch: [106] [473600/1281167 (37%)]	Loss: 1.252340
[2022-06-10 15:13:34 | train] - Train Epoch: [106] [486400/1281167 (38%)]	Loss: 1.035405
[2022-06-10 15:13:54 | train] - Train Epoch: [106] [499200/1281167 (39%)]	Loss: 0.796028
[2022-06-10 15:14:15 | train] - Train Epoch: [106] [512000/1281167 (40%)]	Loss: 0.881691
[2022-06-10 15:14:34 | train] - Train Epoch: [106] [524800/1281167 (41%)]	Loss: 0.733149
[2022-06-10 15:14:55 | train] - Train Epoch: [106] [537600/1281167 (42%)]	Loss: 0.731557
[2022-06-10 15:15:15 | train] - Train Epoch: [106] [550400/1281167 (43%)]	Loss: 0.927083
[2022-06-10 15:15:36 | train] - Train Epoch: [106] [563200/1281167 (44%)]	Loss: 0.847134
[2022-06-10 15:15:57 | train] - Train Epoch: [106] [576000/1281167 (45%)]	Loss: 0.831262
[2022-06-10 15:16:18 | train] - Train Epoch: [106] [588800/1281167 (46%)]	Loss: 0.892864
[2022-06-10 15:16:39 | train] - Train Epoch: [106] [601600/1281167 (47%)]	Loss: 0.768604
[2022-06-10 15:16:59 | train] - Train Epoch: [106] [614400/1281167 (48%)]	Loss: 0.943783
[2022-06-10 15:17:20 | train] - Train Epoch: [106] [627200/1281167 (49%)]	Loss: 0.775209
[2022-06-10 15:17:41 | train] - Train Epoch: [106] [640000/1281167 (50%)]	Loss: 0.913201
[2022-06-10 15:18:02 | train] - Train Epoch: [106] [652800/1281167 (51%)]	Loss: 0.546770
[2022-06-10 15:18:23 | train] - Train Epoch: [106] [665600/1281167 (52%)]	Loss: 0.931073
[2022-06-10 15:18:44 | train] - Train Epoch: [106] [678400/1281167 (53%)]	Loss: 1.042715
[2022-06-10 15:19:05 | train] - Train Epoch: [106] [691200/1281167 (54%)]	Loss: 0.734310
[2022-06-10 15:19:26 | train] - Train Epoch: [106] [704000/1281167 (55%)]	Loss: 0.798386
[2022-06-10 15:19:48 | train] - Train Epoch: [106] [716800/1281167 (56%)]	Loss: 0.804196
[2022-06-10 15:20:08 | train] - Train Epoch: [106] [729600/1281167 (57%)]	Loss: 0.704237
[2022-06-10 15:20:30 | train] - Train Epoch: [106] [742400/1281167 (58%)]	Loss: 1.131836
[2022-06-10 15:20:51 | train] - Train Epoch: [106] [755200/1281167 (59%)]	Loss: 0.980280
[2022-06-10 15:21:11 | train] - Train Epoch: [106] [768000/1281167 (60%)]	Loss: 0.932146
[2022-06-10 15:21:32 | train] - Train Epoch: [106] [780800/1281167 (61%)]	Loss: 0.669703
[2022-06-10 15:21:52 | train] - Train Epoch: [106] [793600/1281167 (62%)]	Loss: 0.674216
[2022-06-10 15:22:14 | train] - Train Epoch: [106] [806400/1281167 (63%)]	Loss: 0.963189
[2022-06-10 15:22:35 | train] - Train Epoch: [106] [819200/1281167 (64%)]	Loss: 0.956060
[2022-06-10 15:22:56 | train] - Train Epoch: [106] [832000/1281167 (65%)]	Loss: 0.863464
[2022-06-10 15:23:18 | train] - Train Epoch: [106] [844800/1281167 (66%)]	Loss: 0.862778
[2022-06-10 15:23:38 | train] - Train Epoch: [106] [857600/1281167 (67%)]	Loss: 0.821593
[2022-06-10 15:23:59 | train] - Train Epoch: [106] [870400/1281167 (68%)]	Loss: 0.721500
[2022-06-10 15:24:20 | train] - Train Epoch: [106] [883200/1281167 (69%)]	Loss: 0.795790
[2022-06-10 15:24:41 | train] - Train Epoch: [106] [896000/1281167 (70%)]	Loss: 1.008845
[2022-06-10 15:25:02 | train] - Train Epoch: [106] [908800/1281167 (71%)]	Loss: 0.545884
[2022-06-10 15:25:22 | train] - Train Epoch: [106] [921600/1281167 (72%)]	Loss: 1.057127
[2022-06-10 15:25:42 | train] - Train Epoch: [106] [934400/1281167 (73%)]	Loss: 1.046623
[2022-06-10 15:26:01 | train] - Train Epoch: [106] [947200/1281167 (74%)]	Loss: 0.783508
[2022-06-10 15:26:22 | train] - Train Epoch: [106] [960000/1281167 (75%)]	Loss: 0.895474
[2022-06-10 15:26:42 | train] - Train Epoch: [106] [972800/1281167 (76%)]	Loss: 0.834613
[2022-06-10 15:27:04 | train] - Train Epoch: [106] [985600/1281167 (77%)]	Loss: 0.696646
[2022-06-10 15:27:25 | train] - Train Epoch: [106] [998400/1281167 (78%)]	Loss: 0.994065
[2022-06-10 15:27:45 | train] - Train Epoch: [106] [1011200/1281167 (79%)]	Loss: 1.032561
[2022-06-10 15:28:06 | train] - Train Epoch: [106] [1024000/1281167 (80%)]	Loss: 0.674662
[2022-06-10 15:28:26 | train] - Train Epoch: [106] [1036800/1281167 (81%)]	Loss: 0.851187
[2022-06-10 15:28:46 | train] - Train Epoch: [106] [1049600/1281167 (82%)]	Loss: 1.152943
[2022-06-10 15:29:06 | train] - Train Epoch: [106] [1062400/1281167 (83%)]	Loss: 0.986438
[2022-06-10 15:29:28 | train] - Train Epoch: [106] [1075200/1281167 (84%)]	Loss: 0.974154
[2022-06-10 15:29:49 | train] - Train Epoch: [106] [1088000/1281167 (85%)]	Loss: 0.775052
[2022-06-10 15:30:09 | train] - Train Epoch: [106] [1100800/1281167 (86%)]	Loss: 0.726893
[2022-06-10 15:30:30 | train] - Train Epoch: [106] [1113600/1281167 (87%)]	Loss: 0.819712
[2022-06-10 15:30:52 | train] - Train Epoch: [106] [1126400/1281167 (88%)]	Loss: 0.672080
[2022-06-10 15:31:12 | train] - Train Epoch: [106] [1139200/1281167 (89%)]	Loss: 1.018113
[2022-06-10 15:31:33 | train] - Train Epoch: [106] [1152000/1281167 (90%)]	Loss: 0.940496
[2022-06-10 15:31:55 | train] - Train Epoch: [106] [1164800/1281167 (91%)]	Loss: 0.979266
[2022-06-10 15:32:15 | train] - Train Epoch: [106] [1177600/1281167 (92%)]	Loss: 0.816652
[2022-06-10 15:32:35 | train] - Train Epoch: [106] [1190400/1281167 (93%)]	Loss: 0.881325
[2022-06-10 15:32:55 | train] - Train Epoch: [106] [1203200/1281167 (94%)]	Loss: 0.999797
[2022-06-10 15:33:16 | train] - Train Epoch: [106] [1216000/1281167 (95%)]	Loss: 0.863735
[2022-06-10 15:33:36 | train] - Train Epoch: [106] [1228800/1281167 (96%)]	Loss: 0.714202
[2022-06-10 15:33:56 | train] - Train Epoch: [106] [1241600/1281167 (97%)]	Loss: 0.822073
[2022-06-10 15:34:17 | train] - Train Epoch: [106] [1254400/1281167 (98%)]	Loss: 0.728171
[2022-06-10 15:34:37 | train] - Train Epoch: [106] [1267200/1281167 (99%)]	Loss: 0.957985
[2022-06-10 15:34:57 | train] - Train Epoch: [106] [1280000/1281167 (100%)]	Loss: 0.838641
[2022-06-10 15:34:59 | train] - Train Epoch: [106]	 Average Loss: 0.846469	 Total Acc : 79.3008	 Total Top5 Acc : 92.4282
[2022-06-10 15:34:59 | train] - -------106 epoch end-----------
========================================
-------106 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 15:36:31 | train] - 
Epoch [106] Test set: Average loss: 1.3934, Accuracy: 34941/50000 (69.8557%), Top-5 Accuracy: 88.8751%

[2022-06-10 15:36:31 | train] - save intermediate epoch [106] result


[2022-06-10 15:37:00 | train] - -------107 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 15:37:02 | train] - Train Epoch: [107] [0/1281167 (0%)]	Loss: 0.758188
[2022-06-10 15:37:23 | train] - Train Epoch: [107] [12800/1281167 (1%)]	Loss: 0.925869
[2022-06-10 15:37:43 | train] - Train Epoch: [107] [25600/1281167 (2%)]	Loss: 1.004658
[2022-06-10 15:38:04 | train] - Train Epoch: [107] [38400/1281167 (3%)]	Loss: 1.090025
[2022-06-10 15:38:24 | train] - Train Epoch: [107] [51200/1281167 (4%)]	Loss: 0.945777
[2022-06-10 15:38:45 | train] - Train Epoch: [107] [64000/1281167 (5%)]	Loss: 0.839881
[2022-06-10 15:39:05 | train] - Train Epoch: [107] [76800/1281167 (6%)]	Loss: 0.794489
[2022-06-10 15:39:25 | train] - Train Epoch: [107] [89600/1281167 (7%)]	Loss: 0.820512
[2022-06-10 15:39:45 | train] - Train Epoch: [107] [102400/1281167 (8%)]	Loss: 0.716347
[2022-06-10 15:40:06 | train] - Train Epoch: [107] [115200/1281167 (9%)]	Loss: 0.750625
[2022-06-10 15:40:27 | train] - Train Epoch: [107] [128000/1281167 (10%)]	Loss: 0.822096
[2022-06-10 15:40:48 | train] - Train Epoch: [107] [140800/1281167 (11%)]	Loss: 1.216719
[2022-06-10 15:41:07 | train] - Train Epoch: [107] [153600/1281167 (12%)]	Loss: 0.991347
[2022-06-10 15:41:28 | train] - Train Epoch: [107] [166400/1281167 (13%)]	Loss: 0.679464
[2022-06-10 15:41:48 | train] - Train Epoch: [107] [179200/1281167 (14%)]	Loss: 0.821959
[2022-06-10 15:42:09 | train] - Train Epoch: [107] [192000/1281167 (15%)]	Loss: 0.660539
[2022-06-10 15:42:28 | train] - Train Epoch: [107] [204800/1281167 (16%)]	Loss: 1.214855
[2022-06-10 15:42:49 | train] - Train Epoch: [107] [217600/1281167 (17%)]	Loss: 0.918103
[2022-06-10 15:43:10 | train] - Train Epoch: [107] [230400/1281167 (18%)]	Loss: 1.077999
[2022-06-10 15:43:30 | train] - Train Epoch: [107] [243200/1281167 (19%)]	Loss: 0.483356
[2022-06-10 15:43:52 | train] - Train Epoch: [107] [256000/1281167 (20%)]	Loss: 0.993908
[2022-06-10 15:44:12 | train] - Train Epoch: [107] [268800/1281167 (21%)]	Loss: 0.793635
[2022-06-10 15:44:32 | train] - Train Epoch: [107] [281600/1281167 (22%)]	Loss: 0.599217
[2022-06-10 15:44:53 | train] - Train Epoch: [107] [294400/1281167 (23%)]	Loss: 0.899932
[2022-06-10 15:45:14 | train] - Train Epoch: [107] [307200/1281167 (24%)]	Loss: 0.898441
[2022-06-10 15:45:34 | train] - Train Epoch: [107] [320000/1281167 (25%)]	Loss: 0.988407
[2022-06-10 15:45:55 | train] - Train Epoch: [107] [332800/1281167 (26%)]	Loss: 0.868008
[2022-06-10 15:46:16 | train] - Train Epoch: [107] [345600/1281167 (27%)]	Loss: 0.783275
[2022-06-10 15:46:36 | train] - Train Epoch: [107] [358400/1281167 (28%)]	Loss: 0.742715
[2022-06-10 15:46:57 | train] - Train Epoch: [107] [371200/1281167 (29%)]	Loss: 0.766527
[2022-06-10 15:47:18 | train] - Train Epoch: [107] [384000/1281167 (30%)]	Loss: 0.862800
[2022-06-10 15:47:38 | train] - Train Epoch: [107] [396800/1281167 (31%)]	Loss: 0.763151
[2022-06-10 15:47:58 | train] - Train Epoch: [107] [409600/1281167 (32%)]	Loss: 0.821440
[2022-06-10 15:48:18 | train] - Train Epoch: [107] [422400/1281167 (33%)]	Loss: 0.964122
[2022-06-10 15:48:39 | train] - Train Epoch: [107] [435200/1281167 (34%)]	Loss: 0.807038
[2022-06-10 15:48:59 | train] - Train Epoch: [107] [448000/1281167 (35%)]	Loss: 0.830347
[2022-06-10 15:49:19 | train] - Train Epoch: [107] [460800/1281167 (36%)]	Loss: 0.823897
[2022-06-10 15:49:39 | train] - Train Epoch: [107] [473600/1281167 (37%)]	Loss: 0.662250
[2022-06-10 15:50:00 | train] - Train Epoch: [107] [486400/1281167 (38%)]	Loss: 0.943442
[2022-06-10 15:50:20 | train] - Train Epoch: [107] [499200/1281167 (39%)]	Loss: 0.715531
[2022-06-10 15:50:41 | train] - Train Epoch: [107] [512000/1281167 (40%)]	Loss: 0.951669
[2022-06-10 15:51:02 | train] - Train Epoch: [107] [524800/1281167 (41%)]	Loss: 0.956682
[2022-06-10 15:51:23 | train] - Train Epoch: [107] [537600/1281167 (42%)]	Loss: 0.915959
[2022-06-10 15:51:44 | train] - Train Epoch: [107] [550400/1281167 (43%)]	Loss: 0.717907
[2022-06-10 15:52:05 | train] - Train Epoch: [107] [563200/1281167 (44%)]	Loss: 0.782685
[2022-06-10 15:52:26 | train] - Train Epoch: [107] [576000/1281167 (45%)]	Loss: 0.909776
[2022-06-10 15:52:46 | train] - Train Epoch: [107] [588800/1281167 (46%)]	Loss: 1.064153
[2022-06-10 15:53:06 | train] - Train Epoch: [107] [601600/1281167 (47%)]	Loss: 0.859460
[2022-06-10 15:53:27 | train] - Train Epoch: [107] [614400/1281167 (48%)]	Loss: 0.899407
[2022-06-10 15:53:48 | train] - Train Epoch: [107] [627200/1281167 (49%)]	Loss: 1.118629
[2022-06-10 15:54:08 | train] - Train Epoch: [107] [640000/1281167 (50%)]	Loss: 0.868987
[2022-06-10 15:54:29 | train] - Train Epoch: [107] [652800/1281167 (51%)]	Loss: 0.638101
[2022-06-10 15:54:49 | train] - Train Epoch: [107] [665600/1281167 (52%)]	Loss: 1.057301
[2022-06-10 15:55:10 | train] - Train Epoch: [107] [678400/1281167 (53%)]	Loss: 0.806737
[2022-06-10 15:55:31 | train] - Train Epoch: [107] [691200/1281167 (54%)]	Loss: 0.980332
[2022-06-10 15:55:51 | train] - Train Epoch: [107] [704000/1281167 (55%)]	Loss: 0.687482
[2022-06-10 15:56:11 | train] - Train Epoch: [107] [716800/1281167 (56%)]	Loss: 0.860197
[2022-06-10 15:56:32 | train] - Train Epoch: [107] [729600/1281167 (57%)]	Loss: 0.870809
[2022-06-10 15:56:52 | train] - Train Epoch: [107] [742400/1281167 (58%)]	Loss: 0.910002
[2022-06-10 15:57:14 | train] - Train Epoch: [107] [755200/1281167 (59%)]	Loss: 0.863498
[2022-06-10 15:57:35 | train] - Train Epoch: [107] [768000/1281167 (60%)]	Loss: 0.854172
[2022-06-10 15:57:56 | train] - Train Epoch: [107] [780800/1281167 (61%)]	Loss: 1.022519
[2022-06-10 15:58:16 | train] - Train Epoch: [107] [793600/1281167 (62%)]	Loss: 1.080135
[2022-06-10 15:58:36 | train] - Train Epoch: [107] [806400/1281167 (63%)]	Loss: 0.812641
[2022-06-10 15:58:57 | train] - Train Epoch: [107] [819200/1281167 (64%)]	Loss: 0.501624
[2022-06-10 15:59:17 | train] - Train Epoch: [107] [832000/1281167 (65%)]	Loss: 0.744649
[2022-06-10 15:59:37 | train] - Train Epoch: [107] [844800/1281167 (66%)]	Loss: 0.672490
[2022-06-10 15:59:57 | train] - Train Epoch: [107] [857600/1281167 (67%)]	Loss: 0.738967
[2022-06-10 16:00:18 | train] - Train Epoch: [107] [870400/1281167 (68%)]	Loss: 1.015983
[2022-06-10 16:00:39 | train] - Train Epoch: [107] [883200/1281167 (69%)]	Loss: 0.853083
[2022-06-10 16:00:59 | train] - Train Epoch: [107] [896000/1281167 (70%)]	Loss: 0.902416
[2022-06-10 16:01:20 | train] - Train Epoch: [107] [908800/1281167 (71%)]	Loss: 1.024630
[2022-06-10 16:01:39 | train] - Train Epoch: [107] [921600/1281167 (72%)]	Loss: 0.848609
[2022-06-10 16:02:00 | train] - Train Epoch: [107] [934400/1281167 (73%)]	Loss: 0.858288
[2022-06-10 16:02:20 | train] - Train Epoch: [107] [947200/1281167 (74%)]	Loss: 0.971988
[2022-06-10 16:02:41 | train] - Train Epoch: [107] [960000/1281167 (75%)]	Loss: 1.144493
[2022-06-10 16:03:01 | train] - Train Epoch: [107] [972800/1281167 (76%)]	Loss: 0.829678
[2022-06-10 16:03:22 | train] - Train Epoch: [107] [985600/1281167 (77%)]	Loss: 0.913991
[2022-06-10 16:03:43 | train] - Train Epoch: [107] [998400/1281167 (78%)]	Loss: 0.709918
[2022-06-10 16:04:03 | train] - Train Epoch: [107] [1011200/1281167 (79%)]	Loss: 1.002694
[2022-06-10 16:04:24 | train] - Train Epoch: [107] [1024000/1281167 (80%)]	Loss: 0.966975
[2022-06-10 16:04:44 | train] - Train Epoch: [107] [1036800/1281167 (81%)]	Loss: 0.922592
[2022-06-10 16:05:04 | train] - Train Epoch: [107] [1049600/1281167 (82%)]	Loss: 0.744310
[2022-06-10 16:05:24 | train] - Train Epoch: [107] [1062400/1281167 (83%)]	Loss: 0.866755
[2022-06-10 16:05:45 | train] - Train Epoch: [107] [1075200/1281167 (84%)]	Loss: 0.733655
[2022-06-10 16:06:06 | train] - Train Epoch: [107] [1088000/1281167 (85%)]	Loss: 0.821504
[2022-06-10 16:06:27 | train] - Train Epoch: [107] [1100800/1281167 (86%)]	Loss: 0.879092
[2022-06-10 16:06:48 | train] - Train Epoch: [107] [1113600/1281167 (87%)]	Loss: 0.690162
[2022-06-10 16:07:08 | train] - Train Epoch: [107] [1126400/1281167 (88%)]	Loss: 0.630271
[2022-06-10 16:07:29 | train] - Train Epoch: [107] [1139200/1281167 (89%)]	Loss: 0.874515
[2022-06-10 16:07:50 | train] - Train Epoch: [107] [1152000/1281167 (90%)]	Loss: 0.653111
[2022-06-10 16:08:10 | train] - Train Epoch: [107] [1164800/1281167 (91%)]	Loss: 0.929866
[2022-06-10 16:08:31 | train] - Train Epoch: [107] [1177600/1281167 (92%)]	Loss: 0.926288
[2022-06-10 16:08:52 | train] - Train Epoch: [107] [1190400/1281167 (93%)]	Loss: 0.899057
[2022-06-10 16:09:12 | train] - Train Epoch: [107] [1203200/1281167 (94%)]	Loss: 0.834754
[2022-06-10 16:09:33 | train] - Train Epoch: [107] [1216000/1281167 (95%)]	Loss: 0.653834
[2022-06-10 16:09:54 | train] - Train Epoch: [107] [1228800/1281167 (96%)]	Loss: 0.746652
[2022-06-10 16:10:15 | train] - Train Epoch: [107] [1241600/1281167 (97%)]	Loss: 0.833771
[2022-06-10 16:10:35 | train] - Train Epoch: [107] [1254400/1281167 (98%)]	Loss: 0.716434
[2022-06-10 16:10:56 | train] - Train Epoch: [107] [1267200/1281167 (99%)]	Loss: 1.169087
[2022-06-10 16:11:16 | train] - Train Epoch: [107] [1280000/1281167 (100%)]	Loss: 0.876950
[2022-06-10 16:11:17 | train] - Train Epoch: [107]	 Average Loss: 0.844400	 Total Acc : 79.3281	 Total Top5 Acc : 92.4632
[2022-06-10 16:11:17 | train] - -------107 epoch end-----------
========================================
-------107 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 16:12:52 | train] - 
Epoch [107] Test set: Average loss: 1.4048, Accuracy: 34785/50000 (69.5404%), Top-5 Accuracy: 88.7104%

[2022-06-10 16:12:52 | train] - save intermediate epoch [107] result


[2022-06-10 16:13:23 | train] - -------108 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 16:13:25 | train] - Train Epoch: [108] [0/1281167 (0%)]	Loss: 0.866182
[2022-06-10 16:13:45 | train] - Train Epoch: [108] [12800/1281167 (1%)]	Loss: 1.120202
[2022-06-10 16:14:05 | train] - Train Epoch: [108] [25600/1281167 (2%)]	Loss: 0.539076
[2022-06-10 16:14:26 | train] - Train Epoch: [108] [38400/1281167 (3%)]	Loss: 0.903747
[2022-06-10 16:14:46 | train] - Train Epoch: [108] [51200/1281167 (4%)]	Loss: 0.798377
[2022-06-10 16:15:07 | train] - Train Epoch: [108] [64000/1281167 (5%)]	Loss: 0.811512
[2022-06-10 16:15:27 | train] - Train Epoch: [108] [76800/1281167 (6%)]	Loss: 0.998813
[2022-06-10 16:15:47 | train] - Train Epoch: [108] [89600/1281167 (7%)]	Loss: 0.634729
[2022-06-10 16:16:08 | train] - Train Epoch: [108] [102400/1281167 (8%)]	Loss: 0.811789
[2022-06-10 16:16:28 | train] - Train Epoch: [108] [115200/1281167 (9%)]	Loss: 1.030269
[2022-06-10 16:16:48 | train] - Train Epoch: [108] [128000/1281167 (10%)]	Loss: 1.010280
[2022-06-10 16:17:09 | train] - Train Epoch: [108] [140800/1281167 (11%)]	Loss: 0.720604
[2022-06-10 16:17:30 | train] - Train Epoch: [108] [153600/1281167 (12%)]	Loss: 0.965235
[2022-06-10 16:17:50 | train] - Train Epoch: [108] [166400/1281167 (13%)]	Loss: 0.891420
[2022-06-10 16:18:10 | train] - Train Epoch: [108] [179200/1281167 (14%)]	Loss: 0.911163
[2022-06-10 16:18:31 | train] - Train Epoch: [108] [192000/1281167 (15%)]	Loss: 0.681427
[2022-06-10 16:18:51 | train] - Train Epoch: [108] [204800/1281167 (16%)]	Loss: 0.906245
[2022-06-10 16:19:12 | train] - Train Epoch: [108] [217600/1281167 (17%)]	Loss: 0.774327
[2022-06-10 16:19:32 | train] - Train Epoch: [108] [230400/1281167 (18%)]	Loss: 1.003841
[2022-06-10 16:19:52 | train] - Train Epoch: [108] [243200/1281167 (19%)]	Loss: 0.840998
[2022-06-10 16:20:13 | train] - Train Epoch: [108] [256000/1281167 (20%)]	Loss: 1.020640
[2022-06-10 16:20:34 | train] - Train Epoch: [108] [268800/1281167 (21%)]	Loss: 0.885257
[2022-06-10 16:20:54 | train] - Train Epoch: [108] [281600/1281167 (22%)]	Loss: 0.430635
[2022-06-10 16:21:14 | train] - Train Epoch: [108] [294400/1281167 (23%)]	Loss: 0.715294
[2022-06-10 16:21:35 | train] - Train Epoch: [108] [307200/1281167 (24%)]	Loss: 0.591252
[2022-06-10 16:21:55 | train] - Train Epoch: [108] [320000/1281167 (25%)]	Loss: 0.698752
[2022-06-10 16:22:16 | train] - Train Epoch: [108] [332800/1281167 (26%)]	Loss: 0.934189
[2022-06-10 16:22:36 | train] - Train Epoch: [108] [345600/1281167 (27%)]	Loss: 0.674144
[2022-06-10 16:22:56 | train] - Train Epoch: [108] [358400/1281167 (28%)]	Loss: 0.698767
[2022-06-10 16:23:16 | train] - Train Epoch: [108] [371200/1281167 (29%)]	Loss: 0.925215
[2022-06-10 16:23:37 | train] - Train Epoch: [108] [384000/1281167 (30%)]	Loss: 1.096564
[2022-06-10 16:23:57 | train] - Train Epoch: [108] [396800/1281167 (31%)]	Loss: 0.809997
[2022-06-10 16:24:18 | train] - Train Epoch: [108] [409600/1281167 (32%)]	Loss: 0.793714
[2022-06-10 16:24:37 | train] - Train Epoch: [108] [422400/1281167 (33%)]	Loss: 0.903176
[2022-06-10 16:24:57 | train] - Train Epoch: [108] [435200/1281167 (34%)]	Loss: 1.099609
[2022-06-10 16:25:17 | train] - Train Epoch: [108] [448000/1281167 (35%)]	Loss: 0.938408
[2022-06-10 16:25:37 | train] - Train Epoch: [108] [460800/1281167 (36%)]	Loss: 0.953128
[2022-06-10 16:25:58 | train] - Train Epoch: [108] [473600/1281167 (37%)]	Loss: 0.835625
[2022-06-10 16:26:18 | train] - Train Epoch: [108] [486400/1281167 (38%)]	Loss: 0.716252
[2022-06-10 16:26:39 | train] - Train Epoch: [108] [499200/1281167 (39%)]	Loss: 0.778909
[2022-06-10 16:26:59 | train] - Train Epoch: [108] [512000/1281167 (40%)]	Loss: 0.848377
[2022-06-10 16:27:20 | train] - Train Epoch: [108] [524800/1281167 (41%)]	Loss: 0.573636
[2022-06-10 16:27:41 | train] - Train Epoch: [108] [537600/1281167 (42%)]	Loss: 0.673052
[2022-06-10 16:28:01 | train] - Train Epoch: [108] [550400/1281167 (43%)]	Loss: 0.874812
[2022-06-10 16:28:22 | train] - Train Epoch: [108] [563200/1281167 (44%)]	Loss: 0.503987
[2022-06-10 16:28:42 | train] - Train Epoch: [108] [576000/1281167 (45%)]	Loss: 1.117704
[2022-06-10 16:29:03 | train] - Train Epoch: [108] [588800/1281167 (46%)]	Loss: 1.200118
[2022-06-10 16:29:23 | train] - Train Epoch: [108] [601600/1281167 (47%)]	Loss: 0.775024
[2022-06-10 16:29:44 | train] - Train Epoch: [108] [614400/1281167 (48%)]	Loss: 0.942406
[2022-06-10 16:30:04 | train] - Train Epoch: [108] [627200/1281167 (49%)]	Loss: 0.783972
[2022-06-10 16:30:25 | train] - Train Epoch: [108] [640000/1281167 (50%)]	Loss: 0.576424
[2022-06-10 16:30:46 | train] - Train Epoch: [108] [652800/1281167 (51%)]	Loss: 0.765967
[2022-06-10 16:31:06 | train] - Train Epoch: [108] [665600/1281167 (52%)]	Loss: 0.897612
[2022-06-10 16:31:26 | train] - Train Epoch: [108] [678400/1281167 (53%)]	Loss: 0.697812
[2022-06-10 16:31:47 | train] - Train Epoch: [108] [691200/1281167 (54%)]	Loss: 0.735090
[2022-06-10 16:32:07 | train] - Train Epoch: [108] [704000/1281167 (55%)]	Loss: 0.767753
[2022-06-10 16:32:29 | train] - Train Epoch: [108] [716800/1281167 (56%)]	Loss: 1.102664
[2022-06-10 16:32:49 | train] - Train Epoch: [108] [729600/1281167 (57%)]	Loss: 0.994122
[2022-06-10 16:33:08 | train] - Train Epoch: [108] [742400/1281167 (58%)]	Loss: 0.907301
[2022-06-10 16:33:29 | train] - Train Epoch: [108] [755200/1281167 (59%)]	Loss: 0.680028
[2022-06-10 16:33:49 | train] - Train Epoch: [108] [768000/1281167 (60%)]	Loss: 0.662875
[2022-06-10 16:34:09 | train] - Train Epoch: [108] [780800/1281167 (61%)]	Loss: 0.985056
[2022-06-10 16:34:30 | train] - Train Epoch: [108] [793600/1281167 (62%)]	Loss: 0.865924
[2022-06-10 16:34:50 | train] - Train Epoch: [108] [806400/1281167 (63%)]	Loss: 0.752322
[2022-06-10 16:35:10 | train] - Train Epoch: [108] [819200/1281167 (64%)]	Loss: 0.675309
[2022-06-10 16:35:30 | train] - Train Epoch: [108] [832000/1281167 (65%)]	Loss: 0.799521
[2022-06-10 16:35:50 | train] - Train Epoch: [108] [844800/1281167 (66%)]	Loss: 0.885101
[2022-06-10 16:36:10 | train] - Train Epoch: [108] [857600/1281167 (67%)]	Loss: 0.877894
[2022-06-10 16:36:29 | train] - Train Epoch: [108] [870400/1281167 (68%)]	Loss: 0.794258
[2022-06-10 16:36:49 | train] - Train Epoch: [108] [883200/1281167 (69%)]	Loss: 0.887006
[2022-06-10 16:37:09 | train] - Train Epoch: [108] [896000/1281167 (70%)]	Loss: 1.140296
[2022-06-10 16:37:29 | train] - Train Epoch: [108] [908800/1281167 (71%)]	Loss: 0.773769
[2022-06-10 16:37:49 | train] - Train Epoch: [108] [921600/1281167 (72%)]	Loss: 0.756544
[2022-06-10 16:38:09 | train] - Train Epoch: [108] [934400/1281167 (73%)]	Loss: 0.983757
[2022-06-10 16:38:29 | train] - Train Epoch: [108] [947200/1281167 (74%)]	Loss: 1.140835
[2022-06-10 16:38:50 | train] - Train Epoch: [108] [960000/1281167 (75%)]	Loss: 0.974166
[2022-06-10 16:39:09 | train] - Train Epoch: [108] [972800/1281167 (76%)]	Loss: 1.018692
[2022-06-10 16:39:30 | train] - Train Epoch: [108] [985600/1281167 (77%)]	Loss: 0.904297
[2022-06-10 16:39:50 | train] - Train Epoch: [108] [998400/1281167 (78%)]	Loss: 0.773128
[2022-06-10 16:40:10 | train] - Train Epoch: [108] [1011200/1281167 (79%)]	Loss: 0.674802
[2022-06-10 16:40:30 | train] - Train Epoch: [108] [1024000/1281167 (80%)]	Loss: 0.825368
[2022-06-10 16:40:50 | train] - Train Epoch: [108] [1036800/1281167 (81%)]	Loss: 1.017339
[2022-06-10 16:41:11 | train] - Train Epoch: [108] [1049600/1281167 (82%)]	Loss: 0.812667
[2022-06-10 16:41:31 | train] - Train Epoch: [108] [1062400/1281167 (83%)]	Loss: 0.748292
[2022-06-10 16:41:52 | train] - Train Epoch: [108] [1075200/1281167 (84%)]	Loss: 0.896763
[2022-06-10 16:42:12 | train] - Train Epoch: [108] [1088000/1281167 (85%)]	Loss: 0.700071
[2022-06-10 16:42:33 | train] - Train Epoch: [108] [1100800/1281167 (86%)]	Loss: 0.822917
[2022-06-10 16:42:53 | train] - Train Epoch: [108] [1113600/1281167 (87%)]	Loss: 0.903252
[2022-06-10 16:43:14 | train] - Train Epoch: [108] [1126400/1281167 (88%)]	Loss: 0.700502
[2022-06-10 16:43:35 | train] - Train Epoch: [108] [1139200/1281167 (89%)]	Loss: 0.918158
[2022-06-10 16:43:56 | train] - Train Epoch: [108] [1152000/1281167 (90%)]	Loss: 0.778853
[2022-06-10 16:44:18 | train] - Train Epoch: [108] [1164800/1281167 (91%)]	Loss: 0.846552
[2022-06-10 16:44:38 | train] - Train Epoch: [108] [1177600/1281167 (92%)]	Loss: 0.946072
[2022-06-10 16:44:59 | train] - Train Epoch: [108] [1190400/1281167 (93%)]	Loss: 0.856310
[2022-06-10 16:45:20 | train] - Train Epoch: [108] [1203200/1281167 (94%)]	Loss: 0.802968
[2022-06-10 16:45:41 | train] - Train Epoch: [108] [1216000/1281167 (95%)]	Loss: 1.139859
[2022-06-10 16:46:01 | train] - Train Epoch: [108] [1228800/1281167 (96%)]	Loss: 0.749149
[2022-06-10 16:46:22 | train] - Train Epoch: [108] [1241600/1281167 (97%)]	Loss: 0.868313
[2022-06-10 16:46:43 | train] - Train Epoch: [108] [1254400/1281167 (98%)]	Loss: 1.001259
[2022-06-10 16:47:03 | train] - Train Epoch: [108] [1267200/1281167 (99%)]	Loss: 1.030392
[2022-06-10 16:47:24 | train] - Train Epoch: [108] [1280000/1281167 (100%)]	Loss: 0.697224
[2022-06-10 16:47:26 | train] - Train Epoch: [108]	 Average Loss: 0.842141	 Total Acc : 79.3290	 Total Top5 Acc : 92.4636
[2022-06-10 16:47:26 | train] - -------108 epoch end-----------
========================================
-------108 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 16:48:58 | train] - 
Epoch [108] Test set: Average loss: 1.3946, Accuracy: 34914/50000 (69.8078%), Top-5 Accuracy: 88.8595%

[2022-06-10 16:48:58 | train] - save intermediate epoch [108] result


[2022-06-10 16:49:31 | train] - -------109 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 16:49:32 | train] - Train Epoch: [109] [0/1281167 (0%)]	Loss: 0.999218
[2022-06-10 16:49:53 | train] - Train Epoch: [109] [12800/1281167 (1%)]	Loss: 0.558076
[2022-06-10 16:50:14 | train] - Train Epoch: [109] [25600/1281167 (2%)]	Loss: 0.847716
[2022-06-10 16:50:35 | train] - Train Epoch: [109] [38400/1281167 (3%)]	Loss: 0.882610
[2022-06-10 16:50:56 | train] - Train Epoch: [109] [51200/1281167 (4%)]	Loss: 0.846788
[2022-06-10 16:51:18 | train] - Train Epoch: [109] [64000/1281167 (5%)]	Loss: 0.730441
[2022-06-10 16:51:38 | train] - Train Epoch: [109] [76800/1281167 (6%)]	Loss: 0.923069
[2022-06-10 16:51:58 | train] - Train Epoch: [109] [89600/1281167 (7%)]	Loss: 0.857900
[2022-06-10 16:52:19 | train] - Train Epoch: [109] [102400/1281167 (8%)]	Loss: 0.852545
[2022-06-10 16:52:40 | train] - Train Epoch: [109] [115200/1281167 (9%)]	Loss: 0.933653
[2022-06-10 16:53:00 | train] - Train Epoch: [109] [128000/1281167 (10%)]	Loss: 0.835687
[2022-06-10 16:53:20 | train] - Train Epoch: [109] [140800/1281167 (11%)]	Loss: 0.787595
[2022-06-10 16:53:41 | train] - Train Epoch: [109] [153600/1281167 (12%)]	Loss: 0.790735
[2022-06-10 16:54:02 | train] - Train Epoch: [109] [166400/1281167 (13%)]	Loss: 0.772464
[2022-06-10 16:54:23 | train] - Train Epoch: [109] [179200/1281167 (14%)]	Loss: 0.928394
[2022-06-10 16:54:43 | train] - Train Epoch: [109] [192000/1281167 (15%)]	Loss: 0.807871
[2022-06-10 16:55:03 | train] - Train Epoch: [109] [204800/1281167 (16%)]	Loss: 0.752252
[2022-06-10 16:55:25 | train] - Train Epoch: [109] [217600/1281167 (17%)]	Loss: 0.762599
[2022-06-10 16:55:46 | train] - Train Epoch: [109] [230400/1281167 (18%)]	Loss: 0.799426
[2022-06-10 16:56:06 | train] - Train Epoch: [109] [243200/1281167 (19%)]	Loss: 1.009505
[2022-06-10 16:56:27 | train] - Train Epoch: [109] [256000/1281167 (20%)]	Loss: 0.714659
[2022-06-10 16:56:48 | train] - Train Epoch: [109] [268800/1281167 (21%)]	Loss: 0.734783
[2022-06-10 16:57:08 | train] - Train Epoch: [109] [281600/1281167 (22%)]	Loss: 0.962039
[2022-06-10 16:57:28 | train] - Train Epoch: [109] [294400/1281167 (23%)]	Loss: 0.819330
[2022-06-10 16:57:48 | train] - Train Epoch: [109] [307200/1281167 (24%)]	Loss: 0.657749
[2022-06-10 16:58:09 | train] - Train Epoch: [109] [320000/1281167 (25%)]	Loss: 0.736177
[2022-06-10 16:58:30 | train] - Train Epoch: [109] [332800/1281167 (26%)]	Loss: 1.036890
[2022-06-10 16:58:49 | train] - Train Epoch: [109] [345600/1281167 (27%)]	Loss: 0.644115
[2022-06-10 16:59:10 | train] - Train Epoch: [109] [358400/1281167 (28%)]	Loss: 0.814995
[2022-06-10 16:59:31 | train] - Train Epoch: [109] [371200/1281167 (29%)]	Loss: 0.802901
[2022-06-10 16:59:51 | train] - Train Epoch: [109] [384000/1281167 (30%)]	Loss: 0.898768
[2022-06-10 17:00:11 | train] - Train Epoch: [109] [396800/1281167 (31%)]	Loss: 0.570745
[2022-06-10 17:00:31 | train] - Train Epoch: [109] [409600/1281167 (32%)]	Loss: 0.850891
[2022-06-10 17:00:52 | train] - Train Epoch: [109] [422400/1281167 (33%)]	Loss: 0.933063
[2022-06-10 17:01:12 | train] - Train Epoch: [109] [435200/1281167 (34%)]	Loss: 0.643312
[2022-06-10 17:01:33 | train] - Train Epoch: [109] [448000/1281167 (35%)]	Loss: 0.925780
[2022-06-10 17:01:53 | train] - Train Epoch: [109] [460800/1281167 (36%)]	Loss: 0.737087
[2022-06-10 17:02:14 | train] - Train Epoch: [109] [473600/1281167 (37%)]	Loss: 1.128734
[2022-06-10 17:02:34 | train] - Train Epoch: [109] [486400/1281167 (38%)]	Loss: 0.956204
[2022-06-10 17:02:55 | train] - Train Epoch: [109] [499200/1281167 (39%)]	Loss: 0.948210
[2022-06-10 17:03:15 | train] - Train Epoch: [109] [512000/1281167 (40%)]	Loss: 1.040887
[2022-06-10 17:03:35 | train] - Train Epoch: [109] [524800/1281167 (41%)]	Loss: 0.782028
[2022-06-10 17:03:55 | train] - Train Epoch: [109] [537600/1281167 (42%)]	Loss: 0.670447
[2022-06-10 17:04:15 | train] - Train Epoch: [109] [550400/1281167 (43%)]	Loss: 0.946480
[2022-06-10 17:04:36 | train] - Train Epoch: [109] [563200/1281167 (44%)]	Loss: 0.833837
[2022-06-10 17:04:56 | train] - Train Epoch: [109] [576000/1281167 (45%)]	Loss: 0.770908
[2022-06-10 17:05:17 | train] - Train Epoch: [109] [588800/1281167 (46%)]	Loss: 0.672712
[2022-06-10 17:05:36 | train] - Train Epoch: [109] [601600/1281167 (47%)]	Loss: 0.946830
[2022-06-10 17:05:57 | train] - Train Epoch: [109] [614400/1281167 (48%)]	Loss: 0.814309
[2022-06-10 17:06:18 | train] - Train Epoch: [109] [627200/1281167 (49%)]	Loss: 0.672413
[2022-06-10 17:06:38 | train] - Train Epoch: [109] [640000/1281167 (50%)]	Loss: 0.821675
[2022-06-10 17:06:58 | train] - Train Epoch: [109] [652800/1281167 (51%)]	Loss: 0.920550
[2022-06-10 17:07:18 | train] - Train Epoch: [109] [665600/1281167 (52%)]	Loss: 0.986938
[2022-06-10 17:07:38 | train] - Train Epoch: [109] [678400/1281167 (53%)]	Loss: 1.057850
[2022-06-10 17:07:59 | train] - Train Epoch: [109] [691200/1281167 (54%)]	Loss: 1.049376
[2022-06-10 17:08:19 | train] - Train Epoch: [109] [704000/1281167 (55%)]	Loss: 1.031482
[2022-06-10 17:08:40 | train] - Train Epoch: [109] [716800/1281167 (56%)]	Loss: 0.781100
[2022-06-10 17:09:00 | train] - Train Epoch: [109] [729600/1281167 (57%)]	Loss: 0.747706
[2022-06-10 17:09:20 | train] - Train Epoch: [109] [742400/1281167 (58%)]	Loss: 0.596544
[2022-06-10 17:09:40 | train] - Train Epoch: [109] [755200/1281167 (59%)]	Loss: 0.968958
[2022-06-10 17:09:59 | train] - Train Epoch: [109] [768000/1281167 (60%)]	Loss: 0.974447
[2022-06-10 17:10:20 | train] - Train Epoch: [109] [780800/1281167 (61%)]	Loss: 0.874252
[2022-06-10 17:10:40 | train] - Train Epoch: [109] [793600/1281167 (62%)]	Loss: 0.946375
[2022-06-10 17:11:00 | train] - Train Epoch: [109] [806400/1281167 (63%)]	Loss: 0.794056
[2022-06-10 17:11:21 | train] - Train Epoch: [109] [819200/1281167 (64%)]	Loss: 0.743454
[2022-06-10 17:11:42 | train] - Train Epoch: [109] [832000/1281167 (65%)]	Loss: 0.886040
[2022-06-10 17:12:03 | train] - Train Epoch: [109] [844800/1281167 (66%)]	Loss: 0.772024
[2022-06-10 17:12:23 | train] - Train Epoch: [109] [857600/1281167 (67%)]	Loss: 0.634111
[2022-06-10 17:12:44 | train] - Train Epoch: [109] [870400/1281167 (68%)]	Loss: 0.621874
[2022-06-10 17:13:04 | train] - Train Epoch: [109] [883200/1281167 (69%)]	Loss: 0.758280
[2022-06-10 17:13:24 | train] - Train Epoch: [109] [896000/1281167 (70%)]	Loss: 0.882855
[2022-06-10 17:13:44 | train] - Train Epoch: [109] [908800/1281167 (71%)]	Loss: 0.912846
[2022-06-10 17:14:04 | train] - Train Epoch: [109] [921600/1281167 (72%)]	Loss: 0.753665
[2022-06-10 17:14:24 | train] - Train Epoch: [109] [934400/1281167 (73%)]	Loss: 0.870423
[2022-06-10 17:14:45 | train] - Train Epoch: [109] [947200/1281167 (74%)]	Loss: 1.060580
[2022-06-10 17:15:05 | train] - Train Epoch: [109] [960000/1281167 (75%)]	Loss: 0.755827
[2022-06-10 17:15:25 | train] - Train Epoch: [109] [972800/1281167 (76%)]	Loss: 0.936469
[2022-06-10 17:15:45 | train] - Train Epoch: [109] [985600/1281167 (77%)]	Loss: 0.877642
[2022-06-10 17:16:06 | train] - Train Epoch: [109] [998400/1281167 (78%)]	Loss: 0.907807
[2022-06-10 17:16:26 | train] - Train Epoch: [109] [1011200/1281167 (79%)]	Loss: 0.829213
[2022-06-10 17:16:47 | train] - Train Epoch: [109] [1024000/1281167 (80%)]	Loss: 0.802822
[2022-06-10 17:17:07 | train] - Train Epoch: [109] [1036800/1281167 (81%)]	Loss: 1.010493
[2022-06-10 17:17:28 | train] - Train Epoch: [109] [1049600/1281167 (82%)]	Loss: 0.766240
[2022-06-10 17:17:49 | train] - Train Epoch: [109] [1062400/1281167 (83%)]	Loss: 0.759256
[2022-06-10 17:18:09 | train] - Train Epoch: [109] [1075200/1281167 (84%)]	Loss: 0.826566
[2022-06-10 17:18:29 | train] - Train Epoch: [109] [1088000/1281167 (85%)]	Loss: 0.956375
[2022-06-10 17:18:49 | train] - Train Epoch: [109] [1100800/1281167 (86%)]	Loss: 0.702855
[2022-06-10 17:19:10 | train] - Train Epoch: [109] [1113600/1281167 (87%)]	Loss: 0.926906
[2022-06-10 17:19:30 | train] - Train Epoch: [109] [1126400/1281167 (88%)]	Loss: 0.729888
[2022-06-10 17:19:50 | train] - Train Epoch: [109] [1139200/1281167 (89%)]	Loss: 0.771337
[2022-06-10 17:20:11 | train] - Train Epoch: [109] [1152000/1281167 (90%)]	Loss: 0.919336
[2022-06-10 17:20:31 | train] - Train Epoch: [109] [1164800/1281167 (91%)]	Loss: 0.954445
[2022-06-10 17:20:51 | train] - Train Epoch: [109] [1177600/1281167 (92%)]	Loss: 1.008414
[2022-06-10 17:21:11 | train] - Train Epoch: [109] [1190400/1281167 (93%)]	Loss: 0.699769
[2022-06-10 17:21:31 | train] - Train Epoch: [109] [1203200/1281167 (94%)]	Loss: 0.758892
[2022-06-10 17:21:51 | train] - Train Epoch: [109] [1216000/1281167 (95%)]	Loss: 0.910490
[2022-06-10 17:22:11 | train] - Train Epoch: [109] [1228800/1281167 (96%)]	Loss: 0.683071
[2022-06-10 17:22:32 | train] - Train Epoch: [109] [1241600/1281167 (97%)]	Loss: 0.612594
[2022-06-10 17:22:52 | train] - Train Epoch: [109] [1254400/1281167 (98%)]	Loss: 0.743576
[2022-06-10 17:23:13 | train] - Train Epoch: [109] [1267200/1281167 (99%)]	Loss: 0.965239
[2022-06-10 17:23:33 | train] - Train Epoch: [109] [1280000/1281167 (100%)]	Loss: 0.823674
[2022-06-10 17:23:35 | train] - Train Epoch: [109]	 Average Loss: 0.840888	 Total Acc : 79.4145	 Total Top5 Acc : 92.4697
[2022-06-10 17:23:35 | train] - -------109 epoch end-----------
========================================
-------109 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 17:25:05 | train] - 
Epoch [109] Test set: Average loss: 1.4037, Accuracy: 34827/50000 (69.6220%), Top-5 Accuracy: 88.7556%

[2022-06-10 17:25:05 | train] - save intermediate epoch [109] result


[2022-06-10 17:25:41 | train] - -------110 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 17:25:43 | train] - Train Epoch: [110] [0/1281167 (0%)]	Loss: 0.871117
[2022-06-10 17:26:02 | train] - Train Epoch: [110] [12800/1281167 (1%)]	Loss: 1.012991
[2022-06-10 17:26:23 | train] - Train Epoch: [110] [25600/1281167 (2%)]	Loss: 0.871695
[2022-06-10 17:26:43 | train] - Train Epoch: [110] [38400/1281167 (3%)]	Loss: 0.893280
[2022-06-10 17:27:03 | train] - Train Epoch: [110] [51200/1281167 (4%)]	Loss: 0.772727
[2022-06-10 17:27:23 | train] - Train Epoch: [110] [64000/1281167 (5%)]	Loss: 0.920340
[2022-06-10 17:27:44 | train] - Train Epoch: [110] [76800/1281167 (6%)]	Loss: 0.925468
[2022-06-10 17:28:04 | train] - Train Epoch: [110] [89600/1281167 (7%)]	Loss: 0.764539
[2022-06-10 17:28:25 | train] - Train Epoch: [110] [102400/1281167 (8%)]	Loss: 1.148177
[2022-06-10 17:28:45 | train] - Train Epoch: [110] [115200/1281167 (9%)]	Loss: 0.999283
[2022-06-10 17:29:06 | train] - Train Epoch: [110] [128000/1281167 (10%)]	Loss: 0.699739
[2022-06-10 17:29:26 | train] - Train Epoch: [110] [140800/1281167 (11%)]	Loss: 0.619455
[2022-06-10 17:29:46 | train] - Train Epoch: [110] [153600/1281167 (12%)]	Loss: 0.891922
[2022-06-10 17:30:07 | train] - Train Epoch: [110] [166400/1281167 (13%)]	Loss: 0.805965
[2022-06-10 17:30:27 | train] - Train Epoch: [110] [179200/1281167 (14%)]	Loss: 0.927095
[2022-06-10 17:30:47 | train] - Train Epoch: [110] [192000/1281167 (15%)]	Loss: 0.894156
[2022-06-10 17:31:07 | train] - Train Epoch: [110] [204800/1281167 (16%)]	Loss: 0.712409
[2022-06-10 17:31:28 | train] - Train Epoch: [110] [217600/1281167 (17%)]	Loss: 0.885211
[2022-06-10 17:31:48 | train] - Train Epoch: [110] [230400/1281167 (18%)]	Loss: 0.882172
[2022-06-10 17:32:10 | train] - Train Epoch: [110] [243200/1281167 (19%)]	Loss: 0.721796
[2022-06-10 17:32:30 | train] - Train Epoch: [110] [256000/1281167 (20%)]	Loss: 0.735854
[2022-06-10 17:32:51 | train] - Train Epoch: [110] [268800/1281167 (21%)]	Loss: 0.698492
[2022-06-10 17:33:11 | train] - Train Epoch: [110] [281600/1281167 (22%)]	Loss: 0.685949
[2022-06-10 17:33:31 | train] - Train Epoch: [110] [294400/1281167 (23%)]	Loss: 0.932178
[2022-06-10 17:33:52 | train] - Train Epoch: [110] [307200/1281167 (24%)]	Loss: 0.978321
[2022-06-10 17:34:13 | train] - Train Epoch: [110] [320000/1281167 (25%)]	Loss: 0.811507
[2022-06-10 17:34:34 | train] - Train Epoch: [110] [332800/1281167 (26%)]	Loss: 0.898641
[2022-06-10 17:34:55 | train] - Train Epoch: [110] [345600/1281167 (27%)]	Loss: 0.806203
[2022-06-10 17:35:16 | train] - Train Epoch: [110] [358400/1281167 (28%)]	Loss: 0.941712
[2022-06-10 17:35:36 | train] - Train Epoch: [110] [371200/1281167 (29%)]	Loss: 0.762500
[2022-06-10 17:35:57 | train] - Train Epoch: [110] [384000/1281167 (30%)]	Loss: 0.885007
[2022-06-10 17:36:17 | train] - Train Epoch: [110] [396800/1281167 (31%)]	Loss: 0.740393
[2022-06-10 17:36:38 | train] - Train Epoch: [110] [409600/1281167 (32%)]	Loss: 0.681734
[2022-06-10 17:36:59 | train] - Train Epoch: [110] [422400/1281167 (33%)]	Loss: 0.852477
[2022-06-10 17:37:20 | train] - Train Epoch: [110] [435200/1281167 (34%)]	Loss: 0.726876
[2022-06-10 17:37:40 | train] - Train Epoch: [110] [448000/1281167 (35%)]	Loss: 0.876641
[2022-06-10 17:38:00 | train] - Train Epoch: [110] [460800/1281167 (36%)]	Loss: 0.784661
[2022-06-10 17:38:21 | train] - Train Epoch: [110] [473600/1281167 (37%)]	Loss: 0.795801
[2022-06-10 17:38:41 | train] - Train Epoch: [110] [486400/1281167 (38%)]	Loss: 0.633041
[2022-06-10 17:39:02 | train] - Train Epoch: [110] [499200/1281167 (39%)]	Loss: 0.903037
[2022-06-10 17:39:22 | train] - Train Epoch: [110] [512000/1281167 (40%)]	Loss: 0.460735
[2022-06-10 17:39:43 | train] - Train Epoch: [110] [524800/1281167 (41%)]	Loss: 0.888700
[2022-06-10 17:40:03 | train] - Train Epoch: [110] [537600/1281167 (42%)]	Loss: 0.975097
[2022-06-10 17:40:25 | train] - Train Epoch: [110] [550400/1281167 (43%)]	Loss: 0.949843
[2022-06-10 17:40:46 | train] - Train Epoch: [110] [563200/1281167 (44%)]	Loss: 0.712668
[2022-06-10 17:41:06 | train] - Train Epoch: [110] [576000/1281167 (45%)]	Loss: 0.964972
[2022-06-10 17:41:26 | train] - Train Epoch: [110] [588800/1281167 (46%)]	Loss: 0.829214
[2022-06-10 17:41:47 | train] - Train Epoch: [110] [601600/1281167 (47%)]	Loss: 0.732311
[2022-06-10 17:42:07 | train] - Train Epoch: [110] [614400/1281167 (48%)]	Loss: 0.744556
[2022-06-10 17:42:27 | train] - Train Epoch: [110] [627200/1281167 (49%)]	Loss: 0.923281
[2022-06-10 17:42:48 | train] - Train Epoch: [110] [640000/1281167 (50%)]	Loss: 1.050965
[2022-06-10 17:43:09 | train] - Train Epoch: [110] [652800/1281167 (51%)]	Loss: 0.711542
[2022-06-10 17:43:29 | train] - Train Epoch: [110] [665600/1281167 (52%)]	Loss: 0.859421
[2022-06-10 17:43:50 | train] - Train Epoch: [110] [678400/1281167 (53%)]	Loss: 0.842807
[2022-06-10 17:44:10 | train] - Train Epoch: [110] [691200/1281167 (54%)]	Loss: 0.822928
[2022-06-10 17:44:30 | train] - Train Epoch: [110] [704000/1281167 (55%)]	Loss: 0.703572
[2022-06-10 17:44:51 | train] - Train Epoch: [110] [716800/1281167 (56%)]	Loss: 1.052165
[2022-06-10 17:45:11 | train] - Train Epoch: [110] [729600/1281167 (57%)]	Loss: 0.804567
[2022-06-10 17:45:31 | train] - Train Epoch: [110] [742400/1281167 (58%)]	Loss: 0.760268
[2022-06-10 17:45:52 | train] - Train Epoch: [110] [755200/1281167 (59%)]	Loss: 1.289460
[2022-06-10 17:46:12 | train] - Train Epoch: [110] [768000/1281167 (60%)]	Loss: 0.911920
[2022-06-10 17:46:33 | train] - Train Epoch: [110] [780800/1281167 (61%)]	Loss: 1.158202
[2022-06-10 17:46:53 | train] - Train Epoch: [110] [793600/1281167 (62%)]	Loss: 0.600211
[2022-06-10 17:47:14 | train] - Train Epoch: [110] [806400/1281167 (63%)]	Loss: 0.664213
[2022-06-10 17:47:34 | train] - Train Epoch: [110] [819200/1281167 (64%)]	Loss: 0.782990
[2022-06-10 17:47:54 | train] - Train Epoch: [110] [832000/1281167 (65%)]	Loss: 1.000903
[2022-06-10 17:48:14 | train] - Train Epoch: [110] [844800/1281167 (66%)]	Loss: 0.788993
[2022-06-10 17:48:35 | train] - Train Epoch: [110] [857600/1281167 (67%)]	Loss: 0.888270
[2022-06-10 17:48:55 | train] - Train Epoch: [110] [870400/1281167 (68%)]	Loss: 0.872045
[2022-06-10 17:49:16 | train] - Train Epoch: [110] [883200/1281167 (69%)]	Loss: 0.842893
[2022-06-10 17:49:36 | train] - Train Epoch: [110] [896000/1281167 (70%)]	Loss: 0.725280
[2022-06-10 17:49:57 | train] - Train Epoch: [110] [908800/1281167 (71%)]	Loss: 0.684101
[2022-06-10 17:50:17 | train] - Train Epoch: [110] [921600/1281167 (72%)]	Loss: 0.886829
[2022-06-10 17:50:38 | train] - Train Epoch: [110] [934400/1281167 (73%)]	Loss: 0.726950
[2022-06-10 17:50:59 | train] - Train Epoch: [110] [947200/1281167 (74%)]	Loss: 0.887469
[2022-06-10 17:51:20 | train] - Train Epoch: [110] [960000/1281167 (75%)]	Loss: 0.901215
[2022-06-10 17:51:40 | train] - Train Epoch: [110] [972800/1281167 (76%)]	Loss: 0.789354
[2022-06-10 17:52:01 | train] - Train Epoch: [110] [985600/1281167 (77%)]	Loss: 0.887298
[2022-06-10 17:52:21 | train] - Train Epoch: [110] [998400/1281167 (78%)]	Loss: 0.751836
[2022-06-10 17:52:42 | train] - Train Epoch: [110] [1011200/1281167 (79%)]	Loss: 0.730915
[2022-06-10 17:53:02 | train] - Train Epoch: [110] [1024000/1281167 (80%)]	Loss: 0.740276
[2022-06-10 17:53:23 | train] - Train Epoch: [110] [1036800/1281167 (81%)]	Loss: 0.636739
[2022-06-10 17:53:44 | train] - Train Epoch: [110] [1049600/1281167 (82%)]	Loss: 0.991113
[2022-06-10 17:54:05 | train] - Train Epoch: [110] [1062400/1281167 (83%)]	Loss: 0.782281
[2022-06-10 17:54:25 | train] - Train Epoch: [110] [1075200/1281167 (84%)]	Loss: 0.735833
[2022-06-10 17:54:46 | train] - Train Epoch: [110] [1088000/1281167 (85%)]	Loss: 0.825909
[2022-06-10 17:55:07 | train] - Train Epoch: [110] [1100800/1281167 (86%)]	Loss: 0.865384
[2022-06-10 17:55:27 | train] - Train Epoch: [110] [1113600/1281167 (87%)]	Loss: 0.912539
[2022-06-10 17:55:48 | train] - Train Epoch: [110] [1126400/1281167 (88%)]	Loss: 0.816923
[2022-06-10 17:56:08 | train] - Train Epoch: [110] [1139200/1281167 (89%)]	Loss: 0.745755
[2022-06-10 17:56:28 | train] - Train Epoch: [110] [1152000/1281167 (90%)]	Loss: 0.825308
[2022-06-10 17:56:49 | train] - Train Epoch: [110] [1164800/1281167 (91%)]	Loss: 0.807867
[2022-06-10 17:57:10 | train] - Train Epoch: [110] [1177600/1281167 (92%)]	Loss: 0.819524
[2022-06-10 17:57:30 | train] - Train Epoch: [110] [1190400/1281167 (93%)]	Loss: 0.703144
[2022-06-10 17:57:51 | train] - Train Epoch: [110] [1203200/1281167 (94%)]	Loss: 0.759287
[2022-06-10 17:58:12 | train] - Train Epoch: [110] [1216000/1281167 (95%)]	Loss: 0.642935
[2022-06-10 17:58:32 | train] - Train Epoch: [110] [1228800/1281167 (96%)]	Loss: 0.893847
[2022-06-10 17:58:52 | train] - Train Epoch: [110] [1241600/1281167 (97%)]	Loss: 0.787066
[2022-06-10 17:59:12 | train] - Train Epoch: [110] [1254400/1281167 (98%)]	Loss: 0.797951
[2022-06-10 17:59:32 | train] - Train Epoch: [110] [1267200/1281167 (99%)]	Loss: 1.021759
[2022-06-10 17:59:52 | train] - Train Epoch: [110] [1280000/1281167 (100%)]	Loss: 0.671572
[2022-06-10 17:59:54 | train] - Train Epoch: [110]	 Average Loss: 0.838733	 Total Acc : 79.4722	 Total Top5 Acc : 92.4899
[2022-06-10 17:59:54 | train] - -------110 epoch end-----------
========================================
-------110 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 18:01:28 | train] - 
Epoch [110] Test set: Average loss: 1.4057, Accuracy: 34759/50000 (69.4969%), Top-5 Accuracy: 88.7324%

[2022-06-10 18:01:28 | train] - save intermediate epoch [110] result


[2022-06-10 18:01:58 | train] - -------111 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 18:02:00 | train] - Train Epoch: [111] [0/1281167 (0%)]	Loss: 0.810862
[2022-06-10 18:02:20 | train] - Train Epoch: [111] [12800/1281167 (1%)]	Loss: 0.770020
[2022-06-10 18:02:40 | train] - Train Epoch: [111] [25600/1281167 (2%)]	Loss: 0.713728
[2022-06-10 18:03:00 | train] - Train Epoch: [111] [38400/1281167 (3%)]	Loss: 0.789738
[2022-06-10 18:03:21 | train] - Train Epoch: [111] [51200/1281167 (4%)]	Loss: 1.156551
[2022-06-10 18:03:41 | train] - Train Epoch: [111] [64000/1281167 (5%)]	Loss: 0.933404
[2022-06-10 18:04:02 | train] - Train Epoch: [111] [76800/1281167 (6%)]	Loss: 0.905662
[2022-06-10 18:04:24 | train] - Train Epoch: [111] [89600/1281167 (7%)]	Loss: 0.698104
[2022-06-10 18:04:44 | train] - Train Epoch: [111] [102400/1281167 (8%)]	Loss: 0.848138
[2022-06-10 18:05:05 | train] - Train Epoch: [111] [115200/1281167 (9%)]	Loss: 0.883969
[2022-06-10 18:05:26 | train] - Train Epoch: [111] [128000/1281167 (10%)]	Loss: 0.764063
[2022-06-10 18:05:46 | train] - Train Epoch: [111] [140800/1281167 (11%)]	Loss: 1.085191
[2022-06-10 18:06:07 | train] - Train Epoch: [111] [153600/1281167 (12%)]	Loss: 0.789510
[2022-06-10 18:06:27 | train] - Train Epoch: [111] [166400/1281167 (13%)]	Loss: 0.939968
[2022-06-10 18:06:47 | train] - Train Epoch: [111] [179200/1281167 (14%)]	Loss: 0.715307
[2022-06-10 18:07:08 | train] - Train Epoch: [111] [192000/1281167 (15%)]	Loss: 0.922873
[2022-06-10 18:07:28 | train] - Train Epoch: [111] [204800/1281167 (16%)]	Loss: 0.761829
[2022-06-10 18:07:49 | train] - Train Epoch: [111] [217600/1281167 (17%)]	Loss: 1.035358
[2022-06-10 18:08:10 | train] - Train Epoch: [111] [230400/1281167 (18%)]	Loss: 0.918358
[2022-06-10 18:08:31 | train] - Train Epoch: [111] [243200/1281167 (19%)]	Loss: 0.641291
[2022-06-10 18:08:51 | train] - Train Epoch: [111] [256000/1281167 (20%)]	Loss: 1.008321
[2022-06-10 18:09:12 | train] - Train Epoch: [111] [268800/1281167 (21%)]	Loss: 0.835968
[2022-06-10 18:09:32 | train] - Train Epoch: [111] [281600/1281167 (22%)]	Loss: 0.894061
[2022-06-10 18:09:52 | train] - Train Epoch: [111] [294400/1281167 (23%)]	Loss: 0.763253
[2022-06-10 18:10:12 | train] - Train Epoch: [111] [307200/1281167 (24%)]	Loss: 0.798849
[2022-06-10 18:10:33 | train] - Train Epoch: [111] [320000/1281167 (25%)]	Loss: 0.708404
[2022-06-10 18:10:53 | train] - Train Epoch: [111] [332800/1281167 (26%)]	Loss: 0.928714
[2022-06-10 18:11:13 | train] - Train Epoch: [111] [345600/1281167 (27%)]	Loss: 0.900988
[2022-06-10 18:11:34 | train] - Train Epoch: [111] [358400/1281167 (28%)]	Loss: 0.661128
[2022-06-10 18:11:54 | train] - Train Epoch: [111] [371200/1281167 (29%)]	Loss: 0.911133
[2022-06-10 18:12:15 | train] - Train Epoch: [111] [384000/1281167 (30%)]	Loss: 0.874667
[2022-06-10 18:12:36 | train] - Train Epoch: [111] [396800/1281167 (31%)]	Loss: 0.596241
[2022-06-10 18:12:56 | train] - Train Epoch: [111] [409600/1281167 (32%)]	Loss: 0.952313
[2022-06-10 18:13:16 | train] - Train Epoch: [111] [422400/1281167 (33%)]	Loss: 0.753542
[2022-06-10 18:13:37 | train] - Train Epoch: [111] [435200/1281167 (34%)]	Loss: 1.040435
[2022-06-10 18:13:57 | train] - Train Epoch: [111] [448000/1281167 (35%)]	Loss: 0.802442
[2022-06-10 18:14:18 | train] - Train Epoch: [111] [460800/1281167 (36%)]	Loss: 0.975073
[2022-06-10 18:14:38 | train] - Train Epoch: [111] [473600/1281167 (37%)]	Loss: 0.886564
[2022-06-10 18:14:58 | train] - Train Epoch: [111] [486400/1281167 (38%)]	Loss: 0.676122
[2022-06-10 18:15:19 | train] - Train Epoch: [111] [499200/1281167 (39%)]	Loss: 0.935583
[2022-06-10 18:15:40 | train] - Train Epoch: [111] [512000/1281167 (40%)]	Loss: 0.579011
[2022-06-10 18:16:01 | train] - Train Epoch: [111] [524800/1281167 (41%)]	Loss: 0.632563
[2022-06-10 18:16:21 | train] - Train Epoch: [111] [537600/1281167 (42%)]	Loss: 0.559229
[2022-06-10 18:16:42 | train] - Train Epoch: [111] [550400/1281167 (43%)]	Loss: 0.664667
[2022-06-10 18:17:03 | train] - Train Epoch: [111] [563200/1281167 (44%)]	Loss: 0.775230
[2022-06-10 18:17:23 | train] - Train Epoch: [111] [576000/1281167 (45%)]	Loss: 0.872060
[2022-06-10 18:17:44 | train] - Train Epoch: [111] [588800/1281167 (46%)]	Loss: 0.792082
[2022-06-10 18:18:05 | train] - Train Epoch: [111] [601600/1281167 (47%)]	Loss: 0.594790
[2022-06-10 18:18:26 | train] - Train Epoch: [111] [614400/1281167 (48%)]	Loss: 0.740830
[2022-06-10 18:18:45 | train] - Train Epoch: [111] [627200/1281167 (49%)]	Loss: 0.765148
[2022-06-10 18:19:06 | train] - Train Epoch: [111] [640000/1281167 (50%)]	Loss: 0.942007
[2022-06-10 18:19:27 | train] - Train Epoch: [111] [652800/1281167 (51%)]	Loss: 0.980877
[2022-06-10 18:19:47 | train] - Train Epoch: [111] [665600/1281167 (52%)]	Loss: 0.728350
[2022-06-10 18:20:07 | train] - Train Epoch: [111] [678400/1281167 (53%)]	Loss: 0.911123
[2022-06-10 18:20:27 | train] - Train Epoch: [111] [691200/1281167 (54%)]	Loss: 0.773807
[2022-06-10 18:20:47 | train] - Train Epoch: [111] [704000/1281167 (55%)]	Loss: 0.990135
[2022-06-10 18:21:07 | train] - Train Epoch: [111] [716800/1281167 (56%)]	Loss: 0.931618
[2022-06-10 18:21:27 | train] - Train Epoch: [111] [729600/1281167 (57%)]	Loss: 0.916173
[2022-06-10 18:21:48 | train] - Train Epoch: [111] [742400/1281167 (58%)]	Loss: 1.025880
[2022-06-10 18:22:08 | train] - Train Epoch: [111] [755200/1281167 (59%)]	Loss: 0.719788
[2022-06-10 18:22:29 | train] - Train Epoch: [111] [768000/1281167 (60%)]	Loss: 0.786674
[2022-06-10 18:22:49 | train] - Train Epoch: [111] [780800/1281167 (61%)]	Loss: 0.564762
[2022-06-10 18:23:09 | train] - Train Epoch: [111] [793600/1281167 (62%)]	Loss: 0.812816
[2022-06-10 18:23:30 | train] - Train Epoch: [111] [806400/1281167 (63%)]	Loss: 0.860349
[2022-06-10 18:23:50 | train] - Train Epoch: [111] [819200/1281167 (64%)]	Loss: 0.952900
[2022-06-10 18:24:11 | train] - Train Epoch: [111] [832000/1281167 (65%)]	Loss: 1.022266
[2022-06-10 18:24:31 | train] - Train Epoch: [111] [844800/1281167 (66%)]	Loss: 0.714047
[2022-06-10 18:24:52 | train] - Train Epoch: [111] [857600/1281167 (67%)]	Loss: 1.062852
[2022-06-10 18:25:12 | train] - Train Epoch: [111] [870400/1281167 (68%)]	Loss: 1.014758
[2022-06-10 18:25:33 | train] - Train Epoch: [111] [883200/1281167 (69%)]	Loss: 1.144184
[2022-06-10 18:25:53 | train] - Train Epoch: [111] [896000/1281167 (70%)]	Loss: 0.744296
[2022-06-10 18:26:14 | train] - Train Epoch: [111] [908800/1281167 (71%)]	Loss: 0.779105
[2022-06-10 18:26:34 | train] - Train Epoch: [111] [921600/1281167 (72%)]	Loss: 0.911321
[2022-06-10 18:26:55 | train] - Train Epoch: [111] [934400/1281167 (73%)]	Loss: 0.570167
[2022-06-10 18:27:15 | train] - Train Epoch: [111] [947200/1281167 (74%)]	Loss: 0.882832
[2022-06-10 18:27:35 | train] - Train Epoch: [111] [960000/1281167 (75%)]	Loss: 0.646348
[2022-06-10 18:27:55 | train] - Train Epoch: [111] [972800/1281167 (76%)]	Loss: 0.854418
[2022-06-10 18:28:16 | train] - Train Epoch: [111] [985600/1281167 (77%)]	Loss: 0.637946
[2022-06-10 18:28:36 | train] - Train Epoch: [111] [998400/1281167 (78%)]	Loss: 0.967663
[2022-06-10 18:28:56 | train] - Train Epoch: [111] [1011200/1281167 (79%)]	Loss: 0.903358
[2022-06-10 18:29:17 | train] - Train Epoch: [111] [1024000/1281167 (80%)]	Loss: 0.912190
[2022-06-10 18:29:38 | train] - Train Epoch: [111] [1036800/1281167 (81%)]	Loss: 0.955963
[2022-06-10 18:29:59 | train] - Train Epoch: [111] [1049600/1281167 (82%)]	Loss: 0.868361
[2022-06-10 18:30:19 | train] - Train Epoch: [111] [1062400/1281167 (83%)]	Loss: 0.892364
[2022-06-10 18:30:40 | train] - Train Epoch: [111] [1075200/1281167 (84%)]	Loss: 0.704159
[2022-06-10 18:31:00 | train] - Train Epoch: [111] [1088000/1281167 (85%)]	Loss: 0.883876
[2022-06-10 18:31:21 | train] - Train Epoch: [111] [1100800/1281167 (86%)]	Loss: 0.754616
[2022-06-10 18:31:41 | train] - Train Epoch: [111] [1113600/1281167 (87%)]	Loss: 0.962759
[2022-06-10 18:32:02 | train] - Train Epoch: [111] [1126400/1281167 (88%)]	Loss: 0.993234
[2022-06-10 18:32:22 | train] - Train Epoch: [111] [1139200/1281167 (89%)]	Loss: 0.725853
[2022-06-10 18:32:42 | train] - Train Epoch: [111] [1152000/1281167 (90%)]	Loss: 0.581012
[2022-06-10 18:33:02 | train] - Train Epoch: [111] [1164800/1281167 (91%)]	Loss: 0.806155
[2022-06-10 18:33:23 | train] - Train Epoch: [111] [1177600/1281167 (92%)]	Loss: 1.319125
[2022-06-10 18:33:44 | train] - Train Epoch: [111] [1190400/1281167 (93%)]	Loss: 0.628873
[2022-06-10 18:34:05 | train] - Train Epoch: [111] [1203200/1281167 (94%)]	Loss: 0.784970
[2022-06-10 18:34:25 | train] - Train Epoch: [111] [1216000/1281167 (95%)]	Loss: 0.946328
[2022-06-10 18:34:46 | train] - Train Epoch: [111] [1228800/1281167 (96%)]	Loss: 0.871017
[2022-06-10 18:35:07 | train] - Train Epoch: [111] [1241600/1281167 (97%)]	Loss: 0.945195
[2022-06-10 18:35:28 | train] - Train Epoch: [111] [1254400/1281167 (98%)]	Loss: 0.737278
[2022-06-10 18:35:49 | train] - Train Epoch: [111] [1267200/1281167 (99%)]	Loss: 0.774040
[2022-06-10 18:36:10 | train] - Train Epoch: [111] [1280000/1281167 (100%)]	Loss: 0.701953
[2022-06-10 18:36:12 | train] - Train Epoch: [111]	 Average Loss: 0.838248	 Total Acc : 79.4760	 Total Top5 Acc : 92.5181
[2022-06-10 18:36:12 | train] - -------111 epoch end-----------
========================================
-------111 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 18:37:44 | train] - 
Epoch [111] Test set: Average loss: 1.4163, Accuracy: 34750/50000 (69.4741%), Top-5 Accuracy: 88.7516%

[2022-06-10 18:37:44 | train] - save intermediate epoch [111] result


[2022-06-10 18:38:15 | train] - -------112 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 18:38:16 | train] - Train Epoch: [112] [0/1281167 (0%)]	Loss: 0.518869
[2022-06-10 18:38:37 | train] - Train Epoch: [112] [12800/1281167 (1%)]	Loss: 0.804063
[2022-06-10 18:38:57 | train] - Train Epoch: [112] [25600/1281167 (2%)]	Loss: 0.837226
[2022-06-10 18:39:17 | train] - Train Epoch: [112] [38400/1281167 (3%)]	Loss: 0.768359
[2022-06-10 18:39:37 | train] - Train Epoch: [112] [51200/1281167 (4%)]	Loss: 0.864111
[2022-06-10 18:39:58 | train] - Train Epoch: [112] [64000/1281167 (5%)]	Loss: 0.635145
[2022-06-10 18:40:18 | train] - Train Epoch: [112] [76800/1281167 (6%)]	Loss: 0.782575
[2022-06-10 18:40:38 | train] - Train Epoch: [112] [89600/1281167 (7%)]	Loss: 0.771194
[2022-06-10 18:40:59 | train] - Train Epoch: [112] [102400/1281167 (8%)]	Loss: 0.677167
[2022-06-10 18:41:19 | train] - Train Epoch: [112] [115200/1281167 (9%)]	Loss: 0.810510
[2022-06-10 18:41:40 | train] - Train Epoch: [112] [128000/1281167 (10%)]	Loss: 0.459815
[2022-06-10 18:42:01 | train] - Train Epoch: [112] [140800/1281167 (11%)]	Loss: 0.738106
[2022-06-10 18:42:22 | train] - Train Epoch: [112] [153600/1281167 (12%)]	Loss: 0.830574
[2022-06-10 18:42:42 | train] - Train Epoch: [112] [166400/1281167 (13%)]	Loss: 0.768426
[2022-06-10 18:43:02 | train] - Train Epoch: [112] [179200/1281167 (14%)]	Loss: 0.689648
[2022-06-10 18:43:21 | train] - Train Epoch: [112] [192000/1281167 (15%)]	Loss: 0.537733
[2022-06-10 18:43:41 | train] - Train Epoch: [112] [204800/1281167 (16%)]	Loss: 0.774987
[2022-06-10 18:44:01 | train] - Train Epoch: [112] [217600/1281167 (17%)]	Loss: 0.533904
[2022-06-10 18:44:21 | train] - Train Epoch: [112] [230400/1281167 (18%)]	Loss: 0.745020
[2022-06-10 18:44:40 | train] - Train Epoch: [112] [243200/1281167 (19%)]	Loss: 0.754384
[2022-06-10 18:45:00 | train] - Train Epoch: [112] [256000/1281167 (20%)]	Loss: 1.224316
[2022-06-10 18:45:20 | train] - Train Epoch: [112] [268800/1281167 (21%)]	Loss: 0.754744
[2022-06-10 18:45:40 | train] - Train Epoch: [112] [281600/1281167 (22%)]	Loss: 0.870185
[2022-06-10 18:46:00 | train] - Train Epoch: [112] [294400/1281167 (23%)]	Loss: 0.925695
[2022-06-10 18:46:19 | train] - Train Epoch: [112] [307200/1281167 (24%)]	Loss: 0.817178
[2022-06-10 18:46:39 | train] - Train Epoch: [112] [320000/1281167 (25%)]	Loss: 0.763255
[2022-06-10 18:46:58 | train] - Train Epoch: [112] [332800/1281167 (26%)]	Loss: 0.824105
[2022-06-10 18:47:18 | train] - Train Epoch: [112] [345600/1281167 (27%)]	Loss: 0.638827
[2022-06-10 18:47:38 | train] - Train Epoch: [112] [358400/1281167 (28%)]	Loss: 0.768754
[2022-06-10 18:47:58 | train] - Train Epoch: [112] [371200/1281167 (29%)]	Loss: 0.724342
[2022-06-10 18:48:18 | train] - Train Epoch: [112] [384000/1281167 (30%)]	Loss: 0.718166
[2022-06-10 18:48:38 | train] - Train Epoch: [112] [396800/1281167 (31%)]	Loss: 0.508792
[2022-06-10 18:48:58 | train] - Train Epoch: [112] [409600/1281167 (32%)]	Loss: 1.173430
[2022-06-10 18:49:18 | train] - Train Epoch: [112] [422400/1281167 (33%)]	Loss: 0.726112
[2022-06-10 18:49:38 | train] - Train Epoch: [112] [435200/1281167 (34%)]	Loss: 0.953246
[2022-06-10 18:49:58 | train] - Train Epoch: [112] [448000/1281167 (35%)]	Loss: 0.867757
[2022-06-10 18:50:18 | train] - Train Epoch: [112] [460800/1281167 (36%)]	Loss: 0.865003
[2022-06-10 18:50:37 | train] - Train Epoch: [112] [473600/1281167 (37%)]	Loss: 0.876267
[2022-06-10 18:50:57 | train] - Train Epoch: [112] [486400/1281167 (38%)]	Loss: 0.928377
[2022-06-10 18:51:16 | train] - Train Epoch: [112] [499200/1281167 (39%)]	Loss: 0.876557
[2022-06-10 18:51:36 | train] - Train Epoch: [112] [512000/1281167 (40%)]	Loss: 1.056995
[2022-06-10 18:51:55 | train] - Train Epoch: [112] [524800/1281167 (41%)]	Loss: 0.617380
[2022-06-10 18:52:15 | train] - Train Epoch: [112] [537600/1281167 (42%)]	Loss: 0.587814
[2022-06-10 18:52:35 | train] - Train Epoch: [112] [550400/1281167 (43%)]	Loss: 0.663435
[2022-06-10 18:52:54 | train] - Train Epoch: [112] [563200/1281167 (44%)]	Loss: 0.740860
[2022-06-10 18:53:14 | train] - Train Epoch: [112] [576000/1281167 (45%)]	Loss: 1.102957
[2022-06-10 18:53:34 | train] - Train Epoch: [112] [588800/1281167 (46%)]	Loss: 0.820338
[2022-06-10 18:53:54 | train] - Train Epoch: [112] [601600/1281167 (47%)]	Loss: 0.857126
[2022-06-10 18:54:13 | train] - Train Epoch: [112] [614400/1281167 (48%)]	Loss: 1.012834
[2022-06-10 18:54:33 | train] - Train Epoch: [112] [627200/1281167 (49%)]	Loss: 0.962689
[2022-06-10 18:54:52 | train] - Train Epoch: [112] [640000/1281167 (50%)]	Loss: 0.746297
[2022-06-10 18:55:12 | train] - Train Epoch: [112] [652800/1281167 (51%)]	Loss: 1.017521
[2022-06-10 18:55:32 | train] - Train Epoch: [112] [665600/1281167 (52%)]	Loss: 0.611319
[2022-06-10 18:55:52 | train] - Train Epoch: [112] [678400/1281167 (53%)]	Loss: 0.759239
[2022-06-10 18:56:11 | train] - Train Epoch: [112] [691200/1281167 (54%)]	Loss: 0.813661
[2022-06-10 18:56:31 | train] - Train Epoch: [112] [704000/1281167 (55%)]	Loss: 1.139986
[2022-06-10 18:56:50 | train] - Train Epoch: [112] [716800/1281167 (56%)]	Loss: 1.111125
[2022-06-10 18:57:09 | train] - Train Epoch: [112] [729600/1281167 (57%)]	Loss: 0.925245
[2022-06-10 18:57:29 | train] - Train Epoch: [112] [742400/1281167 (58%)]	Loss: 0.904076
[2022-06-10 18:57:49 | train] - Train Epoch: [112] [755200/1281167 (59%)]	Loss: 0.954924
[2022-06-10 18:58:08 | train] - Train Epoch: [112] [768000/1281167 (60%)]	Loss: 0.829005
[2022-06-10 18:58:28 | train] - Train Epoch: [112] [780800/1281167 (61%)]	Loss: 0.692749
[2022-06-10 18:58:48 | train] - Train Epoch: [112] [793600/1281167 (62%)]	Loss: 0.930566
[2022-06-10 18:59:08 | train] - Train Epoch: [112] [806400/1281167 (63%)]	Loss: 1.055405
[2022-06-10 18:59:28 | train] - Train Epoch: [112] [819200/1281167 (64%)]	Loss: 1.012391
[2022-06-10 18:59:48 | train] - Train Epoch: [112] [832000/1281167 (65%)]	Loss: 0.996296
[2022-06-10 19:00:07 | train] - Train Epoch: [112] [844800/1281167 (66%)]	Loss: 0.751097
[2022-06-10 19:00:27 | train] - Train Epoch: [112] [857600/1281167 (67%)]	Loss: 0.992542
[2022-06-10 19:00:46 | train] - Train Epoch: [112] [870400/1281167 (68%)]	Loss: 0.787470
[2022-06-10 19:01:06 | train] - Train Epoch: [112] [883200/1281167 (69%)]	Loss: 0.734555
[2022-06-10 19:01:26 | train] - Train Epoch: [112] [896000/1281167 (70%)]	Loss: 0.970225
[2022-06-10 19:01:45 | train] - Train Epoch: [112] [908800/1281167 (71%)]	Loss: 0.775918
[2022-06-10 19:02:05 | train] - Train Epoch: [112] [921600/1281167 (72%)]	Loss: 0.803747
[2022-06-10 19:02:25 | train] - Train Epoch: [112] [934400/1281167 (73%)]	Loss: 0.596359
[2022-06-10 19:02:45 | train] - Train Epoch: [112] [947200/1281167 (74%)]	Loss: 0.854403
[2022-06-10 19:03:05 | train] - Train Epoch: [112] [960000/1281167 (75%)]	Loss: 1.176572
[2022-06-10 19:03:25 | train] - Train Epoch: [112] [972800/1281167 (76%)]	Loss: 0.695710
[2022-06-10 19:03:46 | train] - Train Epoch: [112] [985600/1281167 (77%)]	Loss: 0.889592
[2022-06-10 19:04:06 | train] - Train Epoch: [112] [998400/1281167 (78%)]	Loss: 0.789542
[2022-06-10 19:04:25 | train] - Train Epoch: [112] [1011200/1281167 (79%)]	Loss: 0.591956
[2022-06-10 19:04:45 | train] - Train Epoch: [112] [1024000/1281167 (80%)]	Loss: 0.689022
[2022-06-10 19:05:05 | train] - Train Epoch: [112] [1036800/1281167 (81%)]	Loss: 0.792108
[2022-06-10 19:05:25 | train] - Train Epoch: [112] [1049600/1281167 (82%)]	Loss: 0.805942
[2022-06-10 19:05:45 | train] - Train Epoch: [112] [1062400/1281167 (83%)]	Loss: 0.676578
[2022-06-10 19:06:05 | train] - Train Epoch: [112] [1075200/1281167 (84%)]	Loss: 0.747111
[2022-06-10 19:06:24 | train] - Train Epoch: [112] [1088000/1281167 (85%)]	Loss: 0.877879
[2022-06-10 19:06:44 | train] - Train Epoch: [112] [1100800/1281167 (86%)]	Loss: 0.790960
[2022-06-10 19:07:04 | train] - Train Epoch: [112] [1113600/1281167 (87%)]	Loss: 0.749278
[2022-06-10 19:07:23 | train] - Train Epoch: [112] [1126400/1281167 (88%)]	Loss: 0.836371
[2022-06-10 19:07:43 | train] - Train Epoch: [112] [1139200/1281167 (89%)]	Loss: 0.806407
[2022-06-10 19:08:03 | train] - Train Epoch: [112] [1152000/1281167 (90%)]	Loss: 1.110484
[2022-06-10 19:08:22 | train] - Train Epoch: [112] [1164800/1281167 (91%)]	Loss: 0.904117
[2022-06-10 19:08:42 | train] - Train Epoch: [112] [1177600/1281167 (92%)]	Loss: 0.809276
[2022-06-10 19:09:02 | train] - Train Epoch: [112] [1190400/1281167 (93%)]	Loss: 0.875979
[2022-06-10 19:09:22 | train] - Train Epoch: [112] [1203200/1281167 (94%)]	Loss: 0.930589
[2022-06-10 19:09:42 | train] - Train Epoch: [112] [1216000/1281167 (95%)]	Loss: 0.915846
[2022-06-10 19:10:01 | train] - Train Epoch: [112] [1228800/1281167 (96%)]	Loss: 0.783940
[2022-06-10 19:10:21 | train] - Train Epoch: [112] [1241600/1281167 (97%)]	Loss: 0.843629
[2022-06-10 19:10:41 | train] - Train Epoch: [112] [1254400/1281167 (98%)]	Loss: 0.823467
[2022-06-10 19:11:00 | train] - Train Epoch: [112] [1267200/1281167 (99%)]	Loss: 0.993590
[2022-06-10 19:11:20 | train] - Train Epoch: [112] [1280000/1281167 (100%)]	Loss: 0.781389
[2022-06-10 19:11:22 | train] - Train Epoch: [112]	 Average Loss: 0.834186	 Total Acc : 79.5720	 Total Top5 Acc : 92.5271
[2022-06-10 19:11:22 | train] - -------112 epoch end-----------
========================================
-------112 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 19:12:55 | train] - 
Epoch [112] Test set: Average loss: 1.4198, Accuracy: 34836/50000 (69.6351%), Top-5 Accuracy: 88.7560%

[2022-06-10 19:12:55 | train] - save intermediate epoch [112] result


[2022-06-10 19:13:29 | train] - -------113 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 19:13:31 | train] - Train Epoch: [113] [0/1281167 (0%)]	Loss: 1.173514
[2022-06-10 19:13:51 | train] - Train Epoch: [113] [12800/1281167 (1%)]	Loss: 0.778633
[2022-06-10 19:14:11 | train] - Train Epoch: [113] [25600/1281167 (2%)]	Loss: 0.790331
[2022-06-10 19:14:31 | train] - Train Epoch: [113] [38400/1281167 (3%)]	Loss: 0.842815
[2022-06-10 19:14:51 | train] - Train Epoch: [113] [51200/1281167 (4%)]	Loss: 0.824810
[2022-06-10 19:15:12 | train] - Train Epoch: [113] [64000/1281167 (5%)]	Loss: 0.845228
[2022-06-10 19:15:32 | train] - Train Epoch: [113] [76800/1281167 (6%)]	Loss: 0.918253
[2022-06-10 19:15:52 | train] - Train Epoch: [113] [89600/1281167 (7%)]	Loss: 0.850127
[2022-06-10 19:16:12 | train] - Train Epoch: [113] [102400/1281167 (8%)]	Loss: 0.718864
[2022-06-10 19:16:31 | train] - Train Epoch: [113] [115200/1281167 (9%)]	Loss: 0.734151
[2022-06-10 19:16:50 | train] - Train Epoch: [113] [128000/1281167 (10%)]	Loss: 0.724889
[2022-06-10 19:17:10 | train] - Train Epoch: [113] [140800/1281167 (11%)]	Loss: 0.750383
[2022-06-10 19:17:30 | train] - Train Epoch: [113] [153600/1281167 (12%)]	Loss: 0.531721
[2022-06-10 19:17:49 | train] - Train Epoch: [113] [166400/1281167 (13%)]	Loss: 0.737396
[2022-06-10 19:18:10 | train] - Train Epoch: [113] [179200/1281167 (14%)]	Loss: 0.937114
[2022-06-10 19:18:29 | train] - Train Epoch: [113] [192000/1281167 (15%)]	Loss: 0.835946
[2022-06-10 19:18:49 | train] - Train Epoch: [113] [204800/1281167 (16%)]	Loss: 0.633826
[2022-06-10 19:19:08 | train] - Train Epoch: [113] [217600/1281167 (17%)]	Loss: 0.566467
[2022-06-10 19:19:28 | train] - Train Epoch: [113] [230400/1281167 (18%)]	Loss: 0.749899
[2022-06-10 19:19:48 | train] - Train Epoch: [113] [243200/1281167 (19%)]	Loss: 0.851685
[2022-06-10 19:20:08 | train] - Train Epoch: [113] [256000/1281167 (20%)]	Loss: 0.685391
[2022-06-10 19:20:28 | train] - Train Epoch: [113] [268800/1281167 (21%)]	Loss: 0.885325
[2022-06-10 19:20:48 | train] - Train Epoch: [113] [281600/1281167 (22%)]	Loss: 1.023562
[2022-06-10 19:21:07 | train] - Train Epoch: [113] [294400/1281167 (23%)]	Loss: 0.960704
[2022-06-10 19:21:28 | train] - Train Epoch: [113] [307200/1281167 (24%)]	Loss: 0.840603
[2022-06-10 19:21:47 | train] - Train Epoch: [113] [320000/1281167 (25%)]	Loss: 0.688396
[2022-06-10 19:22:07 | train] - Train Epoch: [113] [332800/1281167 (26%)]	Loss: 0.990604
[2022-06-10 19:22:27 | train] - Train Epoch: [113] [345600/1281167 (27%)]	Loss: 0.748466
[2022-06-10 19:22:47 | train] - Train Epoch: [113] [358400/1281167 (28%)]	Loss: 0.897110
[2022-06-10 19:23:07 | train] - Train Epoch: [113] [371200/1281167 (29%)]	Loss: 0.777326
[2022-06-10 19:23:27 | train] - Train Epoch: [113] [384000/1281167 (30%)]	Loss: 0.812518
[2022-06-10 19:23:47 | train] - Train Epoch: [113] [396800/1281167 (31%)]	Loss: 0.828456
[2022-06-10 19:24:07 | train] - Train Epoch: [113] [409600/1281167 (32%)]	Loss: 0.944342
[2022-06-10 19:24:26 | train] - Train Epoch: [113] [422400/1281167 (33%)]	Loss: 0.700846
[2022-06-10 19:24:46 | train] - Train Epoch: [113] [435200/1281167 (34%)]	Loss: 0.671986
[2022-06-10 19:25:05 | train] - Train Epoch: [113] [448000/1281167 (35%)]	Loss: 0.692844
[2022-06-10 19:25:26 | train] - Train Epoch: [113] [460800/1281167 (36%)]	Loss: 1.082529
[2022-06-10 19:25:46 | train] - Train Epoch: [113] [473600/1281167 (37%)]	Loss: 0.921757
[2022-06-10 19:26:05 | train] - Train Epoch: [113] [486400/1281167 (38%)]	Loss: 0.514072
[2022-06-10 19:26:25 | train] - Train Epoch: [113] [499200/1281167 (39%)]	Loss: 0.877581
[2022-06-10 19:26:45 | train] - Train Epoch: [113] [512000/1281167 (40%)]	Loss: 0.792413
[2022-06-10 19:27:05 | train] - Train Epoch: [113] [524800/1281167 (41%)]	Loss: 0.716463
[2022-06-10 19:27:26 | train] - Train Epoch: [113] [537600/1281167 (42%)]	Loss: 0.977635
[2022-06-10 19:27:46 | train] - Train Epoch: [113] [550400/1281167 (43%)]	Loss: 0.602274
[2022-06-10 19:28:05 | train] - Train Epoch: [113] [563200/1281167 (44%)]	Loss: 0.770793
[2022-06-10 19:28:24 | train] - Train Epoch: [113] [576000/1281167 (45%)]	Loss: 0.600399
[2022-06-10 19:28:45 | train] - Train Epoch: [113] [588800/1281167 (46%)]	Loss: 0.878448
[2022-06-10 19:29:04 | train] - Train Epoch: [113] [601600/1281167 (47%)]	Loss: 0.815432
[2022-06-10 19:29:24 | train] - Train Epoch: [113] [614400/1281167 (48%)]	Loss: 0.818155
[2022-06-10 19:29:44 | train] - Train Epoch: [113] [627200/1281167 (49%)]	Loss: 0.947727
[2022-06-10 19:30:03 | train] - Train Epoch: [113] [640000/1281167 (50%)]	Loss: 0.778980
[2022-06-10 19:30:23 | train] - Train Epoch: [113] [652800/1281167 (51%)]	Loss: 0.898968
[2022-06-10 19:30:43 | train] - Train Epoch: [113] [665600/1281167 (52%)]	Loss: 0.958088
[2022-06-10 19:31:02 | train] - Train Epoch: [113] [678400/1281167 (53%)]	Loss: 0.906064
[2022-06-10 19:31:24 | train] - Train Epoch: [113] [691200/1281167 (54%)]	Loss: 0.760453
[2022-06-10 19:31:44 | train] - Train Epoch: [113] [704000/1281167 (55%)]	Loss: 0.709272
[2022-06-10 19:32:05 | train] - Train Epoch: [113] [716800/1281167 (56%)]	Loss: 0.925641
[2022-06-10 19:32:25 | train] - Train Epoch: [113] [729600/1281167 (57%)]	Loss: 0.904970
[2022-06-10 19:32:45 | train] - Train Epoch: [113] [742400/1281167 (58%)]	Loss: 1.008574
[2022-06-10 19:33:06 | train] - Train Epoch: [113] [755200/1281167 (59%)]	Loss: 0.745563
[2022-06-10 19:33:27 | train] - Train Epoch: [113] [768000/1281167 (60%)]	Loss: 0.750621
[2022-06-10 19:33:47 | train] - Train Epoch: [113] [780800/1281167 (61%)]	Loss: 1.035682
[2022-06-10 19:34:07 | train] - Train Epoch: [113] [793600/1281167 (62%)]	Loss: 0.798780
[2022-06-10 19:34:28 | train] - Train Epoch: [113] [806400/1281167 (63%)]	Loss: 0.711361
[2022-06-10 19:34:49 | train] - Train Epoch: [113] [819200/1281167 (64%)]	Loss: 0.905949
[2022-06-10 19:35:09 | train] - Train Epoch: [113] [832000/1281167 (65%)]	Loss: 0.739200
[2022-06-10 19:35:30 | train] - Train Epoch: [113] [844800/1281167 (66%)]	Loss: 0.798142
[2022-06-10 19:35:50 | train] - Train Epoch: [113] [857600/1281167 (67%)]	Loss: 0.656104
[2022-06-10 19:36:10 | train] - Train Epoch: [113] [870400/1281167 (68%)]	Loss: 0.827654
[2022-06-10 19:36:30 | train] - Train Epoch: [113] [883200/1281167 (69%)]	Loss: 0.696959
[2022-06-10 19:36:51 | train] - Train Epoch: [113] [896000/1281167 (70%)]	Loss: 0.932948
[2022-06-10 19:37:11 | train] - Train Epoch: [113] [908800/1281167 (71%)]	Loss: 0.954334
[2022-06-10 19:37:31 | train] - Train Epoch: [113] [921600/1281167 (72%)]	Loss: 0.734908
[2022-06-10 19:37:51 | train] - Train Epoch: [113] [934400/1281167 (73%)]	Loss: 0.759409
[2022-06-10 19:38:11 | train] - Train Epoch: [113] [947200/1281167 (74%)]	Loss: 0.778199
[2022-06-10 19:38:32 | train] - Train Epoch: [113] [960000/1281167 (75%)]	Loss: 0.774609
[2022-06-10 19:38:52 | train] - Train Epoch: [113] [972800/1281167 (76%)]	Loss: 0.725386
[2022-06-10 19:39:13 | train] - Train Epoch: [113] [985600/1281167 (77%)]	Loss: 0.682583
[2022-06-10 19:39:33 | train] - Train Epoch: [113] [998400/1281167 (78%)]	Loss: 0.612712
[2022-06-10 19:39:54 | train] - Train Epoch: [113] [1011200/1281167 (79%)]	Loss: 0.879916
[2022-06-10 19:40:14 | train] - Train Epoch: [113] [1024000/1281167 (80%)]	Loss: 0.991390
[2022-06-10 19:40:35 | train] - Train Epoch: [113] [1036800/1281167 (81%)]	Loss: 1.017873
[2022-06-10 19:40:55 | train] - Train Epoch: [113] [1049600/1281167 (82%)]	Loss: 1.050813
[2022-06-10 19:41:16 | train] - Train Epoch: [113] [1062400/1281167 (83%)]	Loss: 0.864514
[2022-06-10 19:41:36 | train] - Train Epoch: [113] [1075200/1281167 (84%)]	Loss: 0.947832
[2022-06-10 19:41:57 | train] - Train Epoch: [113] [1088000/1281167 (85%)]	Loss: 0.822412
[2022-06-10 19:42:17 | train] - Train Epoch: [113] [1100800/1281167 (86%)]	Loss: 0.980453
[2022-06-10 19:42:37 | train] - Train Epoch: [113] [1113600/1281167 (87%)]	Loss: 0.892075
[2022-06-10 19:42:57 | train] - Train Epoch: [113] [1126400/1281167 (88%)]	Loss: 0.935419
[2022-06-10 19:43:18 | train] - Train Epoch: [113] [1139200/1281167 (89%)]	Loss: 0.752129
[2022-06-10 19:43:38 | train] - Train Epoch: [113] [1152000/1281167 (90%)]	Loss: 0.844877
[2022-06-10 19:43:59 | train] - Train Epoch: [113] [1164800/1281167 (91%)]	Loss: 0.760830
[2022-06-10 19:44:20 | train] - Train Epoch: [113] [1177600/1281167 (92%)]	Loss: 1.073764
[2022-06-10 19:44:40 | train] - Train Epoch: [113] [1190400/1281167 (93%)]	Loss: 0.709513
[2022-06-10 19:45:00 | train] - Train Epoch: [113] [1203200/1281167 (94%)]	Loss: 0.772986
[2022-06-10 19:45:21 | train] - Train Epoch: [113] [1216000/1281167 (95%)]	Loss: 0.853218
[2022-06-10 19:45:42 | train] - Train Epoch: [113] [1228800/1281167 (96%)]	Loss: 0.714448
[2022-06-10 19:46:03 | train] - Train Epoch: [113] [1241600/1281167 (97%)]	Loss: 0.861617
[2022-06-10 19:46:23 | train] - Train Epoch: [113] [1254400/1281167 (98%)]	Loss: 0.912342
[2022-06-10 19:46:43 | train] - Train Epoch: [113] [1267200/1281167 (99%)]	Loss: 0.642542
[2022-06-10 19:47:03 | train] - Train Epoch: [113] [1280000/1281167 (100%)]	Loss: 0.979940
[2022-06-10 19:47:04 | train] - Train Epoch: [113]	 Average Loss: 0.834834	 Total Acc : 79.5471	 Total Top5 Acc : 92.5581
[2022-06-10 19:47:04 | train] - -------113 epoch end-----------
========================================
-------113 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 19:48:38 | train] - 
Epoch [113] Test set: Average loss: 1.4105, Accuracy: 34849/50000 (69.6659%), Top-5 Accuracy: 88.7720%

[2022-06-10 19:48:38 | train] - save intermediate epoch [113] result


[2022-06-10 19:49:09 | train] - -------114 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 19:49:11 | train] - Train Epoch: [114] [0/1281167 (0%)]	Loss: 0.776211
[2022-06-10 19:49:32 | train] - Train Epoch: [114] [12800/1281167 (1%)]	Loss: 0.845137
[2022-06-10 19:49:53 | train] - Train Epoch: [114] [25600/1281167 (2%)]	Loss: 0.922616
[2022-06-10 19:50:15 | train] - Train Epoch: [114] [38400/1281167 (3%)]	Loss: 0.830266
[2022-06-10 19:50:36 | train] - Train Epoch: [114] [51200/1281167 (4%)]	Loss: 0.885416
[2022-06-10 19:50:58 | train] - Train Epoch: [114] [64000/1281167 (5%)]	Loss: 0.773574
[2022-06-10 19:51:18 | train] - Train Epoch: [114] [76800/1281167 (6%)]	Loss: 1.014200
[2022-06-10 19:51:39 | train] - Train Epoch: [114] [89600/1281167 (7%)]	Loss: 0.866773
[2022-06-10 19:52:00 | train] - Train Epoch: [114] [102400/1281167 (8%)]	Loss: 0.700929
[2022-06-10 19:52:21 | train] - Train Epoch: [114] [115200/1281167 (9%)]	Loss: 0.749028
[2022-06-10 19:52:44 | train] - Train Epoch: [114] [128000/1281167 (10%)]	Loss: 0.698432
[2022-06-10 19:53:05 | train] - Train Epoch: [114] [140800/1281167 (11%)]	Loss: 0.910582
[2022-06-10 19:53:26 | train] - Train Epoch: [114] [153600/1281167 (12%)]	Loss: 0.882883
[2022-06-10 19:53:48 | train] - Train Epoch: [114] [166400/1281167 (13%)]	Loss: 0.741538
[2022-06-10 19:54:08 | train] - Train Epoch: [114] [179200/1281167 (14%)]	Loss: 1.080017
[2022-06-10 19:54:30 | train] - Train Epoch: [114] [192000/1281167 (15%)]	Loss: 0.667415
[2022-06-10 19:54:51 | train] - Train Epoch: [114] [204800/1281167 (16%)]	Loss: 0.991154
[2022-06-10 19:55:13 | train] - Train Epoch: [114] [217600/1281167 (17%)]	Loss: 0.866272
[2022-06-10 19:55:34 | train] - Train Epoch: [114] [230400/1281167 (18%)]	Loss: 0.721206
[2022-06-10 19:55:55 | train] - Train Epoch: [114] [243200/1281167 (19%)]	Loss: 0.640748
[2022-06-10 19:56:17 | train] - Train Epoch: [114] [256000/1281167 (20%)]	Loss: 0.828219
[2022-06-10 19:56:38 | train] - Train Epoch: [114] [268800/1281167 (21%)]	Loss: 1.006323
[2022-06-10 19:57:00 | train] - Train Epoch: [114] [281600/1281167 (22%)]	Loss: 0.889813
[2022-06-10 19:57:21 | train] - Train Epoch: [114] [294400/1281167 (23%)]	Loss: 0.995815
[2022-06-10 19:57:42 | train] - Train Epoch: [114] [307200/1281167 (24%)]	Loss: 0.863506
[2022-06-10 19:58:02 | train] - Train Epoch: [114] [320000/1281167 (25%)]	Loss: 0.772706
[2022-06-10 19:58:24 | train] - Train Epoch: [114] [332800/1281167 (26%)]	Loss: 0.866481
[2022-06-10 19:58:46 | train] - Train Epoch: [114] [345600/1281167 (27%)]	Loss: 0.773305
[2022-06-10 19:59:07 | train] - Train Epoch: [114] [358400/1281167 (28%)]	Loss: 0.801544
[2022-06-10 19:59:27 | train] - Train Epoch: [114] [371200/1281167 (29%)]	Loss: 0.716084
[2022-06-10 19:59:48 | train] - Train Epoch: [114] [384000/1281167 (30%)]	Loss: 0.880964
[2022-06-10 20:00:08 | train] - Train Epoch: [114] [396800/1281167 (31%)]	Loss: 0.808326
[2022-06-10 20:00:30 | train] - Train Epoch: [114] [409600/1281167 (32%)]	Loss: 0.771275
[2022-06-10 20:00:52 | train] - Train Epoch: [114] [422400/1281167 (33%)]	Loss: 0.816689
[2022-06-10 20:01:12 | train] - Train Epoch: [114] [435200/1281167 (34%)]	Loss: 1.086348
[2022-06-10 20:01:34 | train] - Train Epoch: [114] [448000/1281167 (35%)]	Loss: 0.741355
[2022-06-10 20:01:56 | train] - Train Epoch: [114] [460800/1281167 (36%)]	Loss: 0.678247
[2022-06-10 20:02:17 | train] - Train Epoch: [114] [473600/1281167 (37%)]	Loss: 0.777538
[2022-06-10 20:02:38 | train] - Train Epoch: [114] [486400/1281167 (38%)]	Loss: 0.980495
[2022-06-10 20:02:58 | train] - Train Epoch: [114] [499200/1281167 (39%)]	Loss: 0.823511
[2022-06-10 20:03:19 | train] - Train Epoch: [114] [512000/1281167 (40%)]	Loss: 0.721845
[2022-06-10 20:03:40 | train] - Train Epoch: [114] [524800/1281167 (41%)]	Loss: 0.767550
[2022-06-10 20:04:01 | train] - Train Epoch: [114] [537600/1281167 (42%)]	Loss: 0.795559
[2022-06-10 20:04:21 | train] - Train Epoch: [114] [550400/1281167 (43%)]	Loss: 0.868892
[2022-06-10 20:04:42 | train] - Train Epoch: [114] [563200/1281167 (44%)]	Loss: 0.953333
[2022-06-10 20:05:03 | train] - Train Epoch: [114] [576000/1281167 (45%)]	Loss: 0.806687
[2022-06-10 20:05:25 | train] - Train Epoch: [114] [588800/1281167 (46%)]	Loss: 0.687249
[2022-06-10 20:05:46 | train] - Train Epoch: [114] [601600/1281167 (47%)]	Loss: 0.913167
[2022-06-10 20:06:06 | train] - Train Epoch: [114] [614400/1281167 (48%)]	Loss: 0.754246
[2022-06-10 20:06:27 | train] - Train Epoch: [114] [627200/1281167 (49%)]	Loss: 0.933118
[2022-06-10 20:06:49 | train] - Train Epoch: [114] [640000/1281167 (50%)]	Loss: 0.570603
[2022-06-10 20:07:09 | train] - Train Epoch: [114] [652800/1281167 (51%)]	Loss: 0.849142
[2022-06-10 20:07:30 | train] - Train Epoch: [114] [665600/1281167 (52%)]	Loss: 1.077670
[2022-06-10 20:07:50 | train] - Train Epoch: [114] [678400/1281167 (53%)]	Loss: 0.741391
[2022-06-10 20:08:12 | train] - Train Epoch: [114] [691200/1281167 (54%)]	Loss: 1.000157
[2022-06-10 20:08:34 | train] - Train Epoch: [114] [704000/1281167 (55%)]	Loss: 1.066090
[2022-06-10 20:08:55 | train] - Train Epoch: [114] [716800/1281167 (56%)]	Loss: 0.864692
[2022-06-10 20:09:17 | train] - Train Epoch: [114] [729600/1281167 (57%)]	Loss: 0.988240
[2022-06-10 20:09:38 | train] - Train Epoch: [114] [742400/1281167 (58%)]	Loss: 0.758921
[2022-06-10 20:10:00 | train] - Train Epoch: [114] [755200/1281167 (59%)]	Loss: 0.969881
[2022-06-10 20:10:21 | train] - Train Epoch: [114] [768000/1281167 (60%)]	Loss: 0.818348
[2022-06-10 20:10:43 | train] - Train Epoch: [114] [780800/1281167 (61%)]	Loss: 0.894674
[2022-06-10 20:11:05 | train] - Train Epoch: [114] [793600/1281167 (62%)]	Loss: 1.002730
[2022-06-10 20:11:26 | train] - Train Epoch: [114] [806400/1281167 (63%)]	Loss: 0.662880
[2022-06-10 20:11:47 | train] - Train Epoch: [114] [819200/1281167 (64%)]	Loss: 0.894408
[2022-06-10 20:12:08 | train] - Train Epoch: [114] [832000/1281167 (65%)]	Loss: 0.641149
[2022-06-10 20:12:29 | train] - Train Epoch: [114] [844800/1281167 (66%)]	Loss: 0.702466
[2022-06-10 20:12:49 | train] - Train Epoch: [114] [857600/1281167 (67%)]	Loss: 0.914129
[2022-06-10 20:13:10 | train] - Train Epoch: [114] [870400/1281167 (68%)]	Loss: 0.764139
[2022-06-10 20:13:31 | train] - Train Epoch: [114] [883200/1281167 (69%)]	Loss: 0.894525
[2022-06-10 20:13:52 | train] - Train Epoch: [114] [896000/1281167 (70%)]	Loss: 0.980041
[2022-06-10 20:14:13 | train] - Train Epoch: [114] [908800/1281167 (71%)]	Loss: 0.834548
[2022-06-10 20:14:34 | train] - Train Epoch: [114] [921600/1281167 (72%)]	Loss: 0.596119
[2022-06-10 20:14:54 | train] - Train Epoch: [114] [934400/1281167 (73%)]	Loss: 0.812082
[2022-06-10 20:15:14 | train] - Train Epoch: [114] [947200/1281167 (74%)]	Loss: 0.703438
[2022-06-10 20:15:34 | train] - Train Epoch: [114] [960000/1281167 (75%)]	Loss: 0.980868
[2022-06-10 20:15:55 | train] - Train Epoch: [114] [972800/1281167 (76%)]	Loss: 0.738200
[2022-06-10 20:16:16 | train] - Train Epoch: [114] [985600/1281167 (77%)]	Loss: 0.801344
[2022-06-10 20:16:37 | train] - Train Epoch: [114] [998400/1281167 (78%)]	Loss: 0.908180
[2022-06-10 20:16:58 | train] - Train Epoch: [114] [1011200/1281167 (79%)]	Loss: 0.631222
[2022-06-10 20:17:19 | train] - Train Epoch: [114] [1024000/1281167 (80%)]	Loss: 0.873054
[2022-06-10 20:17:39 | train] - Train Epoch: [114] [1036800/1281167 (81%)]	Loss: 1.306818
[2022-06-10 20:18:00 | train] - Train Epoch: [114] [1049600/1281167 (82%)]	Loss: 0.627712
[2022-06-10 20:18:22 | train] - Train Epoch: [114] [1062400/1281167 (83%)]	Loss: 0.760778
[2022-06-10 20:18:43 | train] - Train Epoch: [114] [1075200/1281167 (84%)]	Loss: 0.815328
[2022-06-10 20:19:04 | train] - Train Epoch: [114] [1088000/1281167 (85%)]	Loss: 0.934907
[2022-06-10 20:19:25 | train] - Train Epoch: [114] [1100800/1281167 (86%)]	Loss: 0.901365
[2022-06-10 20:19:46 | train] - Train Epoch: [114] [1113600/1281167 (87%)]	Loss: 0.755331
[2022-06-10 20:20:08 | train] - Train Epoch: [114] [1126400/1281167 (88%)]	Loss: 0.824518
[2022-06-10 20:20:29 | train] - Train Epoch: [114] [1139200/1281167 (89%)]	Loss: 0.813927
[2022-06-10 20:20:51 | train] - Train Epoch: [114] [1152000/1281167 (90%)]	Loss: 1.215975
[2022-06-10 20:21:12 | train] - Train Epoch: [114] [1164800/1281167 (91%)]	Loss: 0.482450
[2022-06-10 20:21:33 | train] - Train Epoch: [114] [1177600/1281167 (92%)]	Loss: 0.822086
[2022-06-10 20:21:53 | train] - Train Epoch: [114] [1190400/1281167 (93%)]	Loss: 0.913499
[2022-06-10 20:22:13 | train] - Train Epoch: [114] [1203200/1281167 (94%)]	Loss: 0.801216
[2022-06-10 20:22:35 | train] - Train Epoch: [114] [1216000/1281167 (95%)]	Loss: 0.735788
[2022-06-10 20:22:56 | train] - Train Epoch: [114] [1228800/1281167 (96%)]	Loss: 0.703556
[2022-06-10 20:23:17 | train] - Train Epoch: [114] [1241600/1281167 (97%)]	Loss: 0.723717
[2022-06-10 20:23:37 | train] - Train Epoch: [114] [1254400/1281167 (98%)]	Loss: 0.870573
[2022-06-10 20:23:58 | train] - Train Epoch: [114] [1267200/1281167 (99%)]	Loss: 0.911901
[2022-06-10 20:24:19 | train] - Train Epoch: [114] [1280000/1281167 (100%)]	Loss: 0.715374
[2022-06-10 20:24:21 | train] - Train Epoch: [114]	 Average Loss: 0.830856	 Total Acc : 79.6718	 Total Top5 Acc : 92.6049
[2022-06-10 20:24:21 | train] - -------114 epoch end-----------
========================================
-------114 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 20:25:56 | train] - 
Epoch [114] Test set: Average loss: 1.4222, Accuracy: 34698/50000 (69.3690%), Top-5 Accuracy: 88.6793%

[2022-06-10 20:25:56 | train] - save intermediate epoch [114] result


[2022-06-10 20:26:29 | train] - -------115 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 20:26:31 | train] - Train Epoch: [115] [0/1281167 (0%)]	Loss: 0.939167
[2022-06-10 20:26:51 | train] - Train Epoch: [115] [12800/1281167 (1%)]	Loss: 0.814851
[2022-06-10 20:27:11 | train] - Train Epoch: [115] [25600/1281167 (2%)]	Loss: 0.933120
[2022-06-10 20:27:32 | train] - Train Epoch: [115] [38400/1281167 (3%)]	Loss: 0.855943
[2022-06-10 20:27:52 | train] - Train Epoch: [115] [51200/1281167 (4%)]	Loss: 0.811859
[2022-06-10 20:28:12 | train] - Train Epoch: [115] [64000/1281167 (5%)]	Loss: 0.839110
[2022-06-10 20:28:32 | train] - Train Epoch: [115] [76800/1281167 (6%)]	Loss: 1.195522
[2022-06-10 20:28:53 | train] - Train Epoch: [115] [89600/1281167 (7%)]	Loss: 1.040826
[2022-06-10 20:29:12 | train] - Train Epoch: [115] [102400/1281167 (8%)]	Loss: 0.827897
[2022-06-10 20:29:32 | train] - Train Epoch: [115] [115200/1281167 (9%)]	Loss: 0.728775
[2022-06-10 20:29:53 | train] - Train Epoch: [115] [128000/1281167 (10%)]	Loss: 0.985695
[2022-06-10 20:30:13 | train] - Train Epoch: [115] [140800/1281167 (11%)]	Loss: 0.615435
[2022-06-10 20:30:34 | train] - Train Epoch: [115] [153600/1281167 (12%)]	Loss: 0.905284
[2022-06-10 20:30:55 | train] - Train Epoch: [115] [166400/1281167 (13%)]	Loss: 0.692381
[2022-06-10 20:31:15 | train] - Train Epoch: [115] [179200/1281167 (14%)]	Loss: 0.915060
[2022-06-10 20:31:35 | train] - Train Epoch: [115] [192000/1281167 (15%)]	Loss: 0.709481
[2022-06-10 20:31:55 | train] - Train Epoch: [115] [204800/1281167 (16%)]	Loss: 1.022664
[2022-06-10 20:32:16 | train] - Train Epoch: [115] [217600/1281167 (17%)]	Loss: 0.844078
[2022-06-10 20:32:36 | train] - Train Epoch: [115] [230400/1281167 (18%)]	Loss: 0.747510
[2022-06-10 20:32:56 | train] - Train Epoch: [115] [243200/1281167 (19%)]	Loss: 0.880752
[2022-06-10 20:33:16 | train] - Train Epoch: [115] [256000/1281167 (20%)]	Loss: 0.512839
[2022-06-10 20:33:37 | train] - Train Epoch: [115] [268800/1281167 (21%)]	Loss: 0.900887
[2022-06-10 20:33:58 | train] - Train Epoch: [115] [281600/1281167 (22%)]	Loss: 0.742750
[2022-06-10 20:34:18 | train] - Train Epoch: [115] [294400/1281167 (23%)]	Loss: 0.703229
[2022-06-10 20:34:38 | train] - Train Epoch: [115] [307200/1281167 (24%)]	Loss: 1.140412
[2022-06-10 20:34:59 | train] - Train Epoch: [115] [320000/1281167 (25%)]	Loss: 0.827534
[2022-06-10 20:35:19 | train] - Train Epoch: [115] [332800/1281167 (26%)]	Loss: 0.723315
[2022-06-10 20:35:39 | train] - Train Epoch: [115] [345600/1281167 (27%)]	Loss: 1.244326
[2022-06-10 20:35:59 | train] - Train Epoch: [115] [358400/1281167 (28%)]	Loss: 0.603601
[2022-06-10 20:36:20 | train] - Train Epoch: [115] [371200/1281167 (29%)]	Loss: 0.895396
[2022-06-10 20:36:41 | train] - Train Epoch: [115] [384000/1281167 (30%)]	Loss: 0.802895
[2022-06-10 20:37:01 | train] - Train Epoch: [115] [396800/1281167 (31%)]	Loss: 0.997785
[2022-06-10 20:37:20 | train] - Train Epoch: [115] [409600/1281167 (32%)]	Loss: 0.799484
[2022-06-10 20:37:41 | train] - Train Epoch: [115] [422400/1281167 (33%)]	Loss: 0.857345
[2022-06-10 20:38:01 | train] - Train Epoch: [115] [435200/1281167 (34%)]	Loss: 0.842483
[2022-06-10 20:38:21 | train] - Train Epoch: [115] [448000/1281167 (35%)]	Loss: 1.243289
[2022-06-10 20:38:41 | train] - Train Epoch: [115] [460800/1281167 (36%)]	Loss: 0.928986
[2022-06-10 20:39:02 | train] - Train Epoch: [115] [473600/1281167 (37%)]	Loss: 0.843693
[2022-06-10 20:39:23 | train] - Train Epoch: [115] [486400/1281167 (38%)]	Loss: 0.895272
[2022-06-10 20:39:43 | train] - Train Epoch: [115] [499200/1281167 (39%)]	Loss: 0.867957
[2022-06-10 20:40:03 | train] - Train Epoch: [115] [512000/1281167 (40%)]	Loss: 0.911422
[2022-06-10 20:40:23 | train] - Train Epoch: [115] [524800/1281167 (41%)]	Loss: 0.858116
[2022-06-10 20:40:43 | train] - Train Epoch: [115] [537600/1281167 (42%)]	Loss: 0.646534
[2022-06-10 20:41:03 | train] - Train Epoch: [115] [550400/1281167 (43%)]	Loss: 0.919904
[2022-06-10 20:41:23 | train] - Train Epoch: [115] [563200/1281167 (44%)]	Loss: 0.783149
[2022-06-10 20:41:44 | train] - Train Epoch: [115] [576000/1281167 (45%)]	Loss: 0.940152
[2022-06-10 20:42:05 | train] - Train Epoch: [115] [588800/1281167 (46%)]	Loss: 0.992793
[2022-06-10 20:42:25 | train] - Train Epoch: [115] [601600/1281167 (47%)]	Loss: 0.873837
[2022-06-10 20:42:45 | train] - Train Epoch: [115] [614400/1281167 (48%)]	Loss: 0.696787
[2022-06-10 20:43:05 | train] - Train Epoch: [115] [627200/1281167 (49%)]	Loss: 0.981718
[2022-06-10 20:43:25 | train] - Train Epoch: [115] [640000/1281167 (50%)]	Loss: 0.913702
[2022-06-10 20:43:46 | train] - Train Epoch: [115] [652800/1281167 (51%)]	Loss: 0.609482
[2022-06-10 20:44:06 | train] - Train Epoch: [115] [665600/1281167 (52%)]	Loss: 0.818448
[2022-06-10 20:44:27 | train] - Train Epoch: [115] [678400/1281167 (53%)]	Loss: 0.958421
[2022-06-10 20:44:48 | train] - Train Epoch: [115] [691200/1281167 (54%)]	Loss: 0.883965
[2022-06-10 20:45:08 | train] - Train Epoch: [115] [704000/1281167 (55%)]	Loss: 0.984554
[2022-06-10 20:45:29 | train] - Train Epoch: [115] [716800/1281167 (56%)]	Loss: 0.718671
[2022-06-10 20:45:49 | train] - Train Epoch: [115] [729600/1281167 (57%)]	Loss: 0.737706
[2022-06-10 20:46:10 | train] - Train Epoch: [115] [742400/1281167 (58%)]	Loss: 0.869714
[2022-06-10 20:46:30 | train] - Train Epoch: [115] [755200/1281167 (59%)]	Loss: 0.859667
[2022-06-10 20:46:51 | train] - Train Epoch: [115] [768000/1281167 (60%)]	Loss: 0.887847
[2022-06-10 20:47:12 | train] - Train Epoch: [115] [780800/1281167 (61%)]	Loss: 0.825946
[2022-06-10 20:47:32 | train] - Train Epoch: [115] [793600/1281167 (62%)]	Loss: 0.775559
[2022-06-10 20:47:52 | train] - Train Epoch: [115] [806400/1281167 (63%)]	Loss: 0.718892
[2022-06-10 20:48:13 | train] - Train Epoch: [115] [819200/1281167 (64%)]	Loss: 1.312906
[2022-06-10 20:48:33 | train] - Train Epoch: [115] [832000/1281167 (65%)]	Loss: 1.159768
[2022-06-10 20:48:54 | train] - Train Epoch: [115] [844800/1281167 (66%)]	Loss: 0.928506
[2022-06-10 20:49:15 | train] - Train Epoch: [115] [857600/1281167 (67%)]	Loss: 0.932177
[2022-06-10 20:49:36 | train] - Train Epoch: [115] [870400/1281167 (68%)]	Loss: 0.864685
[2022-06-10 20:49:56 | train] - Train Epoch: [115] [883200/1281167 (69%)]	Loss: 0.739691
[2022-06-10 20:50:16 | train] - Train Epoch: [115] [896000/1281167 (70%)]	Loss: 0.710512
[2022-06-10 20:50:36 | train] - Train Epoch: [115] [908800/1281167 (71%)]	Loss: 0.660513
[2022-06-10 20:50:56 | train] - Train Epoch: [115] [921600/1281167 (72%)]	Loss: 0.967079
[2022-06-10 20:51:17 | train] - Train Epoch: [115] [934400/1281167 (73%)]	Loss: 0.934577
[2022-06-10 20:51:37 | train] - Train Epoch: [115] [947200/1281167 (74%)]	Loss: 0.904904
[2022-06-10 20:51:58 | train] - Train Epoch: [115] [960000/1281167 (75%)]	Loss: 0.947213
[2022-06-10 20:52:18 | train] - Train Epoch: [115] [972800/1281167 (76%)]	Loss: 0.888309
[2022-06-10 20:52:38 | train] - Train Epoch: [115] [985600/1281167 (77%)]	Loss: 0.905447
[2022-06-10 20:52:59 | train] - Train Epoch: [115] [998400/1281167 (78%)]	Loss: 0.871219
[2022-06-10 20:53:19 | train] - Train Epoch: [115] [1011200/1281167 (79%)]	Loss: 0.925491
[2022-06-10 20:53:39 | train] - Train Epoch: [115] [1024000/1281167 (80%)]	Loss: 0.740272
[2022-06-10 20:53:59 | train] - Train Epoch: [115] [1036800/1281167 (81%)]	Loss: 0.809162
[2022-06-10 20:54:19 | train] - Train Epoch: [115] [1049600/1281167 (82%)]	Loss: 0.779457
[2022-06-10 20:54:40 | train] - Train Epoch: [115] [1062400/1281167 (83%)]	Loss: 0.819732
[2022-06-10 20:55:00 | train] - Train Epoch: [115] [1075200/1281167 (84%)]	Loss: 0.995273
[2022-06-10 20:55:21 | train] - Train Epoch: [115] [1088000/1281167 (85%)]	Loss: 0.799996
[2022-06-10 20:55:42 | train] - Train Epoch: [115] [1100800/1281167 (86%)]	Loss: 0.921069
[2022-06-10 20:56:02 | train] - Train Epoch: [115] [1113600/1281167 (87%)]	Loss: 0.726720
[2022-06-10 20:56:23 | train] - Train Epoch: [115] [1126400/1281167 (88%)]	Loss: 0.858953
[2022-06-10 20:56:43 | train] - Train Epoch: [115] [1139200/1281167 (89%)]	Loss: 0.734942
[2022-06-10 20:57:03 | train] - Train Epoch: [115] [1152000/1281167 (90%)]	Loss: 0.874433
[2022-06-10 20:57:24 | train] - Train Epoch: [115] [1164800/1281167 (91%)]	Loss: 0.863908
[2022-06-10 20:57:44 | train] - Train Epoch: [115] [1177600/1281167 (92%)]	Loss: 1.029946
[2022-06-10 20:58:05 | train] - Train Epoch: [115] [1190400/1281167 (93%)]	Loss: 0.989881
[2022-06-10 20:58:25 | train] - Train Epoch: [115] [1203200/1281167 (94%)]	Loss: 0.853635
[2022-06-10 20:58:45 | train] - Train Epoch: [115] [1216000/1281167 (95%)]	Loss: 1.178435
[2022-06-10 20:59:04 | train] - Train Epoch: [115] [1228800/1281167 (96%)]	Loss: 0.750571
[2022-06-10 20:59:24 | train] - Train Epoch: [115] [1241600/1281167 (97%)]	Loss: 0.637004
[2022-06-10 20:59:45 | train] - Train Epoch: [115] [1254400/1281167 (98%)]	Loss: 0.860039
[2022-06-10 21:00:06 | train] - Train Epoch: [115] [1267200/1281167 (99%)]	Loss: 0.813649
[2022-06-10 21:00:27 | train] - Train Epoch: [115] [1280000/1281167 (100%)]	Loss: 1.083058
[2022-06-10 21:00:28 | train] - Train Epoch: [115]	 Average Loss: 0.829306	 Total Acc : 79.6921	 Total Top5 Acc : 92.5959
[2022-06-10 21:00:28 | train] - -------115 epoch end-----------
========================================
-------115 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-10 21:02:02 | train] - 
Epoch [115] Test set: Average loss: 1.4232, Accuracy: 34699/50000 (69.3698%), Top-5 Accuracy: 88.6929%

[2022-06-10 21:02:02 | train] - save intermediate epoch [115] result


[2022-06-10 21:02:33 | train] - -------116 epoch start-----------
========================================
----- test end -------------------------


[2022-06-10 21:02:35 | train] - Train Epoch: [116] [0/1281167 (0%)]	Loss: 0.887422
[2022-06-10 21:02:55 | train] - Train Epoch: [116] [12800/1281167 (1%)]	Loss: 0.973621
[2022-06-10 21:03:16 | train] - Train Epoch: [116] [25600/1281167 (2%)]	Loss: 0.985188
[2022-06-10 21:03:37 | train] - Train Epoch: [116] [38400/1281167 (3%)]	Loss: 0.682260
Traceback (most recent call last):
  File "main.py", line 390, in <module>
    main()
  File "main.py", line 349, in main
    train_acc, train_top5_acc, train_loss = train(net, train_loader, optimizer, epoch, device, logger)
  File "main.py", line 55, in train
    for batch_idx, (data, target) in enumerate(train_loader):
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1183, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1229, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.8/site-packages/torch/_utils.py", line 438, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 84, in default_collate
    return [default_collate(samples) for samples in transposed]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 84, in <listcomp>
    return [default_collate(samples) for samples in transposed]
  File "/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py", line 54, in default_collate
    storage = elem.storage()._new_shared(numel)
  File "/opt/conda/lib/python3.8/site-packages/torch/storage.py", line 486, in _new_shared
    untyped_storage = module.UntypedStorage._new_shared(size * cls().element_size())
  File "/opt/conda/lib/python3.8/site-packages/torch/storage.py", line 173, in _new_shared
    return cls._new_using_fd(size)
RuntimeError: falseINTERNAL ASSERT FAILED at "/opt/pytorch/pytorch/aten/src/ATen/MapAllocator.cpp":263, please report a bug to PyTorch. unable to open shared memory object </torch_1617_174> in read-write mode

[2022-06-11 05:07:48 | train] - -------start logging -----------

[2022-06-11 05:07:49 | train] - -------end logging -----------

[2022-06-11 05:07:49 | train] - -------116 epoch start-----------
/data/kjh/save_fix_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/ is exists
load log path /data/kjh/save_fix_log/imagenet_resnet50im/log_imagenet_resnet50im_bs128_ep200_seed_3/
load pretrained model : epoch 116
GPU : [0, 1]
activation_index : [-1]
activation_step : [0, 30, 60, 90, 120, 150, 180, 200]
batch_size : 128
data_path : /dataset/ImageNet/Classification
dataset : imagenet
epochs : 200
get_weight_grad_param : True
get_weight_param : True
load_state_dict : False
log_override : True
lr : 0.01
lr_gamma : 0.2
ml_step : [60, 120, 160]
model_name : resnet50im
momentum : 0.9
nGPU : 1
nesterov : True
optimizer : SGD
save_path : /data/kjh/save_fix_log/imagenet_resnet50im
scheduler : multi_step
seed : 3
train : True
visible_devices : 1
warmup : 5
weight_decay : 0.0005
worker : 8
None
[2022-06-11 05:07:51 | train] - Train Epoch: [116] [0/1281167 (0%)]	Loss: 0.806107
[2022-06-11 05:08:12 | train] - Train Epoch: [116] [12800/1281167 (1%)]	Loss: 0.685871
[2022-06-11 05:08:33 | train] - Train Epoch: [116] [25600/1281167 (2%)]	Loss: 0.600639
[2022-06-11 05:08:53 | train] - Train Epoch: [116] [38400/1281167 (3%)]	Loss: 0.786925
[2022-06-11 05:09:15 | train] - Train Epoch: [116] [51200/1281167 (4%)]	Loss: 0.655324
[2022-06-11 05:09:36 | train] - Train Epoch: [116] [64000/1281167 (5%)]	Loss: 0.634410
[2022-06-11 05:09:57 | train] - Train Epoch: [116] [76800/1281167 (6%)]	Loss: 0.803573
[2022-06-11 05:10:18 | train] - Train Epoch: [116] [89600/1281167 (7%)]	Loss: 0.768867
[2022-06-11 05:10:38 | train] - Train Epoch: [116] [102400/1281167 (8%)]	Loss: 0.856244
[2022-06-11 05:10:59 | train] - Train Epoch: [116] [115200/1281167 (9%)]	Loss: 0.561386
[2022-06-11 05:11:20 | train] - Train Epoch: [116] [128000/1281167 (10%)]	Loss: 0.561283
[2022-06-11 05:11:41 | train] - Train Epoch: [116] [140800/1281167 (11%)]	Loss: 1.010683
[2022-06-11 05:12:03 | train] - Train Epoch: [116] [153600/1281167 (12%)]	Loss: 0.780617
[2022-06-11 05:12:23 | train] - Train Epoch: [116] [166400/1281167 (13%)]	Loss: 0.827722
[2022-06-11 05:12:45 | train] - Train Epoch: [116] [179200/1281167 (14%)]	Loss: 0.875426
[2022-06-11 05:13:07 | train] - Train Epoch: [116] [192000/1281167 (15%)]	Loss: 0.902274
[2022-06-11 05:13:28 | train] - Train Epoch: [116] [204800/1281167 (16%)]	Loss: 0.770312
[2022-06-11 05:13:49 | train] - Train Epoch: [116] [217600/1281167 (17%)]	Loss: 0.896017
[2022-06-11 05:14:11 | train] - Train Epoch: [116] [230400/1281167 (18%)]	Loss: 0.849220
[2022-06-11 05:14:32 | train] - Train Epoch: [116] [243200/1281167 (19%)]	Loss: 0.956355
[2022-06-11 05:14:53 | train] - Train Epoch: [116] [256000/1281167 (20%)]	Loss: 0.948005
[2022-06-11 05:15:14 | train] - Train Epoch: [116] [268800/1281167 (21%)]	Loss: 0.958023
[2022-06-11 05:15:35 | train] - Train Epoch: [116] [281600/1281167 (22%)]	Loss: 0.643857
[2022-06-11 05:15:56 | train] - Train Epoch: [116] [294400/1281167 (23%)]	Loss: 0.629054
[2022-06-11 05:16:17 | train] - Train Epoch: [116] [307200/1281167 (24%)]	Loss: 0.643465
[2022-06-11 05:16:38 | train] - Train Epoch: [116] [320000/1281167 (25%)]	Loss: 0.923961
[2022-06-11 05:16:59 | train] - Train Epoch: [116] [332800/1281167 (26%)]	Loss: 0.756487
[2022-06-11 05:17:20 | train] - Train Epoch: [116] [345600/1281167 (27%)]	Loss: 0.925880
[2022-06-11 05:17:42 | train] - Train Epoch: [116] [358400/1281167 (28%)]	Loss: 0.892561
[2022-06-11 05:18:02 | train] - Train Epoch: [116] [371200/1281167 (29%)]	Loss: 0.625336
[2022-06-11 05:18:24 | train] - Train Epoch: [116] [384000/1281167 (30%)]	Loss: 0.643320
[2022-06-11 05:18:45 | train] - Train Epoch: [116] [396800/1281167 (31%)]	Loss: 0.523535
[2022-06-11 05:19:06 | train] - Train Epoch: [116] [409600/1281167 (32%)]	Loss: 0.942369
[2022-06-11 05:19:27 | train] - Train Epoch: [116] [422400/1281167 (33%)]	Loss: 0.844946
[2022-06-11 05:19:48 | train] - Train Epoch: [116] [435200/1281167 (34%)]	Loss: 0.854038
[2022-06-11 05:20:08 | train] - Train Epoch: [116] [448000/1281167 (35%)]	Loss: 0.702305
[2022-06-11 05:20:29 | train] - Train Epoch: [116] [460800/1281167 (36%)]	Loss: 0.837324
[2022-06-11 05:20:50 | train] - Train Epoch: [116] [473600/1281167 (37%)]	Loss: 0.696104
[2022-06-11 05:21:11 | train] - Train Epoch: [116] [486400/1281167 (38%)]	Loss: 1.000793
[2022-06-11 05:21:33 | train] - Train Epoch: [116] [499200/1281167 (39%)]	Loss: 0.641019
[2022-06-11 05:21:55 | train] - Train Epoch: [116] [512000/1281167 (40%)]	Loss: 0.650369
[2022-06-11 05:22:16 | train] - Train Epoch: [116] [524800/1281167 (41%)]	Loss: 0.883493
[2022-06-11 05:22:37 | train] - Train Epoch: [116] [537600/1281167 (42%)]	Loss: 0.796310
[2022-06-11 05:22:58 | train] - Train Epoch: [116] [550400/1281167 (43%)]	Loss: 0.796347
[2022-06-11 05:23:20 | train] - Train Epoch: [116] [563200/1281167 (44%)]	Loss: 0.668066
[2022-06-11 05:23:41 | train] - Train Epoch: [116] [576000/1281167 (45%)]	Loss: 0.754013
[2022-06-11 05:24:01 | train] - Train Epoch: [116] [588800/1281167 (46%)]	Loss: 0.917027
[2022-06-11 05:24:23 | train] - Train Epoch: [116] [601600/1281167 (47%)]	Loss: 0.816841
[2022-06-11 05:24:44 | train] - Train Epoch: [116] [614400/1281167 (48%)]	Loss: 0.661681
[2022-06-11 05:25:06 | train] - Train Epoch: [116] [627200/1281167 (49%)]	Loss: 0.718560
[2022-06-11 05:25:27 | train] - Train Epoch: [116] [640000/1281167 (50%)]	Loss: 0.978498
[2022-06-11 05:25:48 | train] - Train Epoch: [116] [652800/1281167 (51%)]	Loss: 0.723019
[2022-06-11 05:26:09 | train] - Train Epoch: [116] [665600/1281167 (52%)]	Loss: 1.124455
[2022-06-11 05:26:30 | train] - Train Epoch: [116] [678400/1281167 (53%)]	Loss: 0.655561
[2022-06-11 05:26:51 | train] - Train Epoch: [116] [691200/1281167 (54%)]	Loss: 0.699887
[2022-06-11 05:27:12 | train] - Train Epoch: [116] [704000/1281167 (55%)]	Loss: 0.869540
[2022-06-11 05:27:33 | train] - Train Epoch: [116] [716800/1281167 (56%)]	Loss: 0.626688
[2022-06-11 05:27:54 | train] - Train Epoch: [116] [729600/1281167 (57%)]	Loss: 0.547525
[2022-06-11 05:28:15 | train] - Train Epoch: [116] [742400/1281167 (58%)]	Loss: 0.782613
[2022-06-11 05:28:36 | train] - Train Epoch: [116] [755200/1281167 (59%)]	Loss: 1.021492
[2022-06-11 05:28:57 | train] - Train Epoch: [116] [768000/1281167 (60%)]	Loss: 0.970667
[2022-06-11 05:29:18 | train] - Train Epoch: [116] [780800/1281167 (61%)]	Loss: 0.712395
[2022-06-11 05:29:40 | train] - Train Epoch: [116] [793600/1281167 (62%)]	Loss: 0.871403
[2022-06-11 05:30:00 | train] - Train Epoch: [116] [806400/1281167 (63%)]	Loss: 0.700613
[2022-06-11 05:30:22 | train] - Train Epoch: [116] [819200/1281167 (64%)]	Loss: 0.880026
[2022-06-11 05:30:43 | train] - Train Epoch: [116] [832000/1281167 (65%)]	Loss: 0.913173
[2022-06-11 05:31:04 | train] - Train Epoch: [116] [844800/1281167 (66%)]	Loss: 0.723796
[2022-06-11 05:31:25 | train] - Train Epoch: [116] [857600/1281167 (67%)]	Loss: 0.751768
[2022-06-11 05:31:46 | train] - Train Epoch: [116] [870400/1281167 (68%)]	Loss: 0.770674
[2022-06-11 05:32:07 | train] - Train Epoch: [116] [883200/1281167 (69%)]	Loss: 0.779300
[2022-06-11 05:32:28 | train] - Train Epoch: [116] [896000/1281167 (70%)]	Loss: 0.752191
[2022-06-11 05:32:49 | train] - Train Epoch: [116] [908800/1281167 (71%)]	Loss: 0.685542
[2022-06-11 05:33:10 | train] - Train Epoch: [116] [921600/1281167 (72%)]	Loss: 1.231970
[2022-06-11 05:33:32 | train] - Train Epoch: [116] [934400/1281167 (73%)]	Loss: 0.669004
[2022-06-11 05:33:52 | train] - Train Epoch: [116] [947200/1281167 (74%)]	Loss: 0.695256
[2022-06-11 05:34:12 | train] - Train Epoch: [116] [960000/1281167 (75%)]	Loss: 0.793322
[2022-06-11 05:34:33 | train] - Train Epoch: [116] [972800/1281167 (76%)]	Loss: 0.724172
[2022-06-11 05:34:54 | train] - Train Epoch: [116] [985600/1281167 (77%)]	Loss: 0.840285
[2022-06-11 05:35:15 | train] - Train Epoch: [116] [998400/1281167 (78%)]	Loss: 0.792117
[2022-06-11 05:35:36 | train] - Train Epoch: [116] [1011200/1281167 (79%)]	Loss: 0.751759
[2022-06-11 05:35:57 | train] - Train Epoch: [116] [1024000/1281167 (80%)]	Loss: 0.739735
[2022-06-11 05:36:19 | train] - Train Epoch: [116] [1036800/1281167 (81%)]	Loss: 0.773425
[2022-06-11 05:36:40 | train] - Train Epoch: [116] [1049600/1281167 (82%)]	Loss: 0.749500
[2022-06-11 05:37:01 | train] - Train Epoch: [116] [1062400/1281167 (83%)]	Loss: 0.697170
[2022-06-11 05:37:21 | train] - Train Epoch: [116] [1075200/1281167 (84%)]	Loss: 1.057922
[2022-06-11 05:37:42 | train] - Train Epoch: [116] [1088000/1281167 (85%)]	Loss: 0.618264
[2022-06-11 05:38:02 | train] - Train Epoch: [116] [1100800/1281167 (86%)]	Loss: 0.900036
[2022-06-11 05:38:23 | train] - Train Epoch: [116] [1113600/1281167 (87%)]	Loss: 0.626873
[2022-06-11 05:38:43 | train] - Train Epoch: [116] [1126400/1281167 (88%)]	Loss: 0.744778
[2022-06-11 05:39:05 | train] - Train Epoch: [116] [1139200/1281167 (89%)]	Loss: 1.060822
[2022-06-11 05:39:26 | train] - Train Epoch: [116] [1152000/1281167 (90%)]	Loss: 0.738684
[2022-06-11 05:39:47 | train] - Train Epoch: [116] [1164800/1281167 (91%)]	Loss: 0.921924
[2022-06-11 05:40:08 | train] - Train Epoch: [116] [1177600/1281167 (92%)]	Loss: 1.322053
[2022-06-11 05:40:29 | train] - Train Epoch: [116] [1190400/1281167 (93%)]	Loss: 0.788185
[2022-06-11 05:40:50 | train] - Train Epoch: [116] [1203200/1281167 (94%)]	Loss: 0.848237
[2022-06-11 05:41:11 | train] - Train Epoch: [116] [1216000/1281167 (95%)]	Loss: 0.702051
[2022-06-11 05:41:32 | train] - Train Epoch: [116] [1228800/1281167 (96%)]	Loss: 0.668293
[2022-06-11 05:41:53 | train] - Train Epoch: [116] [1241600/1281167 (97%)]	Loss: 1.051809
[2022-06-11 05:42:15 | train] - Train Epoch: [116] [1254400/1281167 (98%)]	Loss: 0.619743
[2022-06-11 05:42:36 | train] - Train Epoch: [116] [1267200/1281167 (99%)]	Loss: 1.004911
[2022-06-11 05:42:58 | train] - Train Epoch: [116] [1280000/1281167 (100%)]	Loss: 0.787168
[2022-06-11 05:43:00 | train] - Train Epoch: [116]	 Average Loss: 0.817049	 Total Acc : 79.9894	 Total Top5 Acc : 92.7096
[2022-06-11 05:43:00 | train] - -------116 epoch end-----------
========================================
-------116 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 05:44:33 | train] - 
Epoch [116] Test set: Average loss: 1.4178, Accuracy: 34809/50000 (69.5968%), Top-5 Accuracy: 88.8455%

[2022-06-11 05:44:33 | train] - save intermediate epoch [116] result


[2022-06-11 05:44:33 | train] - logging best performance 116 epoch
[2022-06-11 05:44:35 | train] - -------117 epoch start-----------
========================================
----- test end -------------------------


logging best performance 116 epoch
[2022-06-11 05:44:37 | train] - Train Epoch: [117] [0/1281167 (0%)]	Loss: 0.758051
[2022-06-11 05:44:59 | train] - Train Epoch: [117] [12800/1281167 (1%)]	Loss: 0.771094
[2022-06-11 05:45:21 | train] - Train Epoch: [117] [25600/1281167 (2%)]	Loss: 0.841334
[2022-06-11 05:45:43 | train] - Train Epoch: [117] [38400/1281167 (3%)]	Loss: 0.505215
[2022-06-11 05:46:04 | train] - Train Epoch: [117] [51200/1281167 (4%)]	Loss: 0.683462
[2022-06-11 05:46:27 | train] - Train Epoch: [117] [64000/1281167 (5%)]	Loss: 0.745489
[2022-06-11 05:46:48 | train] - Train Epoch: [117] [76800/1281167 (6%)]	Loss: 0.698366
[2022-06-11 05:47:10 | train] - Train Epoch: [117] [89600/1281167 (7%)]	Loss: 0.693327
[2022-06-11 05:47:31 | train] - Train Epoch: [117] [102400/1281167 (8%)]	Loss: 0.626252
[2022-06-11 05:47:52 | train] - Train Epoch: [117] [115200/1281167 (9%)]	Loss: 0.552846
[2022-06-11 05:48:14 | train] - Train Epoch: [117] [128000/1281167 (10%)]	Loss: 0.862145
[2022-06-11 05:48:35 | train] - Train Epoch: [117] [140800/1281167 (11%)]	Loss: 0.639074
[2022-06-11 05:48:57 | train] - Train Epoch: [117] [153600/1281167 (12%)]	Loss: 0.703786
[2022-06-11 05:49:19 | train] - Train Epoch: [117] [166400/1281167 (13%)]	Loss: 1.197529
[2022-06-11 05:49:40 | train] - Train Epoch: [117] [179200/1281167 (14%)]	Loss: 0.877647
[2022-06-11 05:50:02 | train] - Train Epoch: [117] [192000/1281167 (15%)]	Loss: 0.844719
[2022-06-11 05:50:24 | train] - Train Epoch: [117] [204800/1281167 (16%)]	Loss: 0.691363
[2022-06-11 05:50:46 | train] - Train Epoch: [117] [217600/1281167 (17%)]	Loss: 0.779376
[2022-06-11 05:51:07 | train] - Train Epoch: [117] [230400/1281167 (18%)]	Loss: 0.793009
[2022-06-11 05:51:28 | train] - Train Epoch: [117] [243200/1281167 (19%)]	Loss: 0.745970
[2022-06-11 05:51:50 | train] - Train Epoch: [117] [256000/1281167 (20%)]	Loss: 0.605700
[2022-06-11 05:52:11 | train] - Train Epoch: [117] [268800/1281167 (21%)]	Loss: 0.819517
[2022-06-11 05:52:33 | train] - Train Epoch: [117] [281600/1281167 (22%)]	Loss: 0.912471
[2022-06-11 05:52:55 | train] - Train Epoch: [117] [294400/1281167 (23%)]	Loss: 0.986165
[2022-06-11 05:53:16 | train] - Train Epoch: [117] [307200/1281167 (24%)]	Loss: 0.799547
[2022-06-11 05:53:38 | train] - Train Epoch: [117] [320000/1281167 (25%)]	Loss: 1.101082
[2022-06-11 05:54:00 | train] - Train Epoch: [117] [332800/1281167 (26%)]	Loss: 0.691032
[2022-06-11 05:54:22 | train] - Train Epoch: [117] [345600/1281167 (27%)]	Loss: 0.901604
[2022-06-11 05:54:43 | train] - Train Epoch: [117] [358400/1281167 (28%)]	Loss: 0.711226
[2022-06-11 05:55:04 | train] - Train Epoch: [117] [371200/1281167 (29%)]	Loss: 0.961762
[2022-06-11 05:55:26 | train] - Train Epoch: [117] [384000/1281167 (30%)]	Loss: 0.901855
[2022-06-11 05:55:47 | train] - Train Epoch: [117] [396800/1281167 (31%)]	Loss: 0.740387
[2022-06-11 05:56:09 | train] - Train Epoch: [117] [409600/1281167 (32%)]	Loss: 0.611621
[2022-06-11 05:56:30 | train] - Train Epoch: [117] [422400/1281167 (33%)]	Loss: 0.752877
[2022-06-11 05:56:52 | train] - Train Epoch: [117] [435200/1281167 (34%)]	Loss: 0.875811
[2022-06-11 05:57:14 | train] - Train Epoch: [117] [448000/1281167 (35%)]	Loss: 0.882383
[2022-06-11 05:57:35 | train] - Train Epoch: [117] [460800/1281167 (36%)]	Loss: 0.840769
[2022-06-11 05:57:57 | train] - Train Epoch: [117] [473600/1281167 (37%)]	Loss: 0.831476
[2022-06-11 05:58:19 | train] - Train Epoch: [117] [486400/1281167 (38%)]	Loss: 0.915312
[2022-06-11 05:58:40 | train] - Train Epoch: [117] [499200/1281167 (39%)]	Loss: 0.801691
[2022-06-11 05:59:02 | train] - Train Epoch: [117] [512000/1281167 (40%)]	Loss: 0.682776
[2022-06-11 05:59:23 | train] - Train Epoch: [117] [524800/1281167 (41%)]	Loss: 0.610703
[2022-06-11 05:59:45 | train] - Train Epoch: [117] [537600/1281167 (42%)]	Loss: 0.945113
[2022-06-11 06:00:07 | train] - Train Epoch: [117] [550400/1281167 (43%)]	Loss: 0.906923
[2022-06-11 06:00:29 | train] - Train Epoch: [117] [563200/1281167 (44%)]	Loss: 0.757411
[2022-06-11 06:00:51 | train] - Train Epoch: [117] [576000/1281167 (45%)]	Loss: 0.819211
[2022-06-11 06:01:12 | train] - Train Epoch: [117] [588800/1281167 (46%)]	Loss: 0.732462
[2022-06-11 06:01:34 | train] - Train Epoch: [117] [601600/1281167 (47%)]	Loss: 0.825835
[2022-06-11 06:01:56 | train] - Train Epoch: [117] [614400/1281167 (48%)]	Loss: 0.826140
[2022-06-11 06:02:18 | train] - Train Epoch: [117] [627200/1281167 (49%)]	Loss: 0.977015
[2022-06-11 06:02:39 | train] - Train Epoch: [117] [640000/1281167 (50%)]	Loss: 0.641242
[2022-06-11 06:03:01 | train] - Train Epoch: [117] [652800/1281167 (51%)]	Loss: 0.659608
[2022-06-11 06:03:22 | train] - Train Epoch: [117] [665600/1281167 (52%)]	Loss: 0.968647
[2022-06-11 06:03:44 | train] - Train Epoch: [117] [678400/1281167 (53%)]	Loss: 0.803408
[2022-06-11 06:04:05 | train] - Train Epoch: [117] [691200/1281167 (54%)]	Loss: 1.225517
[2022-06-11 06:04:27 | train] - Train Epoch: [117] [704000/1281167 (55%)]	Loss: 0.826614
[2022-06-11 06:04:48 | train] - Train Epoch: [117] [716800/1281167 (56%)]	Loss: 0.732466
[2022-06-11 06:05:10 | train] - Train Epoch: [117] [729600/1281167 (57%)]	Loss: 0.614305
[2022-06-11 06:05:31 | train] - Train Epoch: [117] [742400/1281167 (58%)]	Loss: 0.908665
[2022-06-11 06:05:53 | train] - Train Epoch: [117] [755200/1281167 (59%)]	Loss: 0.542327
[2022-06-11 06:06:15 | train] - Train Epoch: [117] [768000/1281167 (60%)]	Loss: 0.703810
[2022-06-11 06:06:36 | train] - Train Epoch: [117] [780800/1281167 (61%)]	Loss: 0.676881
[2022-06-11 06:06:58 | train] - Train Epoch: [117] [793600/1281167 (62%)]	Loss: 0.871973
[2022-06-11 06:07:19 | train] - Train Epoch: [117] [806400/1281167 (63%)]	Loss: 0.702971
[2022-06-11 06:07:41 | train] - Train Epoch: [117] [819200/1281167 (64%)]	Loss: 0.674614
[2022-06-11 06:08:02 | train] - Train Epoch: [117] [832000/1281167 (65%)]	Loss: 0.642694
[2022-06-11 06:08:24 | train] - Train Epoch: [117] [844800/1281167 (66%)]	Loss: 0.837862
[2022-06-11 06:08:45 | train] - Train Epoch: [117] [857600/1281167 (67%)]	Loss: 0.752718
[2022-06-11 06:09:07 | train] - Train Epoch: [117] [870400/1281167 (68%)]	Loss: 1.100420
[2022-06-11 06:09:28 | train] - Train Epoch: [117] [883200/1281167 (69%)]	Loss: 0.713336
[2022-06-11 06:09:50 | train] - Train Epoch: [117] [896000/1281167 (70%)]	Loss: 1.058098
[2022-06-11 06:10:12 | train] - Train Epoch: [117] [908800/1281167 (71%)]	Loss: 0.666279
[2022-06-11 06:10:33 | train] - Train Epoch: [117] [921600/1281167 (72%)]	Loss: 0.700523
[2022-06-11 06:10:54 | train] - Train Epoch: [117] [934400/1281167 (73%)]	Loss: 0.956945
[2022-06-11 06:11:15 | train] - Train Epoch: [117] [947200/1281167 (74%)]	Loss: 0.649807
[2022-06-11 06:11:37 | train] - Train Epoch: [117] [960000/1281167 (75%)]	Loss: 0.978269
[2022-06-11 06:11:58 | train] - Train Epoch: [117] [972800/1281167 (76%)]	Loss: 0.879588
[2022-06-11 06:12:20 | train] - Train Epoch: [117] [985600/1281167 (77%)]	Loss: 0.933163
[2022-06-11 06:12:42 | train] - Train Epoch: [117] [998400/1281167 (78%)]	Loss: 0.751856
[2022-06-11 06:13:03 | train] - Train Epoch: [117] [1011200/1281167 (79%)]	Loss: 0.808019
[2022-06-11 06:13:24 | train] - Train Epoch: [117] [1024000/1281167 (80%)]	Loss: 1.006267
[2022-06-11 06:13:46 | train] - Train Epoch: [117] [1036800/1281167 (81%)]	Loss: 0.850322
[2022-06-11 06:14:08 | train] - Train Epoch: [117] [1049600/1281167 (82%)]	Loss: 0.923934
[2022-06-11 06:14:29 | train] - Train Epoch: [117] [1062400/1281167 (83%)]	Loss: 0.960444
[2022-06-11 06:14:51 | train] - Train Epoch: [117] [1075200/1281167 (84%)]	Loss: 0.985823
[2022-06-11 06:15:13 | train] - Train Epoch: [117] [1088000/1281167 (85%)]	Loss: 0.535045
[2022-06-11 06:15:35 | train] - Train Epoch: [117] [1100800/1281167 (86%)]	Loss: 0.974773
[2022-06-11 06:15:57 | train] - Train Epoch: [117] [1113600/1281167 (87%)]	Loss: 0.934011
[2022-06-11 06:16:18 | train] - Train Epoch: [117] [1126400/1281167 (88%)]	Loss: 0.917124
[2022-06-11 06:16:39 | train] - Train Epoch: [117] [1139200/1281167 (89%)]	Loss: 0.832394
[2022-06-11 06:17:01 | train] - Train Epoch: [117] [1152000/1281167 (90%)]	Loss: 0.774224
[2022-06-11 06:17:23 | train] - Train Epoch: [117] [1164800/1281167 (91%)]	Loss: 0.709881
[2022-06-11 06:17:44 | train] - Train Epoch: [117] [1177600/1281167 (92%)]	Loss: 0.722211
[2022-06-11 06:18:06 | train] - Train Epoch: [117] [1190400/1281167 (93%)]	Loss: 0.854007
[2022-06-11 06:18:28 | train] - Train Epoch: [117] [1203200/1281167 (94%)]	Loss: 0.833885
[2022-06-11 06:18:49 | train] - Train Epoch: [117] [1216000/1281167 (95%)]	Loss: 0.783033
[2022-06-11 06:19:11 | train] - Train Epoch: [117] [1228800/1281167 (96%)]	Loss: 0.769748
[2022-06-11 06:19:33 | train] - Train Epoch: [117] [1241600/1281167 (97%)]	Loss: 0.750540
[2022-06-11 06:19:55 | train] - Train Epoch: [117] [1254400/1281167 (98%)]	Loss: 0.799107
[2022-06-11 06:20:16 | train] - Train Epoch: [117] [1267200/1281167 (99%)]	Loss: 0.785868
[2022-06-11 06:20:39 | train] - Train Epoch: [117] [1280000/1281167 (100%)]	Loss: 0.716518
[2022-06-11 06:20:40 | train] - Train Epoch: [117]	 Average Loss: 0.822501	 Total Acc : 79.8552	 Total Top5 Acc : 92.6501
[2022-06-11 06:20:40 | train] - -------117 epoch end-----------
========================================
-------117 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 06:22:16 | train] - 
Epoch [117] Test set: Average loss: 1.4231, Accuracy: 34840/50000 (69.6455%), Top-5 Accuracy: 88.8243%

[2022-06-11 06:22:16 | train] - save intermediate epoch [117] result


[2022-06-11 06:22:17 | train] - logging best performance 117 epoch
[2022-06-11 06:22:18 | train] - -------118 epoch start-----------
========================================
----- test end -------------------------


logging best performance 117 epoch
[2022-06-11 06:22:20 | train] - Train Epoch: [118] [0/1281167 (0%)]	Loss: 0.983443
[2022-06-11 06:22:42 | train] - Train Epoch: [118] [12800/1281167 (1%)]	Loss: 0.877562
[2022-06-11 06:23:04 | train] - Train Epoch: [118] [25600/1281167 (2%)]	Loss: 0.891567
[2022-06-11 06:23:27 | train] - Train Epoch: [118] [38400/1281167 (3%)]	Loss: 0.726434
[2022-06-11 06:23:49 | train] - Train Epoch: [118] [51200/1281167 (4%)]	Loss: 0.546638
[2022-06-11 06:24:12 | train] - Train Epoch: [118] [64000/1281167 (5%)]	Loss: 0.643370
[2022-06-11 06:24:34 | train] - Train Epoch: [118] [76800/1281167 (6%)]	Loss: 0.855324
[2022-06-11 06:24:56 | train] - Train Epoch: [118] [89600/1281167 (7%)]	Loss: 1.165474
[2022-06-11 06:25:18 | train] - Train Epoch: [118] [102400/1281167 (8%)]	Loss: 0.838927
[2022-06-11 06:25:40 | train] - Train Epoch: [118] [115200/1281167 (9%)]	Loss: 0.993887
[2022-06-11 06:26:02 | train] - Train Epoch: [118] [128000/1281167 (10%)]	Loss: 0.724625
[2022-06-11 06:26:24 | train] - Train Epoch: [118] [140800/1281167 (11%)]	Loss: 0.761913
[2022-06-11 06:26:46 | train] - Train Epoch: [118] [153600/1281167 (12%)]	Loss: 0.870405
[2022-06-11 06:27:08 | train] - Train Epoch: [118] [166400/1281167 (13%)]	Loss: 0.865615
[2022-06-11 06:27:29 | train] - Train Epoch: [118] [179200/1281167 (14%)]	Loss: 0.621171
[2022-06-11 06:27:51 | train] - Train Epoch: [118] [192000/1281167 (15%)]	Loss: 0.646486
[2022-06-11 06:28:12 | train] - Train Epoch: [118] [204800/1281167 (16%)]	Loss: 0.520346
[2022-06-11 06:28:35 | train] - Train Epoch: [118] [217600/1281167 (17%)]	Loss: 0.701708
[2022-06-11 06:28:57 | train] - Train Epoch: [118] [230400/1281167 (18%)]	Loss: 0.823579
[2022-06-11 06:29:19 | train] - Train Epoch: [118] [243200/1281167 (19%)]	Loss: 0.875897
[2022-06-11 06:29:41 | train] - Train Epoch: [118] [256000/1281167 (20%)]	Loss: 0.702557
[2022-06-11 06:30:03 | train] - Train Epoch: [118] [268800/1281167 (21%)]	Loss: 0.751109
[2022-06-11 06:30:25 | train] - Train Epoch: [118] [281600/1281167 (22%)]	Loss: 0.745703
[2022-06-11 06:30:48 | train] - Train Epoch: [118] [294400/1281167 (23%)]	Loss: 0.589400
[2022-06-11 06:31:10 | train] - Train Epoch: [118] [307200/1281167 (24%)]	Loss: 0.916230
[2022-06-11 06:31:32 | train] - Train Epoch: [118] [320000/1281167 (25%)]	Loss: 0.893905
[2022-06-11 06:31:55 | train] - Train Epoch: [118] [332800/1281167 (26%)]	Loss: 0.879027
[2022-06-11 06:32:17 | train] - Train Epoch: [118] [345600/1281167 (27%)]	Loss: 0.812797
[2022-06-11 06:32:39 | train] - Train Epoch: [118] [358400/1281167 (28%)]	Loss: 1.049971
[2022-06-11 06:33:01 | train] - Train Epoch: [118] [371200/1281167 (29%)]	Loss: 0.939248
[2022-06-11 06:33:23 | train] - Train Epoch: [118] [384000/1281167 (30%)]	Loss: 0.673729
[2022-06-11 06:33:46 | train] - Train Epoch: [118] [396800/1281167 (31%)]	Loss: 0.735203
[2022-06-11 06:34:08 | train] - Train Epoch: [118] [409600/1281167 (32%)]	Loss: 0.917602
[2022-06-11 06:34:30 | train] - Train Epoch: [118] [422400/1281167 (33%)]	Loss: 0.854132
[2022-06-11 06:34:54 | train] - Train Epoch: [118] [435200/1281167 (34%)]	Loss: 0.733928
[2022-06-11 06:35:15 | train] - Train Epoch: [118] [448000/1281167 (35%)]	Loss: 0.917414
[2022-06-11 06:35:37 | train] - Train Epoch: [118] [460800/1281167 (36%)]	Loss: 0.881057
[2022-06-11 06:35:58 | train] - Train Epoch: [118] [473600/1281167 (37%)]	Loss: 0.804701
[2022-06-11 06:36:20 | train] - Train Epoch: [118] [486400/1281167 (38%)]	Loss: 0.738242
[2022-06-11 06:36:43 | train] - Train Epoch: [118] [499200/1281167 (39%)]	Loss: 0.664029
[2022-06-11 06:37:04 | train] - Train Epoch: [118] [512000/1281167 (40%)]	Loss: 0.833817
[2022-06-11 06:37:26 | train] - Train Epoch: [118] [524800/1281167 (41%)]	Loss: 0.609013
[2022-06-11 06:37:48 | train] - Train Epoch: [118] [537600/1281167 (42%)]	Loss: 0.594328
[2022-06-11 06:38:10 | train] - Train Epoch: [118] [550400/1281167 (43%)]	Loss: 0.807468
[2022-06-11 06:38:32 | train] - Train Epoch: [118] [563200/1281167 (44%)]	Loss: 1.007071
[2022-06-11 06:38:54 | train] - Train Epoch: [118] [576000/1281167 (45%)]	Loss: 0.670112
[2022-06-11 06:39:17 | train] - Train Epoch: [118] [588800/1281167 (46%)]	Loss: 0.547516
[2022-06-11 06:39:39 | train] - Train Epoch: [118] [601600/1281167 (47%)]	Loss: 0.889590
[2022-06-11 06:40:01 | train] - Train Epoch: [118] [614400/1281167 (48%)]	Loss: 0.982737
[2022-06-11 06:40:23 | train] - Train Epoch: [118] [627200/1281167 (49%)]	Loss: 0.836836
[2022-06-11 06:40:45 | train] - Train Epoch: [118] [640000/1281167 (50%)]	Loss: 0.649287
[2022-06-11 06:41:07 | train] - Train Epoch: [118] [652800/1281167 (51%)]	Loss: 0.626415
[2022-06-11 06:41:29 | train] - Train Epoch: [118] [665600/1281167 (52%)]	Loss: 0.638931
[2022-06-11 06:41:51 | train] - Train Epoch: [118] [678400/1281167 (53%)]	Loss: 0.881750
[2022-06-11 06:42:13 | train] - Train Epoch: [118] [691200/1281167 (54%)]	Loss: 0.713850
[2022-06-11 06:42:35 | train] - Train Epoch: [118] [704000/1281167 (55%)]	Loss: 1.030578
[2022-06-11 06:42:56 | train] - Train Epoch: [118] [716800/1281167 (56%)]	Loss: 1.002019
[2022-06-11 06:43:17 | train] - Train Epoch: [118] [729600/1281167 (57%)]	Loss: 0.627434
[2022-06-11 06:43:40 | train] - Train Epoch: [118] [742400/1281167 (58%)]	Loss: 0.797387
[2022-06-11 06:44:01 | train] - Train Epoch: [118] [755200/1281167 (59%)]	Loss: 0.794868
[2022-06-11 06:44:22 | train] - Train Epoch: [118] [768000/1281167 (60%)]	Loss: 0.927116
[2022-06-11 06:44:44 | train] - Train Epoch: [118] [780800/1281167 (61%)]	Loss: 0.818176
[2022-06-11 06:45:06 | train] - Train Epoch: [118] [793600/1281167 (62%)]	Loss: 0.767083
[2022-06-11 06:45:28 | train] - Train Epoch: [118] [806400/1281167 (63%)]	Loss: 0.629787
[2022-06-11 06:45:50 | train] - Train Epoch: [118] [819200/1281167 (64%)]	Loss: 0.705533
[2022-06-11 06:46:12 | train] - Train Epoch: [118] [832000/1281167 (65%)]	Loss: 0.877427
[2022-06-11 06:46:34 | train] - Train Epoch: [118] [844800/1281167 (66%)]	Loss: 0.679089
[2022-06-11 06:46:56 | train] - Train Epoch: [118] [857600/1281167 (67%)]	Loss: 0.883584
[2022-06-11 06:47:18 | train] - Train Epoch: [118] [870400/1281167 (68%)]	Loss: 0.898890
[2022-06-11 06:47:40 | train] - Train Epoch: [118] [883200/1281167 (69%)]	Loss: 0.884815
[2022-06-11 06:48:02 | train] - Train Epoch: [118] [896000/1281167 (70%)]	Loss: 0.879639
[2022-06-11 06:48:25 | train] - Train Epoch: [118] [908800/1281167 (71%)]	Loss: 0.740851
[2022-06-11 06:48:47 | train] - Train Epoch: [118] [921600/1281167 (72%)]	Loss: 0.881973
[2022-06-11 06:49:10 | train] - Train Epoch: [118] [934400/1281167 (73%)]	Loss: 0.711710
[2022-06-11 06:49:32 | train] - Train Epoch: [118] [947200/1281167 (74%)]	Loss: 0.937226
[2022-06-11 06:49:54 | train] - Train Epoch: [118] [960000/1281167 (75%)]	Loss: 0.847912
[2022-06-11 06:50:16 | train] - Train Epoch: [118] [972800/1281167 (76%)]	Loss: 0.854818
[2022-06-11 06:50:38 | train] - Train Epoch: [118] [985600/1281167 (77%)]	Loss: 0.780856
[2022-06-11 06:50:59 | train] - Train Epoch: [118] [998400/1281167 (78%)]	Loss: 0.806454
[2022-06-11 06:51:21 | train] - Train Epoch: [118] [1011200/1281167 (79%)]	Loss: 0.602588
[2022-06-11 06:51:42 | train] - Train Epoch: [118] [1024000/1281167 (80%)]	Loss: 0.800723
[2022-06-11 06:52:05 | train] - Train Epoch: [118] [1036800/1281167 (81%)]	Loss: 0.895034
[2022-06-11 06:52:27 | train] - Train Epoch: [118] [1049600/1281167 (82%)]	Loss: 0.820192
[2022-06-11 06:52:49 | train] - Train Epoch: [118] [1062400/1281167 (83%)]	Loss: 0.784274
[2022-06-11 06:53:10 | train] - Train Epoch: [118] [1075200/1281167 (84%)]	Loss: 0.718432
[2022-06-11 06:53:32 | train] - Train Epoch: [118] [1088000/1281167 (85%)]	Loss: 0.643338
[2022-06-11 06:53:54 | train] - Train Epoch: [118] [1100800/1281167 (86%)]	Loss: 0.839682
[2022-06-11 06:54:16 | train] - Train Epoch: [118] [1113600/1281167 (87%)]	Loss: 0.847445
[2022-06-11 06:54:39 | train] - Train Epoch: [118] [1126400/1281167 (88%)]	Loss: 0.745235
[2022-06-11 06:55:01 | train] - Train Epoch: [118] [1139200/1281167 (89%)]	Loss: 0.824453
[2022-06-11 06:55:23 | train] - Train Epoch: [118] [1152000/1281167 (90%)]	Loss: 0.807711
[2022-06-11 06:55:45 | train] - Train Epoch: [118] [1164800/1281167 (91%)]	Loss: 1.043404
[2022-06-11 06:56:08 | train] - Train Epoch: [118] [1177600/1281167 (92%)]	Loss: 0.973573
[2022-06-11 06:56:30 | train] - Train Epoch: [118] [1190400/1281167 (93%)]	Loss: 0.694850
[2022-06-11 06:56:53 | train] - Train Epoch: [118] [1203200/1281167 (94%)]	Loss: 0.979216
[2022-06-11 06:57:15 | train] - Train Epoch: [118] [1216000/1281167 (95%)]	Loss: 0.986124
[2022-06-11 06:57:37 | train] - Train Epoch: [118] [1228800/1281167 (96%)]	Loss: 1.032914
[2022-06-11 06:58:00 | train] - Train Epoch: [118] [1241600/1281167 (97%)]	Loss: 0.441538
[2022-06-11 06:58:22 | train] - Train Epoch: [118] [1254400/1281167 (98%)]	Loss: 0.995972
[2022-06-11 06:58:44 | train] - Train Epoch: [118] [1267200/1281167 (99%)]	Loss: 0.883844
[2022-06-11 06:59:06 | train] - Train Epoch: [118] [1280000/1281167 (100%)]	Loss: 0.657963
[2022-06-11 06:59:08 | train] - Train Epoch: [118]	 Average Loss: 0.816800	 Total Acc : 79.9724	 Total Top5 Acc : 92.7031
[2022-06-11 06:59:08 | train] - -------118 epoch end-----------
========================================
-------118 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 07:00:43 | train] - 
Epoch [118] Test set: Average loss: 1.4242, Accuracy: 34794/50000 (69.5620%), Top-5 Accuracy: 88.7252%

[2022-06-11 07:00:43 | train] - save intermediate epoch [118] result


[2022-06-11 07:00:45 | train] - -------119 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 07:00:47 | train] - Train Epoch: [119] [0/1281167 (0%)]	Loss: 0.851486
[2022-06-11 07:01:09 | train] - Train Epoch: [119] [12800/1281167 (1%)]	Loss: 0.611197
[2022-06-11 07:01:31 | train] - Train Epoch: [119] [25600/1281167 (2%)]	Loss: 0.832946
[2022-06-11 07:01:53 | train] - Train Epoch: [119] [38400/1281167 (3%)]	Loss: 0.683473
[2022-06-11 07:02:15 | train] - Train Epoch: [119] [51200/1281167 (4%)]	Loss: 0.742513
[2022-06-11 07:02:38 | train] - Train Epoch: [119] [64000/1281167 (5%)]	Loss: 0.994006
[2022-06-11 07:03:00 | train] - Train Epoch: [119] [76800/1281167 (6%)]	Loss: 0.630711
[2022-06-11 07:03:23 | train] - Train Epoch: [119] [89600/1281167 (7%)]	Loss: 0.653532
[2022-06-11 07:03:44 | train] - Train Epoch: [119] [102400/1281167 (8%)]	Loss: 0.895829
[2022-06-11 07:04:07 | train] - Train Epoch: [119] [115200/1281167 (9%)]	Loss: 0.686865
[2022-06-11 07:04:28 | train] - Train Epoch: [119] [128000/1281167 (10%)]	Loss: 0.933441
[2022-06-11 07:04:50 | train] - Train Epoch: [119] [140800/1281167 (11%)]	Loss: 0.948921
[2022-06-11 07:05:12 | train] - Train Epoch: [119] [153600/1281167 (12%)]	Loss: 0.974805
[2022-06-11 07:05:34 | train] - Train Epoch: [119] [166400/1281167 (13%)]	Loss: 0.746776
[2022-06-11 07:05:56 | train] - Train Epoch: [119] [179200/1281167 (14%)]	Loss: 0.991026
[2022-06-11 07:06:18 | train] - Train Epoch: [119] [192000/1281167 (15%)]	Loss: 0.699008
[2022-06-11 07:06:40 | train] - Train Epoch: [119] [204800/1281167 (16%)]	Loss: 0.877494
[2022-06-11 07:07:02 | train] - Train Epoch: [119] [217600/1281167 (17%)]	Loss: 1.044631
[2022-06-11 07:07:24 | train] - Train Epoch: [119] [230400/1281167 (18%)]	Loss: 0.692891
[2022-06-11 07:07:46 | train] - Train Epoch: [119] [243200/1281167 (19%)]	Loss: 0.778913
[2022-06-11 07:08:08 | train] - Train Epoch: [119] [256000/1281167 (20%)]	Loss: 0.616953
[2022-06-11 07:08:29 | train] - Train Epoch: [119] [268800/1281167 (21%)]	Loss: 0.932834
[2022-06-11 07:08:52 | train] - Train Epoch: [119] [281600/1281167 (22%)]	Loss: 1.221456
[2022-06-11 07:09:13 | train] - Train Epoch: [119] [294400/1281167 (23%)]	Loss: 0.621007
[2022-06-11 07:09:36 | train] - Train Epoch: [119] [307200/1281167 (24%)]	Loss: 0.772912
[2022-06-11 07:09:58 | train] - Train Epoch: [119] [320000/1281167 (25%)]	Loss: 0.676605
[2022-06-11 07:10:20 | train] - Train Epoch: [119] [332800/1281167 (26%)]	Loss: 0.832283
[2022-06-11 07:10:41 | train] - Train Epoch: [119] [345600/1281167 (27%)]	Loss: 1.022478
[2022-06-11 07:11:03 | train] - Train Epoch: [119] [358400/1281167 (28%)]	Loss: 0.903243
[2022-06-11 07:11:24 | train] - Train Epoch: [119] [371200/1281167 (29%)]	Loss: 0.836762
[2022-06-11 07:11:47 | train] - Train Epoch: [119] [384000/1281167 (30%)]	Loss: 1.070783
[2022-06-11 07:12:09 | train] - Train Epoch: [119] [396800/1281167 (31%)]	Loss: 0.595566
[2022-06-11 07:12:31 | train] - Train Epoch: [119] [409600/1281167 (32%)]	Loss: 0.769072
[2022-06-11 07:12:53 | train] - Train Epoch: [119] [422400/1281167 (33%)]	Loss: 0.871649
[2022-06-11 07:13:14 | train] - Train Epoch: [119] [435200/1281167 (34%)]	Loss: 0.841341
[2022-06-11 07:13:36 | train] - Train Epoch: [119] [448000/1281167 (35%)]	Loss: 0.885899
[2022-06-11 07:13:58 | train] - Train Epoch: [119] [460800/1281167 (36%)]	Loss: 0.772362
[2022-06-11 07:14:21 | train] - Train Epoch: [119] [473600/1281167 (37%)]	Loss: 0.439227
[2022-06-11 07:14:43 | train] - Train Epoch: [119] [486400/1281167 (38%)]	Loss: 0.717338
[2022-06-11 07:15:05 | train] - Train Epoch: [119] [499200/1281167 (39%)]	Loss: 0.916801
[2022-06-11 07:15:28 | train] - Train Epoch: [119] [512000/1281167 (40%)]	Loss: 1.328848
[2022-06-11 07:15:50 | train] - Train Epoch: [119] [524800/1281167 (41%)]	Loss: 0.703700
[2022-06-11 07:16:13 | train] - Train Epoch: [119] [537600/1281167 (42%)]	Loss: 0.779650
[2022-06-11 07:16:34 | train] - Train Epoch: [119] [550400/1281167 (43%)]	Loss: 0.650054
[2022-06-11 07:16:56 | train] - Train Epoch: [119] [563200/1281167 (44%)]	Loss: 0.641802
[2022-06-11 07:17:18 | train] - Train Epoch: [119] [576000/1281167 (45%)]	Loss: 0.822930
[2022-06-11 07:17:40 | train] - Train Epoch: [119] [588800/1281167 (46%)]	Loss: 0.897797
[2022-06-11 07:18:02 | train] - Train Epoch: [119] [601600/1281167 (47%)]	Loss: 0.798419
[2022-06-11 07:18:24 | train] - Train Epoch: [119] [614400/1281167 (48%)]	Loss: 0.749044
[2022-06-11 07:18:46 | train] - Train Epoch: [119] [627200/1281167 (49%)]	Loss: 0.973401
[2022-06-11 07:19:07 | train] - Train Epoch: [119] [640000/1281167 (50%)]	Loss: 1.205004
[2022-06-11 07:19:29 | train] - Train Epoch: [119] [652800/1281167 (51%)]	Loss: 0.764617
[2022-06-11 07:19:51 | train] - Train Epoch: [119] [665600/1281167 (52%)]	Loss: 0.743206
[2022-06-11 07:20:13 | train] - Train Epoch: [119] [678400/1281167 (53%)]	Loss: 0.766677
[2022-06-11 07:20:34 | train] - Train Epoch: [119] [691200/1281167 (54%)]	Loss: 0.546537
[2022-06-11 07:20:56 | train] - Train Epoch: [119] [704000/1281167 (55%)]	Loss: 0.593604
[2022-06-11 07:21:19 | train] - Train Epoch: [119] [716800/1281167 (56%)]	Loss: 0.929180
[2022-06-11 07:21:41 | train] - Train Epoch: [119] [729600/1281167 (57%)]	Loss: 1.147053
[2022-06-11 07:22:03 | train] - Train Epoch: [119] [742400/1281167 (58%)]	Loss: 0.733376
[2022-06-11 07:22:25 | train] - Train Epoch: [119] [755200/1281167 (59%)]	Loss: 0.900384
[2022-06-11 07:22:47 | train] - Train Epoch: [119] [768000/1281167 (60%)]	Loss: 0.536783
[2022-06-11 07:23:09 | train] - Train Epoch: [119] [780800/1281167 (61%)]	Loss: 1.049522
[2022-06-11 07:23:32 | train] - Train Epoch: [119] [793600/1281167 (62%)]	Loss: 0.673132
[2022-06-11 07:23:54 | train] - Train Epoch: [119] [806400/1281167 (63%)]	Loss: 1.058913
[2022-06-11 07:24:16 | train] - Train Epoch: [119] [819200/1281167 (64%)]	Loss: 0.845976
[2022-06-11 07:24:38 | train] - Train Epoch: [119] [832000/1281167 (65%)]	Loss: 0.759281
[2022-06-11 07:24:59 | train] - Train Epoch: [119] [844800/1281167 (66%)]	Loss: 0.800265
[2022-06-11 07:25:21 | train] - Train Epoch: [119] [857600/1281167 (67%)]	Loss: 0.615281
[2022-06-11 07:25:43 | train] - Train Epoch: [119] [870400/1281167 (68%)]	Loss: 0.832279
[2022-06-11 07:26:05 | train] - Train Epoch: [119] [883200/1281167 (69%)]	Loss: 0.940827
[2022-06-11 07:26:26 | train] - Train Epoch: [119] [896000/1281167 (70%)]	Loss: 0.780920
[2022-06-11 07:26:48 | train] - Train Epoch: [119] [908800/1281167 (71%)]	Loss: 0.726735
[2022-06-11 07:27:09 | train] - Train Epoch: [119] [921600/1281167 (72%)]	Loss: 0.966604
[2022-06-11 07:27:32 | train] - Train Epoch: [119] [934400/1281167 (73%)]	Loss: 0.821460
[2022-06-11 07:27:54 | train] - Train Epoch: [119] [947200/1281167 (74%)]	Loss: 0.957699
[2022-06-11 07:28:16 | train] - Train Epoch: [119] [960000/1281167 (75%)]	Loss: 0.984511
[2022-06-11 07:28:38 | train] - Train Epoch: [119] [972800/1281167 (76%)]	Loss: 0.911691
[2022-06-11 07:29:00 | train] - Train Epoch: [119] [985600/1281167 (77%)]	Loss: 0.726093
[2022-06-11 07:29:22 | train] - Train Epoch: [119] [998400/1281167 (78%)]	Loss: 0.921069
[2022-06-11 07:29:44 | train] - Train Epoch: [119] [1011200/1281167 (79%)]	Loss: 0.740017
[2022-06-11 07:30:06 | train] - Train Epoch: [119] [1024000/1281167 (80%)]	Loss: 0.690736
[2022-06-11 07:30:27 | train] - Train Epoch: [119] [1036800/1281167 (81%)]	Loss: 0.620528
[2022-06-11 07:30:49 | train] - Train Epoch: [119] [1049600/1281167 (82%)]	Loss: 0.747686
[2022-06-11 07:31:11 | train] - Train Epoch: [119] [1062400/1281167 (83%)]	Loss: 0.931687
[2022-06-11 07:31:34 | train] - Train Epoch: [119] [1075200/1281167 (84%)]	Loss: 0.767262
[2022-06-11 07:31:55 | train] - Train Epoch: [119] [1088000/1281167 (85%)]	Loss: 1.059257
[2022-06-11 07:32:18 | train] - Train Epoch: [119] [1100800/1281167 (86%)]	Loss: 0.741416
[2022-06-11 07:32:40 | train] - Train Epoch: [119] [1113600/1281167 (87%)]	Loss: 0.564837
[2022-06-11 07:33:01 | train] - Train Epoch: [119] [1126400/1281167 (88%)]	Loss: 0.880017
[2022-06-11 07:33:23 | train] - Train Epoch: [119] [1139200/1281167 (89%)]	Loss: 0.521209
[2022-06-11 07:33:45 | train] - Train Epoch: [119] [1152000/1281167 (90%)]	Loss: 0.770293
[2022-06-11 07:34:07 | train] - Train Epoch: [119] [1164800/1281167 (91%)]	Loss: 0.901378
[2022-06-11 07:34:30 | train] - Train Epoch: [119] [1177600/1281167 (92%)]	Loss: 0.746289
[2022-06-11 07:34:51 | train] - Train Epoch: [119] [1190400/1281167 (93%)]	Loss: 1.069947
[2022-06-11 07:35:13 | train] - Train Epoch: [119] [1203200/1281167 (94%)]	Loss: 0.686278
[2022-06-11 07:35:35 | train] - Train Epoch: [119] [1216000/1281167 (95%)]	Loss: 0.951267
[2022-06-11 07:35:57 | train] - Train Epoch: [119] [1228800/1281167 (96%)]	Loss: 0.785934
[2022-06-11 07:36:19 | train] - Train Epoch: [119] [1241600/1281167 (97%)]	Loss: 0.768693
[2022-06-11 07:36:40 | train] - Train Epoch: [119] [1254400/1281167 (98%)]	Loss: 0.950478
[2022-06-11 07:37:03 | train] - Train Epoch: [119] [1267200/1281167 (99%)]	Loss: 0.730146
[2022-06-11 07:37:24 | train] - Train Epoch: [119] [1280000/1281167 (100%)]	Loss: 0.770011
[2022-06-11 07:37:26 | train] - Train Epoch: [119]	 Average Loss: 0.813862	 Total Acc : 80.0296	 Total Top5 Acc : 92.7749
[2022-06-11 07:37:26 | train] - -------119 epoch end-----------
========================================
-------119 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 07:39:01 | train] - 
Epoch [119] Test set: Average loss: 1.4162, Accuracy: 34866/50000 (69.7023%), Top-5 Accuracy: 88.9210%

[2022-06-11 07:39:01 | train] - save intermediate epoch [119] result


[2022-06-11 07:39:03 | train] - logging best performance 119 epoch
[2022-06-11 07:39:04 | train] - -------120 epoch start-----------
[2022-06-11 07:39:04 | train] - -------- logging 120 batch layer input tensor ------------------
[2022-06-11 07:39:33 | train] - -------- logging end 120 --------------------
========================================
----- test end -------------------------


logging best performance 119 epoch
batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-11 07:39:35 | train] - Train Epoch: [120] [0/1281167 (0%)]	Loss: 0.660847
[2022-06-11 07:39:57 | train] - Train Epoch: [120] [12800/1281167 (1%)]	Loss: 0.807449
[2022-06-11 07:40:19 | train] - Train Epoch: [120] [25600/1281167 (2%)]	Loss: 0.911289
[2022-06-11 07:40:41 | train] - Train Epoch: [120] [38400/1281167 (3%)]	Loss: 0.689053
[2022-06-11 07:41:02 | train] - Train Epoch: [120] [51200/1281167 (4%)]	Loss: 0.785545
[2022-06-11 07:41:24 | train] - Train Epoch: [120] [64000/1281167 (5%)]	Loss: 0.816938
[2022-06-11 07:41:45 | train] - Train Epoch: [120] [76800/1281167 (6%)]	Loss: 0.742612
[2022-06-11 07:42:07 | train] - Train Epoch: [120] [89600/1281167 (7%)]	Loss: 0.690276
[2022-06-11 07:42:29 | train] - Train Epoch: [120] [102400/1281167 (8%)]	Loss: 0.817406
[2022-06-11 07:42:51 | train] - Train Epoch: [120] [115200/1281167 (9%)]	Loss: 0.829258
[2022-06-11 07:43:12 | train] - Train Epoch: [120] [128000/1281167 (10%)]	Loss: 0.948570
[2022-06-11 07:43:34 | train] - Train Epoch: [120] [140800/1281167 (11%)]	Loss: 0.806896
[2022-06-11 07:43:57 | train] - Train Epoch: [120] [153600/1281167 (12%)]	Loss: 0.862033
[2022-06-11 07:44:18 | train] - Train Epoch: [120] [166400/1281167 (13%)]	Loss: 0.810298
[2022-06-11 07:44:39 | train] - Train Epoch: [120] [179200/1281167 (14%)]	Loss: 0.757271
[2022-06-11 07:45:01 | train] - Train Epoch: [120] [192000/1281167 (15%)]	Loss: 0.721302
[2022-06-11 07:45:23 | train] - Train Epoch: [120] [204800/1281167 (16%)]	Loss: 0.565447
[2022-06-11 07:45:45 | train] - Train Epoch: [120] [217600/1281167 (17%)]	Loss: 0.609959
[2022-06-11 07:46:06 | train] - Train Epoch: [120] [230400/1281167 (18%)]	Loss: 0.858996
[2022-06-11 07:46:29 | train] - Train Epoch: [120] [243200/1281167 (19%)]	Loss: 0.780170
[2022-06-11 07:46:50 | train] - Train Epoch: [120] [256000/1281167 (20%)]	Loss: 0.919243
[2022-06-11 07:47:10 | train] - Train Epoch: [120] [268800/1281167 (21%)]	Loss: 0.872118
[2022-06-11 07:47:33 | train] - Train Epoch: [120] [281600/1281167 (22%)]	Loss: 0.842748
[2022-06-11 07:47:54 | train] - Train Epoch: [120] [294400/1281167 (23%)]	Loss: 0.882832
[2022-06-11 07:48:16 | train] - Train Epoch: [120] [307200/1281167 (24%)]	Loss: 0.775037
[2022-06-11 07:48:38 | train] - Train Epoch: [120] [320000/1281167 (25%)]	Loss: 0.861685
[2022-06-11 07:49:00 | train] - Train Epoch: [120] [332800/1281167 (26%)]	Loss: 0.781470
[2022-06-11 07:49:22 | train] - Train Epoch: [120] [345600/1281167 (27%)]	Loss: 0.852178
[2022-06-11 07:49:43 | train] - Train Epoch: [120] [358400/1281167 (28%)]	Loss: 0.756680
[2022-06-11 07:50:06 | train] - Train Epoch: [120] [371200/1281167 (29%)]	Loss: 0.849344
[2022-06-11 07:50:28 | train] - Train Epoch: [120] [384000/1281167 (30%)]	Loss: 0.746068
[2022-06-11 07:50:50 | train] - Train Epoch: [120] [396800/1281167 (31%)]	Loss: 0.694139
[2022-06-11 07:51:12 | train] - Train Epoch: [120] [409600/1281167 (32%)]	Loss: 0.779970
[2022-06-11 07:51:34 | train] - Train Epoch: [120] [422400/1281167 (33%)]	Loss: 0.710736
[2022-06-11 07:51:55 | train] - Train Epoch: [120] [435200/1281167 (34%)]	Loss: 0.852090
[2022-06-11 07:52:17 | train] - Train Epoch: [120] [448000/1281167 (35%)]	Loss: 0.563227
[2022-06-11 07:52:39 | train] - Train Epoch: [120] [460800/1281167 (36%)]	Loss: 0.738232
[2022-06-11 07:53:01 | train] - Train Epoch: [120] [473600/1281167 (37%)]	Loss: 0.795750
[2022-06-11 07:53:23 | train] - Train Epoch: [120] [486400/1281167 (38%)]	Loss: 0.911316
[2022-06-11 07:53:45 | train] - Train Epoch: [120] [499200/1281167 (39%)]	Loss: 0.875506
[2022-06-11 07:54:06 | train] - Train Epoch: [120] [512000/1281167 (40%)]	Loss: 0.975399
[2022-06-11 07:54:28 | train] - Train Epoch: [120] [524800/1281167 (41%)]	Loss: 0.614377
[2022-06-11 07:54:49 | train] - Train Epoch: [120] [537600/1281167 (42%)]	Loss: 0.698168
[2022-06-11 07:55:11 | train] - Train Epoch: [120] [550400/1281167 (43%)]	Loss: 0.850129
[2022-06-11 07:55:32 | train] - Train Epoch: [120] [563200/1281167 (44%)]	Loss: 0.684511
[2022-06-11 07:55:54 | train] - Train Epoch: [120] [576000/1281167 (45%)]	Loss: 0.620072
[2022-06-11 07:56:17 | train] - Train Epoch: [120] [588800/1281167 (46%)]	Loss: 0.769063
[2022-06-11 07:56:38 | train] - Train Epoch: [120] [601600/1281167 (47%)]	Loss: 0.555257
[2022-06-11 07:57:00 | train] - Train Epoch: [120] [614400/1281167 (48%)]	Loss: 0.692504
[2022-06-11 07:57:22 | train] - Train Epoch: [120] [627200/1281167 (49%)]	Loss: 0.830475
[2022-06-11 07:57:44 | train] - Train Epoch: [120] [640000/1281167 (50%)]	Loss: 0.883204
[2022-06-11 07:58:06 | train] - Train Epoch: [120] [652800/1281167 (51%)]	Loss: 0.766958
[2022-06-11 07:58:27 | train] - Train Epoch: [120] [665600/1281167 (52%)]	Loss: 1.008575
[2022-06-11 07:58:49 | train] - Train Epoch: [120] [678400/1281167 (53%)]	Loss: 0.895339
[2022-06-11 07:59:11 | train] - Train Epoch: [120] [691200/1281167 (54%)]	Loss: 0.685589
[2022-06-11 07:59:33 | train] - Train Epoch: [120] [704000/1281167 (55%)]	Loss: 0.965592
[2022-06-11 07:59:54 | train] - Train Epoch: [120] [716800/1281167 (56%)]	Loss: 0.522745
[2022-06-11 08:00:17 | train] - Train Epoch: [120] [729600/1281167 (57%)]	Loss: 0.717559
[2022-06-11 08:00:38 | train] - Train Epoch: [120] [742400/1281167 (58%)]	Loss: 0.889543
[2022-06-11 08:01:00 | train] - Train Epoch: [120] [755200/1281167 (59%)]	Loss: 0.835660
[2022-06-11 08:01:21 | train] - Train Epoch: [120] [768000/1281167 (60%)]	Loss: 0.634550
[2022-06-11 08:01:43 | train] - Train Epoch: [120] [780800/1281167 (61%)]	Loss: 0.610938
[2022-06-11 08:02:06 | train] - Train Epoch: [120] [793600/1281167 (62%)]	Loss: 0.899518
[2022-06-11 08:02:27 | train] - Train Epoch: [120] [806400/1281167 (63%)]	Loss: 0.568187
[2022-06-11 08:02:49 | train] - Train Epoch: [120] [819200/1281167 (64%)]	Loss: 0.683113
[2022-06-11 08:03:10 | train] - Train Epoch: [120] [832000/1281167 (65%)]	Loss: 0.767366
[2022-06-11 08:03:32 | train] - Train Epoch: [120] [844800/1281167 (66%)]	Loss: 0.706613
[2022-06-11 08:03:54 | train] - Train Epoch: [120] [857600/1281167 (67%)]	Loss: 0.813236
[2022-06-11 08:04:15 | train] - Train Epoch: [120] [870400/1281167 (68%)]	Loss: 0.834270
[2022-06-11 08:04:36 | train] - Train Epoch: [120] [883200/1281167 (69%)]	Loss: 0.552246
[2022-06-11 08:04:58 | train] - Train Epoch: [120] [896000/1281167 (70%)]	Loss: 0.757027
[2022-06-11 08:05:20 | train] - Train Epoch: [120] [908800/1281167 (71%)]	Loss: 0.652997
[2022-06-11 08:05:42 | train] - Train Epoch: [120] [921600/1281167 (72%)]	Loss: 0.807202
[2022-06-11 08:06:04 | train] - Train Epoch: [120] [934400/1281167 (73%)]	Loss: 0.642897
[2022-06-11 08:06:26 | train] - Train Epoch: [120] [947200/1281167 (74%)]	Loss: 0.579977
[2022-06-11 08:06:47 | train] - Train Epoch: [120] [960000/1281167 (75%)]	Loss: 0.777244
[2022-06-11 08:07:09 | train] - Train Epoch: [120] [972800/1281167 (76%)]	Loss: 0.842240
[2022-06-11 08:07:31 | train] - Train Epoch: [120] [985600/1281167 (77%)]	Loss: 0.782235
[2022-06-11 08:07:53 | train] - Train Epoch: [120] [998400/1281167 (78%)]	Loss: 0.790952
[2022-06-11 08:08:14 | train] - Train Epoch: [120] [1011200/1281167 (79%)]	Loss: 0.631123
[2022-06-11 08:08:36 | train] - Train Epoch: [120] [1024000/1281167 (80%)]	Loss: 0.540270
[2022-06-11 08:08:58 | train] - Train Epoch: [120] [1036800/1281167 (81%)]	Loss: 0.912141
[2022-06-11 08:09:20 | train] - Train Epoch: [120] [1049600/1281167 (82%)]	Loss: 0.825833
[2022-06-11 08:09:41 | train] - Train Epoch: [120] [1062400/1281167 (83%)]	Loss: 0.806439
[2022-06-11 08:10:04 | train] - Train Epoch: [120] [1075200/1281167 (84%)]	Loss: 0.705341
[2022-06-11 08:10:26 | train] - Train Epoch: [120] [1088000/1281167 (85%)]	Loss: 0.736926
[2022-06-11 08:10:47 | train] - Train Epoch: [120] [1100800/1281167 (86%)]	Loss: 0.803901
[2022-06-11 08:11:10 | train] - Train Epoch: [120] [1113600/1281167 (87%)]	Loss: 0.758196
[2022-06-11 08:11:31 | train] - Train Epoch: [120] [1126400/1281167 (88%)]	Loss: 0.632935
[2022-06-11 08:11:53 | train] - Train Epoch: [120] [1139200/1281167 (89%)]	Loss: 0.966460
[2022-06-11 08:12:14 | train] - Train Epoch: [120] [1152000/1281167 (90%)]	Loss: 0.877315
[2022-06-11 08:12:36 | train] - Train Epoch: [120] [1164800/1281167 (91%)]	Loss: 0.701937
[2022-06-11 08:12:58 | train] - Train Epoch: [120] [1177600/1281167 (92%)]	Loss: 0.825747
[2022-06-11 08:13:20 | train] - Train Epoch: [120] [1190400/1281167 (93%)]	Loss: 0.687745
[2022-06-11 08:13:42 | train] - Train Epoch: [120] [1203200/1281167 (94%)]	Loss: 0.844726
[2022-06-11 08:14:04 | train] - Train Epoch: [120] [1216000/1281167 (95%)]	Loss: 0.783908
[2022-06-11 08:14:26 | train] - Train Epoch: [120] [1228800/1281167 (96%)]	Loss: 0.755427
[2022-06-11 08:14:47 | train] - Train Epoch: [120] [1241600/1281167 (97%)]	Loss: 0.875864
[2022-06-11 08:15:09 | train] - Train Epoch: [120] [1254400/1281167 (98%)]	Loss: 0.920737
[2022-06-11 08:15:31 | train] - Train Epoch: [120] [1267200/1281167 (99%)]	Loss: 0.649033
[2022-06-11 08:15:53 | train] - Train Epoch: [120] [1280000/1281167 (100%)]	Loss: 0.786479
[2022-06-11 08:15:55 | train] - Train Epoch: [120]	 Average Loss: 0.784304	 Total Acc : 80.8497	 Total Top5 Acc : 93.0389
[2022-06-11 08:15:55 | train] - -------120 epoch end-----------
========================================
-------120 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 08:17:28 | train] - 
Epoch [120] Test set: Average loss: 1.4129, Accuracy: 34993/50000 (69.9596%), Top-5 Accuracy: 88.9398%

[2022-06-11 08:17:28 | train] - save intermediate epoch [120] result


[2022-06-11 08:17:30 | train] - logging best performance 120 epoch
[2022-06-11 08:17:31 | train] - -------121 epoch start-----------
========================================
----- test end -------------------------


logging best performance 120 epoch
[2022-06-11 08:17:33 | train] - Train Epoch: [121] [0/1281167 (0%)]	Loss: 0.675721
[2022-06-11 08:17:55 | train] - Train Epoch: [121] [12800/1281167 (1%)]	Loss: 0.766778
[2022-06-11 08:18:17 | train] - Train Epoch: [121] [25600/1281167 (2%)]	Loss: 0.685191
[2022-06-11 08:18:39 | train] - Train Epoch: [121] [38400/1281167 (3%)]	Loss: 0.972194
[2022-06-11 08:19:01 | train] - Train Epoch: [121] [51200/1281167 (4%)]	Loss: 0.794205
[2022-06-11 08:19:23 | train] - Train Epoch: [121] [64000/1281167 (5%)]	Loss: 0.511048
[2022-06-11 08:19:45 | train] - Train Epoch: [121] [76800/1281167 (6%)]	Loss: 0.947649
[2022-06-11 08:20:06 | train] - Train Epoch: [121] [89600/1281167 (7%)]	Loss: 0.722563
[2022-06-11 08:20:28 | train] - Train Epoch: [121] [102400/1281167 (8%)]	Loss: 1.027304
[2022-06-11 08:20:49 | train] - Train Epoch: [121] [115200/1281167 (9%)]	Loss: 0.759379
[2022-06-11 08:21:10 | train] - Train Epoch: [121] [128000/1281167 (10%)]	Loss: 0.572398
[2022-06-11 08:21:32 | train] - Train Epoch: [121] [140800/1281167 (11%)]	Loss: 0.854605
[2022-06-11 08:21:54 | train] - Train Epoch: [121] [153600/1281167 (12%)]	Loss: 0.923254
[2022-06-11 08:22:15 | train] - Train Epoch: [121] [166400/1281167 (13%)]	Loss: 0.723581
[2022-06-11 08:22:37 | train] - Train Epoch: [121] [179200/1281167 (14%)]	Loss: 0.697416
[2022-06-11 08:22:59 | train] - Train Epoch: [121] [192000/1281167 (15%)]	Loss: 0.847693
[2022-06-11 08:23:21 | train] - Train Epoch: [121] [204800/1281167 (16%)]	Loss: 0.748914
[2022-06-11 08:23:43 | train] - Train Epoch: [121] [217600/1281167 (17%)]	Loss: 0.620813
[2022-06-11 08:24:05 | train] - Train Epoch: [121] [230400/1281167 (18%)]	Loss: 0.680328
[2022-06-11 08:24:28 | train] - Train Epoch: [121] [243200/1281167 (19%)]	Loss: 0.645152
[2022-06-11 08:24:49 | train] - Train Epoch: [121] [256000/1281167 (20%)]	Loss: 0.990768
[2022-06-11 08:25:11 | train] - Train Epoch: [121] [268800/1281167 (21%)]	Loss: 0.771079
[2022-06-11 08:25:33 | train] - Train Epoch: [121] [281600/1281167 (22%)]	Loss: 1.052459
[2022-06-11 08:25:55 | train] - Train Epoch: [121] [294400/1281167 (23%)]	Loss: 0.692853
[2022-06-11 08:26:16 | train] - Train Epoch: [121] [307200/1281167 (24%)]	Loss: 0.854086
[2022-06-11 08:26:38 | train] - Train Epoch: [121] [320000/1281167 (25%)]	Loss: 0.547318
[2022-06-11 08:27:00 | train] - Train Epoch: [121] [332800/1281167 (26%)]	Loss: 0.831209
[2022-06-11 08:27:22 | train] - Train Epoch: [121] [345600/1281167 (27%)]	Loss: 0.661338
[2022-06-11 08:27:43 | train] - Train Epoch: [121] [358400/1281167 (28%)]	Loss: 0.860673
[2022-06-11 08:28:04 | train] - Train Epoch: [121] [371200/1281167 (29%)]	Loss: 0.918751
[2022-06-11 08:28:26 | train] - Train Epoch: [121] [384000/1281167 (30%)]	Loss: 0.877325
[2022-06-11 08:28:48 | train] - Train Epoch: [121] [396800/1281167 (31%)]	Loss: 0.682270
[2022-06-11 08:29:10 | train] - Train Epoch: [121] [409600/1281167 (32%)]	Loss: 0.599125
[2022-06-11 08:29:33 | train] - Train Epoch: [121] [422400/1281167 (33%)]	Loss: 0.828915
[2022-06-11 08:29:55 | train] - Train Epoch: [121] [435200/1281167 (34%)]	Loss: 0.703474
[2022-06-11 08:30:17 | train] - Train Epoch: [121] [448000/1281167 (35%)]	Loss: 1.058435
[2022-06-11 08:30:38 | train] - Train Epoch: [121] [460800/1281167 (36%)]	Loss: 0.715965
[2022-06-11 08:31:01 | train] - Train Epoch: [121] [473600/1281167 (37%)]	Loss: 0.592766
[2022-06-11 08:31:22 | train] - Train Epoch: [121] [486400/1281167 (38%)]	Loss: 0.772508
[2022-06-11 08:31:44 | train] - Train Epoch: [121] [499200/1281167 (39%)]	Loss: 0.872160
[2022-06-11 08:32:06 | train] - Train Epoch: [121] [512000/1281167 (40%)]	Loss: 0.852155
[2022-06-11 08:32:28 | train] - Train Epoch: [121] [524800/1281167 (41%)]	Loss: 0.944061
[2022-06-11 08:32:50 | train] - Train Epoch: [121] [537600/1281167 (42%)]	Loss: 0.585690
[2022-06-11 08:33:11 | train] - Train Epoch: [121] [550400/1281167 (43%)]	Loss: 0.700690
[2022-06-11 08:33:33 | train] - Train Epoch: [121] [563200/1281167 (44%)]	Loss: 0.733115
[2022-06-11 08:33:55 | train] - Train Epoch: [121] [576000/1281167 (45%)]	Loss: 0.703414
[2022-06-11 08:34:16 | train] - Train Epoch: [121] [588800/1281167 (46%)]	Loss: 0.541626
[2022-06-11 08:34:38 | train] - Train Epoch: [121] [601600/1281167 (47%)]	Loss: 0.882819
[2022-06-11 08:35:01 | train] - Train Epoch: [121] [614400/1281167 (48%)]	Loss: 0.687376
[2022-06-11 08:35:23 | train] - Train Epoch: [121] [627200/1281167 (49%)]	Loss: 0.553757
[2022-06-11 08:35:46 | train] - Train Epoch: [121] [640000/1281167 (50%)]	Loss: 0.805953
[2022-06-11 08:36:08 | train] - Train Epoch: [121] [652800/1281167 (51%)]	Loss: 0.834651
[2022-06-11 08:36:30 | train] - Train Epoch: [121] [665600/1281167 (52%)]	Loss: 0.681846
[2022-06-11 08:36:51 | train] - Train Epoch: [121] [678400/1281167 (53%)]	Loss: 0.717336
[2022-06-11 08:37:13 | train] - Train Epoch: [121] [691200/1281167 (54%)]	Loss: 0.592844
[2022-06-11 08:37:35 | train] - Train Epoch: [121] [704000/1281167 (55%)]	Loss: 1.005657
[2022-06-11 08:37:57 | train] - Train Epoch: [121] [716800/1281167 (56%)]	Loss: 0.571600
[2022-06-11 08:38:19 | train] - Train Epoch: [121] [729600/1281167 (57%)]	Loss: 0.555247
[2022-06-11 08:38:42 | train] - Train Epoch: [121] [742400/1281167 (58%)]	Loss: 0.702749
[2022-06-11 08:39:04 | train] - Train Epoch: [121] [755200/1281167 (59%)]	Loss: 0.758382
[2022-06-11 08:39:26 | train] - Train Epoch: [121] [768000/1281167 (60%)]	Loss: 0.783757
[2022-06-11 08:39:48 | train] - Train Epoch: [121] [780800/1281167 (61%)]	Loss: 0.943007
[2022-06-11 08:40:10 | train] - Train Epoch: [121] [793600/1281167 (62%)]	Loss: 0.824047
[2022-06-11 08:40:31 | train] - Train Epoch: [121] [806400/1281167 (63%)]	Loss: 0.903790
[2022-06-11 08:40:53 | train] - Train Epoch: [121] [819200/1281167 (64%)]	Loss: 0.830456
[2022-06-11 08:41:15 | train] - Train Epoch: [121] [832000/1281167 (65%)]	Loss: 0.757009
[2022-06-11 08:41:37 | train] - Train Epoch: [121] [844800/1281167 (66%)]	Loss: 0.897420
[2022-06-11 08:41:59 | train] - Train Epoch: [121] [857600/1281167 (67%)]	Loss: 0.705823
[2022-06-11 08:42:21 | train] - Train Epoch: [121] [870400/1281167 (68%)]	Loss: 0.797601
[2022-06-11 08:42:42 | train] - Train Epoch: [121] [883200/1281167 (69%)]	Loss: 0.511541
[2022-06-11 08:43:04 | train] - Train Epoch: [121] [896000/1281167 (70%)]	Loss: 0.772961
[2022-06-11 08:43:26 | train] - Train Epoch: [121] [908800/1281167 (71%)]	Loss: 0.698033
[2022-06-11 08:43:48 | train] - Train Epoch: [121] [921600/1281167 (72%)]	Loss: 0.574700
[2022-06-11 08:44:10 | train] - Train Epoch: [121] [934400/1281167 (73%)]	Loss: 1.018727
[2022-06-11 08:44:32 | train] - Train Epoch: [121] [947200/1281167 (74%)]	Loss: 0.944931
[2022-06-11 08:44:54 | train] - Train Epoch: [121] [960000/1281167 (75%)]	Loss: 0.584597
[2022-06-11 08:45:15 | train] - Train Epoch: [121] [972800/1281167 (76%)]	Loss: 0.645440
[2022-06-11 08:45:37 | train] - Train Epoch: [121] [985600/1281167 (77%)]	Loss: 0.618043
[2022-06-11 08:45:59 | train] - Train Epoch: [121] [998400/1281167 (78%)]	Loss: 0.707210
[2022-06-11 08:46:21 | train] - Train Epoch: [121] [1011200/1281167 (79%)]	Loss: 0.885867
[2022-06-11 08:46:43 | train] - Train Epoch: [121] [1024000/1281167 (80%)]	Loss: 0.891691
[2022-06-11 08:47:05 | train] - Train Epoch: [121] [1036800/1281167 (81%)]	Loss: 0.742619
[2022-06-11 08:47:26 | train] - Train Epoch: [121] [1049600/1281167 (82%)]	Loss: 0.524981
[2022-06-11 08:47:48 | train] - Train Epoch: [121] [1062400/1281167 (83%)]	Loss: 0.870345
[2022-06-11 08:48:09 | train] - Train Epoch: [121] [1075200/1281167 (84%)]	Loss: 0.791840
[2022-06-11 08:48:32 | train] - Train Epoch: [121] [1088000/1281167 (85%)]	Loss: 0.731559
[2022-06-11 08:48:54 | train] - Train Epoch: [121] [1100800/1281167 (86%)]	Loss: 0.614199
[2022-06-11 08:49:16 | train] - Train Epoch: [121] [1113600/1281167 (87%)]	Loss: 0.649066
[2022-06-11 08:49:38 | train] - Train Epoch: [121] [1126400/1281167 (88%)]	Loss: 0.732965
[2022-06-11 08:49:59 | train] - Train Epoch: [121] [1139200/1281167 (89%)]	Loss: 0.779953
[2022-06-11 08:50:21 | train] - Train Epoch: [121] [1152000/1281167 (90%)]	Loss: 0.730825
[2022-06-11 08:50:43 | train] - Train Epoch: [121] [1164800/1281167 (91%)]	Loss: 0.470895
[2022-06-11 08:51:05 | train] - Train Epoch: [121] [1177600/1281167 (92%)]	Loss: 0.799235
[2022-06-11 08:51:27 | train] - Train Epoch: [121] [1190400/1281167 (93%)]	Loss: 0.721360
[2022-06-11 08:51:49 | train] - Train Epoch: [121] [1203200/1281167 (94%)]	Loss: 0.660346
[2022-06-11 08:52:11 | train] - Train Epoch: [121] [1216000/1281167 (95%)]	Loss: 0.831517
[2022-06-11 08:52:33 | train] - Train Epoch: [121] [1228800/1281167 (96%)]	Loss: 0.975835
[2022-06-11 08:52:55 | train] - Train Epoch: [121] [1241600/1281167 (97%)]	Loss: 0.836268
[2022-06-11 08:53:16 | train] - Train Epoch: [121] [1254400/1281167 (98%)]	Loss: 0.753212
[2022-06-11 08:53:38 | train] - Train Epoch: [121] [1267200/1281167 (99%)]	Loss: 0.681146
[2022-06-11 08:54:00 | train] - Train Epoch: [121] [1280000/1281167 (100%)]	Loss: 0.937976
[2022-06-11 08:54:02 | train] - Train Epoch: [121]	 Average Loss: 0.776752	 Total Acc : 81.0780	 Total Top5 Acc : 93.0924
[2022-06-11 08:54:02 | train] - -------121 epoch end-----------
========================================
-------121 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 08:55:37 | train] - 
Epoch [121] Test set: Average loss: 1.4043, Accuracy: 35015/50000 (70.0012%), Top-5 Accuracy: 89.0569%

[2022-06-11 08:55:37 | train] - save intermediate epoch [121] result


[2022-06-11 08:55:39 | train] - logging best performance 121 epoch
[2022-06-11 08:55:41 | train] - -------122 epoch start-----------
========================================
----- test end -------------------------


logging best performance 121 epoch
[2022-06-11 08:55:43 | train] - Train Epoch: [122] [0/1281167 (0%)]	Loss: 0.695824
[2022-06-11 08:56:05 | train] - Train Epoch: [122] [12800/1281167 (1%)]	Loss: 0.791995
[2022-06-11 08:56:27 | train] - Train Epoch: [122] [25600/1281167 (2%)]	Loss: 0.882620
[2022-06-11 08:56:49 | train] - Train Epoch: [122] [38400/1281167 (3%)]	Loss: 0.698340
[2022-06-11 08:57:11 | train] - Train Epoch: [122] [51200/1281167 (4%)]	Loss: 1.133655
[2022-06-11 08:57:32 | train] - Train Epoch: [122] [64000/1281167 (5%)]	Loss: 0.685762
[2022-06-11 08:57:53 | train] - Train Epoch: [122] [76800/1281167 (6%)]	Loss: 0.706339
[2022-06-11 08:58:15 | train] - Train Epoch: [122] [89600/1281167 (7%)]	Loss: 0.954492
[2022-06-11 08:58:37 | train] - Train Epoch: [122] [102400/1281167 (8%)]	Loss: 0.826567
[2022-06-11 08:58:59 | train] - Train Epoch: [122] [115200/1281167 (9%)]	Loss: 0.935578
[2022-06-11 08:59:20 | train] - Train Epoch: [122] [128000/1281167 (10%)]	Loss: 0.639403
[2022-06-11 08:59:42 | train] - Train Epoch: [122] [140800/1281167 (11%)]	Loss: 0.678380
[2022-06-11 09:00:05 | train] - Train Epoch: [122] [153600/1281167 (12%)]	Loss: 1.196845
[2022-06-11 09:00:27 | train] - Train Epoch: [122] [166400/1281167 (13%)]	Loss: 0.915534
[2022-06-11 09:00:49 | train] - Train Epoch: [122] [179200/1281167 (14%)]	Loss: 0.636897
[2022-06-11 09:01:11 | train] - Train Epoch: [122] [192000/1281167 (15%)]	Loss: 0.758746
[2022-06-11 09:01:33 | train] - Train Epoch: [122] [204800/1281167 (16%)]	Loss: 0.651195
[2022-06-11 09:01:54 | train] - Train Epoch: [122] [217600/1281167 (17%)]	Loss: 0.820486
[2022-06-11 09:02:16 | train] - Train Epoch: [122] [230400/1281167 (18%)]	Loss: 0.635308
[2022-06-11 09:02:38 | train] - Train Epoch: [122] [243200/1281167 (19%)]	Loss: 0.603258
[2022-06-11 09:03:00 | train] - Train Epoch: [122] [256000/1281167 (20%)]	Loss: 0.903681
[2022-06-11 09:03:22 | train] - Train Epoch: [122] [268800/1281167 (21%)]	Loss: 0.586240
[2022-06-11 09:03:43 | train] - Train Epoch: [122] [281600/1281167 (22%)]	Loss: 0.606606
[2022-06-11 09:04:05 | train] - Train Epoch: [122] [294400/1281167 (23%)]	Loss: 0.671703
[2022-06-11 09:04:27 | train] - Train Epoch: [122] [307200/1281167 (24%)]	Loss: 0.791382
[2022-06-11 09:04:49 | train] - Train Epoch: [122] [320000/1281167 (25%)]	Loss: 0.567418
[2022-06-11 09:05:11 | train] - Train Epoch: [122] [332800/1281167 (26%)]	Loss: 1.150290
[2022-06-11 09:05:31 | train] - Train Epoch: [122] [345600/1281167 (27%)]	Loss: 0.519269
[2022-06-11 09:05:54 | train] - Train Epoch: [122] [358400/1281167 (28%)]	Loss: 0.915530
[2022-06-11 09:06:15 | train] - Train Epoch: [122] [371200/1281167 (29%)]	Loss: 0.753045
[2022-06-11 09:06:37 | train] - Train Epoch: [122] [384000/1281167 (30%)]	Loss: 1.022806
[2022-06-11 09:06:58 | train] - Train Epoch: [122] [396800/1281167 (31%)]	Loss: 1.113211
[2022-06-11 09:07:20 | train] - Train Epoch: [122] [409600/1281167 (32%)]	Loss: 0.794128
[2022-06-11 09:07:41 | train] - Train Epoch: [122] [422400/1281167 (33%)]	Loss: 0.887900
[2022-06-11 09:08:03 | train] - Train Epoch: [122] [435200/1281167 (34%)]	Loss: 0.617213
[2022-06-11 09:08:24 | train] - Train Epoch: [122] [448000/1281167 (35%)]	Loss: 0.607716
[2022-06-11 09:08:46 | train] - Train Epoch: [122] [460800/1281167 (36%)]	Loss: 0.839052
[2022-06-11 09:09:08 | train] - Train Epoch: [122] [473600/1281167 (37%)]	Loss: 0.669943
[2022-06-11 09:09:30 | train] - Train Epoch: [122] [486400/1281167 (38%)]	Loss: 0.870080
[2022-06-11 09:09:52 | train] - Train Epoch: [122] [499200/1281167 (39%)]	Loss: 0.891710
[2022-06-11 09:10:14 | train] - Train Epoch: [122] [512000/1281167 (40%)]	Loss: 1.035390
[2022-06-11 09:10:36 | train] - Train Epoch: [122] [524800/1281167 (41%)]	Loss: 0.381874
[2022-06-11 09:10:58 | train] - Train Epoch: [122] [537600/1281167 (42%)]	Loss: 0.496799
[2022-06-11 09:11:20 | train] - Train Epoch: [122] [550400/1281167 (43%)]	Loss: 0.808602
[2022-06-11 09:11:42 | train] - Train Epoch: [122] [563200/1281167 (44%)]	Loss: 0.558910
[2022-06-11 09:12:04 | train] - Train Epoch: [122] [576000/1281167 (45%)]	Loss: 0.659128
[2022-06-11 09:12:26 | train] - Train Epoch: [122] [588800/1281167 (46%)]	Loss: 0.719975
[2022-06-11 09:12:47 | train] - Train Epoch: [122] [601600/1281167 (47%)]	Loss: 0.652562
[2022-06-11 09:13:09 | train] - Train Epoch: [122] [614400/1281167 (48%)]	Loss: 0.673396
[2022-06-11 09:13:30 | train] - Train Epoch: [122] [627200/1281167 (49%)]	Loss: 0.618423
[2022-06-11 09:13:52 | train] - Train Epoch: [122] [640000/1281167 (50%)]	Loss: 0.753869
[2022-06-11 09:14:14 | train] - Train Epoch: [122] [652800/1281167 (51%)]	Loss: 0.744033
[2022-06-11 09:14:36 | train] - Train Epoch: [122] [665600/1281167 (52%)]	Loss: 0.639753
[2022-06-11 09:14:58 | train] - Train Epoch: [122] [678400/1281167 (53%)]	Loss: 0.977692
[2022-06-11 09:15:20 | train] - Train Epoch: [122] [691200/1281167 (54%)]	Loss: 0.752745
[2022-06-11 09:15:42 | train] - Train Epoch: [122] [704000/1281167 (55%)]	Loss: 0.634175
[2022-06-11 09:16:03 | train] - Train Epoch: [122] [716800/1281167 (56%)]	Loss: 0.810306
[2022-06-11 09:16:25 | train] - Train Epoch: [122] [729600/1281167 (57%)]	Loss: 0.851751
[2022-06-11 09:16:47 | train] - Train Epoch: [122] [742400/1281167 (58%)]	Loss: 0.875248
[2022-06-11 09:17:08 | train] - Train Epoch: [122] [755200/1281167 (59%)]	Loss: 0.826879
[2022-06-11 09:17:29 | train] - Train Epoch: [122] [768000/1281167 (60%)]	Loss: 0.775364
[2022-06-11 09:17:51 | train] - Train Epoch: [122] [780800/1281167 (61%)]	Loss: 0.653681
[2022-06-11 09:18:12 | train] - Train Epoch: [122] [793600/1281167 (62%)]	Loss: 1.001151
[2022-06-11 09:18:35 | train] - Train Epoch: [122] [806400/1281167 (63%)]	Loss: 0.670520
[2022-06-11 09:18:56 | train] - Train Epoch: [122] [819200/1281167 (64%)]	Loss: 0.679834
[2022-06-11 09:19:18 | train] - Train Epoch: [122] [832000/1281167 (65%)]	Loss: 0.591960
[2022-06-11 09:19:39 | train] - Train Epoch: [122] [844800/1281167 (66%)]	Loss: 0.833450
[2022-06-11 09:20:01 | train] - Train Epoch: [122] [857600/1281167 (67%)]	Loss: 0.606348
[2022-06-11 09:20:24 | train] - Train Epoch: [122] [870400/1281167 (68%)]	Loss: 0.662935
[2022-06-11 09:20:46 | train] - Train Epoch: [122] [883200/1281167 (69%)]	Loss: 0.638646
[2022-06-11 09:21:07 | train] - Train Epoch: [122] [896000/1281167 (70%)]	Loss: 0.684645
[2022-06-11 09:21:29 | train] - Train Epoch: [122] [908800/1281167 (71%)]	Loss: 0.845112
[2022-06-11 09:21:51 | train] - Train Epoch: [122] [921600/1281167 (72%)]	Loss: 0.897064
[2022-06-11 09:22:12 | train] - Train Epoch: [122] [934400/1281167 (73%)]	Loss: 0.587376
[2022-06-11 09:22:34 | train] - Train Epoch: [122] [947200/1281167 (74%)]	Loss: 0.682769
[2022-06-11 09:22:56 | train] - Train Epoch: [122] [960000/1281167 (75%)]	Loss: 0.874910
[2022-06-11 09:23:18 | train] - Train Epoch: [122] [972800/1281167 (76%)]	Loss: 0.663666
[2022-06-11 09:23:40 | train] - Train Epoch: [122] [985600/1281167 (77%)]	Loss: 0.624124
[2022-06-11 09:24:02 | train] - Train Epoch: [122] [998400/1281167 (78%)]	Loss: 0.752629
[2022-06-11 09:24:23 | train] - Train Epoch: [122] [1011200/1281167 (79%)]	Loss: 0.612399
[2022-06-11 09:24:45 | train] - Train Epoch: [122] [1024000/1281167 (80%)]	Loss: 0.741670
[2022-06-11 09:25:07 | train] - Train Epoch: [122] [1036800/1281167 (81%)]	Loss: 0.712340
[2022-06-11 09:25:29 | train] - Train Epoch: [122] [1049600/1281167 (82%)]	Loss: 0.875081
[2022-06-11 09:25:51 | train] - Train Epoch: [122] [1062400/1281167 (83%)]	Loss: 0.589673
[2022-06-11 09:26:14 | train] - Train Epoch: [122] [1075200/1281167 (84%)]	Loss: 0.831411
[2022-06-11 09:26:36 | train] - Train Epoch: [122] [1088000/1281167 (85%)]	Loss: 0.904088
[2022-06-11 09:26:57 | train] - Train Epoch: [122] [1100800/1281167 (86%)]	Loss: 0.635548
[2022-06-11 09:27:19 | train] - Train Epoch: [122] [1113600/1281167 (87%)]	Loss: 0.723720
[2022-06-11 09:27:42 | train] - Train Epoch: [122] [1126400/1281167 (88%)]	Loss: 0.998471
[2022-06-11 09:28:03 | train] - Train Epoch: [122] [1139200/1281167 (89%)]	Loss: 0.734514
[2022-06-11 09:28:25 | train] - Train Epoch: [122] [1152000/1281167 (90%)]	Loss: 0.515070
[2022-06-11 09:28:47 | train] - Train Epoch: [122] [1164800/1281167 (91%)]	Loss: 0.846564
[2022-06-11 09:29:09 | train] - Train Epoch: [122] [1177600/1281167 (92%)]	Loss: 0.900696
[2022-06-11 09:29:31 | train] - Train Epoch: [122] [1190400/1281167 (93%)]	Loss: 0.558098
[2022-06-11 09:29:53 | train] - Train Epoch: [122] [1203200/1281167 (94%)]	Loss: 0.853602
[2022-06-11 09:30:15 | train] - Train Epoch: [122] [1216000/1281167 (95%)]	Loss: 0.850245
[2022-06-11 09:30:37 | train] - Train Epoch: [122] [1228800/1281167 (96%)]	Loss: 0.947800
[2022-06-11 09:30:59 | train] - Train Epoch: [122] [1241600/1281167 (97%)]	Loss: 0.886013
[2022-06-11 09:31:21 | train] - Train Epoch: [122] [1254400/1281167 (98%)]	Loss: 0.611906
[2022-06-11 09:31:43 | train] - Train Epoch: [122] [1267200/1281167 (99%)]	Loss: 0.742525
[2022-06-11 09:32:05 | train] - Train Epoch: [122] [1280000/1281167 (100%)]	Loss: 0.748231
[2022-06-11 09:32:07 | train] - Train Epoch: [122]	 Average Loss: 0.769971	 Total Acc : 81.2151	 Total Top5 Acc : 93.1716
[2022-06-11 09:32:07 | train] - -------122 epoch end-----------
========================================
-------122 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 09:33:42 | train] - 
Epoch [122] Test set: Average loss: 1.4076, Accuracy: 34984/50000 (69.9345%), Top-5 Accuracy: 89.0421%

[2022-06-11 09:33:42 | train] - save intermediate epoch [122] result


[2022-06-11 09:33:45 | train] - -------123 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 09:33:47 | train] - Train Epoch: [123] [0/1281167 (0%)]	Loss: 1.049778
[2022-06-11 09:34:08 | train] - Train Epoch: [123] [12800/1281167 (1%)]	Loss: 0.688742
[2022-06-11 09:34:30 | train] - Train Epoch: [123] [25600/1281167 (2%)]	Loss: 0.622092
[2022-06-11 09:34:52 | train] - Train Epoch: [123] [38400/1281167 (3%)]	Loss: 1.034431
[2022-06-11 09:35:14 | train] - Train Epoch: [123] [51200/1281167 (4%)]	Loss: 0.662911
[2022-06-11 09:35:36 | train] - Train Epoch: [123] [64000/1281167 (5%)]	Loss: 0.812739
[2022-06-11 09:35:58 | train] - Train Epoch: [123] [76800/1281167 (6%)]	Loss: 0.703757
[2022-06-11 09:36:20 | train] - Train Epoch: [123] [89600/1281167 (7%)]	Loss: 0.571362
[2022-06-11 09:36:41 | train] - Train Epoch: [123] [102400/1281167 (8%)]	Loss: 0.865948
[2022-06-11 09:37:03 | train] - Train Epoch: [123] [115200/1281167 (9%)]	Loss: 0.396976
[2022-06-11 09:37:25 | train] - Train Epoch: [123] [128000/1281167 (10%)]	Loss: 0.783016
[2022-06-11 09:37:47 | train] - Train Epoch: [123] [140800/1281167 (11%)]	Loss: 0.726928
[2022-06-11 09:38:09 | train] - Train Epoch: [123] [153600/1281167 (12%)]	Loss: 0.591927
[2022-06-11 09:38:31 | train] - Train Epoch: [123] [166400/1281167 (13%)]	Loss: 0.798911
[2022-06-11 09:38:52 | train] - Train Epoch: [123] [179200/1281167 (14%)]	Loss: 0.509467
[2022-06-11 09:39:14 | train] - Train Epoch: [123] [192000/1281167 (15%)]	Loss: 0.810565
[2022-06-11 09:39:35 | train] - Train Epoch: [123] [204800/1281167 (16%)]	Loss: 0.754055
[2022-06-11 09:39:57 | train] - Train Epoch: [123] [217600/1281167 (17%)]	Loss: 0.849451
[2022-06-11 09:40:19 | train] - Train Epoch: [123] [230400/1281167 (18%)]	Loss: 0.645990
[2022-06-11 09:40:40 | train] - Train Epoch: [123] [243200/1281167 (19%)]	Loss: 0.619148
[2022-06-11 09:41:03 | train] - Train Epoch: [123] [256000/1281167 (20%)]	Loss: 0.718350
[2022-06-11 09:41:25 | train] - Train Epoch: [123] [268800/1281167 (21%)]	Loss: 0.911301
[2022-06-11 09:41:47 | train] - Train Epoch: [123] [281600/1281167 (22%)]	Loss: 0.937743
[2022-06-11 09:42:09 | train] - Train Epoch: [123] [294400/1281167 (23%)]	Loss: 0.617897
[2022-06-11 09:42:32 | train] - Train Epoch: [123] [307200/1281167 (24%)]	Loss: 0.872220
[2022-06-11 09:42:54 | train] - Train Epoch: [123] [320000/1281167 (25%)]	Loss: 0.876156
[2022-06-11 09:43:16 | train] - Train Epoch: [123] [332800/1281167 (26%)]	Loss: 0.887164
[2022-06-11 09:43:38 | train] - Train Epoch: [123] [345600/1281167 (27%)]	Loss: 0.869668
[2022-06-11 09:44:01 | train] - Train Epoch: [123] [358400/1281167 (28%)]	Loss: 0.710686
[2022-06-11 09:44:23 | train] - Train Epoch: [123] [371200/1281167 (29%)]	Loss: 0.989789
[2022-06-11 09:44:46 | train] - Train Epoch: [123] [384000/1281167 (30%)]	Loss: 0.568280
[2022-06-11 09:45:08 | train] - Train Epoch: [123] [396800/1281167 (31%)]	Loss: 0.635445
[2022-06-11 09:45:30 | train] - Train Epoch: [123] [409600/1281167 (32%)]	Loss: 0.464657
[2022-06-11 09:45:52 | train] - Train Epoch: [123] [422400/1281167 (33%)]	Loss: 0.619359
[2022-06-11 09:46:14 | train] - Train Epoch: [123] [435200/1281167 (34%)]	Loss: 0.910959
[2022-06-11 09:46:37 | train] - Train Epoch: [123] [448000/1281167 (35%)]	Loss: 0.903560
[2022-06-11 09:46:58 | train] - Train Epoch: [123] [460800/1281167 (36%)]	Loss: 0.904393
[2022-06-11 09:47:20 | train] - Train Epoch: [123] [473600/1281167 (37%)]	Loss: 0.820078
[2022-06-11 09:47:42 | train] - Train Epoch: [123] [486400/1281167 (38%)]	Loss: 0.695310
[2022-06-11 09:48:04 | train] - Train Epoch: [123] [499200/1281167 (39%)]	Loss: 0.792583
[2022-06-11 09:48:26 | train] - Train Epoch: [123] [512000/1281167 (40%)]	Loss: 1.190439
[2022-06-11 09:48:48 | train] - Train Epoch: [123] [524800/1281167 (41%)]	Loss: 0.589989
[2022-06-11 09:49:10 | train] - Train Epoch: [123] [537600/1281167 (42%)]	Loss: 0.825107
[2022-06-11 09:49:32 | train] - Train Epoch: [123] [550400/1281167 (43%)]	Loss: 0.776689
[2022-06-11 09:49:54 | train] - Train Epoch: [123] [563200/1281167 (44%)]	Loss: 0.877200
[2022-06-11 09:50:15 | train] - Train Epoch: [123] [576000/1281167 (45%)]	Loss: 0.867193
[2022-06-11 09:50:36 | train] - Train Epoch: [123] [588800/1281167 (46%)]	Loss: 0.515693
[2022-06-11 09:50:58 | train] - Train Epoch: [123] [601600/1281167 (47%)]	Loss: 0.749921
[2022-06-11 09:51:20 | train] - Train Epoch: [123] [614400/1281167 (48%)]	Loss: 0.959873
[2022-06-11 09:51:41 | train] - Train Epoch: [123] [627200/1281167 (49%)]	Loss: 0.996460
[2022-06-11 09:52:02 | train] - Train Epoch: [123] [640000/1281167 (50%)]	Loss: 0.814507
[2022-06-11 09:52:24 | train] - Train Epoch: [123] [652800/1281167 (51%)]	Loss: 1.083485
[2022-06-11 09:52:46 | train] - Train Epoch: [123] [665600/1281167 (52%)]	Loss: 0.665158
[2022-06-11 09:53:07 | train] - Train Epoch: [123] [678400/1281167 (53%)]	Loss: 0.588936
[2022-06-11 09:53:29 | train] - Train Epoch: [123] [691200/1281167 (54%)]	Loss: 0.790385
[2022-06-11 09:53:50 | train] - Train Epoch: [123] [704000/1281167 (55%)]	Loss: 0.533609
[2022-06-11 09:54:13 | train] - Train Epoch: [123] [716800/1281167 (56%)]	Loss: 0.577756
[2022-06-11 09:54:34 | train] - Train Epoch: [123] [729600/1281167 (57%)]	Loss: 0.796727
[2022-06-11 09:54:56 | train] - Train Epoch: [123] [742400/1281167 (58%)]	Loss: 0.694258
[2022-06-11 09:55:18 | train] - Train Epoch: [123] [755200/1281167 (59%)]	Loss: 0.779712
[2022-06-11 09:55:39 | train] - Train Epoch: [123] [768000/1281167 (60%)]	Loss: 0.921304
[2022-06-11 09:56:01 | train] - Train Epoch: [123] [780800/1281167 (61%)]	Loss: 0.868481
[2022-06-11 09:56:23 | train] - Train Epoch: [123] [793600/1281167 (62%)]	Loss: 0.615438
[2022-06-11 09:56:43 | train] - Train Epoch: [123] [806400/1281167 (63%)]	Loss: 0.655456
[2022-06-11 09:57:05 | train] - Train Epoch: [123] [819200/1281167 (64%)]	Loss: 0.913091
[2022-06-11 09:57:27 | train] - Train Epoch: [123] [832000/1281167 (65%)]	Loss: 0.853076
[2022-06-11 09:57:48 | train] - Train Epoch: [123] [844800/1281167 (66%)]	Loss: 0.899009
[2022-06-11 09:58:09 | train] - Train Epoch: [123] [857600/1281167 (67%)]	Loss: 0.687846
[2022-06-11 09:58:30 | train] - Train Epoch: [123] [870400/1281167 (68%)]	Loss: 0.497582
[2022-06-11 09:58:52 | train] - Train Epoch: [123] [883200/1281167 (69%)]	Loss: 0.838636
[2022-06-11 09:59:13 | train] - Train Epoch: [123] [896000/1281167 (70%)]	Loss: 0.672994
[2022-06-11 09:59:35 | train] - Train Epoch: [123] [908800/1281167 (71%)]	Loss: 0.963669
[2022-06-11 09:59:56 | train] - Train Epoch: [123] [921600/1281167 (72%)]	Loss: 0.897186
[2022-06-11 10:00:18 | train] - Train Epoch: [123] [934400/1281167 (73%)]	Loss: 0.644741
[2022-06-11 10:00:40 | train] - Train Epoch: [123] [947200/1281167 (74%)]	Loss: 0.824139
[2022-06-11 10:01:01 | train] - Train Epoch: [123] [960000/1281167 (75%)]	Loss: 0.634608
[2022-06-11 10:01:22 | train] - Train Epoch: [123] [972800/1281167 (76%)]	Loss: 0.851105
[2022-06-11 10:01:43 | train] - Train Epoch: [123] [985600/1281167 (77%)]	Loss: 0.640714
[2022-06-11 10:02:05 | train] - Train Epoch: [123] [998400/1281167 (78%)]	Loss: 0.698230
[2022-06-11 10:02:27 | train] - Train Epoch: [123] [1011200/1281167 (79%)]	Loss: 0.816375
[2022-06-11 10:02:49 | train] - Train Epoch: [123] [1024000/1281167 (80%)]	Loss: 0.571638
[2022-06-11 10:03:10 | train] - Train Epoch: [123] [1036800/1281167 (81%)]	Loss: 0.748259
[2022-06-11 10:03:32 | train] - Train Epoch: [123] [1049600/1281167 (82%)]	Loss: 0.729322
[2022-06-11 10:03:54 | train] - Train Epoch: [123] [1062400/1281167 (83%)]	Loss: 0.867566
[2022-06-11 10:04:15 | train] - Train Epoch: [123] [1075200/1281167 (84%)]	Loss: 0.768261
[2022-06-11 10:04:37 | train] - Train Epoch: [123] [1088000/1281167 (85%)]	Loss: 0.909932
[2022-06-11 10:04:59 | train] - Train Epoch: [123] [1100800/1281167 (86%)]	Loss: 0.909677
[2022-06-11 10:05:20 | train] - Train Epoch: [123] [1113600/1281167 (87%)]	Loss: 0.808335
[2022-06-11 10:05:42 | train] - Train Epoch: [123] [1126400/1281167 (88%)]	Loss: 0.526143
[2022-06-11 10:06:04 | train] - Train Epoch: [123] [1139200/1281167 (89%)]	Loss: 0.726409
[2022-06-11 10:06:25 | train] - Train Epoch: [123] [1152000/1281167 (90%)]	Loss: 0.799782
[2022-06-11 10:06:47 | train] - Train Epoch: [123] [1164800/1281167 (91%)]	Loss: 0.651522
[2022-06-11 10:07:09 | train] - Train Epoch: [123] [1177600/1281167 (92%)]	Loss: 0.698400
[2022-06-11 10:07:31 | train] - Train Epoch: [123] [1190400/1281167 (93%)]	Loss: 0.779242
[2022-06-11 10:07:52 | train] - Train Epoch: [123] [1203200/1281167 (94%)]	Loss: 0.634872
[2022-06-11 10:08:13 | train] - Train Epoch: [123] [1216000/1281167 (95%)]	Loss: 0.629481
[2022-06-11 10:08:35 | train] - Train Epoch: [123] [1228800/1281167 (96%)]	Loss: 0.896311
[2022-06-11 10:08:56 | train] - Train Epoch: [123] [1241600/1281167 (97%)]	Loss: 1.000779
[2022-06-11 10:09:18 | train] - Train Epoch: [123] [1254400/1281167 (98%)]	Loss: 0.811616
[2022-06-11 10:09:39 | train] - Train Epoch: [123] [1267200/1281167 (99%)]	Loss: 0.766948
[2022-06-11 10:10:00 | train] - Train Epoch: [123] [1280000/1281167 (100%)]	Loss: 0.905346
[2022-06-11 10:10:02 | train] - Train Epoch: [123]	 Average Loss: 0.767737	 Total Acc : 81.2650	 Total Top5 Acc : 93.2031
[2022-06-11 10:10:02 | train] - -------123 epoch end-----------
========================================
-------123 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 10:11:36 | train] - 
Epoch [123] Test set: Average loss: 1.4049, Accuracy: 34972/50000 (69.9133%), Top-5 Accuracy: 89.0082%

[2022-06-11 10:11:36 | train] - save intermediate epoch [123] result


[2022-06-11 10:11:39 | train] - -------124 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 10:11:41 | train] - Train Epoch: [124] [0/1281167 (0%)]	Loss: 0.746523
[2022-06-11 10:12:03 | train] - Train Epoch: [124] [12800/1281167 (1%)]	Loss: 0.940543
[2022-06-11 10:12:23 | train] - Train Epoch: [124] [25600/1281167 (2%)]	Loss: 0.648146
[2022-06-11 10:12:45 | train] - Train Epoch: [124] [38400/1281167 (3%)]	Loss: 0.802656
[2022-06-11 10:13:07 | train] - Train Epoch: [124] [51200/1281167 (4%)]	Loss: 0.653118
[2022-06-11 10:13:28 | train] - Train Epoch: [124] [64000/1281167 (5%)]	Loss: 0.834806
[2022-06-11 10:13:50 | train] - Train Epoch: [124] [76800/1281167 (6%)]	Loss: 0.578775
[2022-06-11 10:14:11 | train] - Train Epoch: [124] [89600/1281167 (7%)]	Loss: 0.625042
[2022-06-11 10:14:33 | train] - Train Epoch: [124] [102400/1281167 (8%)]	Loss: 0.614016
[2022-06-11 10:14:55 | train] - Train Epoch: [124] [115200/1281167 (9%)]	Loss: 0.788151
[2022-06-11 10:15:17 | train] - Train Epoch: [124] [128000/1281167 (10%)]	Loss: 0.724000
[2022-06-11 10:15:38 | train] - Train Epoch: [124] [140800/1281167 (11%)]	Loss: 0.952078
[2022-06-11 10:16:00 | train] - Train Epoch: [124] [153600/1281167 (12%)]	Loss: 0.675129
[2022-06-11 10:16:22 | train] - Train Epoch: [124] [166400/1281167 (13%)]	Loss: 0.821069
[2022-06-11 10:16:43 | train] - Train Epoch: [124] [179200/1281167 (14%)]	Loss: 0.644190
[2022-06-11 10:17:05 | train] - Train Epoch: [124] [192000/1281167 (15%)]	Loss: 0.746882
[2022-06-11 10:17:27 | train] - Train Epoch: [124] [204800/1281167 (16%)]	Loss: 0.848232
[2022-06-11 10:17:49 | train] - Train Epoch: [124] [217600/1281167 (17%)]	Loss: 0.891381
[2022-06-11 10:18:11 | train] - Train Epoch: [124] [230400/1281167 (18%)]	Loss: 0.710890
[2022-06-11 10:18:32 | train] - Train Epoch: [124] [243200/1281167 (19%)]	Loss: 0.612046
[2022-06-11 10:18:54 | train] - Train Epoch: [124] [256000/1281167 (20%)]	Loss: 0.684822
[2022-06-11 10:19:15 | train] - Train Epoch: [124] [268800/1281167 (21%)]	Loss: 0.539541
[2022-06-11 10:19:37 | train] - Train Epoch: [124] [281600/1281167 (22%)]	Loss: 0.863006
[2022-06-11 10:19:58 | train] - Train Epoch: [124] [294400/1281167 (23%)]	Loss: 0.814313
[2022-06-11 10:20:19 | train] - Train Epoch: [124] [307200/1281167 (24%)]	Loss: 0.811802
[2022-06-11 10:20:41 | train] - Train Epoch: [124] [320000/1281167 (25%)]	Loss: 0.404537
[2022-06-11 10:21:03 | train] - Train Epoch: [124] [332800/1281167 (26%)]	Loss: 0.869225
[2022-06-11 10:21:23 | train] - Train Epoch: [124] [345600/1281167 (27%)]	Loss: 0.867012
[2022-06-11 10:21:44 | train] - Train Epoch: [124] [358400/1281167 (28%)]	Loss: 0.813483
[2022-06-11 10:22:06 | train] - Train Epoch: [124] [371200/1281167 (29%)]	Loss: 1.010629
[2022-06-11 10:22:27 | train] - Train Epoch: [124] [384000/1281167 (30%)]	Loss: 0.701900
[2022-06-11 10:22:49 | train] - Train Epoch: [124] [396800/1281167 (31%)]	Loss: 0.743777
[2022-06-11 10:23:10 | train] - Train Epoch: [124] [409600/1281167 (32%)]	Loss: 0.957445
[2022-06-11 10:23:32 | train] - Train Epoch: [124] [422400/1281167 (33%)]	Loss: 0.806330
[2022-06-11 10:23:54 | train] - Train Epoch: [124] [435200/1281167 (34%)]	Loss: 0.715990
[2022-06-11 10:24:15 | train] - Train Epoch: [124] [448000/1281167 (35%)]	Loss: 0.705250
[2022-06-11 10:24:37 | train] - Train Epoch: [124] [460800/1281167 (36%)]	Loss: 0.932178
[2022-06-11 10:24:59 | train] - Train Epoch: [124] [473600/1281167 (37%)]	Loss: 0.690808
[2022-06-11 10:25:20 | train] - Train Epoch: [124] [486400/1281167 (38%)]	Loss: 0.839905
[2022-06-11 10:25:42 | train] - Train Epoch: [124] [499200/1281167 (39%)]	Loss: 0.735726
[2022-06-11 10:26:03 | train] - Train Epoch: [124] [512000/1281167 (40%)]	Loss: 0.740928
[2022-06-11 10:26:24 | train] - Train Epoch: [124] [524800/1281167 (41%)]	Loss: 0.722823
[2022-06-11 10:26:45 | train] - Train Epoch: [124] [537600/1281167 (42%)]	Loss: 0.846026
[2022-06-11 10:27:07 | train] - Train Epoch: [124] [550400/1281167 (43%)]	Loss: 0.742004
[2022-06-11 10:27:28 | train] - Train Epoch: [124] [563200/1281167 (44%)]	Loss: 0.777155
[2022-06-11 10:27:49 | train] - Train Epoch: [124] [576000/1281167 (45%)]	Loss: 0.727628
[2022-06-11 10:28:11 | train] - Train Epoch: [124] [588800/1281167 (46%)]	Loss: 0.825508
[2022-06-11 10:28:33 | train] - Train Epoch: [124] [601600/1281167 (47%)]	Loss: 0.653220
[2022-06-11 10:28:55 | train] - Train Epoch: [124] [614400/1281167 (48%)]	Loss: 0.980085
[2022-06-11 10:29:16 | train] - Train Epoch: [124] [627200/1281167 (49%)]	Loss: 0.888637
[2022-06-11 10:29:37 | train] - Train Epoch: [124] [640000/1281167 (50%)]	Loss: 0.853365
[2022-06-11 10:29:58 | train] - Train Epoch: [124] [652800/1281167 (51%)]	Loss: 0.951881
[2022-06-11 10:30:20 | train] - Train Epoch: [124] [665600/1281167 (52%)]	Loss: 0.723859
[2022-06-11 10:30:42 | train] - Train Epoch: [124] [678400/1281167 (53%)]	Loss: 0.792544
[2022-06-11 10:31:03 | train] - Train Epoch: [124] [691200/1281167 (54%)]	Loss: 0.500017
[2022-06-11 10:31:24 | train] - Train Epoch: [124] [704000/1281167 (55%)]	Loss: 0.978144
[2022-06-11 10:31:46 | train] - Train Epoch: [124] [716800/1281167 (56%)]	Loss: 0.780392
[2022-06-11 10:32:08 | train] - Train Epoch: [124] [729600/1281167 (57%)]	Loss: 0.719604
[2022-06-11 10:32:30 | train] - Train Epoch: [124] [742400/1281167 (58%)]	Loss: 0.662352
[2022-06-11 10:32:51 | train] - Train Epoch: [124] [755200/1281167 (59%)]	Loss: 0.612419
[2022-06-11 10:33:11 | train] - Train Epoch: [124] [768000/1281167 (60%)]	Loss: 0.597745
[2022-06-11 10:33:33 | train] - Train Epoch: [124] [780800/1281167 (61%)]	Loss: 0.633412
[2022-06-11 10:33:54 | train] - Train Epoch: [124] [793600/1281167 (62%)]	Loss: 0.650741
[2022-06-11 10:34:16 | train] - Train Epoch: [124] [806400/1281167 (63%)]	Loss: 0.641314
[2022-06-11 10:34:38 | train] - Train Epoch: [124] [819200/1281167 (64%)]	Loss: 0.658905
[2022-06-11 10:34:59 | train] - Train Epoch: [124] [832000/1281167 (65%)]	Loss: 1.075232
[2022-06-11 10:35:21 | train] - Train Epoch: [124] [844800/1281167 (66%)]	Loss: 0.683275
[2022-06-11 10:35:43 | train] - Train Epoch: [124] [857600/1281167 (67%)]	Loss: 0.853745
[2022-06-11 10:36:05 | train] - Train Epoch: [124] [870400/1281167 (68%)]	Loss: 1.034951
[2022-06-11 10:36:26 | train] - Train Epoch: [124] [883200/1281167 (69%)]	Loss: 0.741415
[2022-06-11 10:36:48 | train] - Train Epoch: [124] [896000/1281167 (70%)]	Loss: 0.587673
[2022-06-11 10:37:09 | train] - Train Epoch: [124] [908800/1281167 (71%)]	Loss: 0.876278
[2022-06-11 10:37:30 | train] - Train Epoch: [124] [921600/1281167 (72%)]	Loss: 0.994663
[2022-06-11 10:37:52 | train] - Train Epoch: [124] [934400/1281167 (73%)]	Loss: 0.584899
[2022-06-11 10:38:14 | train] - Train Epoch: [124] [947200/1281167 (74%)]	Loss: 0.950835
[2022-06-11 10:38:35 | train] - Train Epoch: [124] [960000/1281167 (75%)]	Loss: 0.924480
[2022-06-11 10:38:55 | train] - Train Epoch: [124] [972800/1281167 (76%)]	Loss: 0.768609
[2022-06-11 10:39:16 | train] - Train Epoch: [124] [985600/1281167 (77%)]	Loss: 0.521486
[2022-06-11 10:39:38 | train] - Train Epoch: [124] [998400/1281167 (78%)]	Loss: 0.649325
[2022-06-11 10:39:59 | train] - Train Epoch: [124] [1011200/1281167 (79%)]	Loss: 0.883891
[2022-06-11 10:40:21 | train] - Train Epoch: [124] [1024000/1281167 (80%)]	Loss: 0.698490
[2022-06-11 10:40:42 | train] - Train Epoch: [124] [1036800/1281167 (81%)]	Loss: 0.876418
[2022-06-11 10:41:03 | train] - Train Epoch: [124] [1049600/1281167 (82%)]	Loss: 0.957824
[2022-06-11 10:41:24 | train] - Train Epoch: [124] [1062400/1281167 (83%)]	Loss: 0.835862
[2022-06-11 10:41:46 | train] - Train Epoch: [124] [1075200/1281167 (84%)]	Loss: 0.899217
[2022-06-11 10:42:08 | train] - Train Epoch: [124] [1088000/1281167 (85%)]	Loss: 0.875819
[2022-06-11 10:42:29 | train] - Train Epoch: [124] [1100800/1281167 (86%)]	Loss: 1.015617
[2022-06-11 10:42:51 | train] - Train Epoch: [124] [1113600/1281167 (87%)]	Loss: 0.687510
[2022-06-11 10:43:13 | train] - Train Epoch: [124] [1126400/1281167 (88%)]	Loss: 0.618497
[2022-06-11 10:43:35 | train] - Train Epoch: [124] [1139200/1281167 (89%)]	Loss: 0.749280
[2022-06-11 10:43:57 | train] - Train Epoch: [124] [1152000/1281167 (90%)]	Loss: 0.632661
[2022-06-11 10:44:18 | train] - Train Epoch: [124] [1164800/1281167 (91%)]	Loss: 0.864004
[2022-06-11 10:44:40 | train] - Train Epoch: [124] [1177600/1281167 (92%)]	Loss: 0.746287
[2022-06-11 10:45:01 | train] - Train Epoch: [124] [1190400/1281167 (93%)]	Loss: 0.990068
[2022-06-11 10:45:23 | train] - Train Epoch: [124] [1203200/1281167 (94%)]	Loss: 0.908275
[2022-06-11 10:45:44 | train] - Train Epoch: [124] [1216000/1281167 (95%)]	Loss: 0.711325
[2022-06-11 10:46:06 | train] - Train Epoch: [124] [1228800/1281167 (96%)]	Loss: 0.790411
[2022-06-11 10:46:28 | train] - Train Epoch: [124] [1241600/1281167 (97%)]	Loss: 0.688153
[2022-06-11 10:46:49 | train] - Train Epoch: [124] [1254400/1281167 (98%)]	Loss: 0.651000
[2022-06-11 10:47:10 | train] - Train Epoch: [124] [1267200/1281167 (99%)]	Loss: 0.876872
[2022-06-11 10:47:31 | train] - Train Epoch: [124] [1280000/1281167 (100%)]	Loss: 0.833289
[2022-06-11 10:47:33 | train] - Train Epoch: [124]	 Average Loss: 0.764704	 Total Acc : 81.3745	 Total Top5 Acc : 93.2292
[2022-06-11 10:47:33 | train] - -------124 epoch end-----------
========================================
-------124 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 10:49:07 | train] - 
Epoch [124] Test set: Average loss: 1.4024, Accuracy: 35014/50000 (69.9992%), Top-5 Accuracy: 89.0497%

[2022-06-11 10:49:07 | train] - save intermediate epoch [124] result


[2022-06-11 10:49:12 | train] - -------125 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 10:49:14 | train] - Train Epoch: [125] [0/1281167 (0%)]	Loss: 0.746831
[2022-06-11 10:49:36 | train] - Train Epoch: [125] [12800/1281167 (1%)]	Loss: 0.917004
[2022-06-11 10:49:57 | train] - Train Epoch: [125] [25600/1281167 (2%)]	Loss: 0.641948
[2022-06-11 10:50:18 | train] - Train Epoch: [125] [38400/1281167 (3%)]	Loss: 0.695136
[2022-06-11 10:50:40 | train] - Train Epoch: [125] [51200/1281167 (4%)]	Loss: 0.705683
[2022-06-11 10:51:01 | train] - Train Epoch: [125] [64000/1281167 (5%)]	Loss: 0.789305
[2022-06-11 10:51:23 | train] - Train Epoch: [125] [76800/1281167 (6%)]	Loss: 0.731975
[2022-06-11 10:51:45 | train] - Train Epoch: [125] [89600/1281167 (7%)]	Loss: 0.756540
[2022-06-11 10:52:06 | train] - Train Epoch: [125] [102400/1281167 (8%)]	Loss: 0.722662
[2022-06-11 10:52:27 | train] - Train Epoch: [125] [115200/1281167 (9%)]	Loss: 0.709087
[2022-06-11 10:52:48 | train] - Train Epoch: [125] [128000/1281167 (10%)]	Loss: 0.591761
[2022-06-11 10:53:10 | train] - Train Epoch: [125] [140800/1281167 (11%)]	Loss: 0.684836
[2022-06-11 10:53:31 | train] - Train Epoch: [125] [153600/1281167 (12%)]	Loss: 1.046574
[2022-06-11 10:53:54 | train] - Train Epoch: [125] [166400/1281167 (13%)]	Loss: 0.765945
[2022-06-11 10:54:15 | train] - Train Epoch: [125] [179200/1281167 (14%)]	Loss: 0.784433
[2022-06-11 10:54:37 | train] - Train Epoch: [125] [192000/1281167 (15%)]	Loss: 0.962949
[2022-06-11 10:54:59 | train] - Train Epoch: [125] [204800/1281167 (16%)]	Loss: 1.034254
[2022-06-11 10:55:20 | train] - Train Epoch: [125] [217600/1281167 (17%)]	Loss: 0.916529
[2022-06-11 10:55:42 | train] - Train Epoch: [125] [230400/1281167 (18%)]	Loss: 0.896530
[2022-06-11 10:56:04 | train] - Train Epoch: [125] [243200/1281167 (19%)]	Loss: 0.650416
[2022-06-11 10:56:25 | train] - Train Epoch: [125] [256000/1281167 (20%)]	Loss: 0.758622
[2022-06-11 10:56:47 | train] - Train Epoch: [125] [268800/1281167 (21%)]	Loss: 0.449189
[2022-06-11 10:57:09 | train] - Train Epoch: [125] [281600/1281167 (22%)]	Loss: 0.790410
[2022-06-11 10:57:30 | train] - Train Epoch: [125] [294400/1281167 (23%)]	Loss: 0.682799
[2022-06-11 10:57:51 | train] - Train Epoch: [125] [307200/1281167 (24%)]	Loss: 0.629209
[2022-06-11 10:58:13 | train] - Train Epoch: [125] [320000/1281167 (25%)]	Loss: 0.897884
[2022-06-11 10:58:34 | train] - Train Epoch: [125] [332800/1281167 (26%)]	Loss: 0.765912
[2022-06-11 10:58:55 | train] - Train Epoch: [125] [345600/1281167 (27%)]	Loss: 0.700179
[2022-06-11 10:59:17 | train] - Train Epoch: [125] [358400/1281167 (28%)]	Loss: 0.635881
[2022-06-11 10:59:39 | train] - Train Epoch: [125] [371200/1281167 (29%)]	Loss: 0.768761
[2022-06-11 11:00:01 | train] - Train Epoch: [125] [384000/1281167 (30%)]	Loss: 0.899213
[2022-06-11 11:00:23 | train] - Train Epoch: [125] [396800/1281167 (31%)]	Loss: 0.780452
[2022-06-11 11:00:45 | train] - Train Epoch: [125] [409600/1281167 (32%)]	Loss: 0.759438
[2022-06-11 11:01:06 | train] - Train Epoch: [125] [422400/1281167 (33%)]	Loss: 0.806093
[2022-06-11 11:01:28 | train] - Train Epoch: [125] [435200/1281167 (34%)]	Loss: 0.782088
[2022-06-11 11:01:49 | train] - Train Epoch: [125] [448000/1281167 (35%)]	Loss: 0.836254
[2022-06-11 11:02:11 | train] - Train Epoch: [125] [460800/1281167 (36%)]	Loss: 0.644958
[2022-06-11 11:02:32 | train] - Train Epoch: [125] [473600/1281167 (37%)]	Loss: 0.621099
[2022-06-11 11:02:55 | train] - Train Epoch: [125] [486400/1281167 (38%)]	Loss: 0.656944
[2022-06-11 11:03:16 | train] - Train Epoch: [125] [499200/1281167 (39%)]	Loss: 0.747873
[2022-06-11 11:03:37 | train] - Train Epoch: [125] [512000/1281167 (40%)]	Loss: 0.559309
[2022-06-11 11:03:58 | train] - Train Epoch: [125] [524800/1281167 (41%)]	Loss: 1.088728
[2022-06-11 11:04:20 | train] - Train Epoch: [125] [537600/1281167 (42%)]	Loss: 0.647242
[2022-06-11 11:04:41 | train] - Train Epoch: [125] [550400/1281167 (43%)]	Loss: 0.701459
[2022-06-11 11:05:03 | train] - Train Epoch: [125] [563200/1281167 (44%)]	Loss: 0.891248
[2022-06-11 11:05:24 | train] - Train Epoch: [125] [576000/1281167 (45%)]	Loss: 0.812347
[2022-06-11 11:05:46 | train] - Train Epoch: [125] [588800/1281167 (46%)]	Loss: 0.881256
[2022-06-11 11:06:09 | train] - Train Epoch: [125] [601600/1281167 (47%)]	Loss: 0.711414
[2022-06-11 11:06:31 | train] - Train Epoch: [125] [614400/1281167 (48%)]	Loss: 0.536176
[2022-06-11 11:06:52 | train] - Train Epoch: [125] [627200/1281167 (49%)]	Loss: 0.811870
[2022-06-11 11:07:13 | train] - Train Epoch: [125] [640000/1281167 (50%)]	Loss: 0.999726
[2022-06-11 11:07:35 | train] - Train Epoch: [125] [652800/1281167 (51%)]	Loss: 0.695724
[2022-06-11 11:07:56 | train] - Train Epoch: [125] [665600/1281167 (52%)]	Loss: 0.604744
[2022-06-11 11:08:18 | train] - Train Epoch: [125] [678400/1281167 (53%)]	Loss: 1.052530
[2022-06-11 11:08:40 | train] - Train Epoch: [125] [691200/1281167 (54%)]	Loss: 0.771322
[2022-06-11 11:09:01 | train] - Train Epoch: [125] [704000/1281167 (55%)]	Loss: 0.783746
[2022-06-11 11:09:22 | train] - Train Epoch: [125] [716800/1281167 (56%)]	Loss: 0.593923
[2022-06-11 11:09:44 | train] - Train Epoch: [125] [729600/1281167 (57%)]	Loss: 0.931814
[2022-06-11 11:10:06 | train] - Train Epoch: [125] [742400/1281167 (58%)]	Loss: 0.692786
[2022-06-11 11:10:27 | train] - Train Epoch: [125] [755200/1281167 (59%)]	Loss: 0.446189
[2022-06-11 11:10:48 | train] - Train Epoch: [125] [768000/1281167 (60%)]	Loss: 0.846120
[2022-06-11 11:11:09 | train] - Train Epoch: [125] [780800/1281167 (61%)]	Loss: 0.466288
[2022-06-11 11:11:32 | train] - Train Epoch: [125] [793600/1281167 (62%)]	Loss: 0.809267
[2022-06-11 11:11:53 | train] - Train Epoch: [125] [806400/1281167 (63%)]	Loss: 0.764665
[2022-06-11 11:12:14 | train] - Train Epoch: [125] [819200/1281167 (64%)]	Loss: 0.783084
[2022-06-11 11:12:35 | train] - Train Epoch: [125] [832000/1281167 (65%)]	Loss: 0.774681
[2022-06-11 11:12:57 | train] - Train Epoch: [125] [844800/1281167 (66%)]	Loss: 0.566055
[2022-06-11 11:13:20 | train] - Train Epoch: [125] [857600/1281167 (67%)]	Loss: 0.858645
[2022-06-11 11:13:42 | train] - Train Epoch: [125] [870400/1281167 (68%)]	Loss: 0.705323
[2022-06-11 11:14:03 | train] - Train Epoch: [125] [883200/1281167 (69%)]	Loss: 0.973814
[2022-06-11 11:14:25 | train] - Train Epoch: [125] [896000/1281167 (70%)]	Loss: 0.761148
[2022-06-11 11:14:46 | train] - Train Epoch: [125] [908800/1281167 (71%)]	Loss: 0.526341
[2022-06-11 11:15:08 | train] - Train Epoch: [125] [921600/1281167 (72%)]	Loss: 0.629419
[2022-06-11 11:15:29 | train] - Train Epoch: [125] [934400/1281167 (73%)]	Loss: 0.562296
[2022-06-11 11:15:51 | train] - Train Epoch: [125] [947200/1281167 (74%)]	Loss: 0.776738
[2022-06-11 11:16:13 | train] - Train Epoch: [125] [960000/1281167 (75%)]	Loss: 0.605182
[2022-06-11 11:16:35 | train] - Train Epoch: [125] [972800/1281167 (76%)]	Loss: 0.592261
[2022-06-11 11:16:56 | train] - Train Epoch: [125] [985600/1281167 (77%)]	Loss: 0.736046
[2022-06-11 11:17:17 | train] - Train Epoch: [125] [998400/1281167 (78%)]	Loss: 0.517396
[2022-06-11 11:17:39 | train] - Train Epoch: [125] [1011200/1281167 (79%)]	Loss: 0.646972
[2022-06-11 11:18:00 | train] - Train Epoch: [125] [1024000/1281167 (80%)]	Loss: 0.808389
[2022-06-11 11:18:21 | train] - Train Epoch: [125] [1036800/1281167 (81%)]	Loss: 0.768249
[2022-06-11 11:18:42 | train] - Train Epoch: [125] [1049600/1281167 (82%)]	Loss: 0.767700
[2022-06-11 11:19:05 | train] - Train Epoch: [125] [1062400/1281167 (83%)]	Loss: 0.852150
[2022-06-11 11:19:26 | train] - Train Epoch: [125] [1075200/1281167 (84%)]	Loss: 0.599734
[2022-06-11 11:19:47 | train] - Train Epoch: [125] [1088000/1281167 (85%)]	Loss: 0.840010
[2022-06-11 11:20:09 | train] - Train Epoch: [125] [1100800/1281167 (86%)]	Loss: 0.745724
[2022-06-11 11:20:31 | train] - Train Epoch: [125] [1113600/1281167 (87%)]	Loss: 0.723601
[2022-06-11 11:20:51 | train] - Train Epoch: [125] [1126400/1281167 (88%)]	Loss: 0.657977
[2022-06-11 11:21:13 | train] - Train Epoch: [125] [1139200/1281167 (89%)]	Loss: 0.893362
[2022-06-11 11:21:35 | train] - Train Epoch: [125] [1152000/1281167 (90%)]	Loss: 0.513388
[2022-06-11 11:21:57 | train] - Train Epoch: [125] [1164800/1281167 (91%)]	Loss: 0.712259
[2022-06-11 11:22:19 | train] - Train Epoch: [125] [1177600/1281167 (92%)]	Loss: 0.947147
[2022-06-11 11:22:39 | train] - Train Epoch: [125] [1190400/1281167 (93%)]	Loss: 0.789632
[2022-06-11 11:23:01 | train] - Train Epoch: [125] [1203200/1281167 (94%)]	Loss: 0.900587
[2022-06-11 11:23:23 | train] - Train Epoch: [125] [1216000/1281167 (95%)]	Loss: 0.839356
[2022-06-11 11:23:44 | train] - Train Epoch: [125] [1228800/1281167 (96%)]	Loss: 0.903024
[2022-06-11 11:24:06 | train] - Train Epoch: [125] [1241600/1281167 (97%)]	Loss: 0.688253
[2022-06-11 11:24:28 | train] - Train Epoch: [125] [1254400/1281167 (98%)]	Loss: 0.623825
[2022-06-11 11:24:49 | train] - Train Epoch: [125] [1267200/1281167 (99%)]	Loss: 0.681047
[2022-06-11 11:25:11 | train] - Train Epoch: [125] [1280000/1281167 (100%)]	Loss: 0.550086
[2022-06-11 11:25:13 | train] - Train Epoch: [125]	 Average Loss: 0.765131	 Total Acc : 81.3481	 Total Top5 Acc : 93.2322
[2022-06-11 11:25:13 | train] - -------125 epoch end-----------
========================================
-------125 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 11:26:42 | train] - 
Epoch [125] Test set: Average loss: 1.4046, Accuracy: 35002/50000 (69.9740%), Top-5 Accuracy: 88.9970%

[2022-06-11 11:26:42 | train] - save intermediate epoch [125] result


[2022-06-11 11:26:47 | train] - -------126 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 11:26:48 | train] - Train Epoch: [126] [0/1281167 (0%)]	Loss: 0.655153
[2022-06-11 11:27:09 | train] - Train Epoch: [126] [12800/1281167 (1%)]	Loss: 0.546332
[2022-06-11 11:27:29 | train] - Train Epoch: [126] [25600/1281167 (2%)]	Loss: 0.768949
[2022-06-11 11:27:49 | train] - Train Epoch: [126] [38400/1281167 (3%)]	Loss: 0.854581
[2022-06-11 11:28:10 | train] - Train Epoch: [126] [51200/1281167 (4%)]	Loss: 0.889913
[2022-06-11 11:28:31 | train] - Train Epoch: [126] [64000/1281167 (5%)]	Loss: 0.876240
[2022-06-11 11:28:51 | train] - Train Epoch: [126] [76800/1281167 (6%)]	Loss: 0.676273
[2022-06-11 11:29:12 | train] - Train Epoch: [126] [89600/1281167 (7%)]	Loss: 0.699808
[2022-06-11 11:29:33 | train] - Train Epoch: [126] [102400/1281167 (8%)]	Loss: 0.469704
[2022-06-11 11:29:53 | train] - Train Epoch: [126] [115200/1281167 (9%)]	Loss: 0.741546
[2022-06-11 11:30:13 | train] - Train Epoch: [126] [128000/1281167 (10%)]	Loss: 0.817611
[2022-06-11 11:30:34 | train] - Train Epoch: [126] [140800/1281167 (11%)]	Loss: 0.854005
[2022-06-11 11:30:55 | train] - Train Epoch: [126] [153600/1281167 (12%)]	Loss: 0.655986
[2022-06-11 11:31:15 | train] - Train Epoch: [126] [166400/1281167 (13%)]	Loss: 0.884214
[2022-06-11 11:31:36 | train] - Train Epoch: [126] [179200/1281167 (14%)]	Loss: 0.937075
[2022-06-11 11:31:56 | train] - Train Epoch: [126] [192000/1281167 (15%)]	Loss: 0.959239
[2022-06-11 11:32:17 | train] - Train Epoch: [126] [204800/1281167 (16%)]	Loss: 0.492628
[2022-06-11 11:32:37 | train] - Train Epoch: [126] [217600/1281167 (17%)]	Loss: 0.568113
[2022-06-11 11:32:58 | train] - Train Epoch: [126] [230400/1281167 (18%)]	Loss: 0.779658
[2022-06-11 11:33:18 | train] - Train Epoch: [126] [243200/1281167 (19%)]	Loss: 1.086786
[2022-06-11 11:33:39 | train] - Train Epoch: [126] [256000/1281167 (20%)]	Loss: 0.614159
[2022-06-11 11:33:59 | train] - Train Epoch: [126] [268800/1281167 (21%)]	Loss: 0.655823
[2022-06-11 11:34:19 | train] - Train Epoch: [126] [281600/1281167 (22%)]	Loss: 0.691477
[2022-06-11 11:34:39 | train] - Train Epoch: [126] [294400/1281167 (23%)]	Loss: 0.697559
[2022-06-11 11:35:00 | train] - Train Epoch: [126] [307200/1281167 (24%)]	Loss: 0.627406
[2022-06-11 11:35:21 | train] - Train Epoch: [126] [320000/1281167 (25%)]	Loss: 0.853413
[2022-06-11 11:35:41 | train] - Train Epoch: [126] [332800/1281167 (26%)]	Loss: 0.974268
[2022-06-11 11:36:02 | train] - Train Epoch: [126] [345600/1281167 (27%)]	Loss: 0.796534
[2022-06-11 11:36:23 | train] - Train Epoch: [126] [358400/1281167 (28%)]	Loss: 0.625407
[2022-06-11 11:36:43 | train] - Train Epoch: [126] [371200/1281167 (29%)]	Loss: 0.756502
[2022-06-11 11:37:04 | train] - Train Epoch: [126] [384000/1281167 (30%)]	Loss: 0.874221
[2022-06-11 11:37:24 | train] - Train Epoch: [126] [396800/1281167 (31%)]	Loss: 0.931800
[2022-06-11 11:37:44 | train] - Train Epoch: [126] [409600/1281167 (32%)]	Loss: 0.886131
[2022-06-11 11:38:05 | train] - Train Epoch: [126] [422400/1281167 (33%)]	Loss: 0.669549
[2022-06-11 11:38:25 | train] - Train Epoch: [126] [435200/1281167 (34%)]	Loss: 0.817540
[2022-06-11 11:38:46 | train] - Train Epoch: [126] [448000/1281167 (35%)]	Loss: 0.775813
[2022-06-11 11:39:05 | train] - Train Epoch: [126] [460800/1281167 (36%)]	Loss: 0.572065
[2022-06-11 11:39:26 | train] - Train Epoch: [126] [473600/1281167 (37%)]	Loss: 0.559264
[2022-06-11 11:39:46 | train] - Train Epoch: [126] [486400/1281167 (38%)]	Loss: 1.226513
[2022-06-11 11:40:07 | train] - Train Epoch: [126] [499200/1281167 (39%)]	Loss: 0.753046
[2022-06-11 11:40:28 | train] - Train Epoch: [126] [512000/1281167 (40%)]	Loss: 0.576395
[2022-06-11 11:40:48 | train] - Train Epoch: [126] [524800/1281167 (41%)]	Loss: 0.613296
[2022-06-11 11:41:08 | train] - Train Epoch: [126] [537600/1281167 (42%)]	Loss: 0.856593
[2022-06-11 11:41:29 | train] - Train Epoch: [126] [550400/1281167 (43%)]	Loss: 0.943593
[2022-06-11 11:41:49 | train] - Train Epoch: [126] [563200/1281167 (44%)]	Loss: 0.752780
[2022-06-11 11:42:09 | train] - Train Epoch: [126] [576000/1281167 (45%)]	Loss: 0.686695
[2022-06-11 11:42:30 | train] - Train Epoch: [126] [588800/1281167 (46%)]	Loss: 0.775835
[2022-06-11 11:42:51 | train] - Train Epoch: [126] [601600/1281167 (47%)]	Loss: 0.816767
[2022-06-11 11:43:10 | train] - Train Epoch: [126] [614400/1281167 (48%)]	Loss: 0.629730
[2022-06-11 11:43:32 | train] - Train Epoch: [126] [627200/1281167 (49%)]	Loss: 0.600077
[2022-06-11 11:43:52 | train] - Train Epoch: [126] [640000/1281167 (50%)]	Loss: 0.963363
[2022-06-11 11:44:12 | train] - Train Epoch: [126] [652800/1281167 (51%)]	Loss: 0.650718
[2022-06-11 11:44:34 | train] - Train Epoch: [126] [665600/1281167 (52%)]	Loss: 0.534067
[2022-06-11 11:44:54 | train] - Train Epoch: [126] [678400/1281167 (53%)]	Loss: 0.841394
[2022-06-11 11:45:15 | train] - Train Epoch: [126] [691200/1281167 (54%)]	Loss: 0.624462
[2022-06-11 11:45:35 | train] - Train Epoch: [126] [704000/1281167 (55%)]	Loss: 0.856344
[2022-06-11 11:45:55 | train] - Train Epoch: [126] [716800/1281167 (56%)]	Loss: 0.931364
[2022-06-11 11:46:15 | train] - Train Epoch: [126] [729600/1281167 (57%)]	Loss: 0.514101
[2022-06-11 11:46:36 | train] - Train Epoch: [126] [742400/1281167 (58%)]	Loss: 0.995200
[2022-06-11 11:46:57 | train] - Train Epoch: [126] [755200/1281167 (59%)]	Loss: 0.963424
[2022-06-11 11:47:17 | train] - Train Epoch: [126] [768000/1281167 (60%)]	Loss: 0.873918
[2022-06-11 11:47:37 | train] - Train Epoch: [126] [780800/1281167 (61%)]	Loss: 0.757388
[2022-06-11 11:47:57 | train] - Train Epoch: [126] [793600/1281167 (62%)]	Loss: 0.740256
[2022-06-11 11:48:18 | train] - Train Epoch: [126] [806400/1281167 (63%)]	Loss: 0.614077
[2022-06-11 11:48:38 | train] - Train Epoch: [126] [819200/1281167 (64%)]	Loss: 0.794033
[2022-06-11 11:48:59 | train] - Train Epoch: [126] [832000/1281167 (65%)]	Loss: 0.834208
[2022-06-11 11:49:20 | train] - Train Epoch: [126] [844800/1281167 (66%)]	Loss: 0.665056
[2022-06-11 11:49:40 | train] - Train Epoch: [126] [857600/1281167 (67%)]	Loss: 0.853864
[2022-06-11 11:50:01 | train] - Train Epoch: [126] [870400/1281167 (68%)]	Loss: 1.068844
[2022-06-11 11:50:22 | train] - Train Epoch: [126] [883200/1281167 (69%)]	Loss: 0.894130
[2022-06-11 11:50:43 | train] - Train Epoch: [126] [896000/1281167 (70%)]	Loss: 0.830062
[2022-06-11 11:51:04 | train] - Train Epoch: [126] [908800/1281167 (71%)]	Loss: 0.808448
[2022-06-11 11:51:24 | train] - Train Epoch: [126] [921600/1281167 (72%)]	Loss: 0.652580
[2022-06-11 11:51:45 | train] - Train Epoch: [126] [934400/1281167 (73%)]	Loss: 0.657445
[2022-06-11 11:52:06 | train] - Train Epoch: [126] [947200/1281167 (74%)]	Loss: 0.618022
[2022-06-11 11:52:27 | train] - Train Epoch: [126] [960000/1281167 (75%)]	Loss: 0.645706
[2022-06-11 11:52:48 | train] - Train Epoch: [126] [972800/1281167 (76%)]	Loss: 0.794313
[2022-06-11 11:53:08 | train] - Train Epoch: [126] [985600/1281167 (77%)]	Loss: 0.761297
[2022-06-11 11:53:29 | train] - Train Epoch: [126] [998400/1281167 (78%)]	Loss: 0.844997
[2022-06-11 11:53:49 | train] - Train Epoch: [126] [1011200/1281167 (79%)]	Loss: 0.705561
[2022-06-11 11:54:10 | train] - Train Epoch: [126] [1024000/1281167 (80%)]	Loss: 0.834045
[2022-06-11 11:54:30 | train] - Train Epoch: [126] [1036800/1281167 (81%)]	Loss: 0.729239
[2022-06-11 11:54:50 | train] - Train Epoch: [126] [1049600/1281167 (82%)]	Loss: 0.699334
[2022-06-11 11:55:11 | train] - Train Epoch: [126] [1062400/1281167 (83%)]	Loss: 0.575568
[2022-06-11 11:55:32 | train] - Train Epoch: [126] [1075200/1281167 (84%)]	Loss: 0.911154
[2022-06-11 11:55:52 | train] - Train Epoch: [126] [1088000/1281167 (85%)]	Loss: 0.653385
[2022-06-11 11:56:13 | train] - Train Epoch: [126] [1100800/1281167 (86%)]	Loss: 0.729032
[2022-06-11 11:56:34 | train] - Train Epoch: [126] [1113600/1281167 (87%)]	Loss: 0.749602
[2022-06-11 11:56:55 | train] - Train Epoch: [126] [1126400/1281167 (88%)]	Loss: 0.668600
[2022-06-11 11:57:15 | train] - Train Epoch: [126] [1139200/1281167 (89%)]	Loss: 0.680359
[2022-06-11 11:57:36 | train] - Train Epoch: [126] [1152000/1281167 (90%)]	Loss: 0.867518
[2022-06-11 11:57:56 | train] - Train Epoch: [126] [1164800/1281167 (91%)]	Loss: 0.797942
[2022-06-11 11:58:16 | train] - Train Epoch: [126] [1177600/1281167 (92%)]	Loss: 0.863739
[2022-06-11 11:58:37 | train] - Train Epoch: [126] [1190400/1281167 (93%)]	Loss: 0.785627
[2022-06-11 11:58:57 | train] - Train Epoch: [126] [1203200/1281167 (94%)]	Loss: 0.549529
[2022-06-11 11:59:18 | train] - Train Epoch: [126] [1216000/1281167 (95%)]	Loss: 0.950006
[2022-06-11 11:59:38 | train] - Train Epoch: [126] [1228800/1281167 (96%)]	Loss: 0.684543
[2022-06-11 11:59:58 | train] - Train Epoch: [126] [1241600/1281167 (97%)]	Loss: 0.784562
[2022-06-11 12:00:18 | train] - Train Epoch: [126] [1254400/1281167 (98%)]	Loss: 0.686306
[2022-06-11 12:00:39 | train] - Train Epoch: [126] [1267200/1281167 (99%)]	Loss: 0.857808
[2022-06-11 12:01:00 | train] - Train Epoch: [126] [1280000/1281167 (100%)]	Loss: 1.232925
[2022-06-11 12:01:02 | train] - Train Epoch: [126]	 Average Loss: 0.764354	 Total Acc : 81.3336	 Total Top5 Acc : 93.2233
[2022-06-11 12:01:02 | train] - -------126 epoch end-----------
========================================
-------126 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 12:02:35 | train] - 
Epoch [126] Test set: Average loss: 1.4137, Accuracy: 34920/50000 (69.8126%), Top-5 Accuracy: 88.9910%

[2022-06-11 12:02:35 | train] - save intermediate epoch [126] result


[2022-06-11 12:02:39 | train] - -------127 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 12:02:41 | train] - Train Epoch: [127] [0/1281167 (0%)]	Loss: 0.652517
[2022-06-11 12:03:02 | train] - Train Epoch: [127] [12800/1281167 (1%)]	Loss: 0.718034
[2022-06-11 12:03:23 | train] - Train Epoch: [127] [25600/1281167 (2%)]	Loss: 0.449882
[2022-06-11 12:03:45 | train] - Train Epoch: [127] [38400/1281167 (3%)]	Loss: 0.801749
[2022-06-11 12:04:06 | train] - Train Epoch: [127] [51200/1281167 (4%)]	Loss: 0.699343
[2022-06-11 12:04:28 | train] - Train Epoch: [127] [64000/1281167 (5%)]	Loss: 0.756077
[2022-06-11 12:04:49 | train] - Train Epoch: [127] [76800/1281167 (6%)]	Loss: 0.742802
[2022-06-11 12:05:10 | train] - Train Epoch: [127] [89600/1281167 (7%)]	Loss: 0.739869
[2022-06-11 12:05:31 | train] - Train Epoch: [127] [102400/1281167 (8%)]	Loss: 0.504325
[2022-06-11 12:05:52 | train] - Train Epoch: [127] [115200/1281167 (9%)]	Loss: 0.755233
[2022-06-11 12:06:14 | train] - Train Epoch: [127] [128000/1281167 (10%)]	Loss: 0.628855
[2022-06-11 12:06:36 | train] - Train Epoch: [127] [140800/1281167 (11%)]	Loss: 0.850722
[2022-06-11 12:06:57 | train] - Train Epoch: [127] [153600/1281167 (12%)]	Loss: 1.208665
[2022-06-11 12:07:18 | train] - Train Epoch: [127] [166400/1281167 (13%)]	Loss: 0.824096
[2022-06-11 12:07:39 | train] - Train Epoch: [127] [179200/1281167 (14%)]	Loss: 0.838855
[2022-06-11 12:08:01 | train] - Train Epoch: [127] [192000/1281167 (15%)]	Loss: 0.780995
[2022-06-11 12:08:23 | train] - Train Epoch: [127] [204800/1281167 (16%)]	Loss: 0.810559
[2022-06-11 12:08:45 | train] - Train Epoch: [127] [217600/1281167 (17%)]	Loss: 0.854064
[2022-06-11 12:09:07 | train] - Train Epoch: [127] [230400/1281167 (18%)]	Loss: 0.923983
[2022-06-11 12:09:28 | train] - Train Epoch: [127] [243200/1281167 (19%)]	Loss: 0.737549
[2022-06-11 12:09:49 | train] - Train Epoch: [127] [256000/1281167 (20%)]	Loss: 0.748606
[2022-06-11 12:10:11 | train] - Train Epoch: [127] [268800/1281167 (21%)]	Loss: 0.654894
[2022-06-11 12:10:32 | train] - Train Epoch: [127] [281600/1281167 (22%)]	Loss: 0.770925
[2022-06-11 12:10:53 | train] - Train Epoch: [127] [294400/1281167 (23%)]	Loss: 0.923814
[2022-06-11 12:11:14 | train] - Train Epoch: [127] [307200/1281167 (24%)]	Loss: 0.901721
[2022-06-11 12:11:34 | train] - Train Epoch: [127] [320000/1281167 (25%)]	Loss: 0.766732
[2022-06-11 12:11:56 | train] - Train Epoch: [127] [332800/1281167 (26%)]	Loss: 1.057977
[2022-06-11 12:12:17 | train] - Train Epoch: [127] [345600/1281167 (27%)]	Loss: 0.945714
[2022-06-11 12:12:39 | train] - Train Epoch: [127] [358400/1281167 (28%)]	Loss: 0.776970
[2022-06-11 12:12:59 | train] - Train Epoch: [127] [371200/1281167 (29%)]	Loss: 0.671076
[2022-06-11 12:13:21 | train] - Train Epoch: [127] [384000/1281167 (30%)]	Loss: 0.738714
[2022-06-11 12:13:41 | train] - Train Epoch: [127] [396800/1281167 (31%)]	Loss: 0.675703
[2022-06-11 12:14:02 | train] - Train Epoch: [127] [409600/1281167 (32%)]	Loss: 0.847145
[2022-06-11 12:14:23 | train] - Train Epoch: [127] [422400/1281167 (33%)]	Loss: 0.798380
[2022-06-11 12:14:45 | train] - Train Epoch: [127] [435200/1281167 (34%)]	Loss: 0.734559
[2022-06-11 12:15:07 | train] - Train Epoch: [127] [448000/1281167 (35%)]	Loss: 0.722312
[2022-06-11 12:15:29 | train] - Train Epoch: [127] [460800/1281167 (36%)]	Loss: 0.484828
[2022-06-11 12:15:50 | train] - Train Epoch: [127] [473600/1281167 (37%)]	Loss: 0.774146
[2022-06-11 12:16:12 | train] - Train Epoch: [127] [486400/1281167 (38%)]	Loss: 0.839227
[2022-06-11 12:16:33 | train] - Train Epoch: [127] [499200/1281167 (39%)]	Loss: 0.834460
[2022-06-11 12:16:54 | train] - Train Epoch: [127] [512000/1281167 (40%)]	Loss: 0.785939
[2022-06-11 12:17:15 | train] - Train Epoch: [127] [524800/1281167 (41%)]	Loss: 0.723086
[2022-06-11 12:17:36 | train] - Train Epoch: [127] [537600/1281167 (42%)]	Loss: 0.784407
[2022-06-11 12:17:56 | train] - Train Epoch: [127] [550400/1281167 (43%)]	Loss: 0.704005
[2022-06-11 12:18:17 | train] - Train Epoch: [127] [563200/1281167 (44%)]	Loss: 0.700572
[2022-06-11 12:18:37 | train] - Train Epoch: [127] [576000/1281167 (45%)]	Loss: 0.704800
[2022-06-11 12:18:59 | train] - Train Epoch: [127] [588800/1281167 (46%)]	Loss: 0.831299
[2022-06-11 12:19:20 | train] - Train Epoch: [127] [601600/1281167 (47%)]	Loss: 0.860089
[2022-06-11 12:19:42 | train] - Train Epoch: [127] [614400/1281167 (48%)]	Loss: 0.637790
[2022-06-11 12:20:03 | train] - Train Epoch: [127] [627200/1281167 (49%)]	Loss: 0.891646
[2022-06-11 12:20:24 | train] - Train Epoch: [127] [640000/1281167 (50%)]	Loss: 0.831960
[2022-06-11 12:20:46 | train] - Train Epoch: [127] [652800/1281167 (51%)]	Loss: 0.809961
[2022-06-11 12:21:08 | train] - Train Epoch: [127] [665600/1281167 (52%)]	Loss: 0.755039
[2022-06-11 12:21:29 | train] - Train Epoch: [127] [678400/1281167 (53%)]	Loss: 0.791611
[2022-06-11 12:21:49 | train] - Train Epoch: [127] [691200/1281167 (54%)]	Loss: 0.838161
[2022-06-11 12:22:10 | train] - Train Epoch: [127] [704000/1281167 (55%)]	Loss: 0.716221
[2022-06-11 12:22:32 | train] - Train Epoch: [127] [716800/1281167 (56%)]	Loss: 0.867225
[2022-06-11 12:22:53 | train] - Train Epoch: [127] [729600/1281167 (57%)]	Loss: 0.588002
[2022-06-11 12:23:14 | train] - Train Epoch: [127] [742400/1281167 (58%)]	Loss: 0.890429
[2022-06-11 12:23:35 | train] - Train Epoch: [127] [755200/1281167 (59%)]	Loss: 0.789166
[2022-06-11 12:23:56 | train] - Train Epoch: [127] [768000/1281167 (60%)]	Loss: 0.562979
[2022-06-11 12:24:18 | train] - Train Epoch: [127] [780800/1281167 (61%)]	Loss: 0.697931
[2022-06-11 12:24:39 | train] - Train Epoch: [127] [793600/1281167 (62%)]	Loss: 0.883383
[2022-06-11 12:25:00 | train] - Train Epoch: [127] [806400/1281167 (63%)]	Loss: 0.662321
[2022-06-11 12:25:22 | train] - Train Epoch: [127] [819200/1281167 (64%)]	Loss: 0.824719
[2022-06-11 12:25:44 | train] - Train Epoch: [127] [832000/1281167 (65%)]	Loss: 1.021958
[2022-06-11 12:26:06 | train] - Train Epoch: [127] [844800/1281167 (66%)]	Loss: 0.857113
[2022-06-11 12:26:26 | train] - Train Epoch: [127] [857600/1281167 (67%)]	Loss: 0.749792
[2022-06-11 12:26:48 | train] - Train Epoch: [127] [870400/1281167 (68%)]	Loss: 0.959930
[2022-06-11 12:27:09 | train] - Train Epoch: [127] [883200/1281167 (69%)]	Loss: 0.946325
[2022-06-11 12:27:30 | train] - Train Epoch: [127] [896000/1281167 (70%)]	Loss: 0.743598
[2022-06-11 12:27:51 | train] - Train Epoch: [127] [908800/1281167 (71%)]	Loss: 1.011186
[2022-06-11 12:28:12 | train] - Train Epoch: [127] [921600/1281167 (72%)]	Loss: 0.722288
[2022-06-11 12:28:33 | train] - Train Epoch: [127] [934400/1281167 (73%)]	Loss: 0.643465
[2022-06-11 12:28:54 | train] - Train Epoch: [127] [947200/1281167 (74%)]	Loss: 0.734440
[2022-06-11 12:29:15 | train] - Train Epoch: [127] [960000/1281167 (75%)]	Loss: 0.917501
[2022-06-11 12:29:35 | train] - Train Epoch: [127] [972800/1281167 (76%)]	Loss: 1.059539
[2022-06-11 12:29:57 | train] - Train Epoch: [127] [985600/1281167 (77%)]	Loss: 0.776085
[2022-06-11 12:30:19 | train] - Train Epoch: [127] [998400/1281167 (78%)]	Loss: 0.643387
[2022-06-11 12:30:41 | train] - Train Epoch: [127] [1011200/1281167 (79%)]	Loss: 0.861055
[2022-06-11 12:31:02 | train] - Train Epoch: [127] [1024000/1281167 (80%)]	Loss: 0.926971
[2022-06-11 12:31:23 | train] - Train Epoch: [127] [1036800/1281167 (81%)]	Loss: 0.838899
[2022-06-11 12:31:46 | train] - Train Epoch: [127] [1049600/1281167 (82%)]	Loss: 0.861454
[2022-06-11 12:32:07 | train] - Train Epoch: [127] [1062400/1281167 (83%)]	Loss: 0.692960
[2022-06-11 12:32:29 | train] - Train Epoch: [127] [1075200/1281167 (84%)]	Loss: 0.454537
[2022-06-11 12:32:51 | train] - Train Epoch: [127] [1088000/1281167 (85%)]	Loss: 0.766241
[2022-06-11 12:33:12 | train] - Train Epoch: [127] [1100800/1281167 (86%)]	Loss: 0.637232
[2022-06-11 12:33:34 | train] - Train Epoch: [127] [1113600/1281167 (87%)]	Loss: 0.779551
[2022-06-11 12:33:55 | train] - Train Epoch: [127] [1126400/1281167 (88%)]	Loss: 0.853395
[2022-06-11 12:34:17 | train] - Train Epoch: [127] [1139200/1281167 (89%)]	Loss: 0.679919
[2022-06-11 12:34:38 | train] - Train Epoch: [127] [1152000/1281167 (90%)]	Loss: 0.625132
[2022-06-11 12:34:59 | train] - Train Epoch: [127] [1164800/1281167 (91%)]	Loss: 0.785320
[2022-06-11 12:35:21 | train] - Train Epoch: [127] [1177600/1281167 (92%)]	Loss: 0.755011
[2022-06-11 12:35:42 | train] - Train Epoch: [127] [1190400/1281167 (93%)]	Loss: 0.743994
[2022-06-11 12:36:04 | train] - Train Epoch: [127] [1203200/1281167 (94%)]	Loss: 0.586309
[2022-06-11 12:36:25 | train] - Train Epoch: [127] [1216000/1281167 (95%)]	Loss: 0.958640
[2022-06-11 12:36:47 | train] - Train Epoch: [127] [1228800/1281167 (96%)]	Loss: 1.027040
[2022-06-11 12:37:09 | train] - Train Epoch: [127] [1241600/1281167 (97%)]	Loss: 0.819750
[2022-06-11 12:37:30 | train] - Train Epoch: [127] [1254400/1281167 (98%)]	Loss: 0.837038
[2022-06-11 12:37:51 | train] - Train Epoch: [127] [1267200/1281167 (99%)]	Loss: 0.839297
[2022-06-11 12:38:11 | train] - Train Epoch: [127] [1280000/1281167 (100%)]	Loss: 0.615605
[2022-06-11 12:38:13 | train] - Train Epoch: [127]	 Average Loss: 0.762264	 Total Acc : 81.4023	 Total Top5 Acc : 93.2542
[2022-06-11 12:38:13 | train] - -------127 epoch end-----------
========================================
-------127 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 12:39:48 | train] - 
Epoch [127] Test set: Average loss: 1.4152, Accuracy: 34986/50000 (69.9433%), Top-5 Accuracy: 89.0094%

[2022-06-11 12:39:48 | train] - save intermediate epoch [127] result


[2022-06-11 12:39:53 | train] - -------128 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 12:39:55 | train] - Train Epoch: [128] [0/1281167 (0%)]	Loss: 0.970306
[2022-06-11 12:40:17 | train] - Train Epoch: [128] [12800/1281167 (1%)]	Loss: 0.546537
[2022-06-11 12:40:38 | train] - Train Epoch: [128] [25600/1281167 (2%)]	Loss: 0.872427
[2022-06-11 12:41:00 | train] - Train Epoch: [128] [38400/1281167 (3%)]	Loss: 0.818094
[2022-06-11 12:41:21 | train] - Train Epoch: [128] [51200/1281167 (4%)]	Loss: 0.673256
[2022-06-11 12:41:43 | train] - Train Epoch: [128] [64000/1281167 (5%)]	Loss: 0.879560
[2022-06-11 12:42:04 | train] - Train Epoch: [128] [76800/1281167 (6%)]	Loss: 0.875942
[2022-06-11 12:42:25 | train] - Train Epoch: [128] [89600/1281167 (7%)]	Loss: 0.583047
[2022-06-11 12:42:46 | train] - Train Epoch: [128] [102400/1281167 (8%)]	Loss: 0.596662
[2022-06-11 12:43:08 | train] - Train Epoch: [128] [115200/1281167 (9%)]	Loss: 0.428953
[2022-06-11 12:43:29 | train] - Train Epoch: [128] [128000/1281167 (10%)]	Loss: 0.934218
[2022-06-11 12:43:51 | train] - Train Epoch: [128] [140800/1281167 (11%)]	Loss: 0.888020
[2022-06-11 12:44:12 | train] - Train Epoch: [128] [153600/1281167 (12%)]	Loss: 0.821575
[2022-06-11 12:44:33 | train] - Train Epoch: [128] [166400/1281167 (13%)]	Loss: 0.904171
[2022-06-11 12:44:54 | train] - Train Epoch: [128] [179200/1281167 (14%)]	Loss: 0.859466
[2022-06-11 12:45:15 | train] - Train Epoch: [128] [192000/1281167 (15%)]	Loss: 0.887913
[2022-06-11 12:45:37 | train] - Train Epoch: [128] [204800/1281167 (16%)]	Loss: 0.782054
[2022-06-11 12:45:58 | train] - Train Epoch: [128] [217600/1281167 (17%)]	Loss: 0.950158
[2022-06-11 12:46:19 | train] - Train Epoch: [128] [230400/1281167 (18%)]	Loss: 0.965859
[2022-06-11 12:46:41 | train] - Train Epoch: [128] [243200/1281167 (19%)]	Loss: 0.936168
[2022-06-11 12:47:02 | train] - Train Epoch: [128] [256000/1281167 (20%)]	Loss: 0.755652
[2022-06-11 12:47:24 | train] - Train Epoch: [128] [268800/1281167 (21%)]	Loss: 0.645125
[2022-06-11 12:47:45 | train] - Train Epoch: [128] [281600/1281167 (22%)]	Loss: 0.969185
[2022-06-11 12:48:07 | train] - Train Epoch: [128] [294400/1281167 (23%)]	Loss: 1.010113
[2022-06-11 12:48:28 | train] - Train Epoch: [128] [307200/1281167 (24%)]	Loss: 0.577452
[2022-06-11 12:48:50 | train] - Train Epoch: [128] [320000/1281167 (25%)]	Loss: 0.693310
[2022-06-11 12:49:10 | train] - Train Epoch: [128] [332800/1281167 (26%)]	Loss: 0.831294
[2022-06-11 12:49:32 | train] - Train Epoch: [128] [345600/1281167 (27%)]	Loss: 0.599498
[2022-06-11 12:49:53 | train] - Train Epoch: [128] [358400/1281167 (28%)]	Loss: 0.964481
[2022-06-11 12:50:14 | train] - Train Epoch: [128] [371200/1281167 (29%)]	Loss: 0.654096
[2022-06-11 12:50:35 | train] - Train Epoch: [128] [384000/1281167 (30%)]	Loss: 0.743614
[2022-06-11 12:50:56 | train] - Train Epoch: [128] [396800/1281167 (31%)]	Loss: 0.628202
[2022-06-11 12:51:18 | train] - Train Epoch: [128] [409600/1281167 (32%)]	Loss: 0.571305
[2022-06-11 12:51:39 | train] - Train Epoch: [128] [422400/1281167 (33%)]	Loss: 0.797215
[2022-06-11 12:52:00 | train] - Train Epoch: [128] [435200/1281167 (34%)]	Loss: 0.841015
[2022-06-11 12:52:21 | train] - Train Epoch: [128] [448000/1281167 (35%)]	Loss: 0.607716
[2022-06-11 12:52:42 | train] - Train Epoch: [128] [460800/1281167 (36%)]	Loss: 0.921647
[2022-06-11 12:53:03 | train] - Train Epoch: [128] [473600/1281167 (37%)]	Loss: 0.886189
[2022-06-11 12:53:24 | train] - Train Epoch: [128] [486400/1281167 (38%)]	Loss: 0.961595
[2022-06-11 12:53:46 | train] - Train Epoch: [128] [499200/1281167 (39%)]	Loss: 0.606492
[2022-06-11 12:54:08 | train] - Train Epoch: [128] [512000/1281167 (40%)]	Loss: 0.721045
[2022-06-11 12:54:30 | train] - Train Epoch: [128] [524800/1281167 (41%)]	Loss: 0.929502
[2022-06-11 12:54:52 | train] - Train Epoch: [128] [537600/1281167 (42%)]	Loss: 0.708156
[2022-06-11 12:55:13 | train] - Train Epoch: [128] [550400/1281167 (43%)]	Loss: 0.908158
[2022-06-11 12:55:35 | train] - Train Epoch: [128] [563200/1281167 (44%)]	Loss: 0.702636
[2022-06-11 12:55:56 | train] - Train Epoch: [128] [576000/1281167 (45%)]	Loss: 0.584315
[2022-06-11 12:56:18 | train] - Train Epoch: [128] [588800/1281167 (46%)]	Loss: 0.704180
[2022-06-11 12:56:40 | train] - Train Epoch: [128] [601600/1281167 (47%)]	Loss: 1.056661
[2022-06-11 12:57:01 | train] - Train Epoch: [128] [614400/1281167 (48%)]	Loss: 0.857758
[2022-06-11 12:57:21 | train] - Train Epoch: [128] [627200/1281167 (49%)]	Loss: 0.810761
[2022-06-11 12:57:42 | train] - Train Epoch: [128] [640000/1281167 (50%)]	Loss: 0.883974
[2022-06-11 12:58:05 | train] - Train Epoch: [128] [652800/1281167 (51%)]	Loss: 0.653697
[2022-06-11 12:58:26 | train] - Train Epoch: [128] [665600/1281167 (52%)]	Loss: 0.608467
[2022-06-11 12:58:48 | train] - Train Epoch: [128] [678400/1281167 (53%)]	Loss: 0.841912
[2022-06-11 12:59:10 | train] - Train Epoch: [128] [691200/1281167 (54%)]	Loss: 0.682694
[2022-06-11 12:59:32 | train] - Train Epoch: [128] [704000/1281167 (55%)]	Loss: 0.784419
[2022-06-11 12:59:54 | train] - Train Epoch: [128] [716800/1281167 (56%)]	Loss: 0.866368
[2022-06-11 13:00:16 | train] - Train Epoch: [128] [729600/1281167 (57%)]	Loss: 0.644211
[2022-06-11 13:00:38 | train] - Train Epoch: [128] [742400/1281167 (58%)]	Loss: 0.535213
[2022-06-11 13:01:00 | train] - Train Epoch: [128] [755200/1281167 (59%)]	Loss: 0.713547
[2022-06-11 13:01:22 | train] - Train Epoch: [128] [768000/1281167 (60%)]	Loss: 0.781789
[2022-06-11 13:01:44 | train] - Train Epoch: [128] [780800/1281167 (61%)]	Loss: 0.817915
[2022-06-11 13:02:06 | train] - Train Epoch: [128] [793600/1281167 (62%)]	Loss: 0.563748
[2022-06-11 13:02:28 | train] - Train Epoch: [128] [806400/1281167 (63%)]	Loss: 1.080195
[2022-06-11 13:02:49 | train] - Train Epoch: [128] [819200/1281167 (64%)]	Loss: 0.728284
[2022-06-11 13:03:11 | train] - Train Epoch: [128] [832000/1281167 (65%)]	Loss: 0.812863
[2022-06-11 13:03:33 | train] - Train Epoch: [128] [844800/1281167 (66%)]	Loss: 0.690181
[2022-06-11 13:03:56 | train] - Train Epoch: [128] [857600/1281167 (67%)]	Loss: 0.665753
[2022-06-11 13:04:17 | train] - Train Epoch: [128] [870400/1281167 (68%)]	Loss: 0.586688
[2022-06-11 13:04:40 | train] - Train Epoch: [128] [883200/1281167 (69%)]	Loss: 0.811562
[2022-06-11 13:05:02 | train] - Train Epoch: [128] [896000/1281167 (70%)]	Loss: 0.677781
[2022-06-11 13:05:24 | train] - Train Epoch: [128] [908800/1281167 (71%)]	Loss: 0.675469
[2022-06-11 13:05:45 | train] - Train Epoch: [128] [921600/1281167 (72%)]	Loss: 0.849017
[2022-06-11 13:06:08 | train] - Train Epoch: [128] [934400/1281167 (73%)]	Loss: 0.890962
[2022-06-11 13:06:30 | train] - Train Epoch: [128] [947200/1281167 (74%)]	Loss: 0.794150
[2022-06-11 13:06:52 | train] - Train Epoch: [128] [960000/1281167 (75%)]	Loss: 0.820160
[2022-06-11 13:07:14 | train] - Train Epoch: [128] [972800/1281167 (76%)]	Loss: 0.944919
[2022-06-11 13:07:36 | train] - Train Epoch: [128] [985600/1281167 (77%)]	Loss: 0.784059
[2022-06-11 13:07:58 | train] - Train Epoch: [128] [998400/1281167 (78%)]	Loss: 0.826103
[2022-06-11 13:08:20 | train] - Train Epoch: [128] [1011200/1281167 (79%)]	Loss: 0.551274
[2022-06-11 13:08:42 | train] - Train Epoch: [128] [1024000/1281167 (80%)]	Loss: 0.690952
[2022-06-11 13:09:05 | train] - Train Epoch: [128] [1036800/1281167 (81%)]	Loss: 0.984222
[2022-06-11 13:09:26 | train] - Train Epoch: [128] [1049600/1281167 (82%)]	Loss: 0.722057
[2022-06-11 13:09:48 | train] - Train Epoch: [128] [1062400/1281167 (83%)]	Loss: 0.649213
[2022-06-11 13:10:09 | train] - Train Epoch: [128] [1075200/1281167 (84%)]	Loss: 0.656422
[2022-06-11 13:10:31 | train] - Train Epoch: [128] [1088000/1281167 (85%)]	Loss: 0.848837
[2022-06-11 13:10:54 | train] - Train Epoch: [128] [1100800/1281167 (86%)]	Loss: 0.830062
[2022-06-11 13:11:16 | train] - Train Epoch: [128] [1113600/1281167 (87%)]	Loss: 0.898683
[2022-06-11 13:11:38 | train] - Train Epoch: [128] [1126400/1281167 (88%)]	Loss: 0.681548
[2022-06-11 13:12:00 | train] - Train Epoch: [128] [1139200/1281167 (89%)]	Loss: 0.710197
[2022-06-11 13:12:21 | train] - Train Epoch: [128] [1152000/1281167 (90%)]	Loss: 0.776485
[2022-06-11 13:12:44 | train] - Train Epoch: [128] [1164800/1281167 (91%)]	Loss: 0.543296
[2022-06-11 13:13:05 | train] - Train Epoch: [128] [1177600/1281167 (92%)]	Loss: 0.717057
[2022-06-11 13:13:27 | train] - Train Epoch: [128] [1190400/1281167 (93%)]	Loss: 0.724504
[2022-06-11 13:13:49 | train] - Train Epoch: [128] [1203200/1281167 (94%)]	Loss: 0.763398
[2022-06-11 13:14:11 | train] - Train Epoch: [128] [1216000/1281167 (95%)]	Loss: 0.759319
[2022-06-11 13:14:33 | train] - Train Epoch: [128] [1228800/1281167 (96%)]	Loss: 0.697752
[2022-06-11 13:14:55 | train] - Train Epoch: [128] [1241600/1281167 (97%)]	Loss: 0.639673
[2022-06-11 13:15:17 | train] - Train Epoch: [128] [1254400/1281167 (98%)]	Loss: 0.783841
[2022-06-11 13:15:38 | train] - Train Epoch: [128] [1267200/1281167 (99%)]	Loss: 0.683016
[2022-06-11 13:16:00 | train] - Train Epoch: [128] [1280000/1281167 (100%)]	Loss: 0.874352
[2022-06-11 13:16:02 | train] - Train Epoch: [128]	 Average Loss: 0.761723	 Total Acc : 81.4541	 Total Top5 Acc : 93.2356
[2022-06-11 13:16:02 | train] - -------128 epoch end-----------
========================================
-------128 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 13:17:36 | train] - 
Epoch [128] Test set: Average loss: 1.4151, Accuracy: 35000/50000 (69.9712%), Top-5 Accuracy: 88.9946%

[2022-06-11 13:17:36 | train] - save intermediate epoch [128] result


[2022-06-11 13:17:41 | train] - -------129 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 13:17:43 | train] - Train Epoch: [129] [0/1281167 (0%)]	Loss: 0.613321
[2022-06-11 13:18:03 | train] - Train Epoch: [129] [12800/1281167 (1%)]	Loss: 0.641280
[2022-06-11 13:18:23 | train] - Train Epoch: [129] [25600/1281167 (2%)]	Loss: 0.693765
[2022-06-11 13:18:42 | train] - Train Epoch: [129] [38400/1281167 (3%)]	Loss: 0.900579
[2022-06-11 13:19:02 | train] - Train Epoch: [129] [51200/1281167 (4%)]	Loss: 0.748005
[2022-06-11 13:19:22 | train] - Train Epoch: [129] [64000/1281167 (5%)]	Loss: 0.594788
[2022-06-11 13:19:41 | train] - Train Epoch: [129] [76800/1281167 (6%)]	Loss: 0.561174
[2022-06-11 13:20:01 | train] - Train Epoch: [129] [89600/1281167 (7%)]	Loss: 0.844294
[2022-06-11 13:20:21 | train] - Train Epoch: [129] [102400/1281167 (8%)]	Loss: 0.944379
[2022-06-11 13:20:41 | train] - Train Epoch: [129] [115200/1281167 (9%)]	Loss: 0.788741
[2022-06-11 13:21:00 | train] - Train Epoch: [129] [128000/1281167 (10%)]	Loss: 0.698994
[2022-06-11 13:21:19 | train] - Train Epoch: [129] [140800/1281167 (11%)]	Loss: 0.747667
[2022-06-11 13:21:40 | train] - Train Epoch: [129] [153600/1281167 (12%)]	Loss: 1.053309
[2022-06-11 13:21:59 | train] - Train Epoch: [129] [166400/1281167 (13%)]	Loss: 0.534096
[2022-06-11 13:22:18 | train] - Train Epoch: [129] [179200/1281167 (14%)]	Loss: 1.059894
[2022-06-11 13:22:38 | train] - Train Epoch: [129] [192000/1281167 (15%)]	Loss: 0.884034
[2022-06-11 13:22:58 | train] - Train Epoch: [129] [204800/1281167 (16%)]	Loss: 0.482163
[2022-06-11 13:23:18 | train] - Train Epoch: [129] [217600/1281167 (17%)]	Loss: 0.579466
[2022-06-11 13:23:39 | train] - Train Epoch: [129] [230400/1281167 (18%)]	Loss: 0.742299
[2022-06-11 13:23:59 | train] - Train Epoch: [129] [243200/1281167 (19%)]	Loss: 0.687900
[2022-06-11 13:24:20 | train] - Train Epoch: [129] [256000/1281167 (20%)]	Loss: 0.772845
[2022-06-11 13:24:39 | train] - Train Epoch: [129] [268800/1281167 (21%)]	Loss: 0.759469
[2022-06-11 13:25:00 | train] - Train Epoch: [129] [281600/1281167 (22%)]	Loss: 0.842175
[2022-06-11 13:25:20 | train] - Train Epoch: [129] [294400/1281167 (23%)]	Loss: 0.590415
[2022-06-11 13:25:40 | train] - Train Epoch: [129] [307200/1281167 (24%)]	Loss: 0.647559
[2022-06-11 13:26:00 | train] - Train Epoch: [129] [320000/1281167 (25%)]	Loss: 0.445102
[2022-06-11 13:26:21 | train] - Train Epoch: [129] [332800/1281167 (26%)]	Loss: 0.843174
[2022-06-11 13:26:41 | train] - Train Epoch: [129] [345600/1281167 (27%)]	Loss: 0.704235
[2022-06-11 13:27:01 | train] - Train Epoch: [129] [358400/1281167 (28%)]	Loss: 0.569083
[2022-06-11 13:27:21 | train] - Train Epoch: [129] [371200/1281167 (29%)]	Loss: 0.705879
[2022-06-11 13:27:41 | train] - Train Epoch: [129] [384000/1281167 (30%)]	Loss: 0.723865
[2022-06-11 13:28:01 | train] - Train Epoch: [129] [396800/1281167 (31%)]	Loss: 0.959044
[2022-06-11 13:28:21 | train] - Train Epoch: [129] [409600/1281167 (32%)]	Loss: 0.763993
[2022-06-11 13:28:41 | train] - Train Epoch: [129] [422400/1281167 (33%)]	Loss: 0.637554
[2022-06-11 13:29:01 | train] - Train Epoch: [129] [435200/1281167 (34%)]	Loss: 0.730320
[2022-06-11 13:29:21 | train] - Train Epoch: [129] [448000/1281167 (35%)]	Loss: 0.860050
[2022-06-11 13:29:42 | train] - Train Epoch: [129] [460800/1281167 (36%)]	Loss: 0.803583
[2022-06-11 13:30:02 | train] - Train Epoch: [129] [473600/1281167 (37%)]	Loss: 0.779405
[2022-06-11 13:30:22 | train] - Train Epoch: [129] [486400/1281167 (38%)]	Loss: 0.591249
[2022-06-11 13:30:42 | train] - Train Epoch: [129] [499200/1281167 (39%)]	Loss: 0.612007
[2022-06-11 13:31:02 | train] - Train Epoch: [129] [512000/1281167 (40%)]	Loss: 0.925624
[2022-06-11 13:31:22 | train] - Train Epoch: [129] [524800/1281167 (41%)]	Loss: 0.714907
[2022-06-11 13:31:43 | train] - Train Epoch: [129] [537600/1281167 (42%)]	Loss: 0.548652
[2022-06-11 13:32:03 | train] - Train Epoch: [129] [550400/1281167 (43%)]	Loss: 0.889039
[2022-06-11 13:32:24 | train] - Train Epoch: [129] [563200/1281167 (44%)]	Loss: 0.691066
[2022-06-11 13:32:44 | train] - Train Epoch: [129] [576000/1281167 (45%)]	Loss: 0.955302
[2022-06-11 13:33:04 | train] - Train Epoch: [129] [588800/1281167 (46%)]	Loss: 0.856869
[2022-06-11 13:33:24 | train] - Train Epoch: [129] [601600/1281167 (47%)]	Loss: 0.828659
[2022-06-11 13:33:44 | train] - Train Epoch: [129] [614400/1281167 (48%)]	Loss: 0.883164
[2022-06-11 13:34:04 | train] - Train Epoch: [129] [627200/1281167 (49%)]	Loss: 0.505533
[2022-06-11 13:34:24 | train] - Train Epoch: [129] [640000/1281167 (50%)]	Loss: 0.808924
[2022-06-11 13:34:45 | train] - Train Epoch: [129] [652800/1281167 (51%)]	Loss: 0.828400
[2022-06-11 13:35:05 | train] - Train Epoch: [129] [665600/1281167 (52%)]	Loss: 0.617122
[2022-06-11 13:35:24 | train] - Train Epoch: [129] [678400/1281167 (53%)]	Loss: 1.167467
[2022-06-11 13:35:45 | train] - Train Epoch: [129] [691200/1281167 (54%)]	Loss: 0.810909
[2022-06-11 13:36:04 | train] - Train Epoch: [129] [704000/1281167 (55%)]	Loss: 0.951945
[2022-06-11 13:36:25 | train] - Train Epoch: [129] [716800/1281167 (56%)]	Loss: 0.793436
[2022-06-11 13:36:45 | train] - Train Epoch: [129] [729600/1281167 (57%)]	Loss: 0.537421
[2022-06-11 13:37:05 | train] - Train Epoch: [129] [742400/1281167 (58%)]	Loss: 0.677116
[2022-06-11 13:37:25 | train] - Train Epoch: [129] [755200/1281167 (59%)]	Loss: 0.870575
[2022-06-11 13:37:46 | train] - Train Epoch: [129] [768000/1281167 (60%)]	Loss: 0.683584
[2022-06-11 13:38:06 | train] - Train Epoch: [129] [780800/1281167 (61%)]	Loss: 0.697524
[2022-06-11 13:38:26 | train] - Train Epoch: [129] [793600/1281167 (62%)]	Loss: 0.832588
[2022-06-11 13:38:47 | train] - Train Epoch: [129] [806400/1281167 (63%)]	Loss: 0.893699
[2022-06-11 13:39:07 | train] - Train Epoch: [129] [819200/1281167 (64%)]	Loss: 0.473908
[2022-06-11 13:39:27 | train] - Train Epoch: [129] [832000/1281167 (65%)]	Loss: 0.837723
[2022-06-11 13:39:47 | train] - Train Epoch: [129] [844800/1281167 (66%)]	Loss: 0.740396
[2022-06-11 13:40:07 | train] - Train Epoch: [129] [857600/1281167 (67%)]	Loss: 0.731663
[2022-06-11 13:40:27 | train] - Train Epoch: [129] [870400/1281167 (68%)]	Loss: 0.767261
[2022-06-11 13:40:47 | train] - Train Epoch: [129] [883200/1281167 (69%)]	Loss: 0.609760
[2022-06-11 13:41:07 | train] - Train Epoch: [129] [896000/1281167 (70%)]	Loss: 0.625234
[2022-06-11 13:41:27 | train] - Train Epoch: [129] [908800/1281167 (71%)]	Loss: 0.856065
[2022-06-11 13:41:47 | train] - Train Epoch: [129] [921600/1281167 (72%)]	Loss: 0.726056
[2022-06-11 13:42:08 | train] - Train Epoch: [129] [934400/1281167 (73%)]	Loss: 0.703965
[2022-06-11 13:42:28 | train] - Train Epoch: [129] [947200/1281167 (74%)]	Loss: 0.604113
[2022-06-11 13:42:48 | train] - Train Epoch: [129] [960000/1281167 (75%)]	Loss: 0.752526
[2022-06-11 13:43:08 | train] - Train Epoch: [129] [972800/1281167 (76%)]	Loss: 0.581724
[2022-06-11 13:43:28 | train] - Train Epoch: [129] [985600/1281167 (77%)]	Loss: 0.688604
[2022-06-11 13:43:49 | train] - Train Epoch: [129] [998400/1281167 (78%)]	Loss: 0.826011
[2022-06-11 13:44:09 | train] - Train Epoch: [129] [1011200/1281167 (79%)]	Loss: 0.720597
[2022-06-11 13:44:29 | train] - Train Epoch: [129] [1024000/1281167 (80%)]	Loss: 0.806645
[2022-06-11 13:44:50 | train] - Train Epoch: [129] [1036800/1281167 (81%)]	Loss: 0.523117
[2022-06-11 13:45:09 | train] - Train Epoch: [129] [1049600/1281167 (82%)]	Loss: 0.662079
[2022-06-11 13:45:29 | train] - Train Epoch: [129] [1062400/1281167 (83%)]	Loss: 0.518848
[2022-06-11 13:45:49 | train] - Train Epoch: [129] [1075200/1281167 (84%)]	Loss: 0.551080
[2022-06-11 13:46:10 | train] - Train Epoch: [129] [1088000/1281167 (85%)]	Loss: 0.748747
[2022-06-11 13:46:30 | train] - Train Epoch: [129] [1100800/1281167 (86%)]	Loss: 0.747857
[2022-06-11 13:46:49 | train] - Train Epoch: [129] [1113600/1281167 (87%)]	Loss: 0.764606
[2022-06-11 13:47:10 | train] - Train Epoch: [129] [1126400/1281167 (88%)]	Loss: 0.575916
[2022-06-11 13:47:30 | train] - Train Epoch: [129] [1139200/1281167 (89%)]	Loss: 0.854313
[2022-06-11 13:47:50 | train] - Train Epoch: [129] [1152000/1281167 (90%)]	Loss: 0.767105
[2022-06-11 13:48:10 | train] - Train Epoch: [129] [1164800/1281167 (91%)]	Loss: 0.756666
[2022-06-11 13:48:30 | train] - Train Epoch: [129] [1177600/1281167 (92%)]	Loss: 0.945533
[2022-06-11 13:48:50 | train] - Train Epoch: [129] [1190400/1281167 (93%)]	Loss: 0.787353
[2022-06-11 13:49:11 | train] - Train Epoch: [129] [1203200/1281167 (94%)]	Loss: 0.832519
[2022-06-11 13:49:31 | train] - Train Epoch: [129] [1216000/1281167 (95%)]	Loss: 0.798575
[2022-06-11 13:49:52 | train] - Train Epoch: [129] [1228800/1281167 (96%)]	Loss: 1.157834
[2022-06-11 13:50:12 | train] - Train Epoch: [129] [1241600/1281167 (97%)]	Loss: 0.721469
[2022-06-11 13:50:32 | train] - Train Epoch: [129] [1254400/1281167 (98%)]	Loss: 0.937503
[2022-06-11 13:50:53 | train] - Train Epoch: [129] [1267200/1281167 (99%)]	Loss: 0.691922
[2022-06-11 13:51:13 | train] - Train Epoch: [129] [1280000/1281167 (100%)]	Loss: 0.623462
[2022-06-11 13:51:15 | train] - Train Epoch: [129]	 Average Loss: 0.758638	 Total Acc : 81.4872	 Total Top5 Acc : 93.2896
[2022-06-11 13:51:15 | train] - -------129 epoch end-----------
========================================
-------129 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 13:52:48 | train] - 
Epoch [129] Test set: Average loss: 1.4152, Accuracy: 34977/50000 (69.9265%), Top-5 Accuracy: 88.9742%

[2022-06-11 13:52:48 | train] - save intermediate epoch [129] result


[2022-06-11 13:52:54 | train] - -------130 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 13:52:55 | train] - Train Epoch: [130] [0/1281167 (0%)]	Loss: 0.938374
[2022-06-11 13:53:17 | train] - Train Epoch: [130] [12800/1281167 (1%)]	Loss: 0.737728
[2022-06-11 13:53:39 | train] - Train Epoch: [130] [25600/1281167 (2%)]	Loss: 0.788264
[2022-06-11 13:54:00 | train] - Train Epoch: [130] [38400/1281167 (3%)]	Loss: 0.659434
[2022-06-11 13:54:22 | train] - Train Epoch: [130] [51200/1281167 (4%)]	Loss: 0.564315
[2022-06-11 13:54:44 | train] - Train Epoch: [130] [64000/1281167 (5%)]	Loss: 0.970699
[2022-06-11 13:55:06 | train] - Train Epoch: [130] [76800/1281167 (6%)]	Loss: 0.637168
[2022-06-11 13:55:29 | train] - Train Epoch: [130] [89600/1281167 (7%)]	Loss: 0.582469
[2022-06-11 13:55:50 | train] - Train Epoch: [130] [102400/1281167 (8%)]	Loss: 0.609862
[2022-06-11 13:56:11 | train] - Train Epoch: [130] [115200/1281167 (9%)]	Loss: 0.647577
[2022-06-11 13:56:32 | train] - Train Epoch: [130] [128000/1281167 (10%)]	Loss: 0.754229
[2022-06-11 13:56:54 | train] - Train Epoch: [130] [140800/1281167 (11%)]	Loss: 0.877750
[2022-06-11 13:57:17 | train] - Train Epoch: [130] [153600/1281167 (12%)]	Loss: 0.798753
[2022-06-11 13:57:39 | train] - Train Epoch: [130] [166400/1281167 (13%)]	Loss: 0.762688
[2022-06-11 13:58:00 | train] - Train Epoch: [130] [179200/1281167 (14%)]	Loss: 0.717346
[2022-06-11 13:58:23 | train] - Train Epoch: [130] [192000/1281167 (15%)]	Loss: 0.649161
[2022-06-11 13:58:44 | train] - Train Epoch: [130] [204800/1281167 (16%)]	Loss: 0.821639
[2022-06-11 13:59:06 | train] - Train Epoch: [130] [217600/1281167 (17%)]	Loss: 0.865567
[2022-06-11 13:59:29 | train] - Train Epoch: [130] [230400/1281167 (18%)]	Loss: 0.618888
[2022-06-11 13:59:51 | train] - Train Epoch: [130] [243200/1281167 (19%)]	Loss: 0.806802
[2022-06-11 14:00:12 | train] - Train Epoch: [130] [256000/1281167 (20%)]	Loss: 0.776786
[2022-06-11 14:00:34 | train] - Train Epoch: [130] [268800/1281167 (21%)]	Loss: 0.705360
[2022-06-11 14:00:56 | train] - Train Epoch: [130] [281600/1281167 (22%)]	Loss: 0.663702
[2022-06-11 14:01:18 | train] - Train Epoch: [130] [294400/1281167 (23%)]	Loss: 1.052376
[2022-06-11 14:01:40 | train] - Train Epoch: [130] [307200/1281167 (24%)]	Loss: 0.937663
[2022-06-11 14:02:02 | train] - Train Epoch: [130] [320000/1281167 (25%)]	Loss: 0.724189
[2022-06-11 14:02:24 | train] - Train Epoch: [130] [332800/1281167 (26%)]	Loss: 0.875733
[2022-06-11 14:02:46 | train] - Train Epoch: [130] [345600/1281167 (27%)]	Loss: 0.744647
[2022-06-11 14:03:08 | train] - Train Epoch: [130] [358400/1281167 (28%)]	Loss: 0.947355
[2022-06-11 14:03:30 | train] - Train Epoch: [130] [371200/1281167 (29%)]	Loss: 0.919049
[2022-06-11 14:03:52 | train] - Train Epoch: [130] [384000/1281167 (30%)]	Loss: 0.542221
[2022-06-11 14:04:14 | train] - Train Epoch: [130] [396800/1281167 (31%)]	Loss: 0.841097
[2022-06-11 14:04:36 | train] - Train Epoch: [130] [409600/1281167 (32%)]	Loss: 0.514669
[2022-06-11 14:04:58 | train] - Train Epoch: [130] [422400/1281167 (33%)]	Loss: 0.821154
[2022-06-11 14:05:19 | train] - Train Epoch: [130] [435200/1281167 (34%)]	Loss: 0.935629
[2022-06-11 14:05:42 | train] - Train Epoch: [130] [448000/1281167 (35%)]	Loss: 0.576988
[2022-06-11 14:06:04 | train] - Train Epoch: [130] [460800/1281167 (36%)]	Loss: 0.542274
[2022-06-11 14:06:26 | train] - Train Epoch: [130] [473600/1281167 (37%)]	Loss: 0.791767
[2022-06-11 14:06:48 | train] - Train Epoch: [130] [486400/1281167 (38%)]	Loss: 0.660212
[2022-06-11 14:07:10 | train] - Train Epoch: [130] [499200/1281167 (39%)]	Loss: 0.693478
[2022-06-11 14:07:32 | train] - Train Epoch: [130] [512000/1281167 (40%)]	Loss: 0.890045
[2022-06-11 14:07:55 | train] - Train Epoch: [130] [524800/1281167 (41%)]	Loss: 0.702879
[2022-06-11 14:08:17 | train] - Train Epoch: [130] [537600/1281167 (42%)]	Loss: 0.735539
[2022-06-11 14:08:39 | train] - Train Epoch: [130] [550400/1281167 (43%)]	Loss: 0.688294
[2022-06-11 14:09:00 | train] - Train Epoch: [130] [563200/1281167 (44%)]	Loss: 0.704541
[2022-06-11 14:09:22 | train] - Train Epoch: [130] [576000/1281167 (45%)]	Loss: 1.053131
[2022-06-11 14:09:44 | train] - Train Epoch: [130] [588800/1281167 (46%)]	Loss: 0.649108
[2022-06-11 14:10:06 | train] - Train Epoch: [130] [601600/1281167 (47%)]	Loss: 0.862090
[2022-06-11 14:10:27 | train] - Train Epoch: [130] [614400/1281167 (48%)]	Loss: 0.882842
[2022-06-11 14:10:49 | train] - Train Epoch: [130] [627200/1281167 (49%)]	Loss: 0.741121
[2022-06-11 14:11:11 | train] - Train Epoch: [130] [640000/1281167 (50%)]	Loss: 0.617118
[2022-06-11 14:11:33 | train] - Train Epoch: [130] [652800/1281167 (51%)]	Loss: 0.816232
[2022-06-11 14:11:56 | train] - Train Epoch: [130] [665600/1281167 (52%)]	Loss: 0.644094
[2022-06-11 14:12:18 | train] - Train Epoch: [130] [678400/1281167 (53%)]	Loss: 0.796676
[2022-06-11 14:12:40 | train] - Train Epoch: [130] [691200/1281167 (54%)]	Loss: 0.664827
[2022-06-11 14:13:01 | train] - Train Epoch: [130] [704000/1281167 (55%)]	Loss: 0.878077
[2022-06-11 14:13:24 | train] - Train Epoch: [130] [716800/1281167 (56%)]	Loss: 0.801129
[2022-06-11 14:13:46 | train] - Train Epoch: [130] [729600/1281167 (57%)]	Loss: 1.144146
[2022-06-11 14:14:09 | train] - Train Epoch: [130] [742400/1281167 (58%)]	Loss: 1.077691
[2022-06-11 14:14:31 | train] - Train Epoch: [130] [755200/1281167 (59%)]	Loss: 0.716581
[2022-06-11 14:14:53 | train] - Train Epoch: [130] [768000/1281167 (60%)]	Loss: 0.867799
[2022-06-11 14:15:15 | train] - Train Epoch: [130] [780800/1281167 (61%)]	Loss: 1.006065
[2022-06-11 14:15:36 | train] - Train Epoch: [130] [793600/1281167 (62%)]	Loss: 0.624667
[2022-06-11 14:15:58 | train] - Train Epoch: [130] [806400/1281167 (63%)]	Loss: 0.498066
[2022-06-11 14:16:20 | train] - Train Epoch: [130] [819200/1281167 (64%)]	Loss: 0.688667
[2022-06-11 14:16:42 | train] - Train Epoch: [130] [832000/1281167 (65%)]	Loss: 0.969062
[2022-06-11 14:17:04 | train] - Train Epoch: [130] [844800/1281167 (66%)]	Loss: 0.749026
[2022-06-11 14:17:26 | train] - Train Epoch: [130] [857600/1281167 (67%)]	Loss: 0.669811
[2022-06-11 14:17:48 | train] - Train Epoch: [130] [870400/1281167 (68%)]	Loss: 0.563761
[2022-06-11 14:18:10 | train] - Train Epoch: [130] [883200/1281167 (69%)]	Loss: 0.591765
[2022-06-11 14:18:31 | train] - Train Epoch: [130] [896000/1281167 (70%)]	Loss: 0.821963
[2022-06-11 14:18:54 | train] - Train Epoch: [130] [908800/1281167 (71%)]	Loss: 0.661237
[2022-06-11 14:19:15 | train] - Train Epoch: [130] [921600/1281167 (72%)]	Loss: 0.831131
[2022-06-11 14:19:37 | train] - Train Epoch: [130] [934400/1281167 (73%)]	Loss: 0.738680
[2022-06-11 14:19:59 | train] - Train Epoch: [130] [947200/1281167 (74%)]	Loss: 0.811455
[2022-06-11 14:20:21 | train] - Train Epoch: [130] [960000/1281167 (75%)]	Loss: 0.572901
[2022-06-11 14:20:43 | train] - Train Epoch: [130] [972800/1281167 (76%)]	Loss: 0.696570
[2022-06-11 14:21:04 | train] - Train Epoch: [130] [985600/1281167 (77%)]	Loss: 0.592451
[2022-06-11 14:21:27 | train] - Train Epoch: [130] [998400/1281167 (78%)]	Loss: 0.755223
[2022-06-11 14:21:48 | train] - Train Epoch: [130] [1011200/1281167 (79%)]	Loss: 0.646113
[2022-06-11 14:22:10 | train] - Train Epoch: [130] [1024000/1281167 (80%)]	Loss: 0.534692
[2022-06-11 14:22:32 | train] - Train Epoch: [130] [1036800/1281167 (81%)]	Loss: 0.646201
[2022-06-11 14:22:54 | train] - Train Epoch: [130] [1049600/1281167 (82%)]	Loss: 0.703969
[2022-06-11 14:23:17 | train] - Train Epoch: [130] [1062400/1281167 (83%)]	Loss: 0.559738
[2022-06-11 14:23:40 | train] - Train Epoch: [130] [1075200/1281167 (84%)]	Loss: 0.758038
[2022-06-11 14:24:02 | train] - Train Epoch: [130] [1088000/1281167 (85%)]	Loss: 0.551063
[2022-06-11 14:24:24 | train] - Train Epoch: [130] [1100800/1281167 (86%)]	Loss: 0.591620
[2022-06-11 14:24:46 | train] - Train Epoch: [130] [1113600/1281167 (87%)]	Loss: 0.759012
[2022-06-11 14:25:07 | train] - Train Epoch: [130] [1126400/1281167 (88%)]	Loss: 1.083644
[2022-06-11 14:25:30 | train] - Train Epoch: [130] [1139200/1281167 (89%)]	Loss: 0.661366
[2022-06-11 14:25:51 | train] - Train Epoch: [130] [1152000/1281167 (90%)]	Loss: 0.811500
[2022-06-11 14:26:13 | train] - Train Epoch: [130] [1164800/1281167 (91%)]	Loss: 0.891413
[2022-06-11 14:26:35 | train] - Train Epoch: [130] [1177600/1281167 (92%)]	Loss: 0.648142
[2022-06-11 14:26:57 | train] - Train Epoch: [130] [1190400/1281167 (93%)]	Loss: 0.662095
[2022-06-11 14:27:20 | train] - Train Epoch: [130] [1203200/1281167 (94%)]	Loss: 0.744279
[2022-06-11 14:27:41 | train] - Train Epoch: [130] [1216000/1281167 (95%)]	Loss: 0.531570
[2022-06-11 14:28:04 | train] - Train Epoch: [130] [1228800/1281167 (96%)]	Loss: 0.732651
[2022-06-11 14:28:25 | train] - Train Epoch: [130] [1241600/1281167 (97%)]	Loss: 0.612544
[2022-06-11 14:28:47 | train] - Train Epoch: [130] [1254400/1281167 (98%)]	Loss: 0.783799
[2022-06-11 14:29:09 | train] - Train Epoch: [130] [1267200/1281167 (99%)]	Loss: 0.675974
[2022-06-11 14:29:32 | train] - Train Epoch: [130] [1280000/1281167 (100%)]	Loss: 0.827457
[2022-06-11 14:29:33 | train] - Train Epoch: [130]	 Average Loss: 0.757813	 Total Acc : 81.5440	 Total Top5 Acc : 93.2720
[2022-06-11 14:29:33 | train] - -------130 epoch end-----------
========================================
-------130 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 14:31:06 | train] - 
Epoch [130] Test set: Average loss: 1.4126, Accuracy: 34990/50000 (69.9524%), Top-5 Accuracy: 88.9362%

[2022-06-11 14:31:06 | train] - save intermediate epoch [130] result


[2022-06-11 14:31:12 | train] - -------131 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 14:31:14 | train] - Train Epoch: [131] [0/1281167 (0%)]	Loss: 0.716675
[2022-06-11 14:31:36 | train] - Train Epoch: [131] [12800/1281167 (1%)]	Loss: 0.763796
[2022-06-11 14:31:58 | train] - Train Epoch: [131] [25600/1281167 (2%)]	Loss: 0.771563
[2022-06-11 14:32:20 | train] - Train Epoch: [131] [38400/1281167 (3%)]	Loss: 0.823282
[2022-06-11 14:32:42 | train] - Train Epoch: [131] [51200/1281167 (4%)]	Loss: 1.025621
[2022-06-11 14:33:04 | train] - Train Epoch: [131] [64000/1281167 (5%)]	Loss: 0.820539
[2022-06-11 14:33:26 | train] - Train Epoch: [131] [76800/1281167 (6%)]	Loss: 0.529603
[2022-06-11 14:33:48 | train] - Train Epoch: [131] [89600/1281167 (7%)]	Loss: 0.782913
[2022-06-11 14:34:10 | train] - Train Epoch: [131] [102400/1281167 (8%)]	Loss: 0.806320
[2022-06-11 14:34:32 | train] - Train Epoch: [131] [115200/1281167 (9%)]	Loss: 0.814635
[2022-06-11 14:34:54 | train] - Train Epoch: [131] [128000/1281167 (10%)]	Loss: 0.702363
[2022-06-11 14:35:17 | train] - Train Epoch: [131] [140800/1281167 (11%)]	Loss: 0.745993
[2022-06-11 14:35:38 | train] - Train Epoch: [131] [153600/1281167 (12%)]	Loss: 0.764768
[2022-06-11 14:36:01 | train] - Train Epoch: [131] [166400/1281167 (13%)]	Loss: 0.515670
[2022-06-11 14:36:23 | train] - Train Epoch: [131] [179200/1281167 (14%)]	Loss: 0.922345
[2022-06-11 14:36:45 | train] - Train Epoch: [131] [192000/1281167 (15%)]	Loss: 0.709355
[2022-06-11 14:37:08 | train] - Train Epoch: [131] [204800/1281167 (16%)]	Loss: 0.771043
[2022-06-11 14:37:30 | train] - Train Epoch: [131] [217600/1281167 (17%)]	Loss: 0.791798
[2022-06-11 14:37:52 | train] - Train Epoch: [131] [230400/1281167 (18%)]	Loss: 0.729821
[2022-06-11 14:38:14 | train] - Train Epoch: [131] [243200/1281167 (19%)]	Loss: 0.841231
[2022-06-11 14:38:36 | train] - Train Epoch: [131] [256000/1281167 (20%)]	Loss: 0.748043
[2022-06-11 14:38:58 | train] - Train Epoch: [131] [268800/1281167 (21%)]	Loss: 0.997775
[2022-06-11 14:39:20 | train] - Train Epoch: [131] [281600/1281167 (22%)]	Loss: 0.704126
[2022-06-11 14:39:43 | train] - Train Epoch: [131] [294400/1281167 (23%)]	Loss: 0.961604
[2022-06-11 14:40:04 | train] - Train Epoch: [131] [307200/1281167 (24%)]	Loss: 1.058108
[2022-06-11 14:40:27 | train] - Train Epoch: [131] [320000/1281167 (25%)]	Loss: 0.931267
[2022-06-11 14:40:49 | train] - Train Epoch: [131] [332800/1281167 (26%)]	Loss: 0.780917
[2022-06-11 14:41:11 | train] - Train Epoch: [131] [345600/1281167 (27%)]	Loss: 0.697996
[2022-06-11 14:41:32 | train] - Train Epoch: [131] [358400/1281167 (28%)]	Loss: 0.648193
[2022-06-11 14:41:55 | train] - Train Epoch: [131] [371200/1281167 (29%)]	Loss: 0.795522
[2022-06-11 14:42:16 | train] - Train Epoch: [131] [384000/1281167 (30%)]	Loss: 0.699826
[2022-06-11 14:42:37 | train] - Train Epoch: [131] [396800/1281167 (31%)]	Loss: 0.630279
[2022-06-11 14:42:58 | train] - Train Epoch: [131] [409600/1281167 (32%)]	Loss: 0.634905
[2022-06-11 14:43:20 | train] - Train Epoch: [131] [422400/1281167 (33%)]	Loss: 0.739131
[2022-06-11 14:43:42 | train] - Train Epoch: [131] [435200/1281167 (34%)]	Loss: 0.879323
[2022-06-11 14:44:04 | train] - Train Epoch: [131] [448000/1281167 (35%)]	Loss: 0.626240
[2022-06-11 14:44:25 | train] - Train Epoch: [131] [460800/1281167 (36%)]	Loss: 0.834103
[2022-06-11 14:44:47 | train] - Train Epoch: [131] [473600/1281167 (37%)]	Loss: 0.962577
[2022-06-11 14:45:10 | train] - Train Epoch: [131] [486400/1281167 (38%)]	Loss: 0.792865
[2022-06-11 14:45:32 | train] - Train Epoch: [131] [499200/1281167 (39%)]	Loss: 0.745004
[2022-06-11 14:45:54 | train] - Train Epoch: [131] [512000/1281167 (40%)]	Loss: 0.899464
[2022-06-11 14:46:16 | train] - Train Epoch: [131] [524800/1281167 (41%)]	Loss: 0.799094
[2022-06-11 14:46:38 | train] - Train Epoch: [131] [537600/1281167 (42%)]	Loss: 0.706336
[2022-06-11 14:47:00 | train] - Train Epoch: [131] [550400/1281167 (43%)]	Loss: 0.609526
[2022-06-11 14:47:22 | train] - Train Epoch: [131] [563200/1281167 (44%)]	Loss: 0.648912
[2022-06-11 14:47:43 | train] - Train Epoch: [131] [576000/1281167 (45%)]	Loss: 0.606671
[2022-06-11 14:48:04 | train] - Train Epoch: [131] [588800/1281167 (46%)]	Loss: 0.766712
[2022-06-11 14:48:26 | train] - Train Epoch: [131] [601600/1281167 (47%)]	Loss: 0.815568
[2022-06-11 14:48:48 | train] - Train Epoch: [131] [614400/1281167 (48%)]	Loss: 0.993656
[2022-06-11 14:49:10 | train] - Train Epoch: [131] [627200/1281167 (49%)]	Loss: 0.743114
[2022-06-11 14:49:31 | train] - Train Epoch: [131] [640000/1281167 (50%)]	Loss: 0.762065
[2022-06-11 14:49:53 | train] - Train Epoch: [131] [652800/1281167 (51%)]	Loss: 0.875985
[2022-06-11 14:50:15 | train] - Train Epoch: [131] [665600/1281167 (52%)]	Loss: 0.785636
[2022-06-11 14:50:35 | train] - Train Epoch: [131] [678400/1281167 (53%)]	Loss: 0.726365
[2022-06-11 14:50:57 | train] - Train Epoch: [131] [691200/1281167 (54%)]	Loss: 0.683041
[2022-06-11 14:51:19 | train] - Train Epoch: [131] [704000/1281167 (55%)]	Loss: 0.939959
[2022-06-11 14:51:41 | train] - Train Epoch: [131] [716800/1281167 (56%)]	Loss: 0.682348
[2022-06-11 14:52:03 | train] - Train Epoch: [131] [729600/1281167 (57%)]	Loss: 1.026199
[2022-06-11 14:52:25 | train] - Train Epoch: [131] [742400/1281167 (58%)]	Loss: 0.572214
[2022-06-11 14:52:47 | train] - Train Epoch: [131] [755200/1281167 (59%)]	Loss: 0.621918
[2022-06-11 14:53:10 | train] - Train Epoch: [131] [768000/1281167 (60%)]	Loss: 0.534772
[2022-06-11 14:53:32 | train] - Train Epoch: [131] [780800/1281167 (61%)]	Loss: 0.657923
[2022-06-11 14:53:54 | train] - Train Epoch: [131] [793600/1281167 (62%)]	Loss: 0.971966
[2022-06-11 14:54:16 | train] - Train Epoch: [131] [806400/1281167 (63%)]	Loss: 0.894832
[2022-06-11 14:54:38 | train] - Train Epoch: [131] [819200/1281167 (64%)]	Loss: 0.898339
[2022-06-11 14:55:00 | train] - Train Epoch: [131] [832000/1281167 (65%)]	Loss: 0.773678
[2022-06-11 14:55:22 | train] - Train Epoch: [131] [844800/1281167 (66%)]	Loss: 0.644128
[2022-06-11 14:55:44 | train] - Train Epoch: [131] [857600/1281167 (67%)]	Loss: 0.639739
[2022-06-11 14:56:07 | train] - Train Epoch: [131] [870400/1281167 (68%)]	Loss: 0.992150
[2022-06-11 14:56:29 | train] - Train Epoch: [131] [883200/1281167 (69%)]	Loss: 0.799393
[2022-06-11 14:56:51 | train] - Train Epoch: [131] [896000/1281167 (70%)]	Loss: 0.868224
[2022-06-11 14:57:14 | train] - Train Epoch: [131] [908800/1281167 (71%)]	Loss: 0.757084
[2022-06-11 14:57:36 | train] - Train Epoch: [131] [921600/1281167 (72%)]	Loss: 0.856154
[2022-06-11 14:57:58 | train] - Train Epoch: [131] [934400/1281167 (73%)]	Loss: 0.642373
[2022-06-11 14:58:20 | train] - Train Epoch: [131] [947200/1281167 (74%)]	Loss: 0.867218
[2022-06-11 14:58:42 | train] - Train Epoch: [131] [960000/1281167 (75%)]	Loss: 0.556387
[2022-06-11 14:59:05 | train] - Train Epoch: [131] [972800/1281167 (76%)]	Loss: 0.693652
[2022-06-11 14:59:27 | train] - Train Epoch: [131] [985600/1281167 (77%)]	Loss: 0.842777
[2022-06-11 14:59:49 | train] - Train Epoch: [131] [998400/1281167 (78%)]	Loss: 0.693863
[2022-06-11 15:00:12 | train] - Train Epoch: [131] [1011200/1281167 (79%)]	Loss: 0.702644
[2022-06-11 15:00:34 | train] - Train Epoch: [131] [1024000/1281167 (80%)]	Loss: 0.840749
[2022-06-11 15:00:56 | train] - Train Epoch: [131] [1036800/1281167 (81%)]	Loss: 0.723890
[2022-06-11 15:01:18 | train] - Train Epoch: [131] [1049600/1281167 (82%)]	Loss: 0.887639
[2022-06-11 15:01:41 | train] - Train Epoch: [131] [1062400/1281167 (83%)]	Loss: 0.604769
[2022-06-11 15:02:03 | train] - Train Epoch: [131] [1075200/1281167 (84%)]	Loss: 0.613145
[2022-06-11 15:02:25 | train] - Train Epoch: [131] [1088000/1281167 (85%)]	Loss: 0.744267
[2022-06-11 15:02:48 | train] - Train Epoch: [131] [1100800/1281167 (86%)]	Loss: 0.635464
[2022-06-11 15:03:10 | train] - Train Epoch: [131] [1113600/1281167 (87%)]	Loss: 0.610374
[2022-06-11 15:03:31 | train] - Train Epoch: [131] [1126400/1281167 (88%)]	Loss: 0.592870
[2022-06-11 15:03:54 | train] - Train Epoch: [131] [1139200/1281167 (89%)]	Loss: 0.727239
[2022-06-11 15:04:16 | train] - Train Epoch: [131] [1152000/1281167 (90%)]	Loss: 0.950438
[2022-06-11 15:04:38 | train] - Train Epoch: [131] [1164800/1281167 (91%)]	Loss: 0.656392
[2022-06-11 15:05:00 | train] - Train Epoch: [131] [1177600/1281167 (92%)]	Loss: 0.816212
[2022-06-11 15:05:22 | train] - Train Epoch: [131] [1190400/1281167 (93%)]	Loss: 0.743701
[2022-06-11 15:05:45 | train] - Train Epoch: [131] [1203200/1281167 (94%)]	Loss: 0.611045
[2022-06-11 15:06:06 | train] - Train Epoch: [131] [1216000/1281167 (95%)]	Loss: 0.879625
[2022-06-11 15:06:28 | train] - Train Epoch: [131] [1228800/1281167 (96%)]	Loss: 0.860626
[2022-06-11 15:06:50 | train] - Train Epoch: [131] [1241600/1281167 (97%)]	Loss: 0.651144
[2022-06-11 15:07:12 | train] - Train Epoch: [131] [1254400/1281167 (98%)]	Loss: 0.528465
[2022-06-11 15:07:34 | train] - Train Epoch: [131] [1267200/1281167 (99%)]	Loss: 0.830654
[2022-06-11 15:07:57 | train] - Train Epoch: [131] [1280000/1281167 (100%)]	Loss: 0.790075
[2022-06-11 15:07:59 | train] - Train Epoch: [131]	 Average Loss: 0.756473	 Total Acc : 81.5471	 Total Top5 Acc : 93.3021
[2022-06-11 15:07:59 | train] - -------131 epoch end-----------
========================================
-------131 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 15:09:32 | train] - 
Epoch [131] Test set: Average loss: 1.4062, Accuracy: 35002/50000 (69.9764%), Top-5 Accuracy: 89.0329%

[2022-06-11 15:09:32 | train] - save intermediate epoch [131] result


[2022-06-11 15:09:38 | train] - -------132 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 15:09:40 | train] - Train Epoch: [132] [0/1281167 (0%)]	Loss: 0.897972
[2022-06-11 15:10:02 | train] - Train Epoch: [132] [12800/1281167 (1%)]	Loss: 0.573435
[2022-06-11 15:10:24 | train] - Train Epoch: [132] [25600/1281167 (2%)]	Loss: 0.886126
[2022-06-11 15:10:45 | train] - Train Epoch: [132] [38400/1281167 (3%)]	Loss: 0.851496
[2022-06-11 15:11:07 | train] - Train Epoch: [132] [51200/1281167 (4%)]	Loss: 0.829094
[2022-06-11 15:11:30 | train] - Train Epoch: [132] [64000/1281167 (5%)]	Loss: 0.826641
[2022-06-11 15:11:52 | train] - Train Epoch: [132] [76800/1281167 (6%)]	Loss: 1.011076
[2022-06-11 15:12:14 | train] - Train Epoch: [132] [89600/1281167 (7%)]	Loss: 0.887070
[2022-06-11 15:12:37 | train] - Train Epoch: [132] [102400/1281167 (8%)]	Loss: 0.789822
[2022-06-11 15:12:59 | train] - Train Epoch: [132] [115200/1281167 (9%)]	Loss: 0.538494
[2022-06-11 15:13:21 | train] - Train Epoch: [132] [128000/1281167 (10%)]	Loss: 0.678027
[2022-06-11 15:13:43 | train] - Train Epoch: [132] [140800/1281167 (11%)]	Loss: 0.898531
[2022-06-11 15:14:05 | train] - Train Epoch: [132] [153600/1281167 (12%)]	Loss: 0.930850
[2022-06-11 15:14:27 | train] - Train Epoch: [132] [166400/1281167 (13%)]	Loss: 0.893476
[2022-06-11 15:14:49 | train] - Train Epoch: [132] [179200/1281167 (14%)]	Loss: 0.784363
[2022-06-11 15:15:11 | train] - Train Epoch: [132] [192000/1281167 (15%)]	Loss: 0.913752
[2022-06-11 15:15:33 | train] - Train Epoch: [132] [204800/1281167 (16%)]	Loss: 0.982362
[2022-06-11 15:15:55 | train] - Train Epoch: [132] [217600/1281167 (17%)]	Loss: 0.669856
[2022-06-11 15:16:17 | train] - Train Epoch: [132] [230400/1281167 (18%)]	Loss: 0.832226
[2022-06-11 15:16:38 | train] - Train Epoch: [132] [243200/1281167 (19%)]	Loss: 0.563508
[2022-06-11 15:17:00 | train] - Train Epoch: [132] [256000/1281167 (20%)]	Loss: 0.746937
[2022-06-11 15:17:23 | train] - Train Epoch: [132] [268800/1281167 (21%)]	Loss: 0.997706
[2022-06-11 15:17:45 | train] - Train Epoch: [132] [281600/1281167 (22%)]	Loss: 0.752328
[2022-06-11 15:18:07 | train] - Train Epoch: [132] [294400/1281167 (23%)]	Loss: 0.697225
[2022-06-11 15:18:29 | train] - Train Epoch: [132] [307200/1281167 (24%)]	Loss: 0.945721
[2022-06-11 15:18:51 | train] - Train Epoch: [132] [320000/1281167 (25%)]	Loss: 0.758559
[2022-06-11 15:19:13 | train] - Train Epoch: [132] [332800/1281167 (26%)]	Loss: 0.674131
[2022-06-11 15:19:35 | train] - Train Epoch: [132] [345600/1281167 (27%)]	Loss: 0.609163
[2022-06-11 15:19:58 | train] - Train Epoch: [132] [358400/1281167 (28%)]	Loss: 0.888612
[2022-06-11 15:20:19 | train] - Train Epoch: [132] [371200/1281167 (29%)]	Loss: 0.738859
[2022-06-11 15:20:42 | train] - Train Epoch: [132] [384000/1281167 (30%)]	Loss: 0.602315
[2022-06-11 15:21:04 | train] - Train Epoch: [132] [396800/1281167 (31%)]	Loss: 0.684704
[2022-06-11 15:21:26 | train] - Train Epoch: [132] [409600/1281167 (32%)]	Loss: 0.703569
[2022-06-11 15:21:48 | train] - Train Epoch: [132] [422400/1281167 (33%)]	Loss: 0.814270
[2022-06-11 15:22:10 | train] - Train Epoch: [132] [435200/1281167 (34%)]	Loss: 0.661584
[2022-06-11 15:22:31 | train] - Train Epoch: [132] [448000/1281167 (35%)]	Loss: 0.619335
[2022-06-11 15:22:53 | train] - Train Epoch: [132] [460800/1281167 (36%)]	Loss: 0.890836
[2022-06-11 15:23:15 | train] - Train Epoch: [132] [473600/1281167 (37%)]	Loss: 0.826302
[2022-06-11 15:23:36 | train] - Train Epoch: [132] [486400/1281167 (38%)]	Loss: 0.776217
[2022-06-11 15:23:58 | train] - Train Epoch: [132] [499200/1281167 (39%)]	Loss: 0.734489
[2022-06-11 15:24:20 | train] - Train Epoch: [132] [512000/1281167 (40%)]	Loss: 0.821143
[2022-06-11 15:24:40 | train] - Train Epoch: [132] [524800/1281167 (41%)]	Loss: 0.796391
[2022-06-11 15:25:02 | train] - Train Epoch: [132] [537600/1281167 (42%)]	Loss: 0.764851
[2022-06-11 15:25:24 | train] - Train Epoch: [132] [550400/1281167 (43%)]	Loss: 0.597242
[2022-06-11 15:25:45 | train] - Train Epoch: [132] [563200/1281167 (44%)]	Loss: 0.785548
[2022-06-11 15:26:06 | train] - Train Epoch: [132] [576000/1281167 (45%)]	Loss: 0.514561
[2022-06-11 15:26:28 | train] - Train Epoch: [132] [588800/1281167 (46%)]	Loss: 0.839806
[2022-06-11 15:26:49 | train] - Train Epoch: [132] [601600/1281167 (47%)]	Loss: 0.807795
[2022-06-11 15:27:12 | train] - Train Epoch: [132] [614400/1281167 (48%)]	Loss: 0.570499
[2022-06-11 15:27:34 | train] - Train Epoch: [132] [627200/1281167 (49%)]	Loss: 0.680350
[2022-06-11 15:27:56 | train] - Train Epoch: [132] [640000/1281167 (50%)]	Loss: 0.612712
[2022-06-11 15:28:17 | train] - Train Epoch: [132] [652800/1281167 (51%)]	Loss: 0.774764
[2022-06-11 15:28:40 | train] - Train Epoch: [132] [665600/1281167 (52%)]	Loss: 0.587558
[2022-06-11 15:29:01 | train] - Train Epoch: [132] [678400/1281167 (53%)]	Loss: 0.836372
[2022-06-11 15:29:23 | train] - Train Epoch: [132] [691200/1281167 (54%)]	Loss: 0.687145
[2022-06-11 15:29:44 | train] - Train Epoch: [132] [704000/1281167 (55%)]	Loss: 0.624166
[2022-06-11 15:30:06 | train] - Train Epoch: [132] [716800/1281167 (56%)]	Loss: 0.859045
[2022-06-11 15:30:27 | train] - Train Epoch: [132] [729600/1281167 (57%)]	Loss: 0.578892
[2022-06-11 15:30:49 | train] - Train Epoch: [132] [742400/1281167 (58%)]	Loss: 0.622490
[2022-06-11 15:31:11 | train] - Train Epoch: [132] [755200/1281167 (59%)]	Loss: 0.742966
[2022-06-11 15:31:32 | train] - Train Epoch: [132] [768000/1281167 (60%)]	Loss: 0.811710
[2022-06-11 15:31:54 | train] - Train Epoch: [132] [780800/1281167 (61%)]	Loss: 0.811494
[2022-06-11 15:32:16 | train] - Train Epoch: [132] [793600/1281167 (62%)]	Loss: 0.778130
[2022-06-11 15:32:38 | train] - Train Epoch: [132] [806400/1281167 (63%)]	Loss: 0.859682
[2022-06-11 15:32:59 | train] - Train Epoch: [132] [819200/1281167 (64%)]	Loss: 0.838275
[2022-06-11 15:33:21 | train] - Train Epoch: [132] [832000/1281167 (65%)]	Loss: 1.107141
[2022-06-11 15:33:43 | train] - Train Epoch: [132] [844800/1281167 (66%)]	Loss: 0.598241
[2022-06-11 15:34:04 | train] - Train Epoch: [132] [857600/1281167 (67%)]	Loss: 1.072531
[2022-06-11 15:34:26 | train] - Train Epoch: [132] [870400/1281167 (68%)]	Loss: 0.821516
[2022-06-11 15:34:47 | train] - Train Epoch: [132] [883200/1281167 (69%)]	Loss: 0.934753
[2022-06-11 15:35:09 | train] - Train Epoch: [132] [896000/1281167 (70%)]	Loss: 0.747854
[2022-06-11 15:35:31 | train] - Train Epoch: [132] [908800/1281167 (71%)]	Loss: 0.730244
[2022-06-11 15:35:53 | train] - Train Epoch: [132] [921600/1281167 (72%)]	Loss: 0.937569
[2022-06-11 15:36:15 | train] - Train Epoch: [132] [934400/1281167 (73%)]	Loss: 0.823213
[2022-06-11 15:36:38 | train] - Train Epoch: [132] [947200/1281167 (74%)]	Loss: 0.574458
[2022-06-11 15:37:00 | train] - Train Epoch: [132] [960000/1281167 (75%)]	Loss: 1.089656
[2022-06-11 15:37:21 | train] - Train Epoch: [132] [972800/1281167 (76%)]	Loss: 0.721426
[2022-06-11 15:37:43 | train] - Train Epoch: [132] [985600/1281167 (77%)]	Loss: 0.783594
[2022-06-11 15:38:05 | train] - Train Epoch: [132] [998400/1281167 (78%)]	Loss: 0.828233
[2022-06-11 15:38:26 | train] - Train Epoch: [132] [1011200/1281167 (79%)]	Loss: 0.912755
[2022-06-11 15:38:49 | train] - Train Epoch: [132] [1024000/1281167 (80%)]	Loss: 0.831176
[2022-06-11 15:39:11 | train] - Train Epoch: [132] [1036800/1281167 (81%)]	Loss: 0.765213
[2022-06-11 15:39:33 | train] - Train Epoch: [132] [1049600/1281167 (82%)]	Loss: 0.720183
[2022-06-11 15:39:55 | train] - Train Epoch: [132] [1062400/1281167 (83%)]	Loss: 0.624255
[2022-06-11 15:40:17 | train] - Train Epoch: [132] [1075200/1281167 (84%)]	Loss: 0.750971
[2022-06-11 15:40:39 | train] - Train Epoch: [132] [1088000/1281167 (85%)]	Loss: 0.793028
[2022-06-11 15:41:01 | train] - Train Epoch: [132] [1100800/1281167 (86%)]	Loss: 0.501692
[2022-06-11 15:41:23 | train] - Train Epoch: [132] [1113600/1281167 (87%)]	Loss: 0.688468
[2022-06-11 15:41:45 | train] - Train Epoch: [132] [1126400/1281167 (88%)]	Loss: 0.548779
[2022-06-11 15:42:07 | train] - Train Epoch: [132] [1139200/1281167 (89%)]	Loss: 0.721954
[2022-06-11 15:42:29 | train] - Train Epoch: [132] [1152000/1281167 (90%)]	Loss: 0.906821
[2022-06-11 15:42:51 | train] - Train Epoch: [132] [1164800/1281167 (91%)]	Loss: 0.969882
[2022-06-11 15:43:13 | train] - Train Epoch: [132] [1177600/1281167 (92%)]	Loss: 0.659179
[2022-06-11 15:43:35 | train] - Train Epoch: [132] [1190400/1281167 (93%)]	Loss: 0.789966
[2022-06-11 15:43:56 | train] - Train Epoch: [132] [1203200/1281167 (94%)]	Loss: 0.884331
[2022-06-11 15:44:19 | train] - Train Epoch: [132] [1216000/1281167 (95%)]	Loss: 0.516027
[2022-06-11 15:44:41 | train] - Train Epoch: [132] [1228800/1281167 (96%)]	Loss: 0.604139
[2022-06-11 15:45:03 | train] - Train Epoch: [132] [1241600/1281167 (97%)]	Loss: 0.833889
[2022-06-11 15:45:25 | train] - Train Epoch: [132] [1254400/1281167 (98%)]	Loss: 0.755509
[2022-06-11 15:45:48 | train] - Train Epoch: [132] [1267200/1281167 (99%)]	Loss: 0.522215
[2022-06-11 15:46:10 | train] - Train Epoch: [132] [1280000/1281167 (100%)]	Loss: 0.623062
[2022-06-11 15:46:11 | train] - Train Epoch: [132]	 Average Loss: 0.754798	 Total Acc : 81.6015	 Total Top5 Acc : 93.3068
[2022-06-11 15:46:11 | train] - -------132 epoch end-----------
========================================
-------132 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 15:47:44 | train] - 
Epoch [132] Test set: Average loss: 1.4071, Accuracy: 34997/50000 (69.9664%), Top-5 Accuracy: 88.9082%

[2022-06-11 15:47:44 | train] - save intermediate epoch [132] result


[2022-06-11 15:47:51 | train] - -------133 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 15:47:52 | train] - Train Epoch: [133] [0/1281167 (0%)]	Loss: 0.937819
[2022-06-11 15:48:15 | train] - Train Epoch: [133] [12800/1281167 (1%)]	Loss: 0.927029
[2022-06-11 15:48:36 | train] - Train Epoch: [133] [25600/1281167 (2%)]	Loss: 0.845015
[2022-06-11 15:48:58 | train] - Train Epoch: [133] [38400/1281167 (3%)]	Loss: 0.769114
[2022-06-11 15:49:20 | train] - Train Epoch: [133] [51200/1281167 (4%)]	Loss: 0.814913
[2022-06-11 15:49:42 | train] - Train Epoch: [133] [64000/1281167 (5%)]	Loss: 1.002998
[2022-06-11 15:50:03 | train] - Train Epoch: [133] [76800/1281167 (6%)]	Loss: 0.649295
[2022-06-11 15:50:26 | train] - Train Epoch: [133] [89600/1281167 (7%)]	Loss: 0.940821
[2022-06-11 15:50:48 | train] - Train Epoch: [133] [102400/1281167 (8%)]	Loss: 1.030280
[2022-06-11 15:51:10 | train] - Train Epoch: [133] [115200/1281167 (9%)]	Loss: 0.900036
[2022-06-11 15:51:32 | train] - Train Epoch: [133] [128000/1281167 (10%)]	Loss: 0.673388
[2022-06-11 15:51:53 | train] - Train Epoch: [133] [140800/1281167 (11%)]	Loss: 0.790881
[2022-06-11 15:52:15 | train] - Train Epoch: [133] [153600/1281167 (12%)]	Loss: 0.524427
[2022-06-11 15:52:37 | train] - Train Epoch: [133] [166400/1281167 (13%)]	Loss: 0.704945
[2022-06-11 15:52:59 | train] - Train Epoch: [133] [179200/1281167 (14%)]	Loss: 0.784805
[2022-06-11 15:53:21 | train] - Train Epoch: [133] [192000/1281167 (15%)]	Loss: 0.709399
[2022-06-11 15:53:43 | train] - Train Epoch: [133] [204800/1281167 (16%)]	Loss: 1.003212
[2022-06-11 15:54:04 | train] - Train Epoch: [133] [217600/1281167 (17%)]	Loss: 0.810538
[2022-06-11 15:54:26 | train] - Train Epoch: [133] [230400/1281167 (18%)]	Loss: 0.655965
[2022-06-11 15:54:48 | train] - Train Epoch: [133] [243200/1281167 (19%)]	Loss: 0.966334
[2022-06-11 15:55:10 | train] - Train Epoch: [133] [256000/1281167 (20%)]	Loss: 0.999112
[2022-06-11 15:55:32 | train] - Train Epoch: [133] [268800/1281167 (21%)]	Loss: 0.788210
[2022-06-11 15:55:55 | train] - Train Epoch: [133] [281600/1281167 (22%)]	Loss: 0.698587
[2022-06-11 15:56:16 | train] - Train Epoch: [133] [294400/1281167 (23%)]	Loss: 0.571075
[2022-06-11 15:56:38 | train] - Train Epoch: [133] [307200/1281167 (24%)]	Loss: 0.753432
[2022-06-11 15:56:59 | train] - Train Epoch: [133] [320000/1281167 (25%)]	Loss: 0.974908
[2022-06-11 15:57:22 | train] - Train Epoch: [133] [332800/1281167 (26%)]	Loss: 0.725756
[2022-06-11 15:57:43 | train] - Train Epoch: [133] [345600/1281167 (27%)]	Loss: 0.694988
[2022-06-11 15:58:05 | train] - Train Epoch: [133] [358400/1281167 (28%)]	Loss: 0.767284
[2022-06-11 15:58:26 | train] - Train Epoch: [133] [371200/1281167 (29%)]	Loss: 0.783053
[2022-06-11 15:58:48 | train] - Train Epoch: [133] [384000/1281167 (30%)]	Loss: 0.608763
[2022-06-11 15:59:09 | train] - Train Epoch: [133] [396800/1281167 (31%)]	Loss: 0.712850
[2022-06-11 15:59:31 | train] - Train Epoch: [133] [409600/1281167 (32%)]	Loss: 0.809668
[2022-06-11 15:59:53 | train] - Train Epoch: [133] [422400/1281167 (33%)]	Loss: 0.918304
[2022-06-11 16:00:15 | train] - Train Epoch: [133] [435200/1281167 (34%)]	Loss: 0.713365
[2022-06-11 16:00:37 | train] - Train Epoch: [133] [448000/1281167 (35%)]	Loss: 0.709330
[2022-06-11 16:00:59 | train] - Train Epoch: [133] [460800/1281167 (36%)]	Loss: 0.840468
[2022-06-11 16:01:20 | train] - Train Epoch: [133] [473600/1281167 (37%)]	Loss: 0.562710
[2022-06-11 16:01:42 | train] - Train Epoch: [133] [486400/1281167 (38%)]	Loss: 0.586491
[2022-06-11 16:02:03 | train] - Train Epoch: [133] [499200/1281167 (39%)]	Loss: 0.642038
[2022-06-11 16:02:26 | train] - Train Epoch: [133] [512000/1281167 (40%)]	Loss: 0.567116
[2022-06-11 16:02:48 | train] - Train Epoch: [133] [524800/1281167 (41%)]	Loss: 0.693372
[2022-06-11 16:03:09 | train] - Train Epoch: [133] [537600/1281167 (42%)]	Loss: 0.798283
[2022-06-11 16:03:31 | train] - Train Epoch: [133] [550400/1281167 (43%)]	Loss: 0.677191
[2022-06-11 16:03:53 | train] - Train Epoch: [133] [563200/1281167 (44%)]	Loss: 0.794427
[2022-06-11 16:04:15 | train] - Train Epoch: [133] [576000/1281167 (45%)]	Loss: 0.787052
[2022-06-11 16:04:37 | train] - Train Epoch: [133] [588800/1281167 (46%)]	Loss: 0.922931
[2022-06-11 16:04:59 | train] - Train Epoch: [133] [601600/1281167 (47%)]	Loss: 0.636355
[2022-06-11 16:05:21 | train] - Train Epoch: [133] [614400/1281167 (48%)]	Loss: 0.693833
[2022-06-11 16:05:42 | train] - Train Epoch: [133] [627200/1281167 (49%)]	Loss: 0.716939
[2022-06-11 16:06:04 | train] - Train Epoch: [133] [640000/1281167 (50%)]	Loss: 0.745762
[2022-06-11 16:06:26 | train] - Train Epoch: [133] [652800/1281167 (51%)]	Loss: 0.820636
[2022-06-11 16:06:47 | train] - Train Epoch: [133] [665600/1281167 (52%)]	Loss: 0.773930
[2022-06-11 16:07:09 | train] - Train Epoch: [133] [678400/1281167 (53%)]	Loss: 0.579887
[2022-06-11 16:07:31 | train] - Train Epoch: [133] [691200/1281167 (54%)]	Loss: 0.686203
[2022-06-11 16:07:52 | train] - Train Epoch: [133] [704000/1281167 (55%)]	Loss: 0.643906
[2022-06-11 16:08:14 | train] - Train Epoch: [133] [716800/1281167 (56%)]	Loss: 0.809192
[2022-06-11 16:08:37 | train] - Train Epoch: [133] [729600/1281167 (57%)]	Loss: 0.774757
[2022-06-11 16:08:59 | train] - Train Epoch: [133] [742400/1281167 (58%)]	Loss: 0.805138
[2022-06-11 16:09:20 | train] - Train Epoch: [133] [755200/1281167 (59%)]	Loss: 0.822766
[2022-06-11 16:09:43 | train] - Train Epoch: [133] [768000/1281167 (60%)]	Loss: 1.025685
[2022-06-11 16:10:05 | train] - Train Epoch: [133] [780800/1281167 (61%)]	Loss: 0.909279
[2022-06-11 16:10:26 | train] - Train Epoch: [133] [793600/1281167 (62%)]	Loss: 0.718745
[2022-06-11 16:10:48 | train] - Train Epoch: [133] [806400/1281167 (63%)]	Loss: 0.743173
[2022-06-11 16:11:09 | train] - Train Epoch: [133] [819200/1281167 (64%)]	Loss: 0.705356
[2022-06-11 16:11:31 | train] - Train Epoch: [133] [832000/1281167 (65%)]	Loss: 0.754004
[2022-06-11 16:11:53 | train] - Train Epoch: [133] [844800/1281167 (66%)]	Loss: 0.742682
[2022-06-11 16:12:14 | train] - Train Epoch: [133] [857600/1281167 (67%)]	Loss: 1.125091
[2022-06-11 16:12:36 | train] - Train Epoch: [133] [870400/1281167 (68%)]	Loss: 0.680434
[2022-06-11 16:12:57 | train] - Train Epoch: [133] [883200/1281167 (69%)]	Loss: 0.792202
[2022-06-11 16:13:19 | train] - Train Epoch: [133] [896000/1281167 (70%)]	Loss: 0.773930
[2022-06-11 16:13:40 | train] - Train Epoch: [133] [908800/1281167 (71%)]	Loss: 0.638565
[2022-06-11 16:14:02 | train] - Train Epoch: [133] [921600/1281167 (72%)]	Loss: 0.634409
[2022-06-11 16:14:23 | train] - Train Epoch: [133] [934400/1281167 (73%)]	Loss: 0.798252
[2022-06-11 16:14:45 | train] - Train Epoch: [133] [947200/1281167 (74%)]	Loss: 0.933449
[2022-06-11 16:15:07 | train] - Train Epoch: [133] [960000/1281167 (75%)]	Loss: 0.787656
[2022-06-11 16:15:29 | train] - Train Epoch: [133] [972800/1281167 (76%)]	Loss: 0.569429
[2022-06-11 16:15:51 | train] - Train Epoch: [133] [985600/1281167 (77%)]	Loss: 0.419767
[2022-06-11 16:16:12 | train] - Train Epoch: [133] [998400/1281167 (78%)]	Loss: 0.887118
[2022-06-11 16:16:34 | train] - Train Epoch: [133] [1011200/1281167 (79%)]	Loss: 0.917888
[2022-06-11 16:16:56 | train] - Train Epoch: [133] [1024000/1281167 (80%)]	Loss: 0.540987
[2022-06-11 16:17:18 | train] - Train Epoch: [133] [1036800/1281167 (81%)]	Loss: 0.781182
[2022-06-11 16:17:40 | train] - Train Epoch: [133] [1049600/1281167 (82%)]	Loss: 0.753396
[2022-06-11 16:18:02 | train] - Train Epoch: [133] [1062400/1281167 (83%)]	Loss: 0.577748
[2022-06-11 16:18:24 | train] - Train Epoch: [133] [1075200/1281167 (84%)]	Loss: 0.513506
[2022-06-11 16:18:46 | train] - Train Epoch: [133] [1088000/1281167 (85%)]	Loss: 0.911051
[2022-06-11 16:19:08 | train] - Train Epoch: [133] [1100800/1281167 (86%)]	Loss: 0.788084
[2022-06-11 16:19:30 | train] - Train Epoch: [133] [1113600/1281167 (87%)]	Loss: 0.741508
[2022-06-11 16:19:52 | train] - Train Epoch: [133] [1126400/1281167 (88%)]	Loss: 0.869608
[2022-06-11 16:20:13 | train] - Train Epoch: [133] [1139200/1281167 (89%)]	Loss: 0.653513
[2022-06-11 16:20:35 | train] - Train Epoch: [133] [1152000/1281167 (90%)]	Loss: 0.660268
[2022-06-11 16:20:56 | train] - Train Epoch: [133] [1164800/1281167 (91%)]	Loss: 0.685342
[2022-06-11 16:21:18 | train] - Train Epoch: [133] [1177600/1281167 (92%)]	Loss: 0.861100
[2022-06-11 16:21:40 | train] - Train Epoch: [133] [1190400/1281167 (93%)]	Loss: 0.572876
[2022-06-11 16:22:02 | train] - Train Epoch: [133] [1203200/1281167 (94%)]	Loss: 0.784863
[2022-06-11 16:22:24 | train] - Train Epoch: [133] [1216000/1281167 (95%)]	Loss: 0.719798
[2022-06-11 16:22:46 | train] - Train Epoch: [133] [1228800/1281167 (96%)]	Loss: 0.642975
[2022-06-11 16:23:08 | train] - Train Epoch: [133] [1241600/1281167 (97%)]	Loss: 0.949657
[2022-06-11 16:23:30 | train] - Train Epoch: [133] [1254400/1281167 (98%)]	Loss: 0.751519
[2022-06-11 16:23:52 | train] - Train Epoch: [133] [1267200/1281167 (99%)]	Loss: 0.914155
[2022-06-11 16:24:13 | train] - Train Epoch: [133] [1280000/1281167 (100%)]	Loss: 0.718055
[2022-06-11 16:24:15 | train] - Train Epoch: [133]	 Average Loss: 0.753520	 Total Acc : 81.6519	 Total Top5 Acc : 93.3410
[2022-06-11 16:24:15 | train] - -------133 epoch end-----------
========================================
-------133 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 16:25:49 | train] - 
Epoch [133] Test set: Average loss: 1.4149, Accuracy: 34928/50000 (69.8274%), Top-5 Accuracy: 88.9674%

[2022-06-11 16:25:49 | train] - save intermediate epoch [133] result


[2022-06-11 16:25:56 | train] - -------134 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 16:25:58 | train] - Train Epoch: [134] [0/1281167 (0%)]	Loss: 0.755728
[2022-06-11 16:26:20 | train] - Train Epoch: [134] [12800/1281167 (1%)]	Loss: 0.847177
[2022-06-11 16:26:42 | train] - Train Epoch: [134] [25600/1281167 (2%)]	Loss: 0.776336
[2022-06-11 16:27:04 | train] - Train Epoch: [134] [38400/1281167 (3%)]	Loss: 0.855581
[2022-06-11 16:27:26 | train] - Train Epoch: [134] [51200/1281167 (4%)]	Loss: 0.822718
[2022-06-11 16:27:48 | train] - Train Epoch: [134] [64000/1281167 (5%)]	Loss: 0.802523
[2022-06-11 16:28:10 | train] - Train Epoch: [134] [76800/1281167 (6%)]	Loss: 1.017625
[2022-06-11 16:28:31 | train] - Train Epoch: [134] [89600/1281167 (7%)]	Loss: 0.435343
[2022-06-11 16:28:53 | train] - Train Epoch: [134] [102400/1281167 (8%)]	Loss: 0.914989
[2022-06-11 16:29:16 | train] - Train Epoch: [134] [115200/1281167 (9%)]	Loss: 0.517783
[2022-06-11 16:29:38 | train] - Train Epoch: [134] [128000/1281167 (10%)]	Loss: 0.572760
[2022-06-11 16:29:59 | train] - Train Epoch: [134] [140800/1281167 (11%)]	Loss: 0.980698
[2022-06-11 16:30:21 | train] - Train Epoch: [134] [153600/1281167 (12%)]	Loss: 0.772062
[2022-06-11 16:30:43 | train] - Train Epoch: [134] [166400/1281167 (13%)]	Loss: 0.657731
[2022-06-11 16:31:05 | train] - Train Epoch: [134] [179200/1281167 (14%)]	Loss: 0.951930
[2022-06-11 16:31:28 | train] - Train Epoch: [134] [192000/1281167 (15%)]	Loss: 1.045969
[2022-06-11 16:31:49 | train] - Train Epoch: [134] [204800/1281167 (16%)]	Loss: 0.761339
[2022-06-11 16:32:11 | train] - Train Epoch: [134] [217600/1281167 (17%)]	Loss: 0.513220
[2022-06-11 16:32:32 | train] - Train Epoch: [134] [230400/1281167 (18%)]	Loss: 0.759632
[2022-06-11 16:32:54 | train] - Train Epoch: [134] [243200/1281167 (19%)]	Loss: 0.658715
[2022-06-11 16:33:15 | train] - Train Epoch: [134] [256000/1281167 (20%)]	Loss: 0.708217
[2022-06-11 16:33:37 | train] - Train Epoch: [134] [268800/1281167 (21%)]	Loss: 0.656045
[2022-06-11 16:33:58 | train] - Train Epoch: [134] [281600/1281167 (22%)]	Loss: 1.015807
[2022-06-11 16:34:21 | train] - Train Epoch: [134] [294400/1281167 (23%)]	Loss: 0.836226
[2022-06-11 16:34:43 | train] - Train Epoch: [134] [307200/1281167 (24%)]	Loss: 0.813586
[2022-06-11 16:35:05 | train] - Train Epoch: [134] [320000/1281167 (25%)]	Loss: 0.734949
[2022-06-11 16:35:27 | train] - Train Epoch: [134] [332800/1281167 (26%)]	Loss: 0.899558
[2022-06-11 16:35:49 | train] - Train Epoch: [134] [345600/1281167 (27%)]	Loss: 0.809911
[2022-06-11 16:36:09 | train] - Train Epoch: [134] [358400/1281167 (28%)]	Loss: 0.648088
[2022-06-11 16:36:30 | train] - Train Epoch: [134] [371200/1281167 (29%)]	Loss: 0.800522
[2022-06-11 16:36:52 | train] - Train Epoch: [134] [384000/1281167 (30%)]	Loss: 0.787009
[2022-06-11 16:37:13 | train] - Train Epoch: [134] [396800/1281167 (31%)]	Loss: 0.662517
[2022-06-11 16:37:35 | train] - Train Epoch: [134] [409600/1281167 (32%)]	Loss: 0.686672
[2022-06-11 16:37:57 | train] - Train Epoch: [134] [422400/1281167 (33%)]	Loss: 0.731023
[2022-06-11 16:38:19 | train] - Train Epoch: [134] [435200/1281167 (34%)]	Loss: 0.874949
[2022-06-11 16:38:40 | train] - Train Epoch: [134] [448000/1281167 (35%)]	Loss: 1.035077
[2022-06-11 16:39:02 | train] - Train Epoch: [134] [460800/1281167 (36%)]	Loss: 0.598265
[2022-06-11 16:39:23 | train] - Train Epoch: [134] [473600/1281167 (37%)]	Loss: 0.882827
[2022-06-11 16:39:46 | train] - Train Epoch: [134] [486400/1281167 (38%)]	Loss: 0.968536
[2022-06-11 16:40:08 | train] - Train Epoch: [134] [499200/1281167 (39%)]	Loss: 0.766761
[2022-06-11 16:40:30 | train] - Train Epoch: [134] [512000/1281167 (40%)]	Loss: 0.854674
[2022-06-11 16:40:50 | train] - Train Epoch: [134] [524800/1281167 (41%)]	Loss: 0.534791
[2022-06-11 16:41:11 | train] - Train Epoch: [134] [537600/1281167 (42%)]	Loss: 0.686943
[2022-06-11 16:41:33 | train] - Train Epoch: [134] [550400/1281167 (43%)]	Loss: 0.534304
[2022-06-11 16:41:55 | train] - Train Epoch: [134] [563200/1281167 (44%)]	Loss: 0.794440
[2022-06-11 16:42:17 | train] - Train Epoch: [134] [576000/1281167 (45%)]	Loss: 0.942778
[2022-06-11 16:42:39 | train] - Train Epoch: [134] [588800/1281167 (46%)]	Loss: 0.667686
[2022-06-11 16:43:01 | train] - Train Epoch: [134] [601600/1281167 (47%)]	Loss: 0.762799
[2022-06-11 16:43:22 | train] - Train Epoch: [134] [614400/1281167 (48%)]	Loss: 0.624527
[2022-06-11 16:43:44 | train] - Train Epoch: [134] [627200/1281167 (49%)]	Loss: 0.778035
[2022-06-11 16:44:05 | train] - Train Epoch: [134] [640000/1281167 (50%)]	Loss: 0.754885
[2022-06-11 16:44:27 | train] - Train Epoch: [134] [652800/1281167 (51%)]	Loss: 0.765600
[2022-06-11 16:44:50 | train] - Train Epoch: [134] [665600/1281167 (52%)]	Loss: 0.799069
[2022-06-11 16:45:11 | train] - Train Epoch: [134] [678400/1281167 (53%)]	Loss: 0.795049
[2022-06-11 16:45:32 | train] - Train Epoch: [134] [691200/1281167 (54%)]	Loss: 0.523376
[2022-06-11 16:45:54 | train] - Train Epoch: [134] [704000/1281167 (55%)]	Loss: 1.003254
[2022-06-11 16:46:16 | train] - Train Epoch: [134] [716800/1281167 (56%)]	Loss: 0.612522
[2022-06-11 16:46:37 | train] - Train Epoch: [134] [729600/1281167 (57%)]	Loss: 0.856999
[2022-06-11 16:46:59 | train] - Train Epoch: [134] [742400/1281167 (58%)]	Loss: 0.683249
[2022-06-11 16:47:20 | train] - Train Epoch: [134] [755200/1281167 (59%)]	Loss: 0.761082
[2022-06-11 16:47:42 | train] - Train Epoch: [134] [768000/1281167 (60%)]	Loss: 0.712862
[2022-06-11 16:48:04 | train] - Train Epoch: [134] [780800/1281167 (61%)]	Loss: 0.735540
[2022-06-11 16:48:26 | train] - Train Epoch: [134] [793600/1281167 (62%)]	Loss: 0.678919
[2022-06-11 16:48:48 | train] - Train Epoch: [134] [806400/1281167 (63%)]	Loss: 0.683066
[2022-06-11 16:49:10 | train] - Train Epoch: [134] [819200/1281167 (64%)]	Loss: 0.606901
[2022-06-11 16:49:31 | train] - Train Epoch: [134] [832000/1281167 (65%)]	Loss: 0.686783
[2022-06-11 16:49:52 | train] - Train Epoch: [134] [844800/1281167 (66%)]	Loss: 0.696167
[2022-06-11 16:50:14 | train] - Train Epoch: [134] [857600/1281167 (67%)]	Loss: 0.671996
[2022-06-11 16:50:36 | train] - Train Epoch: [134] [870400/1281167 (68%)]	Loss: 0.923459
[2022-06-11 16:50:57 | train] - Train Epoch: [134] [883200/1281167 (69%)]	Loss: 0.765284
[2022-06-11 16:51:19 | train] - Train Epoch: [134] [896000/1281167 (70%)]	Loss: 0.658192
[2022-06-11 16:51:40 | train] - Train Epoch: [134] [908800/1281167 (71%)]	Loss: 0.790691
[2022-06-11 16:52:02 | train] - Train Epoch: [134] [921600/1281167 (72%)]	Loss: 0.699910
[2022-06-11 16:52:24 | train] - Train Epoch: [134] [934400/1281167 (73%)]	Loss: 0.852673
[2022-06-11 16:52:45 | train] - Train Epoch: [134] [947200/1281167 (74%)]	Loss: 1.174300
[2022-06-11 16:53:07 | train] - Train Epoch: [134] [960000/1281167 (75%)]	Loss: 0.635161
[2022-06-11 16:53:29 | train] - Train Epoch: [134] [972800/1281167 (76%)]	Loss: 0.531721
[2022-06-11 16:53:50 | train] - Train Epoch: [134] [985600/1281167 (77%)]	Loss: 0.706460
[2022-06-11 16:54:12 | train] - Train Epoch: [134] [998400/1281167 (78%)]	Loss: 0.611435
[2022-06-11 16:54:34 | train] - Train Epoch: [134] [1011200/1281167 (79%)]	Loss: 0.977792
[2022-06-11 16:54:56 | train] - Train Epoch: [134] [1024000/1281167 (80%)]	Loss: 0.855876
[2022-06-11 16:55:18 | train] - Train Epoch: [134] [1036800/1281167 (81%)]	Loss: 0.612964
[2022-06-11 16:55:39 | train] - Train Epoch: [134] [1049600/1281167 (82%)]	Loss: 0.829264
[2022-06-11 16:56:01 | train] - Train Epoch: [134] [1062400/1281167 (83%)]	Loss: 0.723130
[2022-06-11 16:56:23 | train] - Train Epoch: [134] [1075200/1281167 (84%)]	Loss: 0.889132
[2022-06-11 16:56:44 | train] - Train Epoch: [134] [1088000/1281167 (85%)]	Loss: 0.723894
[2022-06-11 16:57:06 | train] - Train Epoch: [134] [1100800/1281167 (86%)]	Loss: 0.670540
[2022-06-11 16:57:27 | train] - Train Epoch: [134] [1113600/1281167 (87%)]	Loss: 0.800718
[2022-06-11 16:57:48 | train] - Train Epoch: [134] [1126400/1281167 (88%)]	Loss: 0.699291
[2022-06-11 16:58:09 | train] - Train Epoch: [134] [1139200/1281167 (89%)]	Loss: 0.784269
[2022-06-11 16:58:31 | train] - Train Epoch: [134] [1152000/1281167 (90%)]	Loss: 1.020439
[2022-06-11 16:58:53 | train] - Train Epoch: [134] [1164800/1281167 (91%)]	Loss: 0.846243
[2022-06-11 16:59:13 | train] - Train Epoch: [134] [1177600/1281167 (92%)]	Loss: 0.834864
[2022-06-11 16:59:33 | train] - Train Epoch: [134] [1190400/1281167 (93%)]	Loss: 0.787729
[2022-06-11 16:59:55 | train] - Train Epoch: [134] [1203200/1281167 (94%)]	Loss: 0.853566
[2022-06-11 17:00:17 | train] - Train Epoch: [134] [1216000/1281167 (95%)]	Loss: 0.802747
[2022-06-11 17:00:38 | train] - Train Epoch: [134] [1228800/1281167 (96%)]	Loss: 0.712325
[2022-06-11 17:01:00 | train] - Train Epoch: [134] [1241600/1281167 (97%)]	Loss: 0.749634
[2022-06-11 17:01:21 | train] - Train Epoch: [134] [1254400/1281167 (98%)]	Loss: 0.966362
[2022-06-11 17:01:43 | train] - Train Epoch: [134] [1267200/1281167 (99%)]	Loss: 1.007552
[2022-06-11 17:02:05 | train] - Train Epoch: [134] [1280000/1281167 (100%)]	Loss: 0.619261
[2022-06-11 17:02:07 | train] - Train Epoch: [134]	 Average Loss: 0.751468	 Total Acc : 81.6763	 Total Top5 Acc : 93.3233
[2022-06-11 17:02:07 | train] - -------134 epoch end-----------
========================================
-------134 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 17:03:42 | train] - 
Epoch [134] Test set: Average loss: 1.4161, Accuracy: 34938/50000 (69.8461%), Top-5 Accuracy: 89.0114%

[2022-06-11 17:03:42 | train] - save intermediate epoch [134] result


[2022-06-11 17:03:49 | train] - -------135 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 17:03:50 | train] - Train Epoch: [135] [0/1281167 (0%)]	Loss: 0.559566
[2022-06-11 17:04:13 | train] - Train Epoch: [135] [12800/1281167 (1%)]	Loss: 0.933821
[2022-06-11 17:04:34 | train] - Train Epoch: [135] [25600/1281167 (2%)]	Loss: 0.646055
[2022-06-11 17:04:56 | train] - Train Epoch: [135] [38400/1281167 (3%)]	Loss: 0.855404
[2022-06-11 17:05:17 | train] - Train Epoch: [135] [51200/1281167 (4%)]	Loss: 0.903309
[2022-06-11 17:05:39 | train] - Train Epoch: [135] [64000/1281167 (5%)]	Loss: 0.671033
[2022-06-11 17:06:01 | train] - Train Epoch: [135] [76800/1281167 (6%)]	Loss: 0.704558
[2022-06-11 17:06:23 | train] - Train Epoch: [135] [89600/1281167 (7%)]	Loss: 0.705149
[2022-06-11 17:06:45 | train] - Train Epoch: [135] [102400/1281167 (8%)]	Loss: 0.793911
[2022-06-11 17:07:06 | train] - Train Epoch: [135] [115200/1281167 (9%)]	Loss: 0.637070
[2022-06-11 17:07:28 | train] - Train Epoch: [135] [128000/1281167 (10%)]	Loss: 0.645922
[2022-06-11 17:07:50 | train] - Train Epoch: [135] [140800/1281167 (11%)]	Loss: 0.767533
[2022-06-11 17:08:12 | train] - Train Epoch: [135] [153600/1281167 (12%)]	Loss: 0.838170
[2022-06-11 17:08:33 | train] - Train Epoch: [135] [166400/1281167 (13%)]	Loss: 0.854753
[2022-06-11 17:08:55 | train] - Train Epoch: [135] [179200/1281167 (14%)]	Loss: 0.621892
[2022-06-11 17:09:16 | train] - Train Epoch: [135] [192000/1281167 (15%)]	Loss: 0.798493
[2022-06-11 17:09:38 | train] - Train Epoch: [135] [204800/1281167 (16%)]	Loss: 0.719942
[2022-06-11 17:10:00 | train] - Train Epoch: [135] [217600/1281167 (17%)]	Loss: 0.591757
[2022-06-11 17:10:21 | train] - Train Epoch: [135] [230400/1281167 (18%)]	Loss: 0.639836
[2022-06-11 17:10:43 | train] - Train Epoch: [135] [243200/1281167 (19%)]	Loss: 0.676949
[2022-06-11 17:11:04 | train] - Train Epoch: [135] [256000/1281167 (20%)]	Loss: 0.798021
[2022-06-11 17:11:26 | train] - Train Epoch: [135] [268800/1281167 (21%)]	Loss: 0.511605
[2022-06-11 17:11:48 | train] - Train Epoch: [135] [281600/1281167 (22%)]	Loss: 0.672889
[2022-06-11 17:12:09 | train] - Train Epoch: [135] [294400/1281167 (23%)]	Loss: 0.816932
[2022-06-11 17:12:31 | train] - Train Epoch: [135] [307200/1281167 (24%)]	Loss: 0.845541
[2022-06-11 17:12:53 | train] - Train Epoch: [135] [320000/1281167 (25%)]	Loss: 0.674798
[2022-06-11 17:13:14 | train] - Train Epoch: [135] [332800/1281167 (26%)]	Loss: 0.740806
[2022-06-11 17:13:37 | train] - Train Epoch: [135] [345600/1281167 (27%)]	Loss: 0.835119
[2022-06-11 17:13:58 | train] - Train Epoch: [135] [358400/1281167 (28%)]	Loss: 0.758056
[2022-06-11 17:14:19 | train] - Train Epoch: [135] [371200/1281167 (29%)]	Loss: 0.543256
[2022-06-11 17:14:41 | train] - Train Epoch: [135] [384000/1281167 (30%)]	Loss: 0.705467
[2022-06-11 17:15:02 | train] - Train Epoch: [135] [396800/1281167 (31%)]	Loss: 0.899986
[2022-06-11 17:15:24 | train] - Train Epoch: [135] [409600/1281167 (32%)]	Loss: 0.533098
[2022-06-11 17:15:45 | train] - Train Epoch: [135] [422400/1281167 (33%)]	Loss: 0.489268
[2022-06-11 17:16:07 | train] - Train Epoch: [135] [435200/1281167 (34%)]	Loss: 0.814000
[2022-06-11 17:16:28 | train] - Train Epoch: [135] [448000/1281167 (35%)]	Loss: 0.752205
[2022-06-11 17:16:50 | train] - Train Epoch: [135] [460800/1281167 (36%)]	Loss: 0.768053
[2022-06-11 17:17:11 | train] - Train Epoch: [135] [473600/1281167 (37%)]	Loss: 0.583059
[2022-06-11 17:17:32 | train] - Train Epoch: [135] [486400/1281167 (38%)]	Loss: 0.626083
[2022-06-11 17:17:54 | train] - Train Epoch: [135] [499200/1281167 (39%)]	Loss: 0.730510
[2022-06-11 17:18:16 | train] - Train Epoch: [135] [512000/1281167 (40%)]	Loss: 0.819855
[2022-06-11 17:18:37 | train] - Train Epoch: [135] [524800/1281167 (41%)]	Loss: 0.566539
[2022-06-11 17:18:58 | train] - Train Epoch: [135] [537600/1281167 (42%)]	Loss: 0.677892
[2022-06-11 17:19:20 | train] - Train Epoch: [135] [550400/1281167 (43%)]	Loss: 0.681890
[2022-06-11 17:19:42 | train] - Train Epoch: [135] [563200/1281167 (44%)]	Loss: 0.727824
[2022-06-11 17:20:04 | train] - Train Epoch: [135] [576000/1281167 (45%)]	Loss: 0.750213
[2022-06-11 17:20:26 | train] - Train Epoch: [135] [588800/1281167 (46%)]	Loss: 0.983809
[2022-06-11 17:20:47 | train] - Train Epoch: [135] [601600/1281167 (47%)]	Loss: 0.434966
[2022-06-11 17:21:09 | train] - Train Epoch: [135] [614400/1281167 (48%)]	Loss: 0.812536
[2022-06-11 17:21:31 | train] - Train Epoch: [135] [627200/1281167 (49%)]	Loss: 0.709210
[2022-06-11 17:21:53 | train] - Train Epoch: [135] [640000/1281167 (50%)]	Loss: 0.664719
[2022-06-11 17:22:13 | train] - Train Epoch: [135] [652800/1281167 (51%)]	Loss: 0.672772
[2022-06-11 17:22:35 | train] - Train Epoch: [135] [665600/1281167 (52%)]	Loss: 0.786221
[2022-06-11 17:22:57 | train] - Train Epoch: [135] [678400/1281167 (53%)]	Loss: 0.777980
[2022-06-11 17:23:19 | train] - Train Epoch: [135] [691200/1281167 (54%)]	Loss: 0.721364
[2022-06-11 17:23:41 | train] - Train Epoch: [135] [704000/1281167 (55%)]	Loss: 0.793974
[2022-06-11 17:24:02 | train] - Train Epoch: [135] [716800/1281167 (56%)]	Loss: 0.748978
[2022-06-11 17:24:23 | train] - Train Epoch: [135] [729600/1281167 (57%)]	Loss: 0.814893
[2022-06-11 17:24:44 | train] - Train Epoch: [135] [742400/1281167 (58%)]	Loss: 0.867796
[2022-06-11 17:25:05 | train] - Train Epoch: [135] [755200/1281167 (59%)]	Loss: 0.889159
[2022-06-11 17:25:27 | train] - Train Epoch: [135] [768000/1281167 (60%)]	Loss: 0.697412
[2022-06-11 17:25:49 | train] - Train Epoch: [135] [780800/1281167 (61%)]	Loss: 0.529535
[2022-06-11 17:26:10 | train] - Train Epoch: [135] [793600/1281167 (62%)]	Loss: 0.480856
[2022-06-11 17:26:32 | train] - Train Epoch: [135] [806400/1281167 (63%)]	Loss: 0.618088
[2022-06-11 17:26:53 | train] - Train Epoch: [135] [819200/1281167 (64%)]	Loss: 0.933849
[2022-06-11 17:27:15 | train] - Train Epoch: [135] [832000/1281167 (65%)]	Loss: 0.783030
[2022-06-11 17:27:37 | train] - Train Epoch: [135] [844800/1281167 (66%)]	Loss: 0.876855
[2022-06-11 17:27:59 | train] - Train Epoch: [135] [857600/1281167 (67%)]	Loss: 0.613342
[2022-06-11 17:28:20 | train] - Train Epoch: [135] [870400/1281167 (68%)]	Loss: 0.741218
[2022-06-11 17:28:42 | train] - Train Epoch: [135] [883200/1281167 (69%)]	Loss: 0.679573
[2022-06-11 17:29:03 | train] - Train Epoch: [135] [896000/1281167 (70%)]	Loss: 0.737737
[2022-06-11 17:29:24 | train] - Train Epoch: [135] [908800/1281167 (71%)]	Loss: 0.640835
[2022-06-11 17:29:46 | train] - Train Epoch: [135] [921600/1281167 (72%)]	Loss: 0.644492
[2022-06-11 17:30:08 | train] - Train Epoch: [135] [934400/1281167 (73%)]	Loss: 0.743198
[2022-06-11 17:30:29 | train] - Train Epoch: [135] [947200/1281167 (74%)]	Loss: 0.721604
[2022-06-11 17:30:51 | train] - Train Epoch: [135] [960000/1281167 (75%)]	Loss: 0.602462
[2022-06-11 17:31:13 | train] - Train Epoch: [135] [972800/1281167 (76%)]	Loss: 0.708674
[2022-06-11 17:31:34 | train] - Train Epoch: [135] [985600/1281167 (77%)]	Loss: 0.435669
[2022-06-11 17:31:55 | train] - Train Epoch: [135] [998400/1281167 (78%)]	Loss: 0.796595
[2022-06-11 17:32:17 | train] - Train Epoch: [135] [1011200/1281167 (79%)]	Loss: 0.733865
[2022-06-11 17:32:38 | train] - Train Epoch: [135] [1024000/1281167 (80%)]	Loss: 0.893999
[2022-06-11 17:33:00 | train] - Train Epoch: [135] [1036800/1281167 (81%)]	Loss: 0.365190
[2022-06-11 17:33:22 | train] - Train Epoch: [135] [1049600/1281167 (82%)]	Loss: 0.716995
[2022-06-11 17:33:43 | train] - Train Epoch: [135] [1062400/1281167 (83%)]	Loss: 0.893091
[2022-06-11 17:34:05 | train] - Train Epoch: [135] [1075200/1281167 (84%)]	Loss: 0.618584
[2022-06-11 17:34:27 | train] - Train Epoch: [135] [1088000/1281167 (85%)]	Loss: 0.886305
[2022-06-11 17:34:49 | train] - Train Epoch: [135] [1100800/1281167 (86%)]	Loss: 0.637960
[2022-06-11 17:35:11 | train] - Train Epoch: [135] [1113600/1281167 (87%)]	Loss: 0.781820
[2022-06-11 17:35:33 | train] - Train Epoch: [135] [1126400/1281167 (88%)]	Loss: 0.638892
[2022-06-11 17:35:54 | train] - Train Epoch: [135] [1139200/1281167 (89%)]	Loss: 1.037261
[2022-06-11 17:36:16 | train] - Train Epoch: [135] [1152000/1281167 (90%)]	Loss: 0.643537
[2022-06-11 17:36:38 | train] - Train Epoch: [135] [1164800/1281167 (91%)]	Loss: 0.638507
[2022-06-11 17:37:00 | train] - Train Epoch: [135] [1177600/1281167 (92%)]	Loss: 0.821881
[2022-06-11 17:37:21 | train] - Train Epoch: [135] [1190400/1281167 (93%)]	Loss: 0.842176
[2022-06-11 17:37:43 | train] - Train Epoch: [135] [1203200/1281167 (94%)]	Loss: 0.844318
[2022-06-11 17:38:05 | train] - Train Epoch: [135] [1216000/1281167 (95%)]	Loss: 0.735377
[2022-06-11 17:38:26 | train] - Train Epoch: [135] [1228800/1281167 (96%)]	Loss: 0.592071
[2022-06-11 17:38:48 | train] - Train Epoch: [135] [1241600/1281167 (97%)]	Loss: 0.583128
[2022-06-11 17:39:10 | train] - Train Epoch: [135] [1254400/1281167 (98%)]	Loss: 0.905170
[2022-06-11 17:39:31 | train] - Train Epoch: [135] [1267200/1281167 (99%)]	Loss: 1.056299
[2022-06-11 17:39:53 | train] - Train Epoch: [135] [1280000/1281167 (100%)]	Loss: 0.822363
[2022-06-11 17:39:55 | train] - Train Epoch: [135]	 Average Loss: 0.748821	 Total Acc : 81.7394	 Total Top5 Acc : 93.3891
[2022-06-11 17:39:55 | train] - -------135 epoch end-----------
========================================
-------135 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 17:41:30 | train] - 
Epoch [135] Test set: Average loss: 1.4034, Accuracy: 35004/50000 (69.9804%), Top-5 Accuracy: 88.9326%

[2022-06-11 17:41:30 | train] - save intermediate epoch [135] result


[2022-06-11 17:41:37 | train] - -------136 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 17:41:39 | train] - Train Epoch: [136] [0/1281167 (0%)]	Loss: 0.859867
[2022-06-11 17:42:02 | train] - Train Epoch: [136] [12800/1281167 (1%)]	Loss: 0.869199
[2022-06-11 17:42:23 | train] - Train Epoch: [136] [25600/1281167 (2%)]	Loss: 0.745733
[2022-06-11 17:42:45 | train] - Train Epoch: [136] [38400/1281167 (3%)]	Loss: 0.767776
[2022-06-11 17:43:07 | train] - Train Epoch: [136] [51200/1281167 (4%)]	Loss: 0.869208
[2022-06-11 17:43:28 | train] - Train Epoch: [136] [64000/1281167 (5%)]	Loss: 0.963575
[2022-06-11 17:43:51 | train] - Train Epoch: [136] [76800/1281167 (6%)]	Loss: 0.787345
[2022-06-11 17:44:12 | train] - Train Epoch: [136] [89600/1281167 (7%)]	Loss: 0.587480
[2022-06-11 17:44:34 | train] - Train Epoch: [136] [102400/1281167 (8%)]	Loss: 0.720709
[2022-06-11 17:44:56 | train] - Train Epoch: [136] [115200/1281167 (9%)]	Loss: 0.906586
[2022-06-11 17:45:18 | train] - Train Epoch: [136] [128000/1281167 (10%)]	Loss: 0.595662
[2022-06-11 17:45:39 | train] - Train Epoch: [136] [140800/1281167 (11%)]	Loss: 0.625606
[2022-06-11 17:46:00 | train] - Train Epoch: [136] [153600/1281167 (12%)]	Loss: 0.581895
[2022-06-11 17:46:22 | train] - Train Epoch: [136] [166400/1281167 (13%)]	Loss: 0.751947
[2022-06-11 17:46:43 | train] - Train Epoch: [136] [179200/1281167 (14%)]	Loss: 1.010400
[2022-06-11 17:47:05 | train] - Train Epoch: [136] [192000/1281167 (15%)]	Loss: 0.754002
[2022-06-11 17:47:26 | train] - Train Epoch: [136] [204800/1281167 (16%)]	Loss: 0.645495
[2022-06-11 17:47:47 | train] - Train Epoch: [136] [217600/1281167 (17%)]	Loss: 0.918069
[2022-06-11 17:48:08 | train] - Train Epoch: [136] [230400/1281167 (18%)]	Loss: 0.816029
[2022-06-11 17:48:29 | train] - Train Epoch: [136] [243200/1281167 (19%)]	Loss: 0.441432
[2022-06-11 17:48:50 | train] - Train Epoch: [136] [256000/1281167 (20%)]	Loss: 0.665600
[2022-06-11 17:49:11 | train] - Train Epoch: [136] [268800/1281167 (21%)]	Loss: 0.479498
[2022-06-11 17:49:33 | train] - Train Epoch: [136] [281600/1281167 (22%)]	Loss: 0.779334
[2022-06-11 17:49:55 | train] - Train Epoch: [136] [294400/1281167 (23%)]	Loss: 0.580582
[2022-06-11 17:50:16 | train] - Train Epoch: [136] [307200/1281167 (24%)]	Loss: 0.899854
[2022-06-11 17:50:38 | train] - Train Epoch: [136] [320000/1281167 (25%)]	Loss: 0.685293
[2022-06-11 17:51:00 | train] - Train Epoch: [136] [332800/1281167 (26%)]	Loss: 0.819756
[2022-06-11 17:51:21 | train] - Train Epoch: [136] [345600/1281167 (27%)]	Loss: 0.686121
[2022-06-11 17:51:43 | train] - Train Epoch: [136] [358400/1281167 (28%)]	Loss: 0.691787
[2022-06-11 17:52:05 | train] - Train Epoch: [136] [371200/1281167 (29%)]	Loss: 0.596740
[2022-06-11 17:52:25 | train] - Train Epoch: [136] [384000/1281167 (30%)]	Loss: 0.653526
[2022-06-11 17:52:47 | train] - Train Epoch: [136] [396800/1281167 (31%)]	Loss: 0.668398
[2022-06-11 17:53:09 | train] - Train Epoch: [136] [409600/1281167 (32%)]	Loss: 0.992179
[2022-06-11 17:53:30 | train] - Train Epoch: [136] [422400/1281167 (33%)]	Loss: 0.706327
[2022-06-11 17:53:52 | train] - Train Epoch: [136] [435200/1281167 (34%)]	Loss: 0.474888
[2022-06-11 17:54:14 | train] - Train Epoch: [136] [448000/1281167 (35%)]	Loss: 0.890908
[2022-06-11 17:54:36 | train] - Train Epoch: [136] [460800/1281167 (36%)]	Loss: 0.988058
[2022-06-11 17:54:58 | train] - Train Epoch: [136] [473600/1281167 (37%)]	Loss: 0.670738
[2022-06-11 17:55:19 | train] - Train Epoch: [136] [486400/1281167 (38%)]	Loss: 0.658147
[2022-06-11 17:55:41 | train] - Train Epoch: [136] [499200/1281167 (39%)]	Loss: 0.696737
[2022-06-11 17:56:03 | train] - Train Epoch: [136] [512000/1281167 (40%)]	Loss: 0.732967
[2022-06-11 17:56:25 | train] - Train Epoch: [136] [524800/1281167 (41%)]	Loss: 0.689805
[2022-06-11 17:56:47 | train] - Train Epoch: [136] [537600/1281167 (42%)]	Loss: 0.584957
[2022-06-11 17:57:09 | train] - Train Epoch: [136] [550400/1281167 (43%)]	Loss: 1.030427
[2022-06-11 17:57:30 | train] - Train Epoch: [136] [563200/1281167 (44%)]	Loss: 0.797585
[2022-06-11 17:57:51 | train] - Train Epoch: [136] [576000/1281167 (45%)]	Loss: 0.763416
[2022-06-11 17:58:12 | train] - Train Epoch: [136] [588800/1281167 (46%)]	Loss: 0.765957
[2022-06-11 17:58:33 | train] - Train Epoch: [136] [601600/1281167 (47%)]	Loss: 0.948862
[2022-06-11 17:58:55 | train] - Train Epoch: [136] [614400/1281167 (48%)]	Loss: 0.555775
[2022-06-11 17:59:17 | train] - Train Epoch: [136] [627200/1281167 (49%)]	Loss: 0.765104
[2022-06-11 17:59:40 | train] - Train Epoch: [136] [640000/1281167 (50%)]	Loss: 0.590464
[2022-06-11 18:00:02 | train] - Train Epoch: [136] [652800/1281167 (51%)]	Loss: 0.696159
[2022-06-11 18:00:23 | train] - Train Epoch: [136] [665600/1281167 (52%)]	Loss: 0.497722
[2022-06-11 18:00:45 | train] - Train Epoch: [136] [678400/1281167 (53%)]	Loss: 0.594621
[2022-06-11 18:01:07 | train] - Train Epoch: [136] [691200/1281167 (54%)]	Loss: 0.839244
[2022-06-11 18:01:29 | train] - Train Epoch: [136] [704000/1281167 (55%)]	Loss: 0.629747
[2022-06-11 18:01:51 | train] - Train Epoch: [136] [716800/1281167 (56%)]	Loss: 0.609964
[2022-06-11 18:02:12 | train] - Train Epoch: [136] [729600/1281167 (57%)]	Loss: 0.891846
[2022-06-11 18:02:34 | train] - Train Epoch: [136] [742400/1281167 (58%)]	Loss: 0.868604
[2022-06-11 18:02:56 | train] - Train Epoch: [136] [755200/1281167 (59%)]	Loss: 0.697551
[2022-06-11 18:03:18 | train] - Train Epoch: [136] [768000/1281167 (60%)]	Loss: 0.784927
[2022-06-11 18:03:39 | train] - Train Epoch: [136] [780800/1281167 (61%)]	Loss: 0.819336
[2022-06-11 18:04:01 | train] - Train Epoch: [136] [793600/1281167 (62%)]	Loss: 0.593263
[2022-06-11 18:04:23 | train] - Train Epoch: [136] [806400/1281167 (63%)]	Loss: 0.698908
[2022-06-11 18:04:45 | train] - Train Epoch: [136] [819200/1281167 (64%)]	Loss: 0.947873
[2022-06-11 18:05:07 | train] - Train Epoch: [136] [832000/1281167 (65%)]	Loss: 0.749443
[2022-06-11 18:05:29 | train] - Train Epoch: [136] [844800/1281167 (66%)]	Loss: 0.722461
[2022-06-11 18:05:51 | train] - Train Epoch: [136] [857600/1281167 (67%)]	Loss: 0.884501
[2022-06-11 18:06:13 | train] - Train Epoch: [136] [870400/1281167 (68%)]	Loss: 0.725527
[2022-06-11 18:06:34 | train] - Train Epoch: [136] [883200/1281167 (69%)]	Loss: 0.717720
[2022-06-11 18:06:55 | train] - Train Epoch: [136] [896000/1281167 (70%)]	Loss: 0.660469
[2022-06-11 18:07:16 | train] - Train Epoch: [136] [908800/1281167 (71%)]	Loss: 0.824124
[2022-06-11 18:07:38 | train] - Train Epoch: [136] [921600/1281167 (72%)]	Loss: 0.791753
[2022-06-11 18:07:58 | train] - Train Epoch: [136] [934400/1281167 (73%)]	Loss: 0.768371
[2022-06-11 18:08:19 | train] - Train Epoch: [136] [947200/1281167 (74%)]	Loss: 0.632548
[2022-06-11 18:08:40 | train] - Train Epoch: [136] [960000/1281167 (75%)]	Loss: 0.597445
[2022-06-11 18:09:02 | train] - Train Epoch: [136] [972800/1281167 (76%)]	Loss: 0.758158
[2022-06-11 18:09:24 | train] - Train Epoch: [136] [985600/1281167 (77%)]	Loss: 0.674582
[2022-06-11 18:09:44 | train] - Train Epoch: [136] [998400/1281167 (78%)]	Loss: 0.914744
[2022-06-11 18:10:06 | train] - Train Epoch: [136] [1011200/1281167 (79%)]	Loss: 0.587887
[2022-06-11 18:10:28 | train] - Train Epoch: [136] [1024000/1281167 (80%)]	Loss: 0.651204
[2022-06-11 18:10:50 | train] - Train Epoch: [136] [1036800/1281167 (81%)]	Loss: 0.633228
[2022-06-11 18:11:12 | train] - Train Epoch: [136] [1049600/1281167 (82%)]	Loss: 0.507655
[2022-06-11 18:11:34 | train] - Train Epoch: [136] [1062400/1281167 (83%)]	Loss: 0.862972
[2022-06-11 18:11:56 | train] - Train Epoch: [136] [1075200/1281167 (84%)]	Loss: 1.004311
[2022-06-11 18:12:17 | train] - Train Epoch: [136] [1088000/1281167 (85%)]	Loss: 0.663162
[2022-06-11 18:12:39 | train] - Train Epoch: [136] [1100800/1281167 (86%)]	Loss: 0.578041
[2022-06-11 18:13:01 | train] - Train Epoch: [136] [1113600/1281167 (87%)]	Loss: 1.008481
[2022-06-11 18:13:22 | train] - Train Epoch: [136] [1126400/1281167 (88%)]	Loss: 0.533961
[2022-06-11 18:13:44 | train] - Train Epoch: [136] [1139200/1281167 (89%)]	Loss: 0.703999
[2022-06-11 18:14:06 | train] - Train Epoch: [136] [1152000/1281167 (90%)]	Loss: 0.874696
[2022-06-11 18:14:27 | train] - Train Epoch: [136] [1164800/1281167 (91%)]	Loss: 0.735568
[2022-06-11 18:14:49 | train] - Train Epoch: [136] [1177600/1281167 (92%)]	Loss: 0.833304
[2022-06-11 18:15:11 | train] - Train Epoch: [136] [1190400/1281167 (93%)]	Loss: 0.813290
[2022-06-11 18:15:32 | train] - Train Epoch: [136] [1203200/1281167 (94%)]	Loss: 0.905801
[2022-06-11 18:15:54 | train] - Train Epoch: [136] [1216000/1281167 (95%)]	Loss: 0.777923
[2022-06-11 18:16:16 | train] - Train Epoch: [136] [1228800/1281167 (96%)]	Loss: 0.679622
[2022-06-11 18:16:37 | train] - Train Epoch: [136] [1241600/1281167 (97%)]	Loss: 0.694532
[2022-06-11 18:17:00 | train] - Train Epoch: [136] [1254400/1281167 (98%)]	Loss: 0.854873
[2022-06-11 18:17:21 | train] - Train Epoch: [136] [1267200/1281167 (99%)]	Loss: 0.723666
[2022-06-11 18:17:42 | train] - Train Epoch: [136] [1280000/1281167 (100%)]	Loss: 0.734637
[2022-06-11 18:17:44 | train] - Train Epoch: [136]	 Average Loss: 0.748760	 Total Acc : 81.7432	 Total Top5 Acc : 93.3820
[2022-06-11 18:17:44 | train] - -------136 epoch end-----------
========================================
-------136 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 18:19:19 | train] - 
Epoch [136] Test set: Average loss: 1.4131, Accuracy: 34957/50000 (69.8877%), Top-5 Accuracy: 88.9922%

[2022-06-11 18:19:19 | train] - save intermediate epoch [136] result


[2022-06-11 18:19:27 | train] - -------137 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 18:19:29 | train] - Train Epoch: [137] [0/1281167 (0%)]	Loss: 1.107212
[2022-06-11 18:19:51 | train] - Train Epoch: [137] [12800/1281167 (1%)]	Loss: 0.896375
[2022-06-11 18:20:13 | train] - Train Epoch: [137] [25600/1281167 (2%)]	Loss: 0.825267
[2022-06-11 18:20:34 | train] - Train Epoch: [137] [38400/1281167 (3%)]	Loss: 0.887628
[2022-06-11 18:20:56 | train] - Train Epoch: [137] [51200/1281167 (4%)]	Loss: 0.524793
[2022-06-11 18:21:19 | train] - Train Epoch: [137] [64000/1281167 (5%)]	Loss: 0.776005
[2022-06-11 18:21:40 | train] - Train Epoch: [137] [76800/1281167 (6%)]	Loss: 0.478166
[2022-06-11 18:22:02 | train] - Train Epoch: [137] [89600/1281167 (7%)]	Loss: 0.701892
[2022-06-11 18:22:24 | train] - Train Epoch: [137] [102400/1281167 (8%)]	Loss: 0.572164
[2022-06-11 18:22:46 | train] - Train Epoch: [137] [115200/1281167 (9%)]	Loss: 0.737075
[2022-06-11 18:23:08 | train] - Train Epoch: [137] [128000/1281167 (10%)]	Loss: 0.598876
[2022-06-11 18:23:30 | train] - Train Epoch: [137] [140800/1281167 (11%)]	Loss: 1.019932
[2022-06-11 18:23:51 | train] - Train Epoch: [137] [153600/1281167 (12%)]	Loss: 0.782803
[2022-06-11 18:24:13 | train] - Train Epoch: [137] [166400/1281167 (13%)]	Loss: 0.518612
[2022-06-11 18:24:35 | train] - Train Epoch: [137] [179200/1281167 (14%)]	Loss: 0.809684
[2022-06-11 18:24:56 | train] - Train Epoch: [137] [192000/1281167 (15%)]	Loss: 0.819692
[2022-06-11 18:25:18 | train] - Train Epoch: [137] [204800/1281167 (16%)]	Loss: 0.505937
[2022-06-11 18:25:40 | train] - Train Epoch: [137] [217600/1281167 (17%)]	Loss: 0.923644
[2022-06-11 18:26:02 | train] - Train Epoch: [137] [230400/1281167 (18%)]	Loss: 0.733724
[2022-06-11 18:26:23 | train] - Train Epoch: [137] [243200/1281167 (19%)]	Loss: 0.638829
[2022-06-11 18:26:45 | train] - Train Epoch: [137] [256000/1281167 (20%)]	Loss: 0.807964
[2022-06-11 18:27:07 | train] - Train Epoch: [137] [268800/1281167 (21%)]	Loss: 1.009332
[2022-06-11 18:27:29 | train] - Train Epoch: [137] [281600/1281167 (22%)]	Loss: 0.728013
[2022-06-11 18:27:51 | train] - Train Epoch: [137] [294400/1281167 (23%)]	Loss: 0.798758
[2022-06-11 18:28:13 | train] - Train Epoch: [137] [307200/1281167 (24%)]	Loss: 0.941477
[2022-06-11 18:28:34 | train] - Train Epoch: [137] [320000/1281167 (25%)]	Loss: 0.962681
[2022-06-11 18:28:56 | train] - Train Epoch: [137] [332800/1281167 (26%)]	Loss: 0.779658
[2022-06-11 18:29:19 | train] - Train Epoch: [137] [345600/1281167 (27%)]	Loss: 0.750747
[2022-06-11 18:29:41 | train] - Train Epoch: [137] [358400/1281167 (28%)]	Loss: 0.866531
[2022-06-11 18:30:02 | train] - Train Epoch: [137] [371200/1281167 (29%)]	Loss: 0.504397
[2022-06-11 18:30:25 | train] - Train Epoch: [137] [384000/1281167 (30%)]	Loss: 0.845018
[2022-06-11 18:30:46 | train] - Train Epoch: [137] [396800/1281167 (31%)]	Loss: 0.788426
[2022-06-11 18:31:08 | train] - Train Epoch: [137] [409600/1281167 (32%)]	Loss: 0.784205
[2022-06-11 18:31:30 | train] - Train Epoch: [137] [422400/1281167 (33%)]	Loss: 0.905637
[2022-06-11 18:31:52 | train] - Train Epoch: [137] [435200/1281167 (34%)]	Loss: 0.932192
[2022-06-11 18:32:14 | train] - Train Epoch: [137] [448000/1281167 (35%)]	Loss: 0.516373
[2022-06-11 18:32:36 | train] - Train Epoch: [137] [460800/1281167 (36%)]	Loss: 0.627362
[2022-06-11 18:32:58 | train] - Train Epoch: [137] [473600/1281167 (37%)]	Loss: 0.759759
[2022-06-11 18:33:20 | train] - Train Epoch: [137] [486400/1281167 (38%)]	Loss: 0.938322
[2022-06-11 18:33:41 | train] - Train Epoch: [137] [499200/1281167 (39%)]	Loss: 0.527875
[2022-06-11 18:34:02 | train] - Train Epoch: [137] [512000/1281167 (40%)]	Loss: 0.888041
[2022-06-11 18:34:24 | train] - Train Epoch: [137] [524800/1281167 (41%)]	Loss: 0.852895
[2022-06-11 18:34:46 | train] - Train Epoch: [137] [537600/1281167 (42%)]	Loss: 0.618090
[2022-06-11 18:35:07 | train] - Train Epoch: [137] [550400/1281167 (43%)]	Loss: 0.661515
[2022-06-11 18:35:29 | train] - Train Epoch: [137] [563200/1281167 (44%)]	Loss: 0.771307
[2022-06-11 18:35:50 | train] - Train Epoch: [137] [576000/1281167 (45%)]	Loss: 0.776422
[2022-06-11 18:36:12 | train] - Train Epoch: [137] [588800/1281167 (46%)]	Loss: 0.713013
[2022-06-11 18:36:34 | train] - Train Epoch: [137] [601600/1281167 (47%)]	Loss: 0.631341
[2022-06-11 18:36:56 | train] - Train Epoch: [137] [614400/1281167 (48%)]	Loss: 0.703658
[2022-06-11 18:37:18 | train] - Train Epoch: [137] [627200/1281167 (49%)]	Loss: 0.618309
[2022-06-11 18:37:40 | train] - Train Epoch: [137] [640000/1281167 (50%)]	Loss: 0.942451
[2022-06-11 18:38:03 | train] - Train Epoch: [137] [652800/1281167 (51%)]	Loss: 0.785436
[2022-06-11 18:38:24 | train] - Train Epoch: [137] [665600/1281167 (52%)]	Loss: 0.811821
[2022-06-11 18:38:47 | train] - Train Epoch: [137] [678400/1281167 (53%)]	Loss: 0.718282
[2022-06-11 18:39:08 | train] - Train Epoch: [137] [691200/1281167 (54%)]	Loss: 0.830907
[2022-06-11 18:39:30 | train] - Train Epoch: [137] [704000/1281167 (55%)]	Loss: 0.615740
[2022-06-11 18:39:52 | train] - Train Epoch: [137] [716800/1281167 (56%)]	Loss: 0.638634
[2022-06-11 18:40:14 | train] - Train Epoch: [137] [729600/1281167 (57%)]	Loss: 0.934630
[2022-06-11 18:40:36 | train] - Train Epoch: [137] [742400/1281167 (58%)]	Loss: 0.747796
[2022-06-11 18:40:57 | train] - Train Epoch: [137] [755200/1281167 (59%)]	Loss: 0.669306
[2022-06-11 18:41:18 | train] - Train Epoch: [137] [768000/1281167 (60%)]	Loss: 0.951461
[2022-06-11 18:41:39 | train] - Train Epoch: [137] [780800/1281167 (61%)]	Loss: 0.684855
[2022-06-11 18:42:00 | train] - Train Epoch: [137] [793600/1281167 (62%)]	Loss: 0.944241
[2022-06-11 18:42:22 | train] - Train Epoch: [137] [806400/1281167 (63%)]	Loss: 0.751435
[2022-06-11 18:42:44 | train] - Train Epoch: [137] [819200/1281167 (64%)]	Loss: 0.672741
[2022-06-11 18:43:06 | train] - Train Epoch: [137] [832000/1281167 (65%)]	Loss: 0.752963
[2022-06-11 18:43:27 | train] - Train Epoch: [137] [844800/1281167 (66%)]	Loss: 0.921493
[2022-06-11 18:43:49 | train] - Train Epoch: [137] [857600/1281167 (67%)]	Loss: 0.695577
[2022-06-11 18:44:11 | train] - Train Epoch: [137] [870400/1281167 (68%)]	Loss: 0.799748
[2022-06-11 18:44:32 | train] - Train Epoch: [137] [883200/1281167 (69%)]	Loss: 0.706808
[2022-06-11 18:44:54 | train] - Train Epoch: [137] [896000/1281167 (70%)]	Loss: 0.847657
[2022-06-11 18:45:15 | train] - Train Epoch: [137] [908800/1281167 (71%)]	Loss: 0.524376
[2022-06-11 18:45:36 | train] - Train Epoch: [137] [921600/1281167 (72%)]	Loss: 0.825549
[2022-06-11 18:45:58 | train] - Train Epoch: [137] [934400/1281167 (73%)]	Loss: 0.802490
[2022-06-11 18:46:19 | train] - Train Epoch: [137] [947200/1281167 (74%)]	Loss: 0.849304
[2022-06-11 18:46:41 | train] - Train Epoch: [137] [960000/1281167 (75%)]	Loss: 0.622691
[2022-06-11 18:47:03 | train] - Train Epoch: [137] [972800/1281167 (76%)]	Loss: 0.509827
[2022-06-11 18:47:25 | train] - Train Epoch: [137] [985600/1281167 (77%)]	Loss: 0.595346
[2022-06-11 18:47:47 | train] - Train Epoch: [137] [998400/1281167 (78%)]	Loss: 0.661501
[2022-06-11 18:48:09 | train] - Train Epoch: [137] [1011200/1281167 (79%)]	Loss: 0.706194
[2022-06-11 18:48:31 | train] - Train Epoch: [137] [1024000/1281167 (80%)]	Loss: 0.714378
[2022-06-11 18:48:52 | train] - Train Epoch: [137] [1036800/1281167 (81%)]	Loss: 0.756720
[2022-06-11 18:49:14 | train] - Train Epoch: [137] [1049600/1281167 (82%)]	Loss: 0.852819
[2022-06-11 18:49:37 | train] - Train Epoch: [137] [1062400/1281167 (83%)]	Loss: 0.664026
[2022-06-11 18:49:59 | train] - Train Epoch: [137] [1075200/1281167 (84%)]	Loss: 0.636877
[2022-06-11 18:50:20 | train] - Train Epoch: [137] [1088000/1281167 (85%)]	Loss: 0.569676
[2022-06-11 18:50:41 | train] - Train Epoch: [137] [1100800/1281167 (86%)]	Loss: 0.693853
[2022-06-11 18:51:02 | train] - Train Epoch: [137] [1113600/1281167 (87%)]	Loss: 0.784192
[2022-06-11 18:51:25 | train] - Train Epoch: [137] [1126400/1281167 (88%)]	Loss: 0.577538
[2022-06-11 18:51:46 | train] - Train Epoch: [137] [1139200/1281167 (89%)]	Loss: 0.790847
[2022-06-11 18:52:08 | train] - Train Epoch: [137] [1152000/1281167 (90%)]	Loss: 0.653554
[2022-06-11 18:52:30 | train] - Train Epoch: [137] [1164800/1281167 (91%)]	Loss: 0.493793
[2022-06-11 18:52:52 | train] - Train Epoch: [137] [1177600/1281167 (92%)]	Loss: 0.789866
[2022-06-11 18:53:14 | train] - Train Epoch: [137] [1190400/1281167 (93%)]	Loss: 0.657755
[2022-06-11 18:53:36 | train] - Train Epoch: [137] [1203200/1281167 (94%)]	Loss: 0.825013
[2022-06-11 18:53:59 | train] - Train Epoch: [137] [1216000/1281167 (95%)]	Loss: 1.048844
[2022-06-11 18:54:20 | train] - Train Epoch: [137] [1228800/1281167 (96%)]	Loss: 0.817968
[2022-06-11 18:54:42 | train] - Train Epoch: [137] [1241600/1281167 (97%)]	Loss: 0.959672
[2022-06-11 18:55:04 | train] - Train Epoch: [137] [1254400/1281167 (98%)]	Loss: 0.839632
[2022-06-11 18:55:26 | train] - Train Epoch: [137] [1267200/1281167 (99%)]	Loss: 0.772522
[2022-06-11 18:55:48 | train] - Train Epoch: [137] [1280000/1281167 (100%)]	Loss: 0.944123
[2022-06-11 18:55:50 | train] - Train Epoch: [137]	 Average Loss: 0.747548	 Total Acc : 81.7956	 Total Top5 Acc : 93.4034
[2022-06-11 18:55:50 | train] - -------137 epoch end-----------
========================================
-------137 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 18:57:24 | train] - 
Epoch [137] Test set: Average loss: 1.4192, Accuracy: 34990/50000 (69.9536%), Top-5 Accuracy: 88.9370%

[2022-06-11 18:57:24 | train] - save intermediate epoch [137] result


[2022-06-11 18:57:32 | train] - -------138 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 18:57:34 | train] - Train Epoch: [138] [0/1281167 (0%)]	Loss: 0.728468
[2022-06-11 18:57:55 | train] - Train Epoch: [138] [12800/1281167 (1%)]	Loss: 0.734005
[2022-06-11 18:58:17 | train] - Train Epoch: [138] [25600/1281167 (2%)]	Loss: 0.563973
[2022-06-11 18:58:38 | train] - Train Epoch: [138] [38400/1281167 (3%)]	Loss: 0.878282
[2022-06-11 18:58:59 | train] - Train Epoch: [138] [51200/1281167 (4%)]	Loss: 0.733619
[2022-06-11 18:59:21 | train] - Train Epoch: [138] [64000/1281167 (5%)]	Loss: 0.754905
[2022-06-11 18:59:43 | train] - Train Epoch: [138] [76800/1281167 (6%)]	Loss: 0.637975
[2022-06-11 19:00:04 | train] - Train Epoch: [138] [89600/1281167 (7%)]	Loss: 0.720202
[2022-06-11 19:00:26 | train] - Train Epoch: [138] [102400/1281167 (8%)]	Loss: 0.658237
[2022-06-11 19:00:47 | train] - Train Epoch: [138] [115200/1281167 (9%)]	Loss: 0.741590
[2022-06-11 19:01:08 | train] - Train Epoch: [138] [128000/1281167 (10%)]	Loss: 0.855971
[2022-06-11 19:01:30 | train] - Train Epoch: [138] [140800/1281167 (11%)]	Loss: 0.711572
[2022-06-11 19:01:52 | train] - Train Epoch: [138] [153600/1281167 (12%)]	Loss: 0.710884
[2022-06-11 19:02:14 | train] - Train Epoch: [138] [166400/1281167 (13%)]	Loss: 0.675622
[2022-06-11 19:02:36 | train] - Train Epoch: [138] [179200/1281167 (14%)]	Loss: 0.710100
[2022-06-11 19:02:57 | train] - Train Epoch: [138] [192000/1281167 (15%)]	Loss: 0.711842
[2022-06-11 19:03:19 | train] - Train Epoch: [138] [204800/1281167 (16%)]	Loss: 0.614477
[2022-06-11 19:03:40 | train] - Train Epoch: [138] [217600/1281167 (17%)]	Loss: 0.910315
[2022-06-11 19:04:03 | train] - Train Epoch: [138] [230400/1281167 (18%)]	Loss: 0.775487
[2022-06-11 19:04:25 | train] - Train Epoch: [138] [243200/1281167 (19%)]	Loss: 0.669582
[2022-06-11 19:04:46 | train] - Train Epoch: [138] [256000/1281167 (20%)]	Loss: 0.686805
[2022-06-11 19:05:08 | train] - Train Epoch: [138] [268800/1281167 (21%)]	Loss: 0.650052
[2022-06-11 19:05:29 | train] - Train Epoch: [138] [281600/1281167 (22%)]	Loss: 0.946393
[2022-06-11 19:05:51 | train] - Train Epoch: [138] [294400/1281167 (23%)]	Loss: 0.486934
[2022-06-11 19:06:12 | train] - Train Epoch: [138] [307200/1281167 (24%)]	Loss: 0.957468
[2022-06-11 19:06:33 | train] - Train Epoch: [138] [320000/1281167 (25%)]	Loss: 0.912215
[2022-06-11 19:06:54 | train] - Train Epoch: [138] [332800/1281167 (26%)]	Loss: 0.661942
[2022-06-11 19:07:16 | train] - Train Epoch: [138] [345600/1281167 (27%)]	Loss: 0.762486
[2022-06-11 19:07:37 | train] - Train Epoch: [138] [358400/1281167 (28%)]	Loss: 0.498922
[2022-06-11 19:07:59 | train] - Train Epoch: [138] [371200/1281167 (29%)]	Loss: 0.764310
[2022-06-11 19:08:21 | train] - Train Epoch: [138] [384000/1281167 (30%)]	Loss: 0.625725
[2022-06-11 19:08:43 | train] - Train Epoch: [138] [396800/1281167 (31%)]	Loss: 0.646787
[2022-06-11 19:09:05 | train] - Train Epoch: [138] [409600/1281167 (32%)]	Loss: 0.723506
[2022-06-11 19:09:27 | train] - Train Epoch: [138] [422400/1281167 (33%)]	Loss: 0.726466
[2022-06-11 19:09:49 | train] - Train Epoch: [138] [435200/1281167 (34%)]	Loss: 0.658353
[2022-06-11 19:10:10 | train] - Train Epoch: [138] [448000/1281167 (35%)]	Loss: 0.685816
[2022-06-11 19:10:32 | train] - Train Epoch: [138] [460800/1281167 (36%)]	Loss: 0.602198
[2022-06-11 19:10:54 | train] - Train Epoch: [138] [473600/1281167 (37%)]	Loss: 0.719334
[2022-06-11 19:11:16 | train] - Train Epoch: [138] [486400/1281167 (38%)]	Loss: 0.844408
[2022-06-11 19:11:37 | train] - Train Epoch: [138] [499200/1281167 (39%)]	Loss: 0.831942
[2022-06-11 19:11:59 | train] - Train Epoch: [138] [512000/1281167 (40%)]	Loss: 0.838201
[2022-06-11 19:12:21 | train] - Train Epoch: [138] [524800/1281167 (41%)]	Loss: 0.710001
[2022-06-11 19:12:43 | train] - Train Epoch: [138] [537600/1281167 (42%)]	Loss: 0.766247
[2022-06-11 19:13:05 | train] - Train Epoch: [138] [550400/1281167 (43%)]	Loss: 0.679949
[2022-06-11 19:13:27 | train] - Train Epoch: [138] [563200/1281167 (44%)]	Loss: 0.726268
[2022-06-11 19:13:49 | train] - Train Epoch: [138] [576000/1281167 (45%)]	Loss: 0.977047
[2022-06-11 19:14:11 | train] - Train Epoch: [138] [588800/1281167 (46%)]	Loss: 0.646369
[2022-06-11 19:14:32 | train] - Train Epoch: [138] [601600/1281167 (47%)]	Loss: 0.842796
[2022-06-11 19:14:54 | train] - Train Epoch: [138] [614400/1281167 (48%)]	Loss: 0.691071
[2022-06-11 19:15:16 | train] - Train Epoch: [138] [627200/1281167 (49%)]	Loss: 0.642938
[2022-06-11 19:15:38 | train] - Train Epoch: [138] [640000/1281167 (50%)]	Loss: 0.728339
[2022-06-11 19:16:00 | train] - Train Epoch: [138] [652800/1281167 (51%)]	Loss: 0.912751
[2022-06-11 19:16:22 | train] - Train Epoch: [138] [665600/1281167 (52%)]	Loss: 0.653540
[2022-06-11 19:16:44 | train] - Train Epoch: [138] [678400/1281167 (53%)]	Loss: 0.690759
[2022-06-11 19:17:05 | train] - Train Epoch: [138] [691200/1281167 (54%)]	Loss: 0.681972
[2022-06-11 19:17:28 | train] - Train Epoch: [138] [704000/1281167 (55%)]	Loss: 0.688735
[2022-06-11 19:17:50 | train] - Train Epoch: [138] [716800/1281167 (56%)]	Loss: 0.669492
[2022-06-11 19:18:12 | train] - Train Epoch: [138] [729600/1281167 (57%)]	Loss: 0.739285
[2022-06-11 19:18:33 | train] - Train Epoch: [138] [742400/1281167 (58%)]	Loss: 0.982676
[2022-06-11 19:18:55 | train] - Train Epoch: [138] [755200/1281167 (59%)]	Loss: 0.742674
[2022-06-11 19:19:17 | train] - Train Epoch: [138] [768000/1281167 (60%)]	Loss: 0.579116
[2022-06-11 19:19:39 | train] - Train Epoch: [138] [780800/1281167 (61%)]	Loss: 0.729194
[2022-06-11 19:20:01 | train] - Train Epoch: [138] [793600/1281167 (62%)]	Loss: 0.869905
[2022-06-11 19:20:23 | train] - Train Epoch: [138] [806400/1281167 (63%)]	Loss: 0.735393
[2022-06-11 19:20:44 | train] - Train Epoch: [138] [819200/1281167 (64%)]	Loss: 0.991140
[2022-06-11 19:21:06 | train] - Train Epoch: [138] [832000/1281167 (65%)]	Loss: 1.028782
[2022-06-11 19:21:28 | train] - Train Epoch: [138] [844800/1281167 (66%)]	Loss: 0.728202
[2022-06-11 19:21:50 | train] - Train Epoch: [138] [857600/1281167 (67%)]	Loss: 0.790651
[2022-06-11 19:22:11 | train] - Train Epoch: [138] [870400/1281167 (68%)]	Loss: 0.671394
[2022-06-11 19:22:33 | train] - Train Epoch: [138] [883200/1281167 (69%)]	Loss: 0.868063
[2022-06-11 19:22:55 | train] - Train Epoch: [138] [896000/1281167 (70%)]	Loss: 0.967960
[2022-06-11 19:23:17 | train] - Train Epoch: [138] [908800/1281167 (71%)]	Loss: 0.509254
[2022-06-11 19:23:38 | train] - Train Epoch: [138] [921600/1281167 (72%)]	Loss: 0.818731
[2022-06-11 19:24:00 | train] - Train Epoch: [138] [934400/1281167 (73%)]	Loss: 0.553652
[2022-06-11 19:24:22 | train] - Train Epoch: [138] [947200/1281167 (74%)]	Loss: 0.710286
[2022-06-11 19:24:43 | train] - Train Epoch: [138] [960000/1281167 (75%)]	Loss: 0.754360
[2022-06-11 19:25:05 | train] - Train Epoch: [138] [972800/1281167 (76%)]	Loss: 0.671766
[2022-06-11 19:25:26 | train] - Train Epoch: [138] [985600/1281167 (77%)]	Loss: 0.721526
[2022-06-11 19:25:48 | train] - Train Epoch: [138] [998400/1281167 (78%)]	Loss: 0.808310
[2022-06-11 19:26:10 | train] - Train Epoch: [138] [1011200/1281167 (79%)]	Loss: 0.632504
[2022-06-11 19:26:31 | train] - Train Epoch: [138] [1024000/1281167 (80%)]	Loss: 0.570377
[2022-06-11 19:26:53 | train] - Train Epoch: [138] [1036800/1281167 (81%)]	Loss: 0.628050
[2022-06-11 19:27:15 | train] - Train Epoch: [138] [1049600/1281167 (82%)]	Loss: 0.827457
[2022-06-11 19:27:38 | train] - Train Epoch: [138] [1062400/1281167 (83%)]	Loss: 0.637887
[2022-06-11 19:28:00 | train] - Train Epoch: [138] [1075200/1281167 (84%)]	Loss: 0.678961
[2022-06-11 19:28:21 | train] - Train Epoch: [138] [1088000/1281167 (85%)]	Loss: 0.784242
[2022-06-11 19:28:43 | train] - Train Epoch: [138] [1100800/1281167 (86%)]	Loss: 0.527157
[2022-06-11 19:29:05 | train] - Train Epoch: [138] [1113600/1281167 (87%)]	Loss: 0.803318
[2022-06-11 19:29:27 | train] - Train Epoch: [138] [1126400/1281167 (88%)]	Loss: 0.595481
[2022-06-11 19:29:49 | train] - Train Epoch: [138] [1139200/1281167 (89%)]	Loss: 0.969424
[2022-06-11 19:30:11 | train] - Train Epoch: [138] [1152000/1281167 (90%)]	Loss: 0.761077
[2022-06-11 19:30:33 | train] - Train Epoch: [138] [1164800/1281167 (91%)]	Loss: 0.667216
[2022-06-11 19:30:54 | train] - Train Epoch: [138] [1177600/1281167 (92%)]	Loss: 0.868984
[2022-06-11 19:31:15 | train] - Train Epoch: [138] [1190400/1281167 (93%)]	Loss: 0.838029
[2022-06-11 19:31:38 | train] - Train Epoch: [138] [1203200/1281167 (94%)]	Loss: 0.934997
[2022-06-11 19:31:59 | train] - Train Epoch: [138] [1216000/1281167 (95%)]	Loss: 0.514324
[2022-06-11 19:32:21 | train] - Train Epoch: [138] [1228800/1281167 (96%)]	Loss: 0.675575
[2022-06-11 19:32:43 | train] - Train Epoch: [138] [1241600/1281167 (97%)]	Loss: 0.973802
[2022-06-11 19:33:04 | train] - Train Epoch: [138] [1254400/1281167 (98%)]	Loss: 0.782604
[2022-06-11 19:33:26 | train] - Train Epoch: [138] [1267200/1281167 (99%)]	Loss: 0.675937
[2022-06-11 19:33:49 | train] - Train Epoch: [138] [1280000/1281167 (100%)]	Loss: 0.952435
[2022-06-11 19:33:51 | train] - Train Epoch: [138]	 Average Loss: 0.746120	 Total Acc : 81.8344	 Total Top5 Acc : 93.4001
[2022-06-11 19:33:51 | train] - -------138 epoch end-----------
========================================
-------138 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 19:35:25 | train] - 
Epoch [138] Test set: Average loss: 1.4161, Accuracy: 34967/50000 (69.9053%), Top-5 Accuracy: 88.9434%

[2022-06-11 19:35:25 | train] - save intermediate epoch [138] result


[2022-06-11 19:35:33 | train] - -------139 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 19:35:35 | train] - Train Epoch: [139] [0/1281167 (0%)]	Loss: 0.723657
[2022-06-11 19:35:56 | train] - Train Epoch: [139] [12800/1281167 (1%)]	Loss: 0.870040
[2022-06-11 19:36:18 | train] - Train Epoch: [139] [25600/1281167 (2%)]	Loss: 0.632415
[2022-06-11 19:36:40 | train] - Train Epoch: [139] [38400/1281167 (3%)]	Loss: 0.771488
[2022-06-11 19:37:02 | train] - Train Epoch: [139] [51200/1281167 (4%)]	Loss: 0.801779
[2022-06-11 19:37:24 | train] - Train Epoch: [139] [64000/1281167 (5%)]	Loss: 0.463385
[2022-06-11 19:37:47 | train] - Train Epoch: [139] [76800/1281167 (6%)]	Loss: 0.736127
[2022-06-11 19:38:08 | train] - Train Epoch: [139] [89600/1281167 (7%)]	Loss: 0.763823
[2022-06-11 19:38:30 | train] - Train Epoch: [139] [102400/1281167 (8%)]	Loss: 0.703756
[2022-06-11 19:38:52 | train] - Train Epoch: [139] [115200/1281167 (9%)]	Loss: 0.842135
[2022-06-11 19:39:14 | train] - Train Epoch: [139] [128000/1281167 (10%)]	Loss: 0.614660
[2022-06-11 19:39:35 | train] - Train Epoch: [139] [140800/1281167 (11%)]	Loss: 0.820301
[2022-06-11 19:39:57 | train] - Train Epoch: [139] [153600/1281167 (12%)]	Loss: 0.865323
[2022-06-11 19:40:18 | train] - Train Epoch: [139] [166400/1281167 (13%)]	Loss: 0.736389
[2022-06-11 19:40:40 | train] - Train Epoch: [139] [179200/1281167 (14%)]	Loss: 0.742027
[2022-06-11 19:41:02 | train] - Train Epoch: [139] [192000/1281167 (15%)]	Loss: 0.736058
[2022-06-11 19:41:23 | train] - Train Epoch: [139] [204800/1281167 (16%)]	Loss: 0.645617
[2022-06-11 19:41:46 | train] - Train Epoch: [139] [217600/1281167 (17%)]	Loss: 0.621941
[2022-06-11 19:42:07 | train] - Train Epoch: [139] [230400/1281167 (18%)]	Loss: 0.836061
[2022-06-11 19:42:28 | train] - Train Epoch: [139] [243200/1281167 (19%)]	Loss: 0.713597
[2022-06-11 19:42:50 | train] - Train Epoch: [139] [256000/1281167 (20%)]	Loss: 0.754224
[2022-06-11 19:43:12 | train] - Train Epoch: [139] [268800/1281167 (21%)]	Loss: 0.611810
[2022-06-11 19:43:34 | train] - Train Epoch: [139] [281600/1281167 (22%)]	Loss: 0.728041
[2022-06-11 19:43:55 | train] - Train Epoch: [139] [294400/1281167 (23%)]	Loss: 0.589336
[2022-06-11 19:44:17 | train] - Train Epoch: [139] [307200/1281167 (24%)]	Loss: 0.816125
[2022-06-11 19:44:40 | train] - Train Epoch: [139] [320000/1281167 (25%)]	Loss: 0.907053
[2022-06-11 19:45:02 | train] - Train Epoch: [139] [332800/1281167 (26%)]	Loss: 0.677152
[2022-06-11 19:45:24 | train] - Train Epoch: [139] [345600/1281167 (27%)]	Loss: 1.100585
[2022-06-11 19:45:46 | train] - Train Epoch: [139] [358400/1281167 (28%)]	Loss: 0.638503
[2022-06-11 19:46:08 | train] - Train Epoch: [139] [371200/1281167 (29%)]	Loss: 0.826905
[2022-06-11 19:46:29 | train] - Train Epoch: [139] [384000/1281167 (30%)]	Loss: 0.762748
[2022-06-11 19:46:50 | train] - Train Epoch: [139] [396800/1281167 (31%)]	Loss: 1.071441
[2022-06-11 19:47:12 | train] - Train Epoch: [139] [409600/1281167 (32%)]	Loss: 0.825567
[2022-06-11 19:47:34 | train] - Train Epoch: [139] [422400/1281167 (33%)]	Loss: 0.488957
[2022-06-11 19:47:56 | train] - Train Epoch: [139] [435200/1281167 (34%)]	Loss: 0.699082
[2022-06-11 19:48:17 | train] - Train Epoch: [139] [448000/1281167 (35%)]	Loss: 0.984137
[2022-06-11 19:48:39 | train] - Train Epoch: [139] [460800/1281167 (36%)]	Loss: 0.684333
[2022-06-11 19:49:01 | train] - Train Epoch: [139] [473600/1281167 (37%)]	Loss: 0.808375
[2022-06-11 19:49:23 | train] - Train Epoch: [139] [486400/1281167 (38%)]	Loss: 0.735203
[2022-06-11 19:49:45 | train] - Train Epoch: [139] [499200/1281167 (39%)]	Loss: 0.813158
[2022-06-11 19:50:06 | train] - Train Epoch: [139] [512000/1281167 (40%)]	Loss: 0.661749
[2022-06-11 19:50:28 | train] - Train Epoch: [139] [524800/1281167 (41%)]	Loss: 0.756659
[2022-06-11 19:50:51 | train] - Train Epoch: [139] [537600/1281167 (42%)]	Loss: 0.924595
[2022-06-11 19:51:13 | train] - Train Epoch: [139] [550400/1281167 (43%)]	Loss: 0.795049
[2022-06-11 19:51:34 | train] - Train Epoch: [139] [563200/1281167 (44%)]	Loss: 0.853862
[2022-06-11 19:51:57 | train] - Train Epoch: [139] [576000/1281167 (45%)]	Loss: 0.611970
[2022-06-11 19:52:18 | train] - Train Epoch: [139] [588800/1281167 (46%)]	Loss: 0.602716
[2022-06-11 19:52:40 | train] - Train Epoch: [139] [601600/1281167 (47%)]	Loss: 0.604239
[2022-06-11 19:53:01 | train] - Train Epoch: [139] [614400/1281167 (48%)]	Loss: 0.695567
[2022-06-11 19:53:22 | train] - Train Epoch: [139] [627200/1281167 (49%)]	Loss: 0.813872
[2022-06-11 19:53:43 | train] - Train Epoch: [139] [640000/1281167 (50%)]	Loss: 0.976080
[2022-06-11 19:54:05 | train] - Train Epoch: [139] [652800/1281167 (51%)]	Loss: 0.712077
[2022-06-11 19:54:27 | train] - Train Epoch: [139] [665600/1281167 (52%)]	Loss: 0.864283
[2022-06-11 19:54:48 | train] - Train Epoch: [139] [678400/1281167 (53%)]	Loss: 0.757756
[2022-06-11 19:55:10 | train] - Train Epoch: [139] [691200/1281167 (54%)]	Loss: 0.686163
[2022-06-11 19:55:32 | train] - Train Epoch: [139] [704000/1281167 (55%)]	Loss: 0.808262
[2022-06-11 19:55:54 | train] - Train Epoch: [139] [716800/1281167 (56%)]	Loss: 1.031469
[2022-06-11 19:56:16 | train] - Train Epoch: [139] [729600/1281167 (57%)]	Loss: 0.601324
[2022-06-11 19:56:37 | train] - Train Epoch: [139] [742400/1281167 (58%)]	Loss: 0.623449
[2022-06-11 19:57:00 | train] - Train Epoch: [139] [755200/1281167 (59%)]	Loss: 1.028718
[2022-06-11 19:57:21 | train] - Train Epoch: [139] [768000/1281167 (60%)]	Loss: 0.731494
[2022-06-11 19:57:43 | train] - Train Epoch: [139] [780800/1281167 (61%)]	Loss: 0.727874
[2022-06-11 19:58:05 | train] - Train Epoch: [139] [793600/1281167 (62%)]	Loss: 0.601701
[2022-06-11 19:58:27 | train] - Train Epoch: [139] [806400/1281167 (63%)]	Loss: 0.914883
[2022-06-11 19:58:49 | train] - Train Epoch: [139] [819200/1281167 (64%)]	Loss: 0.673367
[2022-06-11 19:59:10 | train] - Train Epoch: [139] [832000/1281167 (65%)]	Loss: 0.758092
[2022-06-11 19:59:32 | train] - Train Epoch: [139] [844800/1281167 (66%)]	Loss: 0.795121
[2022-06-11 19:59:54 | train] - Train Epoch: [139] [857600/1281167 (67%)]	Loss: 0.847060
[2022-06-11 20:00:16 | train] - Train Epoch: [139] [870400/1281167 (68%)]	Loss: 0.799724
[2022-06-11 20:00:38 | train] - Train Epoch: [139] [883200/1281167 (69%)]	Loss: 0.896637
[2022-06-11 20:01:00 | train] - Train Epoch: [139] [896000/1281167 (70%)]	Loss: 0.852882
[2022-06-11 20:01:23 | train] - Train Epoch: [139] [908800/1281167 (71%)]	Loss: 0.851982
[2022-06-11 20:01:44 | train] - Train Epoch: [139] [921600/1281167 (72%)]	Loss: 0.565601
[2022-06-11 20:02:06 | train] - Train Epoch: [139] [934400/1281167 (73%)]	Loss: 0.844186
[2022-06-11 20:02:28 | train] - Train Epoch: [139] [947200/1281167 (74%)]	Loss: 0.678209
[2022-06-11 20:02:50 | train] - Train Epoch: [139] [960000/1281167 (75%)]	Loss: 0.671769
[2022-06-11 20:03:12 | train] - Train Epoch: [139] [972800/1281167 (76%)]	Loss: 1.164614
[2022-06-11 20:03:34 | train] - Train Epoch: [139] [985600/1281167 (77%)]	Loss: 0.780876
[2022-06-11 20:03:56 | train] - Train Epoch: [139] [998400/1281167 (78%)]	Loss: 0.692268
[2022-06-11 20:04:18 | train] - Train Epoch: [139] [1011200/1281167 (79%)]	Loss: 0.741042
[2022-06-11 20:04:40 | train] - Train Epoch: [139] [1024000/1281167 (80%)]	Loss: 0.663945
[2022-06-11 20:05:02 | train] - Train Epoch: [139] [1036800/1281167 (81%)]	Loss: 0.743044
[2022-06-11 20:05:24 | train] - Train Epoch: [139] [1049600/1281167 (82%)]	Loss: 0.642249
[2022-06-11 20:05:46 | train] - Train Epoch: [139] [1062400/1281167 (83%)]	Loss: 0.616070
[2022-06-11 20:06:07 | train] - Train Epoch: [139] [1075200/1281167 (84%)]	Loss: 0.922096
[2022-06-11 20:06:29 | train] - Train Epoch: [139] [1088000/1281167 (85%)]	Loss: 0.599846
[2022-06-11 20:06:52 | train] - Train Epoch: [139] [1100800/1281167 (86%)]	Loss: 1.099434
[2022-06-11 20:07:14 | train] - Train Epoch: [139] [1113600/1281167 (87%)]	Loss: 0.845558
[2022-06-11 20:07:35 | train] - Train Epoch: [139] [1126400/1281167 (88%)]	Loss: 0.872887
[2022-06-11 20:07:56 | train] - Train Epoch: [139] [1139200/1281167 (89%)]	Loss: 0.725422
[2022-06-11 20:08:18 | train] - Train Epoch: [139] [1152000/1281167 (90%)]	Loss: 0.709567
[2022-06-11 20:08:40 | train] - Train Epoch: [139] [1164800/1281167 (91%)]	Loss: 0.631036
[2022-06-11 20:09:02 | train] - Train Epoch: [139] [1177600/1281167 (92%)]	Loss: 0.660405
[2022-06-11 20:09:23 | train] - Train Epoch: [139] [1190400/1281167 (93%)]	Loss: 0.621305
[2022-06-11 20:09:45 | train] - Train Epoch: [139] [1203200/1281167 (94%)]	Loss: 0.770497
[2022-06-11 20:10:08 | train] - Train Epoch: [139] [1216000/1281167 (95%)]	Loss: 0.966150
[2022-06-11 20:10:30 | train] - Train Epoch: [139] [1228800/1281167 (96%)]	Loss: 0.573645
[2022-06-11 20:10:52 | train] - Train Epoch: [139] [1241600/1281167 (97%)]	Loss: 0.789252
[2022-06-11 20:11:14 | train] - Train Epoch: [139] [1254400/1281167 (98%)]	Loss: 0.658547
[2022-06-11 20:11:37 | train] - Train Epoch: [139] [1267200/1281167 (99%)]	Loss: 0.694420
[2022-06-11 20:11:59 | train] - Train Epoch: [139] [1280000/1281167 (100%)]	Loss: 0.641821
[2022-06-11 20:12:01 | train] - Train Epoch: [139]	 Average Loss: 0.744982	 Total Acc : 81.8756	 Total Top5 Acc : 93.4074
[2022-06-11 20:12:01 | train] - -------139 epoch end-----------
========================================
-------139 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 20:13:34 | train] - 
Epoch [139] Test set: Average loss: 1.4105, Accuracy: 34991/50000 (69.9508%), Top-5 Accuracy: 89.0801%

[2022-06-11 20:13:34 | train] - save intermediate epoch [139] result


[2022-06-11 20:13:42 | train] - -------140 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 20:13:44 | train] - Train Epoch: [140] [0/1281167 (0%)]	Loss: 0.868220
[2022-06-11 20:14:06 | train] - Train Epoch: [140] [12800/1281167 (1%)]	Loss: 1.003015
[2022-06-11 20:14:28 | train] - Train Epoch: [140] [25600/1281167 (2%)]	Loss: 0.944983
[2022-06-11 20:14:50 | train] - Train Epoch: [140] [38400/1281167 (3%)]	Loss: 0.712762
[2022-06-11 20:15:12 | train] - Train Epoch: [140] [51200/1281167 (4%)]	Loss: 0.657585
[2022-06-11 20:15:33 | train] - Train Epoch: [140] [64000/1281167 (5%)]	Loss: 1.138059
[2022-06-11 20:15:55 | train] - Train Epoch: [140] [76800/1281167 (6%)]	Loss: 0.813740
[2022-06-11 20:16:17 | train] - Train Epoch: [140] [89600/1281167 (7%)]	Loss: 0.735509
[2022-06-11 20:16:39 | train] - Train Epoch: [140] [102400/1281167 (8%)]	Loss: 0.800488
[2022-06-11 20:17:01 | train] - Train Epoch: [140] [115200/1281167 (9%)]	Loss: 0.646572
[2022-06-11 20:17:23 | train] - Train Epoch: [140] [128000/1281167 (10%)]	Loss: 0.883679
[2022-06-11 20:17:45 | train] - Train Epoch: [140] [140800/1281167 (11%)]	Loss: 0.811224
[2022-06-11 20:18:07 | train] - Train Epoch: [140] [153600/1281167 (12%)]	Loss: 0.720229
[2022-06-11 20:18:29 | train] - Train Epoch: [140] [166400/1281167 (13%)]	Loss: 0.707308
[2022-06-11 20:18:52 | train] - Train Epoch: [140] [179200/1281167 (14%)]	Loss: 0.683247
[2022-06-11 20:19:13 | train] - Train Epoch: [140] [192000/1281167 (15%)]	Loss: 0.780584
[2022-06-11 20:19:36 | train] - Train Epoch: [140] [204800/1281167 (16%)]	Loss: 0.553482
[2022-06-11 20:19:58 | train] - Train Epoch: [140] [217600/1281167 (17%)]	Loss: 0.716781
[2022-06-11 20:20:20 | train] - Train Epoch: [140] [230400/1281167 (18%)]	Loss: 0.536244
[2022-06-11 20:20:42 | train] - Train Epoch: [140] [243200/1281167 (19%)]	Loss: 0.633206
[2022-06-11 20:21:04 | train] - Train Epoch: [140] [256000/1281167 (20%)]	Loss: 0.667946
[2022-06-11 20:21:26 | train] - Train Epoch: [140] [268800/1281167 (21%)]	Loss: 0.714461
[2022-06-11 20:21:48 | train] - Train Epoch: [140] [281600/1281167 (22%)]	Loss: 0.729474
[2022-06-11 20:22:10 | train] - Train Epoch: [140] [294400/1281167 (23%)]	Loss: 0.628511
[2022-06-11 20:22:31 | train] - Train Epoch: [140] [307200/1281167 (24%)]	Loss: 0.835802
[2022-06-11 20:22:53 | train] - Train Epoch: [140] [320000/1281167 (25%)]	Loss: 0.765437
[2022-06-11 20:23:15 | train] - Train Epoch: [140] [332800/1281167 (26%)]	Loss: 0.788482
[2022-06-11 20:23:38 | train] - Train Epoch: [140] [345600/1281167 (27%)]	Loss: 0.711880
[2022-06-11 20:24:00 | train] - Train Epoch: [140] [358400/1281167 (28%)]	Loss: 0.812441
[2022-06-11 20:24:21 | train] - Train Epoch: [140] [371200/1281167 (29%)]	Loss: 0.823122
[2022-06-11 20:24:44 | train] - Train Epoch: [140] [384000/1281167 (30%)]	Loss: 0.659067
[2022-06-11 20:25:06 | train] - Train Epoch: [140] [396800/1281167 (31%)]	Loss: 0.865271
[2022-06-11 20:25:28 | train] - Train Epoch: [140] [409600/1281167 (32%)]	Loss: 0.486750
[2022-06-11 20:25:50 | train] - Train Epoch: [140] [422400/1281167 (33%)]	Loss: 0.804688
[2022-06-11 20:26:11 | train] - Train Epoch: [140] [435200/1281167 (34%)]	Loss: 0.726307
[2022-06-11 20:26:33 | train] - Train Epoch: [140] [448000/1281167 (35%)]	Loss: 0.760624
[2022-06-11 20:26:55 | train] - Train Epoch: [140] [460800/1281167 (36%)]	Loss: 1.034658
[2022-06-11 20:27:16 | train] - Train Epoch: [140] [473600/1281167 (37%)]	Loss: 0.615172
[2022-06-11 20:27:39 | train] - Train Epoch: [140] [486400/1281167 (38%)]	Loss: 1.002852
[2022-06-11 20:28:01 | train] - Train Epoch: [140] [499200/1281167 (39%)]	Loss: 0.680473
[2022-06-11 20:28:23 | train] - Train Epoch: [140] [512000/1281167 (40%)]	Loss: 0.876894
[2022-06-11 20:28:45 | train] - Train Epoch: [140] [524800/1281167 (41%)]	Loss: 0.529505
[2022-06-11 20:29:07 | train] - Train Epoch: [140] [537600/1281167 (42%)]	Loss: 1.017867
[2022-06-11 20:29:29 | train] - Train Epoch: [140] [550400/1281167 (43%)]	Loss: 0.655469
[2022-06-11 20:29:50 | train] - Train Epoch: [140] [563200/1281167 (44%)]	Loss: 0.915940
[2022-06-11 20:30:12 | train] - Train Epoch: [140] [576000/1281167 (45%)]	Loss: 0.700287
[2022-06-11 20:30:33 | train] - Train Epoch: [140] [588800/1281167 (46%)]	Loss: 0.664331
[2022-06-11 20:30:55 | train] - Train Epoch: [140] [601600/1281167 (47%)]	Loss: 0.856549
[2022-06-11 20:31:17 | train] - Train Epoch: [140] [614400/1281167 (48%)]	Loss: 0.759435
[2022-06-11 20:31:39 | train] - Train Epoch: [140] [627200/1281167 (49%)]	Loss: 0.697449
[2022-06-11 20:32:01 | train] - Train Epoch: [140] [640000/1281167 (50%)]	Loss: 0.617528
[2022-06-11 20:32:23 | train] - Train Epoch: [140] [652800/1281167 (51%)]	Loss: 0.948945
[2022-06-11 20:32:44 | train] - Train Epoch: [140] [665600/1281167 (52%)]	Loss: 0.865791
[2022-06-11 20:33:06 | train] - Train Epoch: [140] [678400/1281167 (53%)]	Loss: 0.533688
[2022-06-11 20:33:28 | train] - Train Epoch: [140] [691200/1281167 (54%)]	Loss: 0.729086
[2022-06-11 20:33:50 | train] - Train Epoch: [140] [704000/1281167 (55%)]	Loss: 0.868993
[2022-06-11 20:34:11 | train] - Train Epoch: [140] [716800/1281167 (56%)]	Loss: 0.816330
[2022-06-11 20:34:33 | train] - Train Epoch: [140] [729600/1281167 (57%)]	Loss: 0.689956
[2022-06-11 20:34:55 | train] - Train Epoch: [140] [742400/1281167 (58%)]	Loss: 0.855761
[2022-06-11 20:35:16 | train] - Train Epoch: [140] [755200/1281167 (59%)]	Loss: 0.926188
[2022-06-11 20:35:39 | train] - Train Epoch: [140] [768000/1281167 (60%)]	Loss: 0.845246
[2022-06-11 20:36:00 | train] - Train Epoch: [140] [780800/1281167 (61%)]	Loss: 0.937339
[2022-06-11 20:36:22 | train] - Train Epoch: [140] [793600/1281167 (62%)]	Loss: 0.755408
[2022-06-11 20:36:44 | train] - Train Epoch: [140] [806400/1281167 (63%)]	Loss: 0.629563
[2022-06-11 20:37:06 | train] - Train Epoch: [140] [819200/1281167 (64%)]	Loss: 0.738519
[2022-06-11 20:37:28 | train] - Train Epoch: [140] [832000/1281167 (65%)]	Loss: 0.669093
[2022-06-11 20:37:49 | train] - Train Epoch: [140] [844800/1281167 (66%)]	Loss: 0.585374
[2022-06-11 20:38:12 | train] - Train Epoch: [140] [857600/1281167 (67%)]	Loss: 0.625383
[2022-06-11 20:38:32 | train] - Train Epoch: [140] [870400/1281167 (68%)]	Loss: 0.792545
[2022-06-11 20:38:54 | train] - Train Epoch: [140] [883200/1281167 (69%)]	Loss: 0.990673
[2022-06-11 20:39:16 | train] - Train Epoch: [140] [896000/1281167 (70%)]	Loss: 0.659517
[2022-06-11 20:39:39 | train] - Train Epoch: [140] [908800/1281167 (71%)]	Loss: 0.838048
[2022-06-11 20:40:00 | train] - Train Epoch: [140] [921600/1281167 (72%)]	Loss: 0.909401
[2022-06-11 20:40:22 | train] - Train Epoch: [140] [934400/1281167 (73%)]	Loss: 0.801011
[2022-06-11 20:40:44 | train] - Train Epoch: [140] [947200/1281167 (74%)]	Loss: 0.703140
[2022-06-11 20:41:05 | train] - Train Epoch: [140] [960000/1281167 (75%)]	Loss: 0.703568
[2022-06-11 20:41:27 | train] - Train Epoch: [140] [972800/1281167 (76%)]	Loss: 0.645932
[2022-06-11 20:41:49 | train] - Train Epoch: [140] [985600/1281167 (77%)]	Loss: 0.670916
[2022-06-11 20:42:10 | train] - Train Epoch: [140] [998400/1281167 (78%)]	Loss: 0.917839
[2022-06-11 20:42:33 | train] - Train Epoch: [140] [1011200/1281167 (79%)]	Loss: 0.768255
[2022-06-11 20:42:55 | train] - Train Epoch: [140] [1024000/1281167 (80%)]	Loss: 0.734508
[2022-06-11 20:43:16 | train] - Train Epoch: [140] [1036800/1281167 (81%)]	Loss: 0.620906
[2022-06-11 20:43:38 | train] - Train Epoch: [140] [1049600/1281167 (82%)]	Loss: 0.799659
[2022-06-11 20:43:59 | train] - Train Epoch: [140] [1062400/1281167 (83%)]	Loss: 0.809253
[2022-06-11 20:44:21 | train] - Train Epoch: [140] [1075200/1281167 (84%)]	Loss: 0.808334
[2022-06-11 20:44:43 | train] - Train Epoch: [140] [1088000/1281167 (85%)]	Loss: 0.626710
[2022-06-11 20:45:05 | train] - Train Epoch: [140] [1100800/1281167 (86%)]	Loss: 0.750012
[2022-06-11 20:45:27 | train] - Train Epoch: [140] [1113600/1281167 (87%)]	Loss: 0.822725
[2022-06-11 20:45:48 | train] - Train Epoch: [140] [1126400/1281167 (88%)]	Loss: 0.488458
[2022-06-11 20:46:10 | train] - Train Epoch: [140] [1139200/1281167 (89%)]	Loss: 0.830821
[2022-06-11 20:46:32 | train] - Train Epoch: [140] [1152000/1281167 (90%)]	Loss: 0.527513
[2022-06-11 20:46:54 | train] - Train Epoch: [140] [1164800/1281167 (91%)]	Loss: 0.653946
[2022-06-11 20:47:15 | train] - Train Epoch: [140] [1177600/1281167 (92%)]	Loss: 0.619209
[2022-06-11 20:47:37 | train] - Train Epoch: [140] [1190400/1281167 (93%)]	Loss: 0.751890
[2022-06-11 20:47:58 | train] - Train Epoch: [140] [1203200/1281167 (94%)]	Loss: 0.981938
[2022-06-11 20:48:19 | train] - Train Epoch: [140] [1216000/1281167 (95%)]	Loss: 0.711665
[2022-06-11 20:48:41 | train] - Train Epoch: [140] [1228800/1281167 (96%)]	Loss: 1.082684
[2022-06-11 20:49:03 | train] - Train Epoch: [140] [1241600/1281167 (97%)]	Loss: 0.705769
[2022-06-11 20:49:24 | train] - Train Epoch: [140] [1254400/1281167 (98%)]	Loss: 0.763173
[2022-06-11 20:49:46 | train] - Train Epoch: [140] [1267200/1281167 (99%)]	Loss: 0.685345
[2022-06-11 20:50:07 | train] - Train Epoch: [140] [1280000/1281167 (100%)]	Loss: 0.642279
[2022-06-11 20:50:09 | train] - Train Epoch: [140]	 Average Loss: 0.741508	 Total Acc : 81.9231	 Total Top5 Acc : 93.4624
[2022-06-11 20:50:09 | train] - -------140 epoch end-----------
========================================
-------140 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 20:51:44 | train] - 
Epoch [140] Test set: Average loss: 1.4161, Accuracy: 34943/50000 (69.8589%), Top-5 Accuracy: 88.9762%

[2022-06-11 20:51:44 | train] - save intermediate epoch [140] result


[2022-06-11 20:51:53 | train] - -------141 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 20:51:55 | train] - Train Epoch: [141] [0/1281167 (0%)]	Loss: 0.576845
[2022-06-11 20:52:17 | train] - Train Epoch: [141] [12800/1281167 (1%)]	Loss: 0.764001
[2022-06-11 20:52:39 | train] - Train Epoch: [141] [25600/1281167 (2%)]	Loss: 0.817468
[2022-06-11 20:53:01 | train] - Train Epoch: [141] [38400/1281167 (3%)]	Loss: 0.749437
[2022-06-11 20:53:23 | train] - Train Epoch: [141] [51200/1281167 (4%)]	Loss: 0.744730
[2022-06-11 20:53:45 | train] - Train Epoch: [141] [64000/1281167 (5%)]	Loss: 0.569717
[2022-06-11 20:54:07 | train] - Train Epoch: [141] [76800/1281167 (6%)]	Loss: 0.673735
[2022-06-11 20:54:28 | train] - Train Epoch: [141] [89600/1281167 (7%)]	Loss: 0.695987
[2022-06-11 20:54:50 | train] - Train Epoch: [141] [102400/1281167 (8%)]	Loss: 0.692893
[2022-06-11 20:55:12 | train] - Train Epoch: [141] [115200/1281167 (9%)]	Loss: 0.767861
[2022-06-11 20:55:34 | train] - Train Epoch: [141] [128000/1281167 (10%)]	Loss: 0.917712
[2022-06-11 20:55:55 | train] - Train Epoch: [141] [140800/1281167 (11%)]	Loss: 0.981392
[2022-06-11 20:56:17 | train] - Train Epoch: [141] [153600/1281167 (12%)]	Loss: 0.757642
[2022-06-11 20:56:40 | train] - Train Epoch: [141] [166400/1281167 (13%)]	Loss: 0.827147
[2022-06-11 20:57:01 | train] - Train Epoch: [141] [179200/1281167 (14%)]	Loss: 1.205150
[2022-06-11 20:57:23 | train] - Train Epoch: [141] [192000/1281167 (15%)]	Loss: 0.678390
[2022-06-11 20:57:45 | train] - Train Epoch: [141] [204800/1281167 (16%)]	Loss: 0.604421
[2022-06-11 20:58:07 | train] - Train Epoch: [141] [217600/1281167 (17%)]	Loss: 0.641010
[2022-06-11 20:58:29 | train] - Train Epoch: [141] [230400/1281167 (18%)]	Loss: 0.808302
[2022-06-11 20:58:51 | train] - Train Epoch: [141] [243200/1281167 (19%)]	Loss: 0.790123
[2022-06-11 20:59:13 | train] - Train Epoch: [141] [256000/1281167 (20%)]	Loss: 0.576481
[2022-06-11 20:59:35 | train] - Train Epoch: [141] [268800/1281167 (21%)]	Loss: 0.948206
[2022-06-11 20:59:57 | train] - Train Epoch: [141] [281600/1281167 (22%)]	Loss: 0.877947
[2022-06-11 21:00:19 | train] - Train Epoch: [141] [294400/1281167 (23%)]	Loss: 0.628532
[2022-06-11 21:00:40 | train] - Train Epoch: [141] [307200/1281167 (24%)]	Loss: 0.663436
[2022-06-11 21:01:02 | train] - Train Epoch: [141] [320000/1281167 (25%)]	Loss: 0.552443
[2022-06-11 21:01:23 | train] - Train Epoch: [141] [332800/1281167 (26%)]	Loss: 0.596342
[2022-06-11 21:01:46 | train] - Train Epoch: [141] [345600/1281167 (27%)]	Loss: 0.601581
[2022-06-11 21:02:08 | train] - Train Epoch: [141] [358400/1281167 (28%)]	Loss: 0.599007
[2022-06-11 21:02:30 | train] - Train Epoch: [141] [371200/1281167 (29%)]	Loss: 0.692344
[2022-06-11 21:02:52 | train] - Train Epoch: [141] [384000/1281167 (30%)]	Loss: 0.850744
[2022-06-11 21:03:14 | train] - Train Epoch: [141] [396800/1281167 (31%)]	Loss: 0.545396
[2022-06-11 21:03:37 | train] - Train Epoch: [141] [409600/1281167 (32%)]	Loss: 0.674683
[2022-06-11 21:03:58 | train] - Train Epoch: [141] [422400/1281167 (33%)]	Loss: 0.496646
[2022-06-11 21:04:20 | train] - Train Epoch: [141] [435200/1281167 (34%)]	Loss: 0.872018
[2022-06-11 21:04:42 | train] - Train Epoch: [141] [448000/1281167 (35%)]	Loss: 0.691397
[2022-06-11 21:05:04 | train] - Train Epoch: [141] [460800/1281167 (36%)]	Loss: 0.683243
[2022-06-11 21:05:26 | train] - Train Epoch: [141] [473600/1281167 (37%)]	Loss: 0.689134
[2022-06-11 21:05:48 | train] - Train Epoch: [141] [486400/1281167 (38%)]	Loss: 0.877075
[2022-06-11 21:06:10 | train] - Train Epoch: [141] [499200/1281167 (39%)]	Loss: 0.787738
[2022-06-11 21:06:31 | train] - Train Epoch: [141] [512000/1281167 (40%)]	Loss: 0.823512
[2022-06-11 21:06:53 | train] - Train Epoch: [141] [524800/1281167 (41%)]	Loss: 0.710775
[2022-06-11 21:07:16 | train] - Train Epoch: [141] [537600/1281167 (42%)]	Loss: 0.684359
[2022-06-11 21:07:37 | train] - Train Epoch: [141] [550400/1281167 (43%)]	Loss: 0.604791
[2022-06-11 21:07:59 | train] - Train Epoch: [141] [563200/1281167 (44%)]	Loss: 0.837241
[2022-06-11 21:08:21 | train] - Train Epoch: [141] [576000/1281167 (45%)]	Loss: 0.835319
[2022-06-11 21:08:43 | train] - Train Epoch: [141] [588800/1281167 (46%)]	Loss: 0.816460
[2022-06-11 21:09:04 | train] - Train Epoch: [141] [601600/1281167 (47%)]	Loss: 0.587946
[2022-06-11 21:09:26 | train] - Train Epoch: [141] [614400/1281167 (48%)]	Loss: 0.706767
[2022-06-11 21:09:48 | train] - Train Epoch: [141] [627200/1281167 (49%)]	Loss: 0.894134
[2022-06-11 21:10:10 | train] - Train Epoch: [141] [640000/1281167 (50%)]	Loss: 0.667049
[2022-06-11 21:10:32 | train] - Train Epoch: [141] [652800/1281167 (51%)]	Loss: 0.612656
[2022-06-11 21:10:54 | train] - Train Epoch: [141] [665600/1281167 (52%)]	Loss: 0.716098
[2022-06-11 21:11:16 | train] - Train Epoch: [141] [678400/1281167 (53%)]	Loss: 0.805707
[2022-06-11 21:11:38 | train] - Train Epoch: [141] [691200/1281167 (54%)]	Loss: 0.527238
[2022-06-11 21:12:00 | train] - Train Epoch: [141] [704000/1281167 (55%)]	Loss: 0.570394
[2022-06-11 21:12:22 | train] - Train Epoch: [141] [716800/1281167 (56%)]	Loss: 0.646404
[2022-06-11 21:12:44 | train] - Train Epoch: [141] [729600/1281167 (57%)]	Loss: 0.869944
[2022-06-11 21:13:06 | train] - Train Epoch: [141] [742400/1281167 (58%)]	Loss: 0.691186
[2022-06-11 21:13:28 | train] - Train Epoch: [141] [755200/1281167 (59%)]	Loss: 0.793885
[2022-06-11 21:13:50 | train] - Train Epoch: [141] [768000/1281167 (60%)]	Loss: 0.643143
[2022-06-11 21:14:12 | train] - Train Epoch: [141] [780800/1281167 (61%)]	Loss: 0.533289
[2022-06-11 21:14:34 | train] - Train Epoch: [141] [793600/1281167 (62%)]	Loss: 1.136631
[2022-06-11 21:14:55 | train] - Train Epoch: [141] [806400/1281167 (63%)]	Loss: 0.564613
[2022-06-11 21:15:17 | train] - Train Epoch: [141] [819200/1281167 (64%)]	Loss: 0.851133
[2022-06-11 21:15:39 | train] - Train Epoch: [141] [832000/1281167 (65%)]	Loss: 0.886506
[2022-06-11 21:16:01 | train] - Train Epoch: [141] [844800/1281167 (66%)]	Loss: 0.562384
[2022-06-11 21:16:23 | train] - Train Epoch: [141] [857600/1281167 (67%)]	Loss: 0.717185
[2022-06-11 21:16:45 | train] - Train Epoch: [141] [870400/1281167 (68%)]	Loss: 0.789781
[2022-06-11 21:17:07 | train] - Train Epoch: [141] [883200/1281167 (69%)]	Loss: 0.704565
[2022-06-11 21:17:28 | train] - Train Epoch: [141] [896000/1281167 (70%)]	Loss: 0.740351
[2022-06-11 21:17:49 | train] - Train Epoch: [141] [908800/1281167 (71%)]	Loss: 0.597892
[2022-06-11 21:18:11 | train] - Train Epoch: [141] [921600/1281167 (72%)]	Loss: 0.526796
[2022-06-11 21:18:32 | train] - Train Epoch: [141] [934400/1281167 (73%)]	Loss: 0.585908
[2022-06-11 21:18:54 | train] - Train Epoch: [141] [947200/1281167 (74%)]	Loss: 0.712070
[2022-06-11 21:19:15 | train] - Train Epoch: [141] [960000/1281167 (75%)]	Loss: 0.873188
[2022-06-11 21:19:36 | train] - Train Epoch: [141] [972800/1281167 (76%)]	Loss: 0.601431
[2022-06-11 21:19:57 | train] - Train Epoch: [141] [985600/1281167 (77%)]	Loss: 0.873187
[2022-06-11 21:20:19 | train] - Train Epoch: [141] [998400/1281167 (78%)]	Loss: 0.511835
[2022-06-11 21:20:40 | train] - Train Epoch: [141] [1011200/1281167 (79%)]	Loss: 0.662139
[2022-06-11 21:21:03 | train] - Train Epoch: [141] [1024000/1281167 (80%)]	Loss: 0.661272
[2022-06-11 21:21:24 | train] - Train Epoch: [141] [1036800/1281167 (81%)]	Loss: 0.744578
[2022-06-11 21:21:45 | train] - Train Epoch: [141] [1049600/1281167 (82%)]	Loss: 0.906718
[2022-06-11 21:22:06 | train] - Train Epoch: [141] [1062400/1281167 (83%)]	Loss: 1.113695
[2022-06-11 21:22:28 | train] - Train Epoch: [141] [1075200/1281167 (84%)]	Loss: 0.500667
[2022-06-11 21:22:49 | train] - Train Epoch: [141] [1088000/1281167 (85%)]	Loss: 0.916119
[2022-06-11 21:23:09 | train] - Train Epoch: [141] [1100800/1281167 (86%)]	Loss: 0.905402
[2022-06-11 21:23:30 | train] - Train Epoch: [141] [1113600/1281167 (87%)]	Loss: 0.839668
[2022-06-11 21:23:51 | train] - Train Epoch: [141] [1126400/1281167 (88%)]	Loss: 0.534607
[2022-06-11 21:24:12 | train] - Train Epoch: [141] [1139200/1281167 (89%)]	Loss: 0.887867
[2022-06-11 21:24:34 | train] - Train Epoch: [141] [1152000/1281167 (90%)]	Loss: 0.950676
[2022-06-11 21:24:55 | train] - Train Epoch: [141] [1164800/1281167 (91%)]	Loss: 0.974155
[2022-06-11 21:25:17 | train] - Train Epoch: [141] [1177600/1281167 (92%)]	Loss: 0.780648
[2022-06-11 21:25:38 | train] - Train Epoch: [141] [1190400/1281167 (93%)]	Loss: 0.837436
[2022-06-11 21:25:59 | train] - Train Epoch: [141] [1203200/1281167 (94%)]	Loss: 0.569975
[2022-06-11 21:26:20 | train] - Train Epoch: [141] [1216000/1281167 (95%)]	Loss: 0.746359
[2022-06-11 21:26:41 | train] - Train Epoch: [141] [1228800/1281167 (96%)]	Loss: 0.753561
[2022-06-11 21:27:01 | train] - Train Epoch: [141] [1241600/1281167 (97%)]	Loss: 0.582098
[2022-06-11 21:27:22 | train] - Train Epoch: [141] [1254400/1281167 (98%)]	Loss: 0.649967
[2022-06-11 21:27:44 | train] - Train Epoch: [141] [1267200/1281167 (99%)]	Loss: 0.777712
[2022-06-11 21:28:06 | train] - Train Epoch: [141] [1280000/1281167 (100%)]	Loss: 0.609836
[2022-06-11 21:28:08 | train] - Train Epoch: [141]	 Average Loss: 0.741440	 Total Acc : 81.9453	 Total Top5 Acc : 93.4277
[2022-06-11 21:28:08 | train] - -------141 epoch end-----------
========================================
-------141 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 21:29:41 | train] - 
Epoch [141] Test set: Average loss: 1.4095, Accuracy: 34962/50000 (69.8941%), Top-5 Accuracy: 88.9722%

[2022-06-11 21:29:41 | train] - save intermediate epoch [141] result


[2022-06-11 21:29:50 | train] - -------142 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 21:29:52 | train] - Train Epoch: [142] [0/1281167 (0%)]	Loss: 0.675414
[2022-06-11 21:30:13 | train] - Train Epoch: [142] [12800/1281167 (1%)]	Loss: 0.741004
[2022-06-11 21:30:35 | train] - Train Epoch: [142] [25600/1281167 (2%)]	Loss: 0.604879
[2022-06-11 21:30:56 | train] - Train Epoch: [142] [38400/1281167 (3%)]	Loss: 0.846778
[2022-06-11 21:31:18 | train] - Train Epoch: [142] [51200/1281167 (4%)]	Loss: 0.700400
[2022-06-11 21:31:40 | train] - Train Epoch: [142] [64000/1281167 (5%)]	Loss: 0.676570
[2022-06-11 21:32:01 | train] - Train Epoch: [142] [76800/1281167 (6%)]	Loss: 0.585492
[2022-06-11 21:32:22 | train] - Train Epoch: [142] [89600/1281167 (7%)]	Loss: 0.808167
[2022-06-11 21:32:43 | train] - Train Epoch: [142] [102400/1281167 (8%)]	Loss: 0.772328
[2022-06-11 21:33:05 | train] - Train Epoch: [142] [115200/1281167 (9%)]	Loss: 0.624159
[2022-06-11 21:33:26 | train] - Train Epoch: [142] [128000/1281167 (10%)]	Loss: 0.776103
[2022-06-11 21:33:47 | train] - Train Epoch: [142] [140800/1281167 (11%)]	Loss: 0.558679
[2022-06-11 21:34:08 | train] - Train Epoch: [142] [153600/1281167 (12%)]	Loss: 0.661931
[2022-06-11 21:34:30 | train] - Train Epoch: [142] [166400/1281167 (13%)]	Loss: 0.885574
[2022-06-11 21:34:52 | train] - Train Epoch: [142] [179200/1281167 (14%)]	Loss: 0.858384
[2022-06-11 21:35:13 | train] - Train Epoch: [142] [192000/1281167 (15%)]	Loss: 0.777093
[2022-06-11 21:35:35 | train] - Train Epoch: [142] [204800/1281167 (16%)]	Loss: 0.969700
[2022-06-11 21:35:56 | train] - Train Epoch: [142] [217600/1281167 (17%)]	Loss: 0.778372
[2022-06-11 21:36:16 | train] - Train Epoch: [142] [230400/1281167 (18%)]	Loss: 0.918770
[2022-06-11 21:36:38 | train] - Train Epoch: [142] [243200/1281167 (19%)]	Loss: 0.860919
[2022-06-11 21:36:58 | train] - Train Epoch: [142] [256000/1281167 (20%)]	Loss: 0.947092
[2022-06-11 21:37:19 | train] - Train Epoch: [142] [268800/1281167 (21%)]	Loss: 0.749723
[2022-06-11 21:37:41 | train] - Train Epoch: [142] [281600/1281167 (22%)]	Loss: 0.727958
[2022-06-11 21:38:02 | train] - Train Epoch: [142] [294400/1281167 (23%)]	Loss: 0.675392
[2022-06-11 21:38:22 | train] - Train Epoch: [142] [307200/1281167 (24%)]	Loss: 0.846186
[2022-06-11 21:38:43 | train] - Train Epoch: [142] [320000/1281167 (25%)]	Loss: 0.728533
[2022-06-11 21:39:04 | train] - Train Epoch: [142] [332800/1281167 (26%)]	Loss: 0.724860
[2022-06-11 21:39:25 | train] - Train Epoch: [142] [345600/1281167 (27%)]	Loss: 0.851887
[2022-06-11 21:39:45 | train] - Train Epoch: [142] [358400/1281167 (28%)]	Loss: 0.797150
[2022-06-11 21:40:07 | train] - Train Epoch: [142] [371200/1281167 (29%)]	Loss: 0.699878
[2022-06-11 21:40:28 | train] - Train Epoch: [142] [384000/1281167 (30%)]	Loss: 0.584231
[2022-06-11 21:40:49 | train] - Train Epoch: [142] [396800/1281167 (31%)]	Loss: 0.614214
[2022-06-11 21:41:10 | train] - Train Epoch: [142] [409600/1281167 (32%)]	Loss: 0.760065
[2022-06-11 21:41:30 | train] - Train Epoch: [142] [422400/1281167 (33%)]	Loss: 0.662443
[2022-06-11 21:41:52 | train] - Train Epoch: [142] [435200/1281167 (34%)]	Loss: 0.543582
[2022-06-11 21:42:14 | train] - Train Epoch: [142] [448000/1281167 (35%)]	Loss: 0.628956
[2022-06-11 21:42:36 | train] - Train Epoch: [142] [460800/1281167 (36%)]	Loss: 0.935302
[2022-06-11 21:42:57 | train] - Train Epoch: [142] [473600/1281167 (37%)]	Loss: 0.570744
[2022-06-11 21:43:19 | train] - Train Epoch: [142] [486400/1281167 (38%)]	Loss: 0.717616
[2022-06-11 21:43:41 | train] - Train Epoch: [142] [499200/1281167 (39%)]	Loss: 0.813249
[2022-06-11 21:44:02 | train] - Train Epoch: [142] [512000/1281167 (40%)]	Loss: 0.930074
[2022-06-11 21:44:23 | train] - Train Epoch: [142] [524800/1281167 (41%)]	Loss: 0.550133
[2022-06-11 21:44:45 | train] - Train Epoch: [142] [537600/1281167 (42%)]	Loss: 0.622681
[2022-06-11 21:45:07 | train] - Train Epoch: [142] [550400/1281167 (43%)]	Loss: 0.874003
[2022-06-11 21:45:29 | train] - Train Epoch: [142] [563200/1281167 (44%)]	Loss: 0.700332
[2022-06-11 21:45:50 | train] - Train Epoch: [142] [576000/1281167 (45%)]	Loss: 0.714872
[2022-06-11 21:46:11 | train] - Train Epoch: [142] [588800/1281167 (46%)]	Loss: 1.023465
[2022-06-11 21:46:33 | train] - Train Epoch: [142] [601600/1281167 (47%)]	Loss: 0.568268
[2022-06-11 21:46:54 | train] - Train Epoch: [142] [614400/1281167 (48%)]	Loss: 0.565735
[2022-06-11 21:47:15 | train] - Train Epoch: [142] [627200/1281167 (49%)]	Loss: 0.502029
[2022-06-11 21:47:36 | train] - Train Epoch: [142] [640000/1281167 (50%)]	Loss: 0.743978
[2022-06-11 21:47:58 | train] - Train Epoch: [142] [652800/1281167 (51%)]	Loss: 0.993784
[2022-06-11 21:48:19 | train] - Train Epoch: [142] [665600/1281167 (52%)]	Loss: 0.711863
[2022-06-11 21:48:40 | train] - Train Epoch: [142] [678400/1281167 (53%)]	Loss: 0.542103
[2022-06-11 21:49:01 | train] - Train Epoch: [142] [691200/1281167 (54%)]	Loss: 0.780278
[2022-06-11 21:49:22 | train] - Train Epoch: [142] [704000/1281167 (55%)]	Loss: 0.893282
[2022-06-11 21:49:44 | train] - Train Epoch: [142] [716800/1281167 (56%)]	Loss: 0.792124
[2022-06-11 21:50:05 | train] - Train Epoch: [142] [729600/1281167 (57%)]	Loss: 0.761567
[2022-06-11 21:50:26 | train] - Train Epoch: [142] [742400/1281167 (58%)]	Loss: 1.147540
[2022-06-11 21:50:48 | train] - Train Epoch: [142] [755200/1281167 (59%)]	Loss: 0.843223
[2022-06-11 21:51:10 | train] - Train Epoch: [142] [768000/1281167 (60%)]	Loss: 0.749659
[2022-06-11 21:51:31 | train] - Train Epoch: [142] [780800/1281167 (61%)]	Loss: 0.842656
[2022-06-11 21:51:52 | train] - Train Epoch: [142] [793600/1281167 (62%)]	Loss: 0.771833
[2022-06-11 21:52:13 | train] - Train Epoch: [142] [806400/1281167 (63%)]	Loss: 0.672505
[2022-06-11 21:52:35 | train] - Train Epoch: [142] [819200/1281167 (64%)]	Loss: 0.471160
[2022-06-11 21:52:57 | train] - Train Epoch: [142] [832000/1281167 (65%)]	Loss: 0.626646
[2022-06-11 21:53:16 | train] - Train Epoch: [142] [844800/1281167 (66%)]	Loss: 0.813992
[2022-06-11 21:53:37 | train] - Train Epoch: [142] [857600/1281167 (67%)]	Loss: 0.743009
[2022-06-11 21:53:58 | train] - Train Epoch: [142] [870400/1281167 (68%)]	Loss: 0.775753
[2022-06-11 21:54:20 | train] - Train Epoch: [142] [883200/1281167 (69%)]	Loss: 0.615433
[2022-06-11 21:54:41 | train] - Train Epoch: [142] [896000/1281167 (70%)]	Loss: 0.412071
[2022-06-11 21:55:03 | train] - Train Epoch: [142] [908800/1281167 (71%)]	Loss: 0.739159
[2022-06-11 21:55:24 | train] - Train Epoch: [142] [921600/1281167 (72%)]	Loss: 0.648367
[2022-06-11 21:55:46 | train] - Train Epoch: [142] [934400/1281167 (73%)]	Loss: 0.965340
[2022-06-11 21:56:06 | train] - Train Epoch: [142] [947200/1281167 (74%)]	Loss: 0.790474
[2022-06-11 21:56:27 | train] - Train Epoch: [142] [960000/1281167 (75%)]	Loss: 0.636159
[2022-06-11 21:56:48 | train] - Train Epoch: [142] [972800/1281167 (76%)]	Loss: 0.379761
[2022-06-11 21:57:08 | train] - Train Epoch: [142] [985600/1281167 (77%)]	Loss: 0.827483
[2022-06-11 21:57:30 | train] - Train Epoch: [142] [998400/1281167 (78%)]	Loss: 0.636888
[2022-06-11 21:57:51 | train] - Train Epoch: [142] [1011200/1281167 (79%)]	Loss: 0.772703
[2022-06-11 21:58:12 | train] - Train Epoch: [142] [1024000/1281167 (80%)]	Loss: 0.622722
[2022-06-11 21:58:34 | train] - Train Epoch: [142] [1036800/1281167 (81%)]	Loss: 0.657555
[2022-06-11 21:58:55 | train] - Train Epoch: [142] [1049600/1281167 (82%)]	Loss: 0.843111
[2022-06-11 21:59:17 | train] - Train Epoch: [142] [1062400/1281167 (83%)]	Loss: 0.688330
[2022-06-11 21:59:37 | train] - Train Epoch: [142] [1075200/1281167 (84%)]	Loss: 0.857854
[2022-06-11 21:59:58 | train] - Train Epoch: [142] [1088000/1281167 (85%)]	Loss: 0.756480
[2022-06-11 22:00:20 | train] - Train Epoch: [142] [1100800/1281167 (86%)]	Loss: 0.518116
[2022-06-11 22:00:40 | train] - Train Epoch: [142] [1113600/1281167 (87%)]	Loss: 0.758101
[2022-06-11 22:01:01 | train] - Train Epoch: [142] [1126400/1281167 (88%)]	Loss: 0.676895
[2022-06-11 22:01:23 | train] - Train Epoch: [142] [1139200/1281167 (89%)]	Loss: 0.902593
[2022-06-11 22:01:45 | train] - Train Epoch: [142] [1152000/1281167 (90%)]	Loss: 0.781827
[2022-06-11 22:02:07 | train] - Train Epoch: [142] [1164800/1281167 (91%)]	Loss: 0.642651
[2022-06-11 22:02:28 | train] - Train Epoch: [142] [1177600/1281167 (92%)]	Loss: 0.591141
[2022-06-11 22:02:49 | train] - Train Epoch: [142] [1190400/1281167 (93%)]	Loss: 0.580119
[2022-06-11 22:03:11 | train] - Train Epoch: [142] [1203200/1281167 (94%)]	Loss: 1.053049
[2022-06-11 22:03:33 | train] - Train Epoch: [142] [1216000/1281167 (95%)]	Loss: 0.819857
[2022-06-11 22:03:54 | train] - Train Epoch: [142] [1228800/1281167 (96%)]	Loss: 0.774799
[2022-06-11 22:04:16 | train] - Train Epoch: [142] [1241600/1281167 (97%)]	Loss: 0.887431
[2022-06-11 22:04:38 | train] - Train Epoch: [142] [1254400/1281167 (98%)]	Loss: 0.623936
[2022-06-11 22:05:00 | train] - Train Epoch: [142] [1267200/1281167 (99%)]	Loss: 0.908917
[2022-06-11 22:05:22 | train] - Train Epoch: [142] [1280000/1281167 (100%)]	Loss: 1.051837
[2022-06-11 22:05:24 | train] - Train Epoch: [142]	 Average Loss: 0.739064	 Total Acc : 82.0035	 Total Top5 Acc : 93.4840
[2022-06-11 22:05:24 | train] - -------142 epoch end-----------
========================================
-------142 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 22:06:58 | train] - 
Epoch [142] Test set: Average loss: 1.4331, Accuracy: 34961/50000 (69.8897%), Top-5 Accuracy: 88.9410%

[2022-06-11 22:06:58 | train] - save intermediate epoch [142] result


[2022-06-11 22:07:08 | train] - -------143 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 22:07:10 | train] - Train Epoch: [143] [0/1281167 (0%)]	Loss: 0.714550
[2022-06-11 22:07:30 | train] - Train Epoch: [143] [12800/1281167 (1%)]	Loss: 0.699057
[2022-06-11 22:07:52 | train] - Train Epoch: [143] [25600/1281167 (2%)]	Loss: 0.698793
[2022-06-11 22:08:12 | train] - Train Epoch: [143] [38400/1281167 (3%)]	Loss: 0.656791
[2022-06-11 22:08:34 | train] - Train Epoch: [143] [51200/1281167 (4%)]	Loss: 0.830107
[2022-06-11 22:08:54 | train] - Train Epoch: [143] [64000/1281167 (5%)]	Loss: 0.750569
[2022-06-11 22:09:14 | train] - Train Epoch: [143] [76800/1281167 (6%)]	Loss: 0.952285
[2022-06-11 22:09:35 | train] - Train Epoch: [143] [89600/1281167 (7%)]	Loss: 0.792469
[2022-06-11 22:09:56 | train] - Train Epoch: [143] [102400/1281167 (8%)]	Loss: 0.899842
[2022-06-11 22:10:16 | train] - Train Epoch: [143] [115200/1281167 (9%)]	Loss: 0.945320
[2022-06-11 22:10:38 | train] - Train Epoch: [143] [128000/1281167 (10%)]	Loss: 0.855873
[2022-06-11 22:10:59 | train] - Train Epoch: [143] [140800/1281167 (11%)]	Loss: 0.695269
[2022-06-11 22:11:19 | train] - Train Epoch: [143] [153600/1281167 (12%)]	Loss: 0.556607
[2022-06-11 22:11:38 | train] - Train Epoch: [143] [166400/1281167 (13%)]	Loss: 0.838163
[2022-06-11 22:11:58 | train] - Train Epoch: [143] [179200/1281167 (14%)]	Loss: 0.552513
[2022-06-11 22:12:19 | train] - Train Epoch: [143] [192000/1281167 (15%)]	Loss: 0.833248
[2022-06-11 22:12:39 | train] - Train Epoch: [143] [204800/1281167 (16%)]	Loss: 0.804229
[2022-06-11 22:13:01 | train] - Train Epoch: [143] [217600/1281167 (17%)]	Loss: 0.877606
[2022-06-11 22:13:22 | train] - Train Epoch: [143] [230400/1281167 (18%)]	Loss: 0.849354
[2022-06-11 22:13:43 | train] - Train Epoch: [143] [243200/1281167 (19%)]	Loss: 0.716347
[2022-06-11 22:14:04 | train] - Train Epoch: [143] [256000/1281167 (20%)]	Loss: 0.753065
[2022-06-11 22:14:24 | train] - Train Epoch: [143] [268800/1281167 (21%)]	Loss: 0.810439
[2022-06-11 22:14:44 | train] - Train Epoch: [143] [281600/1281167 (22%)]	Loss: 0.830276
[2022-06-11 22:15:06 | train] - Train Epoch: [143] [294400/1281167 (23%)]	Loss: 0.793429
[2022-06-11 22:15:27 | train] - Train Epoch: [143] [307200/1281167 (24%)]	Loss: 0.635655
[2022-06-11 22:15:48 | train] - Train Epoch: [143] [320000/1281167 (25%)]	Loss: 0.781129
[2022-06-11 22:16:08 | train] - Train Epoch: [143] [332800/1281167 (26%)]	Loss: 0.741979
[2022-06-11 22:16:29 | train] - Train Epoch: [143] [345600/1281167 (27%)]	Loss: 0.738752
[2022-06-11 22:16:50 | train] - Train Epoch: [143] [358400/1281167 (28%)]	Loss: 1.019002
[2022-06-11 22:17:12 | train] - Train Epoch: [143] [371200/1281167 (29%)]	Loss: 0.690651
[2022-06-11 22:17:34 | train] - Train Epoch: [143] [384000/1281167 (30%)]	Loss: 0.687099
[2022-06-11 22:17:54 | train] - Train Epoch: [143] [396800/1281167 (31%)]	Loss: 0.643904
[2022-06-11 22:18:15 | train] - Train Epoch: [143] [409600/1281167 (32%)]	Loss: 0.845425
[2022-06-11 22:18:36 | train] - Train Epoch: [143] [422400/1281167 (33%)]	Loss: 0.742784
[2022-06-11 22:18:56 | train] - Train Epoch: [143] [435200/1281167 (34%)]	Loss: 0.738167
[2022-06-11 22:19:17 | train] - Train Epoch: [143] [448000/1281167 (35%)]	Loss: 0.585086
[2022-06-11 22:19:37 | train] - Train Epoch: [143] [460800/1281167 (36%)]	Loss: 0.775684
[2022-06-11 22:19:58 | train] - Train Epoch: [143] [473600/1281167 (37%)]	Loss: 0.954195
[2022-06-11 22:20:18 | train] - Train Epoch: [143] [486400/1281167 (38%)]	Loss: 0.905113
[2022-06-11 22:20:38 | train] - Train Epoch: [143] [499200/1281167 (39%)]	Loss: 0.941655
[2022-06-11 22:20:59 | train] - Train Epoch: [143] [512000/1281167 (40%)]	Loss: 0.857087
[2022-06-11 22:21:21 | train] - Train Epoch: [143] [524800/1281167 (41%)]	Loss: 1.008547
[2022-06-11 22:21:41 | train] - Train Epoch: [143] [537600/1281167 (42%)]	Loss: 1.283156
[2022-06-11 22:22:01 | train] - Train Epoch: [143] [550400/1281167 (43%)]	Loss: 0.941074
[2022-06-11 22:22:23 | train] - Train Epoch: [143] [563200/1281167 (44%)]	Loss: 0.806835
[2022-06-11 22:22:44 | train] - Train Epoch: [143] [576000/1281167 (45%)]	Loss: 0.697242
[2022-06-11 22:23:04 | train] - Train Epoch: [143] [588800/1281167 (46%)]	Loss: 0.666059
[2022-06-11 22:23:24 | train] - Train Epoch: [143] [601600/1281167 (47%)]	Loss: 0.891675
[2022-06-11 22:23:45 | train] - Train Epoch: [143] [614400/1281167 (48%)]	Loss: 0.682141
[2022-06-11 22:24:06 | train] - Train Epoch: [143] [627200/1281167 (49%)]	Loss: 0.613191
[2022-06-11 22:24:28 | train] - Train Epoch: [143] [640000/1281167 (50%)]	Loss: 0.750883
[2022-06-11 22:24:50 | train] - Train Epoch: [143] [652800/1281167 (51%)]	Loss: 0.463615
[2022-06-11 22:25:10 | train] - Train Epoch: [143] [665600/1281167 (52%)]	Loss: 0.785742
[2022-06-11 22:25:31 | train] - Train Epoch: [143] [678400/1281167 (53%)]	Loss: 0.576588
[2022-06-11 22:25:52 | train] - Train Epoch: [143] [691200/1281167 (54%)]	Loss: 0.661235
[2022-06-11 22:26:12 | train] - Train Epoch: [143] [704000/1281167 (55%)]	Loss: 0.636486
[2022-06-11 22:26:32 | train] - Train Epoch: [143] [716800/1281167 (56%)]	Loss: 0.610962
[2022-06-11 22:26:53 | train] - Train Epoch: [143] [729600/1281167 (57%)]	Loss: 0.418278
[2022-06-11 22:27:13 | train] - Train Epoch: [143] [742400/1281167 (58%)]	Loss: 0.526969
[2022-06-11 22:27:34 | train] - Train Epoch: [143] [755200/1281167 (59%)]	Loss: 0.494985
[2022-06-11 22:27:55 | train] - Train Epoch: [143] [768000/1281167 (60%)]	Loss: 0.830290
[2022-06-11 22:28:16 | train] - Train Epoch: [143] [780800/1281167 (61%)]	Loss: 0.735237
[2022-06-11 22:28:37 | train] - Train Epoch: [143] [793600/1281167 (62%)]	Loss: 0.707549
[2022-06-11 22:28:58 | train] - Train Epoch: [143] [806400/1281167 (63%)]	Loss: 0.854571
[2022-06-11 22:29:19 | train] - Train Epoch: [143] [819200/1281167 (64%)]	Loss: 0.659813
[2022-06-11 22:29:40 | train] - Train Epoch: [143] [832000/1281167 (65%)]	Loss: 0.871197
[2022-06-11 22:30:01 | train] - Train Epoch: [143] [844800/1281167 (66%)]	Loss: 0.666910
[2022-06-11 22:30:22 | train] - Train Epoch: [143] [857600/1281167 (67%)]	Loss: 0.815158
[2022-06-11 22:30:43 | train] - Train Epoch: [143] [870400/1281167 (68%)]	Loss: 0.755183
[2022-06-11 22:31:04 | train] - Train Epoch: [143] [883200/1281167 (69%)]	Loss: 0.718339
[2022-06-11 22:31:26 | train] - Train Epoch: [143] [896000/1281167 (70%)]	Loss: 0.693096
[2022-06-11 22:31:46 | train] - Train Epoch: [143] [908800/1281167 (71%)]	Loss: 0.547714
[2022-06-11 22:32:07 | train] - Train Epoch: [143] [921600/1281167 (72%)]	Loss: 0.726711
[2022-06-11 22:32:29 | train] - Train Epoch: [143] [934400/1281167 (73%)]	Loss: 0.711719
[2022-06-11 22:32:50 | train] - Train Epoch: [143] [947200/1281167 (74%)]	Loss: 0.902936
[2022-06-11 22:33:11 | train] - Train Epoch: [143] [960000/1281167 (75%)]	Loss: 0.548737
[2022-06-11 22:33:33 | train] - Train Epoch: [143] [972800/1281167 (76%)]	Loss: 0.587959
[2022-06-11 22:33:54 | train] - Train Epoch: [143] [985600/1281167 (77%)]	Loss: 0.834974
[2022-06-11 22:34:15 | train] - Train Epoch: [143] [998400/1281167 (78%)]	Loss: 0.363427
[2022-06-11 22:34:36 | train] - Train Epoch: [143] [1011200/1281167 (79%)]	Loss: 0.837492
[2022-06-11 22:34:58 | train] - Train Epoch: [143] [1024000/1281167 (80%)]	Loss: 0.864716
[2022-06-11 22:35:19 | train] - Train Epoch: [143] [1036800/1281167 (81%)]	Loss: 0.741359
[2022-06-11 22:35:40 | train] - Train Epoch: [143] [1049600/1281167 (82%)]	Loss: 0.632338
[2022-06-11 22:36:01 | train] - Train Epoch: [143] [1062400/1281167 (83%)]	Loss: 0.710956
[2022-06-11 22:36:22 | train] - Train Epoch: [143] [1075200/1281167 (84%)]	Loss: 0.865027
[2022-06-11 22:36:44 | train] - Train Epoch: [143] [1088000/1281167 (85%)]	Loss: 0.617550
[2022-06-11 22:37:05 | train] - Train Epoch: [143] [1100800/1281167 (86%)]	Loss: 0.623666
[2022-06-11 22:37:26 | train] - Train Epoch: [143] [1113600/1281167 (87%)]	Loss: 0.787436
[2022-06-11 22:37:48 | train] - Train Epoch: [143] [1126400/1281167 (88%)]	Loss: 0.583478
[2022-06-11 22:38:09 | train] - Train Epoch: [143] [1139200/1281167 (89%)]	Loss: 0.919991
[2022-06-11 22:38:30 | train] - Train Epoch: [143] [1152000/1281167 (90%)]	Loss: 0.567903
[2022-06-11 22:38:51 | train] - Train Epoch: [143] [1164800/1281167 (91%)]	Loss: 0.861673
[2022-06-11 22:39:11 | train] - Train Epoch: [143] [1177600/1281167 (92%)]	Loss: 0.491314
[2022-06-11 22:39:32 | train] - Train Epoch: [143] [1190400/1281167 (93%)]	Loss: 0.776019
[2022-06-11 22:39:54 | train] - Train Epoch: [143] [1203200/1281167 (94%)]	Loss: 0.743048
[2022-06-11 22:40:16 | train] - Train Epoch: [143] [1216000/1281167 (95%)]	Loss: 0.754226
[2022-06-11 22:40:37 | train] - Train Epoch: [143] [1228800/1281167 (96%)]	Loss: 0.778538
[2022-06-11 22:40:58 | train] - Train Epoch: [143] [1241600/1281167 (97%)]	Loss: 0.792307
[2022-06-11 22:41:20 | train] - Train Epoch: [143] [1254400/1281167 (98%)]	Loss: 0.790823
[2022-06-11 22:41:40 | train] - Train Epoch: [143] [1267200/1281167 (99%)]	Loss: 0.842296
[2022-06-11 22:42:00 | train] - Train Epoch: [143] [1280000/1281167 (100%)]	Loss: 0.862889
[2022-06-11 22:42:02 | train] - Train Epoch: [143]	 Average Loss: 0.736931	 Total Acc : 82.0089	 Total Top5 Acc : 93.4941
[2022-06-11 22:42:02 | train] - -------143 epoch end-----------
========================================
-------143 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 22:43:36 | train] - 
Epoch [143] Test set: Average loss: 1.4294, Accuracy: 34853/50000 (69.6751%), Top-5 Accuracy: 88.8811%

[2022-06-11 22:43:36 | train] - save intermediate epoch [143] result


[2022-06-11 22:43:46 | train] - -------144 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 22:43:48 | train] - Train Epoch: [144] [0/1281167 (0%)]	Loss: 0.684600
[2022-06-11 22:44:10 | train] - Train Epoch: [144] [12800/1281167 (1%)]	Loss: 0.665153
[2022-06-11 22:44:30 | train] - Train Epoch: [144] [25600/1281167 (2%)]	Loss: 0.744538
[2022-06-11 22:44:52 | train] - Train Epoch: [144] [38400/1281167 (3%)]	Loss: 0.551993
[2022-06-11 22:45:13 | train] - Train Epoch: [144] [51200/1281167 (4%)]	Loss: 0.737485
[2022-06-11 22:45:34 | train] - Train Epoch: [144] [64000/1281167 (5%)]	Loss: 0.750514
[2022-06-11 22:45:54 | train] - Train Epoch: [144] [76800/1281167 (6%)]	Loss: 0.738059
[2022-06-11 22:46:15 | train] - Train Epoch: [144] [89600/1281167 (7%)]	Loss: 0.778853
[2022-06-11 22:46:35 | train] - Train Epoch: [144] [102400/1281167 (8%)]	Loss: 0.698645
[2022-06-11 22:46:56 | train] - Train Epoch: [144] [115200/1281167 (9%)]	Loss: 0.560030
[2022-06-11 22:47:16 | train] - Train Epoch: [144] [128000/1281167 (10%)]	Loss: 0.619118
[2022-06-11 22:47:37 | train] - Train Epoch: [144] [140800/1281167 (11%)]	Loss: 0.721988
[2022-06-11 22:47:58 | train] - Train Epoch: [144] [153600/1281167 (12%)]	Loss: 0.769451
[2022-06-11 22:48:19 | train] - Train Epoch: [144] [166400/1281167 (13%)]	Loss: 0.713848
[2022-06-11 22:48:41 | train] - Train Epoch: [144] [179200/1281167 (14%)]	Loss: 0.757490
[2022-06-11 22:49:02 | train] - Train Epoch: [144] [192000/1281167 (15%)]	Loss: 0.864640
[2022-06-11 22:49:24 | train] - Train Epoch: [144] [204800/1281167 (16%)]	Loss: 0.796991
[2022-06-11 22:49:45 | train] - Train Epoch: [144] [217600/1281167 (17%)]	Loss: 0.920976
[2022-06-11 22:50:06 | train] - Train Epoch: [144] [230400/1281167 (18%)]	Loss: 0.696214
[2022-06-11 22:50:28 | train] - Train Epoch: [144] [243200/1281167 (19%)]	Loss: 0.606151
[2022-06-11 22:50:49 | train] - Train Epoch: [144] [256000/1281167 (20%)]	Loss: 0.752079
[2022-06-11 22:51:12 | train] - Train Epoch: [144] [268800/1281167 (21%)]	Loss: 0.928151
[2022-06-11 22:51:33 | train] - Train Epoch: [144] [281600/1281167 (22%)]	Loss: 0.669623
[2022-06-11 22:51:54 | train] - Train Epoch: [144] [294400/1281167 (23%)]	Loss: 0.867766
[2022-06-11 22:52:16 | train] - Train Epoch: [144] [307200/1281167 (24%)]	Loss: 0.750784
[2022-06-11 22:52:36 | train] - Train Epoch: [144] [320000/1281167 (25%)]	Loss: 0.683710
[2022-06-11 22:52:58 | train] - Train Epoch: [144] [332800/1281167 (26%)]	Loss: 0.874432
[2022-06-11 22:53:19 | train] - Train Epoch: [144] [345600/1281167 (27%)]	Loss: 0.939624
[2022-06-11 22:53:40 | train] - Train Epoch: [144] [358400/1281167 (28%)]	Loss: 0.888519
[2022-06-11 22:54:01 | train] - Train Epoch: [144] [371200/1281167 (29%)]	Loss: 0.757789
[2022-06-11 22:54:21 | train] - Train Epoch: [144] [384000/1281167 (30%)]	Loss: 0.792402
[2022-06-11 22:54:42 | train] - Train Epoch: [144] [396800/1281167 (31%)]	Loss: 0.599351
[2022-06-11 22:55:03 | train] - Train Epoch: [144] [409600/1281167 (32%)]	Loss: 0.768540
[2022-06-11 22:55:25 | train] - Train Epoch: [144] [422400/1281167 (33%)]	Loss: 0.854775
[2022-06-11 22:55:46 | train] - Train Epoch: [144] [435200/1281167 (34%)]	Loss: 0.921043
[2022-06-11 22:56:06 | train] - Train Epoch: [144] [448000/1281167 (35%)]	Loss: 0.629743
[2022-06-11 22:56:28 | train] - Train Epoch: [144] [460800/1281167 (36%)]	Loss: 0.822192
[2022-06-11 22:56:49 | train] - Train Epoch: [144] [473600/1281167 (37%)]	Loss: 0.674271
[2022-06-11 22:57:10 | train] - Train Epoch: [144] [486400/1281167 (38%)]	Loss: 0.622458
[2022-06-11 22:57:31 | train] - Train Epoch: [144] [499200/1281167 (39%)]	Loss: 0.822468
[2022-06-11 22:57:52 | train] - Train Epoch: [144] [512000/1281167 (40%)]	Loss: 0.541959
[2022-06-11 22:58:13 | train] - Train Epoch: [144] [524800/1281167 (41%)]	Loss: 0.564905
[2022-06-11 22:58:33 | train] - Train Epoch: [144] [537600/1281167 (42%)]	Loss: 0.660461
[2022-06-11 22:58:55 | train] - Train Epoch: [144] [550400/1281167 (43%)]	Loss: 0.782781
[2022-06-11 22:59:16 | train] - Train Epoch: [144] [563200/1281167 (44%)]	Loss: 0.727090
[2022-06-11 22:59:38 | train] - Train Epoch: [144] [576000/1281167 (45%)]	Loss: 0.921514
[2022-06-11 22:59:59 | train] - Train Epoch: [144] [588800/1281167 (46%)]	Loss: 0.582452
[2022-06-11 23:00:20 | train] - Train Epoch: [144] [601600/1281167 (47%)]	Loss: 0.683236
[2022-06-11 23:00:41 | train] - Train Epoch: [144] [614400/1281167 (48%)]	Loss: 0.899946
[2022-06-11 23:01:03 | train] - Train Epoch: [144] [627200/1281167 (49%)]	Loss: 0.470936
[2022-06-11 23:01:24 | train] - Train Epoch: [144] [640000/1281167 (50%)]	Loss: 0.943879
[2022-06-11 23:01:46 | train] - Train Epoch: [144] [652800/1281167 (51%)]	Loss: 0.636714
[2022-06-11 23:02:06 | train] - Train Epoch: [144] [665600/1281167 (52%)]	Loss: 0.843881
[2022-06-11 23:02:27 | train] - Train Epoch: [144] [678400/1281167 (53%)]	Loss: 0.741693
[2022-06-11 23:02:48 | train] - Train Epoch: [144] [691200/1281167 (54%)]	Loss: 0.635287
[2022-06-11 23:03:10 | train] - Train Epoch: [144] [704000/1281167 (55%)]	Loss: 0.515271
[2022-06-11 23:03:30 | train] - Train Epoch: [144] [716800/1281167 (56%)]	Loss: 0.766276
[2022-06-11 23:03:52 | train] - Train Epoch: [144] [729600/1281167 (57%)]	Loss: 0.469656
[2022-06-11 23:04:12 | train] - Train Epoch: [144] [742400/1281167 (58%)]	Loss: 0.701298
[2022-06-11 23:04:32 | train] - Train Epoch: [144] [755200/1281167 (59%)]	Loss: 0.618663
[2022-06-11 23:04:54 | train] - Train Epoch: [144] [768000/1281167 (60%)]	Loss: 0.766438
[2022-06-11 23:05:15 | train] - Train Epoch: [144] [780800/1281167 (61%)]	Loss: 0.534410
[2022-06-11 23:05:37 | train] - Train Epoch: [144] [793600/1281167 (62%)]	Loss: 0.848786
[2022-06-11 23:05:58 | train] - Train Epoch: [144] [806400/1281167 (63%)]	Loss: 0.763001
[2022-06-11 23:06:19 | train] - Train Epoch: [144] [819200/1281167 (64%)]	Loss: 0.747344
[2022-06-11 23:06:40 | train] - Train Epoch: [144] [832000/1281167 (65%)]	Loss: 0.710879
[2022-06-11 23:07:02 | train] - Train Epoch: [144] [844800/1281167 (66%)]	Loss: 0.772689
[2022-06-11 23:07:24 | train] - Train Epoch: [144] [857600/1281167 (67%)]	Loss: 0.881272
[2022-06-11 23:07:45 | train] - Train Epoch: [144] [870400/1281167 (68%)]	Loss: 0.799324
[2022-06-11 23:08:05 | train] - Train Epoch: [144] [883200/1281167 (69%)]	Loss: 0.742988
[2022-06-11 23:08:26 | train] - Train Epoch: [144] [896000/1281167 (70%)]	Loss: 0.695462
[2022-06-11 23:08:46 | train] - Train Epoch: [144] [908800/1281167 (71%)]	Loss: 1.009138
[2022-06-11 23:09:07 | train] - Train Epoch: [144] [921600/1281167 (72%)]	Loss: 0.882057
[2022-06-11 23:09:28 | train] - Train Epoch: [144] [934400/1281167 (73%)]	Loss: 0.831358
[2022-06-11 23:09:49 | train] - Train Epoch: [144] [947200/1281167 (74%)]	Loss: 0.820728
[2022-06-11 23:10:09 | train] - Train Epoch: [144] [960000/1281167 (75%)]	Loss: 0.597808
[2022-06-11 23:10:30 | train] - Train Epoch: [144] [972800/1281167 (76%)]	Loss: 0.631269
[2022-06-11 23:10:51 | train] - Train Epoch: [144] [985600/1281167 (77%)]	Loss: 0.970191
[2022-06-11 23:11:12 | train] - Train Epoch: [144] [998400/1281167 (78%)]	Loss: 0.861078
[2022-06-11 23:11:33 | train] - Train Epoch: [144] [1011200/1281167 (79%)]	Loss: 0.672632
[2022-06-11 23:11:54 | train] - Train Epoch: [144] [1024000/1281167 (80%)]	Loss: 0.747560
[2022-06-11 23:12:16 | train] - Train Epoch: [144] [1036800/1281167 (81%)]	Loss: 0.838389
[2022-06-11 23:12:37 | train] - Train Epoch: [144] [1049600/1281167 (82%)]	Loss: 0.837090
[2022-06-11 23:12:56 | train] - Train Epoch: [144] [1062400/1281167 (83%)]	Loss: 0.391249
[2022-06-11 23:13:16 | train] - Train Epoch: [144] [1075200/1281167 (84%)]	Loss: 0.532619
[2022-06-11 23:13:38 | train] - Train Epoch: [144] [1088000/1281167 (85%)]	Loss: 0.486559
[2022-06-11 23:13:58 | train] - Train Epoch: [144] [1100800/1281167 (86%)]	Loss: 0.638427
[2022-06-11 23:14:19 | train] - Train Epoch: [144] [1113600/1281167 (87%)]	Loss: 1.009923
[2022-06-11 23:14:40 | train] - Train Epoch: [144] [1126400/1281167 (88%)]	Loss: 0.669534
[2022-06-11 23:15:01 | train] - Train Epoch: [144] [1139200/1281167 (89%)]	Loss: 0.812872
[2022-06-11 23:15:21 | train] - Train Epoch: [144] [1152000/1281167 (90%)]	Loss: 0.453432
[2022-06-11 23:15:43 | train] - Train Epoch: [144] [1164800/1281167 (91%)]	Loss: 0.707452
[2022-06-11 23:16:03 | train] - Train Epoch: [144] [1177600/1281167 (92%)]	Loss: 0.734770
[2022-06-11 23:16:24 | train] - Train Epoch: [144] [1190400/1281167 (93%)]	Loss: 0.883064
[2022-06-11 23:16:45 | train] - Train Epoch: [144] [1203200/1281167 (94%)]	Loss: 0.852391
[2022-06-11 23:17:05 | train] - Train Epoch: [144] [1216000/1281167 (95%)]	Loss: 0.768261
[2022-06-11 23:17:26 | train] - Train Epoch: [144] [1228800/1281167 (96%)]	Loss: 0.601768
[2022-06-11 23:17:47 | train] - Train Epoch: [144] [1241600/1281167 (97%)]	Loss: 0.887325
[2022-06-11 23:18:08 | train] - Train Epoch: [144] [1254400/1281167 (98%)]	Loss: 0.973909
[2022-06-11 23:18:30 | train] - Train Epoch: [144] [1267200/1281167 (99%)]	Loss: 0.911364
[2022-06-11 23:18:50 | train] - Train Epoch: [144] [1280000/1281167 (100%)]	Loss: 0.868761
[2022-06-11 23:18:52 | train] - Train Epoch: [144]	 Average Loss: 0.736090	 Total Acc : 82.0597	 Total Top5 Acc : 93.4983
[2022-06-11 23:18:52 | train] - -------144 epoch end-----------
========================================
-------144 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 23:20:27 | train] - 
Epoch [144] Test set: Average loss: 1.4252, Accuracy: 34971/50000 (69.9169%), Top-5 Accuracy: 89.0002%

[2022-06-11 23:20:27 | train] - save intermediate epoch [144] result


[2022-06-11 23:20:36 | train] - -------145 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 23:20:38 | train] - Train Epoch: [145] [0/1281167 (0%)]	Loss: 0.811050
[2022-06-11 23:21:00 | train] - Train Epoch: [145] [12800/1281167 (1%)]	Loss: 0.858220
[2022-06-11 23:21:22 | train] - Train Epoch: [145] [25600/1281167 (2%)]	Loss: 0.623224
[2022-06-11 23:21:43 | train] - Train Epoch: [145] [38400/1281167 (3%)]	Loss: 0.687510
[2022-06-11 23:22:05 | train] - Train Epoch: [145] [51200/1281167 (4%)]	Loss: 0.726024
[2022-06-11 23:22:26 | train] - Train Epoch: [145] [64000/1281167 (5%)]	Loss: 0.966559
[2022-06-11 23:22:48 | train] - Train Epoch: [145] [76800/1281167 (6%)]	Loss: 0.619733
[2022-06-11 23:23:08 | train] - Train Epoch: [145] [89600/1281167 (7%)]	Loss: 0.953327
[2022-06-11 23:23:28 | train] - Train Epoch: [145] [102400/1281167 (8%)]	Loss: 0.508565
[2022-06-11 23:23:49 | train] - Train Epoch: [145] [115200/1281167 (9%)]	Loss: 0.740383
[2022-06-11 23:24:10 | train] - Train Epoch: [145] [128000/1281167 (10%)]	Loss: 0.945427
[2022-06-11 23:24:30 | train] - Train Epoch: [145] [140800/1281167 (11%)]	Loss: 0.819462
[2022-06-11 23:24:51 | train] - Train Epoch: [145] [153600/1281167 (12%)]	Loss: 1.132992
[2022-06-11 23:25:11 | train] - Train Epoch: [145] [166400/1281167 (13%)]	Loss: 0.651110
[2022-06-11 23:25:33 | train] - Train Epoch: [145] [179200/1281167 (14%)]	Loss: 0.887370
[2022-06-11 23:25:54 | train] - Train Epoch: [145] [192000/1281167 (15%)]	Loss: 0.828089
[2022-06-11 23:26:14 | train] - Train Epoch: [145] [204800/1281167 (16%)]	Loss: 0.761808
[2022-06-11 23:26:34 | train] - Train Epoch: [145] [217600/1281167 (17%)]	Loss: 0.811249
[2022-06-11 23:26:55 | train] - Train Epoch: [145] [230400/1281167 (18%)]	Loss: 0.894932
[2022-06-11 23:27:16 | train] - Train Epoch: [145] [243200/1281167 (19%)]	Loss: 0.700136
[2022-06-11 23:27:37 | train] - Train Epoch: [145] [256000/1281167 (20%)]	Loss: 0.766882
[2022-06-11 23:27:59 | train] - Train Epoch: [145] [268800/1281167 (21%)]	Loss: 0.741140
[2022-06-11 23:28:21 | train] - Train Epoch: [145] [281600/1281167 (22%)]	Loss: 0.717036
[2022-06-11 23:28:41 | train] - Train Epoch: [145] [294400/1281167 (23%)]	Loss: 0.804616
[2022-06-11 23:29:02 | train] - Train Epoch: [145] [307200/1281167 (24%)]	Loss: 0.856851
[2022-06-11 23:29:23 | train] - Train Epoch: [145] [320000/1281167 (25%)]	Loss: 0.946676
[2022-06-11 23:29:44 | train] - Train Epoch: [145] [332800/1281167 (26%)]	Loss: 0.758659
[2022-06-11 23:30:05 | train] - Train Epoch: [145] [345600/1281167 (27%)]	Loss: 0.732831
[2022-06-11 23:30:26 | train] - Train Epoch: [145] [358400/1281167 (28%)]	Loss: 0.622705
[2022-06-11 23:30:47 | train] - Train Epoch: [145] [371200/1281167 (29%)]	Loss: 0.648860
[2022-06-11 23:31:08 | train] - Train Epoch: [145] [384000/1281167 (30%)]	Loss: 0.831272
[2022-06-11 23:31:30 | train] - Train Epoch: [145] [396800/1281167 (31%)]	Loss: 0.796728
[2022-06-11 23:31:52 | train] - Train Epoch: [145] [409600/1281167 (32%)]	Loss: 0.752267
[2022-06-11 23:32:13 | train] - Train Epoch: [145] [422400/1281167 (33%)]	Loss: 0.676388
[2022-06-11 23:32:33 | train] - Train Epoch: [145] [435200/1281167 (34%)]	Loss: 0.818328
[2022-06-11 23:32:53 | train] - Train Epoch: [145] [448000/1281167 (35%)]	Loss: 0.891493
[2022-06-11 23:33:14 | train] - Train Epoch: [145] [460800/1281167 (36%)]	Loss: 0.606284
[2022-06-11 23:33:35 | train] - Train Epoch: [145] [473600/1281167 (37%)]	Loss: 0.612258
[2022-06-11 23:33:55 | train] - Train Epoch: [145] [486400/1281167 (38%)]	Loss: 0.638958
[2022-06-11 23:34:15 | train] - Train Epoch: [145] [499200/1281167 (39%)]	Loss: 0.500012
[2022-06-11 23:34:36 | train] - Train Epoch: [145] [512000/1281167 (40%)]	Loss: 0.695138
[2022-06-11 23:34:57 | train] - Train Epoch: [145] [524800/1281167 (41%)]	Loss: 0.770469
[2022-06-11 23:35:18 | train] - Train Epoch: [145] [537600/1281167 (42%)]	Loss: 0.845117
[2022-06-11 23:35:39 | train] - Train Epoch: [145] [550400/1281167 (43%)]	Loss: 0.841831
[2022-06-11 23:36:00 | train] - Train Epoch: [145] [563200/1281167 (44%)]	Loss: 0.813651
[2022-06-11 23:36:22 | train] - Train Epoch: [145] [576000/1281167 (45%)]	Loss: 0.672124
[2022-06-11 23:36:43 | train] - Train Epoch: [145] [588800/1281167 (46%)]	Loss: 0.541440
[2022-06-11 23:37:04 | train] - Train Epoch: [145] [601600/1281167 (47%)]	Loss: 0.778722
[2022-06-11 23:37:24 | train] - Train Epoch: [145] [614400/1281167 (48%)]	Loss: 0.623189
[2022-06-11 23:37:44 | train] - Train Epoch: [145] [627200/1281167 (49%)]	Loss: 0.994172
[2022-06-11 23:38:05 | train] - Train Epoch: [145] [640000/1281167 (50%)]	Loss: 0.861958
[2022-06-11 23:38:27 | train] - Train Epoch: [145] [652800/1281167 (51%)]	Loss: 0.725784
[2022-06-11 23:38:49 | train] - Train Epoch: [145] [665600/1281167 (52%)]	Loss: 0.675174
[2022-06-11 23:39:10 | train] - Train Epoch: [145] [678400/1281167 (53%)]	Loss: 1.090984
[2022-06-11 23:39:31 | train] - Train Epoch: [145] [691200/1281167 (54%)]	Loss: 0.735115
[2022-06-11 23:39:53 | train] - Train Epoch: [145] [704000/1281167 (55%)]	Loss: 0.578592
[2022-06-11 23:40:13 | train] - Train Epoch: [145] [716800/1281167 (56%)]	Loss: 0.533775
[2022-06-11 23:40:35 | train] - Train Epoch: [145] [729600/1281167 (57%)]	Loss: 0.786499
[2022-06-11 23:40:57 | train] - Train Epoch: [145] [742400/1281167 (58%)]	Loss: 0.999608
[2022-06-11 23:41:19 | train] - Train Epoch: [145] [755200/1281167 (59%)]	Loss: 0.739538
[2022-06-11 23:41:40 | train] - Train Epoch: [145] [768000/1281167 (60%)]	Loss: 0.575464
[2022-06-11 23:42:01 | train] - Train Epoch: [145] [780800/1281167 (61%)]	Loss: 0.751892
[2022-06-11 23:42:22 | train] - Train Epoch: [145] [793600/1281167 (62%)]	Loss: 0.773077
[2022-06-11 23:42:44 | train] - Train Epoch: [145] [806400/1281167 (63%)]	Loss: 0.904103
[2022-06-11 23:43:05 | train] - Train Epoch: [145] [819200/1281167 (64%)]	Loss: 0.936479
[2022-06-11 23:43:25 | train] - Train Epoch: [145] [832000/1281167 (65%)]	Loss: 0.578962
[2022-06-11 23:43:46 | train] - Train Epoch: [145] [844800/1281167 (66%)]	Loss: 0.487510
[2022-06-11 23:44:08 | train] - Train Epoch: [145] [857600/1281167 (67%)]	Loss: 0.928664
[2022-06-11 23:44:29 | train] - Train Epoch: [145] [870400/1281167 (68%)]	Loss: 0.754962
[2022-06-11 23:44:51 | train] - Train Epoch: [145] [883200/1281167 (69%)]	Loss: 0.834349
[2022-06-11 23:45:11 | train] - Train Epoch: [145] [896000/1281167 (70%)]	Loss: 0.812587
[2022-06-11 23:45:31 | train] - Train Epoch: [145] [908800/1281167 (71%)]	Loss: 0.690917
[2022-06-11 23:45:51 | train] - Train Epoch: [145] [921600/1281167 (72%)]	Loss: 0.650128
[2022-06-11 23:46:12 | train] - Train Epoch: [145] [934400/1281167 (73%)]	Loss: 0.590273
[2022-06-11 23:46:32 | train] - Train Epoch: [145] [947200/1281167 (74%)]	Loss: 0.704534
[2022-06-11 23:46:53 | train] - Train Epoch: [145] [960000/1281167 (75%)]	Loss: 0.763079
[2022-06-11 23:47:14 | train] - Train Epoch: [145] [972800/1281167 (76%)]	Loss: 0.751445
[2022-06-11 23:47:36 | train] - Train Epoch: [145] [985600/1281167 (77%)]	Loss: 0.742557
[2022-06-11 23:47:56 | train] - Train Epoch: [145] [998400/1281167 (78%)]	Loss: 0.695450
[2022-06-11 23:48:15 | train] - Train Epoch: [145] [1011200/1281167 (79%)]	Loss: 0.762402
[2022-06-11 23:48:37 | train] - Train Epoch: [145] [1024000/1281167 (80%)]	Loss: 0.660706
[2022-06-11 23:48:58 | train] - Train Epoch: [145] [1036800/1281167 (81%)]	Loss: 1.079173
[2022-06-11 23:49:19 | train] - Train Epoch: [145] [1049600/1281167 (82%)]	Loss: 0.665251
[2022-06-11 23:49:40 | train] - Train Epoch: [145] [1062400/1281167 (83%)]	Loss: 0.657155
[2022-06-11 23:50:02 | train] - Train Epoch: [145] [1075200/1281167 (84%)]	Loss: 0.640398
[2022-06-11 23:50:23 | train] - Train Epoch: [145] [1088000/1281167 (85%)]	Loss: 0.777175
[2022-06-11 23:50:45 | train] - Train Epoch: [145] [1100800/1281167 (86%)]	Loss: 0.611618
[2022-06-11 23:51:07 | train] - Train Epoch: [145] [1113600/1281167 (87%)]	Loss: 0.631563
[2022-06-11 23:51:29 | train] - Train Epoch: [145] [1126400/1281167 (88%)]	Loss: 1.137397
[2022-06-11 23:51:50 | train] - Train Epoch: [145] [1139200/1281167 (89%)]	Loss: 0.837593
[2022-06-11 23:52:11 | train] - Train Epoch: [145] [1152000/1281167 (90%)]	Loss: 0.673766
[2022-06-11 23:52:31 | train] - Train Epoch: [145] [1164800/1281167 (91%)]	Loss: 0.864980
[2022-06-11 23:52:52 | train] - Train Epoch: [145] [1177600/1281167 (92%)]	Loss: 0.757519
[2022-06-11 23:53:14 | train] - Train Epoch: [145] [1190400/1281167 (93%)]	Loss: 0.732071
[2022-06-11 23:53:35 | train] - Train Epoch: [145] [1203200/1281167 (94%)]	Loss: 0.620428
[2022-06-11 23:53:56 | train] - Train Epoch: [145] [1216000/1281167 (95%)]	Loss: 0.530104
[2022-06-11 23:54:17 | train] - Train Epoch: [145] [1228800/1281167 (96%)]	Loss: 0.796888
[2022-06-11 23:54:38 | train] - Train Epoch: [145] [1241600/1281167 (97%)]	Loss: 0.623284
[2022-06-11 23:54:59 | train] - Train Epoch: [145] [1254400/1281167 (98%)]	Loss: 0.849791
[2022-06-11 23:55:21 | train] - Train Epoch: [145] [1267200/1281167 (99%)]	Loss: 0.960189
[2022-06-11 23:55:41 | train] - Train Epoch: [145] [1280000/1281167 (100%)]	Loss: 0.846720
[2022-06-11 23:55:43 | train] - Train Epoch: [145]	 Average Loss: 0.735550	 Total Acc : 82.0987	 Total Top5 Acc : 93.4978
[2022-06-11 23:55:43 | train] - -------145 epoch end-----------
========================================
-------145 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-11 23:57:14 | train] - 
Epoch [145] Test set: Average loss: 1.4276, Accuracy: 34971/50000 (69.9157%), Top-5 Accuracy: 88.9634%

[2022-06-11 23:57:14 | train] - save intermediate epoch [145] result


[2022-06-11 23:57:24 | train] - -------146 epoch start-----------
========================================
----- test end -------------------------


[2022-06-11 23:57:26 | train] - Train Epoch: [146] [0/1281167 (0%)]	Loss: 0.766627
[2022-06-11 23:57:47 | train] - Train Epoch: [146] [12800/1281167 (1%)]	Loss: 0.752688
[2022-06-11 23:58:08 | train] - Train Epoch: [146] [25600/1281167 (2%)]	Loss: 0.658388
[2022-06-11 23:58:29 | train] - Train Epoch: [146] [38400/1281167 (3%)]	Loss: 0.717900
[2022-06-11 23:58:51 | train] - Train Epoch: [146] [51200/1281167 (4%)]	Loss: 0.705223
[2022-06-11 23:59:11 | train] - Train Epoch: [146] [64000/1281167 (5%)]	Loss: 0.765692
[2022-06-11 23:59:34 | train] - Train Epoch: [146] [76800/1281167 (6%)]	Loss: 0.828566
[2022-06-11 23:59:56 | train] - Train Epoch: [146] [89600/1281167 (7%)]	Loss: 0.612901
[2022-06-12 00:00:18 | train] - Train Epoch: [146] [102400/1281167 (8%)]	Loss: 0.782729
[2022-06-12 00:00:39 | train] - Train Epoch: [146] [115200/1281167 (9%)]	Loss: 0.820723
[2022-06-12 00:01:00 | train] - Train Epoch: [146] [128000/1281167 (10%)]	Loss: 0.660977
[2022-06-12 00:01:22 | train] - Train Epoch: [146] [140800/1281167 (11%)]	Loss: 0.607487
[2022-06-12 00:01:43 | train] - Train Epoch: [146] [153600/1281167 (12%)]	Loss: 0.675031
[2022-06-12 00:02:05 | train] - Train Epoch: [146] [166400/1281167 (13%)]	Loss: 0.597768
[2022-06-12 00:02:26 | train] - Train Epoch: [146] [179200/1281167 (14%)]	Loss: 0.666640
[2022-06-12 00:02:46 | train] - Train Epoch: [146] [192000/1281167 (15%)]	Loss: 0.834591
[2022-06-12 00:03:07 | train] - Train Epoch: [146] [204800/1281167 (16%)]	Loss: 0.873628
[2022-06-12 00:03:28 | train] - Train Epoch: [146] [217600/1281167 (17%)]	Loss: 0.821939
[2022-06-12 00:03:48 | train] - Train Epoch: [146] [230400/1281167 (18%)]	Loss: 0.727723
[2022-06-12 00:04:10 | train] - Train Epoch: [146] [243200/1281167 (19%)]	Loss: 0.573523
[2022-06-12 00:04:31 | train] - Train Epoch: [146] [256000/1281167 (20%)]	Loss: 0.763250
[2022-06-12 00:04:52 | train] - Train Epoch: [146] [268800/1281167 (21%)]	Loss: 0.816940
[2022-06-12 00:05:13 | train] - Train Epoch: [146] [281600/1281167 (22%)]	Loss: 0.750734
[2022-06-12 00:05:34 | train] - Train Epoch: [146] [294400/1281167 (23%)]	Loss: 0.548703
[2022-06-12 00:05:56 | train] - Train Epoch: [146] [307200/1281167 (24%)]	Loss: 0.544491
[2022-06-12 00:06:17 | train] - Train Epoch: [146] [320000/1281167 (25%)]	Loss: 0.916032
[2022-06-12 00:06:38 | train] - Train Epoch: [146] [332800/1281167 (26%)]	Loss: 0.714132
[2022-06-12 00:06:59 | train] - Train Epoch: [146] [345600/1281167 (27%)]	Loss: 0.656563
[2022-06-12 00:07:20 | train] - Train Epoch: [146] [358400/1281167 (28%)]	Loss: 0.644106
[2022-06-12 00:07:42 | train] - Train Epoch: [146] [371200/1281167 (29%)]	Loss: 0.542833
[2022-06-12 00:08:03 | train] - Train Epoch: [146] [384000/1281167 (30%)]	Loss: 0.644773
[2022-06-12 00:08:25 | train] - Train Epoch: [146] [396800/1281167 (31%)]	Loss: 0.711471
[2022-06-12 00:08:46 | train] - Train Epoch: [146] [409600/1281167 (32%)]	Loss: 0.607934
[2022-06-12 00:09:07 | train] - Train Epoch: [146] [422400/1281167 (33%)]	Loss: 0.744817
[2022-06-12 00:09:28 | train] - Train Epoch: [146] [435200/1281167 (34%)]	Loss: 0.987623
[2022-06-12 00:09:50 | train] - Train Epoch: [146] [448000/1281167 (35%)]	Loss: 0.712490
[2022-06-12 00:10:11 | train] - Train Epoch: [146] [460800/1281167 (36%)]	Loss: 0.743841
[2022-06-12 00:10:33 | train] - Train Epoch: [146] [473600/1281167 (37%)]	Loss: 0.574514
[2022-06-12 00:10:53 | train] - Train Epoch: [146] [486400/1281167 (38%)]	Loss: 0.777861
[2022-06-12 00:11:15 | train] - Train Epoch: [146] [499200/1281167 (39%)]	Loss: 0.596247
[2022-06-12 00:11:36 | train] - Train Epoch: [146] [512000/1281167 (40%)]	Loss: 0.786004
[2022-06-12 00:11:57 | train] - Train Epoch: [146] [524800/1281167 (41%)]	Loss: 0.721916
[2022-06-12 00:12:17 | train] - Train Epoch: [146] [537600/1281167 (42%)]	Loss: 0.630996
[2022-06-12 00:12:38 | train] - Train Epoch: [146] [550400/1281167 (43%)]	Loss: 1.001650
[2022-06-12 00:12:59 | train] - Train Epoch: [146] [563200/1281167 (44%)]	Loss: 0.788849
[2022-06-12 00:13:20 | train] - Train Epoch: [146] [576000/1281167 (45%)]	Loss: 0.844224
[2022-06-12 00:13:42 | train] - Train Epoch: [146] [588800/1281167 (46%)]	Loss: 0.476272
[2022-06-12 00:14:03 | train] - Train Epoch: [146] [601600/1281167 (47%)]	Loss: 0.654447
[2022-06-12 00:14:24 | train] - Train Epoch: [146] [614400/1281167 (48%)]	Loss: 0.516034
[2022-06-12 00:14:44 | train] - Train Epoch: [146] [627200/1281167 (49%)]	Loss: 0.696603
[2022-06-12 00:15:04 | train] - Train Epoch: [146] [640000/1281167 (50%)]	Loss: 0.702890
[2022-06-12 00:15:25 | train] - Train Epoch: [146] [652800/1281167 (51%)]	Loss: 0.544264
[2022-06-12 00:15:45 | train] - Train Epoch: [146] [665600/1281167 (52%)]	Loss: 0.560402
[2022-06-12 00:16:06 | train] - Train Epoch: [146] [678400/1281167 (53%)]	Loss: 0.695966
[2022-06-12 00:16:27 | train] - Train Epoch: [146] [691200/1281167 (54%)]	Loss: 0.691648
[2022-06-12 00:16:48 | train] - Train Epoch: [146] [704000/1281167 (55%)]	Loss: 0.683001
[2022-06-12 00:17:10 | train] - Train Epoch: [146] [716800/1281167 (56%)]	Loss: 0.891800
[2022-06-12 00:17:30 | train] - Train Epoch: [146] [729600/1281167 (57%)]	Loss: 0.851398
[2022-06-12 00:17:51 | train] - Train Epoch: [146] [742400/1281167 (58%)]	Loss: 0.810132
[2022-06-12 00:18:11 | train] - Train Epoch: [146] [755200/1281167 (59%)]	Loss: 0.732598
[2022-06-12 00:18:33 | train] - Train Epoch: [146] [768000/1281167 (60%)]	Loss: 0.793883
[2022-06-12 00:18:53 | train] - Train Epoch: [146] [780800/1281167 (61%)]	Loss: 0.787434
[2022-06-12 00:19:15 | train] - Train Epoch: [146] [793600/1281167 (62%)]	Loss: 0.703157
[2022-06-12 00:19:37 | train] - Train Epoch: [146] [806400/1281167 (63%)]	Loss: 0.958059
[2022-06-12 00:19:58 | train] - Train Epoch: [146] [819200/1281167 (64%)]	Loss: 0.639112
[2022-06-12 00:20:19 | train] - Train Epoch: [146] [832000/1281167 (65%)]	Loss: 1.202310
[2022-06-12 00:20:40 | train] - Train Epoch: [146] [844800/1281167 (66%)]	Loss: 0.683338
[2022-06-12 00:21:01 | train] - Train Epoch: [146] [857600/1281167 (67%)]	Loss: 0.988522
[2022-06-12 00:21:21 | train] - Train Epoch: [146] [870400/1281167 (68%)]	Loss: 0.841622
[2022-06-12 00:21:41 | train] - Train Epoch: [146] [883200/1281167 (69%)]	Loss: 0.732900
[2022-06-12 00:22:01 | train] - Train Epoch: [146] [896000/1281167 (70%)]	Loss: 0.790239
[2022-06-12 00:22:22 | train] - Train Epoch: [146] [908800/1281167 (71%)]	Loss: 1.113201
[2022-06-12 00:22:43 | train] - Train Epoch: [146] [921600/1281167 (72%)]	Loss: 0.730206
[2022-06-12 00:23:05 | train] - Train Epoch: [146] [934400/1281167 (73%)]	Loss: 0.888046
[2022-06-12 00:23:26 | train] - Train Epoch: [146] [947200/1281167 (74%)]	Loss: 0.737111
[2022-06-12 00:23:46 | train] - Train Epoch: [146] [960000/1281167 (75%)]	Loss: 0.711585
[2022-06-12 00:24:07 | train] - Train Epoch: [146] [972800/1281167 (76%)]	Loss: 0.607706
[2022-06-12 00:24:28 | train] - Train Epoch: [146] [985600/1281167 (77%)]	Loss: 0.626455
[2022-06-12 00:24:48 | train] - Train Epoch: [146] [998400/1281167 (78%)]	Loss: 0.958791
[2022-06-12 00:25:10 | train] - Train Epoch: [146] [1011200/1281167 (79%)]	Loss: 0.650211
[2022-06-12 00:25:32 | train] - Train Epoch: [146] [1024000/1281167 (80%)]	Loss: 0.926995
[2022-06-12 00:25:54 | train] - Train Epoch: [146] [1036800/1281167 (81%)]	Loss: 0.656717
[2022-06-12 00:26:15 | train] - Train Epoch: [146] [1049600/1281167 (82%)]	Loss: 0.546685
[2022-06-12 00:26:36 | train] - Train Epoch: [146] [1062400/1281167 (83%)]	Loss: 0.698717
[2022-06-12 00:26:58 | train] - Train Epoch: [146] [1075200/1281167 (84%)]	Loss: 0.766283
[2022-06-12 00:27:20 | train] - Train Epoch: [146] [1088000/1281167 (85%)]	Loss: 0.676593
[2022-06-12 00:27:40 | train] - Train Epoch: [146] [1100800/1281167 (86%)]	Loss: 0.578493
[2022-06-12 00:28:01 | train] - Train Epoch: [146] [1113600/1281167 (87%)]	Loss: 0.746376
[2022-06-12 00:28:23 | train] - Train Epoch: [146] [1126400/1281167 (88%)]	Loss: 0.706248
[2022-06-12 00:28:45 | train] - Train Epoch: [146] [1139200/1281167 (89%)]	Loss: 0.728619
[2022-06-12 00:29:07 | train] - Train Epoch: [146] [1152000/1281167 (90%)]	Loss: 0.856764
[2022-06-12 00:29:28 | train] - Train Epoch: [146] [1164800/1281167 (91%)]	Loss: 0.895950
[2022-06-12 00:29:49 | train] - Train Epoch: [146] [1177600/1281167 (92%)]	Loss: 0.808127
[2022-06-12 00:30:11 | train] - Train Epoch: [146] [1190400/1281167 (93%)]	Loss: 0.914948
[2022-06-12 00:30:32 | train] - Train Epoch: [146] [1203200/1281167 (94%)]	Loss: 0.901431
[2022-06-12 00:30:52 | train] - Train Epoch: [146] [1216000/1281167 (95%)]	Loss: 0.665202
[2022-06-12 00:31:13 | train] - Train Epoch: [146] [1228800/1281167 (96%)]	Loss: 0.822086
[2022-06-12 00:31:34 | train] - Train Epoch: [146] [1241600/1281167 (97%)]	Loss: 0.657043
[2022-06-12 00:31:54 | train] - Train Epoch: [146] [1254400/1281167 (98%)]	Loss: 0.647729
[2022-06-12 00:32:15 | train] - Train Epoch: [146] [1267200/1281167 (99%)]	Loss: 0.768230
[2022-06-12 00:32:36 | train] - Train Epoch: [146] [1280000/1281167 (100%)]	Loss: 0.577315
[2022-06-12 00:32:37 | train] - Train Epoch: [146]	 Average Loss: 0.731551	 Total Acc : 82.1895	 Total Top5 Acc : 93.5482
[2022-06-12 00:32:37 | train] - -------146 epoch end-----------
========================================
-------146 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 00:34:08 | train] - 
Epoch [146] Test set: Average loss: 1.4234, Accuracy: 35003/50000 (69.9772%), Top-5 Accuracy: 88.9502%

[2022-06-12 00:34:08 | train] - save intermediate epoch [146] result


[2022-06-12 00:34:18 | train] - -------147 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 00:34:20 | train] - Train Epoch: [147] [0/1281167 (0%)]	Loss: 0.768582
[2022-06-12 00:34:41 | train] - Train Epoch: [147] [12800/1281167 (1%)]	Loss: 0.701707
[2022-06-12 00:35:01 | train] - Train Epoch: [147] [25600/1281167 (2%)]	Loss: 0.785575
[2022-06-12 00:35:21 | train] - Train Epoch: [147] [38400/1281167 (3%)]	Loss: 0.710737
[2022-06-12 00:35:41 | train] - Train Epoch: [147] [51200/1281167 (4%)]	Loss: 0.872218
[2022-06-12 00:36:02 | train] - Train Epoch: [147] [64000/1281167 (5%)]	Loss: 0.874716
[2022-06-12 00:36:21 | train] - Train Epoch: [147] [76800/1281167 (6%)]	Loss: 0.912457
[2022-06-12 00:36:42 | train] - Train Epoch: [147] [89600/1281167 (7%)]	Loss: 0.772392
[2022-06-12 00:37:02 | train] - Train Epoch: [147] [102400/1281167 (8%)]	Loss: 0.538939
[2022-06-12 00:37:22 | train] - Train Epoch: [147] [115200/1281167 (9%)]	Loss: 0.600778
[2022-06-12 00:37:42 | train] - Train Epoch: [147] [128000/1281167 (10%)]	Loss: 0.738939
[2022-06-12 00:38:02 | train] - Train Epoch: [147] [140800/1281167 (11%)]	Loss: 0.765605
[2022-06-12 00:38:22 | train] - Train Epoch: [147] [153600/1281167 (12%)]	Loss: 0.771917
[2022-06-12 00:38:42 | train] - Train Epoch: [147] [166400/1281167 (13%)]	Loss: 0.856296
[2022-06-12 00:39:03 | train] - Train Epoch: [147] [179200/1281167 (14%)]	Loss: 0.489229
[2022-06-12 00:39:23 | train] - Train Epoch: [147] [192000/1281167 (15%)]	Loss: 0.843286
[2022-06-12 00:39:44 | train] - Train Epoch: [147] [204800/1281167 (16%)]	Loss: 0.757426
[2022-06-12 00:40:05 | train] - Train Epoch: [147] [217600/1281167 (17%)]	Loss: 0.698505
[2022-06-12 00:40:26 | train] - Train Epoch: [147] [230400/1281167 (18%)]	Loss: 0.953446
[2022-06-12 00:40:45 | train] - Train Epoch: [147] [243200/1281167 (19%)]	Loss: 0.663925
[2022-06-12 00:41:04 | train] - Train Epoch: [147] [256000/1281167 (20%)]	Loss: 0.661819
[2022-06-12 00:41:24 | train] - Train Epoch: [147] [268800/1281167 (21%)]	Loss: 0.659284
[2022-06-12 00:41:43 | train] - Train Epoch: [147] [281600/1281167 (22%)]	Loss: 0.965040
[2022-06-12 00:42:03 | train] - Train Epoch: [147] [294400/1281167 (23%)]	Loss: 0.782138
[2022-06-12 00:42:22 | train] - Train Epoch: [147] [307200/1281167 (24%)]	Loss: 0.870907
[2022-06-12 00:42:41 | train] - Train Epoch: [147] [320000/1281167 (25%)]	Loss: 0.786126
[2022-06-12 00:43:01 | train] - Train Epoch: [147] [332800/1281167 (26%)]	Loss: 0.821049
[2022-06-12 00:43:21 | train] - Train Epoch: [147] [345600/1281167 (27%)]	Loss: 0.765867
[2022-06-12 00:43:40 | train] - Train Epoch: [147] [358400/1281167 (28%)]	Loss: 0.577619
[2022-06-12 00:44:00 | train] - Train Epoch: [147] [371200/1281167 (29%)]	Loss: 0.997330
[2022-06-12 00:44:19 | train] - Train Epoch: [147] [384000/1281167 (30%)]	Loss: 0.581504
[2022-06-12 00:44:38 | train] - Train Epoch: [147] [396800/1281167 (31%)]	Loss: 0.549391
[2022-06-12 00:44:58 | train] - Train Epoch: [147] [409600/1281167 (32%)]	Loss: 0.658553
[2022-06-12 00:45:17 | train] - Train Epoch: [147] [422400/1281167 (33%)]	Loss: 0.473901
[2022-06-12 00:45:37 | train] - Train Epoch: [147] [435200/1281167 (34%)]	Loss: 0.530769
[2022-06-12 00:45:56 | train] - Train Epoch: [147] [448000/1281167 (35%)]	Loss: 0.677771
[2022-06-12 00:46:15 | train] - Train Epoch: [147] [460800/1281167 (36%)]	Loss: 0.565872
[2022-06-12 00:46:34 | train] - Train Epoch: [147] [473600/1281167 (37%)]	Loss: 0.684611
[2022-06-12 00:46:54 | train] - Train Epoch: [147] [486400/1281167 (38%)]	Loss: 0.652772
[2022-06-12 00:47:13 | train] - Train Epoch: [147] [499200/1281167 (39%)]	Loss: 0.817289
[2022-06-12 00:47:32 | train] - Train Epoch: [147] [512000/1281167 (40%)]	Loss: 0.680056
[2022-06-12 00:47:51 | train] - Train Epoch: [147] [524800/1281167 (41%)]	Loss: 0.907854
[2022-06-12 00:48:11 | train] - Train Epoch: [147] [537600/1281167 (42%)]	Loss: 0.964723
[2022-06-12 00:48:30 | train] - Train Epoch: [147] [550400/1281167 (43%)]	Loss: 0.950856
[2022-06-12 00:48:49 | train] - Train Epoch: [147] [563200/1281167 (44%)]	Loss: 0.792648
[2022-06-12 00:49:08 | train] - Train Epoch: [147] [576000/1281167 (45%)]	Loss: 0.786599
[2022-06-12 00:49:29 | train] - Train Epoch: [147] [588800/1281167 (46%)]	Loss: 0.541299
[2022-06-12 00:49:48 | train] - Train Epoch: [147] [601600/1281167 (47%)]	Loss: 0.766081
[2022-06-12 00:50:08 | train] - Train Epoch: [147] [614400/1281167 (48%)]	Loss: 0.621202
[2022-06-12 00:50:29 | train] - Train Epoch: [147] [627200/1281167 (49%)]	Loss: 0.797791
[2022-06-12 00:50:49 | train] - Train Epoch: [147] [640000/1281167 (50%)]	Loss: 0.590285
[2022-06-12 00:51:09 | train] - Train Epoch: [147] [652800/1281167 (51%)]	Loss: 0.976966
[2022-06-12 00:51:29 | train] - Train Epoch: [147] [665600/1281167 (52%)]	Loss: 0.692758
[2022-06-12 00:51:50 | train] - Train Epoch: [147] [678400/1281167 (53%)]	Loss: 0.693001
[2022-06-12 00:52:10 | train] - Train Epoch: [147] [691200/1281167 (54%)]	Loss: 0.704471
[2022-06-12 00:52:31 | train] - Train Epoch: [147] [704000/1281167 (55%)]	Loss: 0.539441
[2022-06-12 00:52:51 | train] - Train Epoch: [147] [716800/1281167 (56%)]	Loss: 0.523689
[2022-06-12 00:53:12 | train] - Train Epoch: [147] [729600/1281167 (57%)]	Loss: 0.574599
[2022-06-12 00:53:32 | train] - Train Epoch: [147] [742400/1281167 (58%)]	Loss: 0.710389
[2022-06-12 00:53:53 | train] - Train Epoch: [147] [755200/1281167 (59%)]	Loss: 0.558348
[2022-06-12 00:54:14 | train] - Train Epoch: [147] [768000/1281167 (60%)]	Loss: 0.593070
[2022-06-12 00:54:34 | train] - Train Epoch: [147] [780800/1281167 (61%)]	Loss: 0.757455
[2022-06-12 00:54:55 | train] - Train Epoch: [147] [793600/1281167 (62%)]	Loss: 0.804175
[2022-06-12 00:55:15 | train] - Train Epoch: [147] [806400/1281167 (63%)]	Loss: 0.773992
[2022-06-12 00:55:36 | train] - Train Epoch: [147] [819200/1281167 (64%)]	Loss: 0.784688
[2022-06-12 00:55:56 | train] - Train Epoch: [147] [832000/1281167 (65%)]	Loss: 0.775887
[2022-06-12 00:56:16 | train] - Train Epoch: [147] [844800/1281167 (66%)]	Loss: 0.711621
[2022-06-12 00:56:37 | train] - Train Epoch: [147] [857600/1281167 (67%)]	Loss: 0.660075
[2022-06-12 00:56:57 | train] - Train Epoch: [147] [870400/1281167 (68%)]	Loss: 0.791004
[2022-06-12 00:57:17 | train] - Train Epoch: [147] [883200/1281167 (69%)]	Loss: 0.701629
[2022-06-12 00:57:37 | train] - Train Epoch: [147] [896000/1281167 (70%)]	Loss: 0.704836
[2022-06-12 00:57:58 | train] - Train Epoch: [147] [908800/1281167 (71%)]	Loss: 0.762617
[2022-06-12 00:58:18 | train] - Train Epoch: [147] [921600/1281167 (72%)]	Loss: 0.779704
[2022-06-12 00:58:39 | train] - Train Epoch: [147] [934400/1281167 (73%)]	Loss: 0.791143
[2022-06-12 00:58:59 | train] - Train Epoch: [147] [947200/1281167 (74%)]	Loss: 0.666880
[2022-06-12 00:59:19 | train] - Train Epoch: [147] [960000/1281167 (75%)]	Loss: 0.824716
[2022-06-12 00:59:40 | train] - Train Epoch: [147] [972800/1281167 (76%)]	Loss: 0.759896
[2022-06-12 01:00:00 | train] - Train Epoch: [147] [985600/1281167 (77%)]	Loss: 0.619920
[2022-06-12 01:00:21 | train] - Train Epoch: [147] [998400/1281167 (78%)]	Loss: 0.891794
[2022-06-12 01:00:42 | train] - Train Epoch: [147] [1011200/1281167 (79%)]	Loss: 0.847817
[2022-06-12 01:01:01 | train] - Train Epoch: [147] [1024000/1281167 (80%)]	Loss: 0.865533
[2022-06-12 01:01:21 | train] - Train Epoch: [147] [1036800/1281167 (81%)]	Loss: 0.930880
[2022-06-12 01:01:41 | train] - Train Epoch: [147] [1049600/1281167 (82%)]	Loss: 0.588511
[2022-06-12 01:02:02 | train] - Train Epoch: [147] [1062400/1281167 (83%)]	Loss: 1.016770
[2022-06-12 01:02:23 | train] - Train Epoch: [147] [1075200/1281167 (84%)]	Loss: 0.823658
[2022-06-12 01:02:42 | train] - Train Epoch: [147] [1088000/1281167 (85%)]	Loss: 0.655411
[2022-06-12 01:03:03 | train] - Train Epoch: [147] [1100800/1281167 (86%)]	Loss: 0.831892
[2022-06-12 01:03:23 | train] - Train Epoch: [147] [1113600/1281167 (87%)]	Loss: 0.754955
[2022-06-12 01:03:44 | train] - Train Epoch: [147] [1126400/1281167 (88%)]	Loss: 0.802191
[2022-06-12 01:04:04 | train] - Train Epoch: [147] [1139200/1281167 (89%)]	Loss: 0.680667
[2022-06-12 01:04:24 | train] - Train Epoch: [147] [1152000/1281167 (90%)]	Loss: 0.574109
[2022-06-12 01:04:45 | train] - Train Epoch: [147] [1164800/1281167 (91%)]	Loss: 0.812756
[2022-06-12 01:05:06 | train] - Train Epoch: [147] [1177600/1281167 (92%)]	Loss: 1.050877
[2022-06-12 01:05:25 | train] - Train Epoch: [147] [1190400/1281167 (93%)]	Loss: 0.529964
[2022-06-12 01:05:46 | train] - Train Epoch: [147] [1203200/1281167 (94%)]	Loss: 0.687727
[2022-06-12 01:06:06 | train] - Train Epoch: [147] [1216000/1281167 (95%)]	Loss: 0.425017
[2022-06-12 01:06:26 | train] - Train Epoch: [147] [1228800/1281167 (96%)]	Loss: 0.900173
[2022-06-12 01:06:46 | train] - Train Epoch: [147] [1241600/1281167 (97%)]	Loss: 0.629202
[2022-06-12 01:07:05 | train] - Train Epoch: [147] [1254400/1281167 (98%)]	Loss: 0.895576
[2022-06-12 01:07:26 | train] - Train Epoch: [147] [1267200/1281167 (99%)]	Loss: 0.744847
[2022-06-12 01:07:45 | train] - Train Epoch: [147] [1280000/1281167 (100%)]	Loss: 0.857527
[2022-06-12 01:07:47 | train] - Train Epoch: [147]	 Average Loss: 0.730919	 Total Acc : 82.1919	 Total Top5 Acc : 93.5454
[2022-06-12 01:07:47 | train] - -------147 epoch end-----------
========================================
-------147 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 01:09:20 | train] - 
Epoch [147] Test set: Average loss: 1.4221, Accuracy: 34991/50000 (69.9568%), Top-5 Accuracy: 88.9146%

[2022-06-12 01:09:20 | train] - save intermediate epoch [147] result


[2022-06-12 01:09:31 | train] - -------148 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 01:09:33 | train] - Train Epoch: [148] [0/1281167 (0%)]	Loss: 0.623678
[2022-06-12 01:09:53 | train] - Train Epoch: [148] [12800/1281167 (1%)]	Loss: 0.592884
[2022-06-12 01:10:14 | train] - Train Epoch: [148] [25600/1281167 (2%)]	Loss: 0.674288
[2022-06-12 01:10:35 | train] - Train Epoch: [148] [38400/1281167 (3%)]	Loss: 0.634954
[2022-06-12 01:10:57 | train] - Train Epoch: [148] [51200/1281167 (4%)]	Loss: 0.683288
[2022-06-12 01:11:17 | train] - Train Epoch: [148] [64000/1281167 (5%)]	Loss: 0.689748
[2022-06-12 01:11:38 | train] - Train Epoch: [148] [76800/1281167 (6%)]	Loss: 0.738031
[2022-06-12 01:11:59 | train] - Train Epoch: [148] [89600/1281167 (7%)]	Loss: 0.678417
[2022-06-12 01:12:20 | train] - Train Epoch: [148] [102400/1281167 (8%)]	Loss: 0.855865
[2022-06-12 01:12:42 | train] - Train Epoch: [148] [115200/1281167 (9%)]	Loss: 0.767995
[2022-06-12 01:13:03 | train] - Train Epoch: [148] [128000/1281167 (10%)]	Loss: 0.952612
[2022-06-12 01:13:25 | train] - Train Epoch: [148] [140800/1281167 (11%)]	Loss: 0.693473
[2022-06-12 01:13:46 | train] - Train Epoch: [148] [153600/1281167 (12%)]	Loss: 0.641189
[2022-06-12 01:14:08 | train] - Train Epoch: [148] [166400/1281167 (13%)]	Loss: 0.579310
[2022-06-12 01:14:29 | train] - Train Epoch: [148] [179200/1281167 (14%)]	Loss: 0.696022
[2022-06-12 01:14:50 | train] - Train Epoch: [148] [192000/1281167 (15%)]	Loss: 0.640813
[2022-06-12 01:15:11 | train] - Train Epoch: [148] [204800/1281167 (16%)]	Loss: 0.885609
[2022-06-12 01:15:32 | train] - Train Epoch: [148] [217600/1281167 (17%)]	Loss: 0.790346
[2022-06-12 01:15:53 | train] - Train Epoch: [148] [230400/1281167 (18%)]	Loss: 0.785721
[2022-06-12 01:16:14 | train] - Train Epoch: [148] [243200/1281167 (19%)]	Loss: 0.840413
[2022-06-12 01:16:34 | train] - Train Epoch: [148] [256000/1281167 (20%)]	Loss: 0.697503
[2022-06-12 01:16:55 | train] - Train Epoch: [148] [268800/1281167 (21%)]	Loss: 0.538843
[2022-06-12 01:17:16 | train] - Train Epoch: [148] [281600/1281167 (22%)]	Loss: 0.560032
[2022-06-12 01:17:38 | train] - Train Epoch: [148] [294400/1281167 (23%)]	Loss: 0.848016
[2022-06-12 01:17:58 | train] - Train Epoch: [148] [307200/1281167 (24%)]	Loss: 0.748366
[2022-06-12 01:18:20 | train] - Train Epoch: [148] [320000/1281167 (25%)]	Loss: 0.821840
[2022-06-12 01:18:42 | train] - Train Epoch: [148] [332800/1281167 (26%)]	Loss: 0.734195
[2022-06-12 01:19:03 | train] - Train Epoch: [148] [345600/1281167 (27%)]	Loss: 0.607556
[2022-06-12 01:19:23 | train] - Train Epoch: [148] [358400/1281167 (28%)]	Loss: 0.726829
[2022-06-12 01:19:44 | train] - Train Epoch: [148] [371200/1281167 (29%)]	Loss: 0.651297
[2022-06-12 01:20:05 | train] - Train Epoch: [148] [384000/1281167 (30%)]	Loss: 0.781062
[2022-06-12 01:20:26 | train] - Train Epoch: [148] [396800/1281167 (31%)]	Loss: 0.783451
[2022-06-12 01:20:47 | train] - Train Epoch: [148] [409600/1281167 (32%)]	Loss: 0.643181
[2022-06-12 01:21:08 | train] - Train Epoch: [148] [422400/1281167 (33%)]	Loss: 0.663137
[2022-06-12 01:21:28 | train] - Train Epoch: [148] [435200/1281167 (34%)]	Loss: 0.698814
[2022-06-12 01:21:48 | train] - Train Epoch: [148] [448000/1281167 (35%)]	Loss: 0.679877
[2022-06-12 01:22:09 | train] - Train Epoch: [148] [460800/1281167 (36%)]	Loss: 0.852196
[2022-06-12 01:22:30 | train] - Train Epoch: [148] [473600/1281167 (37%)]	Loss: 0.892323
[2022-06-12 01:22:51 | train] - Train Epoch: [148] [486400/1281167 (38%)]	Loss: 0.938305
[2022-06-12 01:23:12 | train] - Train Epoch: [148] [499200/1281167 (39%)]	Loss: 0.800582
[2022-06-12 01:23:33 | train] - Train Epoch: [148] [512000/1281167 (40%)]	Loss: 0.853076
[2022-06-12 01:23:55 | train] - Train Epoch: [148] [524800/1281167 (41%)]	Loss: 0.568242
[2022-06-12 01:24:17 | train] - Train Epoch: [148] [537600/1281167 (42%)]	Loss: 0.832372
[2022-06-12 01:24:38 | train] - Train Epoch: [148] [550400/1281167 (43%)]	Loss: 0.750810
[2022-06-12 01:24:59 | train] - Train Epoch: [148] [563200/1281167 (44%)]	Loss: 0.713673
[2022-06-12 01:25:19 | train] - Train Epoch: [148] [576000/1281167 (45%)]	Loss: 0.541310
[2022-06-12 01:25:39 | train] - Train Epoch: [148] [588800/1281167 (46%)]	Loss: 0.858992
[2022-06-12 01:26:00 | train] - Train Epoch: [148] [601600/1281167 (47%)]	Loss: 0.672920
[2022-06-12 01:26:21 | train] - Train Epoch: [148] [614400/1281167 (48%)]	Loss: 0.629835
[2022-06-12 01:26:41 | train] - Train Epoch: [148] [627200/1281167 (49%)]	Loss: 0.847823
[2022-06-12 01:27:02 | train] - Train Epoch: [148] [640000/1281167 (50%)]	Loss: 0.605613
[2022-06-12 01:27:22 | train] - Train Epoch: [148] [652800/1281167 (51%)]	Loss: 0.469792
[2022-06-12 01:27:42 | train] - Train Epoch: [148] [665600/1281167 (52%)]	Loss: 0.804013
[2022-06-12 01:28:04 | train] - Train Epoch: [148] [678400/1281167 (53%)]	Loss: 0.764096
[2022-06-12 01:28:25 | train] - Train Epoch: [148] [691200/1281167 (54%)]	Loss: 0.475746
[2022-06-12 01:28:45 | train] - Train Epoch: [148] [704000/1281167 (55%)]	Loss: 0.634991
[2022-06-12 01:29:06 | train] - Train Epoch: [148] [716800/1281167 (56%)]	Loss: 0.778842
[2022-06-12 01:29:26 | train] - Train Epoch: [148] [729600/1281167 (57%)]	Loss: 0.632674
[2022-06-12 01:29:47 | train] - Train Epoch: [148] [742400/1281167 (58%)]	Loss: 0.744870
[2022-06-12 01:30:08 | train] - Train Epoch: [148] [755200/1281167 (59%)]	Loss: 0.736255
[2022-06-12 01:30:28 | train] - Train Epoch: [148] [768000/1281167 (60%)]	Loss: 0.829549
[2022-06-12 01:30:49 | train] - Train Epoch: [148] [780800/1281167 (61%)]	Loss: 0.744233
[2022-06-12 01:31:09 | train] - Train Epoch: [148] [793600/1281167 (62%)]	Loss: 0.765275
[2022-06-12 01:31:31 | train] - Train Epoch: [148] [806400/1281167 (63%)]	Loss: 0.902738
[2022-06-12 01:31:51 | train] - Train Epoch: [148] [819200/1281167 (64%)]	Loss: 0.598617
[2022-06-12 01:32:12 | train] - Train Epoch: [148] [832000/1281167 (65%)]	Loss: 0.873730
[2022-06-12 01:32:34 | train] - Train Epoch: [148] [844800/1281167 (66%)]	Loss: 0.679694
[2022-06-12 01:32:55 | train] - Train Epoch: [148] [857600/1281167 (67%)]	Loss: 0.771729
[2022-06-12 01:33:16 | train] - Train Epoch: [148] [870400/1281167 (68%)]	Loss: 0.616157
[2022-06-12 01:33:36 | train] - Train Epoch: [148] [883200/1281167 (69%)]	Loss: 0.804344
[2022-06-12 01:33:58 | train] - Train Epoch: [148] [896000/1281167 (70%)]	Loss: 0.568166
[2022-06-12 01:34:18 | train] - Train Epoch: [148] [908800/1281167 (71%)]	Loss: 0.457330
[2022-06-12 01:34:38 | train] - Train Epoch: [148] [921600/1281167 (72%)]	Loss: 0.562283
[2022-06-12 01:34:59 | train] - Train Epoch: [148] [934400/1281167 (73%)]	Loss: 0.651115
[2022-06-12 01:35:20 | train] - Train Epoch: [148] [947200/1281167 (74%)]	Loss: 0.589047
[2022-06-12 01:35:41 | train] - Train Epoch: [148] [960000/1281167 (75%)]	Loss: 0.829468
[2022-06-12 01:36:03 | train] - Train Epoch: [148] [972800/1281167 (76%)]	Loss: 0.902305
[2022-06-12 01:36:24 | train] - Train Epoch: [148] [985600/1281167 (77%)]	Loss: 0.965385
[2022-06-12 01:36:45 | train] - Train Epoch: [148] [998400/1281167 (78%)]	Loss: 0.795198
[2022-06-12 01:37:06 | train] - Train Epoch: [148] [1011200/1281167 (79%)]	Loss: 0.971780
[2022-06-12 01:37:28 | train] - Train Epoch: [148] [1024000/1281167 (80%)]	Loss: 0.795035
[2022-06-12 01:37:49 | train] - Train Epoch: [148] [1036800/1281167 (81%)]	Loss: 0.768619
[2022-06-12 01:38:07 | train] - Train Epoch: [148] [1049600/1281167 (82%)]	Loss: 0.661886
[2022-06-12 01:38:27 | train] - Train Epoch: [148] [1062400/1281167 (83%)]	Loss: 0.651767
[2022-06-12 01:38:47 | train] - Train Epoch: [148] [1075200/1281167 (84%)]	Loss: 0.667695
[2022-06-12 01:39:08 | train] - Train Epoch: [148] [1088000/1281167 (85%)]	Loss: 0.742093
[2022-06-12 01:39:29 | train] - Train Epoch: [148] [1100800/1281167 (86%)]	Loss: 0.597744
[2022-06-12 01:39:50 | train] - Train Epoch: [148] [1113600/1281167 (87%)]	Loss: 0.730719
[2022-06-12 01:40:12 | train] - Train Epoch: [148] [1126400/1281167 (88%)]	Loss: 0.689268
[2022-06-12 01:40:33 | train] - Train Epoch: [148] [1139200/1281167 (89%)]	Loss: 0.860100
[2022-06-12 01:40:55 | train] - Train Epoch: [148] [1152000/1281167 (90%)]	Loss: 0.705222
[2022-06-12 01:41:17 | train] - Train Epoch: [148] [1164800/1281167 (91%)]	Loss: 0.647784
[2022-06-12 01:41:38 | train] - Train Epoch: [148] [1177600/1281167 (92%)]	Loss: 0.637213
[2022-06-12 01:41:59 | train] - Train Epoch: [148] [1190400/1281167 (93%)]	Loss: 0.709235
[2022-06-12 01:42:20 | train] - Train Epoch: [148] [1203200/1281167 (94%)]	Loss: 0.659216
[2022-06-12 01:42:42 | train] - Train Epoch: [148] [1216000/1281167 (95%)]	Loss: 0.592143
[2022-06-12 01:43:03 | train] - Train Epoch: [148] [1228800/1281167 (96%)]	Loss: 0.490951
[2022-06-12 01:43:24 | train] - Train Epoch: [148] [1241600/1281167 (97%)]	Loss: 0.582245
[2022-06-12 01:43:45 | train] - Train Epoch: [148] [1254400/1281167 (98%)]	Loss: 0.582672
[2022-06-12 01:44:06 | train] - Train Epoch: [148] [1267200/1281167 (99%)]	Loss: 0.641309
[2022-06-12 01:44:27 | train] - Train Epoch: [148] [1280000/1281167 (100%)]	Loss: 0.477214
[2022-06-12 01:44:29 | train] - Train Epoch: [148]	 Average Loss: 0.727362	 Total Acc : 82.2698	 Total Top5 Acc : 93.6236
[2022-06-12 01:44:29 | train] - -------148 epoch end-----------
========================================
-------148 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 01:46:02 | train] - 
Epoch [148] Test set: Average loss: 1.4159, Accuracy: 34979/50000 (69.9293%), Top-5 Accuracy: 88.9886%

[2022-06-12 01:46:02 | train] - save intermediate epoch [148] result


[2022-06-12 01:46:13 | train] - -------149 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 01:46:15 | train] - Train Epoch: [149] [0/1281167 (0%)]	Loss: 0.761017
[2022-06-12 01:46:36 | train] - Train Epoch: [149] [12800/1281167 (1%)]	Loss: 0.707382
[2022-06-12 01:46:57 | train] - Train Epoch: [149] [25600/1281167 (2%)]	Loss: 0.564452
[2022-06-12 01:47:18 | train] - Train Epoch: [149] [38400/1281167 (3%)]	Loss: 0.824626
[2022-06-12 01:47:40 | train] - Train Epoch: [149] [51200/1281167 (4%)]	Loss: 0.412905
[2022-06-12 01:48:01 | train] - Train Epoch: [149] [64000/1281167 (5%)]	Loss: 0.711441
[2022-06-12 01:48:22 | train] - Train Epoch: [149] [76800/1281167 (6%)]	Loss: 0.912749
[2022-06-12 01:48:42 | train] - Train Epoch: [149] [89600/1281167 (7%)]	Loss: 0.561385
[2022-06-12 01:49:01 | train] - Train Epoch: [149] [102400/1281167 (8%)]	Loss: 0.653334
[2022-06-12 01:49:21 | train] - Train Epoch: [149] [115200/1281167 (9%)]	Loss: 0.438533
[2022-06-12 01:49:40 | train] - Train Epoch: [149] [128000/1281167 (10%)]	Loss: 0.570315
[2022-06-12 01:50:00 | train] - Train Epoch: [149] [140800/1281167 (11%)]	Loss: 0.756549
[2022-06-12 01:50:20 | train] - Train Epoch: [149] [153600/1281167 (12%)]	Loss: 0.792222
[2022-06-12 01:50:39 | train] - Train Epoch: [149] [166400/1281167 (13%)]	Loss: 0.706712
[2022-06-12 01:50:58 | train] - Train Epoch: [149] [179200/1281167 (14%)]	Loss: 0.747910
[2022-06-12 01:51:17 | train] - Train Epoch: [149] [192000/1281167 (15%)]	Loss: 0.674777
[2022-06-12 01:51:37 | train] - Train Epoch: [149] [204800/1281167 (16%)]	Loss: 0.884544
[2022-06-12 01:51:56 | train] - Train Epoch: [149] [217600/1281167 (17%)]	Loss: 0.970474
[2022-06-12 01:52:16 | train] - Train Epoch: [149] [230400/1281167 (18%)]	Loss: 0.624377
[2022-06-12 01:52:37 | train] - Train Epoch: [149] [243200/1281167 (19%)]	Loss: 0.814554
[2022-06-12 01:52:57 | train] - Train Epoch: [149] [256000/1281167 (20%)]	Loss: 0.963855
[2022-06-12 01:53:17 | train] - Train Epoch: [149] [268800/1281167 (21%)]	Loss: 0.777209
[2022-06-12 01:53:37 | train] - Train Epoch: [149] [281600/1281167 (22%)]	Loss: 0.666826
[2022-06-12 01:53:57 | train] - Train Epoch: [149] [294400/1281167 (23%)]	Loss: 0.597515
[2022-06-12 01:54:17 | train] - Train Epoch: [149] [307200/1281167 (24%)]	Loss: 0.790497
[2022-06-12 01:54:37 | train] - Train Epoch: [149] [320000/1281167 (25%)]	Loss: 0.593882
[2022-06-12 01:54:56 | train] - Train Epoch: [149] [332800/1281167 (26%)]	Loss: 0.889401
[2022-06-12 01:55:17 | train] - Train Epoch: [149] [345600/1281167 (27%)]	Loss: 0.669921
[2022-06-12 01:55:37 | train] - Train Epoch: [149] [358400/1281167 (28%)]	Loss: 0.656871
[2022-06-12 01:55:57 | train] - Train Epoch: [149] [371200/1281167 (29%)]	Loss: 0.687767
[2022-06-12 01:56:18 | train] - Train Epoch: [149] [384000/1281167 (30%)]	Loss: 0.767017
[2022-06-12 01:56:37 | train] - Train Epoch: [149] [396800/1281167 (31%)]	Loss: 0.743279
[2022-06-12 01:56:58 | train] - Train Epoch: [149] [409600/1281167 (32%)]	Loss: 0.509453
[2022-06-12 01:57:19 | train] - Train Epoch: [149] [422400/1281167 (33%)]	Loss: 0.682288
[2022-06-12 01:57:39 | train] - Train Epoch: [149] [435200/1281167 (34%)]	Loss: 0.872117
[2022-06-12 01:57:59 | train] - Train Epoch: [149] [448000/1281167 (35%)]	Loss: 0.685921
[2022-06-12 01:58:19 | train] - Train Epoch: [149] [460800/1281167 (36%)]	Loss: 0.854849
[2022-06-12 01:58:39 | train] - Train Epoch: [149] [473600/1281167 (37%)]	Loss: 0.688135
[2022-06-12 01:59:00 | train] - Train Epoch: [149] [486400/1281167 (38%)]	Loss: 0.902892
[2022-06-12 01:59:19 | train] - Train Epoch: [149] [499200/1281167 (39%)]	Loss: 0.734503
[2022-06-12 01:59:39 | train] - Train Epoch: [149] [512000/1281167 (40%)]	Loss: 0.496207
[2022-06-12 01:59:59 | train] - Train Epoch: [149] [524800/1281167 (41%)]	Loss: 0.632502
[2022-06-12 02:00:18 | train] - Train Epoch: [149] [537600/1281167 (42%)]	Loss: 0.749796
[2022-06-12 02:00:37 | train] - Train Epoch: [149] [550400/1281167 (43%)]	Loss: 0.530855
[2022-06-12 02:00:57 | train] - Train Epoch: [149] [563200/1281167 (44%)]	Loss: 0.728848
[2022-06-12 02:01:16 | train] - Train Epoch: [149] [576000/1281167 (45%)]	Loss: 0.719038
[2022-06-12 02:01:36 | train] - Train Epoch: [149] [588800/1281167 (46%)]	Loss: 0.665070
[2022-06-12 02:01:55 | train] - Train Epoch: [149] [601600/1281167 (47%)]	Loss: 0.559813
[2022-06-12 02:02:16 | train] - Train Epoch: [149] [614400/1281167 (48%)]	Loss: 0.794893
[2022-06-12 02:02:35 | train] - Train Epoch: [149] [627200/1281167 (49%)]	Loss: 0.713008
[2022-06-12 02:02:55 | train] - Train Epoch: [149] [640000/1281167 (50%)]	Loss: 0.804699
[2022-06-12 02:03:15 | train] - Train Epoch: [149] [652800/1281167 (51%)]	Loss: 0.679390
[2022-06-12 02:03:35 | train] - Train Epoch: [149] [665600/1281167 (52%)]	Loss: 0.495626
[2022-06-12 02:03:54 | train] - Train Epoch: [149] [678400/1281167 (53%)]	Loss: 0.884960
[2022-06-12 02:04:14 | train] - Train Epoch: [149] [691200/1281167 (54%)]	Loss: 0.792689
[2022-06-12 02:04:34 | train] - Train Epoch: [149] [704000/1281167 (55%)]	Loss: 0.829786
[2022-06-12 02:04:53 | train] - Train Epoch: [149] [716800/1281167 (56%)]	Loss: 0.669303
[2022-06-12 02:05:13 | train] - Train Epoch: [149] [729600/1281167 (57%)]	Loss: 0.669625
[2022-06-12 02:05:33 | train] - Train Epoch: [149] [742400/1281167 (58%)]	Loss: 0.807725
[2022-06-12 02:05:53 | train] - Train Epoch: [149] [755200/1281167 (59%)]	Loss: 0.726257
[2022-06-12 02:06:13 | train] - Train Epoch: [149] [768000/1281167 (60%)]	Loss: 0.699986
[2022-06-12 02:06:33 | train] - Train Epoch: [149] [780800/1281167 (61%)]	Loss: 0.626043
[2022-06-12 02:06:53 | train] - Train Epoch: [149] [793600/1281167 (62%)]	Loss: 0.543442
[2022-06-12 02:07:12 | train] - Train Epoch: [149] [806400/1281167 (63%)]	Loss: 0.709825
[2022-06-12 02:07:33 | train] - Train Epoch: [149] [819200/1281167 (64%)]	Loss: 0.604254
[2022-06-12 02:07:53 | train] - Train Epoch: [149] [832000/1281167 (65%)]	Loss: 0.672530
[2022-06-12 02:08:12 | train] - Train Epoch: [149] [844800/1281167 (66%)]	Loss: 0.688549
[2022-06-12 02:08:33 | train] - Train Epoch: [149] [857600/1281167 (67%)]	Loss: 0.686022
[2022-06-12 02:08:52 | train] - Train Epoch: [149] [870400/1281167 (68%)]	Loss: 0.739907
[2022-06-12 02:09:13 | train] - Train Epoch: [149] [883200/1281167 (69%)]	Loss: 0.803031
[2022-06-12 02:09:32 | train] - Train Epoch: [149] [896000/1281167 (70%)]	Loss: 0.805720
[2022-06-12 02:09:52 | train] - Train Epoch: [149] [908800/1281167 (71%)]	Loss: 0.914348
[2022-06-12 02:10:12 | train] - Train Epoch: [149] [921600/1281167 (72%)]	Loss: 0.694287
[2022-06-12 02:10:32 | train] - Train Epoch: [149] [934400/1281167 (73%)]	Loss: 0.819595
[2022-06-12 02:10:52 | train] - Train Epoch: [149] [947200/1281167 (74%)]	Loss: 0.877499
[2022-06-12 02:11:11 | train] - Train Epoch: [149] [960000/1281167 (75%)]	Loss: 0.946496
[2022-06-12 02:11:31 | train] - Train Epoch: [149] [972800/1281167 (76%)]	Loss: 0.714637
[2022-06-12 02:11:51 | train] - Train Epoch: [149] [985600/1281167 (77%)]	Loss: 0.559641
[2022-06-12 02:12:12 | train] - Train Epoch: [149] [998400/1281167 (78%)]	Loss: 0.723456
[2022-06-12 02:12:31 | train] - Train Epoch: [149] [1011200/1281167 (79%)]	Loss: 0.583231
[2022-06-12 02:12:51 | train] - Train Epoch: [149] [1024000/1281167 (80%)]	Loss: 0.585628
[2022-06-12 02:13:12 | train] - Train Epoch: [149] [1036800/1281167 (81%)]	Loss: 0.644016
[2022-06-12 02:13:31 | train] - Train Epoch: [149] [1049600/1281167 (82%)]	Loss: 0.986866
[2022-06-12 02:13:51 | train] - Train Epoch: [149] [1062400/1281167 (83%)]	Loss: 0.623411
[2022-06-12 02:14:11 | train] - Train Epoch: [149] [1075200/1281167 (84%)]	Loss: 0.612176
[2022-06-12 02:14:31 | train] - Train Epoch: [149] [1088000/1281167 (85%)]	Loss: 0.965008
[2022-06-12 02:14:50 | train] - Train Epoch: [149] [1100800/1281167 (86%)]	Loss: 0.699947
[2022-06-12 02:15:10 | train] - Train Epoch: [149] [1113600/1281167 (87%)]	Loss: 0.732891
[2022-06-12 02:15:31 | train] - Train Epoch: [149] [1126400/1281167 (88%)]	Loss: 0.724752
[2022-06-12 02:15:50 | train] - Train Epoch: [149] [1139200/1281167 (89%)]	Loss: 0.731075
[2022-06-12 02:16:10 | train] - Train Epoch: [149] [1152000/1281167 (90%)]	Loss: 0.709758
[2022-06-12 02:16:29 | train] - Train Epoch: [149] [1164800/1281167 (91%)]	Loss: 0.824904
[2022-06-12 02:16:49 | train] - Train Epoch: [149] [1177600/1281167 (92%)]	Loss: 0.797778
[2022-06-12 02:17:09 | train] - Train Epoch: [149] [1190400/1281167 (93%)]	Loss: 0.804261
[2022-06-12 02:17:28 | train] - Train Epoch: [149] [1203200/1281167 (94%)]	Loss: 0.571981
[2022-06-12 02:17:48 | train] - Train Epoch: [149] [1216000/1281167 (95%)]	Loss: 0.674414
[2022-06-12 02:18:08 | train] - Train Epoch: [149] [1228800/1281167 (96%)]	Loss: 0.793769
[2022-06-12 02:18:27 | train] - Train Epoch: [149] [1241600/1281167 (97%)]	Loss: 0.728325
[2022-06-12 02:18:47 | train] - Train Epoch: [149] [1254400/1281167 (98%)]	Loss: 0.763696
[2022-06-12 02:19:06 | train] - Train Epoch: [149] [1267200/1281167 (99%)]	Loss: 0.803679
[2022-06-12 02:19:26 | train] - Train Epoch: [149] [1280000/1281167 (100%)]	Loss: 0.513296
[2022-06-12 02:19:27 | train] - Train Epoch: [149]	 Average Loss: 0.727709	 Total Acc : 82.2741	 Total Top5 Acc : 93.5781
[2022-06-12 02:19:27 | train] - -------149 epoch end-----------
========================================
-------149 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 02:20:54 | train] - 
Epoch [149] Test set: Average loss: 1.4326, Accuracy: 34899/50000 (69.7706%), Top-5 Accuracy: 88.9142%

[2022-06-12 02:20:54 | train] - save intermediate epoch [149] result


[2022-06-12 02:21:05 | train] - -------150 epoch start-----------
[2022-06-12 02:21:05 | train] - -------- logging 150 batch layer input tensor ------------------
[2022-06-12 02:21:38 | train] - -------- logging end 150 --------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-12 02:21:40 | train] - Train Epoch: [150] [0/1281167 (0%)]	Loss: 0.683738
[2022-06-12 02:22:01 | train] - Train Epoch: [150] [12800/1281167 (1%)]	Loss: 0.725549
[2022-06-12 02:22:20 | train] - Train Epoch: [150] [25600/1281167 (2%)]	Loss: 0.686819
[2022-06-12 02:22:40 | train] - Train Epoch: [150] [38400/1281167 (3%)]	Loss: 0.543754
[2022-06-12 02:22:59 | train] - Train Epoch: [150] [51200/1281167 (4%)]	Loss: 0.599759
[2022-06-12 02:23:19 | train] - Train Epoch: [150] [64000/1281167 (5%)]	Loss: 0.805882
[2022-06-12 02:23:37 | train] - Train Epoch: [150] [76800/1281167 (6%)]	Loss: 0.708680
[2022-06-12 02:23:57 | train] - Train Epoch: [150] [89600/1281167 (7%)]	Loss: 0.690881
[2022-06-12 02:24:16 | train] - Train Epoch: [150] [102400/1281167 (8%)]	Loss: 0.520479
[2022-06-12 02:24:36 | train] - Train Epoch: [150] [115200/1281167 (9%)]	Loss: 0.978190
[2022-06-12 02:24:56 | train] - Train Epoch: [150] [128000/1281167 (10%)]	Loss: 0.563890
[2022-06-12 02:25:15 | train] - Train Epoch: [150] [140800/1281167 (11%)]	Loss: 0.553306
[2022-06-12 02:25:34 | train] - Train Epoch: [150] [153600/1281167 (12%)]	Loss: 0.719846
[2022-06-12 02:25:54 | train] - Train Epoch: [150] [166400/1281167 (13%)]	Loss: 0.618035
[2022-06-12 02:26:14 | train] - Train Epoch: [150] [179200/1281167 (14%)]	Loss: 0.445663
[2022-06-12 02:26:34 | train] - Train Epoch: [150] [192000/1281167 (15%)]	Loss: 0.734094
[2022-06-12 02:26:53 | train] - Train Epoch: [150] [204800/1281167 (16%)]	Loss: 0.560193
[2022-06-12 02:27:13 | train] - Train Epoch: [150] [217600/1281167 (17%)]	Loss: 0.859655
[2022-06-12 02:27:33 | train] - Train Epoch: [150] [230400/1281167 (18%)]	Loss: 0.570568
[2022-06-12 02:27:52 | train] - Train Epoch: [150] [243200/1281167 (19%)]	Loss: 0.672629
[2022-06-12 02:28:11 | train] - Train Epoch: [150] [256000/1281167 (20%)]	Loss: 0.692662
[2022-06-12 02:28:31 | train] - Train Epoch: [150] [268800/1281167 (21%)]	Loss: 0.554909
[2022-06-12 02:28:50 | train] - Train Epoch: [150] [281600/1281167 (22%)]	Loss: 0.823408
[2022-06-12 02:29:10 | train] - Train Epoch: [150] [294400/1281167 (23%)]	Loss: 0.823693
[2022-06-12 02:29:29 | train] - Train Epoch: [150] [307200/1281167 (24%)]	Loss: 1.008300
[2022-06-12 02:29:48 | train] - Train Epoch: [150] [320000/1281167 (25%)]	Loss: 0.806624
[2022-06-12 02:30:08 | train] - Train Epoch: [150] [332800/1281167 (26%)]	Loss: 1.057534
[2022-06-12 02:30:27 | train] - Train Epoch: [150] [345600/1281167 (27%)]	Loss: 0.589207
[2022-06-12 02:30:47 | train] - Train Epoch: [150] [358400/1281167 (28%)]	Loss: 0.820748
[2022-06-12 02:31:07 | train] - Train Epoch: [150] [371200/1281167 (29%)]	Loss: 0.857838
[2022-06-12 02:31:26 | train] - Train Epoch: [150] [384000/1281167 (30%)]	Loss: 0.474450
[2022-06-12 02:31:45 | train] - Train Epoch: [150] [396800/1281167 (31%)]	Loss: 0.773025
[2022-06-12 02:32:05 | train] - Train Epoch: [150] [409600/1281167 (32%)]	Loss: 0.836036
[2022-06-12 02:32:24 | train] - Train Epoch: [150] [422400/1281167 (33%)]	Loss: 0.661007
[2022-06-12 02:32:44 | train] - Train Epoch: [150] [435200/1281167 (34%)]	Loss: 0.512579
[2022-06-12 02:33:03 | train] - Train Epoch: [150] [448000/1281167 (35%)]	Loss: 0.672721
[2022-06-12 02:33:23 | train] - Train Epoch: [150] [460800/1281167 (36%)]	Loss: 0.746831
[2022-06-12 02:33:42 | train] - Train Epoch: [150] [473600/1281167 (37%)]	Loss: 0.726777
[2022-06-12 02:34:02 | train] - Train Epoch: [150] [486400/1281167 (38%)]	Loss: 0.917475
[2022-06-12 02:34:21 | train] - Train Epoch: [150] [499200/1281167 (39%)]	Loss: 0.877526
[2022-06-12 02:34:40 | train] - Train Epoch: [150] [512000/1281167 (40%)]	Loss: 0.662259
[2022-06-12 02:34:59 | train] - Train Epoch: [150] [524800/1281167 (41%)]	Loss: 0.678100
[2022-06-12 02:35:19 | train] - Train Epoch: [150] [537600/1281167 (42%)]	Loss: 0.753190
[2022-06-12 02:35:39 | train] - Train Epoch: [150] [550400/1281167 (43%)]	Loss: 0.691274
[2022-06-12 02:35:58 | train] - Train Epoch: [150] [563200/1281167 (44%)]	Loss: 0.972936
[2022-06-12 02:36:17 | train] - Train Epoch: [150] [576000/1281167 (45%)]	Loss: 0.986445
[2022-06-12 02:36:36 | train] - Train Epoch: [150] [588800/1281167 (46%)]	Loss: 0.583401
[2022-06-12 02:36:56 | train] - Train Epoch: [150] [601600/1281167 (47%)]	Loss: 0.737493
[2022-06-12 02:37:15 | train] - Train Epoch: [150] [614400/1281167 (48%)]	Loss: 0.771623
[2022-06-12 02:37:35 | train] - Train Epoch: [150] [627200/1281167 (49%)]	Loss: 0.615410
[2022-06-12 02:37:54 | train] - Train Epoch: [150] [640000/1281167 (50%)]	Loss: 0.756220
[2022-06-12 02:38:13 | train] - Train Epoch: [150] [652800/1281167 (51%)]	Loss: 0.941547
[2022-06-12 02:38:33 | train] - Train Epoch: [150] [665600/1281167 (52%)]	Loss: 0.823491
[2022-06-12 02:38:53 | train] - Train Epoch: [150] [678400/1281167 (53%)]	Loss: 0.809934
[2022-06-12 02:39:13 | train] - Train Epoch: [150] [691200/1281167 (54%)]	Loss: 0.858695
[2022-06-12 02:39:32 | train] - Train Epoch: [150] [704000/1281167 (55%)]	Loss: 0.605867
[2022-06-12 02:39:52 | train] - Train Epoch: [150] [716800/1281167 (56%)]	Loss: 0.759721
[2022-06-12 02:40:12 | train] - Train Epoch: [150] [729600/1281167 (57%)]	Loss: 0.606510
[2022-06-12 02:40:31 | train] - Train Epoch: [150] [742400/1281167 (58%)]	Loss: 0.979822
[2022-06-12 02:40:51 | train] - Train Epoch: [150] [755200/1281167 (59%)]	Loss: 1.101387
[2022-06-12 02:41:10 | train] - Train Epoch: [150] [768000/1281167 (60%)]	Loss: 0.767848
[2022-06-12 02:41:29 | train] - Train Epoch: [150] [780800/1281167 (61%)]	Loss: 0.743835
[2022-06-12 02:41:48 | train] - Train Epoch: [150] [793600/1281167 (62%)]	Loss: 0.778842
[2022-06-12 02:42:08 | train] - Train Epoch: [150] [806400/1281167 (63%)]	Loss: 0.989522
[2022-06-12 02:42:28 | train] - Train Epoch: [150] [819200/1281167 (64%)]	Loss: 0.723704
[2022-06-12 02:42:47 | train] - Train Epoch: [150] [832000/1281167 (65%)]	Loss: 0.598686
[2022-06-12 02:43:06 | train] - Train Epoch: [150] [844800/1281167 (66%)]	Loss: 0.834238
[2022-06-12 02:43:25 | train] - Train Epoch: [150] [857600/1281167 (67%)]	Loss: 0.730650
[2022-06-12 02:43:45 | train] - Train Epoch: [150] [870400/1281167 (68%)]	Loss: 0.715224
[2022-06-12 02:44:05 | train] - Train Epoch: [150] [883200/1281167 (69%)]	Loss: 0.711534
[2022-06-12 02:44:24 | train] - Train Epoch: [150] [896000/1281167 (70%)]	Loss: 0.790673
[2022-06-12 02:44:44 | train] - Train Epoch: [150] [908800/1281167 (71%)]	Loss: 0.833597
[2022-06-12 02:45:03 | train] - Train Epoch: [150] [921600/1281167 (72%)]	Loss: 0.632333
[2022-06-12 02:45:23 | train] - Train Epoch: [150] [934400/1281167 (73%)]	Loss: 0.568379
[2022-06-12 02:45:42 | train] - Train Epoch: [150] [947200/1281167 (74%)]	Loss: 0.509200
[2022-06-12 02:46:01 | train] - Train Epoch: [150] [960000/1281167 (75%)]	Loss: 0.579258
[2022-06-12 02:46:21 | train] - Train Epoch: [150] [972800/1281167 (76%)]	Loss: 0.856325
[2022-06-12 02:46:41 | train] - Train Epoch: [150] [985600/1281167 (77%)]	Loss: 0.825666
[2022-06-12 02:47:01 | train] - Train Epoch: [150] [998400/1281167 (78%)]	Loss: 0.647323
[2022-06-12 02:47:21 | train] - Train Epoch: [150] [1011200/1281167 (79%)]	Loss: 0.782966
[2022-06-12 02:47:40 | train] - Train Epoch: [150] [1024000/1281167 (80%)]	Loss: 0.626468
[2022-06-12 02:47:59 | train] - Train Epoch: [150] [1036800/1281167 (81%)]	Loss: 0.592435
[2022-06-12 02:48:19 | train] - Train Epoch: [150] [1049600/1281167 (82%)]	Loss: 0.936825
[2022-06-12 02:48:38 | train] - Train Epoch: [150] [1062400/1281167 (83%)]	Loss: 0.633614
[2022-06-12 02:48:57 | train] - Train Epoch: [150] [1075200/1281167 (84%)]	Loss: 0.957511
[2022-06-12 02:49:17 | train] - Train Epoch: [150] [1088000/1281167 (85%)]	Loss: 0.644550
[2022-06-12 02:49:36 | train] - Train Epoch: [150] [1100800/1281167 (86%)]	Loss: 0.669216
[2022-06-12 02:49:56 | train] - Train Epoch: [150] [1113600/1281167 (87%)]	Loss: 0.766191
[2022-06-12 02:50:15 | train] - Train Epoch: [150] [1126400/1281167 (88%)]	Loss: 0.851239
[2022-06-12 02:50:34 | train] - Train Epoch: [150] [1139200/1281167 (89%)]	Loss: 0.775932
[2022-06-12 02:50:54 | train] - Train Epoch: [150] [1152000/1281167 (90%)]	Loss: 0.742213
[2022-06-12 02:51:14 | train] - Train Epoch: [150] [1164800/1281167 (91%)]	Loss: 0.880224
[2022-06-12 02:51:33 | train] - Train Epoch: [150] [1177600/1281167 (92%)]	Loss: 0.615397
[2022-06-12 02:51:52 | train] - Train Epoch: [150] [1190400/1281167 (93%)]	Loss: 0.808427
[2022-06-12 02:52:11 | train] - Train Epoch: [150] [1203200/1281167 (94%)]	Loss: 0.563714
[2022-06-12 02:52:31 | train] - Train Epoch: [150] [1216000/1281167 (95%)]	Loss: 0.753664
[2022-06-12 02:52:49 | train] - Train Epoch: [150] [1228800/1281167 (96%)]	Loss: 0.737379
[2022-06-12 02:53:09 | train] - Train Epoch: [150] [1241600/1281167 (97%)]	Loss: 0.955532
[2022-06-12 02:53:29 | train] - Train Epoch: [150] [1254400/1281167 (98%)]	Loss: 0.648684
[2022-06-12 02:53:48 | train] - Train Epoch: [150] [1267200/1281167 (99%)]	Loss: 0.632786
[2022-06-12 02:54:07 | train] - Train Epoch: [150] [1280000/1281167 (100%)]	Loss: 0.640191
[2022-06-12 02:54:09 | train] - Train Epoch: [150]	 Average Loss: 0.724723	 Total Acc : 82.3585	 Total Top5 Acc : 93.6240
[2022-06-12 02:54:09 | train] - -------150 epoch end-----------
========================================
-------150 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 02:55:39 | train] - 
Epoch [150] Test set: Average loss: 1.4249, Accuracy: 35036/50000 (70.0432%), Top-5 Accuracy: 88.9350%

[2022-06-12 02:55:39 | train] - save intermediate epoch [150] result


[2022-06-12 02:55:50 | train] - logging best performance 150 epoch
[2022-06-12 02:55:51 | train] - -------151 epoch start-----------
========================================
----- test end -------------------------


logging best performance 150 epoch
[2022-06-12 02:55:53 | train] - Train Epoch: [151] [0/1281167 (0%)]	Loss: 0.538329
[2022-06-12 02:56:13 | train] - Train Epoch: [151] [12800/1281167 (1%)]	Loss: 0.826919
[2022-06-12 02:56:33 | train] - Train Epoch: [151] [25600/1281167 (2%)]	Loss: 0.724681
[2022-06-12 02:56:53 | train] - Train Epoch: [151] [38400/1281167 (3%)]	Loss: 0.699268
[2022-06-12 02:57:14 | train] - Train Epoch: [151] [51200/1281167 (4%)]	Loss: 0.795074
[2022-06-12 02:57:35 | train] - Train Epoch: [151] [64000/1281167 (5%)]	Loss: 0.531231
[2022-06-12 02:57:54 | train] - Train Epoch: [151] [76800/1281167 (6%)]	Loss: 0.624551
[2022-06-12 02:58:13 | train] - Train Epoch: [151] [89600/1281167 (7%)]	Loss: 0.639157
[2022-06-12 02:58:33 | train] - Train Epoch: [151] [102400/1281167 (8%)]	Loss: 0.579215
[2022-06-12 02:58:52 | train] - Train Epoch: [151] [115200/1281167 (9%)]	Loss: 0.755087
[2022-06-12 02:59:12 | train] - Train Epoch: [151] [128000/1281167 (10%)]	Loss: 0.449960
[2022-06-12 02:59:31 | train] - Train Epoch: [151] [140800/1281167 (11%)]	Loss: 0.575133
[2022-06-12 02:59:50 | train] - Train Epoch: [151] [153600/1281167 (12%)]	Loss: 0.607955
[2022-06-12 03:00:09 | train] - Train Epoch: [151] [166400/1281167 (13%)]	Loss: 0.979819
[2022-06-12 03:00:29 | train] - Train Epoch: [151] [179200/1281167 (14%)]	Loss: 0.592025
[2022-06-12 03:00:49 | train] - Train Epoch: [151] [192000/1281167 (15%)]	Loss: 0.837303
[2022-06-12 03:01:08 | train] - Train Epoch: [151] [204800/1281167 (16%)]	Loss: 0.649377
[2022-06-12 03:01:27 | train] - Train Epoch: [151] [217600/1281167 (17%)]	Loss: 0.841862
[2022-06-12 03:01:47 | train] - Train Epoch: [151] [230400/1281167 (18%)]	Loss: 0.639108
[2022-06-12 03:02:07 | train] - Train Epoch: [151] [243200/1281167 (19%)]	Loss: 0.964071
[2022-06-12 03:02:26 | train] - Train Epoch: [151] [256000/1281167 (20%)]	Loss: 0.457898
[2022-06-12 03:02:45 | train] - Train Epoch: [151] [268800/1281167 (21%)]	Loss: 0.714626
[2022-06-12 03:03:04 | train] - Train Epoch: [151] [281600/1281167 (22%)]	Loss: 0.777092
[2022-06-12 03:03:23 | train] - Train Epoch: [151] [294400/1281167 (23%)]	Loss: 0.758479
[2022-06-12 03:03:43 | train] - Train Epoch: [151] [307200/1281167 (24%)]	Loss: 0.635827
[2022-06-12 03:04:02 | train] - Train Epoch: [151] [320000/1281167 (25%)]	Loss: 0.727087
[2022-06-12 03:04:22 | train] - Train Epoch: [151] [332800/1281167 (26%)]	Loss: 0.687480
[2022-06-12 03:04:41 | train] - Train Epoch: [151] [345600/1281167 (27%)]	Loss: 0.605803
[2022-06-12 03:05:01 | train] - Train Epoch: [151] [358400/1281167 (28%)]	Loss: 0.667156
[2022-06-12 03:05:20 | train] - Train Epoch: [151] [371200/1281167 (29%)]	Loss: 0.661521
[2022-06-12 03:05:40 | train] - Train Epoch: [151] [384000/1281167 (30%)]	Loss: 0.552583
[2022-06-12 03:06:00 | train] - Train Epoch: [151] [396800/1281167 (31%)]	Loss: 0.630932
[2022-06-12 03:06:19 | train] - Train Epoch: [151] [409600/1281167 (32%)]	Loss: 0.831308
[2022-06-12 03:06:38 | train] - Train Epoch: [151] [422400/1281167 (33%)]	Loss: 0.778784
[2022-06-12 03:06:58 | train] - Train Epoch: [151] [435200/1281167 (34%)]	Loss: 0.852494
[2022-06-12 03:07:17 | train] - Train Epoch: [151] [448000/1281167 (35%)]	Loss: 0.744000
[2022-06-12 03:07:36 | train] - Train Epoch: [151] [460800/1281167 (36%)]	Loss: 0.628917
[2022-06-12 03:07:55 | train] - Train Epoch: [151] [473600/1281167 (37%)]	Loss: 0.814933
[2022-06-12 03:08:15 | train] - Train Epoch: [151] [486400/1281167 (38%)]	Loss: 0.493308
[2022-06-12 03:08:34 | train] - Train Epoch: [151] [499200/1281167 (39%)]	Loss: 0.733970
[2022-06-12 03:08:54 | train] - Train Epoch: [151] [512000/1281167 (40%)]	Loss: 0.619041
[2022-06-12 03:09:14 | train] - Train Epoch: [151] [524800/1281167 (41%)]	Loss: 0.681897
[2022-06-12 03:09:33 | train] - Train Epoch: [151] [537600/1281167 (42%)]	Loss: 0.487961
[2022-06-12 03:09:53 | train] - Train Epoch: [151] [550400/1281167 (43%)]	Loss: 0.712521
[2022-06-12 03:10:13 | train] - Train Epoch: [151] [563200/1281167 (44%)]	Loss: 0.583837
[2022-06-12 03:10:32 | train] - Train Epoch: [151] [576000/1281167 (45%)]	Loss: 0.638478
[2022-06-12 03:10:52 | train] - Train Epoch: [151] [588800/1281167 (46%)]	Loss: 0.772643
[2022-06-12 03:11:11 | train] - Train Epoch: [151] [601600/1281167 (47%)]	Loss: 0.817767
[2022-06-12 03:11:30 | train] - Train Epoch: [151] [614400/1281167 (48%)]	Loss: 0.824486
[2022-06-12 03:11:49 | train] - Train Epoch: [151] [627200/1281167 (49%)]	Loss: 0.611508
[2022-06-12 03:12:08 | train] - Train Epoch: [151] [640000/1281167 (50%)]	Loss: 0.746990
[2022-06-12 03:12:28 | train] - Train Epoch: [151] [652800/1281167 (51%)]	Loss: 0.866827
[2022-06-12 03:12:47 | train] - Train Epoch: [151] [665600/1281167 (52%)]	Loss: 0.486206
[2022-06-12 03:13:07 | train] - Train Epoch: [151] [678400/1281167 (53%)]	Loss: 0.804297
[2022-06-12 03:13:26 | train] - Train Epoch: [151] [691200/1281167 (54%)]	Loss: 0.848811
[2022-06-12 03:13:46 | train] - Train Epoch: [151] [704000/1281167 (55%)]	Loss: 0.694019
[2022-06-12 03:14:06 | train] - Train Epoch: [151] [716800/1281167 (56%)]	Loss: 0.860951
[2022-06-12 03:14:26 | train] - Train Epoch: [151] [729600/1281167 (57%)]	Loss: 0.836775
[2022-06-12 03:14:45 | train] - Train Epoch: [151] [742400/1281167 (58%)]	Loss: 0.711431
[2022-06-12 03:15:04 | train] - Train Epoch: [151] [755200/1281167 (59%)]	Loss: 0.799725
[2022-06-12 03:15:24 | train] - Train Epoch: [151] [768000/1281167 (60%)]	Loss: 0.435908
[2022-06-12 03:15:44 | train] - Train Epoch: [151] [780800/1281167 (61%)]	Loss: 0.545897
[2022-06-12 03:16:03 | train] - Train Epoch: [151] [793600/1281167 (62%)]	Loss: 0.686843
[2022-06-12 03:16:22 | train] - Train Epoch: [151] [806400/1281167 (63%)]	Loss: 0.947339
[2022-06-12 03:16:42 | train] - Train Epoch: [151] [819200/1281167 (64%)]	Loss: 0.825775
[2022-06-12 03:17:01 | train] - Train Epoch: [151] [832000/1281167 (65%)]	Loss: 0.713501
[2022-06-12 03:17:20 | train] - Train Epoch: [151] [844800/1281167 (66%)]	Loss: 0.903361
[2022-06-12 03:17:40 | train] - Train Epoch: [151] [857600/1281167 (67%)]	Loss: 0.707482
[2022-06-12 03:17:59 | train] - Train Epoch: [151] [870400/1281167 (68%)]	Loss: 0.805408
[2022-06-12 03:18:19 | train] - Train Epoch: [151] [883200/1281167 (69%)]	Loss: 0.893223
[2022-06-12 03:18:38 | train] - Train Epoch: [151] [896000/1281167 (70%)]	Loss: 0.758639
[2022-06-12 03:18:57 | train] - Train Epoch: [151] [908800/1281167 (71%)]	Loss: 0.665333
[2022-06-12 03:19:17 | train] - Train Epoch: [151] [921600/1281167 (72%)]	Loss: 0.605143
[2022-06-12 03:19:37 | train] - Train Epoch: [151] [934400/1281167 (73%)]	Loss: 0.628974
[2022-06-12 03:19:56 | train] - Train Epoch: [151] [947200/1281167 (74%)]	Loss: 0.643182
[2022-06-12 03:20:16 | train] - Train Epoch: [151] [960000/1281167 (75%)]	Loss: 0.753865
[2022-06-12 03:20:36 | train] - Train Epoch: [151] [972800/1281167 (76%)]	Loss: 0.721344
[2022-06-12 03:20:56 | train] - Train Epoch: [151] [985600/1281167 (77%)]	Loss: 0.788352
[2022-06-12 03:21:15 | train] - Train Epoch: [151] [998400/1281167 (78%)]	Loss: 0.461052
[2022-06-12 03:21:35 | train] - Train Epoch: [151] [1011200/1281167 (79%)]	Loss: 0.806301
[2022-06-12 03:21:55 | train] - Train Epoch: [151] [1024000/1281167 (80%)]	Loss: 0.696537
[2022-06-12 03:22:15 | train] - Train Epoch: [151] [1036800/1281167 (81%)]	Loss: 0.738989
[2022-06-12 03:22:35 | train] - Train Epoch: [151] [1049600/1281167 (82%)]	Loss: 0.675104
[2022-06-12 03:22:54 | train] - Train Epoch: [151] [1062400/1281167 (83%)]	Loss: 0.804648
[2022-06-12 03:23:14 | train] - Train Epoch: [151] [1075200/1281167 (84%)]	Loss: 0.516964
[2022-06-12 03:23:34 | train] - Train Epoch: [151] [1088000/1281167 (85%)]	Loss: 0.638260
[2022-06-12 03:23:53 | train] - Train Epoch: [151] [1100800/1281167 (86%)]	Loss: 0.765364
[2022-06-12 03:24:12 | train] - Train Epoch: [151] [1113600/1281167 (87%)]	Loss: 0.654160
[2022-06-12 03:24:32 | train] - Train Epoch: [151] [1126400/1281167 (88%)]	Loss: 0.817446
[2022-06-12 03:24:51 | train] - Train Epoch: [151] [1139200/1281167 (89%)]	Loss: 0.782093
[2022-06-12 03:25:11 | train] - Train Epoch: [151] [1152000/1281167 (90%)]	Loss: 0.801121
[2022-06-12 03:25:30 | train] - Train Epoch: [151] [1164800/1281167 (91%)]	Loss: 0.835458
[2022-06-12 03:25:50 | train] - Train Epoch: [151] [1177600/1281167 (92%)]	Loss: 0.774336
[2022-06-12 03:26:08 | train] - Train Epoch: [151] [1190400/1281167 (93%)]	Loss: 0.815568
[2022-06-12 03:26:28 | train] - Train Epoch: [151] [1203200/1281167 (94%)]	Loss: 0.584917
[2022-06-12 03:26:47 | train] - Train Epoch: [151] [1216000/1281167 (95%)]	Loss: 0.707068
[2022-06-12 03:27:06 | train] - Train Epoch: [151] [1228800/1281167 (96%)]	Loss: 0.833685
[2022-06-12 03:27:25 | train] - Train Epoch: [151] [1241600/1281167 (97%)]	Loss: 0.948709
[2022-06-12 03:27:45 | train] - Train Epoch: [151] [1254400/1281167 (98%)]	Loss: 0.729738
[2022-06-12 03:28:03 | train] - Train Epoch: [151] [1267200/1281167 (99%)]	Loss: 0.699601
[2022-06-12 03:28:24 | train] - Train Epoch: [151] [1280000/1281167 (100%)]	Loss: 0.652903
[2022-06-12 03:28:25 | train] - Train Epoch: [151]	 Average Loss: 0.723367	 Total Acc : 82.4152	 Total Top5 Acc : 93.6405
[2022-06-12 03:28:25 | train] - -------151 epoch end-----------
========================================
-------151 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 03:29:54 | train] - 
Epoch [151] Test set: Average loss: 1.4184, Accuracy: 34923/50000 (69.8198%), Top-5 Accuracy: 88.9254%

[2022-06-12 03:29:54 | train] - save intermediate epoch [151] result


[2022-06-12 03:30:06 | train] - -------152 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 03:30:08 | train] - Train Epoch: [152] [0/1281167 (0%)]	Loss: 0.682476
[2022-06-12 03:30:28 | train] - Train Epoch: [152] [12800/1281167 (1%)]	Loss: 0.441608
[2022-06-12 03:30:48 | train] - Train Epoch: [152] [25600/1281167 (2%)]	Loss: 0.934369
[2022-06-12 03:31:07 | train] - Train Epoch: [152] [38400/1281167 (3%)]	Loss: 0.603932
[2022-06-12 03:31:27 | train] - Train Epoch: [152] [51200/1281167 (4%)]	Loss: 0.575020
[2022-06-12 03:31:46 | train] - Train Epoch: [152] [64000/1281167 (5%)]	Loss: 0.629305
[2022-06-12 03:32:05 | train] - Train Epoch: [152] [76800/1281167 (6%)]	Loss: 0.702690
[2022-06-12 03:32:25 | train] - Train Epoch: [152] [89600/1281167 (7%)]	Loss: 0.679239
[2022-06-12 03:32:44 | train] - Train Epoch: [152] [102400/1281167 (8%)]	Loss: 0.521414
[2022-06-12 03:33:03 | train] - Train Epoch: [152] [115200/1281167 (9%)]	Loss: 0.659363
[2022-06-12 03:33:23 | train] - Train Epoch: [152] [128000/1281167 (10%)]	Loss: 0.814200
[2022-06-12 03:33:42 | train] - Train Epoch: [152] [140800/1281167 (11%)]	Loss: 0.664302
[2022-06-12 03:34:02 | train] - Train Epoch: [152] [153600/1281167 (12%)]	Loss: 0.673399
[2022-06-12 03:34:21 | train] - Train Epoch: [152] [166400/1281167 (13%)]	Loss: 0.619668
[2022-06-12 03:34:40 | train] - Train Epoch: [152] [179200/1281167 (14%)]	Loss: 0.577640
[2022-06-12 03:35:00 | train] - Train Epoch: [152] [192000/1281167 (15%)]	Loss: 0.881035
[2022-06-12 03:35:20 | train] - Train Epoch: [152] [204800/1281167 (16%)]	Loss: 0.611469
[2022-06-12 03:35:39 | train] - Train Epoch: [152] [217600/1281167 (17%)]	Loss: 0.805868
[2022-06-12 03:35:58 | train] - Train Epoch: [152] [230400/1281167 (18%)]	Loss: 0.608649
[2022-06-12 03:36:17 | train] - Train Epoch: [152] [243200/1281167 (19%)]	Loss: 0.790384
[2022-06-12 03:36:37 | train] - Train Epoch: [152] [256000/1281167 (20%)]	Loss: 0.770127
[2022-06-12 03:36:56 | train] - Train Epoch: [152] [268800/1281167 (21%)]	Loss: 0.794875
[2022-06-12 03:37:15 | train] - Train Epoch: [152] [281600/1281167 (22%)]	Loss: 0.679931
[2022-06-12 03:37:35 | train] - Train Epoch: [152] [294400/1281167 (23%)]	Loss: 0.614695
[2022-06-12 03:37:55 | train] - Train Epoch: [152] [307200/1281167 (24%)]	Loss: 0.724137
[2022-06-12 03:38:14 | train] - Train Epoch: [152] [320000/1281167 (25%)]	Loss: 0.801563
[2022-06-12 03:38:33 | train] - Train Epoch: [152] [332800/1281167 (26%)]	Loss: 0.802287
[2022-06-12 03:38:53 | train] - Train Epoch: [152] [345600/1281167 (27%)]	Loss: 0.535659
[2022-06-12 03:39:12 | train] - Train Epoch: [152] [358400/1281167 (28%)]	Loss: 0.838246
[2022-06-12 03:39:32 | train] - Train Epoch: [152] [371200/1281167 (29%)]	Loss: 0.811955
[2022-06-12 03:39:52 | train] - Train Epoch: [152] [384000/1281167 (30%)]	Loss: 0.816885
[2022-06-12 03:40:11 | train] - Train Epoch: [152] [396800/1281167 (31%)]	Loss: 0.594800
[2022-06-12 03:40:31 | train] - Train Epoch: [152] [409600/1281167 (32%)]	Loss: 0.642343
[2022-06-12 03:40:50 | train] - Train Epoch: [152] [422400/1281167 (33%)]	Loss: 0.938239
[2022-06-12 03:41:09 | train] - Train Epoch: [152] [435200/1281167 (34%)]	Loss: 0.632080
[2022-06-12 03:41:29 | train] - Train Epoch: [152] [448000/1281167 (35%)]	Loss: 0.632393
[2022-06-12 03:41:48 | train] - Train Epoch: [152] [460800/1281167 (36%)]	Loss: 0.793960
[2022-06-12 03:42:08 | train] - Train Epoch: [152] [473600/1281167 (37%)]	Loss: 0.818214
[2022-06-12 03:42:28 | train] - Train Epoch: [152] [486400/1281167 (38%)]	Loss: 0.880119
[2022-06-12 03:42:47 | train] - Train Epoch: [152] [499200/1281167 (39%)]	Loss: 0.846500
[2022-06-12 03:43:07 | train] - Train Epoch: [152] [512000/1281167 (40%)]	Loss: 0.710357
[2022-06-12 03:43:27 | train] - Train Epoch: [152] [524800/1281167 (41%)]	Loss: 0.559889
[2022-06-12 03:43:46 | train] - Train Epoch: [152] [537600/1281167 (42%)]	Loss: 0.644907
[2022-06-12 03:44:06 | train] - Train Epoch: [152] [550400/1281167 (43%)]	Loss: 0.913972
[2022-06-12 03:44:25 | train] - Train Epoch: [152] [563200/1281167 (44%)]	Loss: 0.862906
[2022-06-12 03:44:44 | train] - Train Epoch: [152] [576000/1281167 (45%)]	Loss: 0.769756
[2022-06-12 03:45:04 | train] - Train Epoch: [152] [588800/1281167 (46%)]	Loss: 0.775180
[2022-06-12 03:45:24 | train] - Train Epoch: [152] [601600/1281167 (47%)]	Loss: 0.940299
[2022-06-12 03:45:44 | train] - Train Epoch: [152] [614400/1281167 (48%)]	Loss: 0.781751
[2022-06-12 03:46:03 | train] - Train Epoch: [152] [627200/1281167 (49%)]	Loss: 0.844025
[2022-06-12 03:46:23 | train] - Train Epoch: [152] [640000/1281167 (50%)]	Loss: 0.842374
[2022-06-12 03:46:42 | train] - Train Epoch: [152] [652800/1281167 (51%)]	Loss: 0.639955
[2022-06-12 03:47:02 | train] - Train Epoch: [152] [665600/1281167 (52%)]	Loss: 0.721407
[2022-06-12 03:47:21 | train] - Train Epoch: [152] [678400/1281167 (53%)]	Loss: 0.811772
[2022-06-12 03:47:42 | train] - Train Epoch: [152] [691200/1281167 (54%)]	Loss: 0.601024
[2022-06-12 03:48:01 | train] - Train Epoch: [152] [704000/1281167 (55%)]	Loss: 0.713362
[2022-06-12 03:48:21 | train] - Train Epoch: [152] [716800/1281167 (56%)]	Loss: 0.691924
[2022-06-12 03:48:40 | train] - Train Epoch: [152] [729600/1281167 (57%)]	Loss: 1.010301
[2022-06-12 03:49:00 | train] - Train Epoch: [152] [742400/1281167 (58%)]	Loss: 0.679895
[2022-06-12 03:49:19 | train] - Train Epoch: [152] [755200/1281167 (59%)]	Loss: 0.836271
[2022-06-12 03:49:40 | train] - Train Epoch: [152] [768000/1281167 (60%)]	Loss: 0.505601
[2022-06-12 03:49:59 | train] - Train Epoch: [152] [780800/1281167 (61%)]	Loss: 0.755920
[2022-06-12 03:50:19 | train] - Train Epoch: [152] [793600/1281167 (62%)]	Loss: 0.872720
[2022-06-12 03:50:38 | train] - Train Epoch: [152] [806400/1281167 (63%)]	Loss: 0.738791
[2022-06-12 03:50:57 | train] - Train Epoch: [152] [819200/1281167 (64%)]	Loss: 0.652497
[2022-06-12 03:51:17 | train] - Train Epoch: [152] [832000/1281167 (65%)]	Loss: 0.652778
[2022-06-12 03:51:37 | train] - Train Epoch: [152] [844800/1281167 (66%)]	Loss: 0.639009
[2022-06-12 03:51:55 | train] - Train Epoch: [152] [857600/1281167 (67%)]	Loss: 0.780883
[2022-06-12 03:52:15 | train] - Train Epoch: [152] [870400/1281167 (68%)]	Loss: 0.684182
[2022-06-12 03:52:35 | train] - Train Epoch: [152] [883200/1281167 (69%)]	Loss: 0.772651
[2022-06-12 03:52:54 | train] - Train Epoch: [152] [896000/1281167 (70%)]	Loss: 0.942368
[2022-06-12 03:53:14 | train] - Train Epoch: [152] [908800/1281167 (71%)]	Loss: 0.774750
[2022-06-12 03:53:33 | train] - Train Epoch: [152] [921600/1281167 (72%)]	Loss: 0.473784
[2022-06-12 03:53:52 | train] - Train Epoch: [152] [934400/1281167 (73%)]	Loss: 0.828551
[2022-06-12 03:54:11 | train] - Train Epoch: [152] [947200/1281167 (74%)]	Loss: 0.764857
[2022-06-12 03:54:31 | train] - Train Epoch: [152] [960000/1281167 (75%)]	Loss: 0.816523
[2022-06-12 03:54:51 | train] - Train Epoch: [152] [972800/1281167 (76%)]	Loss: 0.587202
[2022-06-12 03:55:10 | train] - Train Epoch: [152] [985600/1281167 (77%)]	Loss: 0.742786
[2022-06-12 03:55:30 | train] - Train Epoch: [152] [998400/1281167 (78%)]	Loss: 0.783665
[2022-06-12 03:55:49 | train] - Train Epoch: [152] [1011200/1281167 (79%)]	Loss: 0.694036
[2022-06-12 03:56:08 | train] - Train Epoch: [152] [1024000/1281167 (80%)]	Loss: 0.540944
[2022-06-12 03:56:28 | train] - Train Epoch: [152] [1036800/1281167 (81%)]	Loss: 0.618852
[2022-06-12 03:56:47 | train] - Train Epoch: [152] [1049600/1281167 (82%)]	Loss: 0.687299
[2022-06-12 03:57:07 | train] - Train Epoch: [152] [1062400/1281167 (83%)]	Loss: 0.697088
[2022-06-12 03:57:26 | train] - Train Epoch: [152] [1075200/1281167 (84%)]	Loss: 0.650168
[2022-06-12 03:57:46 | train] - Train Epoch: [152] [1088000/1281167 (85%)]	Loss: 0.722674
[2022-06-12 03:58:06 | train] - Train Epoch: [152] [1100800/1281167 (86%)]	Loss: 0.648719
[2022-06-12 03:58:26 | train] - Train Epoch: [152] [1113600/1281167 (87%)]	Loss: 0.760844
[2022-06-12 03:58:45 | train] - Train Epoch: [152] [1126400/1281167 (88%)]	Loss: 0.719417
[2022-06-12 03:59:04 | train] - Train Epoch: [152] [1139200/1281167 (89%)]	Loss: 0.643651
[2022-06-12 03:59:24 | train] - Train Epoch: [152] [1152000/1281167 (90%)]	Loss: 0.812399
[2022-06-12 03:59:44 | train] - Train Epoch: [152] [1164800/1281167 (91%)]	Loss: 0.784349
[2022-06-12 04:00:03 | train] - Train Epoch: [152] [1177600/1281167 (92%)]	Loss: 0.776227
[2022-06-12 04:00:23 | train] - Train Epoch: [152] [1190400/1281167 (93%)]	Loss: 0.632789
[2022-06-12 04:00:41 | train] - Train Epoch: [152] [1203200/1281167 (94%)]	Loss: 0.783619
[2022-06-12 04:01:01 | train] - Train Epoch: [152] [1216000/1281167 (95%)]	Loss: 0.839369
[2022-06-12 04:01:21 | train] - Train Epoch: [152] [1228800/1281167 (96%)]	Loss: 0.597332
[2022-06-12 04:01:40 | train] - Train Epoch: [152] [1241600/1281167 (97%)]	Loss: 0.630140
[2022-06-12 04:01:59 | train] - Train Epoch: [152] [1254400/1281167 (98%)]	Loss: 0.660768
[2022-06-12 04:02:19 | train] - Train Epoch: [152] [1267200/1281167 (99%)]	Loss: 0.698253
[2022-06-12 04:02:39 | train] - Train Epoch: [152] [1280000/1281167 (100%)]	Loss: 0.834955
[2022-06-12 04:02:40 | train] - Train Epoch: [152]	 Average Loss: 0.720687	 Total Acc : 82.4508	 Total Top5 Acc : 93.6706
[2022-06-12 04:02:40 | train] - -------152 epoch end-----------
========================================
-------152 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 04:04:07 | train] - 
Epoch [152] Test set: Average loss: 1.4289, Accuracy: 34990/50000 (69.9512%), Top-5 Accuracy: 88.9342%

[2022-06-12 04:04:07 | train] - save intermediate epoch [152] result


[2022-06-12 04:04:19 | train] - -------153 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 04:04:21 | train] - Train Epoch: [153] [0/1281167 (0%)]	Loss: 0.828658
[2022-06-12 04:04:41 | train] - Train Epoch: [153] [12800/1281167 (1%)]	Loss: 0.791865
[2022-06-12 04:05:00 | train] - Train Epoch: [153] [25600/1281167 (2%)]	Loss: 0.556773
[2022-06-12 04:05:19 | train] - Train Epoch: [153] [38400/1281167 (3%)]	Loss: 0.551901
[2022-06-12 04:05:39 | train] - Train Epoch: [153] [51200/1281167 (4%)]	Loss: 0.644441
[2022-06-12 04:05:58 | train] - Train Epoch: [153] [64000/1281167 (5%)]	Loss: 0.733782
[2022-06-12 04:06:17 | train] - Train Epoch: [153] [76800/1281167 (6%)]	Loss: 0.931340
[2022-06-12 04:06:37 | train] - Train Epoch: [153] [89600/1281167 (7%)]	Loss: 0.642587
[2022-06-12 04:06:56 | train] - Train Epoch: [153] [102400/1281167 (8%)]	Loss: 0.729690
[2022-06-12 04:07:16 | train] - Train Epoch: [153] [115200/1281167 (9%)]	Loss: 0.718249
[2022-06-12 04:07:36 | train] - Train Epoch: [153] [128000/1281167 (10%)]	Loss: 0.989800
[2022-06-12 04:07:56 | train] - Train Epoch: [153] [140800/1281167 (11%)]	Loss: 0.576004
[2022-06-12 04:08:16 | train] - Train Epoch: [153] [153600/1281167 (12%)]	Loss: 0.597529
[2022-06-12 04:08:35 | train] - Train Epoch: [153] [166400/1281167 (13%)]	Loss: 0.661841
[2022-06-12 04:08:54 | train] - Train Epoch: [153] [179200/1281167 (14%)]	Loss: 0.583697
[2022-06-12 04:09:13 | train] - Train Epoch: [153] [192000/1281167 (15%)]	Loss: 0.679388
[2022-06-12 04:09:32 | train] - Train Epoch: [153] [204800/1281167 (16%)]	Loss: 0.691176
[2022-06-12 04:09:51 | train] - Train Epoch: [153] [217600/1281167 (17%)]	Loss: 0.642264
[2022-06-12 04:10:10 | train] - Train Epoch: [153] [230400/1281167 (18%)]	Loss: 0.807854
[2022-06-12 04:10:30 | train] - Train Epoch: [153] [243200/1281167 (19%)]	Loss: 0.970321
[2022-06-12 04:10:49 | train] - Train Epoch: [153] [256000/1281167 (20%)]	Loss: 0.480016
[2022-06-12 04:11:09 | train] - Train Epoch: [153] [268800/1281167 (21%)]	Loss: 0.580311
[2022-06-12 04:11:28 | train] - Train Epoch: [153] [281600/1281167 (22%)]	Loss: 0.530825
[2022-06-12 04:11:48 | train] - Train Epoch: [153] [294400/1281167 (23%)]	Loss: 0.702129
[2022-06-12 04:12:08 | train] - Train Epoch: [153] [307200/1281167 (24%)]	Loss: 0.810876
[2022-06-12 04:12:27 | train] - Train Epoch: [153] [320000/1281167 (25%)]	Loss: 0.533840
[2022-06-12 04:12:47 | train] - Train Epoch: [153] [332800/1281167 (26%)]	Loss: 0.640005
[2022-06-12 04:13:07 | train] - Train Epoch: [153] [345600/1281167 (27%)]	Loss: 0.804729
[2022-06-12 04:13:26 | train] - Train Epoch: [153] [358400/1281167 (28%)]	Loss: 0.621031
[2022-06-12 04:13:46 | train] - Train Epoch: [153] [371200/1281167 (29%)]	Loss: 0.882282
[2022-06-12 04:14:06 | train] - Train Epoch: [153] [384000/1281167 (30%)]	Loss: 0.541757
[2022-06-12 04:14:25 | train] - Train Epoch: [153] [396800/1281167 (31%)]	Loss: 1.065981
[2022-06-12 04:14:45 | train] - Train Epoch: [153] [409600/1281167 (32%)]	Loss: 0.711120
[2022-06-12 04:15:04 | train] - Train Epoch: [153] [422400/1281167 (33%)]	Loss: 0.529106
[2022-06-12 04:15:24 | train] - Train Epoch: [153] [435200/1281167 (34%)]	Loss: 0.707125
[2022-06-12 04:15:43 | train] - Train Epoch: [153] [448000/1281167 (35%)]	Loss: 0.803324
[2022-06-12 04:16:03 | train] - Train Epoch: [153] [460800/1281167 (36%)]	Loss: 0.488007
[2022-06-12 04:16:22 | train] - Train Epoch: [153] [473600/1281167 (37%)]	Loss: 0.638384
[2022-06-12 04:16:42 | train] - Train Epoch: [153] [486400/1281167 (38%)]	Loss: 0.551579
[2022-06-12 04:17:01 | train] - Train Epoch: [153] [499200/1281167 (39%)]	Loss: 0.677085
[2022-06-12 04:17:21 | train] - Train Epoch: [153] [512000/1281167 (40%)]	Loss: 0.629386
[2022-06-12 04:17:40 | train] - Train Epoch: [153] [524800/1281167 (41%)]	Loss: 0.572868
[2022-06-12 04:18:00 | train] - Train Epoch: [153] [537600/1281167 (42%)]	Loss: 0.563260
[2022-06-12 04:18:19 | train] - Train Epoch: [153] [550400/1281167 (43%)]	Loss: 0.756681
[2022-06-12 04:18:38 | train] - Train Epoch: [153] [563200/1281167 (44%)]	Loss: 0.523627
[2022-06-12 04:18:58 | train] - Train Epoch: [153] [576000/1281167 (45%)]	Loss: 0.653291
[2022-06-12 04:19:17 | train] - Train Epoch: [153] [588800/1281167 (46%)]	Loss: 0.673738
[2022-06-12 04:19:37 | train] - Train Epoch: [153] [601600/1281167 (47%)]	Loss: 0.633870
[2022-06-12 04:19:57 | train] - Train Epoch: [153] [614400/1281167 (48%)]	Loss: 0.609650
[2022-06-12 04:20:16 | train] - Train Epoch: [153] [627200/1281167 (49%)]	Loss: 0.704386
[2022-06-12 04:20:35 | train] - Train Epoch: [153] [640000/1281167 (50%)]	Loss: 0.747664
[2022-06-12 04:20:55 | train] - Train Epoch: [153] [652800/1281167 (51%)]	Loss: 0.751124
[2022-06-12 04:21:14 | train] - Train Epoch: [153] [665600/1281167 (52%)]	Loss: 0.836578
[2022-06-12 04:21:34 | train] - Train Epoch: [153] [678400/1281167 (53%)]	Loss: 0.570221
[2022-06-12 04:21:53 | train] - Train Epoch: [153] [691200/1281167 (54%)]	Loss: 0.791759
[2022-06-12 04:22:13 | train] - Train Epoch: [153] [704000/1281167 (55%)]	Loss: 0.653057
[2022-06-12 04:22:33 | train] - Train Epoch: [153] [716800/1281167 (56%)]	Loss: 1.003176
[2022-06-12 04:22:53 | train] - Train Epoch: [153] [729600/1281167 (57%)]	Loss: 0.996750
[2022-06-12 04:23:12 | train] - Train Epoch: [153] [742400/1281167 (58%)]	Loss: 0.767630
[2022-06-12 04:23:32 | train] - Train Epoch: [153] [755200/1281167 (59%)]	Loss: 0.452479
[2022-06-12 04:23:52 | train] - Train Epoch: [153] [768000/1281167 (60%)]	Loss: 0.864577
[2022-06-12 04:24:11 | train] - Train Epoch: [153] [780800/1281167 (61%)]	Loss: 0.730015
[2022-06-12 04:24:31 | train] - Train Epoch: [153] [793600/1281167 (62%)]	Loss: 0.636654
[2022-06-12 04:24:50 | train] - Train Epoch: [153] [806400/1281167 (63%)]	Loss: 0.578064
[2022-06-12 04:25:09 | train] - Train Epoch: [153] [819200/1281167 (64%)]	Loss: 0.555972
[2022-06-12 04:25:27 | train] - Train Epoch: [153] [832000/1281167 (65%)]	Loss: 0.600650
[2022-06-12 04:25:48 | train] - Train Epoch: [153] [844800/1281167 (66%)]	Loss: 0.702973
[2022-06-12 04:26:07 | train] - Train Epoch: [153] [857600/1281167 (67%)]	Loss: 0.751277
[2022-06-12 04:26:27 | train] - Train Epoch: [153] [870400/1281167 (68%)]	Loss: 0.740292
[2022-06-12 04:26:47 | train] - Train Epoch: [153] [883200/1281167 (69%)]	Loss: 0.478154
[2022-06-12 04:27:07 | train] - Train Epoch: [153] [896000/1281167 (70%)]	Loss: 0.555441
[2022-06-12 04:27:26 | train] - Train Epoch: [153] [908800/1281167 (71%)]	Loss: 0.542039
[2022-06-12 04:27:46 | train] - Train Epoch: [153] [921600/1281167 (72%)]	Loss: 0.782363
[2022-06-12 04:28:06 | train] - Train Epoch: [153] [934400/1281167 (73%)]	Loss: 0.543049
[2022-06-12 04:28:25 | train] - Train Epoch: [153] [947200/1281167 (74%)]	Loss: 0.692929
[2022-06-12 04:28:45 | train] - Train Epoch: [153] [960000/1281167 (75%)]	Loss: 0.680456
[2022-06-12 04:29:04 | train] - Train Epoch: [153] [972800/1281167 (76%)]	Loss: 0.519002
[2022-06-12 04:29:24 | train] - Train Epoch: [153] [985600/1281167 (77%)]	Loss: 0.831694
[2022-06-12 04:29:44 | train] - Train Epoch: [153] [998400/1281167 (78%)]	Loss: 0.683199
[2022-06-12 04:30:03 | train] - Train Epoch: [153] [1011200/1281167 (79%)]	Loss: 0.773961
[2022-06-12 04:30:23 | train] - Train Epoch: [153] [1024000/1281167 (80%)]	Loss: 0.741316
[2022-06-12 04:30:43 | train] - Train Epoch: [153] [1036800/1281167 (81%)]	Loss: 0.643172
[2022-06-12 04:31:03 | train] - Train Epoch: [153] [1049600/1281167 (82%)]	Loss: 0.996983
[2022-06-12 04:31:23 | train] - Train Epoch: [153] [1062400/1281167 (83%)]	Loss: 0.730644
[2022-06-12 04:31:42 | train] - Train Epoch: [153] [1075200/1281167 (84%)]	Loss: 1.038042
[2022-06-12 04:32:02 | train] - Train Epoch: [153] [1088000/1281167 (85%)]	Loss: 0.614416
[2022-06-12 04:32:22 | train] - Train Epoch: [153] [1100800/1281167 (86%)]	Loss: 0.940572
[2022-06-12 04:32:41 | train] - Train Epoch: [153] [1113600/1281167 (87%)]	Loss: 0.692024
[2022-06-12 04:33:01 | train] - Train Epoch: [153] [1126400/1281167 (88%)]	Loss: 0.624825
[2022-06-12 04:33:20 | train] - Train Epoch: [153] [1139200/1281167 (89%)]	Loss: 0.778381
[2022-06-12 04:33:39 | train] - Train Epoch: [153] [1152000/1281167 (90%)]	Loss: 0.587498
[2022-06-12 04:33:58 | train] - Train Epoch: [153] [1164800/1281167 (91%)]	Loss: 0.614701
[2022-06-12 04:34:18 | train] - Train Epoch: [153] [1177600/1281167 (92%)]	Loss: 0.500297
[2022-06-12 04:34:37 | train] - Train Epoch: [153] [1190400/1281167 (93%)]	Loss: 0.558994
[2022-06-12 04:34:57 | train] - Train Epoch: [153] [1203200/1281167 (94%)]	Loss: 0.841990
[2022-06-12 04:35:16 | train] - Train Epoch: [153] [1216000/1281167 (95%)]	Loss: 0.864201
[2022-06-12 04:35:36 | train] - Train Epoch: [153] [1228800/1281167 (96%)]	Loss: 0.764722
[2022-06-12 04:35:55 | train] - Train Epoch: [153] [1241600/1281167 (97%)]	Loss: 0.622890
[2022-06-12 04:36:15 | train] - Train Epoch: [153] [1254400/1281167 (98%)]	Loss: 0.790826
[2022-06-12 04:36:35 | train] - Train Epoch: [153] [1267200/1281167 (99%)]	Loss: 0.943037
[2022-06-12 04:36:55 | train] - Train Epoch: [153] [1280000/1281167 (100%)]	Loss: 0.722982
[2022-06-12 04:36:56 | train] - Train Epoch: [153]	 Average Loss: 0.717277	 Total Acc : 82.5537	 Total Top5 Acc : 93.6849
[2022-06-12 04:36:56 | train] - -------153 epoch end-----------
========================================
-------153 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 04:38:26 | train] - 
Epoch [153] Test set: Average loss: 1.4229, Accuracy: 35028/50000 (70.0248%), Top-5 Accuracy: 88.9742%

[2022-06-12 04:38:26 | train] - save intermediate epoch [153] result


[2022-06-12 04:38:38 | train] - -------154 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 04:38:40 | train] - Train Epoch: [154] [0/1281167 (0%)]	Loss: 0.924083
[2022-06-12 04:39:00 | train] - Train Epoch: [154] [12800/1281167 (1%)]	Loss: 0.693224
[2022-06-12 04:39:21 | train] - Train Epoch: [154] [25600/1281167 (2%)]	Loss: 0.782516
[2022-06-12 04:39:41 | train] - Train Epoch: [154] [38400/1281167 (3%)]	Loss: 0.636989
[2022-06-12 04:40:03 | train] - Train Epoch: [154] [51200/1281167 (4%)]	Loss: 0.631002
[2022-06-12 04:40:24 | train] - Train Epoch: [154] [64000/1281167 (5%)]	Loss: 0.682317
[2022-06-12 04:40:44 | train] - Train Epoch: [154] [76800/1281167 (6%)]	Loss: 0.807047
[2022-06-12 04:41:04 | train] - Train Epoch: [154] [89600/1281167 (7%)]	Loss: 0.711211
[2022-06-12 04:41:24 | train] - Train Epoch: [154] [102400/1281167 (8%)]	Loss: 0.636375
[2022-06-12 04:41:43 | train] - Train Epoch: [154] [115200/1281167 (9%)]	Loss: 0.862671
[2022-06-12 04:42:03 | train] - Train Epoch: [154] [128000/1281167 (10%)]	Loss: 0.919826
[2022-06-12 04:42:22 | train] - Train Epoch: [154] [140800/1281167 (11%)]	Loss: 0.653991
[2022-06-12 04:42:42 | train] - Train Epoch: [154] [153600/1281167 (12%)]	Loss: 0.674671
[2022-06-12 04:43:01 | train] - Train Epoch: [154] [166400/1281167 (13%)]	Loss: 0.592740
[2022-06-12 04:43:21 | train] - Train Epoch: [154] [179200/1281167 (14%)]	Loss: 0.573530
[2022-06-12 04:43:40 | train] - Train Epoch: [154] [192000/1281167 (15%)]	Loss: 0.657846
[2022-06-12 04:43:59 | train] - Train Epoch: [154] [204800/1281167 (16%)]	Loss: 0.691284
[2022-06-12 04:44:19 | train] - Train Epoch: [154] [217600/1281167 (17%)]	Loss: 0.727091
[2022-06-12 04:44:40 | train] - Train Epoch: [154] [230400/1281167 (18%)]	Loss: 0.636168
[2022-06-12 04:45:00 | train] - Train Epoch: [154] [243200/1281167 (19%)]	Loss: 0.604104
[2022-06-12 04:45:20 | train] - Train Epoch: [154] [256000/1281167 (20%)]	Loss: 0.589735
[2022-06-12 04:45:38 | train] - Train Epoch: [154] [268800/1281167 (21%)]	Loss: 0.777379
[2022-06-12 04:45:57 | train] - Train Epoch: [154] [281600/1281167 (22%)]	Loss: 0.738779
[2022-06-12 04:46:17 | train] - Train Epoch: [154] [294400/1281167 (23%)]	Loss: 0.591071
[2022-06-12 04:46:37 | train] - Train Epoch: [154] [307200/1281167 (24%)]	Loss: 0.574185
[2022-06-12 04:46:55 | train] - Train Epoch: [154] [320000/1281167 (25%)]	Loss: 0.828520
[2022-06-12 04:47:15 | train] - Train Epoch: [154] [332800/1281167 (26%)]	Loss: 0.775182
[2022-06-12 04:47:34 | train] - Train Epoch: [154] [345600/1281167 (27%)]	Loss: 0.990802
[2022-06-12 04:47:53 | train] - Train Epoch: [154] [358400/1281167 (28%)]	Loss: 0.734674
[2022-06-12 04:48:12 | train] - Train Epoch: [154] [371200/1281167 (29%)]	Loss: 0.775423
[2022-06-12 04:48:32 | train] - Train Epoch: [154] [384000/1281167 (30%)]	Loss: 0.746776
[2022-06-12 04:48:51 | train] - Train Epoch: [154] [396800/1281167 (31%)]	Loss: 0.673984
[2022-06-12 04:49:10 | train] - Train Epoch: [154] [409600/1281167 (32%)]	Loss: 0.876381
[2022-06-12 04:49:29 | train] - Train Epoch: [154] [422400/1281167 (33%)]	Loss: 0.777461
[2022-06-12 04:49:49 | train] - Train Epoch: [154] [435200/1281167 (34%)]	Loss: 0.739936
[2022-06-12 04:50:09 | train] - Train Epoch: [154] [448000/1281167 (35%)]	Loss: 0.612903
[2022-06-12 04:50:28 | train] - Train Epoch: [154] [460800/1281167 (36%)]	Loss: 0.561393
[2022-06-12 04:50:47 | train] - Train Epoch: [154] [473600/1281167 (37%)]	Loss: 0.648985
[2022-06-12 04:51:07 | train] - Train Epoch: [154] [486400/1281167 (38%)]	Loss: 0.869458
[2022-06-12 04:51:26 | train] - Train Epoch: [154] [499200/1281167 (39%)]	Loss: 0.539895
[2022-06-12 04:51:46 | train] - Train Epoch: [154] [512000/1281167 (40%)]	Loss: 0.741287
[2022-06-12 04:52:06 | train] - Train Epoch: [154] [524800/1281167 (41%)]	Loss: 0.769356
[2022-06-12 04:52:25 | train] - Train Epoch: [154] [537600/1281167 (42%)]	Loss: 0.624711
[2022-06-12 04:52:45 | train] - Train Epoch: [154] [550400/1281167 (43%)]	Loss: 0.906727
[2022-06-12 04:53:05 | train] - Train Epoch: [154] [563200/1281167 (44%)]	Loss: 0.770024
[2022-06-12 04:53:24 | train] - Train Epoch: [154] [576000/1281167 (45%)]	Loss: 0.621276
[2022-06-12 04:53:43 | train] - Train Epoch: [154] [588800/1281167 (46%)]	Loss: 0.780170
[2022-06-12 04:54:02 | train] - Train Epoch: [154] [601600/1281167 (47%)]	Loss: 0.565512
[2022-06-12 04:54:22 | train] - Train Epoch: [154] [614400/1281167 (48%)]	Loss: 0.498901
[2022-06-12 04:54:42 | train] - Train Epoch: [154] [627200/1281167 (49%)]	Loss: 0.891437
[2022-06-12 04:55:02 | train] - Train Epoch: [154] [640000/1281167 (50%)]	Loss: 0.779023
[2022-06-12 04:55:22 | train] - Train Epoch: [154] [652800/1281167 (51%)]	Loss: 0.742142
[2022-06-12 04:55:41 | train] - Train Epoch: [154] [665600/1281167 (52%)]	Loss: 0.824491
[2022-06-12 04:56:02 | train] - Train Epoch: [154] [678400/1281167 (53%)]	Loss: 0.830197
[2022-06-12 04:56:21 | train] - Train Epoch: [154] [691200/1281167 (54%)]	Loss: 0.846742
[2022-06-12 04:56:40 | train] - Train Epoch: [154] [704000/1281167 (55%)]	Loss: 0.619372
[2022-06-12 04:57:00 | train] - Train Epoch: [154] [716800/1281167 (56%)]	Loss: 0.883826
[2022-06-12 04:57:20 | train] - Train Epoch: [154] [729600/1281167 (57%)]	Loss: 0.801574
[2022-06-12 04:57:39 | train] - Train Epoch: [154] [742400/1281167 (58%)]	Loss: 0.725694
[2022-06-12 04:57:58 | train] - Train Epoch: [154] [755200/1281167 (59%)]	Loss: 0.593554
[2022-06-12 04:58:18 | train] - Train Epoch: [154] [768000/1281167 (60%)]	Loss: 0.807293
[2022-06-12 04:58:37 | train] - Train Epoch: [154] [780800/1281167 (61%)]	Loss: 0.646669
[2022-06-12 04:58:57 | train] - Train Epoch: [154] [793600/1281167 (62%)]	Loss: 0.702113
[2022-06-12 04:59:16 | train] - Train Epoch: [154] [806400/1281167 (63%)]	Loss: 0.681846
[2022-06-12 04:59:36 | train] - Train Epoch: [154] [819200/1281167 (64%)]	Loss: 0.857537
[2022-06-12 04:59:55 | train] - Train Epoch: [154] [832000/1281167 (65%)]	Loss: 0.484877
[2022-06-12 05:00:14 | train] - Train Epoch: [154] [844800/1281167 (66%)]	Loss: 0.730696
[2022-06-12 05:00:34 | train] - Train Epoch: [154] [857600/1281167 (67%)]	Loss: 0.567217
[2022-06-12 05:00:53 | train] - Train Epoch: [154] [870400/1281167 (68%)]	Loss: 0.615811
[2022-06-12 05:01:13 | train] - Train Epoch: [154] [883200/1281167 (69%)]	Loss: 0.601205
[2022-06-12 05:01:32 | train] - Train Epoch: [154] [896000/1281167 (70%)]	Loss: 0.831253
[2022-06-12 05:01:52 | train] - Train Epoch: [154] [908800/1281167 (71%)]	Loss: 0.648070
[2022-06-12 05:02:11 | train] - Train Epoch: [154] [921600/1281167 (72%)]	Loss: 0.790245
[2022-06-12 05:02:31 | train] - Train Epoch: [154] [934400/1281167 (73%)]	Loss: 0.656194
[2022-06-12 05:02:51 | train] - Train Epoch: [154] [947200/1281167 (74%)]	Loss: 0.745912
[2022-06-12 05:03:10 | train] - Train Epoch: [154] [960000/1281167 (75%)]	Loss: 0.864500
[2022-06-12 05:03:29 | train] - Train Epoch: [154] [972800/1281167 (76%)]	Loss: 0.918172
[2022-06-12 05:03:49 | train] - Train Epoch: [154] [985600/1281167 (77%)]	Loss: 0.638128
[2022-06-12 05:04:08 | train] - Train Epoch: [154] [998400/1281167 (78%)]	Loss: 0.814401
[2022-06-12 05:04:27 | train] - Train Epoch: [154] [1011200/1281167 (79%)]	Loss: 0.729307
[2022-06-12 05:04:47 | train] - Train Epoch: [154] [1024000/1281167 (80%)]	Loss: 0.693357
[2022-06-12 05:05:06 | train] - Train Epoch: [154] [1036800/1281167 (81%)]	Loss: 0.600980
[2022-06-12 05:05:25 | train] - Train Epoch: [154] [1049600/1281167 (82%)]	Loss: 0.750877
[2022-06-12 05:05:45 | train] - Train Epoch: [154] [1062400/1281167 (83%)]	Loss: 0.587772
[2022-06-12 05:06:05 | train] - Train Epoch: [154] [1075200/1281167 (84%)]	Loss: 0.712002
[2022-06-12 05:06:24 | train] - Train Epoch: [154] [1088000/1281167 (85%)]	Loss: 0.587183
[2022-06-12 05:06:43 | train] - Train Epoch: [154] [1100800/1281167 (86%)]	Loss: 0.709337
[2022-06-12 05:07:02 | train] - Train Epoch: [154] [1113600/1281167 (87%)]	Loss: 0.786230
[2022-06-12 05:07:22 | train] - Train Epoch: [154] [1126400/1281167 (88%)]	Loss: 1.045668
[2022-06-12 05:07:41 | train] - Train Epoch: [154] [1139200/1281167 (89%)]	Loss: 0.628874
[2022-06-12 05:08:00 | train] - Train Epoch: [154] [1152000/1281167 (90%)]	Loss: 0.814587
[2022-06-12 05:08:20 | train] - Train Epoch: [154] [1164800/1281167 (91%)]	Loss: 0.744115
[2022-06-12 05:08:39 | train] - Train Epoch: [154] [1177600/1281167 (92%)]	Loss: 0.858512
[2022-06-12 05:08:58 | train] - Train Epoch: [154] [1190400/1281167 (93%)]	Loss: 0.639495
[2022-06-12 05:09:18 | train] - Train Epoch: [154] [1203200/1281167 (94%)]	Loss: 0.365173
[2022-06-12 05:09:37 | train] - Train Epoch: [154] [1216000/1281167 (95%)]	Loss: 0.811499
[2022-06-12 05:09:56 | train] - Train Epoch: [154] [1228800/1281167 (96%)]	Loss: 0.776303
[2022-06-12 05:10:16 | train] - Train Epoch: [154] [1241600/1281167 (97%)]	Loss: 0.536502
[2022-06-12 05:10:35 | train] - Train Epoch: [154] [1254400/1281167 (98%)]	Loss: 0.865758
[2022-06-12 05:10:55 | train] - Train Epoch: [154] [1267200/1281167 (99%)]	Loss: 0.843744
[2022-06-12 05:11:15 | train] - Train Epoch: [154] [1280000/1281167 (100%)]	Loss: 0.518700
[2022-06-12 05:11:17 | train] - Train Epoch: [154]	 Average Loss: 0.717271	 Total Acc : 82.5221	 Total Top5 Acc : 93.7001
[2022-06-12 05:11:17 | train] - -------154 epoch end-----------
========================================
-------154 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 05:12:51 | train] - 
Epoch [154] Test set: Average loss: 1.4182, Accuracy: 34962/50000 (69.8977%), Top-5 Accuracy: 88.9994%

[2022-06-12 05:12:51 | train] - save intermediate epoch [154] result


[2022-06-12 05:13:04 | train] - -------155 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 05:13:05 | train] - Train Epoch: [155] [0/1281167 (0%)]	Loss: 0.511585
[2022-06-12 05:13:27 | train] - Train Epoch: [155] [12800/1281167 (1%)]	Loss: 0.712117
[2022-06-12 05:13:48 | train] - Train Epoch: [155] [25600/1281167 (2%)]	Loss: 0.683004
[2022-06-12 05:14:08 | train] - Train Epoch: [155] [38400/1281167 (3%)]	Loss: 0.633108
[2022-06-12 05:14:29 | train] - Train Epoch: [155] [51200/1281167 (4%)]	Loss: 0.526552
[2022-06-12 05:14:51 | train] - Train Epoch: [155] [64000/1281167 (5%)]	Loss: 0.644870
[2022-06-12 05:15:12 | train] - Train Epoch: [155] [76800/1281167 (6%)]	Loss: 0.449325
[2022-06-12 05:15:34 | train] - Train Epoch: [155] [89600/1281167 (7%)]	Loss: 0.786297
[2022-06-12 05:15:55 | train] - Train Epoch: [155] [102400/1281167 (8%)]	Loss: 0.929493
[2022-06-12 05:16:17 | train] - Train Epoch: [155] [115200/1281167 (9%)]	Loss: 0.630830
[2022-06-12 05:16:38 | train] - Train Epoch: [155] [128000/1281167 (10%)]	Loss: 0.696733
[2022-06-12 05:16:59 | train] - Train Epoch: [155] [140800/1281167 (11%)]	Loss: 0.607341
[2022-06-12 05:17:20 | train] - Train Epoch: [155] [153600/1281167 (12%)]	Loss: 0.664289
[2022-06-12 05:17:42 | train] - Train Epoch: [155] [166400/1281167 (13%)]	Loss: 0.802804
[2022-06-12 05:18:03 | train] - Train Epoch: [155] [179200/1281167 (14%)]	Loss: 0.856500
[2022-06-12 05:18:24 | train] - Train Epoch: [155] [192000/1281167 (15%)]	Loss: 0.639928
[2022-06-12 05:18:46 | train] - Train Epoch: [155] [204800/1281167 (16%)]	Loss: 0.786163
[2022-06-12 05:19:07 | train] - Train Epoch: [155] [217600/1281167 (17%)]	Loss: 0.523762
[2022-06-12 05:19:28 | train] - Train Epoch: [155] [230400/1281167 (18%)]	Loss: 0.565911
[2022-06-12 05:19:50 | train] - Train Epoch: [155] [243200/1281167 (19%)]	Loss: 0.827955
[2022-06-12 05:20:12 | train] - Train Epoch: [155] [256000/1281167 (20%)]	Loss: 0.726810
[2022-06-12 05:20:33 | train] - Train Epoch: [155] [268800/1281167 (21%)]	Loss: 0.616181
[2022-06-12 05:20:55 | train] - Train Epoch: [155] [281600/1281167 (22%)]	Loss: 0.961966
[2022-06-12 05:21:16 | train] - Train Epoch: [155] [294400/1281167 (23%)]	Loss: 0.437173
[2022-06-12 05:21:38 | train] - Train Epoch: [155] [307200/1281167 (24%)]	Loss: 0.585175
[2022-06-12 05:22:00 | train] - Train Epoch: [155] [320000/1281167 (25%)]	Loss: 0.600546
[2022-06-12 05:22:21 | train] - Train Epoch: [155] [332800/1281167 (26%)]	Loss: 0.651576
[2022-06-12 05:22:42 | train] - Train Epoch: [155] [345600/1281167 (27%)]	Loss: 0.594308
[2022-06-12 05:23:04 | train] - Train Epoch: [155] [358400/1281167 (28%)]	Loss: 0.615843
[2022-06-12 05:23:25 | train] - Train Epoch: [155] [371200/1281167 (29%)]	Loss: 0.726625
[2022-06-12 05:23:47 | train] - Train Epoch: [155] [384000/1281167 (30%)]	Loss: 0.628527
[2022-06-12 05:24:08 | train] - Train Epoch: [155] [396800/1281167 (31%)]	Loss: 0.769776
[2022-06-12 05:24:30 | train] - Train Epoch: [155] [409600/1281167 (32%)]	Loss: 0.769503
[2022-06-12 05:24:51 | train] - Train Epoch: [155] [422400/1281167 (33%)]	Loss: 0.488757
[2022-06-12 05:25:13 | train] - Train Epoch: [155] [435200/1281167 (34%)]	Loss: 0.505974
[2022-06-12 05:25:35 | train] - Train Epoch: [155] [448000/1281167 (35%)]	Loss: 0.666643
[2022-06-12 05:25:57 | train] - Train Epoch: [155] [460800/1281167 (36%)]	Loss: 0.614871
[2022-06-12 05:26:19 | train] - Train Epoch: [155] [473600/1281167 (37%)]	Loss: 0.497905
[2022-06-12 05:26:41 | train] - Train Epoch: [155] [486400/1281167 (38%)]	Loss: 0.603460
[2022-06-12 05:27:02 | train] - Train Epoch: [155] [499200/1281167 (39%)]	Loss: 0.747386
[2022-06-12 05:27:24 | train] - Train Epoch: [155] [512000/1281167 (40%)]	Loss: 0.719818
[2022-06-12 05:27:46 | train] - Train Epoch: [155] [524800/1281167 (41%)]	Loss: 0.707041
[2022-06-12 05:28:08 | train] - Train Epoch: [155] [537600/1281167 (42%)]	Loss: 0.706585
[2022-06-12 05:28:29 | train] - Train Epoch: [155] [550400/1281167 (43%)]	Loss: 0.855867
[2022-06-12 05:28:51 | train] - Train Epoch: [155] [563200/1281167 (44%)]	Loss: 0.522732
[2022-06-12 05:29:12 | train] - Train Epoch: [155] [576000/1281167 (45%)]	Loss: 0.832443
[2022-06-12 05:29:33 | train] - Train Epoch: [155] [588800/1281167 (46%)]	Loss: 0.855303
[2022-06-12 05:29:55 | train] - Train Epoch: [155] [601600/1281167 (47%)]	Loss: 0.756352
[2022-06-12 05:30:16 | train] - Train Epoch: [155] [614400/1281167 (48%)]	Loss: 0.701653
[2022-06-12 05:30:38 | train] - Train Epoch: [155] [627200/1281167 (49%)]	Loss: 0.694587
[2022-06-12 05:31:00 | train] - Train Epoch: [155] [640000/1281167 (50%)]	Loss: 0.869636
[2022-06-12 05:31:22 | train] - Train Epoch: [155] [652800/1281167 (51%)]	Loss: 0.537013
[2022-06-12 05:31:44 | train] - Train Epoch: [155] [665600/1281167 (52%)]	Loss: 0.453553
[2022-06-12 05:32:06 | train] - Train Epoch: [155] [678400/1281167 (53%)]	Loss: 0.581244
[2022-06-12 05:32:27 | train] - Train Epoch: [155] [691200/1281167 (54%)]	Loss: 0.905607
[2022-06-12 05:32:48 | train] - Train Epoch: [155] [704000/1281167 (55%)]	Loss: 0.905048
[2022-06-12 05:33:10 | train] - Train Epoch: [155] [716800/1281167 (56%)]	Loss: 0.732283
[2022-06-12 05:33:31 | train] - Train Epoch: [155] [729600/1281167 (57%)]	Loss: 0.795503
[2022-06-12 05:33:53 | train] - Train Epoch: [155] [742400/1281167 (58%)]	Loss: 0.894867
[2022-06-12 05:34:14 | train] - Train Epoch: [155] [755200/1281167 (59%)]	Loss: 0.781304
[2022-06-12 05:34:35 | train] - Train Epoch: [155] [768000/1281167 (60%)]	Loss: 0.756340
[2022-06-12 05:34:57 | train] - Train Epoch: [155] [780800/1281167 (61%)]	Loss: 0.989403
[2022-06-12 05:35:18 | train] - Train Epoch: [155] [793600/1281167 (62%)]	Loss: 0.815603
[2022-06-12 05:35:39 | train] - Train Epoch: [155] [806400/1281167 (63%)]	Loss: 0.511696
[2022-06-12 05:36:01 | train] - Train Epoch: [155] [819200/1281167 (64%)]	Loss: 0.694215
[2022-06-12 05:36:23 | train] - Train Epoch: [155] [832000/1281167 (65%)]	Loss: 0.533009
[2022-06-12 05:36:44 | train] - Train Epoch: [155] [844800/1281167 (66%)]	Loss: 0.591418
[2022-06-12 05:37:05 | train] - Train Epoch: [155] [857600/1281167 (67%)]	Loss: 0.720723
[2022-06-12 05:37:27 | train] - Train Epoch: [155] [870400/1281167 (68%)]	Loss: 0.835289
[2022-06-12 05:37:48 | train] - Train Epoch: [155] [883200/1281167 (69%)]	Loss: 0.784791
[2022-06-12 05:38:10 | train] - Train Epoch: [155] [896000/1281167 (70%)]	Loss: 0.661348
[2022-06-12 05:38:31 | train] - Train Epoch: [155] [908800/1281167 (71%)]	Loss: 0.518286
[2022-06-12 05:38:53 | train] - Train Epoch: [155] [921600/1281167 (72%)]	Loss: 0.904725
[2022-06-12 05:39:13 | train] - Train Epoch: [155] [934400/1281167 (73%)]	Loss: 0.769775
[2022-06-12 05:39:34 | train] - Train Epoch: [155] [947200/1281167 (74%)]	Loss: 0.705796
[2022-06-12 05:39:56 | train] - Train Epoch: [155] [960000/1281167 (75%)]	Loss: 0.780345
[2022-06-12 05:40:17 | train] - Train Epoch: [155] [972800/1281167 (76%)]	Loss: 0.739790
[2022-06-12 05:40:39 | train] - Train Epoch: [155] [985600/1281167 (77%)]	Loss: 0.526428
[2022-06-12 05:41:01 | train] - Train Epoch: [155] [998400/1281167 (78%)]	Loss: 0.763231
[2022-06-12 05:41:23 | train] - Train Epoch: [155] [1011200/1281167 (79%)]	Loss: 0.600204
[2022-06-12 05:41:44 | train] - Train Epoch: [155] [1024000/1281167 (80%)]	Loss: 0.442788
[2022-06-12 05:42:06 | train] - Train Epoch: [155] [1036800/1281167 (81%)]	Loss: 0.691126
[2022-06-12 05:42:28 | train] - Train Epoch: [155] [1049600/1281167 (82%)]	Loss: 0.914882
[2022-06-12 05:42:49 | train] - Train Epoch: [155] [1062400/1281167 (83%)]	Loss: 0.612969
[2022-06-12 05:43:11 | train] - Train Epoch: [155] [1075200/1281167 (84%)]	Loss: 0.606273
[2022-06-12 05:43:33 | train] - Train Epoch: [155] [1088000/1281167 (85%)]	Loss: 0.667627
[2022-06-12 05:43:55 | train] - Train Epoch: [155] [1100800/1281167 (86%)]	Loss: 0.959186
[2022-06-12 05:44:16 | train] - Train Epoch: [155] [1113600/1281167 (87%)]	Loss: 0.826268
[2022-06-12 05:44:38 | train] - Train Epoch: [155] [1126400/1281167 (88%)]	Loss: 0.828313
[2022-06-12 05:45:00 | train] - Train Epoch: [155] [1139200/1281167 (89%)]	Loss: 0.787182
[2022-06-12 05:45:22 | train] - Train Epoch: [155] [1152000/1281167 (90%)]	Loss: 0.515898
[2022-06-12 05:45:43 | train] - Train Epoch: [155] [1164800/1281167 (91%)]	Loss: 0.894281
[2022-06-12 05:46:05 | train] - Train Epoch: [155] [1177600/1281167 (92%)]	Loss: 0.674423
[2022-06-12 05:46:26 | train] - Train Epoch: [155] [1190400/1281167 (93%)]	Loss: 0.750230
[2022-06-12 05:46:47 | train] - Train Epoch: [155] [1203200/1281167 (94%)]	Loss: 0.878162
[2022-06-12 05:47:09 | train] - Train Epoch: [155] [1216000/1281167 (95%)]	Loss: 0.783920
[2022-06-12 05:47:30 | train] - Train Epoch: [155] [1228800/1281167 (96%)]	Loss: 0.498893
[2022-06-12 05:47:52 | train] - Train Epoch: [155] [1241600/1281167 (97%)]	Loss: 0.420502
[2022-06-12 05:48:13 | train] - Train Epoch: [155] [1254400/1281167 (98%)]	Loss: 0.584870
[2022-06-12 05:48:34 | train] - Train Epoch: [155] [1267200/1281167 (99%)]	Loss: 0.693053
[2022-06-12 05:48:55 | train] - Train Epoch: [155] [1280000/1281167 (100%)]	Loss: 0.677104
[2022-06-12 05:48:57 | train] - Train Epoch: [155]	 Average Loss: 0.714046	 Total Acc : 82.6183	 Total Top5 Acc : 93.7363
[2022-06-12 05:48:57 | train] - -------155 epoch end-----------
========================================
-------155 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 05:50:32 | train] - 
Epoch [155] Test set: Average loss: 1.4261, Accuracy: 34982/50000 (69.9329%), Top-5 Accuracy: 88.9011%

[2022-06-12 05:50:32 | train] - save intermediate epoch [155] result


[2022-06-12 05:50:45 | train] - -------156 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 05:50:47 | train] - Train Epoch: [156] [0/1281167 (0%)]	Loss: 0.845110
[2022-06-12 05:51:09 | train] - Train Epoch: [156] [12800/1281167 (1%)]	Loss: 1.040177
[2022-06-12 05:51:31 | train] - Train Epoch: [156] [25600/1281167 (2%)]	Loss: 0.614174
[2022-06-12 05:51:53 | train] - Train Epoch: [156] [38400/1281167 (3%)]	Loss: 0.524058
[2022-06-12 05:52:14 | train] - Train Epoch: [156] [51200/1281167 (4%)]	Loss: 0.965868
[2022-06-12 05:52:37 | train] - Train Epoch: [156] [64000/1281167 (5%)]	Loss: 0.654422
[2022-06-12 05:52:59 | train] - Train Epoch: [156] [76800/1281167 (6%)]	Loss: 0.803155
[2022-06-12 05:53:21 | train] - Train Epoch: [156] [89600/1281167 (7%)]	Loss: 1.161139
[2022-06-12 05:53:43 | train] - Train Epoch: [156] [102400/1281167 (8%)]	Loss: 0.674901
[2022-06-12 05:54:04 | train] - Train Epoch: [156] [115200/1281167 (9%)]	Loss: 0.726469
[2022-06-12 05:54:26 | train] - Train Epoch: [156] [128000/1281167 (10%)]	Loss: 0.542209
[2022-06-12 05:54:48 | train] - Train Epoch: [156] [140800/1281167 (11%)]	Loss: 0.666733
[2022-06-12 05:55:10 | train] - Train Epoch: [156] [153600/1281167 (12%)]	Loss: 0.693883
[2022-06-12 05:55:31 | train] - Train Epoch: [156] [166400/1281167 (13%)]	Loss: 0.574624
[2022-06-12 05:55:53 | train] - Train Epoch: [156] [179200/1281167 (14%)]	Loss: 0.511826
[2022-06-12 05:56:16 | train] - Train Epoch: [156] [192000/1281167 (15%)]	Loss: 0.653045
[2022-06-12 05:56:37 | train] - Train Epoch: [156] [204800/1281167 (16%)]	Loss: 0.650623
[2022-06-12 05:56:59 | train] - Train Epoch: [156] [217600/1281167 (17%)]	Loss: 0.761248
[2022-06-12 05:57:20 | train] - Train Epoch: [156] [230400/1281167 (18%)]	Loss: 0.677490
[2022-06-12 05:57:42 | train] - Train Epoch: [156] [243200/1281167 (19%)]	Loss: 0.628806
[2022-06-12 05:58:04 | train] - Train Epoch: [156] [256000/1281167 (20%)]	Loss: 0.751992
[2022-06-12 05:58:26 | train] - Train Epoch: [156] [268800/1281167 (21%)]	Loss: 0.585292
[2022-06-12 05:58:48 | train] - Train Epoch: [156] [281600/1281167 (22%)]	Loss: 0.676029
[2022-06-12 05:59:09 | train] - Train Epoch: [156] [294400/1281167 (23%)]	Loss: 0.885421
[2022-06-12 05:59:31 | train] - Train Epoch: [156] [307200/1281167 (24%)]	Loss: 0.880111
[2022-06-12 05:59:52 | train] - Train Epoch: [156] [320000/1281167 (25%)]	Loss: 0.905715
[2022-06-12 06:00:15 | train] - Train Epoch: [156] [332800/1281167 (26%)]	Loss: 0.771042
[2022-06-12 06:00:36 | train] - Train Epoch: [156] [345600/1281167 (27%)]	Loss: 0.903026
[2022-06-12 06:00:58 | train] - Train Epoch: [156] [358400/1281167 (28%)]	Loss: 0.747201
[2022-06-12 06:01:19 | train] - Train Epoch: [156] [371200/1281167 (29%)]	Loss: 0.691668
[2022-06-12 06:01:41 | train] - Train Epoch: [156] [384000/1281167 (30%)]	Loss: 0.502324
[2022-06-12 06:02:03 | train] - Train Epoch: [156] [396800/1281167 (31%)]	Loss: 0.520143
[2022-06-12 06:02:24 | train] - Train Epoch: [156] [409600/1281167 (32%)]	Loss: 0.709797
[2022-06-12 06:02:46 | train] - Train Epoch: [156] [422400/1281167 (33%)]	Loss: 0.655882
[2022-06-12 06:03:08 | train] - Train Epoch: [156] [435200/1281167 (34%)]	Loss: 0.726301
[2022-06-12 06:03:29 | train] - Train Epoch: [156] [448000/1281167 (35%)]	Loss: 0.592193
[2022-06-12 06:03:51 | train] - Train Epoch: [156] [460800/1281167 (36%)]	Loss: 0.693407
[2022-06-12 06:04:13 | train] - Train Epoch: [156] [473600/1281167 (37%)]	Loss: 0.796771
[2022-06-12 06:04:35 | train] - Train Epoch: [156] [486400/1281167 (38%)]	Loss: 0.778049
[2022-06-12 06:04:57 | train] - Train Epoch: [156] [499200/1281167 (39%)]	Loss: 0.670339
[2022-06-12 06:05:18 | train] - Train Epoch: [156] [512000/1281167 (40%)]	Loss: 0.721403
[2022-06-12 06:05:40 | train] - Train Epoch: [156] [524800/1281167 (41%)]	Loss: 0.765985
[2022-06-12 06:06:02 | train] - Train Epoch: [156] [537600/1281167 (42%)]	Loss: 0.566980
[2022-06-12 06:06:24 | train] - Train Epoch: [156] [550400/1281167 (43%)]	Loss: 0.857277
[2022-06-12 06:06:45 | train] - Train Epoch: [156] [563200/1281167 (44%)]	Loss: 0.743181
[2022-06-12 06:07:07 | train] - Train Epoch: [156] [576000/1281167 (45%)]	Loss: 0.683675
[2022-06-12 06:07:29 | train] - Train Epoch: [156] [588800/1281167 (46%)]	Loss: 0.581425
[2022-06-12 06:07:51 | train] - Train Epoch: [156] [601600/1281167 (47%)]	Loss: 0.803330
[2022-06-12 06:08:13 | train] - Train Epoch: [156] [614400/1281167 (48%)]	Loss: 0.597010
[2022-06-12 06:08:34 | train] - Train Epoch: [156] [627200/1281167 (49%)]	Loss: 0.484885
[2022-06-12 06:08:56 | train] - Train Epoch: [156] [640000/1281167 (50%)]	Loss: 0.593417
[2022-06-12 06:09:18 | train] - Train Epoch: [156] [652800/1281167 (51%)]	Loss: 0.766292
[2022-06-12 06:09:40 | train] - Train Epoch: [156] [665600/1281167 (52%)]	Loss: 0.633878
[2022-06-12 06:10:01 | train] - Train Epoch: [156] [678400/1281167 (53%)]	Loss: 0.704663
[2022-06-12 06:10:23 | train] - Train Epoch: [156] [691200/1281167 (54%)]	Loss: 0.649438
[2022-06-12 06:10:45 | train] - Train Epoch: [156] [704000/1281167 (55%)]	Loss: 0.654537
[2022-06-12 06:11:07 | train] - Train Epoch: [156] [716800/1281167 (56%)]	Loss: 0.691630
[2022-06-12 06:11:29 | train] - Train Epoch: [156] [729600/1281167 (57%)]	Loss: 0.615451
[2022-06-12 06:11:50 | train] - Train Epoch: [156] [742400/1281167 (58%)]	Loss: 0.857517
[2022-06-12 06:12:12 | train] - Train Epoch: [156] [755200/1281167 (59%)]	Loss: 0.704945
[2022-06-12 06:12:34 | train] - Train Epoch: [156] [768000/1281167 (60%)]	Loss: 0.693895
[2022-06-12 06:12:55 | train] - Train Epoch: [156] [780800/1281167 (61%)]	Loss: 0.939860
[2022-06-12 06:13:17 | train] - Train Epoch: [156] [793600/1281167 (62%)]	Loss: 0.656396
[2022-06-12 06:13:39 | train] - Train Epoch: [156] [806400/1281167 (63%)]	Loss: 0.564329
[2022-06-12 06:14:00 | train] - Train Epoch: [156] [819200/1281167 (64%)]	Loss: 0.574621
[2022-06-12 06:14:22 | train] - Train Epoch: [156] [832000/1281167 (65%)]	Loss: 0.934619
[2022-06-12 06:14:43 | train] - Train Epoch: [156] [844800/1281167 (66%)]	Loss: 0.581176
[2022-06-12 06:15:05 | train] - Train Epoch: [156] [857600/1281167 (67%)]	Loss: 0.809529
[2022-06-12 06:15:27 | train] - Train Epoch: [156] [870400/1281167 (68%)]	Loss: 0.795880
[2022-06-12 06:15:49 | train] - Train Epoch: [156] [883200/1281167 (69%)]	Loss: 0.578519
[2022-06-12 06:16:11 | train] - Train Epoch: [156] [896000/1281167 (70%)]	Loss: 0.590002
[2022-06-12 06:16:33 | train] - Train Epoch: [156] [908800/1281167 (71%)]	Loss: 0.632674
[2022-06-12 06:16:55 | train] - Train Epoch: [156] [921600/1281167 (72%)]	Loss: 0.995501
[2022-06-12 06:17:16 | train] - Train Epoch: [156] [934400/1281167 (73%)]	Loss: 0.611313
[2022-06-12 06:17:38 | train] - Train Epoch: [156] [947200/1281167 (74%)]	Loss: 0.531051
[2022-06-12 06:18:00 | train] - Train Epoch: [156] [960000/1281167 (75%)]	Loss: 0.929696
[2022-06-12 06:18:21 | train] - Train Epoch: [156] [972800/1281167 (76%)]	Loss: 0.741798
[2022-06-12 06:18:43 | train] - Train Epoch: [156] [985600/1281167 (77%)]	Loss: 0.639865
[2022-06-12 06:19:05 | train] - Train Epoch: [156] [998400/1281167 (78%)]	Loss: 0.836085
[2022-06-12 06:19:27 | train] - Train Epoch: [156] [1011200/1281167 (79%)]	Loss: 0.656766
[2022-06-12 06:19:48 | train] - Train Epoch: [156] [1024000/1281167 (80%)]	Loss: 0.836163
[2022-06-12 06:20:10 | train] - Train Epoch: [156] [1036800/1281167 (81%)]	Loss: 0.647083
[2022-06-12 06:20:32 | train] - Train Epoch: [156] [1049600/1281167 (82%)]	Loss: 0.875265
[2022-06-12 06:20:53 | train] - Train Epoch: [156] [1062400/1281167 (83%)]	Loss: 0.662793
[2022-06-12 06:21:15 | train] - Train Epoch: [156] [1075200/1281167 (84%)]	Loss: 0.914595
[2022-06-12 06:21:37 | train] - Train Epoch: [156] [1088000/1281167 (85%)]	Loss: 0.909486
[2022-06-12 06:21:59 | train] - Train Epoch: [156] [1100800/1281167 (86%)]	Loss: 0.826213
[2022-06-12 06:22:21 | train] - Train Epoch: [156] [1113600/1281167 (87%)]	Loss: 0.529081
[2022-06-12 06:22:43 | train] - Train Epoch: [156] [1126400/1281167 (88%)]	Loss: 0.745714
[2022-06-12 06:23:04 | train] - Train Epoch: [156] [1139200/1281167 (89%)]	Loss: 0.652576
[2022-06-12 06:23:27 | train] - Train Epoch: [156] [1152000/1281167 (90%)]	Loss: 0.639224
[2022-06-12 06:23:49 | train] - Train Epoch: [156] [1164800/1281167 (91%)]	Loss: 0.523200
[2022-06-12 06:24:11 | train] - Train Epoch: [156] [1177600/1281167 (92%)]	Loss: 0.808925
[2022-06-12 06:24:33 | train] - Train Epoch: [156] [1190400/1281167 (93%)]	Loss: 0.628356
[2022-06-12 06:24:54 | train] - Train Epoch: [156] [1203200/1281167 (94%)]	Loss: 0.586538
[2022-06-12 06:25:16 | train] - Train Epoch: [156] [1216000/1281167 (95%)]	Loss: 0.582265
[2022-06-12 06:25:38 | train] - Train Epoch: [156] [1228800/1281167 (96%)]	Loss: 0.690412
[2022-06-12 06:26:00 | train] - Train Epoch: [156] [1241600/1281167 (97%)]	Loss: 0.685697
[2022-06-12 06:26:21 | train] - Train Epoch: [156] [1254400/1281167 (98%)]	Loss: 0.769345
[2022-06-12 06:26:43 | train] - Train Epoch: [156] [1267200/1281167 (99%)]	Loss: 0.864177
[2022-06-12 06:27:05 | train] - Train Epoch: [156] [1280000/1281167 (100%)]	Loss: 0.816408
[2022-06-12 06:27:07 | train] - Train Epoch: [156]	 Average Loss: 0.713217	 Total Acc : 82.6588	 Total Top5 Acc : 93.7331
[2022-06-12 06:27:07 | train] - -------156 epoch end-----------
========================================
-------156 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 06:28:38 | train] - 
Epoch [156] Test set: Average loss: 1.4379, Accuracy: 34933/50000 (69.8362%), Top-5 Accuracy: 88.9274%

[2022-06-12 06:28:38 | train] - save intermediate epoch [156] result


[2022-06-12 06:28:51 | train] - -------157 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 06:28:53 | train] - Train Epoch: [157] [0/1281167 (0%)]	Loss: 0.766380
[2022-06-12 06:29:16 | train] - Train Epoch: [157] [12800/1281167 (1%)]	Loss: 0.836351
[2022-06-12 06:29:37 | train] - Train Epoch: [157] [25600/1281167 (2%)]	Loss: 0.773857
[2022-06-12 06:29:59 | train] - Train Epoch: [157] [38400/1281167 (3%)]	Loss: 0.811684
[2022-06-12 06:30:21 | train] - Train Epoch: [157] [51200/1281167 (4%)]	Loss: 0.841966
[2022-06-12 06:30:43 | train] - Train Epoch: [157] [64000/1281167 (5%)]	Loss: 0.588916
[2022-06-12 06:31:04 | train] - Train Epoch: [157] [76800/1281167 (6%)]	Loss: 0.738959
[2022-06-12 06:31:26 | train] - Train Epoch: [157] [89600/1281167 (7%)]	Loss: 0.520886
[2022-06-12 06:31:47 | train] - Train Epoch: [157] [102400/1281167 (8%)]	Loss: 0.763854
[2022-06-12 06:32:09 | train] - Train Epoch: [157] [115200/1281167 (9%)]	Loss: 0.594219
[2022-06-12 06:32:31 | train] - Train Epoch: [157] [128000/1281167 (10%)]	Loss: 0.995024
[2022-06-12 06:32:53 | train] - Train Epoch: [157] [140800/1281167 (11%)]	Loss: 0.684431
[2022-06-12 06:33:15 | train] - Train Epoch: [157] [153600/1281167 (12%)]	Loss: 0.845421
[2022-06-12 06:33:37 | train] - Train Epoch: [157] [166400/1281167 (13%)]	Loss: 0.752373
[2022-06-12 06:33:58 | train] - Train Epoch: [157] [179200/1281167 (14%)]	Loss: 0.804656
[2022-06-12 06:34:20 | train] - Train Epoch: [157] [192000/1281167 (15%)]	Loss: 0.694891
[2022-06-12 06:34:42 | train] - Train Epoch: [157] [204800/1281167 (16%)]	Loss: 0.636795
[2022-06-12 06:35:04 | train] - Train Epoch: [157] [217600/1281167 (17%)]	Loss: 0.623885
[2022-06-12 06:35:25 | train] - Train Epoch: [157] [230400/1281167 (18%)]	Loss: 0.501837
[2022-06-12 06:35:47 | train] - Train Epoch: [157] [243200/1281167 (19%)]	Loss: 0.619959
[2022-06-12 06:36:08 | train] - Train Epoch: [157] [256000/1281167 (20%)]	Loss: 0.740186
[2022-06-12 06:36:30 | train] - Train Epoch: [157] [268800/1281167 (21%)]	Loss: 0.757310
[2022-06-12 06:36:52 | train] - Train Epoch: [157] [281600/1281167 (22%)]	Loss: 0.633368
[2022-06-12 06:37:14 | train] - Train Epoch: [157] [294400/1281167 (23%)]	Loss: 0.597389
[2022-06-12 06:37:36 | train] - Train Epoch: [157] [307200/1281167 (24%)]	Loss: 0.799250
[2022-06-12 06:37:58 | train] - Train Epoch: [157] [320000/1281167 (25%)]	Loss: 0.567655
[2022-06-12 06:38:20 | train] - Train Epoch: [157] [332800/1281167 (26%)]	Loss: 0.708240
[2022-06-12 06:38:41 | train] - Train Epoch: [157] [345600/1281167 (27%)]	Loss: 0.615905
[2022-06-12 06:39:03 | train] - Train Epoch: [157] [358400/1281167 (28%)]	Loss: 0.559228
[2022-06-12 06:39:25 | train] - Train Epoch: [157] [371200/1281167 (29%)]	Loss: 0.895093
[2022-06-12 06:39:47 | train] - Train Epoch: [157] [384000/1281167 (30%)]	Loss: 0.704189
[2022-06-12 06:40:08 | train] - Train Epoch: [157] [396800/1281167 (31%)]	Loss: 0.535195
[2022-06-12 06:40:29 | train] - Train Epoch: [157] [409600/1281167 (32%)]	Loss: 0.591959
[2022-06-12 06:40:51 | train] - Train Epoch: [157] [422400/1281167 (33%)]	Loss: 0.722433
[2022-06-12 06:41:12 | train] - Train Epoch: [157] [435200/1281167 (34%)]	Loss: 0.735845
[2022-06-12 06:41:34 | train] - Train Epoch: [157] [448000/1281167 (35%)]	Loss: 0.702701
[2022-06-12 06:41:55 | train] - Train Epoch: [157] [460800/1281167 (36%)]	Loss: 0.695558
[2022-06-12 06:42:17 | train] - Train Epoch: [157] [473600/1281167 (37%)]	Loss: 0.784283
[2022-06-12 06:42:38 | train] - Train Epoch: [157] [486400/1281167 (38%)]	Loss: 0.639264
[2022-06-12 06:43:00 | train] - Train Epoch: [157] [499200/1281167 (39%)]	Loss: 0.898807
[2022-06-12 06:43:21 | train] - Train Epoch: [157] [512000/1281167 (40%)]	Loss: 0.597442
[2022-06-12 06:43:43 | train] - Train Epoch: [157] [524800/1281167 (41%)]	Loss: 0.617817
[2022-06-12 06:44:04 | train] - Train Epoch: [157] [537600/1281167 (42%)]	Loss: 0.769353
[2022-06-12 06:44:25 | train] - Train Epoch: [157] [550400/1281167 (43%)]	Loss: 0.574536
[2022-06-12 06:44:46 | train] - Train Epoch: [157] [563200/1281167 (44%)]	Loss: 0.582564
[2022-06-12 06:45:08 | train] - Train Epoch: [157] [576000/1281167 (45%)]	Loss: 0.387019
[2022-06-12 06:45:29 | train] - Train Epoch: [157] [588800/1281167 (46%)]	Loss: 1.102768
[2022-06-12 06:45:51 | train] - Train Epoch: [157] [601600/1281167 (47%)]	Loss: 0.672020
[2022-06-12 06:46:13 | train] - Train Epoch: [157] [614400/1281167 (48%)]	Loss: 0.634107
[2022-06-12 06:46:36 | train] - Train Epoch: [157] [627200/1281167 (49%)]	Loss: 0.601976
[2022-06-12 06:46:56 | train] - Train Epoch: [157] [640000/1281167 (50%)]	Loss: 0.631522
[2022-06-12 06:47:18 | train] - Train Epoch: [157] [652800/1281167 (51%)]	Loss: 0.811548
[2022-06-12 06:47:39 | train] - Train Epoch: [157] [665600/1281167 (52%)]	Loss: 0.698001
[2022-06-12 06:48:01 | train] - Train Epoch: [157] [678400/1281167 (53%)]	Loss: 0.719966
[2022-06-12 06:48:22 | train] - Train Epoch: [157] [691200/1281167 (54%)]	Loss: 0.596517
[2022-06-12 06:48:44 | train] - Train Epoch: [157] [704000/1281167 (55%)]	Loss: 0.827893
[2022-06-12 06:49:06 | train] - Train Epoch: [157] [716800/1281167 (56%)]	Loss: 0.498917
[2022-06-12 06:49:28 | train] - Train Epoch: [157] [729600/1281167 (57%)]	Loss: 0.749008
[2022-06-12 06:49:49 | train] - Train Epoch: [157] [742400/1281167 (58%)]	Loss: 0.785065
[2022-06-12 06:50:12 | train] - Train Epoch: [157] [755200/1281167 (59%)]	Loss: 0.735644
[2022-06-12 06:50:33 | train] - Train Epoch: [157] [768000/1281167 (60%)]	Loss: 0.556324
[2022-06-12 06:50:56 | train] - Train Epoch: [157] [780800/1281167 (61%)]	Loss: 0.853963
[2022-06-12 06:51:17 | train] - Train Epoch: [157] [793600/1281167 (62%)]	Loss: 0.742194
[2022-06-12 06:51:39 | train] - Train Epoch: [157] [806400/1281167 (63%)]	Loss: 0.764873
[2022-06-12 06:51:59 | train] - Train Epoch: [157] [819200/1281167 (64%)]	Loss: 0.796904
[2022-06-12 06:52:20 | train] - Train Epoch: [157] [832000/1281167 (65%)]	Loss: 0.685279
[2022-06-12 06:52:42 | train] - Train Epoch: [157] [844800/1281167 (66%)]	Loss: 0.660354
[2022-06-12 06:53:03 | train] - Train Epoch: [157] [857600/1281167 (67%)]	Loss: 0.580345
[2022-06-12 06:53:25 | train] - Train Epoch: [157] [870400/1281167 (68%)]	Loss: 0.624059
[2022-06-12 06:53:47 | train] - Train Epoch: [157] [883200/1281167 (69%)]	Loss: 0.706506
[2022-06-12 06:54:08 | train] - Train Epoch: [157] [896000/1281167 (70%)]	Loss: 0.953649
[2022-06-12 06:54:29 | train] - Train Epoch: [157] [908800/1281167 (71%)]	Loss: 0.624178
[2022-06-12 06:54:51 | train] - Train Epoch: [157] [921600/1281167 (72%)]	Loss: 0.691147
[2022-06-12 06:55:12 | train] - Train Epoch: [157] [934400/1281167 (73%)]	Loss: 0.779695
[2022-06-12 06:55:34 | train] - Train Epoch: [157] [947200/1281167 (74%)]	Loss: 0.841612
[2022-06-12 06:55:56 | train] - Train Epoch: [157] [960000/1281167 (75%)]	Loss: 0.781343
[2022-06-12 06:56:18 | train] - Train Epoch: [157] [972800/1281167 (76%)]	Loss: 0.624037
[2022-06-12 06:56:40 | train] - Train Epoch: [157] [985600/1281167 (77%)]	Loss: 0.678010
[2022-06-12 06:57:02 | train] - Train Epoch: [157] [998400/1281167 (78%)]	Loss: 0.718246
[2022-06-12 06:57:23 | train] - Train Epoch: [157] [1011200/1281167 (79%)]	Loss: 0.703304
[2022-06-12 06:57:45 | train] - Train Epoch: [157] [1024000/1281167 (80%)]	Loss: 1.026164
[2022-06-12 06:58:07 | train] - Train Epoch: [157] [1036800/1281167 (81%)]	Loss: 0.531108
[2022-06-12 06:58:29 | train] - Train Epoch: [157] [1049600/1281167 (82%)]	Loss: 0.659390
[2022-06-12 06:58:51 | train] - Train Epoch: [157] [1062400/1281167 (83%)]	Loss: 0.595946
[2022-06-12 06:59:13 | train] - Train Epoch: [157] [1075200/1281167 (84%)]	Loss: 0.626827
[2022-06-12 06:59:35 | train] - Train Epoch: [157] [1088000/1281167 (85%)]	Loss: 0.793259
[2022-06-12 06:59:57 | train] - Train Epoch: [157] [1100800/1281167 (86%)]	Loss: 0.697066
[2022-06-12 07:00:19 | train] - Train Epoch: [157] [1113600/1281167 (87%)]	Loss: 0.597623
[2022-06-12 07:00:41 | train] - Train Epoch: [157] [1126400/1281167 (88%)]	Loss: 0.810032
[2022-06-12 07:01:02 | train] - Train Epoch: [157] [1139200/1281167 (89%)]	Loss: 0.951466
[2022-06-12 07:01:24 | train] - Train Epoch: [157] [1152000/1281167 (90%)]	Loss: 0.678548
[2022-06-12 07:01:46 | train] - Train Epoch: [157] [1164800/1281167 (91%)]	Loss: 0.744444
[2022-06-12 07:02:08 | train] - Train Epoch: [157] [1177600/1281167 (92%)]	Loss: 0.704859
[2022-06-12 07:02:30 | train] - Train Epoch: [157] [1190400/1281167 (93%)]	Loss: 0.521227
[2022-06-12 07:02:51 | train] - Train Epoch: [157] [1203200/1281167 (94%)]	Loss: 0.657161
[2022-06-12 07:03:13 | train] - Train Epoch: [157] [1216000/1281167 (95%)]	Loss: 0.655092
[2022-06-12 07:03:35 | train] - Train Epoch: [157] [1228800/1281167 (96%)]	Loss: 0.433149
[2022-06-12 07:03:56 | train] - Train Epoch: [157] [1241600/1281167 (97%)]	Loss: 0.720684
[2022-06-12 07:04:17 | train] - Train Epoch: [157] [1254400/1281167 (98%)]	Loss: 0.780133
[2022-06-12 07:04:39 | train] - Train Epoch: [157] [1267200/1281167 (99%)]	Loss: 0.614688
[2022-06-12 07:05:01 | train] - Train Epoch: [157] [1280000/1281167 (100%)]	Loss: 0.543087
[2022-06-12 07:05:03 | train] - Train Epoch: [157]	 Average Loss: 0.710922	 Total Acc : 82.7163	 Total Top5 Acc : 93.7550
[2022-06-12 07:05:03 | train] - -------157 epoch end-----------
========================================
-------157 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 07:06:37 | train] - 
Epoch [157] Test set: Average loss: 1.4256, Accuracy: 34949/50000 (69.8681%), Top-5 Accuracy: 88.9051%

[2022-06-12 07:06:37 | train] - save intermediate epoch [157] result


[2022-06-12 07:06:51 | train] - -------158 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 07:06:53 | train] - Train Epoch: [158] [0/1281167 (0%)]	Loss: 0.733885
[2022-06-12 07:07:15 | train] - Train Epoch: [158] [12800/1281167 (1%)]	Loss: 0.858795
[2022-06-12 07:07:37 | train] - Train Epoch: [158] [25600/1281167 (2%)]	Loss: 0.868316
[2022-06-12 07:07:59 | train] - Train Epoch: [158] [38400/1281167 (3%)]	Loss: 0.809557
[2022-06-12 07:08:21 | train] - Train Epoch: [158] [51200/1281167 (4%)]	Loss: 0.614685
[2022-06-12 07:08:43 | train] - Train Epoch: [158] [64000/1281167 (5%)]	Loss: 0.668118
[2022-06-12 07:09:05 | train] - Train Epoch: [158] [76800/1281167 (6%)]	Loss: 0.605512
[2022-06-12 07:09:27 | train] - Train Epoch: [158] [89600/1281167 (7%)]	Loss: 0.712166
[2022-06-12 07:09:50 | train] - Train Epoch: [158] [102400/1281167 (8%)]	Loss: 0.717603
[2022-06-12 07:10:11 | train] - Train Epoch: [158] [115200/1281167 (9%)]	Loss: 0.640694
[2022-06-12 07:10:33 | train] - Train Epoch: [158] [128000/1281167 (10%)]	Loss: 0.728144
[2022-06-12 07:10:56 | train] - Train Epoch: [158] [140800/1281167 (11%)]	Loss: 0.532710
[2022-06-12 07:11:18 | train] - Train Epoch: [158] [153600/1281167 (12%)]	Loss: 0.437720
[2022-06-12 07:11:39 | train] - Train Epoch: [158] [166400/1281167 (13%)]	Loss: 0.656302
[2022-06-12 07:12:01 | train] - Train Epoch: [158] [179200/1281167 (14%)]	Loss: 0.477288
[2022-06-12 07:12:23 | train] - Train Epoch: [158] [192000/1281167 (15%)]	Loss: 0.411074
[2022-06-12 07:12:44 | train] - Train Epoch: [158] [204800/1281167 (16%)]	Loss: 0.687462
[2022-06-12 07:13:06 | train] - Train Epoch: [158] [217600/1281167 (17%)]	Loss: 0.990459
[2022-06-12 07:13:28 | train] - Train Epoch: [158] [230400/1281167 (18%)]	Loss: 0.833099
[2022-06-12 07:13:50 | train] - Train Epoch: [158] [243200/1281167 (19%)]	Loss: 0.518667
[2022-06-12 07:14:13 | train] - Train Epoch: [158] [256000/1281167 (20%)]	Loss: 0.687950
[2022-06-12 07:14:34 | train] - Train Epoch: [158] [268800/1281167 (21%)]	Loss: 0.651878
[2022-06-12 07:14:55 | train] - Train Epoch: [158] [281600/1281167 (22%)]	Loss: 0.725357
[2022-06-12 07:15:17 | train] - Train Epoch: [158] [294400/1281167 (23%)]	Loss: 0.796757
[2022-06-12 07:15:38 | train] - Train Epoch: [158] [307200/1281167 (24%)]	Loss: 0.646858
[2022-06-12 07:16:00 | train] - Train Epoch: [158] [320000/1281167 (25%)]	Loss: 0.870274
[2022-06-12 07:16:22 | train] - Train Epoch: [158] [332800/1281167 (26%)]	Loss: 0.672301
[2022-06-12 07:16:43 | train] - Train Epoch: [158] [345600/1281167 (27%)]	Loss: 0.594553
[2022-06-12 07:17:05 | train] - Train Epoch: [158] [358400/1281167 (28%)]	Loss: 0.501554
[2022-06-12 07:17:27 | train] - Train Epoch: [158] [371200/1281167 (29%)]	Loss: 0.535567
[2022-06-12 07:17:48 | train] - Train Epoch: [158] [384000/1281167 (30%)]	Loss: 0.684812
[2022-06-12 07:18:09 | train] - Train Epoch: [158] [396800/1281167 (31%)]	Loss: 0.658129
[2022-06-12 07:18:31 | train] - Train Epoch: [158] [409600/1281167 (32%)]	Loss: 0.779467
[2022-06-12 07:18:53 | train] - Train Epoch: [158] [422400/1281167 (33%)]	Loss: 0.771973
[2022-06-12 07:19:15 | train] - Train Epoch: [158] [435200/1281167 (34%)]	Loss: 0.836163
[2022-06-12 07:19:36 | train] - Train Epoch: [158] [448000/1281167 (35%)]	Loss: 0.749769
[2022-06-12 07:19:58 | train] - Train Epoch: [158] [460800/1281167 (36%)]	Loss: 0.642730
[2022-06-12 07:20:20 | train] - Train Epoch: [158] [473600/1281167 (37%)]	Loss: 0.590411
[2022-06-12 07:20:42 | train] - Train Epoch: [158] [486400/1281167 (38%)]	Loss: 0.663498
[2022-06-12 07:21:05 | train] - Train Epoch: [158] [499200/1281167 (39%)]	Loss: 0.491069
[2022-06-12 07:21:27 | train] - Train Epoch: [158] [512000/1281167 (40%)]	Loss: 0.678578
[2022-06-12 07:21:48 | train] - Train Epoch: [158] [524800/1281167 (41%)]	Loss: 0.897322
[2022-06-12 07:22:10 | train] - Train Epoch: [158] [537600/1281167 (42%)]	Loss: 0.649450
[2022-06-12 07:22:32 | train] - Train Epoch: [158] [550400/1281167 (43%)]	Loss: 0.672018
[2022-06-12 07:22:54 | train] - Train Epoch: [158] [563200/1281167 (44%)]	Loss: 0.999271
[2022-06-12 07:23:16 | train] - Train Epoch: [158] [576000/1281167 (45%)]	Loss: 0.958220
[2022-06-12 07:23:38 | train] - Train Epoch: [158] [588800/1281167 (46%)]	Loss: 0.586667
[2022-06-12 07:24:00 | train] - Train Epoch: [158] [601600/1281167 (47%)]	Loss: 0.650250
[2022-06-12 07:24:22 | train] - Train Epoch: [158] [614400/1281167 (48%)]	Loss: 0.727176
[2022-06-12 07:24:43 | train] - Train Epoch: [158] [627200/1281167 (49%)]	Loss: 0.769808
[2022-06-12 07:25:05 | train] - Train Epoch: [158] [640000/1281167 (50%)]	Loss: 0.577135
[2022-06-12 07:25:26 | train] - Train Epoch: [158] [652800/1281167 (51%)]	Loss: 0.861504
[2022-06-12 07:25:48 | train] - Train Epoch: [158] [665600/1281167 (52%)]	Loss: 0.537338
[2022-06-12 07:26:09 | train] - Train Epoch: [158] [678400/1281167 (53%)]	Loss: 0.741236
[2022-06-12 07:26:32 | train] - Train Epoch: [158] [691200/1281167 (54%)]	Loss: 0.715339
[2022-06-12 07:26:53 | train] - Train Epoch: [158] [704000/1281167 (55%)]	Loss: 0.493530
[2022-06-12 07:27:15 | train] - Train Epoch: [158] [716800/1281167 (56%)]	Loss: 0.584430
[2022-06-12 07:27:37 | train] - Train Epoch: [158] [729600/1281167 (57%)]	Loss: 0.800834
[2022-06-12 07:27:58 | train] - Train Epoch: [158] [742400/1281167 (58%)]	Loss: 0.647368
[2022-06-12 07:28:20 | train] - Train Epoch: [158] [755200/1281167 (59%)]	Loss: 0.763411
[2022-06-12 07:28:42 | train] - Train Epoch: [158] [768000/1281167 (60%)]	Loss: 0.697126
[2022-06-12 07:29:04 | train] - Train Epoch: [158] [780800/1281167 (61%)]	Loss: 0.618808
[2022-06-12 07:29:25 | train] - Train Epoch: [158] [793600/1281167 (62%)]	Loss: 0.574062
[2022-06-12 07:29:48 | train] - Train Epoch: [158] [806400/1281167 (63%)]	Loss: 0.649521
[2022-06-12 07:30:09 | train] - Train Epoch: [158] [819200/1281167 (64%)]	Loss: 0.884437
[2022-06-12 07:30:31 | train] - Train Epoch: [158] [832000/1281167 (65%)]	Loss: 0.706756
[2022-06-12 07:30:53 | train] - Train Epoch: [158] [844800/1281167 (66%)]	Loss: 0.643089
[2022-06-12 07:31:15 | train] - Train Epoch: [158] [857600/1281167 (67%)]	Loss: 0.886701
[2022-06-12 07:31:36 | train] - Train Epoch: [158] [870400/1281167 (68%)]	Loss: 0.808891
[2022-06-12 07:31:58 | train] - Train Epoch: [158] [883200/1281167 (69%)]	Loss: 0.718504
[2022-06-12 07:32:20 | train] - Train Epoch: [158] [896000/1281167 (70%)]	Loss: 0.724746
[2022-06-12 07:32:42 | train] - Train Epoch: [158] [908800/1281167 (71%)]	Loss: 0.652037
[2022-06-12 07:33:04 | train] - Train Epoch: [158] [921600/1281167 (72%)]	Loss: 0.708998
[2022-06-12 07:33:26 | train] - Train Epoch: [158] [934400/1281167 (73%)]	Loss: 0.734090
[2022-06-12 07:33:47 | train] - Train Epoch: [158] [947200/1281167 (74%)]	Loss: 0.890825
[2022-06-12 07:34:09 | train] - Train Epoch: [158] [960000/1281167 (75%)]	Loss: 0.629800
[2022-06-12 07:34:30 | train] - Train Epoch: [158] [972800/1281167 (76%)]	Loss: 0.886782
[2022-06-12 07:34:51 | train] - Train Epoch: [158] [985600/1281167 (77%)]	Loss: 0.760820
[2022-06-12 07:35:13 | train] - Train Epoch: [158] [998400/1281167 (78%)]	Loss: 0.506210
[2022-06-12 07:35:35 | train] - Train Epoch: [158] [1011200/1281167 (79%)]	Loss: 0.810074
[2022-06-12 07:35:57 | train] - Train Epoch: [158] [1024000/1281167 (80%)]	Loss: 0.620524
[2022-06-12 07:36:18 | train] - Train Epoch: [158] [1036800/1281167 (81%)]	Loss: 0.762091
[2022-06-12 07:36:40 | train] - Train Epoch: [158] [1049600/1281167 (82%)]	Loss: 0.573336
[2022-06-12 07:37:02 | train] - Train Epoch: [158] [1062400/1281167 (83%)]	Loss: 1.042706
[2022-06-12 07:37:24 | train] - Train Epoch: [158] [1075200/1281167 (84%)]	Loss: 0.545107
[2022-06-12 07:37:45 | train] - Train Epoch: [158] [1088000/1281167 (85%)]	Loss: 0.665193
[2022-06-12 07:38:07 | train] - Train Epoch: [158] [1100800/1281167 (86%)]	Loss: 0.951305
[2022-06-12 07:38:29 | train] - Train Epoch: [158] [1113600/1281167 (87%)]	Loss: 0.580422
[2022-06-12 07:38:50 | train] - Train Epoch: [158] [1126400/1281167 (88%)]	Loss: 0.582783
[2022-06-12 07:39:12 | train] - Train Epoch: [158] [1139200/1281167 (89%)]	Loss: 0.712412
[2022-06-12 07:39:34 | train] - Train Epoch: [158] [1152000/1281167 (90%)]	Loss: 0.777055
[2022-06-12 07:39:55 | train] - Train Epoch: [158] [1164800/1281167 (91%)]	Loss: 0.588158
[2022-06-12 07:40:17 | train] - Train Epoch: [158] [1177600/1281167 (92%)]	Loss: 0.736728
[2022-06-12 07:40:38 | train] - Train Epoch: [158] [1190400/1281167 (93%)]	Loss: 0.796291
[2022-06-12 07:41:00 | train] - Train Epoch: [158] [1203200/1281167 (94%)]	Loss: 1.191030
[2022-06-12 07:41:23 | train] - Train Epoch: [158] [1216000/1281167 (95%)]	Loss: 0.599399
[2022-06-12 07:41:44 | train] - Train Epoch: [158] [1228800/1281167 (96%)]	Loss: 0.394282
[2022-06-12 07:42:07 | train] - Train Epoch: [158] [1241600/1281167 (97%)]	Loss: 0.644393
[2022-06-12 07:42:29 | train] - Train Epoch: [158] [1254400/1281167 (98%)]	Loss: 0.807135
[2022-06-12 07:42:51 | train] - Train Epoch: [158] [1267200/1281167 (99%)]	Loss: 0.818297
[2022-06-12 07:43:13 | train] - Train Epoch: [158] [1280000/1281167 (100%)]	Loss: 0.668612
[2022-06-12 07:43:14 | train] - Train Epoch: [158]	 Average Loss: 0.708473	 Total Acc : 82.8025	 Total Top5 Acc : 93.7810
[2022-06-12 07:43:14 | train] - -------158 epoch end-----------
========================================
-------158 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 07:44:48 | train] - 
Epoch [158] Test set: Average loss: 1.4370, Accuracy: 34937/50000 (69.8441%), Top-5 Accuracy: 88.9090%

[2022-06-12 07:44:48 | train] - save intermediate epoch [158] result


[2022-06-12 07:45:02 | train] - -------159 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 07:45:04 | train] - Train Epoch: [159] [0/1281167 (0%)]	Loss: 0.617161
[2022-06-12 07:45:26 | train] - Train Epoch: [159] [12800/1281167 (1%)]	Loss: 0.583222
[2022-06-12 07:45:48 | train] - Train Epoch: [159] [25600/1281167 (2%)]	Loss: 0.519878
[2022-06-12 07:46:09 | train] - Train Epoch: [159] [38400/1281167 (3%)]	Loss: 0.813958
[2022-06-12 07:46:31 | train] - Train Epoch: [159] [51200/1281167 (4%)]	Loss: 0.918621
[2022-06-12 07:46:53 | train] - Train Epoch: [159] [64000/1281167 (5%)]	Loss: 0.744460
[2022-06-12 07:47:15 | train] - Train Epoch: [159] [76800/1281167 (6%)]	Loss: 0.707487
[2022-06-12 07:47:37 | train] - Train Epoch: [159] [89600/1281167 (7%)]	Loss: 0.923728
[2022-06-12 07:47:59 | train] - Train Epoch: [159] [102400/1281167 (8%)]	Loss: 0.461572
[2022-06-12 07:48:21 | train] - Train Epoch: [159] [115200/1281167 (9%)]	Loss: 0.714445
[2022-06-12 07:48:43 | train] - Train Epoch: [159] [128000/1281167 (10%)]	Loss: 0.709796
[2022-06-12 07:49:05 | train] - Train Epoch: [159] [140800/1281167 (11%)]	Loss: 0.814194
[2022-06-12 07:49:27 | train] - Train Epoch: [159] [153600/1281167 (12%)]	Loss: 0.749511
[2022-06-12 07:49:49 | train] - Train Epoch: [159] [166400/1281167 (13%)]	Loss: 0.615631
[2022-06-12 07:50:11 | train] - Train Epoch: [159] [179200/1281167 (14%)]	Loss: 0.735834
[2022-06-12 07:50:33 | train] - Train Epoch: [159] [192000/1281167 (15%)]	Loss: 0.705889
[2022-06-12 07:50:54 | train] - Train Epoch: [159] [204800/1281167 (16%)]	Loss: 0.544809
[2022-06-12 07:51:16 | train] - Train Epoch: [159] [217600/1281167 (17%)]	Loss: 0.998016
[2022-06-12 07:51:38 | train] - Train Epoch: [159] [230400/1281167 (18%)]	Loss: 0.812343
[2022-06-12 07:52:00 | train] - Train Epoch: [159] [243200/1281167 (19%)]	Loss: 0.843917
[2022-06-12 07:52:22 | train] - Train Epoch: [159] [256000/1281167 (20%)]	Loss: 0.835772
[2022-06-12 07:52:44 | train] - Train Epoch: [159] [268800/1281167 (21%)]	Loss: 0.681581
[2022-06-12 07:53:06 | train] - Train Epoch: [159] [281600/1281167 (22%)]	Loss: 0.654312
[2022-06-12 07:53:28 | train] - Train Epoch: [159] [294400/1281167 (23%)]	Loss: 0.641070
[2022-06-12 07:53:50 | train] - Train Epoch: [159] [307200/1281167 (24%)]	Loss: 0.597341
[2022-06-12 07:54:12 | train] - Train Epoch: [159] [320000/1281167 (25%)]	Loss: 0.470150
[2022-06-12 07:54:34 | train] - Train Epoch: [159] [332800/1281167 (26%)]	Loss: 0.920669
[2022-06-12 07:54:55 | train] - Train Epoch: [159] [345600/1281167 (27%)]	Loss: 0.654896
[2022-06-12 07:55:17 | train] - Train Epoch: [159] [358400/1281167 (28%)]	Loss: 0.641838
[2022-06-12 07:55:39 | train] - Train Epoch: [159] [371200/1281167 (29%)]	Loss: 0.890939
[2022-06-12 07:56:01 | train] - Train Epoch: [159] [384000/1281167 (30%)]	Loss: 0.790276
[2022-06-12 07:56:22 | train] - Train Epoch: [159] [396800/1281167 (31%)]	Loss: 0.861164
[2022-06-12 07:56:44 | train] - Train Epoch: [159] [409600/1281167 (32%)]	Loss: 0.686792
[2022-06-12 07:57:06 | train] - Train Epoch: [159] [422400/1281167 (33%)]	Loss: 0.757562
[2022-06-12 07:57:28 | train] - Train Epoch: [159] [435200/1281167 (34%)]	Loss: 0.697594
[2022-06-12 07:57:50 | train] - Train Epoch: [159] [448000/1281167 (35%)]	Loss: 0.464867
[2022-06-12 07:58:12 | train] - Train Epoch: [159] [460800/1281167 (36%)]	Loss: 0.992514
[2022-06-12 07:58:34 | train] - Train Epoch: [159] [473600/1281167 (37%)]	Loss: 0.520447
[2022-06-12 07:58:56 | train] - Train Epoch: [159] [486400/1281167 (38%)]	Loss: 0.626687
[2022-06-12 07:59:18 | train] - Train Epoch: [159] [499200/1281167 (39%)]	Loss: 0.660329
[2022-06-12 07:59:40 | train] - Train Epoch: [159] [512000/1281167 (40%)]	Loss: 0.645210
[2022-06-12 08:00:02 | train] - Train Epoch: [159] [524800/1281167 (41%)]	Loss: 0.590374
[2022-06-12 08:00:23 | train] - Train Epoch: [159] [537600/1281167 (42%)]	Loss: 0.738637
[2022-06-12 08:00:45 | train] - Train Epoch: [159] [550400/1281167 (43%)]	Loss: 0.543125
[2022-06-12 08:01:07 | train] - Train Epoch: [159] [563200/1281167 (44%)]	Loss: 0.711830
[2022-06-12 08:01:28 | train] - Train Epoch: [159] [576000/1281167 (45%)]	Loss: 0.685224
[2022-06-12 08:01:49 | train] - Train Epoch: [159] [588800/1281167 (46%)]	Loss: 0.763549
[2022-06-12 08:02:11 | train] - Train Epoch: [159] [601600/1281167 (47%)]	Loss: 0.556450
[2022-06-12 08:02:34 | train] - Train Epoch: [159] [614400/1281167 (48%)]	Loss: 0.826056
[2022-06-12 08:02:55 | train] - Train Epoch: [159] [627200/1281167 (49%)]	Loss: 0.954689
[2022-06-12 08:03:17 | train] - Train Epoch: [159] [640000/1281167 (50%)]	Loss: 0.686934
[2022-06-12 08:03:39 | train] - Train Epoch: [159] [652800/1281167 (51%)]	Loss: 0.539428
[2022-06-12 08:04:02 | train] - Train Epoch: [159] [665600/1281167 (52%)]	Loss: 0.676739
[2022-06-12 08:04:24 | train] - Train Epoch: [159] [678400/1281167 (53%)]	Loss: 0.722279
[2022-06-12 08:04:46 | train] - Train Epoch: [159] [691200/1281167 (54%)]	Loss: 0.741912
[2022-06-12 08:05:08 | train] - Train Epoch: [159] [704000/1281167 (55%)]	Loss: 0.572982
[2022-06-12 08:05:28 | train] - Train Epoch: [159] [716800/1281167 (56%)]	Loss: 0.876458
[2022-06-12 08:05:47 | train] - Train Epoch: [159] [729600/1281167 (57%)]	Loss: 0.744449
[2022-06-12 08:06:06 | train] - Train Epoch: [159] [742400/1281167 (58%)]	Loss: 0.488416
[2022-06-12 08:06:26 | train] - Train Epoch: [159] [755200/1281167 (59%)]	Loss: 0.740741
[2022-06-12 08:06:47 | train] - Train Epoch: [159] [768000/1281167 (60%)]	Loss: 0.884631
[2022-06-12 08:07:06 | train] - Train Epoch: [159] [780800/1281167 (61%)]	Loss: 0.783536
[2022-06-12 08:07:26 | train] - Train Epoch: [159] [793600/1281167 (62%)]	Loss: 0.554695
[2022-06-12 08:07:47 | train] - Train Epoch: [159] [806400/1281167 (63%)]	Loss: 0.773317
[2022-06-12 08:08:07 | train] - Train Epoch: [159] [819200/1281167 (64%)]	Loss: 0.804922
[2022-06-12 08:08:28 | train] - Train Epoch: [159] [832000/1281167 (65%)]	Loss: 0.570088
[2022-06-12 08:08:48 | train] - Train Epoch: [159] [844800/1281167 (66%)]	Loss: 0.546615
[2022-06-12 08:09:08 | train] - Train Epoch: [159] [857600/1281167 (67%)]	Loss: 0.874048
[2022-06-12 08:09:28 | train] - Train Epoch: [159] [870400/1281167 (68%)]	Loss: 0.753356
[2022-06-12 08:09:48 | train] - Train Epoch: [159] [883200/1281167 (69%)]	Loss: 0.910976
[2022-06-12 08:10:07 | train] - Train Epoch: [159] [896000/1281167 (70%)]	Loss: 0.609258
[2022-06-12 08:10:27 | train] - Train Epoch: [159] [908800/1281167 (71%)]	Loss: 0.577954
[2022-06-12 08:10:47 | train] - Train Epoch: [159] [921600/1281167 (72%)]	Loss: 0.481384
[2022-06-12 08:11:08 | train] - Train Epoch: [159] [934400/1281167 (73%)]	Loss: 0.568807
[2022-06-12 08:11:28 | train] - Train Epoch: [159] [947200/1281167 (74%)]	Loss: 0.538465
[2022-06-12 08:11:48 | train] - Train Epoch: [159] [960000/1281167 (75%)]	Loss: 0.599864
[2022-06-12 08:12:07 | train] - Train Epoch: [159] [972800/1281167 (76%)]	Loss: 0.614686
[2022-06-12 08:12:26 | train] - Train Epoch: [159] [985600/1281167 (77%)]	Loss: 0.596503
[2022-06-12 08:12:46 | train] - Train Epoch: [159] [998400/1281167 (78%)]	Loss: 0.828731
[2022-06-12 08:13:07 | train] - Train Epoch: [159] [1011200/1281167 (79%)]	Loss: 0.541102
[2022-06-12 08:13:26 | train] - Train Epoch: [159] [1024000/1281167 (80%)]	Loss: 0.680201
[2022-06-12 08:13:45 | train] - Train Epoch: [159] [1036800/1281167 (81%)]	Loss: 0.804912
[2022-06-12 08:14:05 | train] - Train Epoch: [159] [1049600/1281167 (82%)]	Loss: 0.919477
[2022-06-12 08:14:25 | train] - Train Epoch: [159] [1062400/1281167 (83%)]	Loss: 0.613887
[2022-06-12 08:14:46 | train] - Train Epoch: [159] [1075200/1281167 (84%)]	Loss: 0.802190
[2022-06-12 08:15:06 | train] - Train Epoch: [159] [1088000/1281167 (85%)]	Loss: 0.810840
[2022-06-12 08:15:26 | train] - Train Epoch: [159] [1100800/1281167 (86%)]	Loss: 0.706737
[2022-06-12 08:15:46 | train] - Train Epoch: [159] [1113600/1281167 (87%)]	Loss: 0.556404
[2022-06-12 08:16:06 | train] - Train Epoch: [159] [1126400/1281167 (88%)]	Loss: 0.822317
[2022-06-12 08:16:26 | train] - Train Epoch: [159] [1139200/1281167 (89%)]	Loss: 0.550505
[2022-06-12 08:16:45 | train] - Train Epoch: [159] [1152000/1281167 (90%)]	Loss: 0.749564
[2022-06-12 08:17:05 | train] - Train Epoch: [159] [1164800/1281167 (91%)]	Loss: 0.771402
[2022-06-12 08:17:25 | train] - Train Epoch: [159] [1177600/1281167 (92%)]	Loss: 1.023703
[2022-06-12 08:17:45 | train] - Train Epoch: [159] [1190400/1281167 (93%)]	Loss: 0.870930
[2022-06-12 08:18:05 | train] - Train Epoch: [159] [1203200/1281167 (94%)]	Loss: 0.788027
[2022-06-12 08:18:25 | train] - Train Epoch: [159] [1216000/1281167 (95%)]	Loss: 0.736080
[2022-06-12 08:18:44 | train] - Train Epoch: [159] [1228800/1281167 (96%)]	Loss: 0.796156
[2022-06-12 08:19:04 | train] - Train Epoch: [159] [1241600/1281167 (97%)]	Loss: 0.515610
[2022-06-12 08:19:24 | train] - Train Epoch: [159] [1254400/1281167 (98%)]	Loss: 0.666180
[2022-06-12 08:19:44 | train] - Train Epoch: [159] [1267200/1281167 (99%)]	Loss: 1.174056
[2022-06-12 08:20:04 | train] - Train Epoch: [159] [1280000/1281167 (100%)]	Loss: 0.656200
[2022-06-12 08:20:06 | train] - Train Epoch: [159]	 Average Loss: 0.707052	 Total Acc : 82.7774	 Total Top5 Acc : 93.7846
[2022-06-12 08:20:06 | train] - -------159 epoch end-----------
========================================
-------159 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 08:21:36 | train] - 
Epoch [159] Test set: Average loss: 1.4273, Accuracy: 34931/50000 (69.8346%), Top-5 Accuracy: 88.8851%

[2022-06-12 08:21:36 | train] - save intermediate epoch [159] result


[2022-06-12 08:21:50 | train] - -------160 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 08:21:52 | train] - Train Epoch: [160] [0/1281167 (0%)]	Loss: 0.588220
[2022-06-12 08:22:11 | train] - Train Epoch: [160] [12800/1281167 (1%)]	Loss: 0.471682
[2022-06-12 08:22:30 | train] - Train Epoch: [160] [25600/1281167 (2%)]	Loss: 0.705724
[2022-06-12 08:22:50 | train] - Train Epoch: [160] [38400/1281167 (3%)]	Loss: 0.927846
[2022-06-12 08:23:10 | train] - Train Epoch: [160] [51200/1281167 (4%)]	Loss: 0.645149
[2022-06-12 08:23:29 | train] - Train Epoch: [160] [64000/1281167 (5%)]	Loss: 0.599693
[2022-06-12 08:23:49 | train] - Train Epoch: [160] [76800/1281167 (6%)]	Loss: 0.791155
[2022-06-12 08:24:09 | train] - Train Epoch: [160] [89600/1281167 (7%)]	Loss: 0.740834
[2022-06-12 08:24:29 | train] - Train Epoch: [160] [102400/1281167 (8%)]	Loss: 0.813272
[2022-06-12 08:24:49 | train] - Train Epoch: [160] [115200/1281167 (9%)]	Loss: 0.524508
[2022-06-12 08:25:08 | train] - Train Epoch: [160] [128000/1281167 (10%)]	Loss: 0.640665
[2022-06-12 08:25:28 | train] - Train Epoch: [160] [140800/1281167 (11%)]	Loss: 0.742863
[2022-06-12 08:25:48 | train] - Train Epoch: [160] [153600/1281167 (12%)]	Loss: 0.606439
[2022-06-12 08:26:08 | train] - Train Epoch: [160] [166400/1281167 (13%)]	Loss: 0.753619
[2022-06-12 08:26:28 | train] - Train Epoch: [160] [179200/1281167 (14%)]	Loss: 0.640935
[2022-06-12 08:26:47 | train] - Train Epoch: [160] [192000/1281167 (15%)]	Loss: 0.816336
[2022-06-12 08:27:07 | train] - Train Epoch: [160] [204800/1281167 (16%)]	Loss: 0.634844
[2022-06-12 08:27:27 | train] - Train Epoch: [160] [217600/1281167 (17%)]	Loss: 0.534490
[2022-06-12 08:27:46 | train] - Train Epoch: [160] [230400/1281167 (18%)]	Loss: 0.775889
[2022-06-12 08:28:06 | train] - Train Epoch: [160] [243200/1281167 (19%)]	Loss: 0.679880
[2022-06-12 08:28:25 | train] - Train Epoch: [160] [256000/1281167 (20%)]	Loss: 0.844531
[2022-06-12 08:28:45 | train] - Train Epoch: [160] [268800/1281167 (21%)]	Loss: 0.594712
[2022-06-12 08:29:04 | train] - Train Epoch: [160] [281600/1281167 (22%)]	Loss: 0.823043
[2022-06-12 08:29:23 | train] - Train Epoch: [160] [294400/1281167 (23%)]	Loss: 0.702281
[2022-06-12 08:29:42 | train] - Train Epoch: [160] [307200/1281167 (24%)]	Loss: 0.581927
[2022-06-12 08:30:02 | train] - Train Epoch: [160] [320000/1281167 (25%)]	Loss: 0.768671
[2022-06-12 08:30:21 | train] - Train Epoch: [160] [332800/1281167 (26%)]	Loss: 0.781226
[2022-06-12 08:30:41 | train] - Train Epoch: [160] [345600/1281167 (27%)]	Loss: 0.762155
[2022-06-12 08:31:01 | train] - Train Epoch: [160] [358400/1281167 (28%)]	Loss: 0.442830
[2022-06-12 08:31:20 | train] - Train Epoch: [160] [371200/1281167 (29%)]	Loss: 0.746628
[2022-06-12 08:31:39 | train] - Train Epoch: [160] [384000/1281167 (30%)]	Loss: 0.567598
[2022-06-12 08:31:59 | train] - Train Epoch: [160] [396800/1281167 (31%)]	Loss: 0.630240
[2022-06-12 08:32:18 | train] - Train Epoch: [160] [409600/1281167 (32%)]	Loss: 0.699131
[2022-06-12 08:32:37 | train] - Train Epoch: [160] [422400/1281167 (33%)]	Loss: 0.791739
[2022-06-12 08:32:58 | train] - Train Epoch: [160] [435200/1281167 (34%)]	Loss: 0.703424
[2022-06-12 08:33:17 | train] - Train Epoch: [160] [448000/1281167 (35%)]	Loss: 0.614932
[2022-06-12 08:33:37 | train] - Train Epoch: [160] [460800/1281167 (36%)]	Loss: 0.746017
[2022-06-12 08:33:56 | train] - Train Epoch: [160] [473600/1281167 (37%)]	Loss: 0.880322
[2022-06-12 08:34:16 | train] - Train Epoch: [160] [486400/1281167 (38%)]	Loss: 0.976281
[2022-06-12 08:34:35 | train] - Train Epoch: [160] [499200/1281167 (39%)]	Loss: 0.795591
[2022-06-12 08:34:54 | train] - Train Epoch: [160] [512000/1281167 (40%)]	Loss: 0.627187
[2022-06-12 08:35:14 | train] - Train Epoch: [160] [524800/1281167 (41%)]	Loss: 0.799577
[2022-06-12 08:35:32 | train] - Train Epoch: [160] [537600/1281167 (42%)]	Loss: 0.646099
[2022-06-12 08:35:52 | train] - Train Epoch: [160] [550400/1281167 (43%)]	Loss: 0.524769
[2022-06-12 08:36:11 | train] - Train Epoch: [160] [563200/1281167 (44%)]	Loss: 0.625380
[2022-06-12 08:36:31 | train] - Train Epoch: [160] [576000/1281167 (45%)]	Loss: 0.540732
[2022-06-12 08:36:51 | train] - Train Epoch: [160] [588800/1281167 (46%)]	Loss: 0.847923
[2022-06-12 08:37:10 | train] - Train Epoch: [160] [601600/1281167 (47%)]	Loss: 0.453457
[2022-06-12 08:37:30 | train] - Train Epoch: [160] [614400/1281167 (48%)]	Loss: 0.780809
[2022-06-12 08:37:51 | train] - Train Epoch: [160] [627200/1281167 (49%)]	Loss: 0.667779
[2022-06-12 08:38:10 | train] - Train Epoch: [160] [640000/1281167 (50%)]	Loss: 0.685244
[2022-06-12 08:38:29 | train] - Train Epoch: [160] [652800/1281167 (51%)]	Loss: 0.756596
[2022-06-12 08:38:49 | train] - Train Epoch: [160] [665600/1281167 (52%)]	Loss: 0.594663
[2022-06-12 08:39:09 | train] - Train Epoch: [160] [678400/1281167 (53%)]	Loss: 0.791980
[2022-06-12 08:39:29 | train] - Train Epoch: [160] [691200/1281167 (54%)]	Loss: 0.788014
[2022-06-12 08:39:48 | train] - Train Epoch: [160] [704000/1281167 (55%)]	Loss: 0.599858
[2022-06-12 08:40:08 | train] - Train Epoch: [160] [716800/1281167 (56%)]	Loss: 0.753067
[2022-06-12 08:40:27 | train] - Train Epoch: [160] [729600/1281167 (57%)]	Loss: 0.762205
[2022-06-12 08:40:47 | train] - Train Epoch: [160] [742400/1281167 (58%)]	Loss: 0.526045
[2022-06-12 08:41:06 | train] - Train Epoch: [160] [755200/1281167 (59%)]	Loss: 0.622495
[2022-06-12 08:41:26 | train] - Train Epoch: [160] [768000/1281167 (60%)]	Loss: 0.564252
[2022-06-12 08:41:46 | train] - Train Epoch: [160] [780800/1281167 (61%)]	Loss: 0.695615
[2022-06-12 08:42:05 | train] - Train Epoch: [160] [793600/1281167 (62%)]	Loss: 0.809683
[2022-06-12 08:42:25 | train] - Train Epoch: [160] [806400/1281167 (63%)]	Loss: 0.900629
[2022-06-12 08:42:45 | train] - Train Epoch: [160] [819200/1281167 (64%)]	Loss: 0.603611
[2022-06-12 08:43:05 | train] - Train Epoch: [160] [832000/1281167 (65%)]	Loss: 0.624298
[2022-06-12 08:43:25 | train] - Train Epoch: [160] [844800/1281167 (66%)]	Loss: 0.548415
[2022-06-12 08:43:44 | train] - Train Epoch: [160] [857600/1281167 (67%)]	Loss: 0.753172
[2022-06-12 08:44:03 | train] - Train Epoch: [160] [870400/1281167 (68%)]	Loss: 0.683362
[2022-06-12 08:44:23 | train] - Train Epoch: [160] [883200/1281167 (69%)]	Loss: 0.970727
[2022-06-12 08:44:42 | train] - Train Epoch: [160] [896000/1281167 (70%)]	Loss: 0.562571
[2022-06-12 08:45:01 | train] - Train Epoch: [160] [908800/1281167 (71%)]	Loss: 0.689056
[2022-06-12 08:45:22 | train] - Train Epoch: [160] [921600/1281167 (72%)]	Loss: 0.554258
[2022-06-12 08:45:41 | train] - Train Epoch: [160] [934400/1281167 (73%)]	Loss: 0.586253
[2022-06-12 08:46:01 | train] - Train Epoch: [160] [947200/1281167 (74%)]	Loss: 0.798252
[2022-06-12 08:46:21 | train] - Train Epoch: [160] [960000/1281167 (75%)]	Loss: 0.615635
[2022-06-12 08:46:40 | train] - Train Epoch: [160] [972800/1281167 (76%)]	Loss: 0.797154
[2022-06-12 08:47:00 | train] - Train Epoch: [160] [985600/1281167 (77%)]	Loss: 0.519810
[2022-06-12 08:47:20 | train] - Train Epoch: [160] [998400/1281167 (78%)]	Loss: 0.453445
[2022-06-12 08:47:40 | train] - Train Epoch: [160] [1011200/1281167 (79%)]	Loss: 0.683447
[2022-06-12 08:47:59 | train] - Train Epoch: [160] [1024000/1281167 (80%)]	Loss: 0.696768
[2022-06-12 08:48:20 | train] - Train Epoch: [160] [1036800/1281167 (81%)]	Loss: 0.824859
[2022-06-12 08:48:39 | train] - Train Epoch: [160] [1049600/1281167 (82%)]	Loss: 0.560488
[2022-06-12 08:48:59 | train] - Train Epoch: [160] [1062400/1281167 (83%)]	Loss: 0.660508
[2022-06-12 08:49:18 | train] - Train Epoch: [160] [1075200/1281167 (84%)]	Loss: 0.754384
[2022-06-12 08:49:38 | train] - Train Epoch: [160] [1088000/1281167 (85%)]	Loss: 0.868221
[2022-06-12 08:49:57 | train] - Train Epoch: [160] [1100800/1281167 (86%)]	Loss: 0.677344
[2022-06-12 08:50:17 | train] - Train Epoch: [160] [1113600/1281167 (87%)]	Loss: 0.569720
[2022-06-12 08:50:37 | train] - Train Epoch: [160] [1126400/1281167 (88%)]	Loss: 0.649742
[2022-06-12 08:50:56 | train] - Train Epoch: [160] [1139200/1281167 (89%)]	Loss: 0.823512
[2022-06-12 08:51:16 | train] - Train Epoch: [160] [1152000/1281167 (90%)]	Loss: 0.680222
[2022-06-12 08:51:36 | train] - Train Epoch: [160] [1164800/1281167 (91%)]	Loss: 0.860987
[2022-06-12 08:51:56 | train] - Train Epoch: [160] [1177600/1281167 (92%)]	Loss: 0.706797
[2022-06-12 08:52:15 | train] - Train Epoch: [160] [1190400/1281167 (93%)]	Loss: 0.643021
[2022-06-12 08:52:34 | train] - Train Epoch: [160] [1203200/1281167 (94%)]	Loss: 0.766719
[2022-06-12 08:52:54 | train] - Train Epoch: [160] [1216000/1281167 (95%)]	Loss: 0.450167
[2022-06-12 08:53:14 | train] - Train Epoch: [160] [1228800/1281167 (96%)]	Loss: 0.598439
[2022-06-12 08:53:33 | train] - Train Epoch: [160] [1241600/1281167 (97%)]	Loss: 0.761215
[2022-06-12 08:53:53 | train] - Train Epoch: [160] [1254400/1281167 (98%)]	Loss: 0.634523
[2022-06-12 08:54:13 | train] - Train Epoch: [160] [1267200/1281167 (99%)]	Loss: 0.635987
[2022-06-12 08:54:32 | train] - Train Epoch: [160] [1280000/1281167 (100%)]	Loss: 0.634021
[2022-06-12 08:54:34 | train] - Train Epoch: [160]	 Average Loss: 0.699715	 Total Acc : 83.0016	 Total Top5 Acc : 93.8635
[2022-06-12 08:54:34 | train] - -------160 epoch end-----------
========================================
-------160 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 08:56:05 | train] - 
Epoch [160] Test set: Average loss: 1.4295, Accuracy: 34961/50000 (69.8957%), Top-5 Accuracy: 88.9462%

[2022-06-12 08:56:05 | train] - save intermediate epoch [160] result


[2022-06-12 08:56:20 | train] - -------161 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 08:56:22 | train] - Train Epoch: [161] [0/1281167 (0%)]	Loss: 0.839460
[2022-06-12 08:56:42 | train] - Train Epoch: [161] [12800/1281167 (1%)]	Loss: 0.639111
[2022-06-12 08:57:01 | train] - Train Epoch: [161] [25600/1281167 (2%)]	Loss: 0.731845
[2022-06-12 08:57:21 | train] - Train Epoch: [161] [38400/1281167 (3%)]	Loss: 0.894988
[2022-06-12 08:57:41 | train] - Train Epoch: [161] [51200/1281167 (4%)]	Loss: 0.740412
[2022-06-12 08:58:02 | train] - Train Epoch: [161] [64000/1281167 (5%)]	Loss: 0.701804
[2022-06-12 08:58:22 | train] - Train Epoch: [161] [76800/1281167 (6%)]	Loss: 0.694946
[2022-06-12 08:58:44 | train] - Train Epoch: [161] [89600/1281167 (7%)]	Loss: 0.534327
[2022-06-12 08:59:05 | train] - Train Epoch: [161] [102400/1281167 (8%)]	Loss: 0.766135
[2022-06-12 08:59:26 | train] - Train Epoch: [161] [115200/1281167 (9%)]	Loss: 0.818587
[2022-06-12 08:59:47 | train] - Train Epoch: [161] [128000/1281167 (10%)]	Loss: 0.683669
[2022-06-12 09:00:06 | train] - Train Epoch: [161] [140800/1281167 (11%)]	Loss: 0.453737
[2022-06-12 09:00:25 | train] - Train Epoch: [161] [153600/1281167 (12%)]	Loss: 1.045947
[2022-06-12 09:00:44 | train] - Train Epoch: [161] [166400/1281167 (13%)]	Loss: 0.577836
[2022-06-12 09:01:03 | train] - Train Epoch: [161] [179200/1281167 (14%)]	Loss: 0.631905
[2022-06-12 09:01:24 | train] - Train Epoch: [161] [192000/1281167 (15%)]	Loss: 0.665342
[2022-06-12 09:01:45 | train] - Train Epoch: [161] [204800/1281167 (16%)]	Loss: 0.593814
[2022-06-12 09:02:05 | train] - Train Epoch: [161] [217600/1281167 (17%)]	Loss: 0.857295
[2022-06-12 09:02:25 | train] - Train Epoch: [161] [230400/1281167 (18%)]	Loss: 0.574085
[2022-06-12 09:02:45 | train] - Train Epoch: [161] [243200/1281167 (19%)]	Loss: 0.526857
[2022-06-12 09:03:04 | train] - Train Epoch: [161] [256000/1281167 (20%)]	Loss: 0.934482
[2022-06-12 09:03:23 | train] - Train Epoch: [161] [268800/1281167 (21%)]	Loss: 0.715341
[2022-06-12 09:03:43 | train] - Train Epoch: [161] [281600/1281167 (22%)]	Loss: 0.728497
[2022-06-12 09:04:03 | train] - Train Epoch: [161] [294400/1281167 (23%)]	Loss: 0.784464
[2022-06-12 09:04:23 | train] - Train Epoch: [161] [307200/1281167 (24%)]	Loss: 0.734118
[2022-06-12 09:04:42 | train] - Train Epoch: [161] [320000/1281167 (25%)]	Loss: 0.709404
[2022-06-12 09:05:01 | train] - Train Epoch: [161] [332800/1281167 (26%)]	Loss: 0.550084
[2022-06-12 09:05:22 | train] - Train Epoch: [161] [345600/1281167 (27%)]	Loss: 0.532594
[2022-06-12 09:05:41 | train] - Train Epoch: [161] [358400/1281167 (28%)]	Loss: 0.660416
[2022-06-12 09:06:01 | train] - Train Epoch: [161] [371200/1281167 (29%)]	Loss: 0.671730
[2022-06-12 09:06:22 | train] - Train Epoch: [161] [384000/1281167 (30%)]	Loss: 0.661097
[2022-06-12 09:06:41 | train] - Train Epoch: [161] [396800/1281167 (31%)]	Loss: 0.403479
[2022-06-12 09:07:02 | train] - Train Epoch: [161] [409600/1281167 (32%)]	Loss: 0.609484
[2022-06-12 09:07:22 | train] - Train Epoch: [161] [422400/1281167 (33%)]	Loss: 0.609142
[2022-06-12 09:07:41 | train] - Train Epoch: [161] [435200/1281167 (34%)]	Loss: 0.825500
[2022-06-12 09:08:01 | train] - Train Epoch: [161] [448000/1281167 (35%)]	Loss: 0.812421
[2022-06-12 09:08:21 | train] - Train Epoch: [161] [460800/1281167 (36%)]	Loss: 0.716258
[2022-06-12 09:08:41 | train] - Train Epoch: [161] [473600/1281167 (37%)]	Loss: 0.713450
[2022-06-12 09:09:00 | train] - Train Epoch: [161] [486400/1281167 (38%)]	Loss: 0.625649
[2022-06-12 09:09:20 | train] - Train Epoch: [161] [499200/1281167 (39%)]	Loss: 0.503403
[2022-06-12 09:09:41 | train] - Train Epoch: [161] [512000/1281167 (40%)]	Loss: 0.807169
[2022-06-12 09:10:01 | train] - Train Epoch: [161] [524800/1281167 (41%)]	Loss: 0.730135
[2022-06-12 09:10:21 | train] - Train Epoch: [161] [537600/1281167 (42%)]	Loss: 0.836017
[2022-06-12 09:10:41 | train] - Train Epoch: [161] [550400/1281167 (43%)]	Loss: 0.794769
[2022-06-12 09:11:01 | train] - Train Epoch: [161] [563200/1281167 (44%)]	Loss: 0.448295
[2022-06-12 09:11:21 | train] - Train Epoch: [161] [576000/1281167 (45%)]	Loss: 0.695426
[2022-06-12 09:11:41 | train] - Train Epoch: [161] [588800/1281167 (46%)]	Loss: 0.837174
[2022-06-12 09:12:01 | train] - Train Epoch: [161] [601600/1281167 (47%)]	Loss: 0.764153
[2022-06-12 09:12:21 | train] - Train Epoch: [161] [614400/1281167 (48%)]	Loss: 0.716945
[2022-06-12 09:12:41 | train] - Train Epoch: [161] [627200/1281167 (49%)]	Loss: 0.581274
[2022-06-12 09:13:01 | train] - Train Epoch: [161] [640000/1281167 (50%)]	Loss: 0.855233
[2022-06-12 09:13:20 | train] - Train Epoch: [161] [652800/1281167 (51%)]	Loss: 0.876341
[2022-06-12 09:13:40 | train] - Train Epoch: [161] [665600/1281167 (52%)]	Loss: 0.698408
[2022-06-12 09:13:59 | train] - Train Epoch: [161] [678400/1281167 (53%)]	Loss: 0.744551
[2022-06-12 09:14:19 | train] - Train Epoch: [161] [691200/1281167 (54%)]	Loss: 0.606200
[2022-06-12 09:14:38 | train] - Train Epoch: [161] [704000/1281167 (55%)]	Loss: 0.491608
[2022-06-12 09:14:58 | train] - Train Epoch: [161] [716800/1281167 (56%)]	Loss: 0.718891
[2022-06-12 09:15:18 | train] - Train Epoch: [161] [729600/1281167 (57%)]	Loss: 0.604063
[2022-06-12 09:15:37 | train] - Train Epoch: [161] [742400/1281167 (58%)]	Loss: 0.728357
[2022-06-12 09:15:57 | train] - Train Epoch: [161] [755200/1281167 (59%)]	Loss: 0.630491
[2022-06-12 09:16:17 | train] - Train Epoch: [161] [768000/1281167 (60%)]	Loss: 0.603216
[2022-06-12 09:16:36 | train] - Train Epoch: [161] [780800/1281167 (61%)]	Loss: 0.885436
[2022-06-12 09:16:56 | train] - Train Epoch: [161] [793600/1281167 (62%)]	Loss: 0.690907
[2022-06-12 09:17:15 | train] - Train Epoch: [161] [806400/1281167 (63%)]	Loss: 0.628215
[2022-06-12 09:17:36 | train] - Train Epoch: [161] [819200/1281167 (64%)]	Loss: 1.045545
[2022-06-12 09:17:55 | train] - Train Epoch: [161] [832000/1281167 (65%)]	Loss: 0.704724
[2022-06-12 09:18:15 | train] - Train Epoch: [161] [844800/1281167 (66%)]	Loss: 0.703390
[2022-06-12 09:18:34 | train] - Train Epoch: [161] [857600/1281167 (67%)]	Loss: 0.716419
[2022-06-12 09:18:53 | train] - Train Epoch: [161] [870400/1281167 (68%)]	Loss: 0.761807
[2022-06-12 09:19:14 | train] - Train Epoch: [161] [883200/1281167 (69%)]	Loss: 0.511898
[2022-06-12 09:19:34 | train] - Train Epoch: [161] [896000/1281167 (70%)]	Loss: 0.873397
[2022-06-12 09:19:54 | train] - Train Epoch: [161] [908800/1281167 (71%)]	Loss: 0.611310
[2022-06-12 09:20:14 | train] - Train Epoch: [161] [921600/1281167 (72%)]	Loss: 0.864190
[2022-06-12 09:20:34 | train] - Train Epoch: [161] [934400/1281167 (73%)]	Loss: 0.714199
[2022-06-12 09:20:54 | train] - Train Epoch: [161] [947200/1281167 (74%)]	Loss: 0.781271
[2022-06-12 09:21:14 | train] - Train Epoch: [161] [960000/1281167 (75%)]	Loss: 0.686328
[2022-06-12 09:21:34 | train] - Train Epoch: [161] [972800/1281167 (76%)]	Loss: 0.565107
[2022-06-12 09:21:54 | train] - Train Epoch: [161] [985600/1281167 (77%)]	Loss: 0.743794
[2022-06-12 09:22:14 | train] - Train Epoch: [161] [998400/1281167 (78%)]	Loss: 0.688915
[2022-06-12 09:22:33 | train] - Train Epoch: [161] [1011200/1281167 (79%)]	Loss: 0.758881
[2022-06-12 09:22:53 | train] - Train Epoch: [161] [1024000/1281167 (80%)]	Loss: 0.582339
[2022-06-12 09:23:14 | train] - Train Epoch: [161] [1036800/1281167 (81%)]	Loss: 0.697884
[2022-06-12 09:23:34 | train] - Train Epoch: [161] [1049600/1281167 (82%)]	Loss: 0.330080
[2022-06-12 09:23:54 | train] - Train Epoch: [161] [1062400/1281167 (83%)]	Loss: 0.732958
[2022-06-12 09:24:13 | train] - Train Epoch: [161] [1075200/1281167 (84%)]	Loss: 0.523479
[2022-06-12 09:24:33 | train] - Train Epoch: [161] [1088000/1281167 (85%)]	Loss: 0.973383
[2022-06-12 09:24:52 | train] - Train Epoch: [161] [1100800/1281167 (86%)]	Loss: 0.753442
[2022-06-12 09:25:12 | train] - Train Epoch: [161] [1113600/1281167 (87%)]	Loss: 0.875237
[2022-06-12 09:25:33 | train] - Train Epoch: [161] [1126400/1281167 (88%)]	Loss: 0.773453
[2022-06-12 09:25:52 | train] - Train Epoch: [161] [1139200/1281167 (89%)]	Loss: 0.895834
[2022-06-12 09:26:12 | train] - Train Epoch: [161] [1152000/1281167 (90%)]	Loss: 0.671361
[2022-06-12 09:26:32 | train] - Train Epoch: [161] [1164800/1281167 (91%)]	Loss: 0.885398
[2022-06-12 09:26:51 | train] - Train Epoch: [161] [1177600/1281167 (92%)]	Loss: 0.600260
[2022-06-12 09:27:12 | train] - Train Epoch: [161] [1190400/1281167 (93%)]	Loss: 0.580089
[2022-06-12 09:27:32 | train] - Train Epoch: [161] [1203200/1281167 (94%)]	Loss: 0.676247
[2022-06-12 09:27:52 | train] - Train Epoch: [161] [1216000/1281167 (95%)]	Loss: 0.689402
[2022-06-12 09:28:12 | train] - Train Epoch: [161] [1228800/1281167 (96%)]	Loss: 0.679810
[2022-06-12 09:28:31 | train] - Train Epoch: [161] [1241600/1281167 (97%)]	Loss: 0.806707
[2022-06-12 09:28:51 | train] - Train Epoch: [161] [1254400/1281167 (98%)]	Loss: 0.610358
[2022-06-12 09:29:11 | train] - Train Epoch: [161] [1267200/1281167 (99%)]	Loss: 0.772007
[2022-06-12 09:29:31 | train] - Train Epoch: [161] [1280000/1281167 (100%)]	Loss: 0.657366
[2022-06-12 09:29:32 | train] - Train Epoch: [161]	 Average Loss: 0.697060	 Total Acc : 83.0760	 Total Top5 Acc : 93.8923
[2022-06-12 09:29:32 | train] - -------161 epoch end-----------
========================================
-------161 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 09:31:01 | train] - 
Epoch [161] Test set: Average loss: 1.4272, Accuracy: 34970/50000 (69.9089%), Top-5 Accuracy: 88.9634%

[2022-06-12 09:31:01 | train] - save intermediate epoch [161] result


[2022-06-12 09:31:18 | train] - -------162 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 09:31:19 | train] - Train Epoch: [162] [0/1281167 (0%)]	Loss: 0.566369
[2022-06-12 09:31:39 | train] - Train Epoch: [162] [12800/1281167 (1%)]	Loss: 0.646540
[2022-06-12 09:31:59 | train] - Train Epoch: [162] [25600/1281167 (2%)]	Loss: 0.604409
[2022-06-12 09:32:18 | train] - Train Epoch: [162] [38400/1281167 (3%)]	Loss: 0.771417
[2022-06-12 09:32:37 | train] - Train Epoch: [162] [51200/1281167 (4%)]	Loss: 0.865765
[2022-06-12 09:32:57 | train] - Train Epoch: [162] [64000/1281167 (5%)]	Loss: 0.737950
[2022-06-12 09:33:17 | train] - Train Epoch: [162] [76800/1281167 (6%)]	Loss: 1.009491
[2022-06-12 09:33:36 | train] - Train Epoch: [162] [89600/1281167 (7%)]	Loss: 0.653517
[2022-06-12 09:33:56 | train] - Train Epoch: [162] [102400/1281167 (8%)]	Loss: 0.587758
[2022-06-12 09:34:16 | train] - Train Epoch: [162] [115200/1281167 (9%)]	Loss: 0.763971
[2022-06-12 09:34:35 | train] - Train Epoch: [162] [128000/1281167 (10%)]	Loss: 0.444439
[2022-06-12 09:34:54 | train] - Train Epoch: [162] [140800/1281167 (11%)]	Loss: 0.655201
[2022-06-12 09:35:13 | train] - Train Epoch: [162] [153600/1281167 (12%)]	Loss: 0.920778
[2022-06-12 09:35:32 | train] - Train Epoch: [162] [166400/1281167 (13%)]	Loss: 0.450992
[2022-06-12 09:35:52 | train] - Train Epoch: [162] [179200/1281167 (14%)]	Loss: 0.802002
[2022-06-12 09:36:12 | train] - Train Epoch: [162] [192000/1281167 (15%)]	Loss: 0.936584
[2022-06-12 09:36:31 | train] - Train Epoch: [162] [204800/1281167 (16%)]	Loss: 0.603644
[2022-06-12 09:36:51 | train] - Train Epoch: [162] [217600/1281167 (17%)]	Loss: 0.391867
[2022-06-12 09:37:11 | train] - Train Epoch: [162] [230400/1281167 (18%)]	Loss: 0.625965
[2022-06-12 09:37:30 | train] - Train Epoch: [162] [243200/1281167 (19%)]	Loss: 0.766484
[2022-06-12 09:37:50 | train] - Train Epoch: [162] [256000/1281167 (20%)]	Loss: 0.504081
[2022-06-12 09:38:09 | train] - Train Epoch: [162] [268800/1281167 (21%)]	Loss: 0.787800
[2022-06-12 09:38:28 | train] - Train Epoch: [162] [281600/1281167 (22%)]	Loss: 0.778894
[2022-06-12 09:38:49 | train] - Train Epoch: [162] [294400/1281167 (23%)]	Loss: 0.527733
[2022-06-12 09:39:08 | train] - Train Epoch: [162] [307200/1281167 (24%)]	Loss: 0.746094
[2022-06-12 09:39:28 | train] - Train Epoch: [162] [320000/1281167 (25%)]	Loss: 0.726201
[2022-06-12 09:39:47 | train] - Train Epoch: [162] [332800/1281167 (26%)]	Loss: 0.585805
[2022-06-12 09:40:07 | train] - Train Epoch: [162] [345600/1281167 (27%)]	Loss: 0.915124
[2022-06-12 09:40:26 | train] - Train Epoch: [162] [358400/1281167 (28%)]	Loss: 0.543099
[2022-06-12 09:40:46 | train] - Train Epoch: [162] [371200/1281167 (29%)]	Loss: 0.687942
[2022-06-12 09:41:06 | train] - Train Epoch: [162] [384000/1281167 (30%)]	Loss: 0.605336
[2022-06-12 09:41:25 | train] - Train Epoch: [162] [396800/1281167 (31%)]	Loss: 0.664487
[2022-06-12 09:41:45 | train] - Train Epoch: [162] [409600/1281167 (32%)]	Loss: 0.764081
[2022-06-12 09:42:04 | train] - Train Epoch: [162] [422400/1281167 (33%)]	Loss: 0.764415
[2022-06-12 09:42:24 | train] - Train Epoch: [162] [435200/1281167 (34%)]	Loss: 0.557325
[2022-06-12 09:42:43 | train] - Train Epoch: [162] [448000/1281167 (35%)]	Loss: 0.733289
[2022-06-12 09:43:03 | train] - Train Epoch: [162] [460800/1281167 (36%)]	Loss: 0.449992
[2022-06-12 09:43:22 | train] - Train Epoch: [162] [473600/1281167 (37%)]	Loss: 0.552123
[2022-06-12 09:43:42 | train] - Train Epoch: [162] [486400/1281167 (38%)]	Loss: 0.731778
[2022-06-12 09:44:01 | train] - Train Epoch: [162] [499200/1281167 (39%)]	Loss: 0.563400
[2022-06-12 09:44:20 | train] - Train Epoch: [162] [512000/1281167 (40%)]	Loss: 0.552825
[2022-06-12 09:44:40 | train] - Train Epoch: [162] [524800/1281167 (41%)]	Loss: 0.682259
[2022-06-12 09:44:59 | train] - Train Epoch: [162] [537600/1281167 (42%)]	Loss: 0.602204
[2022-06-12 09:45:19 | train] - Train Epoch: [162] [550400/1281167 (43%)]	Loss: 0.619795
[2022-06-12 09:45:38 | train] - Train Epoch: [162] [563200/1281167 (44%)]	Loss: 0.615262
[2022-06-12 09:45:57 | train] - Train Epoch: [162] [576000/1281167 (45%)]	Loss: 0.764710
[2022-06-12 09:46:17 | train] - Train Epoch: [162] [588800/1281167 (46%)]	Loss: 0.675464
[2022-06-12 09:46:37 | train] - Train Epoch: [162] [601600/1281167 (47%)]	Loss: 0.892465
[2022-06-12 09:46:55 | train] - Train Epoch: [162] [614400/1281167 (48%)]	Loss: 0.485604
[2022-06-12 09:47:15 | train] - Train Epoch: [162] [627200/1281167 (49%)]	Loss: 0.544702
[2022-06-12 09:47:35 | train] - Train Epoch: [162] [640000/1281167 (50%)]	Loss: 0.944197
[2022-06-12 09:47:54 | train] - Train Epoch: [162] [652800/1281167 (51%)]	Loss: 0.746745
[2022-06-12 09:48:14 | train] - Train Epoch: [162] [665600/1281167 (52%)]	Loss: 0.683331
[2022-06-12 09:48:34 | train] - Train Epoch: [162] [678400/1281167 (53%)]	Loss: 1.124274
[2022-06-12 09:48:54 | train] - Train Epoch: [162] [691200/1281167 (54%)]	Loss: 0.477315
[2022-06-12 09:49:13 | train] - Train Epoch: [162] [704000/1281167 (55%)]	Loss: 0.449963
[2022-06-12 09:49:32 | train] - Train Epoch: [162] [716800/1281167 (56%)]	Loss: 0.803107
[2022-06-12 09:49:51 | train] - Train Epoch: [162] [729600/1281167 (57%)]	Loss: 0.780206
[2022-06-12 09:50:10 | train] - Train Epoch: [162] [742400/1281167 (58%)]	Loss: 0.591756
[2022-06-12 09:50:30 | train] - Train Epoch: [162] [755200/1281167 (59%)]	Loss: 0.767389
[2022-06-12 09:50:49 | train] - Train Epoch: [162] [768000/1281167 (60%)]	Loss: 0.801957
[2022-06-12 09:51:09 | train] - Train Epoch: [162] [780800/1281167 (61%)]	Loss: 0.680473
[2022-06-12 09:51:29 | train] - Train Epoch: [162] [793600/1281167 (62%)]	Loss: 0.678469
[2022-06-12 09:51:49 | train] - Train Epoch: [162] [806400/1281167 (63%)]	Loss: 0.836254
[2022-06-12 09:52:08 | train] - Train Epoch: [162] [819200/1281167 (64%)]	Loss: 0.708080
[2022-06-12 09:52:28 | train] - Train Epoch: [162] [832000/1281167 (65%)]	Loss: 0.612729
[2022-06-12 09:52:47 | train] - Train Epoch: [162] [844800/1281167 (66%)]	Loss: 0.555706
[2022-06-12 09:53:05 | train] - Train Epoch: [162] [857600/1281167 (67%)]	Loss: 0.628288
[2022-06-12 09:53:25 | train] - Train Epoch: [162] [870400/1281167 (68%)]	Loss: 0.421969
[2022-06-12 09:53:44 | train] - Train Epoch: [162] [883200/1281167 (69%)]	Loss: 0.515652
[2022-06-12 09:54:03 | train] - Train Epoch: [162] [896000/1281167 (70%)]	Loss: 0.581032
[2022-06-12 09:54:23 | train] - Train Epoch: [162] [908800/1281167 (71%)]	Loss: 0.809147
[2022-06-12 09:54:42 | train] - Train Epoch: [162] [921600/1281167 (72%)]	Loss: 0.663661
[2022-06-12 09:55:02 | train] - Train Epoch: [162] [934400/1281167 (73%)]	Loss: 0.625392
[2022-06-12 09:55:22 | train] - Train Epoch: [162] [947200/1281167 (74%)]	Loss: 0.499651
[2022-06-12 09:55:41 | train] - Train Epoch: [162] [960000/1281167 (75%)]	Loss: 0.724013
[2022-06-12 09:56:00 | train] - Train Epoch: [162] [972800/1281167 (76%)]	Loss: 0.700039
[2022-06-12 09:56:20 | train] - Train Epoch: [162] [985600/1281167 (77%)]	Loss: 0.772232
[2022-06-12 09:56:40 | train] - Train Epoch: [162] [998400/1281167 (78%)]	Loss: 0.576836
[2022-06-12 09:56:59 | train] - Train Epoch: [162] [1011200/1281167 (79%)]	Loss: 0.844216
[2022-06-12 09:57:17 | train] - Train Epoch: [162] [1024000/1281167 (80%)]	Loss: 0.481531
[2022-06-12 09:57:37 | train] - Train Epoch: [162] [1036800/1281167 (81%)]	Loss: 0.689367
[2022-06-12 09:57:56 | train] - Train Epoch: [162] [1049600/1281167 (82%)]	Loss: 0.654539
[2022-06-12 09:58:15 | train] - Train Epoch: [162] [1062400/1281167 (83%)]	Loss: 0.954377
[2022-06-12 09:58:35 | train] - Train Epoch: [162] [1075200/1281167 (84%)]	Loss: 0.745242
[2022-06-12 09:58:54 | train] - Train Epoch: [162] [1088000/1281167 (85%)]	Loss: 0.801071
[2022-06-12 09:59:13 | train] - Train Epoch: [162] [1100800/1281167 (86%)]	Loss: 0.944576
[2022-06-12 09:59:32 | train] - Train Epoch: [162] [1113600/1281167 (87%)]	Loss: 0.560598
[2022-06-12 09:59:51 | train] - Train Epoch: [162] [1126400/1281167 (88%)]	Loss: 0.955813
[2022-06-12 10:00:11 | train] - Train Epoch: [162] [1139200/1281167 (89%)]	Loss: 0.675233
[2022-06-12 10:00:30 | train] - Train Epoch: [162] [1152000/1281167 (90%)]	Loss: 0.670711
[2022-06-12 10:00:50 | train] - Train Epoch: [162] [1164800/1281167 (91%)]	Loss: 0.908728
[2022-06-12 10:01:09 | train] - Train Epoch: [162] [1177600/1281167 (92%)]	Loss: 0.731082
[2022-06-12 10:01:28 | train] - Train Epoch: [162] [1190400/1281167 (93%)]	Loss: 0.890995
[2022-06-12 10:01:46 | train] - Train Epoch: [162] [1203200/1281167 (94%)]	Loss: 0.603315
[2022-06-12 10:02:06 | train] - Train Epoch: [162] [1216000/1281167 (95%)]	Loss: 0.686293
[2022-06-12 10:02:25 | train] - Train Epoch: [162] [1228800/1281167 (96%)]	Loss: 0.598455
[2022-06-12 10:02:45 | train] - Train Epoch: [162] [1241600/1281167 (97%)]	Loss: 0.706847
[2022-06-12 10:03:04 | train] - Train Epoch: [162] [1254400/1281167 (98%)]	Loss: 0.675962
[2022-06-12 10:03:24 | train] - Train Epoch: [162] [1267200/1281167 (99%)]	Loss: 0.652950
[2022-06-12 10:03:43 | train] - Train Epoch: [162] [1280000/1281167 (100%)]	Loss: 0.554268
[2022-06-12 10:03:45 | train] - Train Epoch: [162]	 Average Loss: 0.693600	 Total Acc : 83.1941	 Total Top5 Acc : 93.9120
[2022-06-12 10:03:45 | train] - -------162 epoch end-----------
========================================
-------162 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 10:05:14 | train] - 
Epoch [162] Test set: Average loss: 1.4270, Accuracy: 34926/50000 (69.8222%), Top-5 Accuracy: 88.9174%

[2022-06-12 10:05:14 | train] - save intermediate epoch [162] result


[2022-06-12 10:05:29 | train] - -------163 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 10:05:31 | train] - Train Epoch: [163] [0/1281167 (0%)]	Loss: 0.660452
[2022-06-12 10:05:51 | train] - Train Epoch: [163] [12800/1281167 (1%)]	Loss: 0.611096
[2022-06-12 10:06:12 | train] - Train Epoch: [163] [25600/1281167 (2%)]	Loss: 0.707484
[2022-06-12 10:06:31 | train] - Train Epoch: [163] [38400/1281167 (3%)]	Loss: 0.766604
[2022-06-12 10:06:51 | train] - Train Epoch: [163] [51200/1281167 (4%)]	Loss: 0.591676
[2022-06-12 10:07:12 | train] - Train Epoch: [163] [64000/1281167 (5%)]	Loss: 0.673622
[2022-06-12 10:07:32 | train] - Train Epoch: [163] [76800/1281167 (6%)]	Loss: 0.782339
[2022-06-12 10:07:52 | train] - Train Epoch: [163] [89600/1281167 (7%)]	Loss: 0.899800
[2022-06-12 10:08:13 | train] - Train Epoch: [163] [102400/1281167 (8%)]	Loss: 1.054791
[2022-06-12 10:08:34 | train] - Train Epoch: [163] [115200/1281167 (9%)]	Loss: 0.858292
[2022-06-12 10:08:55 | train] - Train Epoch: [163] [128000/1281167 (10%)]	Loss: 0.677327
[2022-06-12 10:09:14 | train] - Train Epoch: [163] [140800/1281167 (11%)]	Loss: 0.657098
[2022-06-12 10:09:34 | train] - Train Epoch: [163] [153600/1281167 (12%)]	Loss: 0.513553
[2022-06-12 10:09:54 | train] - Train Epoch: [163] [166400/1281167 (13%)]	Loss: 0.593432
[2022-06-12 10:10:14 | train] - Train Epoch: [163] [179200/1281167 (14%)]	Loss: 0.752288
[2022-06-12 10:10:34 | train] - Train Epoch: [163] [192000/1281167 (15%)]	Loss: 0.568913
[2022-06-12 10:10:53 | train] - Train Epoch: [163] [204800/1281167 (16%)]	Loss: 0.589205
[2022-06-12 10:11:13 | train] - Train Epoch: [163] [217600/1281167 (17%)]	Loss: 0.699916
[2022-06-12 10:11:33 | train] - Train Epoch: [163] [230400/1281167 (18%)]	Loss: 0.552076
[2022-06-12 10:11:52 | train] - Train Epoch: [163] [243200/1281167 (19%)]	Loss: 0.779844
[2022-06-12 10:12:11 | train] - Train Epoch: [163] [256000/1281167 (20%)]	Loss: 0.826703
[2022-06-12 10:12:31 | train] - Train Epoch: [163] [268800/1281167 (21%)]	Loss: 0.597716
[2022-06-12 10:12:51 | train] - Train Epoch: [163] [281600/1281167 (22%)]	Loss: 0.676535
[2022-06-12 10:13:11 | train] - Train Epoch: [163] [294400/1281167 (23%)]	Loss: 0.502914
[2022-06-12 10:13:30 | train] - Train Epoch: [163] [307200/1281167 (24%)]	Loss: 0.699256
[2022-06-12 10:13:51 | train] - Train Epoch: [163] [320000/1281167 (25%)]	Loss: 0.740988
[2022-06-12 10:14:10 | train] - Train Epoch: [163] [332800/1281167 (26%)]	Loss: 0.810365
[2022-06-12 10:14:29 | train] - Train Epoch: [163] [345600/1281167 (27%)]	Loss: 1.179031
[2022-06-12 10:14:49 | train] - Train Epoch: [163] [358400/1281167 (28%)]	Loss: 0.765625
[2022-06-12 10:15:09 | train] - Train Epoch: [163] [371200/1281167 (29%)]	Loss: 0.678782
[2022-06-12 10:15:29 | train] - Train Epoch: [163] [384000/1281167 (30%)]	Loss: 0.734930
[2022-06-12 10:15:48 | train] - Train Epoch: [163] [396800/1281167 (31%)]	Loss: 0.930051
[2022-06-12 10:16:09 | train] - Train Epoch: [163] [409600/1281167 (32%)]	Loss: 0.588368
[2022-06-12 10:16:29 | train] - Train Epoch: [163] [422400/1281167 (33%)]	Loss: 0.708776
[2022-06-12 10:16:49 | train] - Train Epoch: [163] [435200/1281167 (34%)]	Loss: 0.873626
[2022-06-12 10:17:09 | train] - Train Epoch: [163] [448000/1281167 (35%)]	Loss: 0.984708
[2022-06-12 10:17:29 | train] - Train Epoch: [163] [460800/1281167 (36%)]	Loss: 0.452223
[2022-06-12 10:17:48 | train] - Train Epoch: [163] [473600/1281167 (37%)]	Loss: 0.747502
[2022-06-12 10:18:08 | train] - Train Epoch: [163] [486400/1281167 (38%)]	Loss: 0.790124
[2022-06-12 10:18:29 | train] - Train Epoch: [163] [499200/1281167 (39%)]	Loss: 0.843068
[2022-06-12 10:18:47 | train] - Train Epoch: [163] [512000/1281167 (40%)]	Loss: 0.890927
[2022-06-12 10:19:08 | train] - Train Epoch: [163] [524800/1281167 (41%)]	Loss: 0.965795
[2022-06-12 10:19:28 | train] - Train Epoch: [163] [537600/1281167 (42%)]	Loss: 0.857398
[2022-06-12 10:19:47 | train] - Train Epoch: [163] [550400/1281167 (43%)]	Loss: 0.861776
[2022-06-12 10:20:07 | train] - Train Epoch: [163] [563200/1281167 (44%)]	Loss: 0.608338
[2022-06-12 10:20:26 | train] - Train Epoch: [163] [576000/1281167 (45%)]	Loss: 0.708739
[2022-06-12 10:20:46 | train] - Train Epoch: [163] [588800/1281167 (46%)]	Loss: 0.711731
[2022-06-12 10:21:06 | train] - Train Epoch: [163] [601600/1281167 (47%)]	Loss: 0.679587
[2022-06-12 10:21:25 | train] - Train Epoch: [163] [614400/1281167 (48%)]	Loss: 0.870261
[2022-06-12 10:21:47 | train] - Train Epoch: [163] [627200/1281167 (49%)]	Loss: 0.647662
[2022-06-12 10:22:07 | train] - Train Epoch: [163] [640000/1281167 (50%)]	Loss: 0.663630
[2022-06-12 10:22:28 | train] - Train Epoch: [163] [652800/1281167 (51%)]	Loss: 0.668693
[2022-06-12 10:22:48 | train] - Train Epoch: [163] [665600/1281167 (52%)]	Loss: 0.522466
[2022-06-12 10:23:07 | train] - Train Epoch: [163] [678400/1281167 (53%)]	Loss: 0.471089
[2022-06-12 10:23:28 | train] - Train Epoch: [163] [691200/1281167 (54%)]	Loss: 0.607373
[2022-06-12 10:23:48 | train] - Train Epoch: [163] [704000/1281167 (55%)]	Loss: 0.429279
[2022-06-12 10:24:08 | train] - Train Epoch: [163] [716800/1281167 (56%)]	Loss: 0.618287
[2022-06-12 10:24:27 | train] - Train Epoch: [163] [729600/1281167 (57%)]	Loss: 0.546798
[2022-06-12 10:24:47 | train] - Train Epoch: [163] [742400/1281167 (58%)]	Loss: 0.810638
[2022-06-12 10:25:07 | train] - Train Epoch: [163] [755200/1281167 (59%)]	Loss: 0.573449
[2022-06-12 10:25:26 | train] - Train Epoch: [163] [768000/1281167 (60%)]	Loss: 0.617338
[2022-06-12 10:25:46 | train] - Train Epoch: [163] [780800/1281167 (61%)]	Loss: 0.818852
[2022-06-12 10:26:06 | train] - Train Epoch: [163] [793600/1281167 (62%)]	Loss: 0.734396
[2022-06-12 10:26:26 | train] - Train Epoch: [163] [806400/1281167 (63%)]	Loss: 0.697338
[2022-06-12 10:26:46 | train] - Train Epoch: [163] [819200/1281167 (64%)]	Loss: 0.746430
[2022-06-12 10:27:05 | train] - Train Epoch: [163] [832000/1281167 (65%)]	Loss: 0.878808
[2022-06-12 10:27:25 | train] - Train Epoch: [163] [844800/1281167 (66%)]	Loss: 0.896646
[2022-06-12 10:27:44 | train] - Train Epoch: [163] [857600/1281167 (67%)]	Loss: 0.883183
[2022-06-12 10:28:04 | train] - Train Epoch: [163] [870400/1281167 (68%)]	Loss: 0.732203
[2022-06-12 10:28:24 | train] - Train Epoch: [163] [883200/1281167 (69%)]	Loss: 0.506297
[2022-06-12 10:28:43 | train] - Train Epoch: [163] [896000/1281167 (70%)]	Loss: 0.679173
[2022-06-12 10:29:03 | train] - Train Epoch: [163] [908800/1281167 (71%)]	Loss: 0.887002
[2022-06-12 10:29:22 | train] - Train Epoch: [163] [921600/1281167 (72%)]	Loss: 0.533760
[2022-06-12 10:29:42 | train] - Train Epoch: [163] [934400/1281167 (73%)]	Loss: 0.469313
[2022-06-12 10:30:02 | train] - Train Epoch: [163] [947200/1281167 (74%)]	Loss: 0.587860
[2022-06-12 10:30:21 | train] - Train Epoch: [163] [960000/1281167 (75%)]	Loss: 0.638097
[2022-06-12 10:30:41 | train] - Train Epoch: [163] [972800/1281167 (76%)]	Loss: 0.805590
[2022-06-12 10:31:01 | train] - Train Epoch: [163] [985600/1281167 (77%)]	Loss: 0.939287
[2022-06-12 10:31:20 | train] - Train Epoch: [163] [998400/1281167 (78%)]	Loss: 0.838388
[2022-06-12 10:31:40 | train] - Train Epoch: [163] [1011200/1281167 (79%)]	Loss: 0.752258
[2022-06-12 10:31:59 | train] - Train Epoch: [163] [1024000/1281167 (80%)]	Loss: 0.689149
[2022-06-12 10:32:18 | train] - Train Epoch: [163] [1036800/1281167 (81%)]	Loss: 0.663657
[2022-06-12 10:32:38 | train] - Train Epoch: [163] [1049600/1281167 (82%)]	Loss: 0.491866
[2022-06-12 10:32:57 | train] - Train Epoch: [163] [1062400/1281167 (83%)]	Loss: 0.782003
[2022-06-12 10:33:17 | train] - Train Epoch: [163] [1075200/1281167 (84%)]	Loss: 0.585732
[2022-06-12 10:33:36 | train] - Train Epoch: [163] [1088000/1281167 (85%)]	Loss: 0.499847
[2022-06-12 10:33:56 | train] - Train Epoch: [163] [1100800/1281167 (86%)]	Loss: 0.783134
[2022-06-12 10:34:15 | train] - Train Epoch: [163] [1113600/1281167 (87%)]	Loss: 0.751850
[2022-06-12 10:34:35 | train] - Train Epoch: [163] [1126400/1281167 (88%)]	Loss: 0.759065
[2022-06-12 10:34:55 | train] - Train Epoch: [163] [1139200/1281167 (89%)]	Loss: 0.768608
[2022-06-12 10:35:14 | train] - Train Epoch: [163] [1152000/1281167 (90%)]	Loss: 0.815041
[2022-06-12 10:35:34 | train] - Train Epoch: [163] [1164800/1281167 (91%)]	Loss: 0.620384
[2022-06-12 10:35:54 | train] - Train Epoch: [163] [1177600/1281167 (92%)]	Loss: 0.740764
[2022-06-12 10:36:13 | train] - Train Epoch: [163] [1190400/1281167 (93%)]	Loss: 0.651891
[2022-06-12 10:36:33 | train] - Train Epoch: [163] [1203200/1281167 (94%)]	Loss: 0.861916
[2022-06-12 10:36:53 | train] - Train Epoch: [163] [1216000/1281167 (95%)]	Loss: 0.493704
[2022-06-12 10:37:12 | train] - Train Epoch: [163] [1228800/1281167 (96%)]	Loss: 0.770842
[2022-06-12 10:37:31 | train] - Train Epoch: [163] [1241600/1281167 (97%)]	Loss: 0.862638
[2022-06-12 10:37:50 | train] - Train Epoch: [163] [1254400/1281167 (98%)]	Loss: 0.584291
[2022-06-12 10:38:09 | train] - Train Epoch: [163] [1267200/1281167 (99%)]	Loss: 0.611099
[2022-06-12 10:38:28 | train] - Train Epoch: [163] [1280000/1281167 (100%)]	Loss: 0.618523
[2022-06-12 10:38:30 | train] - Train Epoch: [163]	 Average Loss: 0.691181	 Total Acc : 83.2345	 Total Top5 Acc : 93.9467
[2022-06-12 10:38:30 | train] - -------163 epoch end-----------
========================================
-------163 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 10:39:59 | train] - 
Epoch [163] Test set: Average loss: 1.4249, Accuracy: 34945/50000 (69.8589%), Top-5 Accuracy: 88.9422%

[2022-06-12 10:39:59 | train] - save intermediate epoch [163] result


[2022-06-12 10:40:14 | train] - -------164 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 10:40:16 | train] - Train Epoch: [164] [0/1281167 (0%)]	Loss: 0.470781
[2022-06-12 10:40:37 | train] - Train Epoch: [164] [12800/1281167 (1%)]	Loss: 0.680968
[2022-06-12 10:40:57 | train] - Train Epoch: [164] [25600/1281167 (2%)]	Loss: 0.734274
[2022-06-12 10:41:16 | train] - Train Epoch: [164] [38400/1281167 (3%)]	Loss: 0.612975
[2022-06-12 10:41:36 | train] - Train Epoch: [164] [51200/1281167 (4%)]	Loss: 0.549208
[2022-06-12 10:41:55 | train] - Train Epoch: [164] [64000/1281167 (5%)]	Loss: 0.969509
[2022-06-12 10:42:15 | train] - Train Epoch: [164] [76800/1281167 (6%)]	Loss: 0.651728
[2022-06-12 10:42:35 | train] - Train Epoch: [164] [89600/1281167 (7%)]	Loss: 0.521951
[2022-06-12 10:42:54 | train] - Train Epoch: [164] [102400/1281167 (8%)]	Loss: 0.604340
[2022-06-12 10:43:14 | train] - Train Epoch: [164] [115200/1281167 (9%)]	Loss: 0.744716
[2022-06-12 10:43:34 | train] - Train Epoch: [164] [128000/1281167 (10%)]	Loss: 0.743230
[2022-06-12 10:43:53 | train] - Train Epoch: [164] [140800/1281167 (11%)]	Loss: 0.648219
[2022-06-12 10:44:12 | train] - Train Epoch: [164] [153600/1281167 (12%)]	Loss: 1.091516
[2022-06-12 10:44:31 | train] - Train Epoch: [164] [166400/1281167 (13%)]	Loss: 0.566061
[2022-06-12 10:44:51 | train] - Train Epoch: [164] [179200/1281167 (14%)]	Loss: 0.795082
[2022-06-12 10:45:11 | train] - Train Epoch: [164] [192000/1281167 (15%)]	Loss: 0.678653
[2022-06-12 10:45:30 | train] - Train Epoch: [164] [204800/1281167 (16%)]	Loss: 0.791338
[2022-06-12 10:45:50 | train] - Train Epoch: [164] [217600/1281167 (17%)]	Loss: 0.655058
[2022-06-12 10:46:09 | train] - Train Epoch: [164] [230400/1281167 (18%)]	Loss: 0.665679
[2022-06-12 10:46:29 | train] - Train Epoch: [164] [243200/1281167 (19%)]	Loss: 0.590533
[2022-06-12 10:46:49 | train] - Train Epoch: [164] [256000/1281167 (20%)]	Loss: 0.410490
[2022-06-12 10:47:08 | train] - Train Epoch: [164] [268800/1281167 (21%)]	Loss: 1.005781
[2022-06-12 10:47:27 | train] - Train Epoch: [164] [281600/1281167 (22%)]	Loss: 0.533725
[2022-06-12 10:47:47 | train] - Train Epoch: [164] [294400/1281167 (23%)]	Loss: 0.860731
[2022-06-12 10:48:07 | train] - Train Epoch: [164] [307200/1281167 (24%)]	Loss: 0.676561
[2022-06-12 10:48:26 | train] - Train Epoch: [164] [320000/1281167 (25%)]	Loss: 0.931158
[2022-06-12 10:48:45 | train] - Train Epoch: [164] [332800/1281167 (26%)]	Loss: 0.751383
[2022-06-12 10:49:04 | train] - Train Epoch: [164] [345600/1281167 (27%)]	Loss: 0.859321
[2022-06-12 10:49:24 | train] - Train Epoch: [164] [358400/1281167 (28%)]	Loss: 0.845575
[2022-06-12 10:49:43 | train] - Train Epoch: [164] [371200/1281167 (29%)]	Loss: 0.746924
[2022-06-12 10:50:03 | train] - Train Epoch: [164] [384000/1281167 (30%)]	Loss: 0.827881
[2022-06-12 10:50:23 | train] - Train Epoch: [164] [396800/1281167 (31%)]	Loss: 0.575035
[2022-06-12 10:50:42 | train] - Train Epoch: [164] [409600/1281167 (32%)]	Loss: 0.721453
[2022-06-12 10:51:01 | train] - Train Epoch: [164] [422400/1281167 (33%)]	Loss: 0.813542
[2022-06-12 10:51:21 | train] - Train Epoch: [164] [435200/1281167 (34%)]	Loss: 0.692482
[2022-06-12 10:51:40 | train] - Train Epoch: [164] [448000/1281167 (35%)]	Loss: 0.827553
[2022-06-12 10:51:59 | train] - Train Epoch: [164] [460800/1281167 (36%)]	Loss: 0.640882
[2022-06-12 10:52:19 | train] - Train Epoch: [164] [473600/1281167 (37%)]	Loss: 0.609815
[2022-06-12 10:52:38 | train] - Train Epoch: [164] [486400/1281167 (38%)]	Loss: 0.713209
[2022-06-12 10:52:58 | train] - Train Epoch: [164] [499200/1281167 (39%)]	Loss: 0.505644
[2022-06-12 10:53:17 | train] - Train Epoch: [164] [512000/1281167 (40%)]	Loss: 0.557918
[2022-06-12 10:53:37 | train] - Train Epoch: [164] [524800/1281167 (41%)]	Loss: 0.686245
[2022-06-12 10:53:56 | train] - Train Epoch: [164] [537600/1281167 (42%)]	Loss: 0.650825
[2022-06-12 10:54:15 | train] - Train Epoch: [164] [550400/1281167 (43%)]	Loss: 0.661429
[2022-06-12 10:54:34 | train] - Train Epoch: [164] [563200/1281167 (44%)]	Loss: 0.728761
[2022-06-12 10:54:54 | train] - Train Epoch: [164] [576000/1281167 (45%)]	Loss: 0.696836
[2022-06-12 10:55:14 | train] - Train Epoch: [164] [588800/1281167 (46%)]	Loss: 0.828810
[2022-06-12 10:55:33 | train] - Train Epoch: [164] [601600/1281167 (47%)]	Loss: 0.886787
[2022-06-12 10:55:53 | train] - Train Epoch: [164] [614400/1281167 (48%)]	Loss: 0.568794
[2022-06-12 10:56:13 | train] - Train Epoch: [164] [627200/1281167 (49%)]	Loss: 0.726489
[2022-06-12 10:56:32 | train] - Train Epoch: [164] [640000/1281167 (50%)]	Loss: 0.672726
[2022-06-12 10:56:52 | train] - Train Epoch: [164] [652800/1281167 (51%)]	Loss: 0.840333
[2022-06-12 10:57:11 | train] - Train Epoch: [164] [665600/1281167 (52%)]	Loss: 0.517563
[2022-06-12 10:57:30 | train] - Train Epoch: [164] [678400/1281167 (53%)]	Loss: 0.689838
[2022-06-12 10:57:50 | train] - Train Epoch: [164] [691200/1281167 (54%)]	Loss: 0.934528
[2022-06-12 10:58:10 | train] - Train Epoch: [164] [704000/1281167 (55%)]	Loss: 0.608731
[2022-06-12 10:58:29 | train] - Train Epoch: [164] [716800/1281167 (56%)]	Loss: 0.334947
[2022-06-12 10:58:49 | train] - Train Epoch: [164] [729600/1281167 (57%)]	Loss: 0.547453
[2022-06-12 10:59:09 | train] - Train Epoch: [164] [742400/1281167 (58%)]	Loss: 0.644186
[2022-06-12 10:59:29 | train] - Train Epoch: [164] [755200/1281167 (59%)]	Loss: 0.657943
[2022-06-12 10:59:48 | train] - Train Epoch: [164] [768000/1281167 (60%)]	Loss: 0.537430
[2022-06-12 11:00:08 | train] - Train Epoch: [164] [780800/1281167 (61%)]	Loss: 0.647488
[2022-06-12 11:00:27 | train] - Train Epoch: [164] [793600/1281167 (62%)]	Loss: 0.922305
[2022-06-12 11:00:46 | train] - Train Epoch: [164] [806400/1281167 (63%)]	Loss: 0.593406
[2022-06-12 11:01:06 | train] - Train Epoch: [164] [819200/1281167 (64%)]	Loss: 0.639498
[2022-06-12 11:01:25 | train] - Train Epoch: [164] [832000/1281167 (65%)]	Loss: 0.657756
[2022-06-12 11:01:45 | train] - Train Epoch: [164] [844800/1281167 (66%)]	Loss: 0.944648
[2022-06-12 11:02:04 | train] - Train Epoch: [164] [857600/1281167 (67%)]	Loss: 0.615820
[2022-06-12 11:02:24 | train] - Train Epoch: [164] [870400/1281167 (68%)]	Loss: 0.573502
[2022-06-12 11:02:44 | train] - Train Epoch: [164] [883200/1281167 (69%)]	Loss: 0.701188
[2022-06-12 11:03:03 | train] - Train Epoch: [164] [896000/1281167 (70%)]	Loss: 0.493916
[2022-06-12 11:03:23 | train] - Train Epoch: [164] [908800/1281167 (71%)]	Loss: 0.745833
[2022-06-12 11:03:42 | train] - Train Epoch: [164] [921600/1281167 (72%)]	Loss: 0.684566
[2022-06-12 11:04:02 | train] - Train Epoch: [164] [934400/1281167 (73%)]	Loss: 0.571051
[2022-06-12 11:04:21 | train] - Train Epoch: [164] [947200/1281167 (74%)]	Loss: 0.634241
[2022-06-12 11:04:41 | train] - Train Epoch: [164] [960000/1281167 (75%)]	Loss: 0.788719
[2022-06-12 11:05:01 | train] - Train Epoch: [164] [972800/1281167 (76%)]	Loss: 0.511763
[2022-06-12 11:05:20 | train] - Train Epoch: [164] [985600/1281167 (77%)]	Loss: 0.556531
[2022-06-12 11:05:40 | train] - Train Epoch: [164] [998400/1281167 (78%)]	Loss: 0.850821
[2022-06-12 11:05:59 | train] - Train Epoch: [164] [1011200/1281167 (79%)]	Loss: 0.622834
[2022-06-12 11:06:18 | train] - Train Epoch: [164] [1024000/1281167 (80%)]	Loss: 0.607499
[2022-06-12 11:06:38 | train] - Train Epoch: [164] [1036800/1281167 (81%)]	Loss: 0.686158
[2022-06-12 11:06:57 | train] - Train Epoch: [164] [1049600/1281167 (82%)]	Loss: 0.786419
[2022-06-12 11:07:16 | train] - Train Epoch: [164] [1062400/1281167 (83%)]	Loss: 0.794110
[2022-06-12 11:07:36 | train] - Train Epoch: [164] [1075200/1281167 (84%)]	Loss: 0.535368
[2022-06-12 11:07:56 | train] - Train Epoch: [164] [1088000/1281167 (85%)]	Loss: 0.602170
[2022-06-12 11:08:15 | train] - Train Epoch: [164] [1100800/1281167 (86%)]	Loss: 0.666769
[2022-06-12 11:08:35 | train] - Train Epoch: [164] [1113600/1281167 (87%)]	Loss: 0.643849
[2022-06-12 11:08:54 | train] - Train Epoch: [164] [1126400/1281167 (88%)]	Loss: 0.843162
[2022-06-12 11:09:14 | train] - Train Epoch: [164] [1139200/1281167 (89%)]	Loss: 0.698052
[2022-06-12 11:09:33 | train] - Train Epoch: [164] [1152000/1281167 (90%)]	Loss: 0.857469
[2022-06-12 11:09:54 | train] - Train Epoch: [164] [1164800/1281167 (91%)]	Loss: 0.541712
[2022-06-12 11:10:13 | train] - Train Epoch: [164] [1177600/1281167 (92%)]	Loss: 0.665625
[2022-06-12 11:10:33 | train] - Train Epoch: [164] [1190400/1281167 (93%)]	Loss: 0.417892
[2022-06-12 11:10:53 | train] - Train Epoch: [164] [1203200/1281167 (94%)]	Loss: 0.638135
[2022-06-12 11:11:12 | train] - Train Epoch: [164] [1216000/1281167 (95%)]	Loss: 0.560163
[2022-06-12 11:11:32 | train] - Train Epoch: [164] [1228800/1281167 (96%)]	Loss: 0.823580
[2022-06-12 11:11:52 | train] - Train Epoch: [164] [1241600/1281167 (97%)]	Loss: 0.679750
[2022-06-12 11:12:11 | train] - Train Epoch: [164] [1254400/1281167 (98%)]	Loss: 0.493495
[2022-06-12 11:12:31 | train] - Train Epoch: [164] [1267200/1281167 (99%)]	Loss: 0.746494
[2022-06-12 11:12:50 | train] - Train Epoch: [164] [1280000/1281167 (100%)]	Loss: 0.611433
[2022-06-12 11:12:52 | train] - Train Epoch: [164]	 Average Loss: 0.688688	 Total Acc : 83.3167	 Total Top5 Acc : 93.9682
[2022-06-12 11:12:52 | train] - -------164 epoch end-----------
========================================
-------164 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 11:14:24 | train] - 
Epoch [164] Test set: Average loss: 1.4293, Accuracy: 34985/50000 (69.9425%), Top-5 Accuracy: 88.9542%

[2022-06-12 11:14:24 | train] - save intermediate epoch [164] result


[2022-06-12 11:14:39 | train] - -------165 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 11:14:41 | train] - Train Epoch: [165] [0/1281167 (0%)]	Loss: 0.936996
[2022-06-12 11:15:02 | train] - Train Epoch: [165] [12800/1281167 (1%)]	Loss: 0.428629
[2022-06-12 11:15:21 | train] - Train Epoch: [165] [25600/1281167 (2%)]	Loss: 0.625888
[2022-06-12 11:15:41 | train] - Train Epoch: [165] [38400/1281167 (3%)]	Loss: 0.802094
[2022-06-12 11:16:01 | train] - Train Epoch: [165] [51200/1281167 (4%)]	Loss: 0.591916
[2022-06-12 11:16:20 | train] - Train Epoch: [165] [64000/1281167 (5%)]	Loss: 0.770858
[2022-06-12 11:16:39 | train] - Train Epoch: [165] [76800/1281167 (6%)]	Loss: 0.852051
[2022-06-12 11:16:59 | train] - Train Epoch: [165] [89600/1281167 (7%)]	Loss: 0.692267
[2022-06-12 11:17:19 | train] - Train Epoch: [165] [102400/1281167 (8%)]	Loss: 0.526531
[2022-06-12 11:17:39 | train] - Train Epoch: [165] [115200/1281167 (9%)]	Loss: 0.730790
[2022-06-12 11:17:58 | train] - Train Epoch: [165] [128000/1281167 (10%)]	Loss: 0.785382
[2022-06-12 11:18:18 | train] - Train Epoch: [165] [140800/1281167 (11%)]	Loss: 0.562579
[2022-06-12 11:18:38 | train] - Train Epoch: [165] [153600/1281167 (12%)]	Loss: 0.648607
[2022-06-12 11:18:58 | train] - Train Epoch: [165] [166400/1281167 (13%)]	Loss: 0.581227
[2022-06-12 11:19:17 | train] - Train Epoch: [165] [179200/1281167 (14%)]	Loss: 0.549636
[2022-06-12 11:19:36 | train] - Train Epoch: [165] [192000/1281167 (15%)]	Loss: 0.816432
[2022-06-12 11:19:56 | train] - Train Epoch: [165] [204800/1281167 (16%)]	Loss: 0.687085
[2022-06-12 11:20:15 | train] - Train Epoch: [165] [217600/1281167 (17%)]	Loss: 0.749404
[2022-06-12 11:20:34 | train] - Train Epoch: [165] [230400/1281167 (18%)]	Loss: 0.880983
[2022-06-12 11:20:54 | train] - Train Epoch: [165] [243200/1281167 (19%)]	Loss: 0.530776
[2022-06-12 11:21:13 | train] - Train Epoch: [165] [256000/1281167 (20%)]	Loss: 0.746394
[2022-06-12 11:21:33 | train] - Train Epoch: [165] [268800/1281167 (21%)]	Loss: 0.539808
[2022-06-12 11:21:52 | train] - Train Epoch: [165] [281600/1281167 (22%)]	Loss: 0.730266
[2022-06-12 11:22:12 | train] - Train Epoch: [165] [294400/1281167 (23%)]	Loss: 0.709352
[2022-06-12 11:22:32 | train] - Train Epoch: [165] [307200/1281167 (24%)]	Loss: 0.894964
[2022-06-12 11:22:52 | train] - Train Epoch: [165] [320000/1281167 (25%)]	Loss: 0.953701
[2022-06-12 11:23:11 | train] - Train Epoch: [165] [332800/1281167 (26%)]	Loss: 0.766229
[2022-06-12 11:23:31 | train] - Train Epoch: [165] [345600/1281167 (27%)]	Loss: 0.496569
[2022-06-12 11:23:51 | train] - Train Epoch: [165] [358400/1281167 (28%)]	Loss: 0.694383
[2022-06-12 11:24:11 | train] - Train Epoch: [165] [371200/1281167 (29%)]	Loss: 0.650666
[2022-06-12 11:24:30 | train] - Train Epoch: [165] [384000/1281167 (30%)]	Loss: 0.596354
[2022-06-12 11:24:50 | train] - Train Epoch: [165] [396800/1281167 (31%)]	Loss: 0.749313
[2022-06-12 11:25:09 | train] - Train Epoch: [165] [409600/1281167 (32%)]	Loss: 0.497388
[2022-06-12 11:25:29 | train] - Train Epoch: [165] [422400/1281167 (33%)]	Loss: 0.355531
[2022-06-12 11:25:48 | train] - Train Epoch: [165] [435200/1281167 (34%)]	Loss: 0.718322
[2022-06-12 11:26:08 | train] - Train Epoch: [165] [448000/1281167 (35%)]	Loss: 0.573753
[2022-06-12 11:26:28 | train] - Train Epoch: [165] [460800/1281167 (36%)]	Loss: 0.883407
[2022-06-12 11:26:48 | train] - Train Epoch: [165] [473600/1281167 (37%)]	Loss: 0.724999
[2022-06-12 11:27:08 | train] - Train Epoch: [165] [486400/1281167 (38%)]	Loss: 0.718056
[2022-06-12 11:27:27 | train] - Train Epoch: [165] [499200/1281167 (39%)]	Loss: 0.453662
[2022-06-12 11:27:47 | train] - Train Epoch: [165] [512000/1281167 (40%)]	Loss: 0.663813
[2022-06-12 11:28:07 | train] - Train Epoch: [165] [524800/1281167 (41%)]	Loss: 0.470500
[2022-06-12 11:28:26 | train] - Train Epoch: [165] [537600/1281167 (42%)]	Loss: 0.555469
[2022-06-12 11:28:46 | train] - Train Epoch: [165] [550400/1281167 (43%)]	Loss: 0.543475
[2022-06-12 11:29:05 | train] - Train Epoch: [165] [563200/1281167 (44%)]	Loss: 0.635405
[2022-06-12 11:29:24 | train] - Train Epoch: [165] [576000/1281167 (45%)]	Loss: 0.574075
[2022-06-12 11:29:44 | train] - Train Epoch: [165] [588800/1281167 (46%)]	Loss: 0.820169
[2022-06-12 11:30:03 | train] - Train Epoch: [165] [601600/1281167 (47%)]	Loss: 1.015308
[2022-06-12 11:30:23 | train] - Train Epoch: [165] [614400/1281167 (48%)]	Loss: 0.613044
[2022-06-12 11:30:42 | train] - Train Epoch: [165] [627200/1281167 (49%)]	Loss: 0.740487
[2022-06-12 11:31:01 | train] - Train Epoch: [165] [640000/1281167 (50%)]	Loss: 0.901600
[2022-06-12 11:31:21 | train] - Train Epoch: [165] [652800/1281167 (51%)]	Loss: 0.683442
[2022-06-12 11:31:40 | train] - Train Epoch: [165] [665600/1281167 (52%)]	Loss: 0.761514
[2022-06-12 11:32:01 | train] - Train Epoch: [165] [678400/1281167 (53%)]	Loss: 0.558702
[2022-06-12 11:32:20 | train] - Train Epoch: [165] [691200/1281167 (54%)]	Loss: 0.560594
[2022-06-12 11:32:39 | train] - Train Epoch: [165] [704000/1281167 (55%)]	Loss: 0.512702
[2022-06-12 11:32:59 | train] - Train Epoch: [165] [716800/1281167 (56%)]	Loss: 0.791389
[2022-06-12 11:33:18 | train] - Train Epoch: [165] [729600/1281167 (57%)]	Loss: 0.646399
[2022-06-12 11:33:38 | train] - Train Epoch: [165] [742400/1281167 (58%)]	Loss: 0.697024
[2022-06-12 11:33:57 | train] - Train Epoch: [165] [755200/1281167 (59%)]	Loss: 0.801705
[2022-06-12 11:34:16 | train] - Train Epoch: [165] [768000/1281167 (60%)]	Loss: 0.809888
[2022-06-12 11:34:36 | train] - Train Epoch: [165] [780800/1281167 (61%)]	Loss: 0.738262
[2022-06-12 11:34:56 | train] - Train Epoch: [165] [793600/1281167 (62%)]	Loss: 0.792254
[2022-06-12 11:35:16 | train] - Train Epoch: [165] [806400/1281167 (63%)]	Loss: 0.870338
[2022-06-12 11:35:36 | train] - Train Epoch: [165] [819200/1281167 (64%)]	Loss: 0.790525
[2022-06-12 11:35:56 | train] - Train Epoch: [165] [832000/1281167 (65%)]	Loss: 0.896550
[2022-06-12 11:36:15 | train] - Train Epoch: [165] [844800/1281167 (66%)]	Loss: 0.480968
[2022-06-12 11:36:34 | train] - Train Epoch: [165] [857600/1281167 (67%)]	Loss: 0.572560
[2022-06-12 11:36:54 | train] - Train Epoch: [165] [870400/1281167 (68%)]	Loss: 0.588184
[2022-06-12 11:37:13 | train] - Train Epoch: [165] [883200/1281167 (69%)]	Loss: 0.492571
[2022-06-12 11:37:32 | train] - Train Epoch: [165] [896000/1281167 (70%)]	Loss: 0.786053
[2022-06-12 11:37:52 | train] - Train Epoch: [165] [908800/1281167 (71%)]	Loss: 0.742429
[2022-06-12 11:38:12 | train] - Train Epoch: [165] [921600/1281167 (72%)]	Loss: 0.700902
[2022-06-12 11:38:31 | train] - Train Epoch: [165] [934400/1281167 (73%)]	Loss: 0.602001
[2022-06-12 11:38:51 | train] - Train Epoch: [165] [947200/1281167 (74%)]	Loss: 0.629691
[2022-06-12 11:39:10 | train] - Train Epoch: [165] [960000/1281167 (75%)]	Loss: 0.572340
[2022-06-12 11:39:30 | train] - Train Epoch: [165] [972800/1281167 (76%)]	Loss: 0.636883
[2022-06-12 11:39:50 | train] - Train Epoch: [165] [985600/1281167 (77%)]	Loss: 0.860374
[2022-06-12 11:40:10 | train] - Train Epoch: [165] [998400/1281167 (78%)]	Loss: 0.605282
[2022-06-12 11:40:29 | train] - Train Epoch: [165] [1011200/1281167 (79%)]	Loss: 0.838876
[2022-06-12 11:40:48 | train] - Train Epoch: [165] [1024000/1281167 (80%)]	Loss: 0.408137
[2022-06-12 11:41:08 | train] - Train Epoch: [165] [1036800/1281167 (81%)]	Loss: 0.366149
[2022-06-12 11:41:28 | train] - Train Epoch: [165] [1049600/1281167 (82%)]	Loss: 0.640062
[2022-06-12 11:41:48 | train] - Train Epoch: [165] [1062400/1281167 (83%)]	Loss: 0.393566
[2022-06-12 11:42:07 | train] - Train Epoch: [165] [1075200/1281167 (84%)]	Loss: 0.344915
[2022-06-12 11:42:26 | train] - Train Epoch: [165] [1088000/1281167 (85%)]	Loss: 0.572152
[2022-06-12 11:42:46 | train] - Train Epoch: [165] [1100800/1281167 (86%)]	Loss: 0.773736
[2022-06-12 11:43:05 | train] - Train Epoch: [165] [1113600/1281167 (87%)]	Loss: 0.873310
[2022-06-12 11:43:24 | train] - Train Epoch: [165] [1126400/1281167 (88%)]	Loss: 0.533393
[2022-06-12 11:43:44 | train] - Train Epoch: [165] [1139200/1281167 (89%)]	Loss: 0.620977
[2022-06-12 11:44:04 | train] - Train Epoch: [165] [1152000/1281167 (90%)]	Loss: 0.888288
[2022-06-12 11:44:23 | train] - Train Epoch: [165] [1164800/1281167 (91%)]	Loss: 0.807428
[2022-06-12 11:44:43 | train] - Train Epoch: [165] [1177600/1281167 (92%)]	Loss: 0.629245
[2022-06-12 11:45:02 | train] - Train Epoch: [165] [1190400/1281167 (93%)]	Loss: 0.999306
[2022-06-12 11:45:21 | train] - Train Epoch: [165] [1203200/1281167 (94%)]	Loss: 0.390575
[2022-06-12 11:45:41 | train] - Train Epoch: [165] [1216000/1281167 (95%)]	Loss: 0.908187
[2022-06-12 11:46:01 | train] - Train Epoch: [165] [1228800/1281167 (96%)]	Loss: 0.685734
[2022-06-12 11:46:21 | train] - Train Epoch: [165] [1241600/1281167 (97%)]	Loss: 0.613905
[2022-06-12 11:46:41 | train] - Train Epoch: [165] [1254400/1281167 (98%)]	Loss: 0.595323
[2022-06-12 11:47:00 | train] - Train Epoch: [165] [1267200/1281167 (99%)]	Loss: 0.752281
[2022-06-12 11:47:19 | train] - Train Epoch: [165] [1280000/1281167 (100%)]	Loss: 0.772487
[2022-06-12 11:47:21 | train] - Train Epoch: [165]	 Average Loss: 0.686298	 Total Acc : 83.3667	 Total Top5 Acc : 93.9773
[2022-06-12 11:47:21 | train] - -------165 epoch end-----------
========================================
-------165 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 11:48:49 | train] - 
Epoch [165] Test set: Average loss: 1.4253, Accuracy: 34974/50000 (69.9205%), Top-5 Accuracy: 89.0101%

[2022-06-12 11:48:49 | train] - save intermediate epoch [165] result


[2022-06-12 11:49:05 | train] - -------166 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 11:49:07 | train] - Train Epoch: [166] [0/1281167 (0%)]	Loss: 0.757263
[2022-06-12 11:49:28 | train] - Train Epoch: [166] [12800/1281167 (1%)]	Loss: 0.725775
[2022-06-12 11:49:48 | train] - Train Epoch: [166] [25600/1281167 (2%)]	Loss: 0.719130
[2022-06-12 11:50:07 | train] - Train Epoch: [166] [38400/1281167 (3%)]	Loss: 0.991408
[2022-06-12 11:50:27 | train] - Train Epoch: [166] [51200/1281167 (4%)]	Loss: 0.738706
[2022-06-12 11:50:46 | train] - Train Epoch: [166] [64000/1281167 (5%)]	Loss: 0.888041
[2022-06-12 11:51:06 | train] - Train Epoch: [166] [76800/1281167 (6%)]	Loss: 0.566497
[2022-06-12 11:51:25 | train] - Train Epoch: [166] [89600/1281167 (7%)]	Loss: 0.720398
[2022-06-12 11:51:44 | train] - Train Epoch: [166] [102400/1281167 (8%)]	Loss: 0.696273
[2022-06-12 11:52:04 | train] - Train Epoch: [166] [115200/1281167 (9%)]	Loss: 0.716660
[2022-06-12 11:52:23 | train] - Train Epoch: [166] [128000/1281167 (10%)]	Loss: 0.775138
[2022-06-12 11:52:43 | train] - Train Epoch: [166] [140800/1281167 (11%)]	Loss: 0.873355
[2022-06-12 11:53:02 | train] - Train Epoch: [166] [153600/1281167 (12%)]	Loss: 0.651289
[2022-06-12 11:53:22 | train] - Train Epoch: [166] [166400/1281167 (13%)]	Loss: 0.735828
[2022-06-12 11:53:42 | train] - Train Epoch: [166] [179200/1281167 (14%)]	Loss: 0.719471
[2022-06-12 11:54:02 | train] - Train Epoch: [166] [192000/1281167 (15%)]	Loss: 0.707976
[2022-06-12 11:54:21 | train] - Train Epoch: [166] [204800/1281167 (16%)]	Loss: 0.899900
[2022-06-12 11:54:41 | train] - Train Epoch: [166] [217600/1281167 (17%)]	Loss: 0.796162
[2022-06-12 11:55:00 | train] - Train Epoch: [166] [230400/1281167 (18%)]	Loss: 0.751094
[2022-06-12 11:55:20 | train] - Train Epoch: [166] [243200/1281167 (19%)]	Loss: 0.637649
[2022-06-12 11:55:39 | train] - Train Epoch: [166] [256000/1281167 (20%)]	Loss: 0.669743
[2022-06-12 11:55:59 | train] - Train Epoch: [166] [268800/1281167 (21%)]	Loss: 0.473371
[2022-06-12 11:56:19 | train] - Train Epoch: [166] [281600/1281167 (22%)]	Loss: 0.894159
[2022-06-12 11:56:39 | train] - Train Epoch: [166] [294400/1281167 (23%)]	Loss: 0.535405
[2022-06-12 11:56:59 | train] - Train Epoch: [166] [307200/1281167 (24%)]	Loss: 0.536989
[2022-06-12 11:57:19 | train] - Train Epoch: [166] [320000/1281167 (25%)]	Loss: 0.678287
[2022-06-12 11:57:39 | train] - Train Epoch: [166] [332800/1281167 (26%)]	Loss: 0.778989
[2022-06-12 11:57:58 | train] - Train Epoch: [166] [345600/1281167 (27%)]	Loss: 0.750637
[2022-06-12 11:58:18 | train] - Train Epoch: [166] [358400/1281167 (28%)]	Loss: 0.520679
[2022-06-12 11:58:37 | train] - Train Epoch: [166] [371200/1281167 (29%)]	Loss: 1.073149
[2022-06-12 11:58:56 | train] - Train Epoch: [166] [384000/1281167 (30%)]	Loss: 0.778287
[2022-06-12 11:59:17 | train] - Train Epoch: [166] [396800/1281167 (31%)]	Loss: 0.838106
[2022-06-12 11:59:36 | train] - Train Epoch: [166] [409600/1281167 (32%)]	Loss: 0.568863
[2022-06-12 11:59:56 | train] - Train Epoch: [166] [422400/1281167 (33%)]	Loss: 0.808969
[2022-06-12 12:00:15 | train] - Train Epoch: [166] [435200/1281167 (34%)]	Loss: 0.573838
[2022-06-12 12:00:34 | train] - Train Epoch: [166] [448000/1281167 (35%)]	Loss: 0.728454
[2022-06-12 12:00:54 | train] - Train Epoch: [166] [460800/1281167 (36%)]	Loss: 0.591430
[2022-06-12 12:01:14 | train] - Train Epoch: [166] [473600/1281167 (37%)]	Loss: 0.872242
[2022-06-12 12:01:33 | train] - Train Epoch: [166] [486400/1281167 (38%)]	Loss: 0.559123
[2022-06-12 12:01:53 | train] - Train Epoch: [166] [499200/1281167 (39%)]	Loss: 0.947449
[2022-06-12 12:02:13 | train] - Train Epoch: [166] [512000/1281167 (40%)]	Loss: 0.836314
[2022-06-12 12:02:33 | train] - Train Epoch: [166] [524800/1281167 (41%)]	Loss: 0.825866
[2022-06-12 12:02:52 | train] - Train Epoch: [166] [537600/1281167 (42%)]	Loss: 0.802599
[2022-06-12 12:03:11 | train] - Train Epoch: [166] [550400/1281167 (43%)]	Loss: 0.827538
[2022-06-12 12:03:31 | train] - Train Epoch: [166] [563200/1281167 (44%)]	Loss: 0.821593
[2022-06-12 12:03:51 | train] - Train Epoch: [166] [576000/1281167 (45%)]	Loss: 0.562563
[2022-06-12 12:04:10 | train] - Train Epoch: [166] [588800/1281167 (46%)]	Loss: 0.691392
[2022-06-12 12:04:30 | train] - Train Epoch: [166] [601600/1281167 (47%)]	Loss: 0.577961
[2022-06-12 12:04:50 | train] - Train Epoch: [166] [614400/1281167 (48%)]	Loss: 0.934941
[2022-06-12 12:05:10 | train] - Train Epoch: [166] [627200/1281167 (49%)]	Loss: 0.910226
[2022-06-12 12:05:30 | train] - Train Epoch: [166] [640000/1281167 (50%)]	Loss: 0.718284
[2022-06-12 12:05:50 | train] - Train Epoch: [166] [652800/1281167 (51%)]	Loss: 0.748021
[2022-06-12 12:06:10 | train] - Train Epoch: [166] [665600/1281167 (52%)]	Loss: 0.756333
[2022-06-12 12:06:29 | train] - Train Epoch: [166] [678400/1281167 (53%)]	Loss: 0.841280
[2022-06-12 12:06:49 | train] - Train Epoch: [166] [691200/1281167 (54%)]	Loss: 0.579764
[2022-06-12 12:07:09 | train] - Train Epoch: [166] [704000/1281167 (55%)]	Loss: 0.947046
[2022-06-12 12:07:29 | train] - Train Epoch: [166] [716800/1281167 (56%)]	Loss: 0.648543
[2022-06-12 12:07:48 | train] - Train Epoch: [166] [729600/1281167 (57%)]	Loss: 0.725569
[2022-06-12 12:08:07 | train] - Train Epoch: [166] [742400/1281167 (58%)]	Loss: 0.638113
[2022-06-12 12:08:28 | train] - Train Epoch: [166] [755200/1281167 (59%)]	Loss: 0.889240
[2022-06-12 12:08:48 | train] - Train Epoch: [166] [768000/1281167 (60%)]	Loss: 0.636373
[2022-06-12 12:09:07 | train] - Train Epoch: [166] [780800/1281167 (61%)]	Loss: 0.695570
[2022-06-12 12:09:27 | train] - Train Epoch: [166] [793600/1281167 (62%)]	Loss: 0.607667
[2022-06-12 12:09:46 | train] - Train Epoch: [166] [806400/1281167 (63%)]	Loss: 0.761074
[2022-06-12 12:10:06 | train] - Train Epoch: [166] [819200/1281167 (64%)]	Loss: 0.737137
[2022-06-12 12:10:25 | train] - Train Epoch: [166] [832000/1281167 (65%)]	Loss: 0.716233
[2022-06-12 12:10:45 | train] - Train Epoch: [166] [844800/1281167 (66%)]	Loss: 0.590736
[2022-06-12 12:11:06 | train] - Train Epoch: [166] [857600/1281167 (67%)]	Loss: 0.771200
[2022-06-12 12:11:26 | train] - Train Epoch: [166] [870400/1281167 (68%)]	Loss: 0.857370
[2022-06-12 12:11:47 | train] - Train Epoch: [166] [883200/1281167 (69%)]	Loss: 0.900777
[2022-06-12 12:12:06 | train] - Train Epoch: [166] [896000/1281167 (70%)]	Loss: 0.700761
[2022-06-12 12:12:26 | train] - Train Epoch: [166] [908800/1281167 (71%)]	Loss: 0.750162
[2022-06-12 12:12:45 | train] - Train Epoch: [166] [921600/1281167 (72%)]	Loss: 0.708354
[2022-06-12 12:13:05 | train] - Train Epoch: [166] [934400/1281167 (73%)]	Loss: 0.962128
[2022-06-12 12:13:25 | train] - Train Epoch: [166] [947200/1281167 (74%)]	Loss: 0.833316
[2022-06-12 12:13:45 | train] - Train Epoch: [166] [960000/1281167 (75%)]	Loss: 0.635863
[2022-06-12 12:14:04 | train] - Train Epoch: [166] [972800/1281167 (76%)]	Loss: 1.018455
[2022-06-12 12:14:24 | train] - Train Epoch: [166] [985600/1281167 (77%)]	Loss: 0.700956
[2022-06-12 12:14:44 | train] - Train Epoch: [166] [998400/1281167 (78%)]	Loss: 0.932515
[2022-06-12 12:15:05 | train] - Train Epoch: [166] [1011200/1281167 (79%)]	Loss: 0.963175
[2022-06-12 12:15:25 | train] - Train Epoch: [166] [1024000/1281167 (80%)]	Loss: 0.681728
[2022-06-12 12:15:44 | train] - Train Epoch: [166] [1036800/1281167 (81%)]	Loss: 0.918426
[2022-06-12 12:16:04 | train] - Train Epoch: [166] [1049600/1281167 (82%)]	Loss: 0.851011
[2022-06-12 12:16:24 | train] - Train Epoch: [166] [1062400/1281167 (83%)]	Loss: 0.612875
[2022-06-12 12:16:44 | train] - Train Epoch: [166] [1075200/1281167 (84%)]	Loss: 0.750741
[2022-06-12 12:17:04 | train] - Train Epoch: [166] [1088000/1281167 (85%)]	Loss: 0.610942
[2022-06-12 12:17:24 | train] - Train Epoch: [166] [1100800/1281167 (86%)]	Loss: 0.671047
[2022-06-12 12:17:44 | train] - Train Epoch: [166] [1113600/1281167 (87%)]	Loss: 0.779901
[2022-06-12 12:18:05 | train] - Train Epoch: [166] [1126400/1281167 (88%)]	Loss: 0.752785
[2022-06-12 12:18:25 | train] - Train Epoch: [166] [1139200/1281167 (89%)]	Loss: 0.657372
[2022-06-12 12:18:44 | train] - Train Epoch: [166] [1152000/1281167 (90%)]	Loss: 0.700273
[2022-06-12 12:19:04 | train] - Train Epoch: [166] [1164800/1281167 (91%)]	Loss: 0.671630
[2022-06-12 12:19:24 | train] - Train Epoch: [166] [1177600/1281167 (92%)]	Loss: 0.641739
[2022-06-12 12:19:44 | train] - Train Epoch: [166] [1190400/1281167 (93%)]	Loss: 0.817195
[2022-06-12 12:20:05 | train] - Train Epoch: [166] [1203200/1281167 (94%)]	Loss: 0.924686
[2022-06-12 12:20:24 | train] - Train Epoch: [166] [1216000/1281167 (95%)]	Loss: 0.748522
[2022-06-12 12:20:45 | train] - Train Epoch: [166] [1228800/1281167 (96%)]	Loss: 0.584601
[2022-06-12 12:21:05 | train] - Train Epoch: [166] [1241600/1281167 (97%)]	Loss: 0.594150
[2022-06-12 12:21:25 | train] - Train Epoch: [166] [1254400/1281167 (98%)]	Loss: 0.676725
[2022-06-12 12:21:45 | train] - Train Epoch: [166] [1267200/1281167 (99%)]	Loss: 0.552996
[2022-06-12 12:22:04 | train] - Train Epoch: [166] [1280000/1281167 (100%)]	Loss: 0.822671
[2022-06-12 12:22:06 | train] - Train Epoch: [166]	 Average Loss: 0.733641	 Total Acc : 82.1243	 Total Top5 Acc : 93.5020
[2022-06-12 12:22:06 | train] - -------166 epoch end-----------
========================================
-------166 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 12:23:35 | train] - 
Epoch [166] Test set: Average loss: 1.4260, Accuracy: 34998/50000 (69.9672%), Top-5 Accuracy: 88.9011%

[2022-06-12 12:23:35 | train] - save intermediate epoch [166] result


[2022-06-12 12:23:51 | train] - -------167 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 12:23:53 | train] - Train Epoch: [167] [0/1281167 (0%)]	Loss: 0.815050
[2022-06-12 12:24:12 | train] - Train Epoch: [167] [12800/1281167 (1%)]	Loss: 0.909843
[2022-06-12 12:24:32 | train] - Train Epoch: [167] [25600/1281167 (2%)]	Loss: 0.483618
[2022-06-12 12:24:52 | train] - Train Epoch: [167] [38400/1281167 (3%)]	Loss: 0.721982
[2022-06-12 12:25:12 | train] - Train Epoch: [167] [51200/1281167 (4%)]	Loss: 0.721491
[2022-06-12 12:25:32 | train] - Train Epoch: [167] [64000/1281167 (5%)]	Loss: 0.449047
[2022-06-12 12:25:51 | train] - Train Epoch: [167] [76800/1281167 (6%)]	Loss: 0.624738
[2022-06-12 12:26:10 | train] - Train Epoch: [167] [89600/1281167 (7%)]	Loss: 0.683526
[2022-06-12 12:26:30 | train] - Train Epoch: [167] [102400/1281167 (8%)]	Loss: 0.832455
[2022-06-12 12:26:49 | train] - Train Epoch: [167] [115200/1281167 (9%)]	Loss: 0.643769
[2022-06-12 12:27:09 | train] - Train Epoch: [167] [128000/1281167 (10%)]	Loss: 0.863867
[2022-06-12 12:27:29 | train] - Train Epoch: [167] [140800/1281167 (11%)]	Loss: 0.740376
[2022-06-12 12:27:48 | train] - Train Epoch: [167] [153600/1281167 (12%)]	Loss: 0.863898
[2022-06-12 12:28:07 | train] - Train Epoch: [167] [166400/1281167 (13%)]	Loss: 0.881469
[2022-06-12 12:28:27 | train] - Train Epoch: [167] [179200/1281167 (14%)]	Loss: 0.989061
[2022-06-12 12:28:47 | train] - Train Epoch: [167] [192000/1281167 (15%)]	Loss: 0.791750
[2022-06-12 12:29:06 | train] - Train Epoch: [167] [204800/1281167 (16%)]	Loss: 0.702287
[2022-06-12 12:29:26 | train] - Train Epoch: [167] [217600/1281167 (17%)]	Loss: 0.963205
[2022-06-12 12:29:46 | train] - Train Epoch: [167] [230400/1281167 (18%)]	Loss: 0.880542
[2022-06-12 12:30:06 | train] - Train Epoch: [167] [243200/1281167 (19%)]	Loss: 0.640132
[2022-06-12 12:30:24 | train] - Train Epoch: [167] [256000/1281167 (20%)]	Loss: 0.746682
[2022-06-12 12:30:43 | train] - Train Epoch: [167] [268800/1281167 (21%)]	Loss: 0.771014
[2022-06-12 12:31:03 | train] - Train Epoch: [167] [281600/1281167 (22%)]	Loss: 0.722516
[2022-06-12 12:31:23 | train] - Train Epoch: [167] [294400/1281167 (23%)]	Loss: 0.738114
[2022-06-12 12:31:42 | train] - Train Epoch: [167] [307200/1281167 (24%)]	Loss: 1.014460
[2022-06-12 12:32:02 | train] - Train Epoch: [167] [320000/1281167 (25%)]	Loss: 0.825685
[2022-06-12 12:32:22 | train] - Train Epoch: [167] [332800/1281167 (26%)]	Loss: 0.954849
[2022-06-12 12:32:41 | train] - Train Epoch: [167] [345600/1281167 (27%)]	Loss: 0.482141
[2022-06-12 12:33:01 | train] - Train Epoch: [167] [358400/1281167 (28%)]	Loss: 0.856031
[2022-06-12 12:33:20 | train] - Train Epoch: [167] [371200/1281167 (29%)]	Loss: 0.604984
[2022-06-12 12:33:40 | train] - Train Epoch: [167] [384000/1281167 (30%)]	Loss: 0.648249
[2022-06-12 12:34:00 | train] - Train Epoch: [167] [396800/1281167 (31%)]	Loss: 0.778757
[2022-06-12 12:34:19 | train] - Train Epoch: [167] [409600/1281167 (32%)]	Loss: 0.724235
[2022-06-12 12:34:39 | train] - Train Epoch: [167] [422400/1281167 (33%)]	Loss: 0.531374
[2022-06-12 12:34:58 | train] - Train Epoch: [167] [435200/1281167 (34%)]	Loss: 0.773851
[2022-06-12 12:35:18 | train] - Train Epoch: [167] [448000/1281167 (35%)]	Loss: 0.706615
[2022-06-12 12:35:38 | train] - Train Epoch: [167] [460800/1281167 (36%)]	Loss: 0.925651
[2022-06-12 12:35:57 | train] - Train Epoch: [167] [473600/1281167 (37%)]	Loss: 0.844922
[2022-06-12 12:36:16 | train] - Train Epoch: [167] [486400/1281167 (38%)]	Loss: 0.926679
[2022-06-12 12:36:35 | train] - Train Epoch: [167] [499200/1281167 (39%)]	Loss: 0.718128
[2022-06-12 12:36:54 | train] - Train Epoch: [167] [512000/1281167 (40%)]	Loss: 0.593582
[2022-06-12 12:37:14 | train] - Train Epoch: [167] [524800/1281167 (41%)]	Loss: 0.700080
[2022-06-12 12:37:33 | train] - Train Epoch: [167] [537600/1281167 (42%)]	Loss: 0.911033
[2022-06-12 12:37:52 | train] - Train Epoch: [167] [550400/1281167 (43%)]	Loss: 0.796801
[2022-06-12 12:38:12 | train] - Train Epoch: [167] [563200/1281167 (44%)]	Loss: 0.585980
[2022-06-12 12:38:31 | train] - Train Epoch: [167] [576000/1281167 (45%)]	Loss: 0.689116
[2022-06-12 12:38:50 | train] - Train Epoch: [167] [588800/1281167 (46%)]	Loss: 0.890165
[2022-06-12 12:39:10 | train] - Train Epoch: [167] [601600/1281167 (47%)]	Loss: 0.676594
[2022-06-12 12:39:29 | train] - Train Epoch: [167] [614400/1281167 (48%)]	Loss: 0.804249
[2022-06-12 12:39:48 | train] - Train Epoch: [167] [627200/1281167 (49%)]	Loss: 0.718627
[2022-06-12 12:40:07 | train] - Train Epoch: [167] [640000/1281167 (50%)]	Loss: 0.746489
[2022-06-12 12:40:27 | train] - Train Epoch: [167] [652800/1281167 (51%)]	Loss: 0.639374
[2022-06-12 12:40:47 | train] - Train Epoch: [167] [665600/1281167 (52%)]	Loss: 0.806303
[2022-06-12 12:41:06 | train] - Train Epoch: [167] [678400/1281167 (53%)]	Loss: 0.825595
[2022-06-12 12:41:25 | train] - Train Epoch: [167] [691200/1281167 (54%)]	Loss: 0.920078
[2022-06-12 12:41:44 | train] - Train Epoch: [167] [704000/1281167 (55%)]	Loss: 0.633935
[2022-06-12 12:42:03 | train] - Train Epoch: [167] [716800/1281167 (56%)]	Loss: 0.805026
[2022-06-12 12:42:22 | train] - Train Epoch: [167] [729600/1281167 (57%)]	Loss: 0.637318
[2022-06-12 12:42:41 | train] - Train Epoch: [167] [742400/1281167 (58%)]	Loss: 0.482217
[2022-06-12 12:43:01 | train] - Train Epoch: [167] [755200/1281167 (59%)]	Loss: 0.766745
[2022-06-12 12:43:20 | train] - Train Epoch: [167] [768000/1281167 (60%)]	Loss: 0.760092
[2022-06-12 12:43:39 | train] - Train Epoch: [167] [780800/1281167 (61%)]	Loss: 0.696815
[2022-06-12 12:43:59 | train] - Train Epoch: [167] [793600/1281167 (62%)]	Loss: 0.869625
[2022-06-12 12:44:18 | train] - Train Epoch: [167] [806400/1281167 (63%)]	Loss: 0.479584
[2022-06-12 12:44:37 | train] - Train Epoch: [167] [819200/1281167 (64%)]	Loss: 0.909821
[2022-06-12 12:44:58 | train] - Train Epoch: [167] [832000/1281167 (65%)]	Loss: 0.678681
[2022-06-12 12:45:17 | train] - Train Epoch: [167] [844800/1281167 (66%)]	Loss: 0.738569
[2022-06-12 12:45:36 | train] - Train Epoch: [167] [857600/1281167 (67%)]	Loss: 0.850565
[2022-06-12 12:45:56 | train] - Train Epoch: [167] [870400/1281167 (68%)]	Loss: 0.545410
[2022-06-12 12:46:15 | train] - Train Epoch: [167] [883200/1281167 (69%)]	Loss: 0.824103
[2022-06-12 12:46:34 | train] - Train Epoch: [167] [896000/1281167 (70%)]	Loss: 0.745381
[2022-06-12 12:46:53 | train] - Train Epoch: [167] [908800/1281167 (71%)]	Loss: 0.495038
[2022-06-12 12:47:12 | train] - Train Epoch: [167] [921600/1281167 (72%)]	Loss: 0.730017
[2022-06-12 12:47:32 | train] - Train Epoch: [167] [934400/1281167 (73%)]	Loss: 0.868240
[2022-06-12 12:47:51 | train] - Train Epoch: [167] [947200/1281167 (74%)]	Loss: 0.726265
[2022-06-12 12:48:09 | train] - Train Epoch: [167] [960000/1281167 (75%)]	Loss: 0.903284
[2022-06-12 12:48:28 | train] - Train Epoch: [167] [972800/1281167 (76%)]	Loss: 0.784914
[2022-06-12 12:48:48 | train] - Train Epoch: [167] [985600/1281167 (77%)]	Loss: 0.897330
[2022-06-12 12:49:06 | train] - Train Epoch: [167] [998400/1281167 (78%)]	Loss: 0.973662
[2022-06-12 12:49:25 | train] - Train Epoch: [167] [1011200/1281167 (79%)]	Loss: 0.686736
[2022-06-12 12:49:45 | train] - Train Epoch: [167] [1024000/1281167 (80%)]	Loss: 0.715109
[2022-06-12 12:50:05 | train] - Train Epoch: [167] [1036800/1281167 (81%)]	Loss: 0.893546
[2022-06-12 12:50:24 | train] - Train Epoch: [167] [1049600/1281167 (82%)]	Loss: 1.002920
[2022-06-12 12:50:43 | train] - Train Epoch: [167] [1062400/1281167 (83%)]	Loss: 0.793865
[2022-06-12 12:51:03 | train] - Train Epoch: [167] [1075200/1281167 (84%)]	Loss: 0.736439
[2022-06-12 12:51:22 | train] - Train Epoch: [167] [1088000/1281167 (85%)]	Loss: 0.504675
[2022-06-12 12:51:41 | train] - Train Epoch: [167] [1100800/1281167 (86%)]	Loss: 0.719060
[2022-06-12 12:52:01 | train] - Train Epoch: [167] [1113600/1281167 (87%)]	Loss: 0.771747
[2022-06-12 12:52:21 | train] - Train Epoch: [167] [1126400/1281167 (88%)]	Loss: 0.784948
[2022-06-12 12:52:40 | train] - Train Epoch: [167] [1139200/1281167 (89%)]	Loss: 0.602011
[2022-06-12 12:53:00 | train] - Train Epoch: [167] [1152000/1281167 (90%)]	Loss: 0.405137
[2022-06-12 12:53:19 | train] - Train Epoch: [167] [1164800/1281167 (91%)]	Loss: 0.724359
[2022-06-12 12:53:39 | train] - Train Epoch: [167] [1177600/1281167 (92%)]	Loss: 0.818253
[2022-06-12 12:53:59 | train] - Train Epoch: [167] [1190400/1281167 (93%)]	Loss: 0.596379
[2022-06-12 12:54:18 | train] - Train Epoch: [167] [1203200/1281167 (94%)]	Loss: 0.532256
[2022-06-12 12:54:38 | train] - Train Epoch: [167] [1216000/1281167 (95%)]	Loss: 0.715587
[2022-06-12 12:54:57 | train] - Train Epoch: [167] [1228800/1281167 (96%)]	Loss: 1.013218
[2022-06-12 12:55:17 | train] - Train Epoch: [167] [1241600/1281167 (97%)]	Loss: 0.517296
[2022-06-12 12:55:36 | train] - Train Epoch: [167] [1254400/1281167 (98%)]	Loss: 0.653419
[2022-06-12 12:55:56 | train] - Train Epoch: [167] [1267200/1281167 (99%)]	Loss: 0.800202
[2022-06-12 12:56:16 | train] - Train Epoch: [167] [1280000/1281167 (100%)]	Loss: 0.623738
[2022-06-12 12:56:17 | train] - Train Epoch: [167]	 Average Loss: 0.733476	 Total Acc : 82.1757	 Total Top5 Acc : 93.5064
[2022-06-12 12:56:17 | train] - -------167 epoch end-----------
========================================
-------167 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 12:57:45 | train] - 
Epoch [167] Test set: Average loss: 1.4354, Accuracy: 34984/50000 (69.9381%), Top-5 Accuracy: 88.9210%

[2022-06-12 12:57:45 | train] - save intermediate epoch [167] result


[2022-06-12 12:58:01 | train] - -------168 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 12:58:03 | train] - Train Epoch: [168] [0/1281167 (0%)]	Loss: 0.735866
[2022-06-12 12:58:24 | train] - Train Epoch: [168] [12800/1281167 (1%)]	Loss: 0.735619
[2022-06-12 12:58:46 | train] - Train Epoch: [168] [25600/1281167 (2%)]	Loss: 1.008618
[2022-06-12 12:59:08 | train] - Train Epoch: [168] [38400/1281167 (3%)]	Loss: 1.014518
[2022-06-12 12:59:29 | train] - Train Epoch: [168] [51200/1281167 (4%)]	Loss: 0.717026
[2022-06-12 12:59:51 | train] - Train Epoch: [168] [64000/1281167 (5%)]	Loss: 0.762962
[2022-06-12 13:00:13 | train] - Train Epoch: [168] [76800/1281167 (6%)]	Loss: 0.899827
[2022-06-12 13:00:35 | train] - Train Epoch: [168] [89600/1281167 (7%)]	Loss: 0.895334
[2022-06-12 13:00:56 | train] - Train Epoch: [168] [102400/1281167 (8%)]	Loss: 0.698712
[2022-06-12 13:01:18 | train] - Train Epoch: [168] [115200/1281167 (9%)]	Loss: 0.927224
[2022-06-12 13:01:39 | train] - Train Epoch: [168] [128000/1281167 (10%)]	Loss: 0.771540
[2022-06-12 13:02:01 | train] - Train Epoch: [168] [140800/1281167 (11%)]	Loss: 0.700981
[2022-06-12 13:02:22 | train] - Train Epoch: [168] [153600/1281167 (12%)]	Loss: 0.703146
[2022-06-12 13:02:44 | train] - Train Epoch: [168] [166400/1281167 (13%)]	Loss: 0.891575
[2022-06-12 13:03:06 | train] - Train Epoch: [168] [179200/1281167 (14%)]	Loss: 0.730377
[2022-06-12 13:03:27 | train] - Train Epoch: [168] [192000/1281167 (15%)]	Loss: 0.681201
[2022-06-12 13:03:48 | train] - Train Epoch: [168] [204800/1281167 (16%)]	Loss: 0.966596
[2022-06-12 13:04:10 | train] - Train Epoch: [168] [217600/1281167 (17%)]	Loss: 0.712785
[2022-06-12 13:04:32 | train] - Train Epoch: [168] [230400/1281167 (18%)]	Loss: 0.525775
[2022-06-12 13:04:53 | train] - Train Epoch: [168] [243200/1281167 (19%)]	Loss: 0.720159
[2022-06-12 13:05:15 | train] - Train Epoch: [168] [256000/1281167 (20%)]	Loss: 0.733456
[2022-06-12 13:05:36 | train] - Train Epoch: [168] [268800/1281167 (21%)]	Loss: 0.742213
[2022-06-12 13:05:57 | train] - Train Epoch: [168] [281600/1281167 (22%)]	Loss: 0.582449
[2022-06-12 13:06:18 | train] - Train Epoch: [168] [294400/1281167 (23%)]	Loss: 0.792493
[2022-06-12 13:06:40 | train] - Train Epoch: [168] [307200/1281167 (24%)]	Loss: 0.620101
[2022-06-12 13:07:02 | train] - Train Epoch: [168] [320000/1281167 (25%)]	Loss: 0.721604
[2022-06-12 13:07:24 | train] - Train Epoch: [168] [332800/1281167 (26%)]	Loss: 0.582568
[2022-06-12 13:07:45 | train] - Train Epoch: [168] [345600/1281167 (27%)]	Loss: 1.009146
[2022-06-12 13:08:07 | train] - Train Epoch: [168] [358400/1281167 (28%)]	Loss: 0.545516
[2022-06-12 13:08:29 | train] - Train Epoch: [168] [371200/1281167 (29%)]	Loss: 0.578477
[2022-06-12 13:08:51 | train] - Train Epoch: [168] [384000/1281167 (30%)]	Loss: 0.743327
[2022-06-12 13:09:12 | train] - Train Epoch: [168] [396800/1281167 (31%)]	Loss: 0.738393
[2022-06-12 13:09:34 | train] - Train Epoch: [168] [409600/1281167 (32%)]	Loss: 0.742885
[2022-06-12 13:09:56 | train] - Train Epoch: [168] [422400/1281167 (33%)]	Loss: 0.879471
[2022-06-12 13:10:18 | train] - Train Epoch: [168] [435200/1281167 (34%)]	Loss: 0.619797
[2022-06-12 13:10:38 | train] - Train Epoch: [168] [448000/1281167 (35%)]	Loss: 0.972474
[2022-06-12 13:10:59 | train] - Train Epoch: [168] [460800/1281167 (36%)]	Loss: 0.472653
[2022-06-12 13:11:20 | train] - Train Epoch: [168] [473600/1281167 (37%)]	Loss: 0.862821
[2022-06-12 13:11:42 | train] - Train Epoch: [168] [486400/1281167 (38%)]	Loss: 0.470204
[2022-06-12 13:12:04 | train] - Train Epoch: [168] [499200/1281167 (39%)]	Loss: 0.885988
[2022-06-12 13:12:25 | train] - Train Epoch: [168] [512000/1281167 (40%)]	Loss: 1.028279
[2022-06-12 13:12:47 | train] - Train Epoch: [168] [524800/1281167 (41%)]	Loss: 1.036326
[2022-06-12 13:13:09 | train] - Train Epoch: [168] [537600/1281167 (42%)]	Loss: 0.852916
[2022-06-12 13:13:31 | train] - Train Epoch: [168] [550400/1281167 (43%)]	Loss: 0.596535
[2022-06-12 13:13:52 | train] - Train Epoch: [168] [563200/1281167 (44%)]	Loss: 0.798072
[2022-06-12 13:14:14 | train] - Train Epoch: [168] [576000/1281167 (45%)]	Loss: 0.755948
[2022-06-12 13:14:36 | train] - Train Epoch: [168] [588800/1281167 (46%)]	Loss: 0.595618
[2022-06-12 13:14:59 | train] - Train Epoch: [168] [601600/1281167 (47%)]	Loss: 0.834611
[2022-06-12 13:15:20 | train] - Train Epoch: [168] [614400/1281167 (48%)]	Loss: 0.535572
[2022-06-12 13:15:41 | train] - Train Epoch: [168] [627200/1281167 (49%)]	Loss: 0.690250
[2022-06-12 13:16:03 | train] - Train Epoch: [168] [640000/1281167 (50%)]	Loss: 0.882435
[2022-06-12 13:16:24 | train] - Train Epoch: [168] [652800/1281167 (51%)]	Loss: 1.013967
[2022-06-12 13:16:46 | train] - Train Epoch: [168] [665600/1281167 (52%)]	Loss: 0.710076
[2022-06-12 13:17:08 | train] - Train Epoch: [168] [678400/1281167 (53%)]	Loss: 0.774727
[2022-06-12 13:17:29 | train] - Train Epoch: [168] [691200/1281167 (54%)]	Loss: 0.469039
[2022-06-12 13:17:52 | train] - Train Epoch: [168] [704000/1281167 (55%)]	Loss: 0.815843
[2022-06-12 13:18:13 | train] - Train Epoch: [168] [716800/1281167 (56%)]	Loss: 0.752693
[2022-06-12 13:18:35 | train] - Train Epoch: [168] [729600/1281167 (57%)]	Loss: 0.715891
[2022-06-12 13:18:56 | train] - Train Epoch: [168] [742400/1281167 (58%)]	Loss: 0.927728
[2022-06-12 13:19:18 | train] - Train Epoch: [168] [755200/1281167 (59%)]	Loss: 0.835168
[2022-06-12 13:19:39 | train] - Train Epoch: [168] [768000/1281167 (60%)]	Loss: 0.844708
[2022-06-12 13:20:01 | train] - Train Epoch: [168] [780800/1281167 (61%)]	Loss: 0.677423
[2022-06-12 13:20:23 | train] - Train Epoch: [168] [793600/1281167 (62%)]	Loss: 0.827935
[2022-06-12 13:20:45 | train] - Train Epoch: [168] [806400/1281167 (63%)]	Loss: 0.754803
[2022-06-12 13:21:06 | train] - Train Epoch: [168] [819200/1281167 (64%)]	Loss: 0.633416
[2022-06-12 13:21:29 | train] - Train Epoch: [168] [832000/1281167 (65%)]	Loss: 0.920275
[2022-06-12 13:21:49 | train] - Train Epoch: [168] [844800/1281167 (66%)]	Loss: 0.920344
[2022-06-12 13:22:10 | train] - Train Epoch: [168] [857600/1281167 (67%)]	Loss: 0.848231
[2022-06-12 13:22:33 | train] - Train Epoch: [168] [870400/1281167 (68%)]	Loss: 0.563529
[2022-06-12 13:22:54 | train] - Train Epoch: [168] [883200/1281167 (69%)]	Loss: 0.705223
[2022-06-12 13:23:13 | train] - Train Epoch: [168] [896000/1281167 (70%)]	Loss: 0.761686
[2022-06-12 13:23:34 | train] - Train Epoch: [168] [908800/1281167 (71%)]	Loss: 0.664788
[2022-06-12 13:23:54 | train] - Train Epoch: [168] [921600/1281167 (72%)]	Loss: 0.757246
[2022-06-12 13:24:13 | train] - Train Epoch: [168] [934400/1281167 (73%)]	Loss: 0.695542
[2022-06-12 13:24:33 | train] - Train Epoch: [168] [947200/1281167 (74%)]	Loss: 0.914784
[2022-06-12 13:24:53 | train] - Train Epoch: [168] [960000/1281167 (75%)]	Loss: 0.705215
[2022-06-12 13:25:12 | train] - Train Epoch: [168] [972800/1281167 (76%)]	Loss: 0.846971
[2022-06-12 13:25:33 | train] - Train Epoch: [168] [985600/1281167 (77%)]	Loss: 0.615745
[2022-06-12 13:25:54 | train] - Train Epoch: [168] [998400/1281167 (78%)]	Loss: 0.663016
[2022-06-12 13:26:14 | train] - Train Epoch: [168] [1011200/1281167 (79%)]	Loss: 0.850616
[2022-06-12 13:26:34 | train] - Train Epoch: [168] [1024000/1281167 (80%)]	Loss: 0.906130
[2022-06-12 13:26:54 | train] - Train Epoch: [168] [1036800/1281167 (81%)]	Loss: 0.600337
[2022-06-12 13:27:13 | train] - Train Epoch: [168] [1049600/1281167 (82%)]	Loss: 0.662173
[2022-06-12 13:27:32 | train] - Train Epoch: [168] [1062400/1281167 (83%)]	Loss: 1.103665
[2022-06-12 13:27:52 | train] - Train Epoch: [168] [1075200/1281167 (84%)]	Loss: 0.646376
[2022-06-12 13:28:13 | train] - Train Epoch: [168] [1088000/1281167 (85%)]	Loss: 0.722771
[2022-06-12 13:28:33 | train] - Train Epoch: [168] [1100800/1281167 (86%)]	Loss: 0.749943
[2022-06-12 13:28:53 | train] - Train Epoch: [168] [1113600/1281167 (87%)]	Loss: 0.922681
[2022-06-12 13:29:14 | train] - Train Epoch: [168] [1126400/1281167 (88%)]	Loss: 0.835948
[2022-06-12 13:29:35 | train] - Train Epoch: [168] [1139200/1281167 (89%)]	Loss: 0.645232
[2022-06-12 13:29:54 | train] - Train Epoch: [168] [1152000/1281167 (90%)]	Loss: 0.774856
[2022-06-12 13:30:15 | train] - Train Epoch: [168] [1164800/1281167 (91%)]	Loss: 0.873891
[2022-06-12 13:30:36 | train] - Train Epoch: [168] [1177600/1281167 (92%)]	Loss: 0.620725
[2022-06-12 13:30:57 | train] - Train Epoch: [168] [1190400/1281167 (93%)]	Loss: 0.974286
[2022-06-12 13:31:16 | train] - Train Epoch: [168] [1203200/1281167 (94%)]	Loss: 0.601720
[2022-06-12 13:31:35 | train] - Train Epoch: [168] [1216000/1281167 (95%)]	Loss: 0.704513
[2022-06-12 13:31:55 | train] - Train Epoch: [168] [1228800/1281167 (96%)]	Loss: 0.873750
[2022-06-12 13:32:15 | train] - Train Epoch: [168] [1241600/1281167 (97%)]	Loss: 0.743410
[2022-06-12 13:32:34 | train] - Train Epoch: [168] [1254400/1281167 (98%)]	Loss: 0.769985
[2022-06-12 13:32:54 | train] - Train Epoch: [168] [1267200/1281167 (99%)]	Loss: 0.827847
[2022-06-12 13:33:15 | train] - Train Epoch: [168] [1280000/1281167 (100%)]	Loss: 0.620101
[2022-06-12 13:33:17 | train] - Train Epoch: [168]	 Average Loss: 0.731967	 Total Acc : 82.1936	 Total Top5 Acc : 93.5262
[2022-06-12 13:33:17 | train] - -------168 epoch end-----------
========================================
-------168 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 13:34:47 | train] - 
Epoch [168] Test set: Average loss: 1.4373, Accuracy: 34927/50000 (69.8230%), Top-5 Accuracy: 88.9690%

[2022-06-12 13:34:47 | train] - save intermediate epoch [168] result


[2022-06-12 13:35:04 | train] - -------169 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 13:35:06 | train] - Train Epoch: [169] [0/1281167 (0%)]	Loss: 0.911104
[2022-06-12 13:35:27 | train] - Train Epoch: [169] [12800/1281167 (1%)]	Loss: 0.685784
[2022-06-12 13:35:47 | train] - Train Epoch: [169] [25600/1281167 (2%)]	Loss: 0.791260
[2022-06-12 13:36:07 | train] - Train Epoch: [169] [38400/1281167 (3%)]	Loss: 0.759990
[2022-06-12 13:36:27 | train] - Train Epoch: [169] [51200/1281167 (4%)]	Loss: 0.882276
[2022-06-12 13:36:47 | train] - Train Epoch: [169] [64000/1281167 (5%)]	Loss: 0.682023
[2022-06-12 13:37:07 | train] - Train Epoch: [169] [76800/1281167 (6%)]	Loss: 0.507519
[2022-06-12 13:37:26 | train] - Train Epoch: [169] [89600/1281167 (7%)]	Loss: 0.820539
[2022-06-12 13:37:45 | train] - Train Epoch: [169] [102400/1281167 (8%)]	Loss: 0.801741
[2022-06-12 13:38:05 | train] - Train Epoch: [169] [115200/1281167 (9%)]	Loss: 0.918628
[2022-06-12 13:38:25 | train] - Train Epoch: [169] [128000/1281167 (10%)]	Loss: 0.684362
[2022-06-12 13:38:45 | train] - Train Epoch: [169] [140800/1281167 (11%)]	Loss: 0.860776
[2022-06-12 13:39:05 | train] - Train Epoch: [169] [153600/1281167 (12%)]	Loss: 0.791677
[2022-06-12 13:39:25 | train] - Train Epoch: [169] [166400/1281167 (13%)]	Loss: 0.671948
[2022-06-12 13:39:44 | train] - Train Epoch: [169] [179200/1281167 (14%)]	Loss: 0.740517
[2022-06-12 13:40:04 | train] - Train Epoch: [169] [192000/1281167 (15%)]	Loss: 0.571064
[2022-06-12 13:40:24 | train] - Train Epoch: [169] [204800/1281167 (16%)]	Loss: 0.611609
[2022-06-12 13:40:43 | train] - Train Epoch: [169] [217600/1281167 (17%)]	Loss: 0.928108
[2022-06-12 13:41:03 | train] - Train Epoch: [169] [230400/1281167 (18%)]	Loss: 0.434246
[2022-06-12 13:41:22 | train] - Train Epoch: [169] [243200/1281167 (19%)]	Loss: 0.995972
[2022-06-12 13:41:42 | train] - Train Epoch: [169] [256000/1281167 (20%)]	Loss: 0.597807
[2022-06-12 13:42:02 | train] - Train Epoch: [169] [268800/1281167 (21%)]	Loss: 0.921810
[2022-06-12 13:42:21 | train] - Train Epoch: [169] [281600/1281167 (22%)]	Loss: 0.789895
[2022-06-12 13:42:40 | train] - Train Epoch: [169] [294400/1281167 (23%)]	Loss: 0.625176
[2022-06-12 13:43:00 | train] - Train Epoch: [169] [307200/1281167 (24%)]	Loss: 0.904030
[2022-06-12 13:43:19 | train] - Train Epoch: [169] [320000/1281167 (25%)]	Loss: 0.807733
[2022-06-12 13:43:38 | train] - Train Epoch: [169] [332800/1281167 (26%)]	Loss: 0.814070
[2022-06-12 13:43:58 | train] - Train Epoch: [169] [345600/1281167 (27%)]	Loss: 0.787715
[2022-06-12 13:44:17 | train] - Train Epoch: [169] [358400/1281167 (28%)]	Loss: 0.778146
[2022-06-12 13:44:36 | train] - Train Epoch: [169] [371200/1281167 (29%)]	Loss: 0.948896
[2022-06-12 13:44:56 | train] - Train Epoch: [169] [384000/1281167 (30%)]	Loss: 0.780434
[2022-06-12 13:45:16 | train] - Train Epoch: [169] [396800/1281167 (31%)]	Loss: 0.926820
[2022-06-12 13:45:36 | train] - Train Epoch: [169] [409600/1281167 (32%)]	Loss: 0.477969
[2022-06-12 13:45:55 | train] - Train Epoch: [169] [422400/1281167 (33%)]	Loss: 0.692321
[2022-06-12 13:46:14 | train] - Train Epoch: [169] [435200/1281167 (34%)]	Loss: 0.651241
[2022-06-12 13:46:34 | train] - Train Epoch: [169] [448000/1281167 (35%)]	Loss: 0.558174
[2022-06-12 13:46:53 | train] - Train Epoch: [169] [460800/1281167 (36%)]	Loss: 0.708270
[2022-06-12 13:47:13 | train] - Train Epoch: [169] [473600/1281167 (37%)]	Loss: 0.837022
[2022-06-12 13:47:33 | train] - Train Epoch: [169] [486400/1281167 (38%)]	Loss: 0.600665
[2022-06-12 13:47:52 | train] - Train Epoch: [169] [499200/1281167 (39%)]	Loss: 0.713201
[2022-06-12 13:48:12 | train] - Train Epoch: [169] [512000/1281167 (40%)]	Loss: 0.769968
[2022-06-12 13:48:31 | train] - Train Epoch: [169] [524800/1281167 (41%)]	Loss: 0.834075
[2022-06-12 13:48:50 | train] - Train Epoch: [169] [537600/1281167 (42%)]	Loss: 0.934127
[2022-06-12 13:49:10 | train] - Train Epoch: [169] [550400/1281167 (43%)]	Loss: 0.700342
[2022-06-12 13:49:29 | train] - Train Epoch: [169] [563200/1281167 (44%)]	Loss: 0.584792
[2022-06-12 13:49:49 | train] - Train Epoch: [169] [576000/1281167 (45%)]	Loss: 0.921274
[2022-06-12 13:50:08 | train] - Train Epoch: [169] [588800/1281167 (46%)]	Loss: 0.757887
[2022-06-12 13:50:28 | train] - Train Epoch: [169] [601600/1281167 (47%)]	Loss: 0.696814
[2022-06-12 13:50:48 | train] - Train Epoch: [169] [614400/1281167 (48%)]	Loss: 0.747791
[2022-06-12 13:51:08 | train] - Train Epoch: [169] [627200/1281167 (49%)]	Loss: 0.707996
[2022-06-12 13:51:28 | train] - Train Epoch: [169] [640000/1281167 (50%)]	Loss: 0.874266
[2022-06-12 13:51:47 | train] - Train Epoch: [169] [652800/1281167 (51%)]	Loss: 0.751695
[2022-06-12 13:52:06 | train] - Train Epoch: [169] [665600/1281167 (52%)]	Loss: 0.646738
[2022-06-12 13:52:25 | train] - Train Epoch: [169] [678400/1281167 (53%)]	Loss: 0.777309
[2022-06-12 13:52:45 | train] - Train Epoch: [169] [691200/1281167 (54%)]	Loss: 0.687094
[2022-06-12 13:53:04 | train] - Train Epoch: [169] [704000/1281167 (55%)]	Loss: 0.466770
[2022-06-12 13:53:23 | train] - Train Epoch: [169] [716800/1281167 (56%)]	Loss: 0.699024
[2022-06-12 13:53:42 | train] - Train Epoch: [169] [729600/1281167 (57%)]	Loss: 0.807986
[2022-06-12 13:54:01 | train] - Train Epoch: [169] [742400/1281167 (58%)]	Loss: 0.623426
[2022-06-12 13:54:20 | train] - Train Epoch: [169] [755200/1281167 (59%)]	Loss: 0.696742
[2022-06-12 13:54:40 | train] - Train Epoch: [169] [768000/1281167 (60%)]	Loss: 0.566249
[2022-06-12 13:55:00 | train] - Train Epoch: [169] [780800/1281167 (61%)]	Loss: 0.569675
[2022-06-12 13:55:19 | train] - Train Epoch: [169] [793600/1281167 (62%)]	Loss: 0.723379
[2022-06-12 13:55:38 | train] - Train Epoch: [169] [806400/1281167 (63%)]	Loss: 0.570569
[2022-06-12 13:55:59 | train] - Train Epoch: [169] [819200/1281167 (64%)]	Loss: 0.653512
[2022-06-12 13:56:19 | train] - Train Epoch: [169] [832000/1281167 (65%)]	Loss: 0.826259
[2022-06-12 13:56:39 | train] - Train Epoch: [169] [844800/1281167 (66%)]	Loss: 0.573032
[2022-06-12 13:56:59 | train] - Train Epoch: [169] [857600/1281167 (67%)]	Loss: 0.611338
[2022-06-12 13:57:18 | train] - Train Epoch: [169] [870400/1281167 (68%)]	Loss: 0.568385
[2022-06-12 13:57:37 | train] - Train Epoch: [169] [883200/1281167 (69%)]	Loss: 0.728444
[2022-06-12 13:57:57 | train] - Train Epoch: [169] [896000/1281167 (70%)]	Loss: 0.984660
[2022-06-12 13:58:16 | train] - Train Epoch: [169] [908800/1281167 (71%)]	Loss: 0.694655
[2022-06-12 13:58:36 | train] - Train Epoch: [169] [921600/1281167 (72%)]	Loss: 0.393809
[2022-06-12 13:58:56 | train] - Train Epoch: [169] [934400/1281167 (73%)]	Loss: 0.675197
[2022-06-12 13:59:17 | train] - Train Epoch: [169] [947200/1281167 (74%)]	Loss: 0.627596
[2022-06-12 13:59:37 | train] - Train Epoch: [169] [960000/1281167 (75%)]	Loss: 0.643997
[2022-06-12 13:59:57 | train] - Train Epoch: [169] [972800/1281167 (76%)]	Loss: 0.599362
[2022-06-12 14:00:17 | train] - Train Epoch: [169] [985600/1281167 (77%)]	Loss: 0.703306
[2022-06-12 14:00:38 | train] - Train Epoch: [169] [998400/1281167 (78%)]	Loss: 0.595632
[2022-06-12 14:00:58 | train] - Train Epoch: [169] [1011200/1281167 (79%)]	Loss: 0.615058
[2022-06-12 14:01:19 | train] - Train Epoch: [169] [1024000/1281167 (80%)]	Loss: 0.821279
[2022-06-12 14:01:39 | train] - Train Epoch: [169] [1036800/1281167 (81%)]	Loss: 0.757938
[2022-06-12 14:01:59 | train] - Train Epoch: [169] [1049600/1281167 (82%)]	Loss: 0.649778
[2022-06-12 14:02:18 | train] - Train Epoch: [169] [1062400/1281167 (83%)]	Loss: 0.929558
[2022-06-12 14:02:39 | train] - Train Epoch: [169] [1075200/1281167 (84%)]	Loss: 0.497938
[2022-06-12 14:02:58 | train] - Train Epoch: [169] [1088000/1281167 (85%)]	Loss: 0.703362
[2022-06-12 14:03:19 | train] - Train Epoch: [169] [1100800/1281167 (86%)]	Loss: 0.634266
[2022-06-12 14:03:38 | train] - Train Epoch: [169] [1113600/1281167 (87%)]	Loss: 0.849715
[2022-06-12 14:03:58 | train] - Train Epoch: [169] [1126400/1281167 (88%)]	Loss: 0.613033
[2022-06-12 14:04:18 | train] - Train Epoch: [169] [1139200/1281167 (89%)]	Loss: 0.688474
[2022-06-12 14:04:38 | train] - Train Epoch: [169] [1152000/1281167 (90%)]	Loss: 0.873104
[2022-06-12 14:04:58 | train] - Train Epoch: [169] [1164800/1281167 (91%)]	Loss: 0.608853
[2022-06-12 14:05:18 | train] - Train Epoch: [169] [1177600/1281167 (92%)]	Loss: 0.517262
[2022-06-12 14:05:38 | train] - Train Epoch: [169] [1190400/1281167 (93%)]	Loss: 0.638237
[2022-06-12 14:05:58 | train] - Train Epoch: [169] [1203200/1281167 (94%)]	Loss: 0.660175
[2022-06-12 14:06:18 | train] - Train Epoch: [169] [1216000/1281167 (95%)]	Loss: 0.809455
[2022-06-12 14:06:37 | train] - Train Epoch: [169] [1228800/1281167 (96%)]	Loss: 0.671207
[2022-06-12 14:06:57 | train] - Train Epoch: [169] [1241600/1281167 (97%)]	Loss: 0.635127
[2022-06-12 14:07:17 | train] - Train Epoch: [169] [1254400/1281167 (98%)]	Loss: 0.500801
[2022-06-12 14:07:37 | train] - Train Epoch: [169] [1267200/1281167 (99%)]	Loss: 0.620412
[2022-06-12 14:07:57 | train] - Train Epoch: [169] [1280000/1281167 (100%)]	Loss: 0.743924
[2022-06-12 14:07:59 | train] - Train Epoch: [169]	 Average Loss: 0.731490	 Total Acc : 82.2620	 Total Top5 Acc : 93.5240
[2022-06-12 14:07:59 | train] - -------169 epoch end-----------
========================================
-------169 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 14:09:26 | train] - 
Epoch [169] Test set: Average loss: 1.4288, Accuracy: 34958/50000 (69.8861%), Top-5 Accuracy: 88.9510%

[2022-06-12 14:09:26 | train] - save intermediate epoch [169] result


[2022-06-12 14:09:43 | train] - -------170 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 14:09:45 | train] - Train Epoch: [170] [0/1281167 (0%)]	Loss: 0.616279
[2022-06-12 14:10:06 | train] - Train Epoch: [170] [12800/1281167 (1%)]	Loss: 0.627750
[2022-06-12 14:10:26 | train] - Train Epoch: [170] [25600/1281167 (2%)]	Loss: 0.496413
[2022-06-12 14:10:46 | train] - Train Epoch: [170] [38400/1281167 (3%)]	Loss: 0.652399
[2022-06-12 14:11:06 | train] - Train Epoch: [170] [51200/1281167 (4%)]	Loss: 0.588918
[2022-06-12 14:11:27 | train] - Train Epoch: [170] [64000/1281167 (5%)]	Loss: 0.720371
[2022-06-12 14:11:47 | train] - Train Epoch: [170] [76800/1281167 (6%)]	Loss: 0.819879
[2022-06-12 14:12:07 | train] - Train Epoch: [170] [89600/1281167 (7%)]	Loss: 0.549242
[2022-06-12 14:12:27 | train] - Train Epoch: [170] [102400/1281167 (8%)]	Loss: 0.704823
[2022-06-12 14:12:47 | train] - Train Epoch: [170] [115200/1281167 (9%)]	Loss: 0.665270
[2022-06-12 14:13:07 | train] - Train Epoch: [170] [128000/1281167 (10%)]	Loss: 0.478713
[2022-06-12 14:13:26 | train] - Train Epoch: [170] [140800/1281167 (11%)]	Loss: 0.742143
[2022-06-12 14:13:47 | train] - Train Epoch: [170] [153600/1281167 (12%)]	Loss: 0.793216
[2022-06-12 14:14:06 | train] - Train Epoch: [170] [166400/1281167 (13%)]	Loss: 0.969187
[2022-06-12 14:14:26 | train] - Train Epoch: [170] [179200/1281167 (14%)]	Loss: 0.914909
[2022-06-12 14:14:46 | train] - Train Epoch: [170] [192000/1281167 (15%)]	Loss: 0.870358
[2022-06-12 14:15:06 | train] - Train Epoch: [170] [204800/1281167 (16%)]	Loss: 0.704616
[2022-06-12 14:15:25 | train] - Train Epoch: [170] [217600/1281167 (17%)]	Loss: 0.744701
[2022-06-12 14:15:45 | train] - Train Epoch: [170] [230400/1281167 (18%)]	Loss: 0.790374
[2022-06-12 14:16:05 | train] - Train Epoch: [170] [243200/1281167 (19%)]	Loss: 0.865249
[2022-06-12 14:16:24 | train] - Train Epoch: [170] [256000/1281167 (20%)]	Loss: 0.514836
[2022-06-12 14:16:43 | train] - Train Epoch: [170] [268800/1281167 (21%)]	Loss: 0.968023
[2022-06-12 14:17:02 | train] - Train Epoch: [170] [281600/1281167 (22%)]	Loss: 0.675963
[2022-06-12 14:17:22 | train] - Train Epoch: [170] [294400/1281167 (23%)]	Loss: 1.183584
[2022-06-12 14:17:41 | train] - Train Epoch: [170] [307200/1281167 (24%)]	Loss: 0.828771
[2022-06-12 14:18:00 | train] - Train Epoch: [170] [320000/1281167 (25%)]	Loss: 0.651288
[2022-06-12 14:18:20 | train] - Train Epoch: [170] [332800/1281167 (26%)]	Loss: 0.584243
[2022-06-12 14:18:40 | train] - Train Epoch: [170] [345600/1281167 (27%)]	Loss: 0.892162
[2022-06-12 14:18:59 | train] - Train Epoch: [170] [358400/1281167 (28%)]	Loss: 0.751224
[2022-06-12 14:19:19 | train] - Train Epoch: [170] [371200/1281167 (29%)]	Loss: 1.041662
[2022-06-12 14:19:38 | train] - Train Epoch: [170] [384000/1281167 (30%)]	Loss: 0.491220
[2022-06-12 14:19:57 | train] - Train Epoch: [170] [396800/1281167 (31%)]	Loss: 1.005252
[2022-06-12 14:20:17 | train] - Train Epoch: [170] [409600/1281167 (32%)]	Loss: 0.881205
[2022-06-12 14:20:37 | train] - Train Epoch: [170] [422400/1281167 (33%)]	Loss: 0.579153
[2022-06-12 14:20:56 | train] - Train Epoch: [170] [435200/1281167 (34%)]	Loss: 0.718522
[2022-06-12 14:21:16 | train] - Train Epoch: [170] [448000/1281167 (35%)]	Loss: 0.756015
[2022-06-12 14:21:36 | train] - Train Epoch: [170] [460800/1281167 (36%)]	Loss: 0.917221
[2022-06-12 14:21:56 | train] - Train Epoch: [170] [473600/1281167 (37%)]	Loss: 0.796276
[2022-06-12 14:22:15 | train] - Train Epoch: [170] [486400/1281167 (38%)]	Loss: 0.882566
[2022-06-12 14:22:35 | train] - Train Epoch: [170] [499200/1281167 (39%)]	Loss: 0.672227
[2022-06-12 14:22:55 | train] - Train Epoch: [170] [512000/1281167 (40%)]	Loss: 0.944734
[2022-06-12 14:23:13 | train] - Train Epoch: [170] [524800/1281167 (41%)]	Loss: 0.760250
[2022-06-12 14:23:34 | train] - Train Epoch: [170] [537600/1281167 (42%)]	Loss: 0.671173
[2022-06-12 14:23:53 | train] - Train Epoch: [170] [550400/1281167 (43%)]	Loss: 0.678254
[2022-06-12 14:24:12 | train] - Train Epoch: [170] [563200/1281167 (44%)]	Loss: 0.983706
[2022-06-12 14:24:32 | train] - Train Epoch: [170] [576000/1281167 (45%)]	Loss: 0.778524
[2022-06-12 14:24:51 | train] - Train Epoch: [170] [588800/1281167 (46%)]	Loss: 0.614886
[2022-06-12 14:25:11 | train] - Train Epoch: [170] [601600/1281167 (47%)]	Loss: 0.879608
[2022-06-12 14:25:30 | train] - Train Epoch: [170] [614400/1281167 (48%)]	Loss: 0.813134
[2022-06-12 14:25:50 | train] - Train Epoch: [170] [627200/1281167 (49%)]	Loss: 0.709437
[2022-06-12 14:26:10 | train] - Train Epoch: [170] [640000/1281167 (50%)]	Loss: 1.019400
[2022-06-12 14:26:29 | train] - Train Epoch: [170] [652800/1281167 (51%)]	Loss: 0.827527
[2022-06-12 14:26:49 | train] - Train Epoch: [170] [665600/1281167 (52%)]	Loss: 0.707309
[2022-06-12 14:27:08 | train] - Train Epoch: [170] [678400/1281167 (53%)]	Loss: 0.580592
[2022-06-12 14:27:27 | train] - Train Epoch: [170] [691200/1281167 (54%)]	Loss: 0.787715
[2022-06-12 14:27:47 | train] - Train Epoch: [170] [704000/1281167 (55%)]	Loss: 0.814849
[2022-06-12 14:28:05 | train] - Train Epoch: [170] [716800/1281167 (56%)]	Loss: 0.814097
[2022-06-12 14:28:25 | train] - Train Epoch: [170] [729600/1281167 (57%)]	Loss: 0.791756
[2022-06-12 14:28:45 | train] - Train Epoch: [170] [742400/1281167 (58%)]	Loss: 0.633467
[2022-06-12 14:29:05 | train] - Train Epoch: [170] [755200/1281167 (59%)]	Loss: 0.682622
[2022-06-12 14:29:24 | train] - Train Epoch: [170] [768000/1281167 (60%)]	Loss: 0.584105
[2022-06-12 14:29:44 | train] - Train Epoch: [170] [780800/1281167 (61%)]	Loss: 0.711886
[2022-06-12 14:30:03 | train] - Train Epoch: [170] [793600/1281167 (62%)]	Loss: 1.004172
[2022-06-12 14:30:22 | train] - Train Epoch: [170] [806400/1281167 (63%)]	Loss: 0.766145
[2022-06-12 14:30:42 | train] - Train Epoch: [170] [819200/1281167 (64%)]	Loss: 0.647035
[2022-06-12 14:31:01 | train] - Train Epoch: [170] [832000/1281167 (65%)]	Loss: 0.650640
[2022-06-12 14:31:20 | train] - Train Epoch: [170] [844800/1281167 (66%)]	Loss: 0.762739
[2022-06-12 14:31:40 | train] - Train Epoch: [170] [857600/1281167 (67%)]	Loss: 0.412395
[2022-06-12 14:31:59 | train] - Train Epoch: [170] [870400/1281167 (68%)]	Loss: 0.497263
[2022-06-12 14:32:19 | train] - Train Epoch: [170] [883200/1281167 (69%)]	Loss: 0.704091
[2022-06-12 14:32:38 | train] - Train Epoch: [170] [896000/1281167 (70%)]	Loss: 0.656050
[2022-06-12 14:32:58 | train] - Train Epoch: [170] [908800/1281167 (71%)]	Loss: 0.523507
[2022-06-12 14:33:18 | train] - Train Epoch: [170] [921600/1281167 (72%)]	Loss: 0.717297
[2022-06-12 14:33:37 | train] - Train Epoch: [170] [934400/1281167 (73%)]	Loss: 0.802199
[2022-06-12 14:33:57 | train] - Train Epoch: [170] [947200/1281167 (74%)]	Loss: 0.815160
[2022-06-12 14:34:16 | train] - Train Epoch: [170] [960000/1281167 (75%)]	Loss: 0.807465
[2022-06-12 14:34:36 | train] - Train Epoch: [170] [972800/1281167 (76%)]	Loss: 0.812432
[2022-06-12 14:34:55 | train] - Train Epoch: [170] [985600/1281167 (77%)]	Loss: 0.835266
[2022-06-12 14:35:15 | train] - Train Epoch: [170] [998400/1281167 (78%)]	Loss: 0.652088
[2022-06-12 14:35:35 | train] - Train Epoch: [170] [1011200/1281167 (79%)]	Loss: 0.671780
[2022-06-12 14:35:56 | train] - Train Epoch: [170] [1024000/1281167 (80%)]	Loss: 0.750189
[2022-06-12 14:36:15 | train] - Train Epoch: [170] [1036800/1281167 (81%)]	Loss: 0.663164
[2022-06-12 14:36:34 | train] - Train Epoch: [170] [1049600/1281167 (82%)]	Loss: 0.842635
[2022-06-12 14:36:54 | train] - Train Epoch: [170] [1062400/1281167 (83%)]	Loss: 0.612887
[2022-06-12 14:37:14 | train] - Train Epoch: [170] [1075200/1281167 (84%)]	Loss: 0.617027
[2022-06-12 14:37:34 | train] - Train Epoch: [170] [1088000/1281167 (85%)]	Loss: 0.687842
[2022-06-12 14:37:54 | train] - Train Epoch: [170] [1100800/1281167 (86%)]	Loss: 0.691245
[2022-06-12 14:38:14 | train] - Train Epoch: [170] [1113600/1281167 (87%)]	Loss: 0.620288
[2022-06-12 14:38:34 | train] - Train Epoch: [170] [1126400/1281167 (88%)]	Loss: 0.895873
[2022-06-12 14:38:53 | train] - Train Epoch: [170] [1139200/1281167 (89%)]	Loss: 0.699884
[2022-06-12 14:39:13 | train] - Train Epoch: [170] [1152000/1281167 (90%)]	Loss: 0.703913
[2022-06-12 14:39:33 | train] - Train Epoch: [170] [1164800/1281167 (91%)]	Loss: 0.584875
[2022-06-12 14:39:52 | train] - Train Epoch: [170] [1177600/1281167 (92%)]	Loss: 0.795866
[2022-06-12 14:40:12 | train] - Train Epoch: [170] [1190400/1281167 (93%)]	Loss: 0.704837
[2022-06-12 14:40:32 | train] - Train Epoch: [170] [1203200/1281167 (94%)]	Loss: 0.571769
[2022-06-12 14:40:52 | train] - Train Epoch: [170] [1216000/1281167 (95%)]	Loss: 0.948050
[2022-06-12 14:41:12 | train] - Train Epoch: [170] [1228800/1281167 (96%)]	Loss: 0.646929
[2022-06-12 14:41:32 | train] - Train Epoch: [170] [1241600/1281167 (97%)]	Loss: 0.661316
[2022-06-12 14:41:51 | train] - Train Epoch: [170] [1254400/1281167 (98%)]	Loss: 0.636937
[2022-06-12 14:42:11 | train] - Train Epoch: [170] [1267200/1281167 (99%)]	Loss: 0.912451
[2022-06-12 14:42:30 | train] - Train Epoch: [170] [1280000/1281167 (100%)]	Loss: 0.930545
[2022-06-12 14:42:32 | train] - Train Epoch: [170]	 Average Loss: 0.730008	 Total Acc : 82.2233	 Total Top5 Acc : 93.5564
[2022-06-12 14:42:32 | train] - -------170 epoch end-----------
========================================
-------170 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 14:43:59 | train] - 
Epoch [170] Test set: Average loss: 1.4342, Accuracy: 34953/50000 (69.8785%), Top-5 Accuracy: 88.8375%

[2022-06-12 14:43:59 | train] - save intermediate epoch [170] result


[2022-06-12 14:44:17 | train] - -------171 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 14:44:19 | train] - Train Epoch: [171] [0/1281167 (0%)]	Loss: 0.629749
[2022-06-12 14:44:40 | train] - Train Epoch: [171] [12800/1281167 (1%)]	Loss: 0.736203
[2022-06-12 14:45:01 | train] - Train Epoch: [171] [25600/1281167 (2%)]	Loss: 0.726805
[2022-06-12 14:45:21 | train] - Train Epoch: [171] [38400/1281167 (3%)]	Loss: 0.818076
[2022-06-12 14:45:40 | train] - Train Epoch: [171] [51200/1281167 (4%)]	Loss: 0.872364
[2022-06-12 14:45:59 | train] - Train Epoch: [171] [64000/1281167 (5%)]	Loss: 0.627046
[2022-06-12 14:46:18 | train] - Train Epoch: [171] [76800/1281167 (6%)]	Loss: 0.564163
[2022-06-12 14:46:38 | train] - Train Epoch: [171] [89600/1281167 (7%)]	Loss: 0.557324
[2022-06-12 14:46:57 | train] - Train Epoch: [171] [102400/1281167 (8%)]	Loss: 0.905224
[2022-06-12 14:47:17 | train] - Train Epoch: [171] [115200/1281167 (9%)]	Loss: 0.923637
[2022-06-12 14:47:37 | train] - Train Epoch: [171] [128000/1281167 (10%)]	Loss: 0.775069
[2022-06-12 14:47:56 | train] - Train Epoch: [171] [140800/1281167 (11%)]	Loss: 0.608822
[2022-06-12 14:48:16 | train] - Train Epoch: [171] [153600/1281167 (12%)]	Loss: 0.544430
[2022-06-12 14:48:35 | train] - Train Epoch: [171] [166400/1281167 (13%)]	Loss: 0.630083
[2022-06-12 14:48:55 | train] - Train Epoch: [171] [179200/1281167 (14%)]	Loss: 0.694089
[2022-06-12 14:49:15 | train] - Train Epoch: [171] [192000/1281167 (15%)]	Loss: 0.763373
[2022-06-12 14:49:35 | train] - Train Epoch: [171] [204800/1281167 (16%)]	Loss: 0.637409
[2022-06-12 14:49:54 | train] - Train Epoch: [171] [217600/1281167 (17%)]	Loss: 0.714067
[2022-06-12 14:50:14 | train] - Train Epoch: [171] [230400/1281167 (18%)]	Loss: 0.640934
[2022-06-12 14:50:33 | train] - Train Epoch: [171] [243200/1281167 (19%)]	Loss: 0.743465
[2022-06-12 14:50:53 | train] - Train Epoch: [171] [256000/1281167 (20%)]	Loss: 0.704467
[2022-06-12 14:51:12 | train] - Train Epoch: [171] [268800/1281167 (21%)]	Loss: 0.491797
[2022-06-12 14:51:32 | train] - Train Epoch: [171] [281600/1281167 (22%)]	Loss: 1.011515
[2022-06-12 14:51:52 | train] - Train Epoch: [171] [294400/1281167 (23%)]	Loss: 0.676047
[2022-06-12 14:52:11 | train] - Train Epoch: [171] [307200/1281167 (24%)]	Loss: 0.765488
[2022-06-12 14:52:31 | train] - Train Epoch: [171] [320000/1281167 (25%)]	Loss: 0.675493
[2022-06-12 14:52:50 | train] - Train Epoch: [171] [332800/1281167 (26%)]	Loss: 0.699295
[2022-06-12 14:53:10 | train] - Train Epoch: [171] [345600/1281167 (27%)]	Loss: 0.817221
[2022-06-12 14:53:29 | train] - Train Epoch: [171] [358400/1281167 (28%)]	Loss: 0.775726
[2022-06-12 14:53:49 | train] - Train Epoch: [171] [371200/1281167 (29%)]	Loss: 0.626253
[2022-06-12 14:54:08 | train] - Train Epoch: [171] [384000/1281167 (30%)]	Loss: 0.755930
[2022-06-12 14:54:28 | train] - Train Epoch: [171] [396800/1281167 (31%)]	Loss: 0.963444
[2022-06-12 14:54:47 | train] - Train Epoch: [171] [409600/1281167 (32%)]	Loss: 0.863962
[2022-06-12 14:55:07 | train] - Train Epoch: [171] [422400/1281167 (33%)]	Loss: 0.680419
[2022-06-12 14:55:26 | train] - Train Epoch: [171] [435200/1281167 (34%)]	Loss: 0.723710
[2022-06-12 14:55:46 | train] - Train Epoch: [171] [448000/1281167 (35%)]	Loss: 0.797933
[2022-06-12 14:56:05 | train] - Train Epoch: [171] [460800/1281167 (36%)]	Loss: 0.706032
[2022-06-12 14:56:24 | train] - Train Epoch: [171] [473600/1281167 (37%)]	Loss: 0.658184
[2022-06-12 14:56:44 | train] - Train Epoch: [171] [486400/1281167 (38%)]	Loss: 0.713935
[2022-06-12 14:57:04 | train] - Train Epoch: [171] [499200/1281167 (39%)]	Loss: 0.919810
[2022-06-12 14:57:24 | train] - Train Epoch: [171] [512000/1281167 (40%)]	Loss: 0.831127
[2022-06-12 14:57:43 | train] - Train Epoch: [171] [524800/1281167 (41%)]	Loss: 0.460314
[2022-06-12 14:58:03 | train] - Train Epoch: [171] [537600/1281167 (42%)]	Loss: 0.651891
[2022-06-12 14:58:23 | train] - Train Epoch: [171] [550400/1281167 (43%)]	Loss: 0.910872
[2022-06-12 14:58:42 | train] - Train Epoch: [171] [563200/1281167 (44%)]	Loss: 0.752378
[2022-06-12 14:59:02 | train] - Train Epoch: [171] [576000/1281167 (45%)]	Loss: 0.755055
[2022-06-12 14:59:21 | train] - Train Epoch: [171] [588800/1281167 (46%)]	Loss: 0.724627
[2022-06-12 14:59:41 | train] - Train Epoch: [171] [601600/1281167 (47%)]	Loss: 1.082122
[2022-06-12 15:00:00 | train] - Train Epoch: [171] [614400/1281167 (48%)]	Loss: 0.911354
[2022-06-12 15:00:19 | train] - Train Epoch: [171] [627200/1281167 (49%)]	Loss: 0.728838
[2022-06-12 15:00:38 | train] - Train Epoch: [171] [640000/1281167 (50%)]	Loss: 0.695796
[2022-06-12 15:00:57 | train] - Train Epoch: [171] [652800/1281167 (51%)]	Loss: 0.836352
[2022-06-12 15:01:17 | train] - Train Epoch: [171] [665600/1281167 (52%)]	Loss: 0.858973
[2022-06-12 15:01:36 | train] - Train Epoch: [171] [678400/1281167 (53%)]	Loss: 0.711707
[2022-06-12 15:01:55 | train] - Train Epoch: [171] [691200/1281167 (54%)]	Loss: 0.631370
[2022-06-12 15:02:14 | train] - Train Epoch: [171] [704000/1281167 (55%)]	Loss: 0.762541
[2022-06-12 15:02:35 | train] - Train Epoch: [171] [716800/1281167 (56%)]	Loss: 0.702992
[2022-06-12 15:02:55 | train] - Train Epoch: [171] [729600/1281167 (57%)]	Loss: 0.633496
[2022-06-12 15:03:15 | train] - Train Epoch: [171] [742400/1281167 (58%)]	Loss: 1.025801
[2022-06-12 15:03:35 | train] - Train Epoch: [171] [755200/1281167 (59%)]	Loss: 0.693668
[2022-06-12 15:03:55 | train] - Train Epoch: [171] [768000/1281167 (60%)]	Loss: 0.720659
[2022-06-12 15:04:13 | train] - Train Epoch: [171] [780800/1281167 (61%)]	Loss: 0.816878
[2022-06-12 15:04:33 | train] - Train Epoch: [171] [793600/1281167 (62%)]	Loss: 0.958956
[2022-06-12 15:04:52 | train] - Train Epoch: [171] [806400/1281167 (63%)]	Loss: 0.653387
[2022-06-12 15:05:11 | train] - Train Epoch: [171] [819200/1281167 (64%)]	Loss: 0.572691
[2022-06-12 15:05:31 | train] - Train Epoch: [171] [832000/1281167 (65%)]	Loss: 0.587578
[2022-06-12 15:05:51 | train] - Train Epoch: [171] [844800/1281167 (66%)]	Loss: 0.678707
[2022-06-12 15:06:10 | train] - Train Epoch: [171] [857600/1281167 (67%)]	Loss: 0.816418
[2022-06-12 15:06:29 | train] - Train Epoch: [171] [870400/1281167 (68%)]	Loss: 0.930911
[2022-06-12 15:06:48 | train] - Train Epoch: [171] [883200/1281167 (69%)]	Loss: 0.644907
[2022-06-12 15:07:08 | train] - Train Epoch: [171] [896000/1281167 (70%)]	Loss: 0.604589
[2022-06-12 15:07:28 | train] - Train Epoch: [171] [908800/1281167 (71%)]	Loss: 0.811550
[2022-06-12 15:07:47 | train] - Train Epoch: [171] [921600/1281167 (72%)]	Loss: 0.840849
[2022-06-12 15:08:07 | train] - Train Epoch: [171] [934400/1281167 (73%)]	Loss: 0.708636
[2022-06-12 15:08:26 | train] - Train Epoch: [171] [947200/1281167 (74%)]	Loss: 0.722022
[2022-06-12 15:08:45 | train] - Train Epoch: [171] [960000/1281167 (75%)]	Loss: 0.876811
[2022-06-12 15:09:04 | train] - Train Epoch: [171] [972800/1281167 (76%)]	Loss: 0.582652
[2022-06-12 15:09:24 | train] - Train Epoch: [171] [985600/1281167 (77%)]	Loss: 0.686101
[2022-06-12 15:09:44 | train] - Train Epoch: [171] [998400/1281167 (78%)]	Loss: 0.705217
[2022-06-12 15:10:03 | train] - Train Epoch: [171] [1011200/1281167 (79%)]	Loss: 0.680327
[2022-06-12 15:10:23 | train] - Train Epoch: [171] [1024000/1281167 (80%)]	Loss: 0.515315
[2022-06-12 15:10:43 | train] - Train Epoch: [171] [1036800/1281167 (81%)]	Loss: 0.839456
[2022-06-12 15:11:02 | train] - Train Epoch: [171] [1049600/1281167 (82%)]	Loss: 0.829635
[2022-06-12 15:11:22 | train] - Train Epoch: [171] [1062400/1281167 (83%)]	Loss: 0.715404
[2022-06-12 15:11:41 | train] - Train Epoch: [171] [1075200/1281167 (84%)]	Loss: 0.623669
[2022-06-12 15:12:01 | train] - Train Epoch: [171] [1088000/1281167 (85%)]	Loss: 0.569812
[2022-06-12 15:12:21 | train] - Train Epoch: [171] [1100800/1281167 (86%)]	Loss: 0.830011
[2022-06-12 15:12:40 | train] - Train Epoch: [171] [1113600/1281167 (87%)]	Loss: 0.832091
[2022-06-12 15:13:00 | train] - Train Epoch: [171] [1126400/1281167 (88%)]	Loss: 0.787924
[2022-06-12 15:13:20 | train] - Train Epoch: [171] [1139200/1281167 (89%)]	Loss: 0.504145
[2022-06-12 15:13:39 | train] - Train Epoch: [171] [1152000/1281167 (90%)]	Loss: 0.592792
[2022-06-12 15:13:59 | train] - Train Epoch: [171] [1164800/1281167 (91%)]	Loss: 0.680874
[2022-06-12 15:14:18 | train] - Train Epoch: [171] [1177600/1281167 (92%)]	Loss: 0.739460
[2022-06-12 15:14:38 | train] - Train Epoch: [171] [1190400/1281167 (93%)]	Loss: 0.799041
[2022-06-12 15:14:58 | train] - Train Epoch: [171] [1203200/1281167 (94%)]	Loss: 0.859580
[2022-06-12 15:15:18 | train] - Train Epoch: [171] [1216000/1281167 (95%)]	Loss: 0.750172
[2022-06-12 15:15:38 | train] - Train Epoch: [171] [1228800/1281167 (96%)]	Loss: 0.740957
[2022-06-12 15:15:58 | train] - Train Epoch: [171] [1241600/1281167 (97%)]	Loss: 0.637081
[2022-06-12 15:16:17 | train] - Train Epoch: [171] [1254400/1281167 (98%)]	Loss: 0.815734
[2022-06-12 15:16:37 | train] - Train Epoch: [171] [1267200/1281167 (99%)]	Loss: 0.721319
[2022-06-12 15:16:56 | train] - Train Epoch: [171] [1280000/1281167 (100%)]	Loss: 0.919249
[2022-06-12 15:16:58 | train] - Train Epoch: [171]	 Average Loss: 0.728714	 Total Acc : 82.2827	 Total Top5 Acc : 93.5303
[2022-06-12 15:16:58 | train] - -------171 epoch end-----------
========================================
-------171 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 15:18:27 | train] - 
Epoch [171] Test set: Average loss: 1.4233, Accuracy: 34982/50000 (69.9377%), Top-5 Accuracy: 89.0114%

[2022-06-12 15:18:27 | train] - save intermediate epoch [171] result


[2022-06-12 15:18:45 | train] - -------172 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 15:18:47 | train] - Train Epoch: [172] [0/1281167 (0%)]	Loss: 0.715533
[2022-06-12 15:19:06 | train] - Train Epoch: [172] [12800/1281167 (1%)]	Loss: 0.711261
[2022-06-12 15:19:26 | train] - Train Epoch: [172] [25600/1281167 (2%)]	Loss: 0.679952
[2022-06-12 15:19:46 | train] - Train Epoch: [172] [38400/1281167 (3%)]	Loss: 0.634002
[2022-06-12 15:20:05 | train] - Train Epoch: [172] [51200/1281167 (4%)]	Loss: 0.808953
[2022-06-12 15:20:25 | train] - Train Epoch: [172] [64000/1281167 (5%)]	Loss: 1.035856
[2022-06-12 15:20:45 | train] - Train Epoch: [172] [76800/1281167 (6%)]	Loss: 0.886722
[2022-06-12 15:21:05 | train] - Train Epoch: [172] [89600/1281167 (7%)]	Loss: 0.753777
[2022-06-12 15:21:24 | train] - Train Epoch: [172] [102400/1281167 (8%)]	Loss: 0.803260
[2022-06-12 15:21:44 | train] - Train Epoch: [172] [115200/1281167 (9%)]	Loss: 0.583421
[2022-06-12 15:22:03 | train] - Train Epoch: [172] [128000/1281167 (10%)]	Loss: 0.521555
[2022-06-12 15:22:22 | train] - Train Epoch: [172] [140800/1281167 (11%)]	Loss: 0.869958
[2022-06-12 15:22:42 | train] - Train Epoch: [172] [153600/1281167 (12%)]	Loss: 0.849477
[2022-06-12 15:23:01 | train] - Train Epoch: [172] [166400/1281167 (13%)]	Loss: 0.881319
[2022-06-12 15:23:20 | train] - Train Epoch: [172] [179200/1281167 (14%)]	Loss: 0.644441
[2022-06-12 15:23:39 | train] - Train Epoch: [172] [192000/1281167 (15%)]	Loss: 0.790519
[2022-06-12 15:23:58 | train] - Train Epoch: [172] [204800/1281167 (16%)]	Loss: 0.625500
[2022-06-12 15:24:18 | train] - Train Epoch: [172] [217600/1281167 (17%)]	Loss: 0.890452
[2022-06-12 15:24:37 | train] - Train Epoch: [172] [230400/1281167 (18%)]	Loss: 0.702471
[2022-06-12 15:24:56 | train] - Train Epoch: [172] [243200/1281167 (19%)]	Loss: 0.934040
[2022-06-12 15:25:15 | train] - Train Epoch: [172] [256000/1281167 (20%)]	Loss: 0.769959
[2022-06-12 15:25:35 | train] - Train Epoch: [172] [268800/1281167 (21%)]	Loss: 0.631479
[2022-06-12 15:25:55 | train] - Train Epoch: [172] [281600/1281167 (22%)]	Loss: 0.796558
[2022-06-12 15:26:15 | train] - Train Epoch: [172] [294400/1281167 (23%)]	Loss: 0.610087
[2022-06-12 15:26:35 | train] - Train Epoch: [172] [307200/1281167 (24%)]	Loss: 0.612508
[2022-06-12 15:26:55 | train] - Train Epoch: [172] [320000/1281167 (25%)]	Loss: 0.791899
[2022-06-12 15:27:14 | train] - Train Epoch: [172] [332800/1281167 (26%)]	Loss: 0.812312
[2022-06-12 15:27:34 | train] - Train Epoch: [172] [345600/1281167 (27%)]	Loss: 0.845457
[2022-06-12 15:27:54 | train] - Train Epoch: [172] [358400/1281167 (28%)]	Loss: 0.905912
[2022-06-12 15:28:14 | train] - Train Epoch: [172] [371200/1281167 (29%)]	Loss: 0.871652
[2022-06-12 15:28:33 | train] - Train Epoch: [172] [384000/1281167 (30%)]	Loss: 0.770972
[2022-06-12 15:28:52 | train] - Train Epoch: [172] [396800/1281167 (31%)]	Loss: 0.621043
[2022-06-12 15:29:11 | train] - Train Epoch: [172] [409600/1281167 (32%)]	Loss: 0.963849
[2022-06-12 15:29:30 | train] - Train Epoch: [172] [422400/1281167 (33%)]	Loss: 0.840946
[2022-06-12 15:29:49 | train] - Train Epoch: [172] [435200/1281167 (34%)]	Loss: 0.907343
[2022-06-12 15:30:09 | train] - Train Epoch: [172] [448000/1281167 (35%)]	Loss: 1.062581
[2022-06-12 15:30:29 | train] - Train Epoch: [172] [460800/1281167 (36%)]	Loss: 0.560834
[2022-06-12 15:30:48 | train] - Train Epoch: [172] [473600/1281167 (37%)]	Loss: 0.747857
[2022-06-12 15:31:08 | train] - Train Epoch: [172] [486400/1281167 (38%)]	Loss: 0.748024
[2022-06-12 15:31:27 | train] - Train Epoch: [172] [499200/1281167 (39%)]	Loss: 0.729073
[2022-06-12 15:31:47 | train] - Train Epoch: [172] [512000/1281167 (40%)]	Loss: 0.609628
[2022-06-12 15:32:07 | train] - Train Epoch: [172] [524800/1281167 (41%)]	Loss: 0.846695
[2022-06-12 15:32:26 | train] - Train Epoch: [172] [537600/1281167 (42%)]	Loss: 0.401859
[2022-06-12 15:32:46 | train] - Train Epoch: [172] [550400/1281167 (43%)]	Loss: 0.809781
[2022-06-12 15:33:06 | train] - Train Epoch: [172] [563200/1281167 (44%)]	Loss: 0.754586
[2022-06-12 15:33:26 | train] - Train Epoch: [172] [576000/1281167 (45%)]	Loss: 0.567880
[2022-06-12 15:33:45 | train] - Train Epoch: [172] [588800/1281167 (46%)]	Loss: 0.727554
[2022-06-12 15:34:04 | train] - Train Epoch: [172] [601600/1281167 (47%)]	Loss: 1.067362
[2022-06-12 15:34:24 | train] - Train Epoch: [172] [614400/1281167 (48%)]	Loss: 0.778712
[2022-06-12 15:34:44 | train] - Train Epoch: [172] [627200/1281167 (49%)]	Loss: 1.030035
[2022-06-12 15:35:03 | train] - Train Epoch: [172] [640000/1281167 (50%)]	Loss: 0.717054
[2022-06-12 15:35:23 | train] - Train Epoch: [172] [652800/1281167 (51%)]	Loss: 0.661859
[2022-06-12 15:35:42 | train] - Train Epoch: [172] [665600/1281167 (52%)]	Loss: 0.677432
[2022-06-12 15:36:01 | train] - Train Epoch: [172] [678400/1281167 (53%)]	Loss: 0.779435
[2022-06-12 15:36:21 | train] - Train Epoch: [172] [691200/1281167 (54%)]	Loss: 0.667539
[2022-06-12 15:36:41 | train] - Train Epoch: [172] [704000/1281167 (55%)]	Loss: 0.807739
[2022-06-12 15:37:01 | train] - Train Epoch: [172] [716800/1281167 (56%)]	Loss: 0.454042
[2022-06-12 15:37:21 | train] - Train Epoch: [172] [729600/1281167 (57%)]	Loss: 0.834137
[2022-06-12 15:37:41 | train] - Train Epoch: [172] [742400/1281167 (58%)]	Loss: 0.606908
[2022-06-12 15:38:01 | train] - Train Epoch: [172] [755200/1281167 (59%)]	Loss: 0.711139
[2022-06-12 15:38:20 | train] - Train Epoch: [172] [768000/1281167 (60%)]	Loss: 0.720942
[2022-06-12 15:38:40 | train] - Train Epoch: [172] [780800/1281167 (61%)]	Loss: 0.791833
[2022-06-12 15:38:59 | train] - Train Epoch: [172] [793600/1281167 (62%)]	Loss: 0.734674
[2022-06-12 15:39:19 | train] - Train Epoch: [172] [806400/1281167 (63%)]	Loss: 0.634522
[2022-06-12 15:39:39 | train] - Train Epoch: [172] [819200/1281167 (64%)]	Loss: 0.626312
[2022-06-12 15:39:58 | train] - Train Epoch: [172] [832000/1281167 (65%)]	Loss: 0.700771
[2022-06-12 15:40:18 | train] - Train Epoch: [172] [844800/1281167 (66%)]	Loss: 0.754725
[2022-06-12 15:40:38 | train] - Train Epoch: [172] [857600/1281167 (67%)]	Loss: 0.536558
[2022-06-12 15:40:58 | train] - Train Epoch: [172] [870400/1281167 (68%)]	Loss: 0.639477
[2022-06-12 15:41:19 | train] - Train Epoch: [172] [883200/1281167 (69%)]	Loss: 0.760798
[2022-06-12 15:41:38 | train] - Train Epoch: [172] [896000/1281167 (70%)]	Loss: 0.527825
[2022-06-12 15:41:58 | train] - Train Epoch: [172] [908800/1281167 (71%)]	Loss: 0.624604
[2022-06-12 15:42:19 | train] - Train Epoch: [172] [921600/1281167 (72%)]	Loss: 0.888351
[2022-06-12 15:42:39 | train] - Train Epoch: [172] [934400/1281167 (73%)]	Loss: 0.870533
[2022-06-12 15:42:59 | train] - Train Epoch: [172] [947200/1281167 (74%)]	Loss: 0.716532
[2022-06-12 15:43:19 | train] - Train Epoch: [172] [960000/1281167 (75%)]	Loss: 0.726710
[2022-06-12 15:43:39 | train] - Train Epoch: [172] [972800/1281167 (76%)]	Loss: 0.777362
[2022-06-12 15:44:00 | train] - Train Epoch: [172] [985600/1281167 (77%)]	Loss: 0.657753
[2022-06-12 15:44:20 | train] - Train Epoch: [172] [998400/1281167 (78%)]	Loss: 0.731509
[2022-06-12 15:44:39 | train] - Train Epoch: [172] [1011200/1281167 (79%)]	Loss: 0.925211
[2022-06-12 15:45:00 | train] - Train Epoch: [172] [1024000/1281167 (80%)]	Loss: 0.557469
[2022-06-12 15:45:20 | train] - Train Epoch: [172] [1036800/1281167 (81%)]	Loss: 0.889301
[2022-06-12 15:45:41 | train] - Train Epoch: [172] [1049600/1281167 (82%)]	Loss: 0.676702
[2022-06-12 15:46:01 | train] - Train Epoch: [172] [1062400/1281167 (83%)]	Loss: 0.691819
[2022-06-12 15:46:21 | train] - Train Epoch: [172] [1075200/1281167 (84%)]	Loss: 0.849942
[2022-06-12 15:46:41 | train] - Train Epoch: [172] [1088000/1281167 (85%)]	Loss: 0.699395
[2022-06-12 15:47:01 | train] - Train Epoch: [172] [1100800/1281167 (86%)]	Loss: 0.614812
[2022-06-12 15:47:22 | train] - Train Epoch: [172] [1113600/1281167 (87%)]	Loss: 0.687613
[2022-06-12 15:47:43 | train] - Train Epoch: [172] [1126400/1281167 (88%)]	Loss: 0.601143
[2022-06-12 15:48:03 | train] - Train Epoch: [172] [1139200/1281167 (89%)]	Loss: 0.627259
[2022-06-12 15:48:22 | train] - Train Epoch: [172] [1152000/1281167 (90%)]	Loss: 0.823829
[2022-06-12 15:48:42 | train] - Train Epoch: [172] [1164800/1281167 (91%)]	Loss: 0.719086
[2022-06-12 15:49:03 | train] - Train Epoch: [172] [1177600/1281167 (92%)]	Loss: 0.907167
[2022-06-12 15:49:23 | train] - Train Epoch: [172] [1190400/1281167 (93%)]	Loss: 1.077897
[2022-06-12 15:49:43 | train] - Train Epoch: [172] [1203200/1281167 (94%)]	Loss: 0.579614
[2022-06-12 15:50:04 | train] - Train Epoch: [172] [1216000/1281167 (95%)]	Loss: 0.738772
[2022-06-12 15:50:24 | train] - Train Epoch: [172] [1228800/1281167 (96%)]	Loss: 0.778741
[2022-06-12 15:50:44 | train] - Train Epoch: [172] [1241600/1281167 (97%)]	Loss: 0.724777
[2022-06-12 15:51:04 | train] - Train Epoch: [172] [1254400/1281167 (98%)]	Loss: 0.975441
[2022-06-12 15:51:24 | train] - Train Epoch: [172] [1267200/1281167 (99%)]	Loss: 0.772959
[2022-06-12 15:51:44 | train] - Train Epoch: [172] [1280000/1281167 (100%)]	Loss: 0.952968
[2022-06-12 15:51:46 | train] - Train Epoch: [172]	 Average Loss: 0.727670	 Total Acc : 82.3351	 Total Top5 Acc : 93.5824
[2022-06-12 15:51:46 | train] - -------172 epoch end-----------
========================================
-------172 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 15:53:16 | train] - 
Epoch [172] Test set: Average loss: 1.4239, Accuracy: 34941/50000 (69.8557%), Top-5 Accuracy: 88.9522%

[2022-06-12 15:53:16 | train] - save intermediate epoch [172] result


[2022-06-12 15:53:34 | train] - -------173 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 15:53:36 | train] - Train Epoch: [173] [0/1281167 (0%)]	Loss: 0.921645
[2022-06-12 15:53:57 | train] - Train Epoch: [173] [12800/1281167 (1%)]	Loss: 0.688986
[2022-06-12 15:54:17 | train] - Train Epoch: [173] [25600/1281167 (2%)]	Loss: 0.930693
[2022-06-12 15:54:38 | train] - Train Epoch: [173] [38400/1281167 (3%)]	Loss: 0.562404
[2022-06-12 15:54:58 | train] - Train Epoch: [173] [51200/1281167 (4%)]	Loss: 0.725533
[2022-06-12 15:55:18 | train] - Train Epoch: [173] [64000/1281167 (5%)]	Loss: 0.642077
[2022-06-12 15:55:38 | train] - Train Epoch: [173] [76800/1281167 (6%)]	Loss: 0.705642
[2022-06-12 15:55:59 | train] - Train Epoch: [173] [89600/1281167 (7%)]	Loss: 0.656875
[2022-06-12 15:56:19 | train] - Train Epoch: [173] [102400/1281167 (8%)]	Loss: 0.935541
[2022-06-12 15:56:38 | train] - Train Epoch: [173] [115200/1281167 (9%)]	Loss: 0.586504
[2022-06-12 15:56:59 | train] - Train Epoch: [173] [128000/1281167 (10%)]	Loss: 0.964508
[2022-06-12 15:57:19 | train] - Train Epoch: [173] [140800/1281167 (11%)]	Loss: 0.450052
[2022-06-12 15:57:39 | train] - Train Epoch: [173] [153600/1281167 (12%)]	Loss: 0.614699
[2022-06-12 15:57:59 | train] - Train Epoch: [173] [166400/1281167 (13%)]	Loss: 0.705989
[2022-06-12 15:58:19 | train] - Train Epoch: [173] [179200/1281167 (14%)]	Loss: 0.916780
[2022-06-12 15:58:40 | train] - Train Epoch: [173] [192000/1281167 (15%)]	Loss: 0.772423
[2022-06-12 15:59:00 | train] - Train Epoch: [173] [204800/1281167 (16%)]	Loss: 1.004594
[2022-06-12 15:59:21 | train] - Train Epoch: [173] [217600/1281167 (17%)]	Loss: 0.619059
[2022-06-12 15:59:41 | train] - Train Epoch: [173] [230400/1281167 (18%)]	Loss: 0.693330
[2022-06-12 16:00:02 | train] - Train Epoch: [173] [243200/1281167 (19%)]	Loss: 0.680921
[2022-06-12 16:00:22 | train] - Train Epoch: [173] [256000/1281167 (20%)]	Loss: 0.633758
[2022-06-12 16:00:42 | train] - Train Epoch: [173] [268800/1281167 (21%)]	Loss: 0.707155
[2022-06-12 16:01:03 | train] - Train Epoch: [173] [281600/1281167 (22%)]	Loss: 0.688565
[2022-06-12 16:01:24 | train] - Train Epoch: [173] [294400/1281167 (23%)]	Loss: 0.516649
[2022-06-12 16:01:44 | train] - Train Epoch: [173] [307200/1281167 (24%)]	Loss: 0.799570
[2022-06-12 16:02:04 | train] - Train Epoch: [173] [320000/1281167 (25%)]	Loss: 0.817654
[2022-06-12 16:02:25 | train] - Train Epoch: [173] [332800/1281167 (26%)]	Loss: 0.922295
[2022-06-12 16:02:46 | train] - Train Epoch: [173] [345600/1281167 (27%)]	Loss: 0.433469
[2022-06-12 16:03:06 | train] - Train Epoch: [173] [358400/1281167 (28%)]	Loss: 0.904414
[2022-06-12 16:03:27 | train] - Train Epoch: [173] [371200/1281167 (29%)]	Loss: 0.736574
[2022-06-12 16:03:47 | train] - Train Epoch: [173] [384000/1281167 (30%)]	Loss: 0.818568
[2022-06-12 16:04:07 | train] - Train Epoch: [173] [396800/1281167 (31%)]	Loss: 0.764159
[2022-06-12 16:04:27 | train] - Train Epoch: [173] [409600/1281167 (32%)]	Loss: 0.817168
[2022-06-12 16:04:47 | train] - Train Epoch: [173] [422400/1281167 (33%)]	Loss: 0.718296
[2022-06-12 16:05:09 | train] - Train Epoch: [173] [435200/1281167 (34%)]	Loss: 0.707374
[2022-06-12 16:05:28 | train] - Train Epoch: [173] [448000/1281167 (35%)]	Loss: 0.830474
[2022-06-12 16:05:49 | train] - Train Epoch: [173] [460800/1281167 (36%)]	Loss: 0.794907
[2022-06-12 16:06:09 | train] - Train Epoch: [173] [473600/1281167 (37%)]	Loss: 0.462529
[2022-06-12 16:06:28 | train] - Train Epoch: [173] [486400/1281167 (38%)]	Loss: 0.818868
[2022-06-12 16:06:49 | train] - Train Epoch: [173] [499200/1281167 (39%)]	Loss: 0.642193
[2022-06-12 16:07:09 | train] - Train Epoch: [173] [512000/1281167 (40%)]	Loss: 0.624545
[2022-06-12 16:07:29 | train] - Train Epoch: [173] [524800/1281167 (41%)]	Loss: 0.577700
[2022-06-12 16:07:49 | train] - Train Epoch: [173] [537600/1281167 (42%)]	Loss: 0.787655
[2022-06-12 16:08:10 | train] - Train Epoch: [173] [550400/1281167 (43%)]	Loss: 0.867889
[2022-06-12 16:08:30 | train] - Train Epoch: [173] [563200/1281167 (44%)]	Loss: 0.794475
[2022-06-12 16:08:51 | train] - Train Epoch: [173] [576000/1281167 (45%)]	Loss: 0.682211
[2022-06-12 16:09:10 | train] - Train Epoch: [173] [588800/1281167 (46%)]	Loss: 0.675323
[2022-06-12 16:09:31 | train] - Train Epoch: [173] [601600/1281167 (47%)]	Loss: 0.697654
[2022-06-12 16:09:52 | train] - Train Epoch: [173] [614400/1281167 (48%)]	Loss: 0.803328
[2022-06-12 16:10:12 | train] - Train Epoch: [173] [627200/1281167 (49%)]	Loss: 0.722865
[2022-06-12 16:10:33 | train] - Train Epoch: [173] [640000/1281167 (50%)]	Loss: 0.731477
[2022-06-12 16:10:53 | train] - Train Epoch: [173] [652800/1281167 (51%)]	Loss: 0.868991
[2022-06-12 16:11:13 | train] - Train Epoch: [173] [665600/1281167 (52%)]	Loss: 0.687298
[2022-06-12 16:11:33 | train] - Train Epoch: [173] [678400/1281167 (53%)]	Loss: 0.544813
[2022-06-12 16:11:53 | train] - Train Epoch: [173] [691200/1281167 (54%)]	Loss: 0.781211
[2022-06-12 16:12:13 | train] - Train Epoch: [173] [704000/1281167 (55%)]	Loss: 0.775108
[2022-06-12 16:12:34 | train] - Train Epoch: [173] [716800/1281167 (56%)]	Loss: 0.564893
[2022-06-12 16:12:54 | train] - Train Epoch: [173] [729600/1281167 (57%)]	Loss: 0.759259
[2022-06-12 16:13:14 | train] - Train Epoch: [173] [742400/1281167 (58%)]	Loss: 0.601823
[2022-06-12 16:13:35 | train] - Train Epoch: [173] [755200/1281167 (59%)]	Loss: 0.738508
[2022-06-12 16:13:56 | train] - Train Epoch: [173] [768000/1281167 (60%)]	Loss: 0.551007
[2022-06-12 16:14:16 | train] - Train Epoch: [173] [780800/1281167 (61%)]	Loss: 0.833055
[2022-06-12 16:14:36 | train] - Train Epoch: [173] [793600/1281167 (62%)]	Loss: 0.687111
[2022-06-12 16:14:57 | train] - Train Epoch: [173] [806400/1281167 (63%)]	Loss: 0.722861
[2022-06-12 16:15:17 | train] - Train Epoch: [173] [819200/1281167 (64%)]	Loss: 0.482638
[2022-06-12 16:15:37 | train] - Train Epoch: [173] [832000/1281167 (65%)]	Loss: 0.614980
[2022-06-12 16:15:57 | train] - Train Epoch: [173] [844800/1281167 (66%)]	Loss: 0.858598
[2022-06-12 16:16:17 | train] - Train Epoch: [173] [857600/1281167 (67%)]	Loss: 0.765818
[2022-06-12 16:16:38 | train] - Train Epoch: [173] [870400/1281167 (68%)]	Loss: 0.623440
[2022-06-12 16:16:59 | train] - Train Epoch: [173] [883200/1281167 (69%)]	Loss: 0.685406
[2022-06-12 16:17:19 | train] - Train Epoch: [173] [896000/1281167 (70%)]	Loss: 0.611999
[2022-06-12 16:17:40 | train] - Train Epoch: [173] [908800/1281167 (71%)]	Loss: 0.627351
[2022-06-12 16:18:00 | train] - Train Epoch: [173] [921600/1281167 (72%)]	Loss: 0.735449
[2022-06-12 16:18:20 | train] - Train Epoch: [173] [934400/1281167 (73%)]	Loss: 0.822290
[2022-06-12 16:18:41 | train] - Train Epoch: [173] [947200/1281167 (74%)]	Loss: 0.854862
[2022-06-12 16:19:02 | train] - Train Epoch: [173] [960000/1281167 (75%)]	Loss: 0.914992
[2022-06-12 16:19:22 | train] - Train Epoch: [173] [972800/1281167 (76%)]	Loss: 1.056502
[2022-06-12 16:19:42 | train] - Train Epoch: [173] [985600/1281167 (77%)]	Loss: 0.896224
[2022-06-12 16:20:02 | train] - Train Epoch: [173] [998400/1281167 (78%)]	Loss: 0.602942
[2022-06-12 16:20:24 | train] - Train Epoch: [173] [1011200/1281167 (79%)]	Loss: 0.879466
[2022-06-12 16:20:44 | train] - Train Epoch: [173] [1024000/1281167 (80%)]	Loss: 0.826300
[2022-06-12 16:21:05 | train] - Train Epoch: [173] [1036800/1281167 (81%)]	Loss: 0.791264
[2022-06-12 16:21:25 | train] - Train Epoch: [173] [1049600/1281167 (82%)]	Loss: 1.004285
[2022-06-12 16:21:46 | train] - Train Epoch: [173] [1062400/1281167 (83%)]	Loss: 0.677502
[2022-06-12 16:22:06 | train] - Train Epoch: [173] [1075200/1281167 (84%)]	Loss: 0.666225
[2022-06-12 16:22:26 | train] - Train Epoch: [173] [1088000/1281167 (85%)]	Loss: 0.639520
[2022-06-12 16:22:47 | train] - Train Epoch: [173] [1100800/1281167 (86%)]	Loss: 0.578464
[2022-06-12 16:23:07 | train] - Train Epoch: [173] [1113600/1281167 (87%)]	Loss: 0.709693
[2022-06-12 16:23:27 | train] - Train Epoch: [173] [1126400/1281167 (88%)]	Loss: 0.735240
[2022-06-12 16:23:46 | train] - Train Epoch: [173] [1139200/1281167 (89%)]	Loss: 0.495668
[2022-06-12 16:24:06 | train] - Train Epoch: [173] [1152000/1281167 (90%)]	Loss: 0.528662
[2022-06-12 16:24:26 | train] - Train Epoch: [173] [1164800/1281167 (91%)]	Loss: 0.591827
[2022-06-12 16:24:46 | train] - Train Epoch: [173] [1177600/1281167 (92%)]	Loss: 0.882796
[2022-06-12 16:25:07 | train] - Train Epoch: [173] [1190400/1281167 (93%)]	Loss: 0.587847
[2022-06-12 16:25:26 | train] - Train Epoch: [173] [1203200/1281167 (94%)]	Loss: 0.708691
[2022-06-12 16:25:47 | train] - Train Epoch: [173] [1216000/1281167 (95%)]	Loss: 0.743661
[2022-06-12 16:26:08 | train] - Train Epoch: [173] [1228800/1281167 (96%)]	Loss: 0.640581
[2022-06-12 16:26:28 | train] - Train Epoch: [173] [1241600/1281167 (97%)]	Loss: 0.799231
[2022-06-12 16:26:48 | train] - Train Epoch: [173] [1254400/1281167 (98%)]	Loss: 0.726978
[2022-06-12 16:27:09 | train] - Train Epoch: [173] [1267200/1281167 (99%)]	Loss: 0.906650
[2022-06-12 16:27:29 | train] - Train Epoch: [173] [1280000/1281167 (100%)]	Loss: 0.640216
[2022-06-12 16:27:31 | train] - Train Epoch: [173]	 Average Loss: 0.728698	 Total Acc : 82.2933	 Total Top5 Acc : 93.5262
[2022-06-12 16:27:31 | train] - -------173 epoch end-----------
========================================
-------173 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 16:29:04 | train] - 
Epoch [173] Test set: Average loss: 1.4274, Accuracy: 34929/50000 (69.8306%), Top-5 Accuracy: 88.8775%

[2022-06-12 16:29:04 | train] - save intermediate epoch [173] result


[2022-06-12 16:29:24 | train] - -------174 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 16:29:26 | train] - Train Epoch: [174] [0/1281167 (0%)]	Loss: 0.939990
[2022-06-12 16:29:47 | train] - Train Epoch: [174] [12800/1281167 (1%)]	Loss: 0.680594
[2022-06-12 16:30:08 | train] - Train Epoch: [174] [25600/1281167 (2%)]	Loss: 0.422353
[2022-06-12 16:30:28 | train] - Train Epoch: [174] [38400/1281167 (3%)]	Loss: 0.870892
[2022-06-12 16:30:48 | train] - Train Epoch: [174] [51200/1281167 (4%)]	Loss: 0.741210
[2022-06-12 16:31:09 | train] - Train Epoch: [174] [64000/1281167 (5%)]	Loss: 0.787674
[2022-06-12 16:31:30 | train] - Train Epoch: [174] [76800/1281167 (6%)]	Loss: 0.704872
[2022-06-12 16:31:51 | train] - Train Epoch: [174] [89600/1281167 (7%)]	Loss: 0.950151
[2022-06-12 16:32:12 | train] - Train Epoch: [174] [102400/1281167 (8%)]	Loss: 0.688747
[2022-06-12 16:32:33 | train] - Train Epoch: [174] [115200/1281167 (9%)]	Loss: 0.686419
[2022-06-12 16:32:55 | train] - Train Epoch: [174] [128000/1281167 (10%)]	Loss: 0.939786
[2022-06-12 16:33:16 | train] - Train Epoch: [174] [140800/1281167 (11%)]	Loss: 0.798916
[2022-06-12 16:33:38 | train] - Train Epoch: [174] [153600/1281167 (12%)]	Loss: 0.896019
[2022-06-12 16:34:00 | train] - Train Epoch: [174] [166400/1281167 (13%)]	Loss: 0.536524
[2022-06-12 16:34:21 | train] - Train Epoch: [174] [179200/1281167 (14%)]	Loss: 0.744937
[2022-06-12 16:34:43 | train] - Train Epoch: [174] [192000/1281167 (15%)]	Loss: 0.633477
[2022-06-12 16:35:04 | train] - Train Epoch: [174] [204800/1281167 (16%)]	Loss: 0.558803
[2022-06-12 16:35:26 | train] - Train Epoch: [174] [217600/1281167 (17%)]	Loss: 0.822314
[2022-06-12 16:35:47 | train] - Train Epoch: [174] [230400/1281167 (18%)]	Loss: 0.594392
[2022-06-12 16:36:08 | train] - Train Epoch: [174] [243200/1281167 (19%)]	Loss: 0.545074
[2022-06-12 16:36:30 | train] - Train Epoch: [174] [256000/1281167 (20%)]	Loss: 0.652842
[2022-06-12 16:36:50 | train] - Train Epoch: [174] [268800/1281167 (21%)]	Loss: 0.499907
[2022-06-12 16:37:12 | train] - Train Epoch: [174] [281600/1281167 (22%)]	Loss: 0.833173
[2022-06-12 16:37:33 | train] - Train Epoch: [174] [294400/1281167 (23%)]	Loss: 0.796771
[2022-06-12 16:37:54 | train] - Train Epoch: [174] [307200/1281167 (24%)]	Loss: 1.053582
[2022-06-12 16:38:15 | train] - Train Epoch: [174] [320000/1281167 (25%)]	Loss: 0.643032
[2022-06-12 16:38:37 | train] - Train Epoch: [174] [332800/1281167 (26%)]	Loss: 0.650366
[2022-06-12 16:38:58 | train] - Train Epoch: [174] [345600/1281167 (27%)]	Loss: 0.689369
[2022-06-12 16:39:18 | train] - Train Epoch: [174] [358400/1281167 (28%)]	Loss: 0.664835
[2022-06-12 16:39:38 | train] - Train Epoch: [174] [371200/1281167 (29%)]	Loss: 0.935675
[2022-06-12 16:39:59 | train] - Train Epoch: [174] [384000/1281167 (30%)]	Loss: 0.638062
[2022-06-12 16:40:21 | train] - Train Epoch: [174] [396800/1281167 (31%)]	Loss: 0.539689
[2022-06-12 16:40:43 | train] - Train Epoch: [174] [409600/1281167 (32%)]	Loss: 0.599408
[2022-06-12 16:41:04 | train] - Train Epoch: [174] [422400/1281167 (33%)]	Loss: 0.855679
[2022-06-12 16:41:24 | train] - Train Epoch: [174] [435200/1281167 (34%)]	Loss: 0.776354
[2022-06-12 16:41:46 | train] - Train Epoch: [174] [448000/1281167 (35%)]	Loss: 0.782262
[2022-06-12 16:42:07 | train] - Train Epoch: [174] [460800/1281167 (36%)]	Loss: 0.838925
[2022-06-12 16:42:29 | train] - Train Epoch: [174] [473600/1281167 (37%)]	Loss: 0.688534
[2022-06-12 16:42:50 | train] - Train Epoch: [174] [486400/1281167 (38%)]	Loss: 0.835208
[2022-06-12 16:43:10 | train] - Train Epoch: [174] [499200/1281167 (39%)]	Loss: 0.739986
[2022-06-12 16:43:32 | train] - Train Epoch: [174] [512000/1281167 (40%)]	Loss: 0.694057
[2022-06-12 16:43:52 | train] - Train Epoch: [174] [524800/1281167 (41%)]	Loss: 0.770200
[2022-06-12 16:44:13 | train] - Train Epoch: [174] [537600/1281167 (42%)]	Loss: 0.773849
[2022-06-12 16:44:33 | train] - Train Epoch: [174] [550400/1281167 (43%)]	Loss: 0.890691
[2022-06-12 16:44:54 | train] - Train Epoch: [174] [563200/1281167 (44%)]	Loss: 0.556169
[2022-06-12 16:45:16 | train] - Train Epoch: [174] [576000/1281167 (45%)]	Loss: 0.669494
[2022-06-12 16:45:38 | train] - Train Epoch: [174] [588800/1281167 (46%)]	Loss: 0.794196
[2022-06-12 16:45:58 | train] - Train Epoch: [174] [601600/1281167 (47%)]	Loss: 0.988668
[2022-06-12 16:46:20 | train] - Train Epoch: [174] [614400/1281167 (48%)]	Loss: 0.757768
[2022-06-12 16:46:41 | train] - Train Epoch: [174] [627200/1281167 (49%)]	Loss: 0.766971
[2022-06-12 16:47:02 | train] - Train Epoch: [174] [640000/1281167 (50%)]	Loss: 0.719708
[2022-06-12 16:47:23 | train] - Train Epoch: [174] [652800/1281167 (51%)]	Loss: 0.646480
[2022-06-12 16:47:45 | train] - Train Epoch: [174] [665600/1281167 (52%)]	Loss: 0.760478
[2022-06-12 16:48:06 | train] - Train Epoch: [174] [678400/1281167 (53%)]	Loss: 0.585975
[2022-06-12 16:48:27 | train] - Train Epoch: [174] [691200/1281167 (54%)]	Loss: 0.505788
[2022-06-12 16:48:48 | train] - Train Epoch: [174] [704000/1281167 (55%)]	Loss: 0.564232
[2022-06-12 16:49:08 | train] - Train Epoch: [174] [716800/1281167 (56%)]	Loss: 0.665398
[2022-06-12 16:49:28 | train] - Train Epoch: [174] [729600/1281167 (57%)]	Loss: 0.759746
[2022-06-12 16:49:50 | train] - Train Epoch: [174] [742400/1281167 (58%)]	Loss: 0.596275
[2022-06-12 16:50:10 | train] - Train Epoch: [174] [755200/1281167 (59%)]	Loss: 0.604266
[2022-06-12 16:50:30 | train] - Train Epoch: [174] [768000/1281167 (60%)]	Loss: 0.826644
[2022-06-12 16:50:50 | train] - Train Epoch: [174] [780800/1281167 (61%)]	Loss: 0.699167
[2022-06-12 16:51:10 | train] - Train Epoch: [174] [793600/1281167 (62%)]	Loss: 0.674889
[2022-06-12 16:51:32 | train] - Train Epoch: [174] [806400/1281167 (63%)]	Loss: 0.637407
[2022-06-12 16:51:53 | train] - Train Epoch: [174] [819200/1281167 (64%)]	Loss: 0.894383
[2022-06-12 16:52:14 | train] - Train Epoch: [174] [832000/1281167 (65%)]	Loss: 0.704259
[2022-06-12 16:52:35 | train] - Train Epoch: [174] [844800/1281167 (66%)]	Loss: 0.798437
[2022-06-12 16:52:55 | train] - Train Epoch: [174] [857600/1281167 (67%)]	Loss: 0.980813
[2022-06-12 16:53:16 | train] - Train Epoch: [174] [870400/1281167 (68%)]	Loss: 0.666423
[2022-06-12 16:53:37 | train] - Train Epoch: [174] [883200/1281167 (69%)]	Loss: 0.673238
[2022-06-12 16:53:59 | train] - Train Epoch: [174] [896000/1281167 (70%)]	Loss: 0.786886
[2022-06-12 16:54:20 | train] - Train Epoch: [174] [908800/1281167 (71%)]	Loss: 0.530690
[2022-06-12 16:54:41 | train] - Train Epoch: [174] [921600/1281167 (72%)]	Loss: 0.495587
[2022-06-12 16:55:02 | train] - Train Epoch: [174] [934400/1281167 (73%)]	Loss: 0.740430
[2022-06-12 16:55:23 | train] - Train Epoch: [174] [947200/1281167 (74%)]	Loss: 0.588880
[2022-06-12 16:55:44 | train] - Train Epoch: [174] [960000/1281167 (75%)]	Loss: 0.551441
[2022-06-12 16:56:06 | train] - Train Epoch: [174] [972800/1281167 (76%)]	Loss: 0.486722
[2022-06-12 16:56:27 | train] - Train Epoch: [174] [985600/1281167 (77%)]	Loss: 0.958509
[2022-06-12 16:56:49 | train] - Train Epoch: [174] [998400/1281167 (78%)]	Loss: 0.554310
[2022-06-12 16:57:10 | train] - Train Epoch: [174] [1011200/1281167 (79%)]	Loss: 0.770961
[2022-06-12 16:57:31 | train] - Train Epoch: [174] [1024000/1281167 (80%)]	Loss: 0.993878
[2022-06-12 16:57:52 | train] - Train Epoch: [174] [1036800/1281167 (81%)]	Loss: 0.627385
[2022-06-12 16:58:13 | train] - Train Epoch: [174] [1049600/1281167 (82%)]	Loss: 0.792542
[2022-06-12 16:58:35 | train] - Train Epoch: [174] [1062400/1281167 (83%)]	Loss: 0.853362
[2022-06-12 16:58:57 | train] - Train Epoch: [174] [1075200/1281167 (84%)]	Loss: 0.578289
[2022-06-12 16:59:18 | train] - Train Epoch: [174] [1088000/1281167 (85%)]	Loss: 0.596245
[2022-06-12 16:59:39 | train] - Train Epoch: [174] [1100800/1281167 (86%)]	Loss: 0.674530
[2022-06-12 17:00:00 | train] - Train Epoch: [174] [1113600/1281167 (87%)]	Loss: 0.574034
[2022-06-12 17:00:21 | train] - Train Epoch: [174] [1126400/1281167 (88%)]	Loss: 1.109641
[2022-06-12 17:00:42 | train] - Train Epoch: [174] [1139200/1281167 (89%)]	Loss: 0.559467
[2022-06-12 17:01:03 | train] - Train Epoch: [174] [1152000/1281167 (90%)]	Loss: 0.778278
[2022-06-12 17:01:24 | train] - Train Epoch: [174] [1164800/1281167 (91%)]	Loss: 0.923160
[2022-06-12 17:01:46 | train] - Train Epoch: [174] [1177600/1281167 (92%)]	Loss: 0.601649
[2022-06-12 17:02:08 | train] - Train Epoch: [174] [1190400/1281167 (93%)]	Loss: 0.775463
[2022-06-12 17:02:29 | train] - Train Epoch: [174] [1203200/1281167 (94%)]	Loss: 0.931051
[2022-06-12 17:02:50 | train] - Train Epoch: [174] [1216000/1281167 (95%)]	Loss: 0.591295
[2022-06-12 17:03:11 | train] - Train Epoch: [174] [1228800/1281167 (96%)]	Loss: 0.812398
[2022-06-12 17:03:31 | train] - Train Epoch: [174] [1241600/1281167 (97%)]	Loss: 0.613591
[2022-06-12 17:03:53 | train] - Train Epoch: [174] [1254400/1281167 (98%)]	Loss: 0.963475
[2022-06-12 17:04:14 | train] - Train Epoch: [174] [1267200/1281167 (99%)]	Loss: 1.038023
[2022-06-12 17:04:34 | train] - Train Epoch: [174] [1280000/1281167 (100%)]	Loss: 0.787896
[2022-06-12 17:04:36 | train] - Train Epoch: [174]	 Average Loss: 0.728061	 Total Acc : 82.2989	 Total Top5 Acc : 93.5759
[2022-06-12 17:04:36 | train] - -------174 epoch end-----------
========================================
-------174 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 17:06:07 | train] - 
Epoch [174] Test set: Average loss: 1.4321, Accuracy: 35040/50000 (70.0524%), Top-5 Accuracy: 88.9762%

[2022-06-12 17:06:07 | train] - save intermediate epoch [174] result


[2022-06-12 17:06:24 | train] - logging best performance 174 epoch
[2022-06-12 17:06:26 | train] - -------175 epoch start-----------
========================================
----- test end -------------------------


logging best performance 174 epoch
[2022-06-12 17:06:27 | train] - Train Epoch: [175] [0/1281167 (0%)]	Loss: 0.697603
[2022-06-12 17:06:48 | train] - Train Epoch: [175] [12800/1281167 (1%)]	Loss: 0.722493
[2022-06-12 17:07:08 | train] - Train Epoch: [175] [25600/1281167 (2%)]	Loss: 0.528955
[2022-06-12 17:07:28 | train] - Train Epoch: [175] [38400/1281167 (3%)]	Loss: 0.735780
[2022-06-12 17:07:48 | train] - Train Epoch: [175] [51200/1281167 (4%)]	Loss: 0.994393
[2022-06-12 17:08:08 | train] - Train Epoch: [175] [64000/1281167 (5%)]	Loss: 0.912583
[2022-06-12 17:08:28 | train] - Train Epoch: [175] [76800/1281167 (6%)]	Loss: 0.354134
[2022-06-12 17:08:50 | train] - Train Epoch: [175] [89600/1281167 (7%)]	Loss: 1.062964
[2022-06-12 17:09:11 | train] - Train Epoch: [175] [102400/1281167 (8%)]	Loss: 0.727477
[2022-06-12 17:09:31 | train] - Train Epoch: [175] [115200/1281167 (9%)]	Loss: 0.675503
[2022-06-12 17:09:51 | train] - Train Epoch: [175] [128000/1281167 (10%)]	Loss: 0.670716
[2022-06-12 17:10:12 | train] - Train Epoch: [175] [140800/1281167 (11%)]	Loss: 0.805545
[2022-06-12 17:10:33 | train] - Train Epoch: [175] [153600/1281167 (12%)]	Loss: 0.675443
[2022-06-12 17:10:53 | train] - Train Epoch: [175] [166400/1281167 (13%)]	Loss: 0.826970
[2022-06-12 17:11:13 | train] - Train Epoch: [175] [179200/1281167 (14%)]	Loss: 0.722383
[2022-06-12 17:11:34 | train] - Train Epoch: [175] [192000/1281167 (15%)]	Loss: 0.719695
[2022-06-12 17:11:55 | train] - Train Epoch: [175] [204800/1281167 (16%)]	Loss: 0.715626
[2022-06-12 17:12:16 | train] - Train Epoch: [175] [217600/1281167 (17%)]	Loss: 0.743504
[2022-06-12 17:12:37 | train] - Train Epoch: [175] [230400/1281167 (18%)]	Loss: 0.822917
[2022-06-12 17:12:58 | train] - Train Epoch: [175] [243200/1281167 (19%)]	Loss: 0.944819
[2022-06-12 17:13:19 | train] - Train Epoch: [175] [256000/1281167 (20%)]	Loss: 0.736003
[2022-06-12 17:13:40 | train] - Train Epoch: [175] [268800/1281167 (21%)]	Loss: 0.672273
[2022-06-12 17:14:00 | train] - Train Epoch: [175] [281600/1281167 (22%)]	Loss: 0.884004
[2022-06-12 17:14:21 | train] - Train Epoch: [175] [294400/1281167 (23%)]	Loss: 0.822156
[2022-06-12 17:14:41 | train] - Train Epoch: [175] [307200/1281167 (24%)]	Loss: 0.694917
[2022-06-12 17:15:02 | train] - Train Epoch: [175] [320000/1281167 (25%)]	Loss: 0.797533
[2022-06-12 17:15:23 | train] - Train Epoch: [175] [332800/1281167 (26%)]	Loss: 0.682046
[2022-06-12 17:15:44 | train] - Train Epoch: [175] [345600/1281167 (27%)]	Loss: 0.547599
[2022-06-12 17:16:05 | train] - Train Epoch: [175] [358400/1281167 (28%)]	Loss: 0.607320
[2022-06-12 17:16:27 | train] - Train Epoch: [175] [371200/1281167 (29%)]	Loss: 0.742272
[2022-06-12 17:16:48 | train] - Train Epoch: [175] [384000/1281167 (30%)]	Loss: 0.593193
[2022-06-12 17:17:09 | train] - Train Epoch: [175] [396800/1281167 (31%)]	Loss: 0.808992
[2022-06-12 17:17:31 | train] - Train Epoch: [175] [409600/1281167 (32%)]	Loss: 0.840290
[2022-06-12 17:17:51 | train] - Train Epoch: [175] [422400/1281167 (33%)]	Loss: 1.183159
[2022-06-12 17:18:13 | train] - Train Epoch: [175] [435200/1281167 (34%)]	Loss: 0.817499
[2022-06-12 17:18:33 | train] - Train Epoch: [175] [448000/1281167 (35%)]	Loss: 0.732559
[2022-06-12 17:18:52 | train] - Train Epoch: [175] [460800/1281167 (36%)]	Loss: 0.756113
[2022-06-12 17:19:12 | train] - Train Epoch: [175] [473600/1281167 (37%)]	Loss: 0.784256
[2022-06-12 17:19:34 | train] - Train Epoch: [175] [486400/1281167 (38%)]	Loss: 0.486919
[2022-06-12 17:19:55 | train] - Train Epoch: [175] [499200/1281167 (39%)]	Loss: 0.973092
[2022-06-12 17:20:16 | train] - Train Epoch: [175] [512000/1281167 (40%)]	Loss: 0.811195
[2022-06-12 17:20:36 | train] - Train Epoch: [175] [524800/1281167 (41%)]	Loss: 0.826863
[2022-06-12 17:20:57 | train] - Train Epoch: [175] [537600/1281167 (42%)]	Loss: 0.646405
[2022-06-12 17:21:19 | train] - Train Epoch: [175] [550400/1281167 (43%)]	Loss: 0.441373
[2022-06-12 17:21:39 | train] - Train Epoch: [175] [563200/1281167 (44%)]	Loss: 0.831201
[2022-06-12 17:22:00 | train] - Train Epoch: [175] [576000/1281167 (45%)]	Loss: 0.566040
[2022-06-12 17:22:22 | train] - Train Epoch: [175] [588800/1281167 (46%)]	Loss: 0.738183
[2022-06-12 17:22:43 | train] - Train Epoch: [175] [601600/1281167 (47%)]	Loss: 0.862660
[2022-06-12 17:23:04 | train] - Train Epoch: [175] [614400/1281167 (48%)]	Loss: 0.626287
[2022-06-12 17:23:25 | train] - Train Epoch: [175] [627200/1281167 (49%)]	Loss: 0.860245
[2022-06-12 17:23:46 | train] - Train Epoch: [175] [640000/1281167 (50%)]	Loss: 0.993863
[2022-06-12 17:24:06 | train] - Train Epoch: [175] [652800/1281167 (51%)]	Loss: 0.751611
[2022-06-12 17:24:28 | train] - Train Epoch: [175] [665600/1281167 (52%)]	Loss: 0.821520
[2022-06-12 17:24:49 | train] - Train Epoch: [175] [678400/1281167 (53%)]	Loss: 0.649531
[2022-06-12 17:25:10 | train] - Train Epoch: [175] [691200/1281167 (54%)]	Loss: 0.538572
[2022-06-12 17:25:31 | train] - Train Epoch: [175] [704000/1281167 (55%)]	Loss: 0.539144
[2022-06-12 17:25:53 | train] - Train Epoch: [175] [716800/1281167 (56%)]	Loss: 0.903745
[2022-06-12 17:26:14 | train] - Train Epoch: [175] [729600/1281167 (57%)]	Loss: 0.969852
[2022-06-12 17:26:35 | train] - Train Epoch: [175] [742400/1281167 (58%)]	Loss: 0.621008
[2022-06-12 17:26:57 | train] - Train Epoch: [175] [755200/1281167 (59%)]	Loss: 0.747603
[2022-06-12 17:27:18 | train] - Train Epoch: [175] [768000/1281167 (60%)]	Loss: 0.669998
[2022-06-12 17:27:39 | train] - Train Epoch: [175] [780800/1281167 (61%)]	Loss: 0.894972
[2022-06-12 17:28:01 | train] - Train Epoch: [175] [793600/1281167 (62%)]	Loss: 0.869191
[2022-06-12 17:28:21 | train] - Train Epoch: [175] [806400/1281167 (63%)]	Loss: 0.909574
[2022-06-12 17:28:43 | train] - Train Epoch: [175] [819200/1281167 (64%)]	Loss: 0.414212
[2022-06-12 17:29:04 | train] - Train Epoch: [175] [832000/1281167 (65%)]	Loss: 0.665628
[2022-06-12 17:29:25 | train] - Train Epoch: [175] [844800/1281167 (66%)]	Loss: 0.753519
[2022-06-12 17:29:46 | train] - Train Epoch: [175] [857600/1281167 (67%)]	Loss: 1.060249
[2022-06-12 17:30:07 | train] - Train Epoch: [175] [870400/1281167 (68%)]	Loss: 0.779184
[2022-06-12 17:30:29 | train] - Train Epoch: [175] [883200/1281167 (69%)]	Loss: 0.801794
[2022-06-12 17:30:49 | train] - Train Epoch: [175] [896000/1281167 (70%)]	Loss: 0.644876
[2022-06-12 17:31:10 | train] - Train Epoch: [175] [908800/1281167 (71%)]	Loss: 0.758083
[2022-06-12 17:31:32 | train] - Train Epoch: [175] [921600/1281167 (72%)]	Loss: 0.590086
[2022-06-12 17:31:53 | train] - Train Epoch: [175] [934400/1281167 (73%)]	Loss: 0.607812
[2022-06-12 17:32:15 | train] - Train Epoch: [175] [947200/1281167 (74%)]	Loss: 0.778994
[2022-06-12 17:32:36 | train] - Train Epoch: [175] [960000/1281167 (75%)]	Loss: 0.738335
[2022-06-12 17:32:57 | train] - Train Epoch: [175] [972800/1281167 (76%)]	Loss: 0.569563
[2022-06-12 17:33:18 | train] - Train Epoch: [175] [985600/1281167 (77%)]	Loss: 0.547434
[2022-06-12 17:33:39 | train] - Train Epoch: [175] [998400/1281167 (78%)]	Loss: 0.644470
[2022-06-12 17:34:00 | train] - Train Epoch: [175] [1011200/1281167 (79%)]	Loss: 0.678918
[2022-06-12 17:34:21 | train] - Train Epoch: [175] [1024000/1281167 (80%)]	Loss: 0.707703
[2022-06-12 17:34:42 | train] - Train Epoch: [175] [1036800/1281167 (81%)]	Loss: 0.697624
[2022-06-12 17:35:03 | train] - Train Epoch: [175] [1049600/1281167 (82%)]	Loss: 0.598572
[2022-06-12 17:35:24 | train] - Train Epoch: [175] [1062400/1281167 (83%)]	Loss: 0.566172
[2022-06-12 17:35:45 | train] - Train Epoch: [175] [1075200/1281167 (84%)]	Loss: 0.559366
[2022-06-12 17:36:06 | train] - Train Epoch: [175] [1088000/1281167 (85%)]	Loss: 0.713188
[2022-06-12 17:36:27 | train] - Train Epoch: [175] [1100800/1281167 (86%)]	Loss: 0.684636
[2022-06-12 17:36:49 | train] - Train Epoch: [175] [1113600/1281167 (87%)]	Loss: 0.633672
[2022-06-12 17:37:09 | train] - Train Epoch: [175] [1126400/1281167 (88%)]	Loss: 0.746198
[2022-06-12 17:37:30 | train] - Train Epoch: [175] [1139200/1281167 (89%)]	Loss: 0.793043
[2022-06-12 17:37:51 | train] - Train Epoch: [175] [1152000/1281167 (90%)]	Loss: 0.947451
[2022-06-12 17:38:13 | train] - Train Epoch: [175] [1164800/1281167 (91%)]	Loss: 0.543250
[2022-06-12 17:38:34 | train] - Train Epoch: [175] [1177600/1281167 (92%)]	Loss: 0.595883
[2022-06-12 17:38:55 | train] - Train Epoch: [175] [1190400/1281167 (93%)]	Loss: 0.554298
[2022-06-12 17:39:15 | train] - Train Epoch: [175] [1203200/1281167 (94%)]	Loss: 0.589978
[2022-06-12 17:39:36 | train] - Train Epoch: [175] [1216000/1281167 (95%)]	Loss: 0.617713
[2022-06-12 17:39:56 | train] - Train Epoch: [175] [1228800/1281167 (96%)]	Loss: 0.719940
[2022-06-12 17:40:16 | train] - Train Epoch: [175] [1241600/1281167 (97%)]	Loss: 0.636794
[2022-06-12 17:40:37 | train] - Train Epoch: [175] [1254400/1281167 (98%)]	Loss: 0.564088
[2022-06-12 17:40:58 | train] - Train Epoch: [175] [1267200/1281167 (99%)]	Loss: 0.596798
[2022-06-12 17:41:19 | train] - Train Epoch: [175] [1280000/1281167 (100%)]	Loss: 0.464908
[2022-06-12 17:41:21 | train] - Train Epoch: [175]	 Average Loss: 0.727970	 Total Acc : 82.3358	 Total Top5 Acc : 93.5680
[2022-06-12 17:41:21 | train] - -------175 epoch end-----------
========================================
-------175 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 17:42:56 | train] - 
Epoch [175] Test set: Average loss: 1.4273, Accuracy: 34878/50000 (69.7275%), Top-5 Accuracy: 88.8743%

[2022-06-12 17:42:56 | train] - save intermediate epoch [175] result


[2022-06-12 17:43:15 | train] - -------176 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 17:43:17 | train] - Train Epoch: [176] [0/1281167 (0%)]	Loss: 0.570070
[2022-06-12 17:43:39 | train] - Train Epoch: [176] [12800/1281167 (1%)]	Loss: 0.647473
[2022-06-12 17:44:00 | train] - Train Epoch: [176] [25600/1281167 (2%)]	Loss: 0.790006
[2022-06-12 17:44:21 | train] - Train Epoch: [176] [38400/1281167 (3%)]	Loss: 0.644371
[2022-06-12 17:44:43 | train] - Train Epoch: [176] [51200/1281167 (4%)]	Loss: 0.496771
[2022-06-12 17:45:04 | train] - Train Epoch: [176] [64000/1281167 (5%)]	Loss: 0.738598
[2022-06-12 17:45:25 | train] - Train Epoch: [176] [76800/1281167 (6%)]	Loss: 0.926131
[2022-06-12 17:45:47 | train] - Train Epoch: [176] [89600/1281167 (7%)]	Loss: 0.745179
[2022-06-12 17:46:09 | train] - Train Epoch: [176] [102400/1281167 (8%)]	Loss: 0.819361
[2022-06-12 17:46:30 | train] - Train Epoch: [176] [115200/1281167 (9%)]	Loss: 0.790093
[2022-06-12 17:46:51 | train] - Train Epoch: [176] [128000/1281167 (10%)]	Loss: 0.716508
[2022-06-12 17:47:12 | train] - Train Epoch: [176] [140800/1281167 (11%)]	Loss: 0.732175
[2022-06-12 17:47:33 | train] - Train Epoch: [176] [153600/1281167 (12%)]	Loss: 0.805071
[2022-06-12 17:47:54 | train] - Train Epoch: [176] [166400/1281167 (13%)]	Loss: 0.905040
[2022-06-12 17:48:16 | train] - Train Epoch: [176] [179200/1281167 (14%)]	Loss: 0.749099
[2022-06-12 17:48:37 | train] - Train Epoch: [176] [192000/1281167 (15%)]	Loss: 0.879047
[2022-06-12 17:48:57 | train] - Train Epoch: [176] [204800/1281167 (16%)]	Loss: 0.810456
[2022-06-12 17:49:18 | train] - Train Epoch: [176] [217600/1281167 (17%)]	Loss: 0.552882
[2022-06-12 17:49:39 | train] - Train Epoch: [176] [230400/1281167 (18%)]	Loss: 0.735807
[2022-06-12 17:50:00 | train] - Train Epoch: [176] [243200/1281167 (19%)]	Loss: 0.710291
[2022-06-12 17:50:21 | train] - Train Epoch: [176] [256000/1281167 (20%)]	Loss: 0.870541
[2022-06-12 17:50:43 | train] - Train Epoch: [176] [268800/1281167 (21%)]	Loss: 0.690682
[2022-06-12 17:51:04 | train] - Train Epoch: [176] [281600/1281167 (22%)]	Loss: 0.675155
[2022-06-12 17:51:25 | train] - Train Epoch: [176] [294400/1281167 (23%)]	Loss: 0.763231
[2022-06-12 17:51:45 | train] - Train Epoch: [176] [307200/1281167 (24%)]	Loss: 0.687981
[2022-06-12 17:52:06 | train] - Train Epoch: [176] [320000/1281167 (25%)]	Loss: 0.642226
[2022-06-12 17:52:27 | train] - Train Epoch: [176] [332800/1281167 (26%)]	Loss: 0.701383
[2022-06-12 17:52:48 | train] - Train Epoch: [176] [345600/1281167 (27%)]	Loss: 0.571296
[2022-06-12 17:53:09 | train] - Train Epoch: [176] [358400/1281167 (28%)]	Loss: 0.712896
[2022-06-12 17:53:31 | train] - Train Epoch: [176] [371200/1281167 (29%)]	Loss: 0.806227
[2022-06-12 17:53:52 | train] - Train Epoch: [176] [384000/1281167 (30%)]	Loss: 0.737904
[2022-06-12 17:54:13 | train] - Train Epoch: [176] [396800/1281167 (31%)]	Loss: 0.595443
[2022-06-12 17:54:34 | train] - Train Epoch: [176] [409600/1281167 (32%)]	Loss: 0.864187
[2022-06-12 17:54:56 | train] - Train Epoch: [176] [422400/1281167 (33%)]	Loss: 0.937634
[2022-06-12 17:55:17 | train] - Train Epoch: [176] [435200/1281167 (34%)]	Loss: 0.713363
[2022-06-12 17:55:38 | train] - Train Epoch: [176] [448000/1281167 (35%)]	Loss: 0.675615
[2022-06-12 17:55:59 | train] - Train Epoch: [176] [460800/1281167 (36%)]	Loss: 0.813367
[2022-06-12 17:56:20 | train] - Train Epoch: [176] [473600/1281167 (37%)]	Loss: 0.768890
[2022-06-12 17:56:42 | train] - Train Epoch: [176] [486400/1281167 (38%)]	Loss: 0.919885
[2022-06-12 17:57:03 | train] - Train Epoch: [176] [499200/1281167 (39%)]	Loss: 0.603663
[2022-06-12 17:57:23 | train] - Train Epoch: [176] [512000/1281167 (40%)]	Loss: 0.676077
[2022-06-12 17:57:45 | train] - Train Epoch: [176] [524800/1281167 (41%)]	Loss: 0.833912
[2022-06-12 17:58:07 | train] - Train Epoch: [176] [537600/1281167 (42%)]	Loss: 0.782926
[2022-06-12 17:58:28 | train] - Train Epoch: [176] [550400/1281167 (43%)]	Loss: 0.667315
[2022-06-12 17:58:49 | train] - Train Epoch: [176] [563200/1281167 (44%)]	Loss: 0.662331
[2022-06-12 17:59:10 | train] - Train Epoch: [176] [576000/1281167 (45%)]	Loss: 0.692751
[2022-06-12 17:59:32 | train] - Train Epoch: [176] [588800/1281167 (46%)]	Loss: 0.664758
[2022-06-12 17:59:54 | train] - Train Epoch: [176] [601600/1281167 (47%)]	Loss: 0.899952
[2022-06-12 18:00:15 | train] - Train Epoch: [176] [614400/1281167 (48%)]	Loss: 0.452817
[2022-06-12 18:00:36 | train] - Train Epoch: [176] [627200/1281167 (49%)]	Loss: 0.631491
[2022-06-12 18:00:57 | train] - Train Epoch: [176] [640000/1281167 (50%)]	Loss: 0.820133
[2022-06-12 18:01:19 | train] - Train Epoch: [176] [652800/1281167 (51%)]	Loss: 0.510362
[2022-06-12 18:01:40 | train] - Train Epoch: [176] [665600/1281167 (52%)]	Loss: 0.676772
[2022-06-12 18:02:02 | train] - Train Epoch: [176] [678400/1281167 (53%)]	Loss: 0.677224
[2022-06-12 18:02:23 | train] - Train Epoch: [176] [691200/1281167 (54%)]	Loss: 0.779148
[2022-06-12 18:02:44 | train] - Train Epoch: [176] [704000/1281167 (55%)]	Loss: 0.666605
[2022-06-12 18:03:06 | train] - Train Epoch: [176] [716800/1281167 (56%)]	Loss: 0.620926
[2022-06-12 18:03:27 | train] - Train Epoch: [176] [729600/1281167 (57%)]	Loss: 0.825472
[2022-06-12 18:03:48 | train] - Train Epoch: [176] [742400/1281167 (58%)]	Loss: 0.976322
[2022-06-12 18:04:09 | train] - Train Epoch: [176] [755200/1281167 (59%)]	Loss: 0.964483
[2022-06-12 18:04:30 | train] - Train Epoch: [176] [768000/1281167 (60%)]	Loss: 0.792260
[2022-06-12 18:04:50 | train] - Train Epoch: [176] [780800/1281167 (61%)]	Loss: 0.578383
[2022-06-12 18:05:12 | train] - Train Epoch: [176] [793600/1281167 (62%)]	Loss: 0.713798
[2022-06-12 18:05:33 | train] - Train Epoch: [176] [806400/1281167 (63%)]	Loss: 0.700058
[2022-06-12 18:05:54 | train] - Train Epoch: [176] [819200/1281167 (64%)]	Loss: 0.840881
[2022-06-12 18:06:16 | train] - Train Epoch: [176] [832000/1281167 (65%)]	Loss: 0.618207
[2022-06-12 18:06:37 | train] - Train Epoch: [176] [844800/1281167 (66%)]	Loss: 0.657237
[2022-06-12 18:06:58 | train] - Train Epoch: [176] [857600/1281167 (67%)]	Loss: 0.741912
[2022-06-12 18:07:20 | train] - Train Epoch: [176] [870400/1281167 (68%)]	Loss: 0.671370
[2022-06-12 18:07:42 | train] - Train Epoch: [176] [883200/1281167 (69%)]	Loss: 0.470988
[2022-06-12 18:08:03 | train] - Train Epoch: [176] [896000/1281167 (70%)]	Loss: 0.673593
[2022-06-12 18:08:24 | train] - Train Epoch: [176] [908800/1281167 (71%)]	Loss: 0.781279
[2022-06-12 18:08:46 | train] - Train Epoch: [176] [921600/1281167 (72%)]	Loss: 0.845010
[2022-06-12 18:09:07 | train] - Train Epoch: [176] [934400/1281167 (73%)]	Loss: 0.850205
[2022-06-12 18:09:28 | train] - Train Epoch: [176] [947200/1281167 (74%)]	Loss: 0.776996
[2022-06-12 18:09:49 | train] - Train Epoch: [176] [960000/1281167 (75%)]	Loss: 0.860020
[2022-06-12 18:10:10 | train] - Train Epoch: [176] [972800/1281167 (76%)]	Loss: 0.556850
[2022-06-12 18:10:31 | train] - Train Epoch: [176] [985600/1281167 (77%)]	Loss: 0.675354
[2022-06-12 18:10:53 | train] - Train Epoch: [176] [998400/1281167 (78%)]	Loss: 0.757748
[2022-06-12 18:11:13 | train] - Train Epoch: [176] [1011200/1281167 (79%)]	Loss: 0.570234
[2022-06-12 18:11:35 | train] - Train Epoch: [176] [1024000/1281167 (80%)]	Loss: 0.789096
[2022-06-12 18:11:55 | train] - Train Epoch: [176] [1036800/1281167 (81%)]	Loss: 0.890187
[2022-06-12 18:12:17 | train] - Train Epoch: [176] [1049600/1281167 (82%)]	Loss: 0.607787
[2022-06-12 18:12:39 | train] - Train Epoch: [176] [1062400/1281167 (83%)]	Loss: 0.631620
[2022-06-12 18:13:00 | train] - Train Epoch: [176] [1075200/1281167 (84%)]	Loss: 0.512342
[2022-06-12 18:13:22 | train] - Train Epoch: [176] [1088000/1281167 (85%)]	Loss: 0.360974
[2022-06-12 18:13:43 | train] - Train Epoch: [176] [1100800/1281167 (86%)]	Loss: 0.598835
[2022-06-12 18:14:04 | train] - Train Epoch: [176] [1113600/1281167 (87%)]	Loss: 0.685623
[2022-06-12 18:14:25 | train] - Train Epoch: [176] [1126400/1281167 (88%)]	Loss: 0.694515
[2022-06-12 18:14:45 | train] - Train Epoch: [176] [1139200/1281167 (89%)]	Loss: 0.678583
[2022-06-12 18:15:07 | train] - Train Epoch: [176] [1152000/1281167 (90%)]	Loss: 0.696791
[2022-06-12 18:15:28 | train] - Train Epoch: [176] [1164800/1281167 (91%)]	Loss: 0.555510
[2022-06-12 18:15:49 | train] - Train Epoch: [176] [1177600/1281167 (92%)]	Loss: 0.703336
[2022-06-12 18:16:11 | train] - Train Epoch: [176] [1190400/1281167 (93%)]	Loss: 0.599468
[2022-06-12 18:16:32 | train] - Train Epoch: [176] [1203200/1281167 (94%)]	Loss: 0.751016
[2022-06-12 18:16:54 | train] - Train Epoch: [176] [1216000/1281167 (95%)]	Loss: 0.691145
[2022-06-12 18:17:16 | train] - Train Epoch: [176] [1228800/1281167 (96%)]	Loss: 0.785875
[2022-06-12 18:17:37 | train] - Train Epoch: [176] [1241600/1281167 (97%)]	Loss: 0.569996
[2022-06-12 18:17:59 | train] - Train Epoch: [176] [1254400/1281167 (98%)]	Loss: 0.651139
[2022-06-12 18:18:19 | train] - Train Epoch: [176] [1267200/1281167 (99%)]	Loss: 1.041044
[2022-06-12 18:18:41 | train] - Train Epoch: [176] [1280000/1281167 (100%)]	Loss: 0.745709
[2022-06-12 18:18:43 | train] - Train Epoch: [176]	 Average Loss: 0.725846	 Total Acc : 82.3706	 Total Top5 Acc : 93.5772
[2022-06-12 18:18:43 | train] - -------176 epoch end-----------
========================================
-------176 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 18:20:14 | train] - 
Epoch [176] Test set: Average loss: 1.4300, Accuracy: 34947/50000 (69.8653%), Top-5 Accuracy: 88.9882%

[2022-06-12 18:20:14 | train] - save intermediate epoch [176] result


[2022-06-12 18:20:33 | train] - -------177 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 18:20:35 | train] - Train Epoch: [177] [0/1281167 (0%)]	Loss: 0.684633
[2022-06-12 18:20:57 | train] - Train Epoch: [177] [12800/1281167 (1%)]	Loss: 0.709355
[2022-06-12 18:21:18 | train] - Train Epoch: [177] [25600/1281167 (2%)]	Loss: 1.107970
[2022-06-12 18:21:39 | train] - Train Epoch: [177] [38400/1281167 (3%)]	Loss: 0.773342
[2022-06-12 18:22:00 | train] - Train Epoch: [177] [51200/1281167 (4%)]	Loss: 0.847899
[2022-06-12 18:22:22 | train] - Train Epoch: [177] [64000/1281167 (5%)]	Loss: 0.814832
[2022-06-12 18:22:44 | train] - Train Epoch: [177] [76800/1281167 (6%)]	Loss: 0.875389
[2022-06-12 18:23:05 | train] - Train Epoch: [177] [89600/1281167 (7%)]	Loss: 0.857615
[2022-06-12 18:23:26 | train] - Train Epoch: [177] [102400/1281167 (8%)]	Loss: 0.694723
[2022-06-12 18:23:49 | train] - Train Epoch: [177] [115200/1281167 (9%)]	Loss: 0.840963
[2022-06-12 18:24:10 | train] - Train Epoch: [177] [128000/1281167 (10%)]	Loss: 0.504406
[2022-06-12 18:24:33 | train] - Train Epoch: [177] [140800/1281167 (11%)]	Loss: 1.026050
[2022-06-12 18:24:54 | train] - Train Epoch: [177] [153600/1281167 (12%)]	Loss: 0.411550
[2022-06-12 18:25:16 | train] - Train Epoch: [177] [166400/1281167 (13%)]	Loss: 0.743199
[2022-06-12 18:25:38 | train] - Train Epoch: [177] [179200/1281167 (14%)]	Loss: 0.713693
[2022-06-12 18:25:59 | train] - Train Epoch: [177] [192000/1281167 (15%)]	Loss: 0.627861
[2022-06-12 18:26:21 | train] - Train Epoch: [177] [204800/1281167 (16%)]	Loss: 0.501105
[2022-06-12 18:26:43 | train] - Train Epoch: [177] [217600/1281167 (17%)]	Loss: 0.785475
[2022-06-12 18:27:05 | train] - Train Epoch: [177] [230400/1281167 (18%)]	Loss: 0.685661
[2022-06-12 18:27:27 | train] - Train Epoch: [177] [243200/1281167 (19%)]	Loss: 0.431055
[2022-06-12 18:27:48 | train] - Train Epoch: [177] [256000/1281167 (20%)]	Loss: 0.574958
[2022-06-12 18:28:09 | train] - Train Epoch: [177] [268800/1281167 (21%)]	Loss: 0.867661
[2022-06-12 18:28:31 | train] - Train Epoch: [177] [281600/1281167 (22%)]	Loss: 0.664035
[2022-06-12 18:28:52 | train] - Train Epoch: [177] [294400/1281167 (23%)]	Loss: 0.856734
[2022-06-12 18:29:14 | train] - Train Epoch: [177] [307200/1281167 (24%)]	Loss: 0.475560
[2022-06-12 18:29:36 | train] - Train Epoch: [177] [320000/1281167 (25%)]	Loss: 0.675536
[2022-06-12 18:29:56 | train] - Train Epoch: [177] [332800/1281167 (26%)]	Loss: 0.722875
[2022-06-12 18:30:18 | train] - Train Epoch: [177] [345600/1281167 (27%)]	Loss: 0.826217
[2022-06-12 18:30:40 | train] - Train Epoch: [177] [358400/1281167 (28%)]	Loss: 0.554942
[2022-06-12 18:31:01 | train] - Train Epoch: [177] [371200/1281167 (29%)]	Loss: 0.565933
[2022-06-12 18:31:22 | train] - Train Epoch: [177] [384000/1281167 (30%)]	Loss: 0.631312
[2022-06-12 18:31:44 | train] - Train Epoch: [177] [396800/1281167 (31%)]	Loss: 0.823775
[2022-06-12 18:32:05 | train] - Train Epoch: [177] [409600/1281167 (32%)]	Loss: 0.831358
[2022-06-12 18:32:27 | train] - Train Epoch: [177] [422400/1281167 (33%)]	Loss: 0.912072
[2022-06-12 18:32:49 | train] - Train Epoch: [177] [435200/1281167 (34%)]	Loss: 0.758501
[2022-06-12 18:33:10 | train] - Train Epoch: [177] [448000/1281167 (35%)]	Loss: 0.910794
[2022-06-12 18:33:32 | train] - Train Epoch: [177] [460800/1281167 (36%)]	Loss: 0.626237
[2022-06-12 18:33:54 | train] - Train Epoch: [177] [473600/1281167 (37%)]	Loss: 0.405706
[2022-06-12 18:34:16 | train] - Train Epoch: [177] [486400/1281167 (38%)]	Loss: 0.660168
[2022-06-12 18:34:37 | train] - Train Epoch: [177] [499200/1281167 (39%)]	Loss: 0.655822
[2022-06-12 18:34:58 | train] - Train Epoch: [177] [512000/1281167 (40%)]	Loss: 0.841185
[2022-06-12 18:35:18 | train] - Train Epoch: [177] [524800/1281167 (41%)]	Loss: 1.003162
[2022-06-12 18:35:39 | train] - Train Epoch: [177] [537600/1281167 (42%)]	Loss: 0.677434
[2022-06-12 18:36:00 | train] - Train Epoch: [177] [550400/1281167 (43%)]	Loss: 0.683768
[2022-06-12 18:36:22 | train] - Train Epoch: [177] [563200/1281167 (44%)]	Loss: 0.797050
[2022-06-12 18:36:43 | train] - Train Epoch: [177] [576000/1281167 (45%)]	Loss: 0.695548
[2022-06-12 18:37:05 | train] - Train Epoch: [177] [588800/1281167 (46%)]	Loss: 0.575298
[2022-06-12 18:37:26 | train] - Train Epoch: [177] [601600/1281167 (47%)]	Loss: 0.762442
[2022-06-12 18:37:48 | train] - Train Epoch: [177] [614400/1281167 (48%)]	Loss: 0.696193
[2022-06-12 18:38:09 | train] - Train Epoch: [177] [627200/1281167 (49%)]	Loss: 0.650712
[2022-06-12 18:38:31 | train] - Train Epoch: [177] [640000/1281167 (50%)]	Loss: 0.945589
[2022-06-12 18:38:52 | train] - Train Epoch: [177] [652800/1281167 (51%)]	Loss: 0.799810
[2022-06-12 18:39:14 | train] - Train Epoch: [177] [665600/1281167 (52%)]	Loss: 0.564092
[2022-06-12 18:39:34 | train] - Train Epoch: [177] [678400/1281167 (53%)]	Loss: 0.782814
[2022-06-12 18:39:56 | train] - Train Epoch: [177] [691200/1281167 (54%)]	Loss: 1.010118
[2022-06-12 18:40:18 | train] - Train Epoch: [177] [704000/1281167 (55%)]	Loss: 1.155491
[2022-06-12 18:40:39 | train] - Train Epoch: [177] [716800/1281167 (56%)]	Loss: 0.829220
[2022-06-12 18:41:01 | train] - Train Epoch: [177] [729600/1281167 (57%)]	Loss: 0.945979
[2022-06-12 18:41:22 | train] - Train Epoch: [177] [742400/1281167 (58%)]	Loss: 0.798254
[2022-06-12 18:41:43 | train] - Train Epoch: [177] [755200/1281167 (59%)]	Loss: 0.752787
[2022-06-12 18:42:05 | train] - Train Epoch: [177] [768000/1281167 (60%)]	Loss: 0.731720
[2022-06-12 18:42:27 | train] - Train Epoch: [177] [780800/1281167 (61%)]	Loss: 0.733441
[2022-06-12 18:42:48 | train] - Train Epoch: [177] [793600/1281167 (62%)]	Loss: 0.690652
[2022-06-12 18:43:09 | train] - Train Epoch: [177] [806400/1281167 (63%)]	Loss: 0.699260
[2022-06-12 18:43:31 | train] - Train Epoch: [177] [819200/1281167 (64%)]	Loss: 0.817352
[2022-06-12 18:43:53 | train] - Train Epoch: [177] [832000/1281167 (65%)]	Loss: 0.640276
[2022-06-12 18:44:14 | train] - Train Epoch: [177] [844800/1281167 (66%)]	Loss: 0.802501
[2022-06-12 18:44:36 | train] - Train Epoch: [177] [857600/1281167 (67%)]	Loss: 0.488211
[2022-06-12 18:44:57 | train] - Train Epoch: [177] [870400/1281167 (68%)]	Loss: 0.816750
[2022-06-12 18:45:19 | train] - Train Epoch: [177] [883200/1281167 (69%)]	Loss: 0.843234
[2022-06-12 18:45:41 | train] - Train Epoch: [177] [896000/1281167 (70%)]	Loss: 0.752617
[2022-06-12 18:46:04 | train] - Train Epoch: [177] [908800/1281167 (71%)]	Loss: 0.757903
[2022-06-12 18:46:26 | train] - Train Epoch: [177] [921600/1281167 (72%)]	Loss: 0.670565
[2022-06-12 18:46:48 | train] - Train Epoch: [177] [934400/1281167 (73%)]	Loss: 0.592358
[2022-06-12 18:47:10 | train] - Train Epoch: [177] [947200/1281167 (74%)]	Loss: 0.735827
[2022-06-12 18:47:31 | train] - Train Epoch: [177] [960000/1281167 (75%)]	Loss: 0.805784
[2022-06-12 18:47:53 | train] - Train Epoch: [177] [972800/1281167 (76%)]	Loss: 0.878043
[2022-06-12 18:48:15 | train] - Train Epoch: [177] [985600/1281167 (77%)]	Loss: 0.688595
[2022-06-12 18:48:36 | train] - Train Epoch: [177] [998400/1281167 (78%)]	Loss: 0.685254
[2022-06-12 18:48:58 | train] - Train Epoch: [177] [1011200/1281167 (79%)]	Loss: 0.880601
[2022-06-12 18:49:20 | train] - Train Epoch: [177] [1024000/1281167 (80%)]	Loss: 0.711376
[2022-06-12 18:49:42 | train] - Train Epoch: [177] [1036800/1281167 (81%)]	Loss: 0.697292
[2022-06-12 18:50:03 | train] - Train Epoch: [177] [1049600/1281167 (82%)]	Loss: 0.942467
[2022-06-12 18:50:25 | train] - Train Epoch: [177] [1062400/1281167 (83%)]	Loss: 0.671802
[2022-06-12 18:50:46 | train] - Train Epoch: [177] [1075200/1281167 (84%)]	Loss: 0.654274
[2022-06-12 18:51:08 | train] - Train Epoch: [177] [1088000/1281167 (85%)]	Loss: 0.695006
[2022-06-12 18:51:30 | train] - Train Epoch: [177] [1100800/1281167 (86%)]	Loss: 0.717044
[2022-06-12 18:51:51 | train] - Train Epoch: [177] [1113600/1281167 (87%)]	Loss: 0.844633
[2022-06-12 18:52:12 | train] - Train Epoch: [177] [1126400/1281167 (88%)]	Loss: 0.775794
[2022-06-12 18:52:34 | train] - Train Epoch: [177] [1139200/1281167 (89%)]	Loss: 0.777265
[2022-06-12 18:52:56 | train] - Train Epoch: [177] [1152000/1281167 (90%)]	Loss: 1.007614
[2022-06-12 18:53:16 | train] - Train Epoch: [177] [1164800/1281167 (91%)]	Loss: 0.881452
[2022-06-12 18:53:37 | train] - Train Epoch: [177] [1177600/1281167 (92%)]	Loss: 0.737036
[2022-06-12 18:53:57 | train] - Train Epoch: [177] [1190400/1281167 (93%)]	Loss: 0.756081
[2022-06-12 18:54:19 | train] - Train Epoch: [177] [1203200/1281167 (94%)]	Loss: 0.849253
[2022-06-12 18:54:40 | train] - Train Epoch: [177] [1216000/1281167 (95%)]	Loss: 0.908839
[2022-06-12 18:55:01 | train] - Train Epoch: [177] [1228800/1281167 (96%)]	Loss: 0.782487
[2022-06-12 18:55:23 | train] - Train Epoch: [177] [1241600/1281167 (97%)]	Loss: 0.919907
[2022-06-12 18:55:45 | train] - Train Epoch: [177] [1254400/1281167 (98%)]	Loss: 0.722145
[2022-06-12 18:56:06 | train] - Train Epoch: [177] [1267200/1281167 (99%)]	Loss: 0.810384
[2022-06-12 18:56:27 | train] - Train Epoch: [177] [1280000/1281167 (100%)]	Loss: 0.847238
[2022-06-12 18:56:29 | train] - Train Epoch: [177]	 Average Loss: 0.725446	 Total Acc : 82.3741	 Total Top5 Acc : 93.6128
[2022-06-12 18:56:29 | train] - -------177 epoch end-----------
========================================
-------177 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 18:58:03 | train] - 
Epoch [177] Test set: Average loss: 1.4337, Accuracy: 34908/50000 (69.7886%), Top-5 Accuracy: 88.8895%

[2022-06-12 18:58:03 | train] - save intermediate epoch [177] result


[2022-06-12 18:58:22 | train] - -------178 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 18:58:24 | train] - Train Epoch: [178] [0/1281167 (0%)]	Loss: 0.887682
[2022-06-12 18:58:46 | train] - Train Epoch: [178] [12800/1281167 (1%)]	Loss: 0.777726
[2022-06-12 18:59:08 | train] - Train Epoch: [178] [25600/1281167 (2%)]	Loss: 0.768045
[2022-06-12 18:59:29 | train] - Train Epoch: [178] [38400/1281167 (3%)]	Loss: 0.625389
[2022-06-12 18:59:51 | train] - Train Epoch: [178] [51200/1281167 (4%)]	Loss: 0.853504
[2022-06-12 19:00:13 | train] - Train Epoch: [178] [64000/1281167 (5%)]	Loss: 0.657392
[2022-06-12 19:00:35 | train] - Train Epoch: [178] [76800/1281167 (6%)]	Loss: 0.484282
[2022-06-12 19:00:57 | train] - Train Epoch: [178] [89600/1281167 (7%)]	Loss: 0.961224
[2022-06-12 19:01:19 | train] - Train Epoch: [178] [102400/1281167 (8%)]	Loss: 0.557105
[2022-06-12 19:01:41 | train] - Train Epoch: [178] [115200/1281167 (9%)]	Loss: 0.604131
[2022-06-12 19:02:03 | train] - Train Epoch: [178] [128000/1281167 (10%)]	Loss: 0.802079
[2022-06-12 19:02:24 | train] - Train Epoch: [178] [140800/1281167 (11%)]	Loss: 0.791503
[2022-06-12 19:02:46 | train] - Train Epoch: [178] [153600/1281167 (12%)]	Loss: 0.495738
[2022-06-12 19:03:08 | train] - Train Epoch: [178] [166400/1281167 (13%)]	Loss: 0.552931
[2022-06-12 19:03:30 | train] - Train Epoch: [178] [179200/1281167 (14%)]	Loss: 0.875030
[2022-06-12 19:03:52 | train] - Train Epoch: [178] [192000/1281167 (15%)]	Loss: 0.840931
[2022-06-12 19:04:14 | train] - Train Epoch: [178] [204800/1281167 (16%)]	Loss: 0.720807
[2022-06-12 19:04:36 | train] - Train Epoch: [178] [217600/1281167 (17%)]	Loss: 0.682200
[2022-06-12 19:04:58 | train] - Train Epoch: [178] [230400/1281167 (18%)]	Loss: 0.704186
[2022-06-12 19:05:20 | train] - Train Epoch: [178] [243200/1281167 (19%)]	Loss: 0.432134
[2022-06-12 19:05:42 | train] - Train Epoch: [178] [256000/1281167 (20%)]	Loss: 0.732105
[2022-06-12 19:06:04 | train] - Train Epoch: [178] [268800/1281167 (21%)]	Loss: 0.867729
[2022-06-12 19:06:25 | train] - Train Epoch: [178] [281600/1281167 (22%)]	Loss: 0.794304
[2022-06-12 19:06:47 | train] - Train Epoch: [178] [294400/1281167 (23%)]	Loss: 0.706759
[2022-06-12 19:07:09 | train] - Train Epoch: [178] [307200/1281167 (24%)]	Loss: 0.582829
[2022-06-12 19:07:31 | train] - Train Epoch: [178] [320000/1281167 (25%)]	Loss: 0.675081
[2022-06-12 19:07:53 | train] - Train Epoch: [178] [332800/1281167 (26%)]	Loss: 0.745099
[2022-06-12 19:08:14 | train] - Train Epoch: [178] [345600/1281167 (27%)]	Loss: 0.645770
[2022-06-12 19:08:36 | train] - Train Epoch: [178] [358400/1281167 (28%)]	Loss: 0.727019
[2022-06-12 19:08:58 | train] - Train Epoch: [178] [371200/1281167 (29%)]	Loss: 0.906803
[2022-06-12 19:09:20 | train] - Train Epoch: [178] [384000/1281167 (30%)]	Loss: 0.841567
[2022-06-12 19:09:42 | train] - Train Epoch: [178] [396800/1281167 (31%)]	Loss: 0.699070
[2022-06-12 19:10:04 | train] - Train Epoch: [178] [409600/1281167 (32%)]	Loss: 0.694954
[2022-06-12 19:10:25 | train] - Train Epoch: [178] [422400/1281167 (33%)]	Loss: 0.766311
[2022-06-12 19:10:46 | train] - Train Epoch: [178] [435200/1281167 (34%)]	Loss: 0.700138
[2022-06-12 19:11:08 | train] - Train Epoch: [178] [448000/1281167 (35%)]	Loss: 0.802781
[2022-06-12 19:11:30 | train] - Train Epoch: [178] [460800/1281167 (36%)]	Loss: 0.552751
[2022-06-12 19:11:52 | train] - Train Epoch: [178] [473600/1281167 (37%)]	Loss: 0.531449
[2022-06-12 19:12:13 | train] - Train Epoch: [178] [486400/1281167 (38%)]	Loss: 0.571324
[2022-06-12 19:12:35 | train] - Train Epoch: [178] [499200/1281167 (39%)]	Loss: 0.691539
[2022-06-12 19:12:57 | train] - Train Epoch: [178] [512000/1281167 (40%)]	Loss: 0.634943
[2022-06-12 19:13:19 | train] - Train Epoch: [178] [524800/1281167 (41%)]	Loss: 0.676907
[2022-06-12 19:13:39 | train] - Train Epoch: [178] [537600/1281167 (42%)]	Loss: 0.841280
[2022-06-12 19:14:01 | train] - Train Epoch: [178] [550400/1281167 (43%)]	Loss: 0.698817
[2022-06-12 19:14:23 | train] - Train Epoch: [178] [563200/1281167 (44%)]	Loss: 0.503162
[2022-06-12 19:14:44 | train] - Train Epoch: [178] [576000/1281167 (45%)]	Loss: 0.849523
[2022-06-12 19:15:05 | train] - Train Epoch: [178] [588800/1281167 (46%)]	Loss: 0.839112
[2022-06-12 19:15:27 | train] - Train Epoch: [178] [601600/1281167 (47%)]	Loss: 0.807602
[2022-06-12 19:15:48 | train] - Train Epoch: [178] [614400/1281167 (48%)]	Loss: 0.794139
[2022-06-12 19:16:09 | train] - Train Epoch: [178] [627200/1281167 (49%)]	Loss: 0.510214
[2022-06-12 19:16:31 | train] - Train Epoch: [178] [640000/1281167 (50%)]	Loss: 0.897628
[2022-06-12 19:16:53 | train] - Train Epoch: [178] [652800/1281167 (51%)]	Loss: 0.633363
[2022-06-12 19:17:15 | train] - Train Epoch: [178] [665600/1281167 (52%)]	Loss: 0.649862
[2022-06-12 19:17:37 | train] - Train Epoch: [178] [678400/1281167 (53%)]	Loss: 0.735794
[2022-06-12 19:17:59 | train] - Train Epoch: [178] [691200/1281167 (54%)]	Loss: 0.662679
[2022-06-12 19:18:21 | train] - Train Epoch: [178] [704000/1281167 (55%)]	Loss: 0.839678
[2022-06-12 19:18:43 | train] - Train Epoch: [178] [716800/1281167 (56%)]	Loss: 0.522953
[2022-06-12 19:19:05 | train] - Train Epoch: [178] [729600/1281167 (57%)]	Loss: 0.867613
[2022-06-12 19:19:26 | train] - Train Epoch: [178] [742400/1281167 (58%)]	Loss: 0.789330
[2022-06-12 19:19:48 | train] - Train Epoch: [178] [755200/1281167 (59%)]	Loss: 0.972811
[2022-06-12 19:20:10 | train] - Train Epoch: [178] [768000/1281167 (60%)]	Loss: 0.598516
[2022-06-12 19:20:32 | train] - Train Epoch: [178] [780800/1281167 (61%)]	Loss: 0.779351
[2022-06-12 19:20:54 | train] - Train Epoch: [178] [793600/1281167 (62%)]	Loss: 0.632470
[2022-06-12 19:21:15 | train] - Train Epoch: [178] [806400/1281167 (63%)]	Loss: 0.991253
[2022-06-12 19:21:37 | train] - Train Epoch: [178] [819200/1281167 (64%)]	Loss: 0.632546
[2022-06-12 19:21:59 | train] - Train Epoch: [178] [832000/1281167 (65%)]	Loss: 1.098475
[2022-06-12 19:22:21 | train] - Train Epoch: [178] [844800/1281167 (66%)]	Loss: 0.715459
[2022-06-12 19:22:43 | train] - Train Epoch: [178] [857600/1281167 (67%)]	Loss: 1.036112
[2022-06-12 19:23:05 | train] - Train Epoch: [178] [870400/1281167 (68%)]	Loss: 0.644679
[2022-06-12 19:23:27 | train] - Train Epoch: [178] [883200/1281167 (69%)]	Loss: 0.738878
[2022-06-12 19:23:48 | train] - Train Epoch: [178] [896000/1281167 (70%)]	Loss: 0.802029
[2022-06-12 19:24:10 | train] - Train Epoch: [178] [908800/1281167 (71%)]	Loss: 0.808359
[2022-06-12 19:24:32 | train] - Train Epoch: [178] [921600/1281167 (72%)]	Loss: 0.409753
[2022-06-12 19:24:54 | train] - Train Epoch: [178] [934400/1281167 (73%)]	Loss: 0.697999
[2022-06-12 19:25:15 | train] - Train Epoch: [178] [947200/1281167 (74%)]	Loss: 0.755247
[2022-06-12 19:25:37 | train] - Train Epoch: [178] [960000/1281167 (75%)]	Loss: 0.732894
[2022-06-12 19:25:59 | train] - Train Epoch: [178] [972800/1281167 (76%)]	Loss: 0.685842
[2022-06-12 19:26:20 | train] - Train Epoch: [178] [985600/1281167 (77%)]	Loss: 0.582391
[2022-06-12 19:26:42 | train] - Train Epoch: [178] [998400/1281167 (78%)]	Loss: 0.815752
[2022-06-12 19:27:04 | train] - Train Epoch: [178] [1011200/1281167 (79%)]	Loss: 0.717711
[2022-06-12 19:27:26 | train] - Train Epoch: [178] [1024000/1281167 (80%)]	Loss: 0.851672
[2022-06-12 19:27:48 | train] - Train Epoch: [178] [1036800/1281167 (81%)]	Loss: 0.626730
[2022-06-12 19:28:09 | train] - Train Epoch: [178] [1049600/1281167 (82%)]	Loss: 0.781032
[2022-06-12 19:28:31 | train] - Train Epoch: [178] [1062400/1281167 (83%)]	Loss: 0.957775
[2022-06-12 19:28:54 | train] - Train Epoch: [178] [1075200/1281167 (84%)]	Loss: 0.562792
[2022-06-12 19:29:16 | train] - Train Epoch: [178] [1088000/1281167 (85%)]	Loss: 0.691669
[2022-06-12 19:29:38 | train] - Train Epoch: [178] [1100800/1281167 (86%)]	Loss: 0.699671
[2022-06-12 19:30:00 | train] - Train Epoch: [178] [1113600/1281167 (87%)]	Loss: 0.824762
[2022-06-12 19:30:22 | train] - Train Epoch: [178] [1126400/1281167 (88%)]	Loss: 0.736772
[2022-06-12 19:30:43 | train] - Train Epoch: [178] [1139200/1281167 (89%)]	Loss: 0.610176
[2022-06-12 19:31:05 | train] - Train Epoch: [178] [1152000/1281167 (90%)]	Loss: 0.619500
[2022-06-12 19:31:27 | train] - Train Epoch: [178] [1164800/1281167 (91%)]	Loss: 0.840901
[2022-06-12 19:31:48 | train] - Train Epoch: [178] [1177600/1281167 (92%)]	Loss: 0.504376
[2022-06-12 19:32:10 | train] - Train Epoch: [178] [1190400/1281167 (93%)]	Loss: 0.762631
[2022-06-12 19:32:32 | train] - Train Epoch: [178] [1203200/1281167 (94%)]	Loss: 0.649347
[2022-06-12 19:32:54 | train] - Train Epoch: [178] [1216000/1281167 (95%)]	Loss: 0.934016
[2022-06-12 19:33:16 | train] - Train Epoch: [178] [1228800/1281167 (96%)]	Loss: 0.836919
[2022-06-12 19:33:38 | train] - Train Epoch: [178] [1241600/1281167 (97%)]	Loss: 0.624284
[2022-06-12 19:34:00 | train] - Train Epoch: [178] [1254400/1281167 (98%)]	Loss: 0.776926
[2022-06-12 19:34:21 | train] - Train Epoch: [178] [1267200/1281167 (99%)]	Loss: 0.856224
[2022-06-12 19:34:43 | train] - Train Epoch: [178] [1280000/1281167 (100%)]	Loss: 0.625122
[2022-06-12 19:34:45 | train] - Train Epoch: [178]	 Average Loss: 0.725448	 Total Acc : 82.3470	 Total Top5 Acc : 93.5812
[2022-06-12 19:34:45 | train] - -------178 epoch end-----------
========================================
-------178 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 19:36:19 | train] - 
Epoch [178] Test set: Average loss: 1.4254, Accuracy: 34951/50000 (69.8721%), Top-5 Accuracy: 88.8675%

[2022-06-12 19:36:19 | train] - save intermediate epoch [178] result


[2022-06-12 19:36:39 | train] - -------179 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 19:36:41 | train] - Train Epoch: [179] [0/1281167 (0%)]	Loss: 0.730077
[2022-06-12 19:37:03 | train] - Train Epoch: [179] [12800/1281167 (1%)]	Loss: 0.769044
[2022-06-12 19:37:25 | train] - Train Epoch: [179] [25600/1281167 (2%)]	Loss: 0.832435
[2022-06-12 19:37:47 | train] - Train Epoch: [179] [38400/1281167 (3%)]	Loss: 0.715418
[2022-06-12 19:38:09 | train] - Train Epoch: [179] [51200/1281167 (4%)]	Loss: 1.020825
[2022-06-12 19:38:31 | train] - Train Epoch: [179] [64000/1281167 (5%)]	Loss: 0.598714
[2022-06-12 19:38:53 | train] - Train Epoch: [179] [76800/1281167 (6%)]	Loss: 0.667240
[2022-06-12 19:39:14 | train] - Train Epoch: [179] [89600/1281167 (7%)]	Loss: 0.778308
[2022-06-12 19:39:36 | train] - Train Epoch: [179] [102400/1281167 (8%)]	Loss: 0.684591
[2022-06-12 19:39:57 | train] - Train Epoch: [179] [115200/1281167 (9%)]	Loss: 0.836886
[2022-06-12 19:40:19 | train] - Train Epoch: [179] [128000/1281167 (10%)]	Loss: 0.739335
[2022-06-12 19:40:41 | train] - Train Epoch: [179] [140800/1281167 (11%)]	Loss: 0.619981
[2022-06-12 19:41:03 | train] - Train Epoch: [179] [153600/1281167 (12%)]	Loss: 0.641709
[2022-06-12 19:41:25 | train] - Train Epoch: [179] [166400/1281167 (13%)]	Loss: 0.903547
[2022-06-12 19:41:47 | train] - Train Epoch: [179] [179200/1281167 (14%)]	Loss: 0.815724
[2022-06-12 19:42:08 | train] - Train Epoch: [179] [192000/1281167 (15%)]	Loss: 0.602776
[2022-06-12 19:42:30 | train] - Train Epoch: [179] [204800/1281167 (16%)]	Loss: 0.820890
[2022-06-12 19:42:51 | train] - Train Epoch: [179] [217600/1281167 (17%)]	Loss: 0.640453
[2022-06-12 19:43:13 | train] - Train Epoch: [179] [230400/1281167 (18%)]	Loss: 0.849212
[2022-06-12 19:43:34 | train] - Train Epoch: [179] [243200/1281167 (19%)]	Loss: 0.742502
[2022-06-12 19:43:57 | train] - Train Epoch: [179] [256000/1281167 (20%)]	Loss: 0.648046
[2022-06-12 19:44:19 | train] - Train Epoch: [179] [268800/1281167 (21%)]	Loss: 0.803012
[2022-06-12 19:44:40 | train] - Train Epoch: [179] [281600/1281167 (22%)]	Loss: 0.646003
[2022-06-12 19:45:02 | train] - Train Epoch: [179] [294400/1281167 (23%)]	Loss: 0.524709
[2022-06-12 19:45:23 | train] - Train Epoch: [179] [307200/1281167 (24%)]	Loss: 0.793518
[2022-06-12 19:45:45 | train] - Train Epoch: [179] [320000/1281167 (25%)]	Loss: 0.599323
[2022-06-12 19:46:06 | train] - Train Epoch: [179] [332800/1281167 (26%)]	Loss: 0.801194
[2022-06-12 19:46:27 | train] - Train Epoch: [179] [345600/1281167 (27%)]	Loss: 0.830006
[2022-06-12 19:46:49 | train] - Train Epoch: [179] [358400/1281167 (28%)]	Loss: 0.577834
[2022-06-12 19:47:11 | train] - Train Epoch: [179] [371200/1281167 (29%)]	Loss: 0.503064
[2022-06-12 19:47:33 | train] - Train Epoch: [179] [384000/1281167 (30%)]	Loss: 0.664864
[2022-06-12 19:47:54 | train] - Train Epoch: [179] [396800/1281167 (31%)]	Loss: 0.547115
[2022-06-12 19:48:16 | train] - Train Epoch: [179] [409600/1281167 (32%)]	Loss: 0.665230
[2022-06-12 19:48:38 | train] - Train Epoch: [179] [422400/1281167 (33%)]	Loss: 0.449796
[2022-06-12 19:48:59 | train] - Train Epoch: [179] [435200/1281167 (34%)]	Loss: 0.914624
[2022-06-12 19:49:21 | train] - Train Epoch: [179] [448000/1281167 (35%)]	Loss: 0.989594
[2022-06-12 19:49:43 | train] - Train Epoch: [179] [460800/1281167 (36%)]	Loss: 0.856534
[2022-06-12 19:50:05 | train] - Train Epoch: [179] [473600/1281167 (37%)]	Loss: 0.472185
[2022-06-12 19:50:26 | train] - Train Epoch: [179] [486400/1281167 (38%)]	Loss: 0.950623
[2022-06-12 19:50:49 | train] - Train Epoch: [179] [499200/1281167 (39%)]	Loss: 0.641853
[2022-06-12 19:51:11 | train] - Train Epoch: [179] [512000/1281167 (40%)]	Loss: 0.908435
[2022-06-12 19:51:32 | train] - Train Epoch: [179] [524800/1281167 (41%)]	Loss: 0.698136
[2022-06-12 19:51:54 | train] - Train Epoch: [179] [537600/1281167 (42%)]	Loss: 0.937596
[2022-06-12 19:52:16 | train] - Train Epoch: [179] [550400/1281167 (43%)]	Loss: 0.958754
[2022-06-12 19:52:39 | train] - Train Epoch: [179] [563200/1281167 (44%)]	Loss: 0.907738
[2022-06-12 19:53:01 | train] - Train Epoch: [179] [576000/1281167 (45%)]	Loss: 0.647186
[2022-06-12 19:53:23 | train] - Train Epoch: [179] [588800/1281167 (46%)]	Loss: 0.469302
[2022-06-12 19:53:45 | train] - Train Epoch: [179] [601600/1281167 (47%)]	Loss: 0.614980
[2022-06-12 19:54:07 | train] - Train Epoch: [179] [614400/1281167 (48%)]	Loss: 0.650677
[2022-06-12 19:54:29 | train] - Train Epoch: [179] [627200/1281167 (49%)]	Loss: 0.603042
[2022-06-12 19:54:50 | train] - Train Epoch: [179] [640000/1281167 (50%)]	Loss: 0.911735
[2022-06-12 19:55:12 | train] - Train Epoch: [179] [652800/1281167 (51%)]	Loss: 0.534943
[2022-06-12 19:55:34 | train] - Train Epoch: [179] [665600/1281167 (52%)]	Loss: 0.826390
[2022-06-12 19:55:56 | train] - Train Epoch: [179] [678400/1281167 (53%)]	Loss: 0.738317
[2022-06-12 19:56:17 | train] - Train Epoch: [179] [691200/1281167 (54%)]	Loss: 0.930770
[2022-06-12 19:56:38 | train] - Train Epoch: [179] [704000/1281167 (55%)]	Loss: 0.690204
[2022-06-12 19:57:00 | train] - Train Epoch: [179] [716800/1281167 (56%)]	Loss: 0.735314
[2022-06-12 19:57:22 | train] - Train Epoch: [179] [729600/1281167 (57%)]	Loss: 0.861187
[2022-06-12 19:57:44 | train] - Train Epoch: [179] [742400/1281167 (58%)]	Loss: 0.589874
[2022-06-12 19:58:06 | train] - Train Epoch: [179] [755200/1281167 (59%)]	Loss: 0.710343
[2022-06-12 19:58:27 | train] - Train Epoch: [179] [768000/1281167 (60%)]	Loss: 0.708419
[2022-06-12 19:58:50 | train] - Train Epoch: [179] [780800/1281167 (61%)]	Loss: 0.635484
[2022-06-12 19:59:12 | train] - Train Epoch: [179] [793600/1281167 (62%)]	Loss: 0.773450
[2022-06-12 19:59:34 | train] - Train Epoch: [179] [806400/1281167 (63%)]	Loss: 1.068788
[2022-06-12 19:59:56 | train] - Train Epoch: [179] [819200/1281167 (64%)]	Loss: 0.682932
[2022-06-12 20:00:17 | train] - Train Epoch: [179] [832000/1281167 (65%)]	Loss: 0.520420
[2022-06-12 20:00:38 | train] - Train Epoch: [179] [844800/1281167 (66%)]	Loss: 0.696751
[2022-06-12 20:01:00 | train] - Train Epoch: [179] [857600/1281167 (67%)]	Loss: 0.934636
[2022-06-12 20:01:22 | train] - Train Epoch: [179] [870400/1281167 (68%)]	Loss: 0.870874
[2022-06-12 20:01:44 | train] - Train Epoch: [179] [883200/1281167 (69%)]	Loss: 0.678809
[2022-06-12 20:02:06 | train] - Train Epoch: [179] [896000/1281167 (70%)]	Loss: 0.768512
[2022-06-12 20:02:28 | train] - Train Epoch: [179] [908800/1281167 (71%)]	Loss: 0.810748
[2022-06-12 20:02:51 | train] - Train Epoch: [179] [921600/1281167 (72%)]	Loss: 0.867335
[2022-06-12 20:03:13 | train] - Train Epoch: [179] [934400/1281167 (73%)]	Loss: 0.878277
[2022-06-12 20:03:35 | train] - Train Epoch: [179] [947200/1281167 (74%)]	Loss: 0.679948
[2022-06-12 20:03:57 | train] - Train Epoch: [179] [960000/1281167 (75%)]	Loss: 0.580335
[2022-06-12 20:04:20 | train] - Train Epoch: [179] [972800/1281167 (76%)]	Loss: 0.731295
[2022-06-12 20:04:42 | train] - Train Epoch: [179] [985600/1281167 (77%)]	Loss: 0.596723
[2022-06-12 20:05:04 | train] - Train Epoch: [179] [998400/1281167 (78%)]	Loss: 0.552138
[2022-06-12 20:05:26 | train] - Train Epoch: [179] [1011200/1281167 (79%)]	Loss: 0.475953
[2022-06-12 20:05:49 | train] - Train Epoch: [179] [1024000/1281167 (80%)]	Loss: 0.909843
[2022-06-12 20:06:11 | train] - Train Epoch: [179] [1036800/1281167 (81%)]	Loss: 0.800229
[2022-06-12 20:06:33 | train] - Train Epoch: [179] [1049600/1281167 (82%)]	Loss: 0.685845
[2022-06-12 20:06:55 | train] - Train Epoch: [179] [1062400/1281167 (83%)]	Loss: 0.567914
[2022-06-12 20:07:17 | train] - Train Epoch: [179] [1075200/1281167 (84%)]	Loss: 0.675959
[2022-06-12 20:07:39 | train] - Train Epoch: [179] [1088000/1281167 (85%)]	Loss: 1.023193
[2022-06-12 20:08:01 | train] - Train Epoch: [179] [1100800/1281167 (86%)]	Loss: 0.659930
[2022-06-12 20:08:22 | train] - Train Epoch: [179] [1113600/1281167 (87%)]	Loss: 1.082936
[2022-06-12 20:08:44 | train] - Train Epoch: [179] [1126400/1281167 (88%)]	Loss: 0.638928
[2022-06-12 20:09:06 | train] - Train Epoch: [179] [1139200/1281167 (89%)]	Loss: 0.863482
[2022-06-12 20:09:27 | train] - Train Epoch: [179] [1152000/1281167 (90%)]	Loss: 0.971794
[2022-06-12 20:09:49 | train] - Train Epoch: [179] [1164800/1281167 (91%)]	Loss: 0.693362
[2022-06-12 20:10:10 | train] - Train Epoch: [179] [1177600/1281167 (92%)]	Loss: 0.598103
[2022-06-12 20:10:33 | train] - Train Epoch: [179] [1190400/1281167 (93%)]	Loss: 0.777163
[2022-06-12 20:10:55 | train] - Train Epoch: [179] [1203200/1281167 (94%)]	Loss: 0.603879
[2022-06-12 20:11:17 | train] - Train Epoch: [179] [1216000/1281167 (95%)]	Loss: 0.870086
[2022-06-12 20:11:39 | train] - Train Epoch: [179] [1228800/1281167 (96%)]	Loss: 0.706612
[2022-06-12 20:12:00 | train] - Train Epoch: [179] [1241600/1281167 (97%)]	Loss: 0.800982
[2022-06-12 20:12:21 | train] - Train Epoch: [179] [1254400/1281167 (98%)]	Loss: 0.723205
[2022-06-12 20:12:43 | train] - Train Epoch: [179] [1267200/1281167 (99%)]	Loss: 0.751433
[2022-06-12 20:13:05 | train] - Train Epoch: [179] [1280000/1281167 (100%)]	Loss: 0.553721
[2022-06-12 20:13:06 | train] - Train Epoch: [179]	 Average Loss: 0.722926	 Total Acc : 82.4362	 Total Top5 Acc : 93.6057
[2022-06-12 20:13:06 | train] - -------179 epoch end-----------
========================================
-------179 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 20:14:42 | train] - 
Epoch [179] Test set: Average loss: 1.4286, Accuracy: 35007/50000 (69.9852%), Top-5 Accuracy: 89.0393%

[2022-06-12 20:14:42 | train] - save intermediate epoch [179] result


[2022-06-12 20:15:02 | train] - -------180 epoch start-----------
[2022-06-12 20:15:02 | train] - -------- logging 180 batch layer input tensor ------------------
[2022-06-12 20:15:31 | train] - -------- logging end 180 --------------------
========================================
----- test end -------------------------


batch_input shape : torch.Size([128, 3, 224, 224])
batch_output shape : torch.Size([128, 64, 112, 112])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 64, 56, 56])
batch_input shape : torch.Size([128, 64, 56, 56])
batch_output shape : torch.Size([128, 256, 56, 56])
batch_input shape : torch.Size([128, 256, 56, 56])
batch_output shape : torch.Size([128, 128, 56, 56])
batch_input shape : torch.Size([128, 128, 56, 56])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 128, 28, 28])
batch_input shape : torch.Size([128, 128, 28, 28])
batch_output shape : torch.Size([128, 512, 28, 28])
batch_input shape : torch.Size([128, 512, 28, 28])
batch_output shape : torch.Size([128, 256, 28, 28])
batch_input shape : torch.Size([128, 256, 28, 28])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 256, 14, 14])
batch_input shape : torch.Size([128, 256, 14, 14])
batch_output shape : torch.Size([128, 1024, 14, 14])
batch_input shape : torch.Size([128, 1024, 14, 14])
batch_output shape : torch.Size([128, 512, 14, 14])
batch_input shape : torch.Size([128, 512, 14, 14])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 512, 7, 7])
batch_input shape : torch.Size([128, 512, 7, 7])
batch_output shape : torch.Size([128, 2048, 7, 7])
batch_input shape : torch.Size([128, 2048])
batch_output shape : torch.Size([128, 1000])
[2022-06-12 20:15:33 | train] - Train Epoch: [180] [0/1281167 (0%)]	Loss: 0.593919
[2022-06-12 20:15:55 | train] - Train Epoch: [180] [12800/1281167 (1%)]	Loss: 0.646714
[2022-06-12 20:16:16 | train] - Train Epoch: [180] [25600/1281167 (2%)]	Loss: 0.616601
[2022-06-12 20:16:38 | train] - Train Epoch: [180] [38400/1281167 (3%)]	Loss: 0.616790
[2022-06-12 20:16:59 | train] - Train Epoch: [180] [51200/1281167 (4%)]	Loss: 0.479000
[2022-06-12 20:17:21 | train] - Train Epoch: [180] [64000/1281167 (5%)]	Loss: 0.612423
[2022-06-12 20:17:41 | train] - Train Epoch: [180] [76800/1281167 (6%)]	Loss: 0.844258
[2022-06-12 20:18:02 | train] - Train Epoch: [180] [89600/1281167 (7%)]	Loss: 0.987062
[2022-06-12 20:18:24 | train] - Train Epoch: [180] [102400/1281167 (8%)]	Loss: 0.576565
[2022-06-12 20:18:46 | train] - Train Epoch: [180] [115200/1281167 (9%)]	Loss: 0.608418
[2022-06-12 20:19:08 | train] - Train Epoch: [180] [128000/1281167 (10%)]	Loss: 0.590964
[2022-06-12 20:19:30 | train] - Train Epoch: [180] [140800/1281167 (11%)]	Loss: 0.758524
[2022-06-12 20:19:52 | train] - Train Epoch: [180] [153600/1281167 (12%)]	Loss: 0.591574
[2022-06-12 20:20:14 | train] - Train Epoch: [180] [166400/1281167 (13%)]	Loss: 1.173356
[2022-06-12 20:20:36 | train] - Train Epoch: [180] [179200/1281167 (14%)]	Loss: 0.680557
[2022-06-12 20:20:59 | train] - Train Epoch: [180] [192000/1281167 (15%)]	Loss: 0.637042
[2022-06-12 20:21:21 | train] - Train Epoch: [180] [204800/1281167 (16%)]	Loss: 0.724099
[2022-06-12 20:21:43 | train] - Train Epoch: [180] [217600/1281167 (17%)]	Loss: 0.633317
[2022-06-12 20:22:05 | train] - Train Epoch: [180] [230400/1281167 (18%)]	Loss: 0.643296
[2022-06-12 20:22:28 | train] - Train Epoch: [180] [243200/1281167 (19%)]	Loss: 0.626401
[2022-06-12 20:22:51 | train] - Train Epoch: [180] [256000/1281167 (20%)]	Loss: 0.764106
[2022-06-12 20:23:12 | train] - Train Epoch: [180] [268800/1281167 (21%)]	Loss: 1.152494
[2022-06-12 20:23:35 | train] - Train Epoch: [180] [281600/1281167 (22%)]	Loss: 0.994621
[2022-06-12 20:23:57 | train] - Train Epoch: [180] [294400/1281167 (23%)]	Loss: 0.586610
[2022-06-12 20:24:19 | train] - Train Epoch: [180] [307200/1281167 (24%)]	Loss: 0.936858
[2022-06-12 20:24:42 | train] - Train Epoch: [180] [320000/1281167 (25%)]	Loss: 0.447187
[2022-06-12 20:25:03 | train] - Train Epoch: [180] [332800/1281167 (26%)]	Loss: 0.813205
[2022-06-12 20:25:25 | train] - Train Epoch: [180] [345600/1281167 (27%)]	Loss: 0.677109
[2022-06-12 20:25:47 | train] - Train Epoch: [180] [358400/1281167 (28%)]	Loss: 0.617548
[2022-06-12 20:26:10 | train] - Train Epoch: [180] [371200/1281167 (29%)]	Loss: 0.776710
[2022-06-12 20:26:32 | train] - Train Epoch: [180] [384000/1281167 (30%)]	Loss: 0.934463
[2022-06-12 20:26:54 | train] - Train Epoch: [180] [396800/1281167 (31%)]	Loss: 0.536598
[2022-06-12 20:27:17 | train] - Train Epoch: [180] [409600/1281167 (32%)]	Loss: 0.854486
[2022-06-12 20:27:38 | train] - Train Epoch: [180] [422400/1281167 (33%)]	Loss: 0.762785
[2022-06-12 20:27:59 | train] - Train Epoch: [180] [435200/1281167 (34%)]	Loss: 0.469727
[2022-06-12 20:28:22 | train] - Train Epoch: [180] [448000/1281167 (35%)]	Loss: 0.585359
[2022-06-12 20:28:44 | train] - Train Epoch: [180] [460800/1281167 (36%)]	Loss: 0.630012
[2022-06-12 20:29:06 | train] - Train Epoch: [180] [473600/1281167 (37%)]	Loss: 0.838830
[2022-06-12 20:29:29 | train] - Train Epoch: [180] [486400/1281167 (38%)]	Loss: 0.500008
[2022-06-12 20:29:51 | train] - Train Epoch: [180] [499200/1281167 (39%)]	Loss: 0.682106
[2022-06-12 20:30:14 | train] - Train Epoch: [180] [512000/1281167 (40%)]	Loss: 0.797313
[2022-06-12 20:30:36 | train] - Train Epoch: [180] [524800/1281167 (41%)]	Loss: 0.747863
[2022-06-12 20:30:58 | train] - Train Epoch: [180] [537600/1281167 (42%)]	Loss: 0.620055
[2022-06-12 20:31:21 | train] - Train Epoch: [180] [550400/1281167 (43%)]	Loss: 0.649723
[2022-06-12 20:31:42 | train] - Train Epoch: [180] [563200/1281167 (44%)]	Loss: 0.816760
[2022-06-12 20:32:05 | train] - Train Epoch: [180] [576000/1281167 (45%)]	Loss: 0.612293
[2022-06-12 20:32:26 | train] - Train Epoch: [180] [588800/1281167 (46%)]	Loss: 0.509340
[2022-06-12 20:32:48 | train] - Train Epoch: [180] [601600/1281167 (47%)]	Loss: 0.999399
[2022-06-12 20:33:11 | train] - Train Epoch: [180] [614400/1281167 (48%)]	Loss: 0.734308
[2022-06-12 20:33:33 | train] - Train Epoch: [180] [627200/1281167 (49%)]	Loss: 0.642228
[2022-06-12 20:33:55 | train] - Train Epoch: [180] [640000/1281167 (50%)]	Loss: 0.635731
[2022-06-12 20:34:17 | train] - Train Epoch: [180] [652800/1281167 (51%)]	Loss: 0.567956
[2022-06-12 20:34:39 | train] - Train Epoch: [180] [665600/1281167 (52%)]	Loss: 1.056582
[2022-06-12 20:35:01 | train] - Train Epoch: [180] [678400/1281167 (53%)]	Loss: 0.647618
[2022-06-12 20:35:23 | train] - Train Epoch: [180] [691200/1281167 (54%)]	Loss: 0.685439
[2022-06-12 20:35:46 | train] - Train Epoch: [180] [704000/1281167 (55%)]	Loss: 0.870143
[2022-06-12 20:36:08 | train] - Train Epoch: [180] [716800/1281167 (56%)]	Loss: 0.720183
[2022-06-12 20:36:30 | train] - Train Epoch: [180] [729600/1281167 (57%)]	Loss: 0.596352
[2022-06-12 20:36:53 | train] - Train Epoch: [180] [742400/1281167 (58%)]	Loss: 0.772583
[2022-06-12 20:37:15 | train] - Train Epoch: [180] [755200/1281167 (59%)]	Loss: 0.873901
[2022-06-12 20:37:38 | train] - Train Epoch: [180] [768000/1281167 (60%)]	Loss: 0.617474
[2022-06-12 20:38:01 | train] - Train Epoch: [180] [780800/1281167 (61%)]	Loss: 1.346945
[2022-06-12 20:38:23 | train] - Train Epoch: [180] [793600/1281167 (62%)]	Loss: 0.927036
[2022-06-12 20:38:45 | train] - Train Epoch: [180] [806400/1281167 (63%)]	Loss: 0.574925
[2022-06-12 20:39:09 | train] - Train Epoch: [180] [819200/1281167 (64%)]	Loss: 0.870084
[2022-06-12 20:39:31 | train] - Train Epoch: [180] [832000/1281167 (65%)]	Loss: 0.843739
[2022-06-12 20:39:54 | train] - Train Epoch: [180] [844800/1281167 (66%)]	Loss: 0.476125
[2022-06-12 20:40:17 | train] - Train Epoch: [180] [857600/1281167 (67%)]	Loss: 0.743875
[2022-06-12 20:40:39 | train] - Train Epoch: [180] [870400/1281167 (68%)]	Loss: 0.814373
[2022-06-12 20:41:01 | train] - Train Epoch: [180] [883200/1281167 (69%)]	Loss: 0.726640
[2022-06-12 20:41:24 | train] - Train Epoch: [180] [896000/1281167 (70%)]	Loss: 0.590867
[2022-06-12 20:41:46 | train] - Train Epoch: [180] [908800/1281167 (71%)]	Loss: 0.536590
[2022-06-12 20:42:08 | train] - Train Epoch: [180] [921600/1281167 (72%)]	Loss: 1.025094
[2022-06-12 20:42:29 | train] - Train Epoch: [180] [934400/1281167 (73%)]	Loss: 0.935934
[2022-06-12 20:42:52 | train] - Train Epoch: [180] [947200/1281167 (74%)]	Loss: 0.583308
[2022-06-12 20:43:14 | train] - Train Epoch: [180] [960000/1281167 (75%)]	Loss: 0.773008
[2022-06-12 20:43:36 | train] - Train Epoch: [180] [972800/1281167 (76%)]	Loss: 0.810211
[2022-06-12 20:43:58 | train] - Train Epoch: [180] [985600/1281167 (77%)]	Loss: 0.898305
[2022-06-12 20:44:20 | train] - Train Epoch: [180] [998400/1281167 (78%)]	Loss: 0.826117
[2022-06-12 20:44:42 | train] - Train Epoch: [180] [1011200/1281167 (79%)]	Loss: 0.521834
[2022-06-12 20:45:04 | train] - Train Epoch: [180] [1024000/1281167 (80%)]	Loss: 0.743190
[2022-06-12 20:45:26 | train] - Train Epoch: [180] [1036800/1281167 (81%)]	Loss: 0.961970
[2022-06-12 20:45:48 | train] - Train Epoch: [180] [1049600/1281167 (82%)]	Loss: 0.773807
[2022-06-12 20:46:11 | train] - Train Epoch: [180] [1062400/1281167 (83%)]	Loss: 0.816359
[2022-06-12 20:46:33 | train] - Train Epoch: [180] [1075200/1281167 (84%)]	Loss: 0.666684
[2022-06-12 20:46:55 | train] - Train Epoch: [180] [1088000/1281167 (85%)]	Loss: 0.660440
[2022-06-12 20:47:17 | train] - Train Epoch: [180] [1100800/1281167 (86%)]	Loss: 0.366914
[2022-06-12 20:47:39 | train] - Train Epoch: [180] [1113600/1281167 (87%)]	Loss: 0.653188
[2022-06-12 20:48:01 | train] - Train Epoch: [180] [1126400/1281167 (88%)]	Loss: 0.533830
[2022-06-12 20:48:24 | train] - Train Epoch: [180] [1139200/1281167 (89%)]	Loss: 0.734522
[2022-06-12 20:48:47 | train] - Train Epoch: [180] [1152000/1281167 (90%)]	Loss: 0.905492
[2022-06-12 20:49:09 | train] - Train Epoch: [180] [1164800/1281167 (91%)]	Loss: 0.856033
[2022-06-12 20:49:32 | train] - Train Epoch: [180] [1177600/1281167 (92%)]	Loss: 0.848330
[2022-06-12 20:49:55 | train] - Train Epoch: [180] [1190400/1281167 (93%)]	Loss: 0.727238
[2022-06-12 20:50:16 | train] - Train Epoch: [180] [1203200/1281167 (94%)]	Loss: 0.680857
[2022-06-12 20:50:38 | train] - Train Epoch: [180] [1216000/1281167 (95%)]	Loss: 0.821987
[2022-06-12 20:51:01 | train] - Train Epoch: [180] [1228800/1281167 (96%)]	Loss: 0.860785
[2022-06-12 20:51:23 | train] - Train Epoch: [180] [1241600/1281167 (97%)]	Loss: 0.771409
[2022-06-12 20:51:46 | train] - Train Epoch: [180] [1254400/1281167 (98%)]	Loss: 0.627385
[2022-06-12 20:52:08 | train] - Train Epoch: [180] [1267200/1281167 (99%)]	Loss: 0.534243
[2022-06-12 20:52:30 | train] - Train Epoch: [180] [1280000/1281167 (100%)]	Loss: 0.697498
[2022-06-12 20:52:32 | train] - Train Epoch: [180]	 Average Loss: 0.723151	 Total Acc : 82.3784	 Total Top5 Acc : 93.5940
[2022-06-12 20:52:32 | train] - -------180 epoch end-----------
========================================
-------180 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 20:54:06 | train] - 
Epoch [180] Test set: Average loss: 1.4287, Accuracy: 34988/50000 (69.9473%), Top-5 Accuracy: 88.9522%

[2022-06-12 20:54:06 | train] - save intermediate epoch [180] result


[2022-06-12 20:54:26 | train] - -------181 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 20:54:28 | train] - Train Epoch: [181] [0/1281167 (0%)]	Loss: 0.682769
[2022-06-12 20:54:50 | train] - Train Epoch: [181] [12800/1281167 (1%)]	Loss: 0.644660
[2022-06-12 20:55:11 | train] - Train Epoch: [181] [25600/1281167 (2%)]	Loss: 0.632442
[2022-06-12 20:55:33 | train] - Train Epoch: [181] [38400/1281167 (3%)]	Loss: 0.815418
[2022-06-12 20:55:54 | train] - Train Epoch: [181] [51200/1281167 (4%)]	Loss: 0.486260
[2022-06-12 20:56:16 | train] - Train Epoch: [181] [64000/1281167 (5%)]	Loss: 0.631441
[2022-06-12 20:56:38 | train] - Train Epoch: [181] [76800/1281167 (6%)]	Loss: 0.637570
[2022-06-12 20:56:59 | train] - Train Epoch: [181] [89600/1281167 (7%)]	Loss: 0.858876
[2022-06-12 20:57:21 | train] - Train Epoch: [181] [102400/1281167 (8%)]	Loss: 1.007497
[2022-06-12 20:57:43 | train] - Train Epoch: [181] [115200/1281167 (9%)]	Loss: 0.848939
[2022-06-12 20:58:05 | train] - Train Epoch: [181] [128000/1281167 (10%)]	Loss: 0.727979
[2022-06-12 20:58:26 | train] - Train Epoch: [181] [140800/1281167 (11%)]	Loss: 0.681061
[2022-06-12 20:58:48 | train] - Train Epoch: [181] [153600/1281167 (12%)]	Loss: 0.716911
[2022-06-12 20:59:10 | train] - Train Epoch: [181] [166400/1281167 (13%)]	Loss: 0.718027
[2022-06-12 20:59:31 | train] - Train Epoch: [181] [179200/1281167 (14%)]	Loss: 0.825231
[2022-06-12 20:59:52 | train] - Train Epoch: [181] [192000/1281167 (15%)]	Loss: 0.672985
[2022-06-12 21:00:14 | train] - Train Epoch: [181] [204800/1281167 (16%)]	Loss: 0.570534
[2022-06-12 21:00:36 | train] - Train Epoch: [181] [217600/1281167 (17%)]	Loss: 1.165738
[2022-06-12 21:00:58 | train] - Train Epoch: [181] [230400/1281167 (18%)]	Loss: 0.549982
[2022-06-12 21:01:20 | train] - Train Epoch: [181] [243200/1281167 (19%)]	Loss: 0.790308
[2022-06-12 21:01:41 | train] - Train Epoch: [181] [256000/1281167 (20%)]	Loss: 0.566060
[2022-06-12 21:02:03 | train] - Train Epoch: [181] [268800/1281167 (21%)]	Loss: 0.891643
[2022-06-12 21:02:25 | train] - Train Epoch: [181] [281600/1281167 (22%)]	Loss: 0.787823
[2022-06-12 21:02:46 | train] - Train Epoch: [181] [294400/1281167 (23%)]	Loss: 0.773182
[2022-06-12 21:03:07 | train] - Train Epoch: [181] [307200/1281167 (24%)]	Loss: 0.745782
[2022-06-12 21:03:29 | train] - Train Epoch: [181] [320000/1281167 (25%)]	Loss: 1.075486
[2022-06-12 21:03:49 | train] - Train Epoch: [181] [332800/1281167 (26%)]	Loss: 0.707306
[2022-06-12 21:04:11 | train] - Train Epoch: [181] [345600/1281167 (27%)]	Loss: 0.798856
[2022-06-12 21:04:32 | train] - Train Epoch: [181] [358400/1281167 (28%)]	Loss: 0.660859
[2022-06-12 21:04:53 | train] - Train Epoch: [181] [371200/1281167 (29%)]	Loss: 0.856551
[2022-06-12 21:05:14 | train] - Train Epoch: [181] [384000/1281167 (30%)]	Loss: 0.624909
[2022-06-12 21:05:36 | train] - Train Epoch: [181] [396800/1281167 (31%)]	Loss: 0.626027
[2022-06-12 21:05:56 | train] - Train Epoch: [181] [409600/1281167 (32%)]	Loss: 0.691005
[2022-06-12 21:06:17 | train] - Train Epoch: [181] [422400/1281167 (33%)]	Loss: 0.631485
[2022-06-12 21:06:39 | train] - Train Epoch: [181] [435200/1281167 (34%)]	Loss: 0.646044
[2022-06-12 21:07:00 | train] - Train Epoch: [181] [448000/1281167 (35%)]	Loss: 0.923427
[2022-06-12 21:07:22 | train] - Train Epoch: [181] [460800/1281167 (36%)]	Loss: 0.990769
[2022-06-12 21:07:43 | train] - Train Epoch: [181] [473600/1281167 (37%)]	Loss: 0.684781
[2022-06-12 21:08:04 | train] - Train Epoch: [181] [486400/1281167 (38%)]	Loss: 1.024238
[2022-06-12 21:08:25 | train] - Train Epoch: [181] [499200/1281167 (39%)]	Loss: 0.622334
[2022-06-12 21:08:45 | train] - Train Epoch: [181] [512000/1281167 (40%)]	Loss: 0.841161
[2022-06-12 21:09:06 | train] - Train Epoch: [181] [524800/1281167 (41%)]	Loss: 0.677795
[2022-06-12 21:09:26 | train] - Train Epoch: [181] [537600/1281167 (42%)]	Loss: 0.748075
[2022-06-12 21:09:47 | train] - Train Epoch: [181] [550400/1281167 (43%)]	Loss: 0.789334
[2022-06-12 21:10:09 | train] - Train Epoch: [181] [563200/1281167 (44%)]	Loss: 0.752660
[2022-06-12 21:10:30 | train] - Train Epoch: [181] [576000/1281167 (45%)]	Loss: 0.719549
[2022-06-12 21:10:51 | train] - Train Epoch: [181] [588800/1281167 (46%)]	Loss: 1.092695
[2022-06-12 21:11:11 | train] - Train Epoch: [181] [601600/1281167 (47%)]	Loss: 0.560412
[2022-06-12 21:11:32 | train] - Train Epoch: [181] [614400/1281167 (48%)]	Loss: 0.720915
[2022-06-12 21:11:54 | train] - Train Epoch: [181] [627200/1281167 (49%)]	Loss: 0.721293
[2022-06-12 21:12:14 | train] - Train Epoch: [181] [640000/1281167 (50%)]	Loss: 0.811470
[2022-06-12 21:12:35 | train] - Train Epoch: [181] [652800/1281167 (51%)]	Loss: 0.928350
[2022-06-12 21:12:56 | train] - Train Epoch: [181] [665600/1281167 (52%)]	Loss: 0.857394
[2022-06-12 21:13:17 | train] - Train Epoch: [181] [678400/1281167 (53%)]	Loss: 0.757612
[2022-06-12 21:13:38 | train] - Train Epoch: [181] [691200/1281167 (54%)]	Loss: 0.702129
[2022-06-12 21:13:59 | train] - Train Epoch: [181] [704000/1281167 (55%)]	Loss: 0.643630
[2022-06-12 21:14:20 | train] - Train Epoch: [181] [716800/1281167 (56%)]	Loss: 0.789435
[2022-06-12 21:14:40 | train] - Train Epoch: [181] [729600/1281167 (57%)]	Loss: 0.784581
[2022-06-12 21:15:00 | train] - Train Epoch: [181] [742400/1281167 (58%)]	Loss: 0.655842
[2022-06-12 21:15:21 | train] - Train Epoch: [181] [755200/1281167 (59%)]	Loss: 0.677981
[2022-06-12 21:15:42 | train] - Train Epoch: [181] [768000/1281167 (60%)]	Loss: 0.642000
[2022-06-12 21:16:02 | train] - Train Epoch: [181] [780800/1281167 (61%)]	Loss: 0.665090
[2022-06-12 21:16:23 | train] - Train Epoch: [181] [793600/1281167 (62%)]	Loss: 0.727283
[2022-06-12 21:16:43 | train] - Train Epoch: [181] [806400/1281167 (63%)]	Loss: 0.762613
[2022-06-12 21:17:04 | train] - Train Epoch: [181] [819200/1281167 (64%)]	Loss: 0.630857
[2022-06-12 21:17:25 | train] - Train Epoch: [181] [832000/1281167 (65%)]	Loss: 0.607560
[2022-06-12 21:17:44 | train] - Train Epoch: [181] [844800/1281167 (66%)]	Loss: 0.641833
[2022-06-12 21:18:05 | train] - Train Epoch: [181] [857600/1281167 (67%)]	Loss: 0.708729
[2022-06-12 21:18:26 | train] - Train Epoch: [181] [870400/1281167 (68%)]	Loss: 0.844231
[2022-06-12 21:18:48 | train] - Train Epoch: [181] [883200/1281167 (69%)]	Loss: 0.833989
[2022-06-12 21:19:08 | train] - Train Epoch: [181] [896000/1281167 (70%)]	Loss: 0.854896
[2022-06-12 21:19:28 | train] - Train Epoch: [181] [908800/1281167 (71%)]	Loss: 0.819823
[2022-06-12 21:19:50 | train] - Train Epoch: [181] [921600/1281167 (72%)]	Loss: 0.741921
[2022-06-12 21:20:10 | train] - Train Epoch: [181] [934400/1281167 (73%)]	Loss: 0.929563
[2022-06-12 21:20:31 | train] - Train Epoch: [181] [947200/1281167 (74%)]	Loss: 0.593360
[2022-06-12 21:20:51 | train] - Train Epoch: [181] [960000/1281167 (75%)]	Loss: 0.545761
[2022-06-12 21:21:12 | train] - Train Epoch: [181] [972800/1281167 (76%)]	Loss: 0.721920
[2022-06-12 21:21:33 | train] - Train Epoch: [181] [985600/1281167 (77%)]	Loss: 0.645897
[2022-06-12 21:21:52 | train] - Train Epoch: [181] [998400/1281167 (78%)]	Loss: 0.714575
[2022-06-12 21:22:12 | train] - Train Epoch: [181] [1011200/1281167 (79%)]	Loss: 0.771568
[2022-06-12 21:22:32 | train] - Train Epoch: [181] [1024000/1281167 (80%)]	Loss: 0.766061
[2022-06-12 21:22:53 | train] - Train Epoch: [181] [1036800/1281167 (81%)]	Loss: 0.625197
[2022-06-12 21:23:13 | train] - Train Epoch: [181] [1049600/1281167 (82%)]	Loss: 0.557718
[2022-06-12 21:23:34 | train] - Train Epoch: [181] [1062400/1281167 (83%)]	Loss: 0.805292
[2022-06-12 21:23:54 | train] - Train Epoch: [181] [1075200/1281167 (84%)]	Loss: 0.679520
[2022-06-12 21:24:14 | train] - Train Epoch: [181] [1088000/1281167 (85%)]	Loss: 0.575269
[2022-06-12 21:24:35 | train] - Train Epoch: [181] [1100800/1281167 (86%)]	Loss: 0.710495
[2022-06-12 21:24:55 | train] - Train Epoch: [181] [1113600/1281167 (87%)]	Loss: 0.900248
[2022-06-12 21:25:16 | train] - Train Epoch: [181] [1126400/1281167 (88%)]	Loss: 0.650249
[2022-06-12 21:25:38 | train] - Train Epoch: [181] [1139200/1281167 (89%)]	Loss: 0.698022
[2022-06-12 21:25:59 | train] - Train Epoch: [181] [1152000/1281167 (90%)]	Loss: 0.719477
[2022-06-12 21:26:21 | train] - Train Epoch: [181] [1164800/1281167 (91%)]	Loss: 0.650569
[2022-06-12 21:26:41 | train] - Train Epoch: [181] [1177600/1281167 (92%)]	Loss: 1.169160
[2022-06-12 21:27:01 | train] - Train Epoch: [181] [1190400/1281167 (93%)]	Loss: 0.593836
[2022-06-12 21:27:22 | train] - Train Epoch: [181] [1203200/1281167 (94%)]	Loss: 0.797507
[2022-06-12 21:27:43 | train] - Train Epoch: [181] [1216000/1281167 (95%)]	Loss: 0.800431
[2022-06-12 21:28:04 | train] - Train Epoch: [181] [1228800/1281167 (96%)]	Loss: 0.667327
[2022-06-12 21:28:25 | train] - Train Epoch: [181] [1241600/1281167 (97%)]	Loss: 0.666760
[2022-06-12 21:28:46 | train] - Train Epoch: [181] [1254400/1281167 (98%)]	Loss: 0.456050
[2022-06-12 21:29:08 | train] - Train Epoch: [181] [1267200/1281167 (99%)]	Loss: 0.617793
[2022-06-12 21:29:29 | train] - Train Epoch: [181] [1280000/1281167 (100%)]	Loss: 0.513990
[2022-06-12 21:29:30 | train] - Train Epoch: [181]	 Average Loss: 0.722612	 Total Acc : 82.4538	 Total Top5 Acc : 93.6169
[2022-06-12 21:29:30 | train] - -------181 epoch end-----------
========================================
-------181 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 21:31:04 | train] - 
Epoch [181] Test set: Average loss: 1.4357, Accuracy: 34961/50000 (69.8909%), Top-5 Accuracy: 89.0241%

[2022-06-12 21:31:04 | train] - save intermediate epoch [181] result


[2022-06-12 21:31:25 | train] - -------182 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 21:31:27 | train] - Train Epoch: [182] [0/1281167 (0%)]	Loss: 0.661673
[2022-06-12 21:31:48 | train] - Train Epoch: [182] [12800/1281167 (1%)]	Loss: 0.821595
[2022-06-12 21:32:09 | train] - Train Epoch: [182] [25600/1281167 (2%)]	Loss: 0.685303
[2022-06-12 21:32:29 | train] - Train Epoch: [182] [38400/1281167 (3%)]	Loss: 0.637028
[2022-06-12 21:32:49 | train] - Train Epoch: [182] [51200/1281167 (4%)]	Loss: 0.662484
[2022-06-12 21:33:09 | train] - Train Epoch: [182] [64000/1281167 (5%)]	Loss: 0.545180
[2022-06-12 21:33:31 | train] - Train Epoch: [182] [76800/1281167 (6%)]	Loss: 0.609999
[2022-06-12 21:33:50 | train] - Train Epoch: [182] [89600/1281167 (7%)]	Loss: 0.721482
[2022-06-12 21:34:12 | train] - Train Epoch: [182] [102400/1281167 (8%)]	Loss: 0.439459
[2022-06-12 21:34:32 | train] - Train Epoch: [182] [115200/1281167 (9%)]	Loss: 0.897404
[2022-06-12 21:34:52 | train] - Train Epoch: [182] [128000/1281167 (10%)]	Loss: 0.633509
[2022-06-12 21:35:13 | train] - Train Epoch: [182] [140800/1281167 (11%)]	Loss: 0.808228
[2022-06-12 21:35:34 | train] - Train Epoch: [182] [153600/1281167 (12%)]	Loss: 0.774715
[2022-06-12 21:35:54 | train] - Train Epoch: [182] [166400/1281167 (13%)]	Loss: 0.816100
[2022-06-12 21:36:15 | train] - Train Epoch: [182] [179200/1281167 (14%)]	Loss: 0.706152
[2022-06-12 21:36:36 | train] - Train Epoch: [182] [192000/1281167 (15%)]	Loss: 0.734981
[2022-06-12 21:36:57 | train] - Train Epoch: [182] [204800/1281167 (16%)]	Loss: 0.683415
[2022-06-12 21:37:18 | train] - Train Epoch: [182] [217600/1281167 (17%)]	Loss: 0.620427
[2022-06-12 21:37:39 | train] - Train Epoch: [182] [230400/1281167 (18%)]	Loss: 0.505730
[2022-06-12 21:38:00 | train] - Train Epoch: [182] [243200/1281167 (19%)]	Loss: 0.762383
[2022-06-12 21:38:21 | train] - Train Epoch: [182] [256000/1281167 (20%)]	Loss: 0.818944
[2022-06-12 21:38:42 | train] - Train Epoch: [182] [268800/1281167 (21%)]	Loss: 0.732016
[2022-06-12 21:39:04 | train] - Train Epoch: [182] [281600/1281167 (22%)]	Loss: 0.812549
[2022-06-12 21:39:24 | train] - Train Epoch: [182] [294400/1281167 (23%)]	Loss: 0.688847
[2022-06-12 21:39:45 | train] - Train Epoch: [182] [307200/1281167 (24%)]	Loss: 0.729970
[2022-06-12 21:40:06 | train] - Train Epoch: [182] [320000/1281167 (25%)]	Loss: 0.436818
[2022-06-12 21:40:28 | train] - Train Epoch: [182] [332800/1281167 (26%)]	Loss: 0.807145
[2022-06-12 21:40:49 | train] - Train Epoch: [182] [345600/1281167 (27%)]	Loss: 1.037405
[2022-06-12 21:41:10 | train] - Train Epoch: [182] [358400/1281167 (28%)]	Loss: 0.762252
[2022-06-12 21:41:31 | train] - Train Epoch: [182] [371200/1281167 (29%)]	Loss: 0.589991
[2022-06-12 21:41:53 | train] - Train Epoch: [182] [384000/1281167 (30%)]	Loss: 0.759656
[2022-06-12 21:42:14 | train] - Train Epoch: [182] [396800/1281167 (31%)]	Loss: 0.511169
[2022-06-12 21:42:34 | train] - Train Epoch: [182] [409600/1281167 (32%)]	Loss: 0.665386
[2022-06-12 21:42:55 | train] - Train Epoch: [182] [422400/1281167 (33%)]	Loss: 0.754139
[2022-06-12 21:43:15 | train] - Train Epoch: [182] [435200/1281167 (34%)]	Loss: 0.664499
[2022-06-12 21:43:36 | train] - Train Epoch: [182] [448000/1281167 (35%)]	Loss: 0.888027
[2022-06-12 21:43:57 | train] - Train Epoch: [182] [460800/1281167 (36%)]	Loss: 0.623910
[2022-06-12 21:44:19 | train] - Train Epoch: [182] [473600/1281167 (37%)]	Loss: 1.054746
[2022-06-12 21:44:40 | train] - Train Epoch: [182] [486400/1281167 (38%)]	Loss: 0.653449
[2022-06-12 21:45:00 | train] - Train Epoch: [182] [499200/1281167 (39%)]	Loss: 0.753679
[2022-06-12 21:45:22 | train] - Train Epoch: [182] [512000/1281167 (40%)]	Loss: 0.812501
[2022-06-12 21:45:43 | train] - Train Epoch: [182] [524800/1281167 (41%)]	Loss: 0.741889
[2022-06-12 21:46:05 | train] - Train Epoch: [182] [537600/1281167 (42%)]	Loss: 0.650894
[2022-06-12 21:46:25 | train] - Train Epoch: [182] [550400/1281167 (43%)]	Loss: 0.587264
[2022-06-12 21:46:46 | train] - Train Epoch: [182] [563200/1281167 (44%)]	Loss: 0.628378
[2022-06-12 21:47:07 | train] - Train Epoch: [182] [576000/1281167 (45%)]	Loss: 0.939272
[2022-06-12 21:47:28 | train] - Train Epoch: [182] [588800/1281167 (46%)]	Loss: 0.859393
[2022-06-12 21:47:49 | train] - Train Epoch: [182] [601600/1281167 (47%)]	Loss: 0.792735
[2022-06-12 21:48:10 | train] - Train Epoch: [182] [614400/1281167 (48%)]	Loss: 0.691599
[2022-06-12 21:48:31 | train] - Train Epoch: [182] [627200/1281167 (49%)]	Loss: 0.608575
[2022-06-12 21:48:51 | train] - Train Epoch: [182] [640000/1281167 (50%)]	Loss: 0.779351
[2022-06-12 21:49:12 | train] - Train Epoch: [182] [652800/1281167 (51%)]	Loss: 0.530813
[2022-06-12 21:49:33 | train] - Train Epoch: [182] [665600/1281167 (52%)]	Loss: 0.730927
[2022-06-12 21:49:55 | train] - Train Epoch: [182] [678400/1281167 (53%)]	Loss: 0.673178
[2022-06-12 21:50:16 | train] - Train Epoch: [182] [691200/1281167 (54%)]	Loss: 0.649015
[2022-06-12 21:50:36 | train] - Train Epoch: [182] [704000/1281167 (55%)]	Loss: 0.683627
[2022-06-12 21:50:56 | train] - Train Epoch: [182] [716800/1281167 (56%)]	Loss: 0.741858
[2022-06-12 21:51:18 | train] - Train Epoch: [182] [729600/1281167 (57%)]	Loss: 0.439325
[2022-06-12 21:51:39 | train] - Train Epoch: [182] [742400/1281167 (58%)]	Loss: 0.686194
[2022-06-12 21:52:00 | train] - Train Epoch: [182] [755200/1281167 (59%)]	Loss: 0.758765
[2022-06-12 21:52:21 | train] - Train Epoch: [182] [768000/1281167 (60%)]	Loss: 0.601004
[2022-06-12 21:52:42 | train] - Train Epoch: [182] [780800/1281167 (61%)]	Loss: 0.740706
[2022-06-12 21:53:02 | train] - Train Epoch: [182] [793600/1281167 (62%)]	Loss: 0.790787
[2022-06-12 21:53:23 | train] - Train Epoch: [182] [806400/1281167 (63%)]	Loss: 1.039696
[2022-06-12 21:53:45 | train] - Train Epoch: [182] [819200/1281167 (64%)]	Loss: 0.834090
[2022-06-12 21:54:04 | train] - Train Epoch: [182] [832000/1281167 (65%)]	Loss: 0.598680
[2022-06-12 21:54:26 | train] - Train Epoch: [182] [844800/1281167 (66%)]	Loss: 0.491753
[2022-06-12 21:54:46 | train] - Train Epoch: [182] [857600/1281167 (67%)]	Loss: 0.796205
[2022-06-12 21:55:06 | train] - Train Epoch: [182] [870400/1281167 (68%)]	Loss: 0.697483
[2022-06-12 21:55:26 | train] - Train Epoch: [182] [883200/1281167 (69%)]	Loss: 0.689273
[2022-06-12 21:55:47 | train] - Train Epoch: [182] [896000/1281167 (70%)]	Loss: 0.766592
[2022-06-12 21:56:07 | train] - Train Epoch: [182] [908800/1281167 (71%)]	Loss: 0.873167
[2022-06-12 21:56:28 | train] - Train Epoch: [182] [921600/1281167 (72%)]	Loss: 0.734925
[2022-06-12 21:56:50 | train] - Train Epoch: [182] [934400/1281167 (73%)]	Loss: 0.768810
[2022-06-12 21:57:10 | train] - Train Epoch: [182] [947200/1281167 (74%)]	Loss: 1.081663
[2022-06-12 21:57:31 | train] - Train Epoch: [182] [960000/1281167 (75%)]	Loss: 0.697088
[2022-06-12 21:57:51 | train] - Train Epoch: [182] [972800/1281167 (76%)]	Loss: 0.575315
[2022-06-12 21:58:11 | train] - Train Epoch: [182] [985600/1281167 (77%)]	Loss: 0.639096
[2022-06-12 21:58:32 | train] - Train Epoch: [182] [998400/1281167 (78%)]	Loss: 0.510352
[2022-06-12 21:58:53 | train] - Train Epoch: [182] [1011200/1281167 (79%)]	Loss: 0.975297
[2022-06-12 21:59:14 | train] - Train Epoch: [182] [1024000/1281167 (80%)]	Loss: 0.675890
[2022-06-12 21:59:34 | train] - Train Epoch: [182] [1036800/1281167 (81%)]	Loss: 1.024500
[2022-06-12 21:59:54 | train] - Train Epoch: [182] [1049600/1281167 (82%)]	Loss: 0.714440
[2022-06-12 22:00:14 | train] - Train Epoch: [182] [1062400/1281167 (83%)]	Loss: 0.624422
[2022-06-12 22:00:35 | train] - Train Epoch: [182] [1075200/1281167 (84%)]	Loss: 0.731568
[2022-06-12 22:00:55 | train] - Train Epoch: [182] [1088000/1281167 (85%)]	Loss: 0.663925
[2022-06-12 22:01:16 | train] - Train Epoch: [182] [1100800/1281167 (86%)]	Loss: 0.850249
[2022-06-12 22:01:35 | train] - Train Epoch: [182] [1113600/1281167 (87%)]	Loss: 0.456685
[2022-06-12 22:01:55 | train] - Train Epoch: [182] [1126400/1281167 (88%)]	Loss: 0.881795
[2022-06-12 22:02:16 | train] - Train Epoch: [182] [1139200/1281167 (89%)]	Loss: 0.707882
[2022-06-12 22:02:38 | train] - Train Epoch: [182] [1152000/1281167 (90%)]	Loss: 0.917903
[2022-06-12 22:02:58 | train] - Train Epoch: [182] [1164800/1281167 (91%)]	Loss: 0.513711
[2022-06-12 22:03:19 | train] - Train Epoch: [182] [1177600/1281167 (92%)]	Loss: 1.088765
[2022-06-12 22:03:39 | train] - Train Epoch: [182] [1190400/1281167 (93%)]	Loss: 0.746035
[2022-06-12 22:03:59 | train] - Train Epoch: [182] [1203200/1281167 (94%)]	Loss: 0.926463
[2022-06-12 22:04:19 | train] - Train Epoch: [182] [1216000/1281167 (95%)]	Loss: 0.547205
[2022-06-12 22:04:39 | train] - Train Epoch: [182] [1228800/1281167 (96%)]	Loss: 0.751090
[2022-06-12 22:04:58 | train] - Train Epoch: [182] [1241600/1281167 (97%)]	Loss: 0.866531
[2022-06-12 22:05:19 | train] - Train Epoch: [182] [1254400/1281167 (98%)]	Loss: 0.550850
[2022-06-12 22:05:39 | train] - Train Epoch: [182] [1267200/1281167 (99%)]	Loss: 0.801352
[2022-06-12 22:05:59 | train] - Train Epoch: [182] [1280000/1281167 (100%)]	Loss: 0.756512
[2022-06-12 22:06:01 | train] - Train Epoch: [182]	 Average Loss: 0.722461	 Total Acc : 82.4561	 Total Top5 Acc : 93.6394
[2022-06-12 22:06:01 | train] - -------182 epoch end-----------
========================================
-------182 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 22:07:31 | train] - 
Epoch [182] Test set: Average loss: 1.4335, Accuracy: 34926/50000 (69.8234%), Top-5 Accuracy: 88.9362%

[2022-06-12 22:07:31 | train] - save intermediate epoch [182] result


[2022-06-12 22:07:54 | train] - -------183 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 22:07:56 | train] - Train Epoch: [183] [0/1281167 (0%)]	Loss: 0.869125
[2022-06-12 22:08:17 | train] - Train Epoch: [183] [12800/1281167 (1%)]	Loss: 0.556665
[2022-06-12 22:08:37 | train] - Train Epoch: [183] [25600/1281167 (2%)]	Loss: 0.697466
[2022-06-12 22:08:57 | train] - Train Epoch: [183] [38400/1281167 (3%)]	Loss: 0.701876
[2022-06-12 22:09:17 | train] - Train Epoch: [183] [51200/1281167 (4%)]	Loss: 0.564888
[2022-06-12 22:09:37 | train] - Train Epoch: [183] [64000/1281167 (5%)]	Loss: 0.670557
[2022-06-12 22:09:55 | train] - Train Epoch: [183] [76800/1281167 (6%)]	Loss: 0.781191
[2022-06-12 22:10:16 | train] - Train Epoch: [183] [89600/1281167 (7%)]	Loss: 0.579529
[2022-06-12 22:10:35 | train] - Train Epoch: [183] [102400/1281167 (8%)]	Loss: 0.630817
[2022-06-12 22:10:56 | train] - Train Epoch: [183] [115200/1281167 (9%)]	Loss: 0.743949
[2022-06-12 22:11:16 | train] - Train Epoch: [183] [128000/1281167 (10%)]	Loss: 0.606012
[2022-06-12 22:11:36 | train] - Train Epoch: [183] [140800/1281167 (11%)]	Loss: 0.737989
[2022-06-12 22:11:57 | train] - Train Epoch: [183] [153600/1281167 (12%)]	Loss: 0.704133
[2022-06-12 22:12:18 | train] - Train Epoch: [183] [166400/1281167 (13%)]	Loss: 0.675748
[2022-06-12 22:12:39 | train] - Train Epoch: [183] [179200/1281167 (14%)]	Loss: 0.651800
[2022-06-12 22:12:59 | train] - Train Epoch: [183] [192000/1281167 (15%)]	Loss: 0.921133
[2022-06-12 22:13:19 | train] - Train Epoch: [183] [204800/1281167 (16%)]	Loss: 1.031524
[2022-06-12 22:13:39 | train] - Train Epoch: [183] [217600/1281167 (17%)]	Loss: 0.519589
[2022-06-12 22:13:59 | train] - Train Epoch: [183] [230400/1281167 (18%)]	Loss: 0.584042
[2022-06-12 22:14:20 | train] - Train Epoch: [183] [243200/1281167 (19%)]	Loss: 0.684198
[2022-06-12 22:14:41 | train] - Train Epoch: [183] [256000/1281167 (20%)]	Loss: 0.908457
[2022-06-12 22:15:02 | train] - Train Epoch: [183] [268800/1281167 (21%)]	Loss: 0.661931
[2022-06-12 22:15:22 | train] - Train Epoch: [183] [281600/1281167 (22%)]	Loss: 0.787166
[2022-06-12 22:15:43 | train] - Train Epoch: [183] [294400/1281167 (23%)]	Loss: 0.559499
[2022-06-12 22:16:04 | train] - Train Epoch: [183] [307200/1281167 (24%)]	Loss: 0.826791
[2022-06-12 22:16:24 | train] - Train Epoch: [183] [320000/1281167 (25%)]	Loss: 0.757980
[2022-06-12 22:16:44 | train] - Train Epoch: [183] [332800/1281167 (26%)]	Loss: 1.007164
[2022-06-12 22:17:04 | train] - Train Epoch: [183] [345600/1281167 (27%)]	Loss: 0.877712
[2022-06-12 22:17:25 | train] - Train Epoch: [183] [358400/1281167 (28%)]	Loss: 0.595007
[2022-06-12 22:17:45 | train] - Train Epoch: [183] [371200/1281167 (29%)]	Loss: 0.838328
[2022-06-12 22:18:06 | train] - Train Epoch: [183] [384000/1281167 (30%)]	Loss: 0.675912
[2022-06-12 22:18:27 | train] - Train Epoch: [183] [396800/1281167 (31%)]	Loss: 0.621511
[2022-06-12 22:18:48 | train] - Train Epoch: [183] [409600/1281167 (32%)]	Loss: 0.727339
[2022-06-12 22:19:09 | train] - Train Epoch: [183] [422400/1281167 (33%)]	Loss: 0.531498
[2022-06-12 22:19:29 | train] - Train Epoch: [183] [435200/1281167 (34%)]	Loss: 0.510491
[2022-06-12 22:19:48 | train] - Train Epoch: [183] [448000/1281167 (35%)]	Loss: 0.723884
[2022-06-12 22:20:08 | train] - Train Epoch: [183] [460800/1281167 (36%)]	Loss: 0.450315
[2022-06-12 22:20:29 | train] - Train Epoch: [183] [473600/1281167 (37%)]	Loss: 0.598222
[2022-06-12 22:20:51 | train] - Train Epoch: [183] [486400/1281167 (38%)]	Loss: 0.830295
[2022-06-12 22:21:12 | train] - Train Epoch: [183] [499200/1281167 (39%)]	Loss: 0.741820
[2022-06-12 22:21:32 | train] - Train Epoch: [183] [512000/1281167 (40%)]	Loss: 0.643551
[2022-06-12 22:21:53 | train] - Train Epoch: [183] [524800/1281167 (41%)]	Loss: 0.743157
[2022-06-12 22:22:13 | train] - Train Epoch: [183] [537600/1281167 (42%)]	Loss: 0.602387
[2022-06-12 22:22:33 | train] - Train Epoch: [183] [550400/1281167 (43%)]	Loss: 0.972760
[2022-06-12 22:22:53 | train] - Train Epoch: [183] [563200/1281167 (44%)]	Loss: 0.733418
[2022-06-12 22:23:14 | train] - Train Epoch: [183] [576000/1281167 (45%)]	Loss: 0.708642
[2022-06-12 22:23:34 | train] - Train Epoch: [183] [588800/1281167 (46%)]	Loss: 0.862342
[2022-06-12 22:23:55 | train] - Train Epoch: [183] [601600/1281167 (47%)]	Loss: 0.976070
[2022-06-12 22:24:15 | train] - Train Epoch: [183] [614400/1281167 (48%)]	Loss: 0.784865
[2022-06-12 22:24:35 | train] - Train Epoch: [183] [627200/1281167 (49%)]	Loss: 0.549166
[2022-06-12 22:24:55 | train] - Train Epoch: [183] [640000/1281167 (50%)]	Loss: 0.633780
[2022-06-12 22:25:16 | train] - Train Epoch: [183] [652800/1281167 (51%)]	Loss: 0.870423
[2022-06-12 22:25:37 | train] - Train Epoch: [183] [665600/1281167 (52%)]	Loss: 0.702036
[2022-06-12 22:25:56 | train] - Train Epoch: [183] [678400/1281167 (53%)]	Loss: 0.556672
[2022-06-12 22:26:17 | train] - Train Epoch: [183] [691200/1281167 (54%)]	Loss: 0.846921
[2022-06-12 22:26:37 | train] - Train Epoch: [183] [704000/1281167 (55%)]	Loss: 0.559353
[2022-06-12 22:26:59 | train] - Train Epoch: [183] [716800/1281167 (56%)]	Loss: 0.612303
[2022-06-12 22:27:19 | train] - Train Epoch: [183] [729600/1281167 (57%)]	Loss: 0.791536
[2022-06-12 22:27:40 | train] - Train Epoch: [183] [742400/1281167 (58%)]	Loss: 0.823794
[2022-06-12 22:27:59 | train] - Train Epoch: [183] [755200/1281167 (59%)]	Loss: 0.878881
[2022-06-12 22:28:19 | train] - Train Epoch: [183] [768000/1281167 (60%)]	Loss: 0.749336
[2022-06-12 22:28:41 | train] - Train Epoch: [183] [780800/1281167 (61%)]	Loss: 0.664813
[2022-06-12 22:29:01 | train] - Train Epoch: [183] [793600/1281167 (62%)]	Loss: 0.743049
[2022-06-12 22:29:21 | train] - Train Epoch: [183] [806400/1281167 (63%)]	Loss: 0.679249
[2022-06-12 22:29:42 | train] - Train Epoch: [183] [819200/1281167 (64%)]	Loss: 0.840480
[2022-06-12 22:30:02 | train] - Train Epoch: [183] [832000/1281167 (65%)]	Loss: 0.802485
[2022-06-12 22:30:22 | train] - Train Epoch: [183] [844800/1281167 (66%)]	Loss: 1.001614
[2022-06-12 22:30:42 | train] - Train Epoch: [183] [857600/1281167 (67%)]	Loss: 0.737121
[2022-06-12 22:31:03 | train] - Train Epoch: [183] [870400/1281167 (68%)]	Loss: 0.690412
[2022-06-12 22:31:24 | train] - Train Epoch: [183] [883200/1281167 (69%)]	Loss: 0.696232
[2022-06-12 22:31:44 | train] - Train Epoch: [183] [896000/1281167 (70%)]	Loss: 0.700960
[2022-06-12 22:32:04 | train] - Train Epoch: [183] [908800/1281167 (71%)]	Loss: 0.483594
[2022-06-12 22:32:25 | train] - Train Epoch: [183] [921600/1281167 (72%)]	Loss: 0.642680
[2022-06-12 22:32:46 | train] - Train Epoch: [183] [934400/1281167 (73%)]	Loss: 0.846716
[2022-06-12 22:33:06 | train] - Train Epoch: [183] [947200/1281167 (74%)]	Loss: 0.798721
[2022-06-12 22:33:28 | train] - Train Epoch: [183] [960000/1281167 (75%)]	Loss: 0.813778
[2022-06-12 22:33:48 | train] - Train Epoch: [183] [972800/1281167 (76%)]	Loss: 0.923063
[2022-06-12 22:34:08 | train] - Train Epoch: [183] [985600/1281167 (77%)]	Loss: 0.569415
[2022-06-12 22:34:28 | train] - Train Epoch: [183] [998400/1281167 (78%)]	Loss: 0.794422
[2022-06-12 22:34:49 | train] - Train Epoch: [183] [1011200/1281167 (79%)]	Loss: 0.616313
[2022-06-12 22:35:09 | train] - Train Epoch: [183] [1024000/1281167 (80%)]	Loss: 0.737842
[2022-06-12 22:35:31 | train] - Train Epoch: [183] [1036800/1281167 (81%)]	Loss: 0.686418
[2022-06-12 22:35:52 | train] - Train Epoch: [183] [1049600/1281167 (82%)]	Loss: 0.697349
[2022-06-12 22:36:12 | train] - Train Epoch: [183] [1062400/1281167 (83%)]	Loss: 0.753092
[2022-06-12 22:36:32 | train] - Train Epoch: [183] [1075200/1281167 (84%)]	Loss: 0.686270
[2022-06-12 22:36:52 | train] - Train Epoch: [183] [1088000/1281167 (85%)]	Loss: 0.550413
[2022-06-12 22:37:12 | train] - Train Epoch: [183] [1100800/1281167 (86%)]	Loss: 0.524471
[2022-06-12 22:37:34 | train] - Train Epoch: [183] [1113600/1281167 (87%)]	Loss: 0.781424
[2022-06-12 22:37:55 | train] - Train Epoch: [183] [1126400/1281167 (88%)]	Loss: 0.669960
[2022-06-12 22:38:15 | train] - Train Epoch: [183] [1139200/1281167 (89%)]	Loss: 0.443789
[2022-06-12 22:38:35 | train] - Train Epoch: [183] [1152000/1281167 (90%)]	Loss: 0.800594
[2022-06-12 22:38:55 | train] - Train Epoch: [183] [1164800/1281167 (91%)]	Loss: 0.618808
[2022-06-12 22:39:15 | train] - Train Epoch: [183] [1177600/1281167 (92%)]	Loss: 0.616990
[2022-06-12 22:39:36 | train] - Train Epoch: [183] [1190400/1281167 (93%)]	Loss: 0.769129
[2022-06-12 22:39:56 | train] - Train Epoch: [183] [1203200/1281167 (94%)]	Loss: 0.602927
[2022-06-12 22:40:17 | train] - Train Epoch: [183] [1216000/1281167 (95%)]	Loss: 0.610448
[2022-06-12 22:40:37 | train] - Train Epoch: [183] [1228800/1281167 (96%)]	Loss: 0.703632
[2022-06-12 22:40:57 | train] - Train Epoch: [183] [1241600/1281167 (97%)]	Loss: 0.705873
[2022-06-12 22:41:18 | train] - Train Epoch: [183] [1254400/1281167 (98%)]	Loss: 0.680164
[2022-06-12 22:41:38 | train] - Train Epoch: [183] [1267200/1281167 (99%)]	Loss: 0.983985
[2022-06-12 22:41:58 | train] - Train Epoch: [183] [1280000/1281167 (100%)]	Loss: 0.747855
[2022-06-12 22:42:00 | train] - Train Epoch: [183]	 Average Loss: 0.723345	 Total Acc : 82.4501	 Total Top5 Acc : 93.6197
[2022-06-12 22:42:00 | train] - -------183 epoch end-----------
========================================
-------183 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 22:43:31 | train] - 
Epoch [183] Test set: Average loss: 1.4321, Accuracy: 34931/50000 (69.8346%), Top-5 Accuracy: 88.9502%

[2022-06-12 22:43:31 | train] - save intermediate epoch [183] result


[2022-06-12 22:43:53 | train] - -------184 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 22:43:55 | train] - Train Epoch: [184] [0/1281167 (0%)]	Loss: 0.922238
[2022-06-12 22:44:16 | train] - Train Epoch: [184] [12800/1281167 (1%)]	Loss: 0.673045
[2022-06-12 22:44:36 | train] - Train Epoch: [184] [25600/1281167 (2%)]	Loss: 0.853101
[2022-06-12 22:44:58 | train] - Train Epoch: [184] [38400/1281167 (3%)]	Loss: 0.524135
[2022-06-12 22:45:18 | train] - Train Epoch: [184] [51200/1281167 (4%)]	Loss: 0.650770
[2022-06-12 22:45:38 | train] - Train Epoch: [184] [64000/1281167 (5%)]	Loss: 0.543930
[2022-06-12 22:45:59 | train] - Train Epoch: [184] [76800/1281167 (6%)]	Loss: 0.859679
[2022-06-12 22:46:21 | train] - Train Epoch: [184] [89600/1281167 (7%)]	Loss: 0.859792
[2022-06-12 22:46:42 | train] - Train Epoch: [184] [102400/1281167 (8%)]	Loss: 0.724154
[2022-06-12 22:47:03 | train] - Train Epoch: [184] [115200/1281167 (9%)]	Loss: 1.102561
[2022-06-12 22:47:23 | train] - Train Epoch: [184] [128000/1281167 (10%)]	Loss: 0.785905
[2022-06-12 22:47:44 | train] - Train Epoch: [184] [140800/1281167 (11%)]	Loss: 0.724351
[2022-06-12 22:48:05 | train] - Train Epoch: [184] [153600/1281167 (12%)]	Loss: 0.644303
[2022-06-12 22:48:26 | train] - Train Epoch: [184] [166400/1281167 (13%)]	Loss: 0.704539
[2022-06-12 22:48:46 | train] - Train Epoch: [184] [179200/1281167 (14%)]	Loss: 0.709816
[2022-06-12 22:49:07 | train] - Train Epoch: [184] [192000/1281167 (15%)]	Loss: 0.793194
[2022-06-12 22:49:27 | train] - Train Epoch: [184] [204800/1281167 (16%)]	Loss: 0.676062
[2022-06-12 22:49:48 | train] - Train Epoch: [184] [217600/1281167 (17%)]	Loss: 0.603706
[2022-06-12 22:50:09 | train] - Train Epoch: [184] [230400/1281167 (18%)]	Loss: 0.691090
[2022-06-12 22:50:31 | train] - Train Epoch: [184] [243200/1281167 (19%)]	Loss: 0.725808
[2022-06-12 22:50:52 | train] - Train Epoch: [184] [256000/1281167 (20%)]	Loss: 0.788352
[2022-06-12 22:51:13 | train] - Train Epoch: [184] [268800/1281167 (21%)]	Loss: 0.754540
[2022-06-12 22:51:33 | train] - Train Epoch: [184] [281600/1281167 (22%)]	Loss: 0.964534
[2022-06-12 22:51:53 | train] - Train Epoch: [184] [294400/1281167 (23%)]	Loss: 0.706794
[2022-06-12 22:52:14 | train] - Train Epoch: [184] [307200/1281167 (24%)]	Loss: 0.798947
[2022-06-12 22:52:34 | train] - Train Epoch: [184] [320000/1281167 (25%)]	Loss: 0.796466
[2022-06-12 22:52:56 | train] - Train Epoch: [184] [332800/1281167 (26%)]	Loss: 0.742315
[2022-06-12 22:53:18 | train] - Train Epoch: [184] [345600/1281167 (27%)]	Loss: 0.689811
[2022-06-12 22:53:38 | train] - Train Epoch: [184] [358400/1281167 (28%)]	Loss: 0.859900
[2022-06-12 22:53:59 | train] - Train Epoch: [184] [371200/1281167 (29%)]	Loss: 0.687863
[2022-06-12 22:54:19 | train] - Train Epoch: [184] [384000/1281167 (30%)]	Loss: 0.639360
[2022-06-12 22:54:40 | train] - Train Epoch: [184] [396800/1281167 (31%)]	Loss: 0.823869
[2022-06-12 22:55:01 | train] - Train Epoch: [184] [409600/1281167 (32%)]	Loss: 0.762422
[2022-06-12 22:55:22 | train] - Train Epoch: [184] [422400/1281167 (33%)]	Loss: 0.772803
[2022-06-12 22:55:42 | train] - Train Epoch: [184] [435200/1281167 (34%)]	Loss: 0.679179
[2022-06-12 22:56:04 | train] - Train Epoch: [184] [448000/1281167 (35%)]	Loss: 0.954559
[2022-06-12 22:56:26 | train] - Train Epoch: [184] [460800/1281167 (36%)]	Loss: 0.878973
[2022-06-12 22:56:48 | train] - Train Epoch: [184] [473600/1281167 (37%)]	Loss: 0.732667
[2022-06-12 22:57:10 | train] - Train Epoch: [184] [486400/1281167 (38%)]	Loss: 0.666001
[2022-06-12 22:57:31 | train] - Train Epoch: [184] [499200/1281167 (39%)]	Loss: 0.858823
[2022-06-12 22:57:52 | train] - Train Epoch: [184] [512000/1281167 (40%)]	Loss: 0.871880
[2022-06-12 22:58:12 | train] - Train Epoch: [184] [524800/1281167 (41%)]	Loss: 0.530683
[2022-06-12 22:58:32 | train] - Train Epoch: [184] [537600/1281167 (42%)]	Loss: 0.568549
[2022-06-12 22:58:53 | train] - Train Epoch: [184] [550400/1281167 (43%)]	Loss: 0.884343
[2022-06-12 22:59:14 | train] - Train Epoch: [184] [563200/1281167 (44%)]	Loss: 0.688899
[2022-06-12 22:59:34 | train] - Train Epoch: [184] [576000/1281167 (45%)]	Loss: 0.637297
[2022-06-12 22:59:55 | train] - Train Epoch: [184] [588800/1281167 (46%)]	Loss: 0.784374
[2022-06-12 23:00:16 | train] - Train Epoch: [184] [601600/1281167 (47%)]	Loss: 0.940398
[2022-06-12 23:00:37 | train] - Train Epoch: [184] [614400/1281167 (48%)]	Loss: 0.704839
[2022-06-12 23:00:59 | train] - Train Epoch: [184] [627200/1281167 (49%)]	Loss: 0.908814
[2022-06-12 23:01:19 | train] - Train Epoch: [184] [640000/1281167 (50%)]	Loss: 0.702536
[2022-06-12 23:01:39 | train] - Train Epoch: [184] [652800/1281167 (51%)]	Loss: 0.452477
[2022-06-12 23:02:00 | train] - Train Epoch: [184] [665600/1281167 (52%)]	Loss: 0.489916
[2022-06-12 23:02:22 | train] - Train Epoch: [184] [678400/1281167 (53%)]	Loss: 0.715636
[2022-06-12 23:02:44 | train] - Train Epoch: [184] [691200/1281167 (54%)]	Loss: 0.616671
[2022-06-12 23:03:05 | train] - Train Epoch: [184] [704000/1281167 (55%)]	Loss: 0.478981
[2022-06-12 23:03:27 | train] - Train Epoch: [184] [716800/1281167 (56%)]	Loss: 0.702517
[2022-06-12 23:03:48 | train] - Train Epoch: [184] [729600/1281167 (57%)]	Loss: 0.488696
[2022-06-12 23:04:09 | train] - Train Epoch: [184] [742400/1281167 (58%)]	Loss: 1.041851
[2022-06-12 23:04:30 | train] - Train Epoch: [184] [755200/1281167 (59%)]	Loss: 0.646755
[2022-06-12 23:04:50 | train] - Train Epoch: [184] [768000/1281167 (60%)]	Loss: 0.628612
[2022-06-12 23:05:09 | train] - Train Epoch: [184] [780800/1281167 (61%)]	Loss: 0.914487
[2022-06-12 23:05:30 | train] - Train Epoch: [184] [793600/1281167 (62%)]	Loss: 0.579750
[2022-06-12 23:05:51 | train] - Train Epoch: [184] [806400/1281167 (63%)]	Loss: 0.853425
[2022-06-12 23:06:13 | train] - Train Epoch: [184] [819200/1281167 (64%)]	Loss: 0.951498
[2022-06-12 23:06:34 | train] - Train Epoch: [184] [832000/1281167 (65%)]	Loss: 0.752383
[2022-06-12 23:06:54 | train] - Train Epoch: [184] [844800/1281167 (66%)]	Loss: 0.510317
[2022-06-12 23:07:15 | train] - Train Epoch: [184] [857600/1281167 (67%)]	Loss: 0.510790
[2022-06-12 23:07:35 | train] - Train Epoch: [184] [870400/1281167 (68%)]	Loss: 0.758576
[2022-06-12 23:07:55 | train] - Train Epoch: [184] [883200/1281167 (69%)]	Loss: 0.581653
[2022-06-12 23:08:16 | train] - Train Epoch: [184] [896000/1281167 (70%)]	Loss: 0.769205
[2022-06-12 23:08:38 | train] - Train Epoch: [184] [908800/1281167 (71%)]	Loss: 0.765029
[2022-06-12 23:08:58 | train] - Train Epoch: [184] [921600/1281167 (72%)]	Loss: 0.720550
[2022-06-12 23:09:18 | train] - Train Epoch: [184] [934400/1281167 (73%)]	Loss: 0.840247
[2022-06-12 23:09:38 | train] - Train Epoch: [184] [947200/1281167 (74%)]	Loss: 0.994108
[2022-06-12 23:10:00 | train] - Train Epoch: [184] [960000/1281167 (75%)]	Loss: 0.839247
[2022-06-12 23:10:21 | train] - Train Epoch: [184] [972800/1281167 (76%)]	Loss: 0.758909
[2022-06-12 23:10:42 | train] - Train Epoch: [184] [985600/1281167 (77%)]	Loss: 0.671205
[2022-06-12 23:11:02 | train] - Train Epoch: [184] [998400/1281167 (78%)]	Loss: 0.757232
[2022-06-12 23:11:22 | train] - Train Epoch: [184] [1011200/1281167 (79%)]	Loss: 0.796275
[2022-06-12 23:11:44 | train] - Train Epoch: [184] [1024000/1281167 (80%)]	Loss: 0.781531
[2022-06-12 23:12:04 | train] - Train Epoch: [184] [1036800/1281167 (81%)]	Loss: 0.638657
[2022-06-12 23:12:25 | train] - Train Epoch: [184] [1049600/1281167 (82%)]	Loss: 1.115447
[2022-06-12 23:12:46 | train] - Train Epoch: [184] [1062400/1281167 (83%)]	Loss: 0.852757
[2022-06-12 23:13:06 | train] - Train Epoch: [184] [1075200/1281167 (84%)]	Loss: 0.634833
[2022-06-12 23:13:28 | train] - Train Epoch: [184] [1088000/1281167 (85%)]	Loss: 0.808350
[2022-06-12 23:13:49 | train] - Train Epoch: [184] [1100800/1281167 (86%)]	Loss: 0.564222
[2022-06-12 23:14:10 | train] - Train Epoch: [184] [1113600/1281167 (87%)]	Loss: 0.745103
[2022-06-12 23:14:31 | train] - Train Epoch: [184] [1126400/1281167 (88%)]	Loss: 0.686923
[2022-06-12 23:14:52 | train] - Train Epoch: [184] [1139200/1281167 (89%)]	Loss: 0.622196
[2022-06-12 23:15:12 | train] - Train Epoch: [184] [1152000/1281167 (90%)]	Loss: 0.715231
[2022-06-12 23:15:32 | train] - Train Epoch: [184] [1164800/1281167 (91%)]	Loss: 0.667174
[2022-06-12 23:15:52 | train] - Train Epoch: [184] [1177600/1281167 (92%)]	Loss: 0.664719
[2022-06-12 23:16:12 | train] - Train Epoch: [184] [1190400/1281167 (93%)]	Loss: 0.675114
[2022-06-12 23:16:33 | train] - Train Epoch: [184] [1203200/1281167 (94%)]	Loss: 0.809419
[2022-06-12 23:16:53 | train] - Train Epoch: [184] [1216000/1281167 (95%)]	Loss: 1.027909
[2022-06-12 23:17:14 | train] - Train Epoch: [184] [1228800/1281167 (96%)]	Loss: 0.548285
[2022-06-12 23:17:34 | train] - Train Epoch: [184] [1241600/1281167 (97%)]	Loss: 0.783420
[2022-06-12 23:17:55 | train] - Train Epoch: [184] [1254400/1281167 (98%)]	Loss: 0.621055
[2022-06-12 23:18:15 | train] - Train Epoch: [184] [1267200/1281167 (99%)]	Loss: 0.658097
[2022-06-12 23:18:35 | train] - Train Epoch: [184] [1280000/1281167 (100%)]	Loss: 0.719624
[2022-06-12 23:18:37 | train] - Train Epoch: [184]	 Average Loss: 0.723576	 Total Acc : 82.4429	 Total Top5 Acc : 93.5930
[2022-06-12 23:18:37 | train] - -------184 epoch end-----------
========================================
-------184 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 23:20:07 | train] - 
Epoch [184] Test set: Average loss: 1.4366, Accuracy: 34943/50000 (69.8597%), Top-5 Accuracy: 88.9162%

[2022-06-12 23:20:07 | train] - save intermediate epoch [184] result


[2022-06-12 23:20:29 | train] - -------185 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 23:20:31 | train] - Train Epoch: [185] [0/1281167 (0%)]	Loss: 0.810068
[2022-06-12 23:20:52 | train] - Train Epoch: [185] [12800/1281167 (1%)]	Loss: 0.680230
[2022-06-12 23:21:12 | train] - Train Epoch: [185] [25600/1281167 (2%)]	Loss: 0.946441
[2022-06-12 23:21:33 | train] - Train Epoch: [185] [38400/1281167 (3%)]	Loss: 0.676576
[2022-06-12 23:21:54 | train] - Train Epoch: [185] [51200/1281167 (4%)]	Loss: 0.653052
[2022-06-12 23:22:15 | train] - Train Epoch: [185] [64000/1281167 (5%)]	Loss: 0.667974
[2022-06-12 23:22:36 | train] - Train Epoch: [185] [76800/1281167 (6%)]	Loss: 0.657883
[2022-06-12 23:22:57 | train] - Train Epoch: [185] [89600/1281167 (7%)]	Loss: 0.561648
[2022-06-12 23:23:19 | train] - Train Epoch: [185] [102400/1281167 (8%)]	Loss: 0.823772
[2022-06-12 23:23:38 | train] - Train Epoch: [185] [115200/1281167 (9%)]	Loss: 0.663596
[2022-06-12 23:23:59 | train] - Train Epoch: [185] [128000/1281167 (10%)]	Loss: 0.669165
[2022-06-12 23:24:20 | train] - Train Epoch: [185] [140800/1281167 (11%)]	Loss: 0.578471
[2022-06-12 23:24:41 | train] - Train Epoch: [185] [153600/1281167 (12%)]	Loss: 0.544758
[2022-06-12 23:25:03 | train] - Train Epoch: [185] [166400/1281167 (13%)]	Loss: 0.692307
[2022-06-12 23:25:24 | train] - Train Epoch: [185] [179200/1281167 (14%)]	Loss: 0.804142
[2022-06-12 23:25:45 | train] - Train Epoch: [185] [192000/1281167 (15%)]	Loss: 0.662722
[2022-06-12 23:26:07 | train] - Train Epoch: [185] [204800/1281167 (16%)]	Loss: 0.647653
[2022-06-12 23:26:27 | train] - Train Epoch: [185] [217600/1281167 (17%)]	Loss: 0.926398
[2022-06-12 23:26:48 | train] - Train Epoch: [185] [230400/1281167 (18%)]	Loss: 0.582795
[2022-06-12 23:27:09 | train] - Train Epoch: [185] [243200/1281167 (19%)]	Loss: 0.561373
[2022-06-12 23:27:30 | train] - Train Epoch: [185] [256000/1281167 (20%)]	Loss: 0.940406
[2022-06-12 23:27:50 | train] - Train Epoch: [185] [268800/1281167 (21%)]	Loss: 0.690829
[2022-06-12 23:28:10 | train] - Train Epoch: [185] [281600/1281167 (22%)]	Loss: 0.673959
[2022-06-12 23:28:31 | train] - Train Epoch: [185] [294400/1281167 (23%)]	Loss: 0.598119
[2022-06-12 23:28:50 | train] - Train Epoch: [185] [307200/1281167 (24%)]	Loss: 0.599510
[2022-06-12 23:29:10 | train] - Train Epoch: [185] [320000/1281167 (25%)]	Loss: 0.507172
[2022-06-12 23:29:31 | train] - Train Epoch: [185] [332800/1281167 (26%)]	Loss: 0.673495
[2022-06-12 23:29:51 | train] - Train Epoch: [185] [345600/1281167 (27%)]	Loss: 0.635511
[2022-06-12 23:30:11 | train] - Train Epoch: [185] [358400/1281167 (28%)]	Loss: 0.967701
[2022-06-12 23:30:32 | train] - Train Epoch: [185] [371200/1281167 (29%)]	Loss: 0.695719
[2022-06-12 23:30:54 | train] - Train Epoch: [185] [384000/1281167 (30%)]	Loss: 0.646133
[2022-06-12 23:31:15 | train] - Train Epoch: [185] [396800/1281167 (31%)]	Loss: 0.575947
[2022-06-12 23:31:36 | train] - Train Epoch: [185] [409600/1281167 (32%)]	Loss: 0.892412
[2022-06-12 23:31:56 | train] - Train Epoch: [185] [422400/1281167 (33%)]	Loss: 0.578010
[2022-06-12 23:32:17 | train] - Train Epoch: [185] [435200/1281167 (34%)]	Loss: 0.850273
[2022-06-12 23:32:38 | train] - Train Epoch: [185] [448000/1281167 (35%)]	Loss: 0.628059
[2022-06-12 23:32:58 | train] - Train Epoch: [185] [460800/1281167 (36%)]	Loss: 0.457796
[2022-06-12 23:33:19 | train] - Train Epoch: [185] [473600/1281167 (37%)]	Loss: 0.879399
[2022-06-12 23:33:39 | train] - Train Epoch: [185] [486400/1281167 (38%)]	Loss: 0.783676
[2022-06-12 23:34:00 | train] - Train Epoch: [185] [499200/1281167 (39%)]	Loss: 0.602267
[2022-06-12 23:34:21 | train] - Train Epoch: [185] [512000/1281167 (40%)]	Loss: 0.797516
[2022-06-12 23:34:42 | train] - Train Epoch: [185] [524800/1281167 (41%)]	Loss: 0.629831
[2022-06-12 23:35:02 | train] - Train Epoch: [185] [537600/1281167 (42%)]	Loss: 0.763497
[2022-06-12 23:35:23 | train] - Train Epoch: [185] [550400/1281167 (43%)]	Loss: 0.701565
[2022-06-12 23:35:44 | train] - Train Epoch: [185] [563200/1281167 (44%)]	Loss: 0.635637
[2022-06-12 23:36:04 | train] - Train Epoch: [185] [576000/1281167 (45%)]	Loss: 0.492706
[2022-06-12 23:36:25 | train] - Train Epoch: [185] [588800/1281167 (46%)]	Loss: 0.634989
[2022-06-12 23:36:46 | train] - Train Epoch: [185] [601600/1281167 (47%)]	Loss: 0.550992
[2022-06-12 23:37:08 | train] - Train Epoch: [185] [614400/1281167 (48%)]	Loss: 0.817408
[2022-06-12 23:37:28 | train] - Train Epoch: [185] [627200/1281167 (49%)]	Loss: 0.727458
[2022-06-12 23:37:48 | train] - Train Epoch: [185] [640000/1281167 (50%)]	Loss: 0.511684
[2022-06-12 23:38:09 | train] - Train Epoch: [185] [652800/1281167 (51%)]	Loss: 0.688217
[2022-06-12 23:38:31 | train] - Train Epoch: [185] [665600/1281167 (52%)]	Loss: 0.719715
[2022-06-12 23:38:52 | train] - Train Epoch: [185] [678400/1281167 (53%)]	Loss: 0.438058
[2022-06-12 23:39:12 | train] - Train Epoch: [185] [691200/1281167 (54%)]	Loss: 0.742163
[2022-06-12 23:39:33 | train] - Train Epoch: [185] [704000/1281167 (55%)]	Loss: 0.698477
[2022-06-12 23:39:53 | train] - Train Epoch: [185] [716800/1281167 (56%)]	Loss: 0.849565
[2022-06-12 23:40:14 | train] - Train Epoch: [185] [729600/1281167 (57%)]	Loss: 0.706732
[2022-06-12 23:40:36 | train] - Train Epoch: [185] [742400/1281167 (58%)]	Loss: 0.692221
[2022-06-12 23:40:56 | train] - Train Epoch: [185] [755200/1281167 (59%)]	Loss: 0.846440
[2022-06-12 23:41:18 | train] - Train Epoch: [185] [768000/1281167 (60%)]	Loss: 0.660438
[2022-06-12 23:41:39 | train] - Train Epoch: [185] [780800/1281167 (61%)]	Loss: 0.698628
[2022-06-12 23:42:00 | train] - Train Epoch: [185] [793600/1281167 (62%)]	Loss: 0.665460
[2022-06-12 23:42:21 | train] - Train Epoch: [185] [806400/1281167 (63%)]	Loss: 0.585845
[2022-06-12 23:42:43 | train] - Train Epoch: [185] [819200/1281167 (64%)]	Loss: 0.825833
[2022-06-12 23:43:04 | train] - Train Epoch: [185] [832000/1281167 (65%)]	Loss: 0.630714
[2022-06-12 23:43:25 | train] - Train Epoch: [185] [844800/1281167 (66%)]	Loss: 0.507055
[2022-06-12 23:43:47 | train] - Train Epoch: [185] [857600/1281167 (67%)]	Loss: 0.766619
[2022-06-12 23:44:07 | train] - Train Epoch: [185] [870400/1281167 (68%)]	Loss: 0.646132
[2022-06-12 23:44:28 | train] - Train Epoch: [185] [883200/1281167 (69%)]	Loss: 0.652183
[2022-06-12 23:44:49 | train] - Train Epoch: [185] [896000/1281167 (70%)]	Loss: 0.608642
[2022-06-12 23:45:08 | train] - Train Epoch: [185] [908800/1281167 (71%)]	Loss: 0.607281
[2022-06-12 23:45:29 | train] - Train Epoch: [185] [921600/1281167 (72%)]	Loss: 0.682660
[2022-06-12 23:45:49 | train] - Train Epoch: [185] [934400/1281167 (73%)]	Loss: 0.674921
[2022-06-12 23:46:10 | train] - Train Epoch: [185] [947200/1281167 (74%)]	Loss: 0.492870
[2022-06-12 23:46:31 | train] - Train Epoch: [185] [960000/1281167 (75%)]	Loss: 0.723461
[2022-06-12 23:46:52 | train] - Train Epoch: [185] [972800/1281167 (76%)]	Loss: 0.580473
[2022-06-12 23:47:12 | train] - Train Epoch: [185] [985600/1281167 (77%)]	Loss: 0.665121
[2022-06-12 23:47:33 | train] - Train Epoch: [185] [998400/1281167 (78%)]	Loss: 0.567366
[2022-06-12 23:47:54 | train] - Train Epoch: [185] [1011200/1281167 (79%)]	Loss: 0.510172
[2022-06-12 23:48:16 | train] - Train Epoch: [185] [1024000/1281167 (80%)]	Loss: 0.792703
[2022-06-12 23:48:37 | train] - Train Epoch: [185] [1036800/1281167 (81%)]	Loss: 0.766916
[2022-06-12 23:48:57 | train] - Train Epoch: [185] [1049600/1281167 (82%)]	Loss: 0.947107
[2022-06-12 23:49:18 | train] - Train Epoch: [185] [1062400/1281167 (83%)]	Loss: 0.656805
[2022-06-12 23:49:37 | train] - Train Epoch: [185] [1075200/1281167 (84%)]	Loss: 0.586939
[2022-06-12 23:49:58 | train] - Train Epoch: [185] [1088000/1281167 (85%)]	Loss: 0.642419
[2022-06-12 23:50:18 | train] - Train Epoch: [185] [1100800/1281167 (86%)]	Loss: 0.797233
[2022-06-12 23:50:38 | train] - Train Epoch: [185] [1113600/1281167 (87%)]	Loss: 0.781119
[2022-06-12 23:50:58 | train] - Train Epoch: [185] [1126400/1281167 (88%)]	Loss: 0.824095
[2022-06-12 23:51:19 | train] - Train Epoch: [185] [1139200/1281167 (89%)]	Loss: 0.738816
[2022-06-12 23:51:40 | train] - Train Epoch: [185] [1152000/1281167 (90%)]	Loss: 0.704441
[2022-06-12 23:52:01 | train] - Train Epoch: [185] [1164800/1281167 (91%)]	Loss: 0.662333
[2022-06-12 23:52:23 | train] - Train Epoch: [185] [1177600/1281167 (92%)]	Loss: 0.588783
[2022-06-12 23:52:43 | train] - Train Epoch: [185] [1190400/1281167 (93%)]	Loss: 0.560140
[2022-06-12 23:53:05 | train] - Train Epoch: [185] [1203200/1281167 (94%)]	Loss: 0.719529
[2022-06-12 23:53:26 | train] - Train Epoch: [185] [1216000/1281167 (95%)]	Loss: 0.623399
[2022-06-12 23:53:47 | train] - Train Epoch: [185] [1228800/1281167 (96%)]	Loss: 0.884660
[2022-06-12 23:54:09 | train] - Train Epoch: [185] [1241600/1281167 (97%)]	Loss: 0.599389
[2022-06-12 23:54:30 | train] - Train Epoch: [185] [1254400/1281167 (98%)]	Loss: 0.686386
[2022-06-12 23:54:51 | train] - Train Epoch: [185] [1267200/1281167 (99%)]	Loss: 0.636965
[2022-06-12 23:55:11 | train] - Train Epoch: [185] [1280000/1281167 (100%)]	Loss: 0.573250
[2022-06-12 23:55:13 | train] - Train Epoch: [185]	 Average Loss: 0.722351	 Total Acc : 82.4393	 Total Top5 Acc : 93.6286
[2022-06-12 23:55:13 | train] - -------185 epoch end-----------
========================================
-------185 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-12 23:56:43 | train] - 
Epoch [185] Test set: Average loss: 1.4366, Accuracy: 34975/50000 (69.9213%), Top-5 Accuracy: 88.9322%

[2022-06-12 23:56:43 | train] - save intermediate epoch [185] result


[2022-06-12 23:57:05 | train] - -------186 epoch start-----------
========================================
----- test end -------------------------


[2022-06-12 23:57:07 | train] - Train Epoch: [186] [0/1281167 (0%)]	Loss: 0.556074
[2022-06-12 23:57:29 | train] - Train Epoch: [186] [12800/1281167 (1%)]	Loss: 0.748025
[2022-06-12 23:57:51 | train] - Train Epoch: [186] [25600/1281167 (2%)]	Loss: 0.658778
[2022-06-12 23:58:12 | train] - Train Epoch: [186] [38400/1281167 (3%)]	Loss: 0.767502
[2022-06-12 23:58:33 | train] - Train Epoch: [186] [51200/1281167 (4%)]	Loss: 0.592200
[2022-06-12 23:58:54 | train] - Train Epoch: [186] [64000/1281167 (5%)]	Loss: 0.678398
[2022-06-12 23:59:16 | train] - Train Epoch: [186] [76800/1281167 (6%)]	Loss: 0.474075
[2022-06-12 23:59:37 | train] - Train Epoch: [186] [89600/1281167 (7%)]	Loss: 0.763841
[2022-06-12 23:59:58 | train] - Train Epoch: [186] [102400/1281167 (8%)]	Loss: 0.615109
[2022-06-13 00:00:19 | train] - Train Epoch: [186] [115200/1281167 (9%)]	Loss: 0.777148
[2022-06-13 00:00:40 | train] - Train Epoch: [186] [128000/1281167 (10%)]	Loss: 0.661329
[2022-06-13 00:01:02 | train] - Train Epoch: [186] [140800/1281167 (11%)]	Loss: 0.782453
[2022-06-13 00:01:23 | train] - Train Epoch: [186] [153600/1281167 (12%)]	Loss: 0.845418
[2022-06-13 00:01:44 | train] - Train Epoch: [186] [166400/1281167 (13%)]	Loss: 0.561507
[2022-06-13 00:02:04 | train] - Train Epoch: [186] [179200/1281167 (14%)]	Loss: 0.913425
[2022-06-13 00:02:25 | train] - Train Epoch: [186] [192000/1281167 (15%)]	Loss: 0.752403
[2022-06-13 00:02:46 | train] - Train Epoch: [186] [204800/1281167 (16%)]	Loss: 0.619956
[2022-06-13 00:03:07 | train] - Train Epoch: [186] [217600/1281167 (17%)]	Loss: 0.608605
[2022-06-13 00:03:28 | train] - Train Epoch: [186] [230400/1281167 (18%)]	Loss: 1.007124
[2022-06-13 00:03:49 | train] - Train Epoch: [186] [243200/1281167 (19%)]	Loss: 1.017811
[2022-06-13 00:04:10 | train] - Train Epoch: [186] [256000/1281167 (20%)]	Loss: 0.693746
[2022-06-13 00:04:31 | train] - Train Epoch: [186] [268800/1281167 (21%)]	Loss: 0.841258
[2022-06-13 00:04:53 | train] - Train Epoch: [186] [281600/1281167 (22%)]	Loss: 0.747409
[2022-06-13 00:05:14 | train] - Train Epoch: [186] [294400/1281167 (23%)]	Loss: 0.707210
[2022-06-13 00:05:36 | train] - Train Epoch: [186] [307200/1281167 (24%)]	Loss: 0.572294
[2022-06-13 00:05:58 | train] - Train Epoch: [186] [320000/1281167 (25%)]	Loss: 0.610816
[2022-06-13 00:06:19 | train] - Train Epoch: [186] [332800/1281167 (26%)]	Loss: 0.715454
[2022-06-13 00:06:41 | train] - Train Epoch: [186] [345600/1281167 (27%)]	Loss: 0.878789
[2022-06-13 00:07:03 | train] - Train Epoch: [186] [358400/1281167 (28%)]	Loss: 0.532165
[2022-06-13 00:07:24 | train] - Train Epoch: [186] [371200/1281167 (29%)]	Loss: 0.724897
[2022-06-13 00:07:46 | train] - Train Epoch: [186] [384000/1281167 (30%)]	Loss: 0.898800
[2022-06-13 00:08:07 | train] - Train Epoch: [186] [396800/1281167 (31%)]	Loss: 0.678048
[2022-06-13 00:08:29 | train] - Train Epoch: [186] [409600/1281167 (32%)]	Loss: 0.621269
[2022-06-13 00:08:50 | train] - Train Epoch: [186] [422400/1281167 (33%)]	Loss: 0.775476
[2022-06-13 00:09:12 | train] - Train Epoch: [186] [435200/1281167 (34%)]	Loss: 0.669504
[2022-06-13 00:09:34 | train] - Train Epoch: [186] [448000/1281167 (35%)]	Loss: 0.652500
[2022-06-13 00:09:55 | train] - Train Epoch: [186] [460800/1281167 (36%)]	Loss: 0.561552
[2022-06-13 00:10:17 | train] - Train Epoch: [186] [473600/1281167 (37%)]	Loss: 0.810828
[2022-06-13 00:10:39 | train] - Train Epoch: [186] [486400/1281167 (38%)]	Loss: 0.908372
[2022-06-13 00:11:00 | train] - Train Epoch: [186] [499200/1281167 (39%)]	Loss: 0.846943
[2022-06-13 00:11:22 | train] - Train Epoch: [186] [512000/1281167 (40%)]	Loss: 0.621821
[2022-06-13 00:11:43 | train] - Train Epoch: [186] [524800/1281167 (41%)]	Loss: 0.904147
[2022-06-13 00:12:05 | train] - Train Epoch: [186] [537600/1281167 (42%)]	Loss: 0.754637
[2022-06-13 00:12:26 | train] - Train Epoch: [186] [550400/1281167 (43%)]	Loss: 0.992905
[2022-06-13 00:12:48 | train] - Train Epoch: [186] [563200/1281167 (44%)]	Loss: 0.607635
[2022-06-13 00:13:09 | train] - Train Epoch: [186] [576000/1281167 (45%)]	Loss: 0.534527
[2022-06-13 00:13:30 | train] - Train Epoch: [186] [588800/1281167 (46%)]	Loss: 0.598517
[2022-06-13 00:13:52 | train] - Train Epoch: [186] [601600/1281167 (47%)]	Loss: 0.626139
[2022-06-13 00:14:13 | train] - Train Epoch: [186] [614400/1281167 (48%)]	Loss: 0.883802
[2022-06-13 00:14:34 | train] - Train Epoch: [186] [627200/1281167 (49%)]	Loss: 0.611671
[2022-06-13 00:14:56 | train] - Train Epoch: [186] [640000/1281167 (50%)]	Loss: 0.837521
[2022-06-13 00:15:17 | train] - Train Epoch: [186] [652800/1281167 (51%)]	Loss: 0.852265
[2022-06-13 00:15:39 | train] - Train Epoch: [186] [665600/1281167 (52%)]	Loss: 0.763578
[2022-06-13 00:16:01 | train] - Train Epoch: [186] [678400/1281167 (53%)]	Loss: 0.700606
[2022-06-13 00:16:23 | train] - Train Epoch: [186] [691200/1281167 (54%)]	Loss: 0.824413
[2022-06-13 00:16:45 | train] - Train Epoch: [186] [704000/1281167 (55%)]	Loss: 0.706254
[2022-06-13 00:17:07 | train] - Train Epoch: [186] [716800/1281167 (56%)]	Loss: 0.932941
[2022-06-13 00:17:29 | train] - Train Epoch: [186] [729600/1281167 (57%)]	Loss: 0.629254
[2022-06-13 00:17:50 | train] - Train Epoch: [186] [742400/1281167 (58%)]	Loss: 0.620603
[2022-06-13 00:18:12 | train] - Train Epoch: [186] [755200/1281167 (59%)]	Loss: 0.528068
[2022-06-13 00:18:34 | train] - Train Epoch: [186] [768000/1281167 (60%)]	Loss: 0.567722
[2022-06-13 00:18:56 | train] - Train Epoch: [186] [780800/1281167 (61%)]	Loss: 0.692165
[2022-06-13 00:19:17 | train] - Train Epoch: [186] [793600/1281167 (62%)]	Loss: 0.657285
[2022-06-13 00:19:39 | train] - Train Epoch: [186] [806400/1281167 (63%)]	Loss: 0.886896
[2022-06-13 00:20:01 | train] - Train Epoch: [186] [819200/1281167 (64%)]	Loss: 0.589822
[2022-06-13 00:20:22 | train] - Train Epoch: [186] [832000/1281167 (65%)]	Loss: 0.963802
[2022-06-13 00:20:44 | train] - Train Epoch: [186] [844800/1281167 (66%)]	Loss: 0.835340
[2022-06-13 00:21:05 | train] - Train Epoch: [186] [857600/1281167 (67%)]	Loss: 0.674092
[2022-06-13 00:21:27 | train] - Train Epoch: [186] [870400/1281167 (68%)]	Loss: 0.896319
[2022-06-13 00:21:49 | train] - Train Epoch: [186] [883200/1281167 (69%)]	Loss: 0.872032
[2022-06-13 00:22:10 | train] - Train Epoch: [186] [896000/1281167 (70%)]	Loss: 0.667367
[2022-06-13 00:22:31 | train] - Train Epoch: [186] [908800/1281167 (71%)]	Loss: 0.892388
[2022-06-13 00:22:53 | train] - Train Epoch: [186] [921600/1281167 (72%)]	Loss: 0.961205
[2022-06-13 00:23:15 | train] - Train Epoch: [186] [934400/1281167 (73%)]	Loss: 0.614074
[2022-06-13 00:23:37 | train] - Train Epoch: [186] [947200/1281167 (74%)]	Loss: 0.508645
[2022-06-13 00:23:58 | train] - Train Epoch: [186] [960000/1281167 (75%)]	Loss: 0.715380
[2022-06-13 00:24:20 | train] - Train Epoch: [186] [972800/1281167 (76%)]	Loss: 0.825577
[2022-06-13 00:24:41 | train] - Train Epoch: [186] [985600/1281167 (77%)]	Loss: 0.672838
[2022-06-13 00:25:02 | train] - Train Epoch: [186] [998400/1281167 (78%)]	Loss: 0.757607
[2022-06-13 00:25:24 | train] - Train Epoch: [186] [1011200/1281167 (79%)]	Loss: 0.756189
[2022-06-13 00:25:46 | train] - Train Epoch: [186] [1024000/1281167 (80%)]	Loss: 0.772780
[2022-06-13 00:26:08 | train] - Train Epoch: [186] [1036800/1281167 (81%)]	Loss: 0.796345
[2022-06-13 00:26:30 | train] - Train Epoch: [186] [1049600/1281167 (82%)]	Loss: 0.439902
[2022-06-13 00:26:52 | train] - Train Epoch: [186] [1062400/1281167 (83%)]	Loss: 0.795875
[2022-06-13 00:27:13 | train] - Train Epoch: [186] [1075200/1281167 (84%)]	Loss: 0.974230
[2022-06-13 00:27:35 | train] - Train Epoch: [186] [1088000/1281167 (85%)]	Loss: 0.768435
[2022-06-13 00:27:56 | train] - Train Epoch: [186] [1100800/1281167 (86%)]	Loss: 0.594206
[2022-06-13 00:28:18 | train] - Train Epoch: [186] [1113600/1281167 (87%)]	Loss: 0.632312
[2022-06-13 00:28:38 | train] - Train Epoch: [186] [1126400/1281167 (88%)]	Loss: 0.692508
[2022-06-13 00:29:00 | train] - Train Epoch: [186] [1139200/1281167 (89%)]	Loss: 0.685823
[2022-06-13 00:29:21 | train] - Train Epoch: [186] [1152000/1281167 (90%)]	Loss: 0.763868
[2022-06-13 00:29:43 | train] - Train Epoch: [186] [1164800/1281167 (91%)]	Loss: 0.899523
[2022-06-13 00:30:04 | train] - Train Epoch: [186] [1177600/1281167 (92%)]	Loss: 0.912568
[2022-06-13 00:30:26 | train] - Train Epoch: [186] [1190400/1281167 (93%)]	Loss: 0.725929
[2022-06-13 00:30:48 | train] - Train Epoch: [186] [1203200/1281167 (94%)]	Loss: 0.692597
[2022-06-13 00:31:09 | train] - Train Epoch: [186] [1216000/1281167 (95%)]	Loss: 0.786278
[2022-06-13 00:31:30 | train] - Train Epoch: [186] [1228800/1281167 (96%)]	Loss: 0.837505
[2022-06-13 00:31:51 | train] - Train Epoch: [186] [1241600/1281167 (97%)]	Loss: 0.810183
[2022-06-13 00:32:13 | train] - Train Epoch: [186] [1254400/1281167 (98%)]	Loss: 0.749761
[2022-06-13 00:32:35 | train] - Train Epoch: [186] [1267200/1281167 (99%)]	Loss: 0.631436
[2022-06-13 00:32:55 | train] - Train Epoch: [186] [1280000/1281167 (100%)]	Loss: 1.011477
[2022-06-13 00:32:57 | train] - Train Epoch: [186]	 Average Loss: 0.722111	 Total Acc : 82.4581	 Total Top5 Acc : 93.6135
[2022-06-13 00:32:57 | train] - -------186 epoch end-----------
========================================
-------186 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 00:34:27 | train] - 
Epoch [186] Test set: Average loss: 1.4273, Accuracy: 34936/50000 (69.8457%), Top-5 Accuracy: 88.9274%

[2022-06-13 00:34:27 | train] - save intermediate epoch [186] result


[2022-06-13 00:34:49 | train] - -------187 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 00:34:51 | train] - Train Epoch: [187] [0/1281167 (0%)]	Loss: 0.869227
[2022-06-13 00:35:10 | train] - Train Epoch: [187] [12800/1281167 (1%)]	Loss: 0.784007
[2022-06-13 00:35:31 | train] - Train Epoch: [187] [25600/1281167 (2%)]	Loss: 0.811239
[2022-06-13 00:35:52 | train] - Train Epoch: [187] [38400/1281167 (3%)]	Loss: 0.598616
[2022-06-13 00:36:13 | train] - Train Epoch: [187] [51200/1281167 (4%)]	Loss: 0.926946
[2022-06-13 00:36:35 | train] - Train Epoch: [187] [64000/1281167 (5%)]	Loss: 0.767960
[2022-06-13 00:36:56 | train] - Train Epoch: [187] [76800/1281167 (6%)]	Loss: 0.646274
[2022-06-13 00:37:18 | train] - Train Epoch: [187] [89600/1281167 (7%)]	Loss: 0.757894
[2022-06-13 00:37:39 | train] - Train Epoch: [187] [102400/1281167 (8%)]	Loss: 0.839262
[2022-06-13 00:38:01 | train] - Train Epoch: [187] [115200/1281167 (9%)]	Loss: 0.801441
[2022-06-13 00:38:22 | train] - Train Epoch: [187] [128000/1281167 (10%)]	Loss: 0.815283
[2022-06-13 00:38:43 | train] - Train Epoch: [187] [140800/1281167 (11%)]	Loss: 0.728689
[2022-06-13 00:39:05 | train] - Train Epoch: [187] [153600/1281167 (12%)]	Loss: 0.722899
[2022-06-13 00:39:25 | train] - Train Epoch: [187] [166400/1281167 (13%)]	Loss: 0.670009
[2022-06-13 00:39:46 | train] - Train Epoch: [187] [179200/1281167 (14%)]	Loss: 0.826463
[2022-06-13 00:40:08 | train] - Train Epoch: [187] [192000/1281167 (15%)]	Loss: 0.764345
[2022-06-13 00:40:30 | train] - Train Epoch: [187] [204800/1281167 (16%)]	Loss: 1.046843
[2022-06-13 00:40:51 | train] - Train Epoch: [187] [217600/1281167 (17%)]	Loss: 0.659456
[2022-06-13 00:41:12 | train] - Train Epoch: [187] [230400/1281167 (18%)]	Loss: 0.725399
[2022-06-13 00:41:33 | train] - Train Epoch: [187] [243200/1281167 (19%)]	Loss: 0.706057
[2022-06-13 00:41:55 | train] - Train Epoch: [187] [256000/1281167 (20%)]	Loss: 0.843668
[2022-06-13 00:42:14 | train] - Train Epoch: [187] [268800/1281167 (21%)]	Loss: 0.751499
[2022-06-13 00:42:36 | train] - Train Epoch: [187] [281600/1281167 (22%)]	Loss: 0.736499
[2022-06-13 00:42:57 | train] - Train Epoch: [187] [294400/1281167 (23%)]	Loss: 0.772412
[2022-06-13 00:43:18 | train] - Train Epoch: [187] [307200/1281167 (24%)]	Loss: 0.644209
[2022-06-13 00:43:39 | train] - Train Epoch: [187] [320000/1281167 (25%)]	Loss: 0.724939
[2022-06-13 00:44:01 | train] - Train Epoch: [187] [332800/1281167 (26%)]	Loss: 0.778029
[2022-06-13 00:44:22 | train] - Train Epoch: [187] [345600/1281167 (27%)]	Loss: 0.679036
[2022-06-13 00:44:44 | train] - Train Epoch: [187] [358400/1281167 (28%)]	Loss: 0.576303
[2022-06-13 00:45:05 | train] - Train Epoch: [187] [371200/1281167 (29%)]	Loss: 0.789932
[2022-06-13 00:45:26 | train] - Train Epoch: [187] [384000/1281167 (30%)]	Loss: 0.917717
[2022-06-13 00:45:47 | train] - Train Epoch: [187] [396800/1281167 (31%)]	Loss: 0.824335
[2022-06-13 00:46:09 | train] - Train Epoch: [187] [409600/1281167 (32%)]	Loss: 0.563121
[2022-06-13 00:46:30 | train] - Train Epoch: [187] [422400/1281167 (33%)]	Loss: 0.799301
[2022-06-13 00:46:51 | train] - Train Epoch: [187] [435200/1281167 (34%)]	Loss: 0.819515
[2022-06-13 00:47:13 | train] - Train Epoch: [187] [448000/1281167 (35%)]	Loss: 0.626530
[2022-06-13 00:47:34 | train] - Train Epoch: [187] [460800/1281167 (36%)]	Loss: 0.744333
[2022-06-13 00:47:55 | train] - Train Epoch: [187] [473600/1281167 (37%)]	Loss: 0.846890
[2022-06-13 00:48:16 | train] - Train Epoch: [187] [486400/1281167 (38%)]	Loss: 0.777994
[2022-06-13 00:48:37 | train] - Train Epoch: [187] [499200/1281167 (39%)]	Loss: 0.774184
[2022-06-13 00:48:59 | train] - Train Epoch: [187] [512000/1281167 (40%)]	Loss: 0.831182
[2022-06-13 00:49:19 | train] - Train Epoch: [187] [524800/1281167 (41%)]	Loss: 0.862886
[2022-06-13 00:49:41 | train] - Train Epoch: [187] [537600/1281167 (42%)]	Loss: 0.506761
[2022-06-13 00:50:02 | train] - Train Epoch: [187] [550400/1281167 (43%)]	Loss: 0.616510
[2022-06-13 00:50:23 | train] - Train Epoch: [187] [563200/1281167 (44%)]	Loss: 0.596718
[2022-06-13 00:50:44 | train] - Train Epoch: [187] [576000/1281167 (45%)]	Loss: 0.789217
[2022-06-13 00:51:05 | train] - Train Epoch: [187] [588800/1281167 (46%)]	Loss: 0.552201
[2022-06-13 00:51:25 | train] - Train Epoch: [187] [601600/1281167 (47%)]	Loss: 0.969661
[2022-06-13 00:51:47 | train] - Train Epoch: [187] [614400/1281167 (48%)]	Loss: 0.868670
[2022-06-13 00:52:08 | train] - Train Epoch: [187] [627200/1281167 (49%)]	Loss: 0.850487
[2022-06-13 00:52:30 | train] - Train Epoch: [187] [640000/1281167 (50%)]	Loss: 0.709385
[2022-06-13 00:52:51 | train] - Train Epoch: [187] [652800/1281167 (51%)]	Loss: 0.695620
[2022-06-13 00:53:12 | train] - Train Epoch: [187] [665600/1281167 (52%)]	Loss: 0.784345
[2022-06-13 00:53:33 | train] - Train Epoch: [187] [678400/1281167 (53%)]	Loss: 0.650135
[2022-06-13 00:53:54 | train] - Train Epoch: [187] [691200/1281167 (54%)]	Loss: 0.772639
[2022-06-13 00:54:15 | train] - Train Epoch: [187] [704000/1281167 (55%)]	Loss: 0.663524
[2022-06-13 00:54:37 | train] - Train Epoch: [187] [716800/1281167 (56%)]	Loss: 0.844299
[2022-06-13 00:54:58 | train] - Train Epoch: [187] [729600/1281167 (57%)]	Loss: 0.939464
[2022-06-13 00:55:20 | train] - Train Epoch: [187] [742400/1281167 (58%)]	Loss: 0.663835
[2022-06-13 00:55:40 | train] - Train Epoch: [187] [755200/1281167 (59%)]	Loss: 0.916222
[2022-06-13 00:56:02 | train] - Train Epoch: [187] [768000/1281167 (60%)]	Loss: 1.015644
[2022-06-13 00:56:22 | train] - Train Epoch: [187] [780800/1281167 (61%)]	Loss: 0.618760
[2022-06-13 00:56:44 | train] - Train Epoch: [187] [793600/1281167 (62%)]	Loss: 0.795248
[2022-06-13 00:57:05 | train] - Train Epoch: [187] [806400/1281167 (63%)]	Loss: 0.793173
[2022-06-13 00:57:27 | train] - Train Epoch: [187] [819200/1281167 (64%)]	Loss: 1.010006
[2022-06-13 00:57:48 | train] - Train Epoch: [187] [832000/1281167 (65%)]	Loss: 0.881496
[2022-06-13 00:58:10 | train] - Train Epoch: [187] [844800/1281167 (66%)]	Loss: 0.720116
[2022-06-13 00:58:31 | train] - Train Epoch: [187] [857600/1281167 (67%)]	Loss: 0.741129
[2022-06-13 00:58:52 | train] - Train Epoch: [187] [870400/1281167 (68%)]	Loss: 0.627276
[2022-06-13 00:59:13 | train] - Train Epoch: [187] [883200/1281167 (69%)]	Loss: 0.887102
[2022-06-13 00:59:34 | train] - Train Epoch: [187] [896000/1281167 (70%)]	Loss: 0.873061
[2022-06-13 00:59:54 | train] - Train Epoch: [187] [908800/1281167 (71%)]	Loss: 0.717107
[2022-06-13 01:00:16 | train] - Train Epoch: [187] [921600/1281167 (72%)]	Loss: 0.801456
[2022-06-13 01:00:37 | train] - Train Epoch: [187] [934400/1281167 (73%)]	Loss: 1.213996
[2022-06-13 01:00:58 | train] - Train Epoch: [187] [947200/1281167 (74%)]	Loss: 0.727598
[2022-06-13 01:01:20 | train] - Train Epoch: [187] [960000/1281167 (75%)]	Loss: 0.778081
[2022-06-13 01:01:41 | train] - Train Epoch: [187] [972800/1281167 (76%)]	Loss: 0.920097
[2022-06-13 01:02:03 | train] - Train Epoch: [187] [985600/1281167 (77%)]	Loss: 0.702166
[2022-06-13 01:02:24 | train] - Train Epoch: [187] [998400/1281167 (78%)]	Loss: 0.957798
[2022-06-13 01:02:45 | train] - Train Epoch: [187] [1011200/1281167 (79%)]	Loss: 0.751534
[2022-06-13 01:03:06 | train] - Train Epoch: [187] [1024000/1281167 (80%)]	Loss: 0.900972
[2022-06-13 01:03:27 | train] - Train Epoch: [187] [1036800/1281167 (81%)]	Loss: 0.724848
[2022-06-13 01:03:48 | train] - Train Epoch: [187] [1049600/1281167 (82%)]	Loss: 0.493479
[2022-06-13 01:04:09 | train] - Train Epoch: [187] [1062400/1281167 (83%)]	Loss: 0.563283
[2022-06-13 01:04:29 | train] - Train Epoch: [187] [1075200/1281167 (84%)]	Loss: 0.802187
[2022-06-13 01:04:49 | train] - Train Epoch: [187] [1088000/1281167 (85%)]	Loss: 0.798099
[2022-06-13 01:05:10 | train] - Train Epoch: [187] [1100800/1281167 (86%)]	Loss: 0.850390
[2022-06-13 01:05:30 | train] - Train Epoch: [187] [1113600/1281167 (87%)]	Loss: 0.924131
[2022-06-13 01:05:51 | train] - Train Epoch: [187] [1126400/1281167 (88%)]	Loss: 0.704657
[2022-06-13 01:06:12 | train] - Train Epoch: [187] [1139200/1281167 (89%)]	Loss: 0.605175
[2022-06-13 01:06:33 | train] - Train Epoch: [187] [1152000/1281167 (90%)]	Loss: 0.783127
[2022-06-13 01:06:54 | train] - Train Epoch: [187] [1164800/1281167 (91%)]	Loss: 0.494459
[2022-06-13 01:07:15 | train] - Train Epoch: [187] [1177600/1281167 (92%)]	Loss: 0.631323
[2022-06-13 01:07:36 | train] - Train Epoch: [187] [1190400/1281167 (93%)]	Loss: 0.740246
[2022-06-13 01:07:56 | train] - Train Epoch: [187] [1203200/1281167 (94%)]	Loss: 0.709101
[2022-06-13 01:08:17 | train] - Train Epoch: [187] [1216000/1281167 (95%)]	Loss: 0.700652
[2022-06-13 01:08:38 | train] - Train Epoch: [187] [1228800/1281167 (96%)]	Loss: 0.930058
[2022-06-13 01:08:59 | train] - Train Epoch: [187] [1241600/1281167 (97%)]	Loss: 0.762351
[2022-06-13 01:09:21 | train] - Train Epoch: [187] [1254400/1281167 (98%)]	Loss: 0.832271
[2022-06-13 01:09:42 | train] - Train Epoch: [187] [1267200/1281167 (99%)]	Loss: 0.559410
[2022-06-13 01:10:03 | train] - Train Epoch: [187] [1280000/1281167 (100%)]	Loss: 0.653638
[2022-06-13 01:10:05 | train] - Train Epoch: [187]	 Average Loss: 0.721335	 Total Acc : 82.5251	 Total Top5 Acc : 93.6263
[2022-06-13 01:10:05 | train] - -------187 epoch end-----------
========================================
-------187 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 01:11:38 | train] - 
Epoch [187] Test set: Average loss: 1.4340, Accuracy: 34940/50000 (69.8501%), Top-5 Accuracy: 88.8523%

[2022-06-13 01:11:38 | train] - save intermediate epoch [187] result


[2022-06-13 01:12:00 | train] - -------188 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 01:12:02 | train] - Train Epoch: [188] [0/1281167 (0%)]	Loss: 0.524772
[2022-06-13 01:12:24 | train] - Train Epoch: [188] [12800/1281167 (1%)]	Loss: 0.865712
[2022-06-13 01:12:46 | train] - Train Epoch: [188] [25600/1281167 (2%)]	Loss: 0.807027
[2022-06-13 01:13:09 | train] - Train Epoch: [188] [38400/1281167 (3%)]	Loss: 0.813133
[2022-06-13 01:13:30 | train] - Train Epoch: [188] [51200/1281167 (4%)]	Loss: 0.756334
[2022-06-13 01:13:52 | train] - Train Epoch: [188] [64000/1281167 (5%)]	Loss: 0.981161
[2022-06-13 01:14:14 | train] - Train Epoch: [188] [76800/1281167 (6%)]	Loss: 0.612813
[2022-06-13 01:14:36 | train] - Train Epoch: [188] [89600/1281167 (7%)]	Loss: 0.877938
[2022-06-13 01:14:57 | train] - Train Epoch: [188] [102400/1281167 (8%)]	Loss: 0.563663
[2022-06-13 01:15:19 | train] - Train Epoch: [188] [115200/1281167 (9%)]	Loss: 0.658118
[2022-06-13 01:15:41 | train] - Train Epoch: [188] [128000/1281167 (10%)]	Loss: 0.612831
[2022-06-13 01:16:04 | train] - Train Epoch: [188] [140800/1281167 (11%)]	Loss: 0.650553
[2022-06-13 01:16:25 | train] - Train Epoch: [188] [153600/1281167 (12%)]	Loss: 0.642919
[2022-06-13 01:16:48 | train] - Train Epoch: [188] [166400/1281167 (13%)]	Loss: 0.454443
[2022-06-13 01:17:09 | train] - Train Epoch: [188] [179200/1281167 (14%)]	Loss: 0.853104
[2022-06-13 01:17:30 | train] - Train Epoch: [188] [192000/1281167 (15%)]	Loss: 0.721784
[2022-06-13 01:17:51 | train] - Train Epoch: [188] [204800/1281167 (16%)]	Loss: 0.752439
[2022-06-13 01:18:13 | train] - Train Epoch: [188] [217600/1281167 (17%)]	Loss: 0.736642
[2022-06-13 01:18:35 | train] - Train Epoch: [188] [230400/1281167 (18%)]	Loss: 0.588110
[2022-06-13 01:18:57 | train] - Train Epoch: [188] [243200/1281167 (19%)]	Loss: 0.724389
[2022-06-13 01:19:19 | train] - Train Epoch: [188] [256000/1281167 (20%)]	Loss: 0.820454
[2022-06-13 01:19:41 | train] - Train Epoch: [188] [268800/1281167 (21%)]	Loss: 0.570730
[2022-06-13 01:20:03 | train] - Train Epoch: [188] [281600/1281167 (22%)]	Loss: 0.676850
[2022-06-13 01:20:25 | train] - Train Epoch: [188] [294400/1281167 (23%)]	Loss: 0.833723
[2022-06-13 01:20:47 | train] - Train Epoch: [188] [307200/1281167 (24%)]	Loss: 0.713058
[2022-06-13 01:21:09 | train] - Train Epoch: [188] [320000/1281167 (25%)]	Loss: 0.704885
[2022-06-13 01:21:31 | train] - Train Epoch: [188] [332800/1281167 (26%)]	Loss: 0.573507
[2022-06-13 01:21:54 | train] - Train Epoch: [188] [345600/1281167 (27%)]	Loss: 0.849552
[2022-06-13 01:22:16 | train] - Train Epoch: [188] [358400/1281167 (28%)]	Loss: 0.728239
[2022-06-13 01:22:38 | train] - Train Epoch: [188] [371200/1281167 (29%)]	Loss: 0.889677
[2022-06-13 01:23:00 | train] - Train Epoch: [188] [384000/1281167 (30%)]	Loss: 0.669293
[2022-06-13 01:23:22 | train] - Train Epoch: [188] [396800/1281167 (31%)]	Loss: 0.913859
[2022-06-13 01:23:44 | train] - Train Epoch: [188] [409600/1281167 (32%)]	Loss: 0.794699
[2022-06-13 01:24:06 | train] - Train Epoch: [188] [422400/1281167 (33%)]	Loss: 0.623516
[2022-06-13 01:24:28 | train] - Train Epoch: [188] [435200/1281167 (34%)]	Loss: 0.758930
[2022-06-13 01:24:51 | train] - Train Epoch: [188] [448000/1281167 (35%)]	Loss: 0.772373
[2022-06-13 01:25:13 | train] - Train Epoch: [188] [460800/1281167 (36%)]	Loss: 0.702118
[2022-06-13 01:25:35 | train] - Train Epoch: [188] [473600/1281167 (37%)]	Loss: 0.577460
[2022-06-13 01:25:57 | train] - Train Epoch: [188] [486400/1281167 (38%)]	Loss: 0.719770
[2022-06-13 01:26:19 | train] - Train Epoch: [188] [499200/1281167 (39%)]	Loss: 0.756741
[2022-06-13 01:26:41 | train] - Train Epoch: [188] [512000/1281167 (40%)]	Loss: 0.665595
[2022-06-13 01:27:03 | train] - Train Epoch: [188] [524800/1281167 (41%)]	Loss: 0.565268
[2022-06-13 01:27:24 | train] - Train Epoch: [188] [537600/1281167 (42%)]	Loss: 0.752754
[2022-06-13 01:27:46 | train] - Train Epoch: [188] [550400/1281167 (43%)]	Loss: 0.609012
[2022-06-13 01:28:07 | train] - Train Epoch: [188] [563200/1281167 (44%)]	Loss: 0.664897
[2022-06-13 01:28:29 | train] - Train Epoch: [188] [576000/1281167 (45%)]	Loss: 0.789262
[2022-06-13 01:28:50 | train] - Train Epoch: [188] [588800/1281167 (46%)]	Loss: 0.922120
[2022-06-13 01:29:12 | train] - Train Epoch: [188] [601600/1281167 (47%)]	Loss: 0.647636
[2022-06-13 01:29:33 | train] - Train Epoch: [188] [614400/1281167 (48%)]	Loss: 0.818360
[2022-06-13 01:29:55 | train] - Train Epoch: [188] [627200/1281167 (49%)]	Loss: 0.711881
[2022-06-13 01:30:17 | train] - Train Epoch: [188] [640000/1281167 (50%)]	Loss: 0.682476
[2022-06-13 01:30:38 | train] - Train Epoch: [188] [652800/1281167 (51%)]	Loss: 0.813262
[2022-06-13 01:31:00 | train] - Train Epoch: [188] [665600/1281167 (52%)]	Loss: 0.560049
[2022-06-13 01:31:21 | train] - Train Epoch: [188] [678400/1281167 (53%)]	Loss: 0.813934
[2022-06-13 01:31:43 | train] - Train Epoch: [188] [691200/1281167 (54%)]	Loss: 0.717292
[2022-06-13 01:32:06 | train] - Train Epoch: [188] [704000/1281167 (55%)]	Loss: 0.677273
[2022-06-13 01:32:28 | train] - Train Epoch: [188] [716800/1281167 (56%)]	Loss: 0.728892
[2022-06-13 01:32:50 | train] - Train Epoch: [188] [729600/1281167 (57%)]	Loss: 0.873442
[2022-06-13 01:33:12 | train] - Train Epoch: [188] [742400/1281167 (58%)]	Loss: 0.553351
[2022-06-13 01:33:33 | train] - Train Epoch: [188] [755200/1281167 (59%)]	Loss: 1.023279
[2022-06-13 01:33:55 | train] - Train Epoch: [188] [768000/1281167 (60%)]	Loss: 1.004575
[2022-06-13 01:34:17 | train] - Train Epoch: [188] [780800/1281167 (61%)]	Loss: 0.645581
[2022-06-13 01:34:39 | train] - Train Epoch: [188] [793600/1281167 (62%)]	Loss: 0.713301
[2022-06-13 01:35:01 | train] - Train Epoch: [188] [806400/1281167 (63%)]	Loss: 0.824156
[2022-06-13 01:35:22 | train] - Train Epoch: [188] [819200/1281167 (64%)]	Loss: 0.651957
[2022-06-13 01:35:44 | train] - Train Epoch: [188] [832000/1281167 (65%)]	Loss: 0.668773
[2022-06-13 01:36:05 | train] - Train Epoch: [188] [844800/1281167 (66%)]	Loss: 0.580297
[2022-06-13 01:36:27 | train] - Train Epoch: [188] [857600/1281167 (67%)]	Loss: 0.725851
[2022-06-13 01:36:48 | train] - Train Epoch: [188] [870400/1281167 (68%)]	Loss: 0.739207
[2022-06-13 01:37:10 | train] - Train Epoch: [188] [883200/1281167 (69%)]	Loss: 0.728309
[2022-06-13 01:37:32 | train] - Train Epoch: [188] [896000/1281167 (70%)]	Loss: 0.906632
[2022-06-13 01:37:54 | train] - Train Epoch: [188] [908800/1281167 (71%)]	Loss: 0.565818
[2022-06-13 01:38:16 | train] - Train Epoch: [188] [921600/1281167 (72%)]	Loss: 0.804541
[2022-06-13 01:38:39 | train] - Train Epoch: [188] [934400/1281167 (73%)]	Loss: 0.676103
[2022-06-13 01:39:02 | train] - Train Epoch: [188] [947200/1281167 (74%)]	Loss: 0.745821
[2022-06-13 01:39:24 | train] - Train Epoch: [188] [960000/1281167 (75%)]	Loss: 0.581119
[2022-06-13 01:39:46 | train] - Train Epoch: [188] [972800/1281167 (76%)]	Loss: 0.856158
[2022-06-13 01:40:06 | train] - Train Epoch: [188] [985600/1281167 (77%)]	Loss: 0.601011
[2022-06-13 01:40:28 | train] - Train Epoch: [188] [998400/1281167 (78%)]	Loss: 0.541610
[2022-06-13 01:40:51 | train] - Train Epoch: [188] [1011200/1281167 (79%)]	Loss: 0.828938
[2022-06-13 01:41:13 | train] - Train Epoch: [188] [1024000/1281167 (80%)]	Loss: 0.652658
[2022-06-13 01:41:35 | train] - Train Epoch: [188] [1036800/1281167 (81%)]	Loss: 0.655374
[2022-06-13 01:41:57 | train] - Train Epoch: [188] [1049600/1281167 (82%)]	Loss: 0.913824
[2022-06-13 01:42:20 | train] - Train Epoch: [188] [1062400/1281167 (83%)]	Loss: 0.661425
[2022-06-13 01:42:42 | train] - Train Epoch: [188] [1075200/1281167 (84%)]	Loss: 0.756522
[2022-06-13 01:43:02 | train] - Train Epoch: [188] [1088000/1281167 (85%)]	Loss: 0.727378
[2022-06-13 01:43:24 | train] - Train Epoch: [188] [1100800/1281167 (86%)]	Loss: 0.845781
[2022-06-13 01:43:45 | train] - Train Epoch: [188] [1113600/1281167 (87%)]	Loss: 0.693418
[2022-06-13 01:44:07 | train] - Train Epoch: [188] [1126400/1281167 (88%)]	Loss: 0.824846
[2022-06-13 01:44:28 | train] - Train Epoch: [188] [1139200/1281167 (89%)]	Loss: 0.676029
[2022-06-13 01:44:50 | train] - Train Epoch: [188] [1152000/1281167 (90%)]	Loss: 0.900037
[2022-06-13 01:45:11 | train] - Train Epoch: [188] [1164800/1281167 (91%)]	Loss: 0.713314
[2022-06-13 01:45:33 | train] - Train Epoch: [188] [1177600/1281167 (92%)]	Loss: 0.802599
[2022-06-13 01:45:55 | train] - Train Epoch: [188] [1190400/1281167 (93%)]	Loss: 0.517351
[2022-06-13 01:46:17 | train] - Train Epoch: [188] [1203200/1281167 (94%)]	Loss: 0.627955
[2022-06-13 01:46:39 | train] - Train Epoch: [188] [1216000/1281167 (95%)]	Loss: 0.757312
[2022-06-13 01:47:01 | train] - Train Epoch: [188] [1228800/1281167 (96%)]	Loss: 0.808791
[2022-06-13 01:47:23 | train] - Train Epoch: [188] [1241600/1281167 (97%)]	Loss: 0.822098
[2022-06-13 01:47:46 | train] - Train Epoch: [188] [1254400/1281167 (98%)]	Loss: 0.769386
[2022-06-13 01:48:08 | train] - Train Epoch: [188] [1267200/1281167 (99%)]	Loss: 0.831860
[2022-06-13 01:48:30 | train] - Train Epoch: [188] [1280000/1281167 (100%)]	Loss: 0.930240
[2022-06-13 01:48:32 | train] - Train Epoch: [188]	 Average Loss: 0.718644	 Total Acc : 82.5809	 Total Top5 Acc : 93.6613
[2022-06-13 01:48:32 | train] - -------188 epoch end-----------
========================================
-------188 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 01:50:06 | train] - 
Epoch [188] Test set: Average loss: 1.4313, Accuracy: 35006/50000 (69.9844%), Top-5 Accuracy: 88.9162%

[2022-06-13 01:50:06 | train] - save intermediate epoch [188] result


[2022-06-13 01:50:28 | train] - -------189 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 01:50:30 | train] - Train Epoch: [189] [0/1281167 (0%)]	Loss: 0.805806
[2022-06-13 01:50:52 | train] - Train Epoch: [189] [12800/1281167 (1%)]	Loss: 0.595751
[2022-06-13 01:51:13 | train] - Train Epoch: [189] [25600/1281167 (2%)]	Loss: 0.684617
[2022-06-13 01:51:34 | train] - Train Epoch: [189] [38400/1281167 (3%)]	Loss: 0.430479
[2022-06-13 01:51:56 | train] - Train Epoch: [189] [51200/1281167 (4%)]	Loss: 0.697100
[2022-06-13 01:52:19 | train] - Train Epoch: [189] [64000/1281167 (5%)]	Loss: 0.816791
[2022-06-13 01:52:41 | train] - Train Epoch: [189] [76800/1281167 (6%)]	Loss: 0.677890
[2022-06-13 01:53:03 | train] - Train Epoch: [189] [89600/1281167 (7%)]	Loss: 0.729507
[2022-06-13 01:53:25 | train] - Train Epoch: [189] [102400/1281167 (8%)]	Loss: 0.614700
[2022-06-13 01:53:48 | train] - Train Epoch: [189] [115200/1281167 (9%)]	Loss: 0.618707
[2022-06-13 01:54:10 | train] - Train Epoch: [189] [128000/1281167 (10%)]	Loss: 0.716793
[2022-06-13 01:54:32 | train] - Train Epoch: [189] [140800/1281167 (11%)]	Loss: 0.809229
[2022-06-13 01:54:54 | train] - Train Epoch: [189] [153600/1281167 (12%)]	Loss: 0.749370
[2022-06-13 01:55:16 | train] - Train Epoch: [189] [166400/1281167 (13%)]	Loss: 0.731446
[2022-06-13 01:55:39 | train] - Train Epoch: [189] [179200/1281167 (14%)]	Loss: 0.735310
[2022-06-13 01:56:01 | train] - Train Epoch: [189] [192000/1281167 (15%)]	Loss: 0.530894
[2022-06-13 01:56:23 | train] - Train Epoch: [189] [204800/1281167 (16%)]	Loss: 0.737010
[2022-06-13 01:56:44 | train] - Train Epoch: [189] [217600/1281167 (17%)]	Loss: 0.748160
[2022-06-13 01:57:06 | train] - Train Epoch: [189] [230400/1281167 (18%)]	Loss: 0.844020
[2022-06-13 01:57:29 | train] - Train Epoch: [189] [243200/1281167 (19%)]	Loss: 0.562612
[2022-06-13 01:57:50 | train] - Train Epoch: [189] [256000/1281167 (20%)]	Loss: 0.767372
[2022-06-13 01:58:11 | train] - Train Epoch: [189] [268800/1281167 (21%)]	Loss: 0.722438
[2022-06-13 01:58:33 | train] - Train Epoch: [189] [281600/1281167 (22%)]	Loss: 0.702069
[2022-06-13 01:58:55 | train] - Train Epoch: [189] [294400/1281167 (23%)]	Loss: 0.775694
[2022-06-13 01:59:17 | train] - Train Epoch: [189] [307200/1281167 (24%)]	Loss: 0.770035
[2022-06-13 01:59:39 | train] - Train Epoch: [189] [320000/1281167 (25%)]	Loss: 0.694391
[2022-06-13 02:00:00 | train] - Train Epoch: [189] [332800/1281167 (26%)]	Loss: 0.747666
[2022-06-13 02:00:23 | train] - Train Epoch: [189] [345600/1281167 (27%)]	Loss: 0.624199
[2022-06-13 02:00:44 | train] - Train Epoch: [189] [358400/1281167 (28%)]	Loss: 0.673754
[2022-06-13 02:01:07 | train] - Train Epoch: [189] [371200/1281167 (29%)]	Loss: 0.609451
[2022-06-13 02:01:27 | train] - Train Epoch: [189] [384000/1281167 (30%)]	Loss: 0.497804
[2022-06-13 02:01:49 | train] - Train Epoch: [189] [396800/1281167 (31%)]	Loss: 0.643427
[2022-06-13 02:02:11 | train] - Train Epoch: [189] [409600/1281167 (32%)]	Loss: 0.734949
[2022-06-13 02:02:34 | train] - Train Epoch: [189] [422400/1281167 (33%)]	Loss: 0.860632
[2022-06-13 02:02:56 | train] - Train Epoch: [189] [435200/1281167 (34%)]	Loss: 0.655928
[2022-06-13 02:03:18 | train] - Train Epoch: [189] [448000/1281167 (35%)]	Loss: 0.457647
[2022-06-13 02:03:40 | train] - Train Epoch: [189] [460800/1281167 (36%)]	Loss: 0.740614
[2022-06-13 02:04:01 | train] - Train Epoch: [189] [473600/1281167 (37%)]	Loss: 0.827981
[2022-06-13 02:04:23 | train] - Train Epoch: [189] [486400/1281167 (38%)]	Loss: 0.730296
[2022-06-13 02:04:45 | train] - Train Epoch: [189] [499200/1281167 (39%)]	Loss: 0.654896
[2022-06-13 02:05:07 | train] - Train Epoch: [189] [512000/1281167 (40%)]	Loss: 0.536525
[2022-06-13 02:05:29 | train] - Train Epoch: [189] [524800/1281167 (41%)]	Loss: 0.846682
[2022-06-13 02:05:51 | train] - Train Epoch: [189] [537600/1281167 (42%)]	Loss: 0.539565
[2022-06-13 02:06:12 | train] - Train Epoch: [189] [550400/1281167 (43%)]	Loss: 0.481856
[2022-06-13 02:06:33 | train] - Train Epoch: [189] [563200/1281167 (44%)]	Loss: 0.808434
[2022-06-13 02:06:55 | train] - Train Epoch: [189] [576000/1281167 (45%)]	Loss: 0.504586
[2022-06-13 02:07:17 | train] - Train Epoch: [189] [588800/1281167 (46%)]	Loss: 0.733592
[2022-06-13 02:07:39 | train] - Train Epoch: [189] [601600/1281167 (47%)]	Loss: 0.627860
[2022-06-13 02:08:01 | train] - Train Epoch: [189] [614400/1281167 (48%)]	Loss: 0.650464
[2022-06-13 02:08:23 | train] - Train Epoch: [189] [627200/1281167 (49%)]	Loss: 0.736121
[2022-06-13 02:08:45 | train] - Train Epoch: [189] [640000/1281167 (50%)]	Loss: 0.764520
[2022-06-13 02:09:07 | train] - Train Epoch: [189] [652800/1281167 (51%)]	Loss: 0.892608
[2022-06-13 02:09:29 | train] - Train Epoch: [189] [665600/1281167 (52%)]	Loss: 0.811936
[2022-06-13 02:09:51 | train] - Train Epoch: [189] [678400/1281167 (53%)]	Loss: 0.852186
[2022-06-13 02:10:13 | train] - Train Epoch: [189] [691200/1281167 (54%)]	Loss: 0.561635
[2022-06-13 02:10:36 | train] - Train Epoch: [189] [704000/1281167 (55%)]	Loss: 0.526291
[2022-06-13 02:10:57 | train] - Train Epoch: [189] [716800/1281167 (56%)]	Loss: 0.798931
[2022-06-13 02:11:19 | train] - Train Epoch: [189] [729600/1281167 (57%)]	Loss: 0.792325
[2022-06-13 02:11:41 | train] - Train Epoch: [189] [742400/1281167 (58%)]	Loss: 0.770514
[2022-06-13 02:12:02 | train] - Train Epoch: [189] [755200/1281167 (59%)]	Loss: 0.619515
[2022-06-13 02:12:24 | train] - Train Epoch: [189] [768000/1281167 (60%)]	Loss: 0.965539
[2022-06-13 02:12:46 | train] - Train Epoch: [189] [780800/1281167 (61%)]	Loss: 0.612522
[2022-06-13 02:13:08 | train] - Train Epoch: [189] [793600/1281167 (62%)]	Loss: 0.935194
[2022-06-13 02:13:29 | train] - Train Epoch: [189] [806400/1281167 (63%)]	Loss: 0.871045
[2022-06-13 02:13:51 | train] - Train Epoch: [189] [819200/1281167 (64%)]	Loss: 0.798258
[2022-06-13 02:14:13 | train] - Train Epoch: [189] [832000/1281167 (65%)]	Loss: 0.925335
[2022-06-13 02:14:35 | train] - Train Epoch: [189] [844800/1281167 (66%)]	Loss: 0.693664
[2022-06-13 02:14:57 | train] - Train Epoch: [189] [857600/1281167 (67%)]	Loss: 0.670549
[2022-06-13 02:15:19 | train] - Train Epoch: [189] [870400/1281167 (68%)]	Loss: 0.582028
[2022-06-13 02:15:41 | train] - Train Epoch: [189] [883200/1281167 (69%)]	Loss: 0.451086
[2022-06-13 02:16:03 | train] - Train Epoch: [189] [896000/1281167 (70%)]	Loss: 0.516727
[2022-06-13 02:16:24 | train] - Train Epoch: [189] [908800/1281167 (71%)]	Loss: 0.773528
[2022-06-13 02:16:47 | train] - Train Epoch: [189] [921600/1281167 (72%)]	Loss: 1.069111
[2022-06-13 02:17:09 | train] - Train Epoch: [189] [934400/1281167 (73%)]	Loss: 0.722091
[2022-06-13 02:17:31 | train] - Train Epoch: [189] [947200/1281167 (74%)]	Loss: 0.675669
[2022-06-13 02:17:54 | train] - Train Epoch: [189] [960000/1281167 (75%)]	Loss: 0.741985
[2022-06-13 02:18:16 | train] - Train Epoch: [189] [972800/1281167 (76%)]	Loss: 0.652228
[2022-06-13 02:18:37 | train] - Train Epoch: [189] [985600/1281167 (77%)]	Loss: 0.744691
[2022-06-13 02:18:59 | train] - Train Epoch: [189] [998400/1281167 (78%)]	Loss: 0.852819
[2022-06-13 02:19:21 | train] - Train Epoch: [189] [1011200/1281167 (79%)]	Loss: 0.771973
[2022-06-13 02:19:43 | train] - Train Epoch: [189] [1024000/1281167 (80%)]	Loss: 0.574115
[2022-06-13 02:20:05 | train] - Train Epoch: [189] [1036800/1281167 (81%)]	Loss: 0.881929
[2022-06-13 02:20:27 | train] - Train Epoch: [189] [1049600/1281167 (82%)]	Loss: 0.417297
[2022-06-13 02:20:49 | train] - Train Epoch: [189] [1062400/1281167 (83%)]	Loss: 0.750909
[2022-06-13 02:21:12 | train] - Train Epoch: [189] [1075200/1281167 (84%)]	Loss: 0.594544
[2022-06-13 02:21:34 | train] - Train Epoch: [189] [1088000/1281167 (85%)]	Loss: 0.624457
[2022-06-13 02:21:55 | train] - Train Epoch: [189] [1100800/1281167 (86%)]	Loss: 0.861274
[2022-06-13 02:22:16 | train] - Train Epoch: [189] [1113600/1281167 (87%)]	Loss: 0.685945
[2022-06-13 02:22:38 | train] - Train Epoch: [189] [1126400/1281167 (88%)]	Loss: 0.951095
[2022-06-13 02:23:00 | train] - Train Epoch: [189] [1139200/1281167 (89%)]	Loss: 0.675625
[2022-06-13 02:23:22 | train] - Train Epoch: [189] [1152000/1281167 (90%)]	Loss: 0.401055
[2022-06-13 02:23:43 | train] - Train Epoch: [189] [1164800/1281167 (91%)]	Loss: 0.604904
[2022-06-13 02:24:05 | train] - Train Epoch: [189] [1177600/1281167 (92%)]	Loss: 0.700451
[2022-06-13 02:24:27 | train] - Train Epoch: [189] [1190400/1281167 (93%)]	Loss: 0.888170
[2022-06-13 02:24:49 | train] - Train Epoch: [189] [1203200/1281167 (94%)]	Loss: 0.786479
[2022-06-13 02:25:11 | train] - Train Epoch: [189] [1216000/1281167 (95%)]	Loss: 0.715089
[2022-06-13 02:25:33 | train] - Train Epoch: [189] [1228800/1281167 (96%)]	Loss: 0.698719
[2022-06-13 02:25:55 | train] - Train Epoch: [189] [1241600/1281167 (97%)]	Loss: 0.767174
[2022-06-13 02:26:18 | train] - Train Epoch: [189] [1254400/1281167 (98%)]	Loss: 0.888370
[2022-06-13 02:26:40 | train] - Train Epoch: [189] [1267200/1281167 (99%)]	Loss: 0.718668
[2022-06-13 02:27:02 | train] - Train Epoch: [189] [1280000/1281167 (100%)]	Loss: 0.615363
[2022-06-13 02:27:04 | train] - Train Epoch: [189]	 Average Loss: 0.718654	 Total Acc : 82.5147	 Total Top5 Acc : 93.6862
[2022-06-13 02:27:04 | train] - -------189 epoch end-----------
========================================
-------189 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 02:28:37 | train] - 
Epoch [189] Test set: Average loss: 1.4373, Accuracy: 34958/50000 (69.8909%), Top-5 Accuracy: 88.8671%

[2022-06-13 02:28:37 | train] - save intermediate epoch [189] result


[2022-06-13 02:29:00 | train] - -------190 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 02:29:02 | train] - Train Epoch: [190] [0/1281167 (0%)]	Loss: 0.669164
[2022-06-13 02:29:24 | train] - Train Epoch: [190] [12800/1281167 (1%)]	Loss: 0.791631
[2022-06-13 02:29:45 | train] - Train Epoch: [190] [25600/1281167 (2%)]	Loss: 0.518736
[2022-06-13 02:30:05 | train] - Train Epoch: [190] [38400/1281167 (3%)]	Loss: 0.519699
[2022-06-13 02:30:26 | train] - Train Epoch: [190] [51200/1281167 (4%)]	Loss: 0.941912
[2022-06-13 02:30:47 | train] - Train Epoch: [190] [64000/1281167 (5%)]	Loss: 0.712991
[2022-06-13 02:31:09 | train] - Train Epoch: [190] [76800/1281167 (6%)]	Loss: 0.739010
[2022-06-13 02:31:31 | train] - Train Epoch: [190] [89600/1281167 (7%)]	Loss: 0.691340
[2022-06-13 02:31:53 | train] - Train Epoch: [190] [102400/1281167 (8%)]	Loss: 0.489420
[2022-06-13 02:32:15 | train] - Train Epoch: [190] [115200/1281167 (9%)]	Loss: 0.817290
[2022-06-13 02:32:37 | train] - Train Epoch: [190] [128000/1281167 (10%)]	Loss: 0.719887
[2022-06-13 02:32:58 | train] - Train Epoch: [190] [140800/1281167 (11%)]	Loss: 1.011993
[2022-06-13 02:33:19 | train] - Train Epoch: [190] [153600/1281167 (12%)]	Loss: 0.798866
[2022-06-13 02:33:42 | train] - Train Epoch: [190] [166400/1281167 (13%)]	Loss: 0.634615
[2022-06-13 02:34:03 | train] - Train Epoch: [190] [179200/1281167 (14%)]	Loss: 0.536075
[2022-06-13 02:34:25 | train] - Train Epoch: [190] [192000/1281167 (15%)]	Loss: 0.853409
[2022-06-13 02:34:47 | train] - Train Epoch: [190] [204800/1281167 (16%)]	Loss: 0.648740
[2022-06-13 02:35:09 | train] - Train Epoch: [190] [217600/1281167 (17%)]	Loss: 0.864666
[2022-06-13 02:35:30 | train] - Train Epoch: [190] [230400/1281167 (18%)]	Loss: 0.910536
[2022-06-13 02:35:52 | train] - Train Epoch: [190] [243200/1281167 (19%)]	Loss: 0.775324
[2022-06-13 02:36:15 | train] - Train Epoch: [190] [256000/1281167 (20%)]	Loss: 1.039027
[2022-06-13 02:36:36 | train] - Train Epoch: [190] [268800/1281167 (21%)]	Loss: 0.655911
[2022-06-13 02:36:57 | train] - Train Epoch: [190] [281600/1281167 (22%)]	Loss: 0.572234
[2022-06-13 02:37:18 | train] - Train Epoch: [190] [294400/1281167 (23%)]	Loss: 0.612470
[2022-06-13 02:37:40 | train] - Train Epoch: [190] [307200/1281167 (24%)]	Loss: 0.858207
[2022-06-13 02:38:01 | train] - Train Epoch: [190] [320000/1281167 (25%)]	Loss: 0.584979
[2022-06-13 02:38:21 | train] - Train Epoch: [190] [332800/1281167 (26%)]	Loss: 0.868875
[2022-06-13 02:38:42 | train] - Train Epoch: [190] [345600/1281167 (27%)]	Loss: 0.803861
[2022-06-13 02:39:03 | train] - Train Epoch: [190] [358400/1281167 (28%)]	Loss: 0.974489
[2022-06-13 02:39:23 | train] - Train Epoch: [190] [371200/1281167 (29%)]	Loss: 0.722922
[2022-06-13 02:39:44 | train] - Train Epoch: [190] [384000/1281167 (30%)]	Loss: 0.704843
[2022-06-13 02:40:06 | train] - Train Epoch: [190] [396800/1281167 (31%)]	Loss: 0.942330
[2022-06-13 02:40:27 | train] - Train Epoch: [190] [409600/1281167 (32%)]	Loss: 0.859362
[2022-06-13 02:40:49 | train] - Train Epoch: [190] [422400/1281167 (33%)]	Loss: 0.712789
[2022-06-13 02:41:10 | train] - Train Epoch: [190] [435200/1281167 (34%)]	Loss: 0.402934
[2022-06-13 02:41:31 | train] - Train Epoch: [190] [448000/1281167 (35%)]	Loss: 0.670041
[2022-06-13 02:41:53 | train] - Train Epoch: [190] [460800/1281167 (36%)]	Loss: 0.644863
[2022-06-13 02:42:14 | train] - Train Epoch: [190] [473600/1281167 (37%)]	Loss: 0.582994
[2022-06-13 02:42:35 | train] - Train Epoch: [190] [486400/1281167 (38%)]	Loss: 0.862003
[2022-06-13 02:42:56 | train] - Train Epoch: [190] [499200/1281167 (39%)]	Loss: 0.552024
[2022-06-13 02:43:17 | train] - Train Epoch: [190] [512000/1281167 (40%)]	Loss: 0.802252
[2022-06-13 02:43:37 | train] - Train Epoch: [190] [524800/1281167 (41%)]	Loss: 0.911935
[2022-06-13 02:43:58 | train] - Train Epoch: [190] [537600/1281167 (42%)]	Loss: 0.667669
[2022-06-13 02:44:19 | train] - Train Epoch: [190] [550400/1281167 (43%)]	Loss: 0.948498
[2022-06-13 02:44:40 | train] - Train Epoch: [190] [563200/1281167 (44%)]	Loss: 0.712289
[2022-06-13 02:45:01 | train] - Train Epoch: [190] [576000/1281167 (45%)]	Loss: 0.538851
[2022-06-13 02:45:21 | train] - Train Epoch: [190] [588800/1281167 (46%)]	Loss: 0.481636
[2022-06-13 02:45:43 | train] - Train Epoch: [190] [601600/1281167 (47%)]	Loss: 0.888223
[2022-06-13 02:46:03 | train] - Train Epoch: [190] [614400/1281167 (48%)]	Loss: 0.711590
[2022-06-13 02:46:24 | train] - Train Epoch: [190] [627200/1281167 (49%)]	Loss: 0.889706
[2022-06-13 02:46:44 | train] - Train Epoch: [190] [640000/1281167 (50%)]	Loss: 0.799439
[2022-06-13 02:47:05 | train] - Train Epoch: [190] [652800/1281167 (51%)]	Loss: 0.637608
[2022-06-13 02:47:26 | train] - Train Epoch: [190] [665600/1281167 (52%)]	Loss: 0.656194
[2022-06-13 02:47:47 | train] - Train Epoch: [190] [678400/1281167 (53%)]	Loss: 0.974402
[2022-06-13 02:48:08 | train] - Train Epoch: [190] [691200/1281167 (54%)]	Loss: 0.454230
[2022-06-13 02:48:28 | train] - Train Epoch: [190] [704000/1281167 (55%)]	Loss: 0.641154
[2022-06-13 02:48:49 | train] - Train Epoch: [190] [716800/1281167 (56%)]	Loss: 0.716251
[2022-06-13 02:49:09 | train] - Train Epoch: [190] [729600/1281167 (57%)]	Loss: 0.946732
[2022-06-13 02:49:29 | train] - Train Epoch: [190] [742400/1281167 (58%)]	Loss: 0.685753
[2022-06-13 02:49:50 | train] - Train Epoch: [190] [755200/1281167 (59%)]	Loss: 0.576966
[2022-06-13 02:50:11 | train] - Train Epoch: [190] [768000/1281167 (60%)]	Loss: 0.771375
[2022-06-13 02:50:31 | train] - Train Epoch: [190] [780800/1281167 (61%)]	Loss: 0.539156
[2022-06-13 02:50:51 | train] - Train Epoch: [190] [793600/1281167 (62%)]	Loss: 0.584330
[2022-06-13 02:51:12 | train] - Train Epoch: [190] [806400/1281167 (63%)]	Loss: 0.798111
[2022-06-13 02:51:32 | train] - Train Epoch: [190] [819200/1281167 (64%)]	Loss: 0.791625
[2022-06-13 02:51:52 | train] - Train Epoch: [190] [832000/1281167 (65%)]	Loss: 0.669066
[2022-06-13 02:52:13 | train] - Train Epoch: [190] [844800/1281167 (66%)]	Loss: 0.690932
[2022-06-13 02:52:33 | train] - Train Epoch: [190] [857600/1281167 (67%)]	Loss: 0.821409
[2022-06-13 02:52:54 | train] - Train Epoch: [190] [870400/1281167 (68%)]	Loss: 0.575488
[2022-06-13 02:53:15 | train] - Train Epoch: [190] [883200/1281167 (69%)]	Loss: 0.648025
[2022-06-13 02:53:35 | train] - Train Epoch: [190] [896000/1281167 (70%)]	Loss: 0.602700
[2022-06-13 02:53:55 | train] - Train Epoch: [190] [908800/1281167 (71%)]	Loss: 0.754704
[2022-06-13 02:54:16 | train] - Train Epoch: [190] [921600/1281167 (72%)]	Loss: 0.782866
[2022-06-13 02:54:35 | train] - Train Epoch: [190] [934400/1281167 (73%)]	Loss: 0.653705
[2022-06-13 02:54:56 | train] - Train Epoch: [190] [947200/1281167 (74%)]	Loss: 0.811900
[2022-06-13 02:55:16 | train] - Train Epoch: [190] [960000/1281167 (75%)]	Loss: 0.545417
[2022-06-13 02:55:37 | train] - Train Epoch: [190] [972800/1281167 (76%)]	Loss: 0.594687
[2022-06-13 02:55:58 | train] - Train Epoch: [190] [985600/1281167 (77%)]	Loss: 0.814359
[2022-06-13 02:56:19 | train] - Train Epoch: [190] [998400/1281167 (78%)]	Loss: 0.788322
[2022-06-13 02:56:40 | train] - Train Epoch: [190] [1011200/1281167 (79%)]	Loss: 1.046420
[2022-06-13 02:57:01 | train] - Train Epoch: [190] [1024000/1281167 (80%)]	Loss: 0.835446
[2022-06-13 02:57:21 | train] - Train Epoch: [190] [1036800/1281167 (81%)]	Loss: 0.956226
[2022-06-13 02:57:41 | train] - Train Epoch: [190] [1049600/1281167 (82%)]	Loss: 0.891890
[2022-06-13 02:58:02 | train] - Train Epoch: [190] [1062400/1281167 (83%)]	Loss: 0.848796
[2022-06-13 02:58:22 | train] - Train Epoch: [190] [1075200/1281167 (84%)]	Loss: 0.784806
[2022-06-13 02:58:41 | train] - Train Epoch: [190] [1088000/1281167 (85%)]	Loss: 0.823152
[2022-06-13 02:59:02 | train] - Train Epoch: [190] [1100800/1281167 (86%)]	Loss: 0.782357
[2022-06-13 02:59:22 | train] - Train Epoch: [190] [1113600/1281167 (87%)]	Loss: 0.786673
[2022-06-13 02:59:42 | train] - Train Epoch: [190] [1126400/1281167 (88%)]	Loss: 0.823951
[2022-06-13 03:00:02 | train] - Train Epoch: [190] [1139200/1281167 (89%)]	Loss: 0.701609
[2022-06-13 03:00:23 | train] - Train Epoch: [190] [1152000/1281167 (90%)]	Loss: 0.799591
[2022-06-13 03:00:44 | train] - Train Epoch: [190] [1164800/1281167 (91%)]	Loss: 0.552133
[2022-06-13 03:01:05 | train] - Train Epoch: [190] [1177600/1281167 (92%)]	Loss: 0.936617
[2022-06-13 03:01:26 | train] - Train Epoch: [190] [1190400/1281167 (93%)]	Loss: 0.657856
[2022-06-13 03:01:47 | train] - Train Epoch: [190] [1203200/1281167 (94%)]	Loss: 0.840950
[2022-06-13 03:02:08 | train] - Train Epoch: [190] [1216000/1281167 (95%)]	Loss: 0.820753
[2022-06-13 03:02:29 | train] - Train Epoch: [190] [1228800/1281167 (96%)]	Loss: 0.683751
[2022-06-13 03:02:51 | train] - Train Epoch: [190] [1241600/1281167 (97%)]	Loss: 0.765086
[2022-06-13 03:03:11 | train] - Train Epoch: [190] [1254400/1281167 (98%)]	Loss: 0.622730
[2022-06-13 03:03:32 | train] - Train Epoch: [190] [1267200/1281167 (99%)]	Loss: 0.355127
[2022-06-13 03:03:52 | train] - Train Epoch: [190] [1280000/1281167 (100%)]	Loss: 0.677623
[2022-06-13 03:03:54 | train] - Train Epoch: [190]	 Average Loss: 0.719238	 Total Acc : 82.5157	 Total Top5 Acc : 93.6552
[2022-06-13 03:03:54 | train] - -------190 epoch end-----------
========================================
-------190 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 03:05:26 | train] - 
Epoch [190] Test set: Average loss: 1.4419, Accuracy: 34934/50000 (69.8370%), Top-5 Accuracy: 88.8163%

[2022-06-13 03:05:26 | train] - save intermediate epoch [190] result


[2022-06-13 03:05:49 | train] - -------191 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 03:05:51 | train] - Train Epoch: [191] [0/1281167 (0%)]	Loss: 0.762611
[2022-06-13 03:06:13 | train] - Train Epoch: [191] [12800/1281167 (1%)]	Loss: 0.581064
[2022-06-13 03:06:34 | train] - Train Epoch: [191] [25600/1281167 (2%)]	Loss: 0.708151
[2022-06-13 03:06:56 | train] - Train Epoch: [191] [38400/1281167 (3%)]	Loss: 0.495060
[2022-06-13 03:07:18 | train] - Train Epoch: [191] [51200/1281167 (4%)]	Loss: 0.506466
[2022-06-13 03:07:40 | train] - Train Epoch: [191] [64000/1281167 (5%)]	Loss: 0.933231
[2022-06-13 03:08:02 | train] - Train Epoch: [191] [76800/1281167 (6%)]	Loss: 0.839644
[2022-06-13 03:08:24 | train] - Train Epoch: [191] [89600/1281167 (7%)]	Loss: 0.813865
[2022-06-13 03:08:46 | train] - Train Epoch: [191] [102400/1281167 (8%)]	Loss: 0.747368
[2022-06-13 03:09:08 | train] - Train Epoch: [191] [115200/1281167 (9%)]	Loss: 1.096909
[2022-06-13 03:09:30 | train] - Train Epoch: [191] [128000/1281167 (10%)]	Loss: 0.599516
[2022-06-13 03:09:52 | train] - Train Epoch: [191] [140800/1281167 (11%)]	Loss: 0.954718
[2022-06-13 03:10:14 | train] - Train Epoch: [191] [153600/1281167 (12%)]	Loss: 0.723645
[2022-06-13 03:10:36 | train] - Train Epoch: [191] [166400/1281167 (13%)]	Loss: 0.705997
[2022-06-13 03:10:58 | train] - Train Epoch: [191] [179200/1281167 (14%)]	Loss: 0.698626
[2022-06-13 03:11:20 | train] - Train Epoch: [191] [192000/1281167 (15%)]	Loss: 0.788727
[2022-06-13 03:11:42 | train] - Train Epoch: [191] [204800/1281167 (16%)]	Loss: 0.555601
[2022-06-13 03:12:04 | train] - Train Epoch: [191] [217600/1281167 (17%)]	Loss: 0.690977
[2022-06-13 03:12:26 | train] - Train Epoch: [191] [230400/1281167 (18%)]	Loss: 0.552828
[2022-06-13 03:12:48 | train] - Train Epoch: [191] [243200/1281167 (19%)]	Loss: 0.627444
[2022-06-13 03:13:10 | train] - Train Epoch: [191] [256000/1281167 (20%)]	Loss: 0.737202
[2022-06-13 03:13:31 | train] - Train Epoch: [191] [268800/1281167 (21%)]	Loss: 0.555713
[2022-06-13 03:13:53 | train] - Train Epoch: [191] [281600/1281167 (22%)]	Loss: 0.628712
[2022-06-13 03:14:15 | train] - Train Epoch: [191] [294400/1281167 (23%)]	Loss: 0.588236
[2022-06-13 03:14:37 | train] - Train Epoch: [191] [307200/1281167 (24%)]	Loss: 0.625480
[2022-06-13 03:15:00 | train] - Train Epoch: [191] [320000/1281167 (25%)]	Loss: 0.731074
[2022-06-13 03:15:23 | train] - Train Epoch: [191] [332800/1281167 (26%)]	Loss: 0.463475
[2022-06-13 03:15:44 | train] - Train Epoch: [191] [345600/1281167 (27%)]	Loss: 0.954517
[2022-06-13 03:16:06 | train] - Train Epoch: [191] [358400/1281167 (28%)]	Loss: 0.847477
[2022-06-13 03:16:28 | train] - Train Epoch: [191] [371200/1281167 (29%)]	Loss: 0.767314
[2022-06-13 03:16:50 | train] - Train Epoch: [191] [384000/1281167 (30%)]	Loss: 0.815690
[2022-06-13 03:17:12 | train] - Train Epoch: [191] [396800/1281167 (31%)]	Loss: 0.747289
[2022-06-13 03:17:34 | train] - Train Epoch: [191] [409600/1281167 (32%)]	Loss: 0.569317
[2022-06-13 03:17:56 | train] - Train Epoch: [191] [422400/1281167 (33%)]	Loss: 0.488446
[2022-06-13 03:18:17 | train] - Train Epoch: [191] [435200/1281167 (34%)]	Loss: 1.000911
[2022-06-13 03:18:38 | train] - Train Epoch: [191] [448000/1281167 (35%)]	Loss: 0.733183
[2022-06-13 03:19:00 | train] - Train Epoch: [191] [460800/1281167 (36%)]	Loss: 0.671963
[2022-06-13 03:19:21 | train] - Train Epoch: [191] [473600/1281167 (37%)]	Loss: 0.654534
[2022-06-13 03:19:44 | train] - Train Epoch: [191] [486400/1281167 (38%)]	Loss: 0.695231
[2022-06-13 03:20:07 | train] - Train Epoch: [191] [499200/1281167 (39%)]	Loss: 0.813969
[2022-06-13 03:20:27 | train] - Train Epoch: [191] [512000/1281167 (40%)]	Loss: 0.617922
[2022-06-13 03:20:50 | train] - Train Epoch: [191] [524800/1281167 (41%)]	Loss: 0.898222
[2022-06-13 03:21:12 | train] - Train Epoch: [191] [537600/1281167 (42%)]	Loss: 0.929075
[2022-06-13 03:21:34 | train] - Train Epoch: [191] [550400/1281167 (43%)]	Loss: 0.724260
[2022-06-13 03:21:56 | train] - Train Epoch: [191] [563200/1281167 (44%)]	Loss: 0.633627
[2022-06-13 03:22:18 | train] - Train Epoch: [191] [576000/1281167 (45%)]	Loss: 0.444475
[2022-06-13 03:22:40 | train] - Train Epoch: [191] [588800/1281167 (46%)]	Loss: 0.507613
[2022-06-13 03:23:02 | train] - Train Epoch: [191] [601600/1281167 (47%)]	Loss: 0.706121
[2022-06-13 03:23:25 | train] - Train Epoch: [191] [614400/1281167 (48%)]	Loss: 0.724314
[2022-06-13 03:23:47 | train] - Train Epoch: [191] [627200/1281167 (49%)]	Loss: 0.735195
[2022-06-13 03:24:09 | train] - Train Epoch: [191] [640000/1281167 (50%)]	Loss: 0.652523
[2022-06-13 03:24:31 | train] - Train Epoch: [191] [652800/1281167 (51%)]	Loss: 0.790249
[2022-06-13 03:24:53 | train] - Train Epoch: [191] [665600/1281167 (52%)]	Loss: 0.952351
[2022-06-13 03:25:15 | train] - Train Epoch: [191] [678400/1281167 (53%)]	Loss: 0.744350
[2022-06-13 03:25:37 | train] - Train Epoch: [191] [691200/1281167 (54%)]	Loss: 0.737672
[2022-06-13 03:25:59 | train] - Train Epoch: [191] [704000/1281167 (55%)]	Loss: 0.836114
[2022-06-13 03:26:20 | train] - Train Epoch: [191] [716800/1281167 (56%)]	Loss: 0.637225
[2022-06-13 03:26:43 | train] - Train Epoch: [191] [729600/1281167 (57%)]	Loss: 0.789781
[2022-06-13 03:27:05 | train] - Train Epoch: [191] [742400/1281167 (58%)]	Loss: 0.861063
[2022-06-13 03:27:27 | train] - Train Epoch: [191] [755200/1281167 (59%)]	Loss: 0.633134
[2022-06-13 03:27:48 | train] - Train Epoch: [191] [768000/1281167 (60%)]	Loss: 0.653823
[2022-06-13 03:28:10 | train] - Train Epoch: [191] [780800/1281167 (61%)]	Loss: 1.047820
[2022-06-13 03:28:31 | train] - Train Epoch: [191] [793600/1281167 (62%)]	Loss: 0.919105
[2022-06-13 03:28:53 | train] - Train Epoch: [191] [806400/1281167 (63%)]	Loss: 0.579779
[2022-06-13 03:29:14 | train] - Train Epoch: [191] [819200/1281167 (64%)]	Loss: 0.892739
[2022-06-13 03:29:36 | train] - Train Epoch: [191] [832000/1281167 (65%)]	Loss: 0.727367
[2022-06-13 03:29:58 | train] - Train Epoch: [191] [844800/1281167 (66%)]	Loss: 0.748404
[2022-06-13 03:30:21 | train] - Train Epoch: [191] [857600/1281167 (67%)]	Loss: 0.509209
[2022-06-13 03:30:42 | train] - Train Epoch: [191] [870400/1281167 (68%)]	Loss: 0.671280
[2022-06-13 03:31:04 | train] - Train Epoch: [191] [883200/1281167 (69%)]	Loss: 0.702765
[2022-06-13 03:31:25 | train] - Train Epoch: [191] [896000/1281167 (70%)]	Loss: 0.815626
[2022-06-13 03:31:47 | train] - Train Epoch: [191] [908800/1281167 (71%)]	Loss: 0.916483
[2022-06-13 03:32:09 | train] - Train Epoch: [191] [921600/1281167 (72%)]	Loss: 0.711223
[2022-06-13 03:32:31 | train] - Train Epoch: [191] [934400/1281167 (73%)]	Loss: 0.676370
[2022-06-13 03:32:53 | train] - Train Epoch: [191] [947200/1281167 (74%)]	Loss: 0.590441
[2022-06-13 03:33:15 | train] - Train Epoch: [191] [960000/1281167 (75%)]	Loss: 0.838152
[2022-06-13 03:33:37 | train] - Train Epoch: [191] [972800/1281167 (76%)]	Loss: 0.920305
[2022-06-13 03:33:59 | train] - Train Epoch: [191] [985600/1281167 (77%)]	Loss: 1.040696
[2022-06-13 03:34:21 | train] - Train Epoch: [191] [998400/1281167 (78%)]	Loss: 0.826358
[2022-06-13 03:34:43 | train] - Train Epoch: [191] [1011200/1281167 (79%)]	Loss: 0.704558
[2022-06-13 03:35:04 | train] - Train Epoch: [191] [1024000/1281167 (80%)]	Loss: 0.627361
[2022-06-13 03:35:27 | train] - Train Epoch: [191] [1036800/1281167 (81%)]	Loss: 1.012598
[2022-06-13 03:35:49 | train] - Train Epoch: [191] [1049600/1281167 (82%)]	Loss: 0.787071
[2022-06-13 03:36:12 | train] - Train Epoch: [191] [1062400/1281167 (83%)]	Loss: 0.915898
[2022-06-13 03:36:34 | train] - Train Epoch: [191] [1075200/1281167 (84%)]	Loss: 0.671428
[2022-06-13 03:36:56 | train] - Train Epoch: [191] [1088000/1281167 (85%)]	Loss: 0.652231
[2022-06-13 03:37:18 | train] - Train Epoch: [191] [1100800/1281167 (86%)]	Loss: 0.749832
[2022-06-13 03:37:40 | train] - Train Epoch: [191] [1113600/1281167 (87%)]	Loss: 0.733711
[2022-06-13 03:38:02 | train] - Train Epoch: [191] [1126400/1281167 (88%)]	Loss: 0.761919
[2022-06-13 03:38:25 | train] - Train Epoch: [191] [1139200/1281167 (89%)]	Loss: 0.867893
[2022-06-13 03:38:47 | train] - Train Epoch: [191] [1152000/1281167 (90%)]	Loss: 0.802216
[2022-06-13 03:39:09 | train] - Train Epoch: [191] [1164800/1281167 (91%)]	Loss: 0.623918
[2022-06-13 03:39:31 | train] - Train Epoch: [191] [1177600/1281167 (92%)]	Loss: 0.615738
[2022-06-13 03:39:53 | train] - Train Epoch: [191] [1190400/1281167 (93%)]	Loss: 0.784425
[2022-06-13 03:40:15 | train] - Train Epoch: [191] [1203200/1281167 (94%)]	Loss: 0.566187
[2022-06-13 03:40:38 | train] - Train Epoch: [191] [1216000/1281167 (95%)]	Loss: 0.576583
[2022-06-13 03:41:00 | train] - Train Epoch: [191] [1228800/1281167 (96%)]	Loss: 0.707575
[2022-06-13 03:41:22 | train] - Train Epoch: [191] [1241600/1281167 (97%)]	Loss: 0.778178
[2022-06-13 03:41:44 | train] - Train Epoch: [191] [1254400/1281167 (98%)]	Loss: 0.716706
[2022-06-13 03:42:06 | train] - Train Epoch: [191] [1267200/1281167 (99%)]	Loss: 0.597050
[2022-06-13 03:42:29 | train] - Train Epoch: [191] [1280000/1281167 (100%)]	Loss: 0.470386
[2022-06-13 03:42:31 | train] - Train Epoch: [191]	 Average Loss: 0.718568	 Total Acc : 82.5366	 Total Top5 Acc : 93.6626
[2022-06-13 03:42:31 | train] - -------191 epoch end-----------
========================================
-------191 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 03:44:04 | train] - 
Epoch [191] Test set: Average loss: 1.4320, Accuracy: 34957/50000 (69.8853%), Top-5 Accuracy: 88.9402%

[2022-06-13 03:44:04 | train] - save intermediate epoch [191] result


[2022-06-13 03:44:27 | train] - -------192 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 03:44:29 | train] - Train Epoch: [192] [0/1281167 (0%)]	Loss: 0.594847
[2022-06-13 03:44:52 | train] - Train Epoch: [192] [12800/1281167 (1%)]	Loss: 0.597385
[2022-06-13 03:45:14 | train] - Train Epoch: [192] [25600/1281167 (2%)]	Loss: 0.726195
[2022-06-13 03:45:37 | train] - Train Epoch: [192] [38400/1281167 (3%)]	Loss: 0.876065
[2022-06-13 03:45:59 | train] - Train Epoch: [192] [51200/1281167 (4%)]	Loss: 0.971806
[2022-06-13 03:46:20 | train] - Train Epoch: [192] [64000/1281167 (5%)]	Loss: 0.682497
[2022-06-13 03:46:42 | train] - Train Epoch: [192] [76800/1281167 (6%)]	Loss: 0.799386
[2022-06-13 03:47:04 | train] - Train Epoch: [192] [89600/1281167 (7%)]	Loss: 0.473127
[2022-06-13 03:47:26 | train] - Train Epoch: [192] [102400/1281167 (8%)]	Loss: 0.419763
[2022-06-13 03:47:49 | train] - Train Epoch: [192] [115200/1281167 (9%)]	Loss: 0.818114
[2022-06-13 03:48:11 | train] - Train Epoch: [192] [128000/1281167 (10%)]	Loss: 0.594473
[2022-06-13 03:48:33 | train] - Train Epoch: [192] [140800/1281167 (11%)]	Loss: 0.564372
[2022-06-13 03:48:55 | train] - Train Epoch: [192] [153600/1281167 (12%)]	Loss: 0.543447
[2022-06-13 03:49:17 | train] - Train Epoch: [192] [166400/1281167 (13%)]	Loss: 0.818190
[2022-06-13 03:49:39 | train] - Train Epoch: [192] [179200/1281167 (14%)]	Loss: 0.647759
[2022-06-13 03:50:01 | train] - Train Epoch: [192] [192000/1281167 (15%)]	Loss: 0.591976
[2022-06-13 03:50:24 | train] - Train Epoch: [192] [204800/1281167 (16%)]	Loss: 0.773642
[2022-06-13 03:50:46 | train] - Train Epoch: [192] [217600/1281167 (17%)]	Loss: 0.951522
[2022-06-13 03:51:07 | train] - Train Epoch: [192] [230400/1281167 (18%)]	Loss: 0.626933
[2022-06-13 03:51:29 | train] - Train Epoch: [192] [243200/1281167 (19%)]	Loss: 0.584280
[2022-06-13 03:51:52 | train] - Train Epoch: [192] [256000/1281167 (20%)]	Loss: 0.899195
[2022-06-13 03:52:13 | train] - Train Epoch: [192] [268800/1281167 (21%)]	Loss: 0.900806
[2022-06-13 03:52:36 | train] - Train Epoch: [192] [281600/1281167 (22%)]	Loss: 0.719929
[2022-06-13 03:52:58 | train] - Train Epoch: [192] [294400/1281167 (23%)]	Loss: 0.450362
[2022-06-13 03:53:20 | train] - Train Epoch: [192] [307200/1281167 (24%)]	Loss: 0.838508
[2022-06-13 03:53:42 | train] - Train Epoch: [192] [320000/1281167 (25%)]	Loss: 0.861764
[2022-06-13 03:54:04 | train] - Train Epoch: [192] [332800/1281167 (26%)]	Loss: 0.734698
[2022-06-13 03:54:26 | train] - Train Epoch: [192] [345600/1281167 (27%)]	Loss: 0.647015
[2022-06-13 03:54:49 | train] - Train Epoch: [192] [358400/1281167 (28%)]	Loss: 0.656548
[2022-06-13 03:55:10 | train] - Train Epoch: [192] [371200/1281167 (29%)]	Loss: 0.657237
[2022-06-13 03:55:32 | train] - Train Epoch: [192] [384000/1281167 (30%)]	Loss: 0.672314
[2022-06-13 03:55:54 | train] - Train Epoch: [192] [396800/1281167 (31%)]	Loss: 0.492712
[2022-06-13 03:56:16 | train] - Train Epoch: [192] [409600/1281167 (32%)]	Loss: 0.716209
[2022-06-13 03:56:38 | train] - Train Epoch: [192] [422400/1281167 (33%)]	Loss: 0.847977
[2022-06-13 03:57:00 | train] - Train Epoch: [192] [435200/1281167 (34%)]	Loss: 0.850236
[2022-06-13 03:57:23 | train] - Train Epoch: [192] [448000/1281167 (35%)]	Loss: 0.606364
[2022-06-13 03:57:45 | train] - Train Epoch: [192] [460800/1281167 (36%)]	Loss: 0.717797
[2022-06-13 03:58:07 | train] - Train Epoch: [192] [473600/1281167 (37%)]	Loss: 0.586447
[2022-06-13 03:58:30 | train] - Train Epoch: [192] [486400/1281167 (38%)]	Loss: 0.730661
[2022-06-13 03:58:52 | train] - Train Epoch: [192] [499200/1281167 (39%)]	Loss: 0.709480
[2022-06-13 03:59:14 | train] - Train Epoch: [192] [512000/1281167 (40%)]	Loss: 0.854083
[2022-06-13 03:59:36 | train] - Train Epoch: [192] [524800/1281167 (41%)]	Loss: 0.875913
[2022-06-13 03:59:58 | train] - Train Epoch: [192] [537600/1281167 (42%)]	Loss: 0.789416
[2022-06-13 04:00:21 | train] - Train Epoch: [192] [550400/1281167 (43%)]	Loss: 0.659998
[2022-06-13 04:00:44 | train] - Train Epoch: [192] [563200/1281167 (44%)]	Loss: 0.852915
[2022-06-13 04:01:06 | train] - Train Epoch: [192] [576000/1281167 (45%)]	Loss: 0.846461
[2022-06-13 04:01:27 | train] - Train Epoch: [192] [588800/1281167 (46%)]	Loss: 0.661111
[2022-06-13 04:01:50 | train] - Train Epoch: [192] [601600/1281167 (47%)]	Loss: 0.666885
[2022-06-13 04:02:12 | train] - Train Epoch: [192] [614400/1281167 (48%)]	Loss: 1.119674
[2022-06-13 04:02:34 | train] - Train Epoch: [192] [627200/1281167 (49%)]	Loss: 0.589734
[2022-06-13 04:02:56 | train] - Train Epoch: [192] [640000/1281167 (50%)]	Loss: 0.705329
[2022-06-13 04:03:18 | train] - Train Epoch: [192] [652800/1281167 (51%)]	Loss: 0.575349
[2022-06-13 04:03:41 | train] - Train Epoch: [192] [665600/1281167 (52%)]	Loss: 0.871402
[2022-06-13 04:04:03 | train] - Train Epoch: [192] [678400/1281167 (53%)]	Loss: 0.756768
[2022-06-13 04:04:25 | train] - Train Epoch: [192] [691200/1281167 (54%)]	Loss: 0.681160
[2022-06-13 04:04:48 | train] - Train Epoch: [192] [704000/1281167 (55%)]	Loss: 0.611285
[2022-06-13 04:05:10 | train] - Train Epoch: [192] [716800/1281167 (56%)]	Loss: 0.811934
[2022-06-13 04:05:33 | train] - Train Epoch: [192] [729600/1281167 (57%)]	Loss: 0.504897
[2022-06-13 04:05:56 | train] - Train Epoch: [192] [742400/1281167 (58%)]	Loss: 0.687850
[2022-06-13 04:06:18 | train] - Train Epoch: [192] [755200/1281167 (59%)]	Loss: 0.726726
[2022-06-13 04:06:40 | train] - Train Epoch: [192] [768000/1281167 (60%)]	Loss: 0.724184
[2022-06-13 04:07:02 | train] - Train Epoch: [192] [780800/1281167 (61%)]	Loss: 0.715662
[2022-06-13 04:07:25 | train] - Train Epoch: [192] [793600/1281167 (62%)]	Loss: 1.165292
[2022-06-13 04:07:46 | train] - Train Epoch: [192] [806400/1281167 (63%)]	Loss: 0.826384
[2022-06-13 04:08:08 | train] - Train Epoch: [192] [819200/1281167 (64%)]	Loss: 0.697480
[2022-06-13 04:08:30 | train] - Train Epoch: [192] [832000/1281167 (65%)]	Loss: 0.828652
[2022-06-13 04:08:52 | train] - Train Epoch: [192] [844800/1281167 (66%)]	Loss: 0.667083
[2022-06-13 04:09:15 | train] - Train Epoch: [192] [857600/1281167 (67%)]	Loss: 0.679213
[2022-06-13 04:09:36 | train] - Train Epoch: [192] [870400/1281167 (68%)]	Loss: 0.741330
[2022-06-13 04:09:58 | train] - Train Epoch: [192] [883200/1281167 (69%)]	Loss: 0.762881
[2022-06-13 04:10:20 | train] - Train Epoch: [192] [896000/1281167 (70%)]	Loss: 0.872813
[2022-06-13 04:10:42 | train] - Train Epoch: [192] [908800/1281167 (71%)]	Loss: 0.681240
[2022-06-13 04:11:04 | train] - Train Epoch: [192] [921600/1281167 (72%)]	Loss: 0.613190
[2022-06-13 04:11:26 | train] - Train Epoch: [192] [934400/1281167 (73%)]	Loss: 0.722019
[2022-06-13 04:11:48 | train] - Train Epoch: [192] [947200/1281167 (74%)]	Loss: 0.769291
[2022-06-13 04:12:11 | train] - Train Epoch: [192] [960000/1281167 (75%)]	Loss: 0.883961
[2022-06-13 04:12:33 | train] - Train Epoch: [192] [972800/1281167 (76%)]	Loss: 0.767212
[2022-06-13 04:12:56 | train] - Train Epoch: [192] [985600/1281167 (77%)]	Loss: 0.684666
[2022-06-13 04:13:18 | train] - Train Epoch: [192] [998400/1281167 (78%)]	Loss: 0.770079
[2022-06-13 04:13:40 | train] - Train Epoch: [192] [1011200/1281167 (79%)]	Loss: 0.730313
[2022-06-13 04:14:02 | train] - Train Epoch: [192] [1024000/1281167 (80%)]	Loss: 0.837117
[2022-06-13 04:14:24 | train] - Train Epoch: [192] [1036800/1281167 (81%)]	Loss: 0.979144
[2022-06-13 04:14:46 | train] - Train Epoch: [192] [1049600/1281167 (82%)]	Loss: 0.579220
[2022-06-13 04:15:09 | train] - Train Epoch: [192] [1062400/1281167 (83%)]	Loss: 0.791695
[2022-06-13 04:15:31 | train] - Train Epoch: [192] [1075200/1281167 (84%)]	Loss: 0.697835
[2022-06-13 04:15:53 | train] - Train Epoch: [192] [1088000/1281167 (85%)]	Loss: 0.683838
[2022-06-13 04:16:15 | train] - Train Epoch: [192] [1100800/1281167 (86%)]	Loss: 0.712662
[2022-06-13 04:16:37 | train] - Train Epoch: [192] [1113600/1281167 (87%)]	Loss: 0.696429
[2022-06-13 04:17:00 | train] - Train Epoch: [192] [1126400/1281167 (88%)]	Loss: 0.655504
[2022-06-13 04:17:22 | train] - Train Epoch: [192] [1139200/1281167 (89%)]	Loss: 0.783747
[2022-06-13 04:17:44 | train] - Train Epoch: [192] [1152000/1281167 (90%)]	Loss: 0.684447
[2022-06-13 04:18:06 | train] - Train Epoch: [192] [1164800/1281167 (91%)]	Loss: 0.544717
[2022-06-13 04:18:29 | train] - Train Epoch: [192] [1177600/1281167 (92%)]	Loss: 0.637664
[2022-06-13 04:18:51 | train] - Train Epoch: [192] [1190400/1281167 (93%)]	Loss: 0.778665
[2022-06-13 04:19:13 | train] - Train Epoch: [192] [1203200/1281167 (94%)]	Loss: 0.862845
[2022-06-13 04:19:35 | train] - Train Epoch: [192] [1216000/1281167 (95%)]	Loss: 0.678051
[2022-06-13 04:19:57 | train] - Train Epoch: [192] [1228800/1281167 (96%)]	Loss: 0.689999
[2022-06-13 04:20:19 | train] - Train Epoch: [192] [1241600/1281167 (97%)]	Loss: 0.626600
[2022-06-13 04:20:41 | train] - Train Epoch: [192] [1254400/1281167 (98%)]	Loss: 0.946154
[2022-06-13 04:21:03 | train] - Train Epoch: [192] [1267200/1281167 (99%)]	Loss: 0.630649
[2022-06-13 04:21:25 | train] - Train Epoch: [192] [1280000/1281167 (100%)]	Loss: 0.810759
[2022-06-13 04:21:28 | train] - Train Epoch: [192]	 Average Loss: 0.718100	 Total Acc : 82.5631	 Total Top5 Acc : 93.6953
[2022-06-13 04:21:28 | train] - -------192 epoch end-----------
========================================
-------192 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 04:23:03 | train] - 
Epoch [192] Test set: Average loss: 1.4377, Accuracy: 34942/50000 (69.8553%), Top-5 Accuracy: 88.8531%

[2022-06-13 04:23:03 | train] - save intermediate epoch [192] result


[2022-06-13 04:23:27 | train] - -------193 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 04:23:29 | train] - Train Epoch: [193] [0/1281167 (0%)]	Loss: 0.600326
[2022-06-13 04:23:51 | train] - Train Epoch: [193] [12800/1281167 (1%)]	Loss: 0.930206
[2022-06-13 04:24:12 | train] - Train Epoch: [193] [25600/1281167 (2%)]	Loss: 0.751157
[2022-06-13 04:24:34 | train] - Train Epoch: [193] [38400/1281167 (3%)]	Loss: 0.753691
[2022-06-13 04:24:56 | train] - Train Epoch: [193] [51200/1281167 (4%)]	Loss: 0.968578
[2022-06-13 04:25:19 | train] - Train Epoch: [193] [64000/1281167 (5%)]	Loss: 0.777458
[2022-06-13 04:25:40 | train] - Train Epoch: [193] [76800/1281167 (6%)]	Loss: 0.908318
[2022-06-13 04:26:01 | train] - Train Epoch: [193] [89600/1281167 (7%)]	Loss: 0.835749
[2022-06-13 04:26:23 | train] - Train Epoch: [193] [102400/1281167 (8%)]	Loss: 0.864439
[2022-06-13 04:26:44 | train] - Train Epoch: [193] [115200/1281167 (9%)]	Loss: 0.979107
[2022-06-13 04:27:06 | train] - Train Epoch: [193] [128000/1281167 (10%)]	Loss: 0.860757
[2022-06-13 04:27:27 | train] - Train Epoch: [193] [140800/1281167 (11%)]	Loss: 0.589137
[2022-06-13 04:27:49 | train] - Train Epoch: [193] [153600/1281167 (12%)]	Loss: 0.510453
[2022-06-13 04:28:11 | train] - Train Epoch: [193] [166400/1281167 (13%)]	Loss: 0.608758
[2022-06-13 04:28:33 | train] - Train Epoch: [193] [179200/1281167 (14%)]	Loss: 0.822946
[2022-06-13 04:28:54 | train] - Train Epoch: [193] [192000/1281167 (15%)]	Loss: 0.518118
[2022-06-13 04:29:16 | train] - Train Epoch: [193] [204800/1281167 (16%)]	Loss: 0.730500
[2022-06-13 04:29:39 | train] - Train Epoch: [193] [217600/1281167 (17%)]	Loss: 0.737798
[2022-06-13 04:30:01 | train] - Train Epoch: [193] [230400/1281167 (18%)]	Loss: 0.744181
[2022-06-13 04:30:22 | train] - Train Epoch: [193] [243200/1281167 (19%)]	Loss: 0.675531
[2022-06-13 04:30:44 | train] - Train Epoch: [193] [256000/1281167 (20%)]	Loss: 0.606665
[2022-06-13 04:31:06 | train] - Train Epoch: [193] [268800/1281167 (21%)]	Loss: 0.518229
[2022-06-13 04:31:27 | train] - Train Epoch: [193] [281600/1281167 (22%)]	Loss: 0.948323
[2022-06-13 04:31:49 | train] - Train Epoch: [193] [294400/1281167 (23%)]	Loss: 1.017889
[2022-06-13 04:32:11 | train] - Train Epoch: [193] [307200/1281167 (24%)]	Loss: 0.642751
[2022-06-13 04:32:33 | train] - Train Epoch: [193] [320000/1281167 (25%)]	Loss: 0.566108
[2022-06-13 04:32:54 | train] - Train Epoch: [193] [332800/1281167 (26%)]	Loss: 0.957089
[2022-06-13 04:33:17 | train] - Train Epoch: [193] [345600/1281167 (27%)]	Loss: 0.517603
[2022-06-13 04:33:39 | train] - Train Epoch: [193] [358400/1281167 (28%)]	Loss: 1.014306
[2022-06-13 04:34:00 | train] - Train Epoch: [193] [371200/1281167 (29%)]	Loss: 0.769892
[2022-06-13 04:34:22 | train] - Train Epoch: [193] [384000/1281167 (30%)]	Loss: 0.685581
[2022-06-13 04:34:43 | train] - Train Epoch: [193] [396800/1281167 (31%)]	Loss: 0.682092
[2022-06-13 04:35:04 | train] - Train Epoch: [193] [409600/1281167 (32%)]	Loss: 0.809893
[2022-06-13 04:35:27 | train] - Train Epoch: [193] [422400/1281167 (33%)]	Loss: 0.742504
[2022-06-13 04:35:49 | train] - Train Epoch: [193] [435200/1281167 (34%)]	Loss: 0.526106
[2022-06-13 04:36:10 | train] - Train Epoch: [193] [448000/1281167 (35%)]	Loss: 0.813136
[2022-06-13 04:36:32 | train] - Train Epoch: [193] [460800/1281167 (36%)]	Loss: 0.535928
[2022-06-13 04:36:54 | train] - Train Epoch: [193] [473600/1281167 (37%)]	Loss: 0.457101
[2022-06-13 04:37:16 | train] - Train Epoch: [193] [486400/1281167 (38%)]	Loss: 0.513000
[2022-06-13 04:37:38 | train] - Train Epoch: [193] [499200/1281167 (39%)]	Loss: 0.766955
[2022-06-13 04:37:59 | train] - Train Epoch: [193] [512000/1281167 (40%)]	Loss: 0.672898
[2022-06-13 04:38:21 | train] - Train Epoch: [193] [524800/1281167 (41%)]	Loss: 0.611662
[2022-06-13 04:38:43 | train] - Train Epoch: [193] [537600/1281167 (42%)]	Loss: 0.861731
[2022-06-13 04:39:05 | train] - Train Epoch: [193] [550400/1281167 (43%)]	Loss: 1.115189
[2022-06-13 04:39:27 | train] - Train Epoch: [193] [563200/1281167 (44%)]	Loss: 0.789722
[2022-06-13 04:39:49 | train] - Train Epoch: [193] [576000/1281167 (45%)]	Loss: 0.797529
[2022-06-13 04:40:11 | train] - Train Epoch: [193] [588800/1281167 (46%)]	Loss: 0.864763
[2022-06-13 04:40:33 | train] - Train Epoch: [193] [601600/1281167 (47%)]	Loss: 0.623655
[2022-06-13 04:40:54 | train] - Train Epoch: [193] [614400/1281167 (48%)]	Loss: 0.911533
[2022-06-13 04:41:17 | train] - Train Epoch: [193] [627200/1281167 (49%)]	Loss: 0.578018
[2022-06-13 04:41:39 | train] - Train Epoch: [193] [640000/1281167 (50%)]	Loss: 0.652092
[2022-06-13 04:42:02 | train] - Train Epoch: [193] [652800/1281167 (51%)]	Loss: 0.776495
[2022-06-13 04:42:24 | train] - Train Epoch: [193] [665600/1281167 (52%)]	Loss: 0.724278
[2022-06-13 04:42:46 | train] - Train Epoch: [193] [678400/1281167 (53%)]	Loss: 0.648886
[2022-06-13 04:43:09 | train] - Train Epoch: [193] [691200/1281167 (54%)]	Loss: 0.863994
[2022-06-13 04:43:30 | train] - Train Epoch: [193] [704000/1281167 (55%)]	Loss: 0.522877
[2022-06-13 04:43:53 | train] - Train Epoch: [193] [716800/1281167 (56%)]	Loss: 0.744228
[2022-06-13 04:44:14 | train] - Train Epoch: [193] [729600/1281167 (57%)]	Loss: 0.928135
[2022-06-13 04:44:36 | train] - Train Epoch: [193] [742400/1281167 (58%)]	Loss: 0.819726
[2022-06-13 04:44:57 | train] - Train Epoch: [193] [755200/1281167 (59%)]	Loss: 0.534086
[2022-06-13 04:45:19 | train] - Train Epoch: [193] [768000/1281167 (60%)]	Loss: 0.849683
[2022-06-13 04:45:41 | train] - Train Epoch: [193] [780800/1281167 (61%)]	Loss: 0.763805
[2022-06-13 04:46:04 | train] - Train Epoch: [193] [793600/1281167 (62%)]	Loss: 0.718221
[2022-06-13 04:46:27 | train] - Train Epoch: [193] [806400/1281167 (63%)]	Loss: 0.791964
[2022-06-13 04:46:50 | train] - Train Epoch: [193] [819200/1281167 (64%)]	Loss: 0.722344
[2022-06-13 04:47:12 | train] - Train Epoch: [193] [832000/1281167 (65%)]	Loss: 0.730333
[2022-06-13 04:47:34 | train] - Train Epoch: [193] [844800/1281167 (66%)]	Loss: 0.726156
[2022-06-13 04:47:55 | train] - Train Epoch: [193] [857600/1281167 (67%)]	Loss: 0.562363
[2022-06-13 04:48:18 | train] - Train Epoch: [193] [870400/1281167 (68%)]	Loss: 0.877994
[2022-06-13 04:48:40 | train] - Train Epoch: [193] [883200/1281167 (69%)]	Loss: 0.440089
[2022-06-13 04:49:02 | train] - Train Epoch: [193] [896000/1281167 (70%)]	Loss: 0.586301
[2022-06-13 04:49:24 | train] - Train Epoch: [193] [908800/1281167 (71%)]	Loss: 0.805273
[2022-06-13 04:49:46 | train] - Train Epoch: [193] [921600/1281167 (72%)]	Loss: 0.835569
[2022-06-13 04:50:07 | train] - Train Epoch: [193] [934400/1281167 (73%)]	Loss: 0.634772
[2022-06-13 04:50:29 | train] - Train Epoch: [193] [947200/1281167 (74%)]	Loss: 1.023516
[2022-06-13 04:50:51 | train] - Train Epoch: [193] [960000/1281167 (75%)]	Loss: 0.916714
[2022-06-13 04:51:13 | train] - Train Epoch: [193] [972800/1281167 (76%)]	Loss: 0.567414
[2022-06-13 04:51:35 | train] - Train Epoch: [193] [985600/1281167 (77%)]	Loss: 0.802262
[2022-06-13 04:51:57 | train] - Train Epoch: [193] [998400/1281167 (78%)]	Loss: 0.827217
[2022-06-13 04:52:19 | train] - Train Epoch: [193] [1011200/1281167 (79%)]	Loss: 0.621943
[2022-06-13 04:52:41 | train] - Train Epoch: [193] [1024000/1281167 (80%)]	Loss: 0.593802
[2022-06-13 04:53:03 | train] - Train Epoch: [193] [1036800/1281167 (81%)]	Loss: 0.700679
[2022-06-13 04:53:25 | train] - Train Epoch: [193] [1049600/1281167 (82%)]	Loss: 0.835218
[2022-06-13 04:53:47 | train] - Train Epoch: [193] [1062400/1281167 (83%)]	Loss: 0.446960
[2022-06-13 04:54:09 | train] - Train Epoch: [193] [1075200/1281167 (84%)]	Loss: 0.685028
[2022-06-13 04:54:32 | train] - Train Epoch: [193] [1088000/1281167 (85%)]	Loss: 0.836993
[2022-06-13 04:54:54 | train] - Train Epoch: [193] [1100800/1281167 (86%)]	Loss: 0.855754
[2022-06-13 04:55:17 | train] - Train Epoch: [193] [1113600/1281167 (87%)]	Loss: 0.638397
[2022-06-13 04:55:38 | train] - Train Epoch: [193] [1126400/1281167 (88%)]	Loss: 0.600857
[2022-06-13 04:56:00 | train] - Train Epoch: [193] [1139200/1281167 (89%)]	Loss: 0.640289
[2022-06-13 04:56:22 | train] - Train Epoch: [193] [1152000/1281167 (90%)]	Loss: 0.594090
[2022-06-13 04:56:44 | train] - Train Epoch: [193] [1164800/1281167 (91%)]	Loss: 0.589440
[2022-06-13 04:57:06 | train] - Train Epoch: [193] [1177600/1281167 (92%)]	Loss: 0.771632
[2022-06-13 04:57:28 | train] - Train Epoch: [193] [1190400/1281167 (93%)]	Loss: 0.569340
[2022-06-13 04:57:50 | train] - Train Epoch: [193] [1203200/1281167 (94%)]	Loss: 0.473764
[2022-06-13 04:58:13 | train] - Train Epoch: [193] [1216000/1281167 (95%)]	Loss: 0.740682
[2022-06-13 04:58:35 | train] - Train Epoch: [193] [1228800/1281167 (96%)]	Loss: 0.912268
[2022-06-13 04:58:57 | train] - Train Epoch: [193] [1241600/1281167 (97%)]	Loss: 0.738838
[2022-06-13 04:59:19 | train] - Train Epoch: [193] [1254400/1281167 (98%)]	Loss: 0.722884
[2022-06-13 04:59:41 | train] - Train Epoch: [193] [1267200/1281167 (99%)]	Loss: 0.730908
[2022-06-13 05:00:03 | train] - Train Epoch: [193] [1280000/1281167 (100%)]	Loss: 1.064862
[2022-06-13 05:00:05 | train] - Train Epoch: [193]	 Average Loss: 0.716347	 Total Acc : 82.6458	 Total Top5 Acc : 93.6704
[2022-06-13 05:00:05 | train] - -------193 epoch end-----------
========================================
-------193 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 05:01:38 | train] - 
Epoch [193] Test set: Average loss: 1.4285, Accuracy: 34991/50000 (69.9556%), Top-5 Accuracy: 88.9182%

[2022-06-13 05:01:38 | train] - save intermediate epoch [193] result


[2022-06-13 05:02:02 | train] - -------194 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 05:02:04 | train] - Train Epoch: [194] [0/1281167 (0%)]	Loss: 0.541981
[2022-06-13 05:02:23 | train] - Train Epoch: [194] [12800/1281167 (1%)]	Loss: 0.768285
[2022-06-13 05:02:42 | train] - Train Epoch: [194] [25600/1281167 (2%)]	Loss: 0.508021
[2022-06-13 05:03:03 | train] - Train Epoch: [194] [38400/1281167 (3%)]	Loss: 0.685835
[2022-06-13 05:03:22 | train] - Train Epoch: [194] [51200/1281167 (4%)]	Loss: 0.526108
[2022-06-13 05:03:41 | train] - Train Epoch: [194] [64000/1281167 (5%)]	Loss: 0.782412
[2022-06-13 05:04:01 | train] - Train Epoch: [194] [76800/1281167 (6%)]	Loss: 0.552182
[2022-06-13 05:04:21 | train] - Train Epoch: [194] [89600/1281167 (7%)]	Loss: 0.597315
[2022-06-13 05:04:39 | train] - Train Epoch: [194] [102400/1281167 (8%)]	Loss: 0.576187
[2022-06-13 05:04:59 | train] - Train Epoch: [194] [115200/1281167 (9%)]	Loss: 0.686218
[2022-06-13 05:05:18 | train] - Train Epoch: [194] [128000/1281167 (10%)]	Loss: 0.688549
[2022-06-13 05:05:37 | train] - Train Epoch: [194] [140800/1281167 (11%)]	Loss: 0.831302
[2022-06-13 05:05:57 | train] - Train Epoch: [194] [153600/1281167 (12%)]	Loss: 0.850025
[2022-06-13 05:06:16 | train] - Train Epoch: [194] [166400/1281167 (13%)]	Loss: 0.776401
[2022-06-13 05:06:36 | train] - Train Epoch: [194] [179200/1281167 (14%)]	Loss: 0.908258
[2022-06-13 05:06:56 | train] - Train Epoch: [194] [192000/1281167 (15%)]	Loss: 0.678629
[2022-06-13 05:07:15 | train] - Train Epoch: [194] [204800/1281167 (16%)]	Loss: 0.726192
[2022-06-13 05:07:35 | train] - Train Epoch: [194] [217600/1281167 (17%)]	Loss: 0.770196
[2022-06-13 05:07:55 | train] - Train Epoch: [194] [230400/1281167 (18%)]	Loss: 0.813220
[2022-06-13 05:08:14 | train] - Train Epoch: [194] [243200/1281167 (19%)]	Loss: 0.643204
[2022-06-13 05:08:33 | train] - Train Epoch: [194] [256000/1281167 (20%)]	Loss: 0.735980
[2022-06-13 05:08:53 | train] - Train Epoch: [194] [268800/1281167 (21%)]	Loss: 0.799370
[2022-06-13 05:09:13 | train] - Train Epoch: [194] [281600/1281167 (22%)]	Loss: 0.629231
[2022-06-13 05:09:31 | train] - Train Epoch: [194] [294400/1281167 (23%)]	Loss: 0.747576
[2022-06-13 05:09:51 | train] - Train Epoch: [194] [307200/1281167 (24%)]	Loss: 0.669601
[2022-06-13 05:10:11 | train] - Train Epoch: [194] [320000/1281167 (25%)]	Loss: 0.691267
[2022-06-13 05:10:31 | train] - Train Epoch: [194] [332800/1281167 (26%)]	Loss: 0.558324
[2022-06-13 05:10:50 | train] - Train Epoch: [194] [345600/1281167 (27%)]	Loss: 0.805146
[2022-06-13 05:11:10 | train] - Train Epoch: [194] [358400/1281167 (28%)]	Loss: 0.785359
[2022-06-13 05:11:29 | train] - Train Epoch: [194] [371200/1281167 (29%)]	Loss: 0.794460
[2022-06-13 05:11:48 | train] - Train Epoch: [194] [384000/1281167 (30%)]	Loss: 0.766227
[2022-06-13 05:12:07 | train] - Train Epoch: [194] [396800/1281167 (31%)]	Loss: 0.664726
[2022-06-13 05:12:26 | train] - Train Epoch: [194] [409600/1281167 (32%)]	Loss: 0.942230
[2022-06-13 05:12:46 | train] - Train Epoch: [194] [422400/1281167 (33%)]	Loss: 0.880362
[2022-06-13 05:13:05 | train] - Train Epoch: [194] [435200/1281167 (34%)]	Loss: 0.960222
[2022-06-13 05:13:24 | train] - Train Epoch: [194] [448000/1281167 (35%)]	Loss: 0.682268
[2022-06-13 05:13:43 | train] - Train Epoch: [194] [460800/1281167 (36%)]	Loss: 0.536507
[2022-06-13 05:14:03 | train] - Train Epoch: [194] [473600/1281167 (37%)]	Loss: 0.942407
[2022-06-13 05:14:22 | train] - Train Epoch: [194] [486400/1281167 (38%)]	Loss: 0.649504
[2022-06-13 05:14:41 | train] - Train Epoch: [194] [499200/1281167 (39%)]	Loss: 0.773006
[2022-06-13 05:15:01 | train] - Train Epoch: [194] [512000/1281167 (40%)]	Loss: 1.015444
[2022-06-13 05:15:20 | train] - Train Epoch: [194] [524800/1281167 (41%)]	Loss: 0.694917
[2022-06-13 05:15:39 | train] - Train Epoch: [194] [537600/1281167 (42%)]	Loss: 0.946381
[2022-06-13 05:15:59 | train] - Train Epoch: [194] [550400/1281167 (43%)]	Loss: 0.671706
[2022-06-13 05:16:18 | train] - Train Epoch: [194] [563200/1281167 (44%)]	Loss: 0.718573
[2022-06-13 05:16:37 | train] - Train Epoch: [194] [576000/1281167 (45%)]	Loss: 0.513211
[2022-06-13 05:16:57 | train] - Train Epoch: [194] [588800/1281167 (46%)]	Loss: 0.786041
[2022-06-13 05:17:16 | train] - Train Epoch: [194] [601600/1281167 (47%)]	Loss: 0.882547
[2022-06-13 05:17:35 | train] - Train Epoch: [194] [614400/1281167 (48%)]	Loss: 0.783560
[2022-06-13 05:17:55 | train] - Train Epoch: [194] [627200/1281167 (49%)]	Loss: 0.961571
[2022-06-13 05:18:14 | train] - Train Epoch: [194] [640000/1281167 (50%)]	Loss: 0.809278
[2022-06-13 05:18:33 | train] - Train Epoch: [194] [652800/1281167 (51%)]	Loss: 0.824526
[2022-06-13 05:18:53 | train] - Train Epoch: [194] [665600/1281167 (52%)]	Loss: 0.627710
[2022-06-13 05:19:13 | train] - Train Epoch: [194] [678400/1281167 (53%)]	Loss: 0.778353
[2022-06-13 05:19:32 | train] - Train Epoch: [194] [691200/1281167 (54%)]	Loss: 0.845171
[2022-06-13 05:19:51 | train] - Train Epoch: [194] [704000/1281167 (55%)]	Loss: 0.886471
[2022-06-13 05:20:11 | train] - Train Epoch: [194] [716800/1281167 (56%)]	Loss: 0.670812
[2022-06-13 05:20:31 | train] - Train Epoch: [194] [729600/1281167 (57%)]	Loss: 0.625356
[2022-06-13 05:20:50 | train] - Train Epoch: [194] [742400/1281167 (58%)]	Loss: 0.790572
[2022-06-13 05:21:10 | train] - Train Epoch: [194] [755200/1281167 (59%)]	Loss: 0.603040
[2022-06-13 05:21:29 | train] - Train Epoch: [194] [768000/1281167 (60%)]	Loss: 0.784037
[2022-06-13 05:21:48 | train] - Train Epoch: [194] [780800/1281167 (61%)]	Loss: 0.655506
[2022-06-13 05:22:08 | train] - Train Epoch: [194] [793600/1281167 (62%)]	Loss: 0.733383
[2022-06-13 05:22:27 | train] - Train Epoch: [194] [806400/1281167 (63%)]	Loss: 0.752299
[2022-06-13 05:22:47 | train] - Train Epoch: [194] [819200/1281167 (64%)]	Loss: 0.738267
[2022-06-13 05:23:06 | train] - Train Epoch: [194] [832000/1281167 (65%)]	Loss: 0.606988
[2022-06-13 05:23:26 | train] - Train Epoch: [194] [844800/1281167 (66%)]	Loss: 0.794213
[2022-06-13 05:23:45 | train] - Train Epoch: [194] [857600/1281167 (67%)]	Loss: 0.747286
[2022-06-13 05:24:04 | train] - Train Epoch: [194] [870400/1281167 (68%)]	Loss: 0.626631
[2022-06-13 05:24:24 | train] - Train Epoch: [194] [883200/1281167 (69%)]	Loss: 0.598371
[2022-06-13 05:24:43 | train] - Train Epoch: [194] [896000/1281167 (70%)]	Loss: 0.630451
[2022-06-13 05:25:03 | train] - Train Epoch: [194] [908800/1281167 (71%)]	Loss: 0.575161
[2022-06-13 05:25:22 | train] - Train Epoch: [194] [921600/1281167 (72%)]	Loss: 0.563553
[2022-06-13 05:25:42 | train] - Train Epoch: [194] [934400/1281167 (73%)]	Loss: 0.688094
[2022-06-13 05:26:01 | train] - Train Epoch: [194] [947200/1281167 (74%)]	Loss: 0.469689
[2022-06-13 05:26:20 | train] - Train Epoch: [194] [960000/1281167 (75%)]	Loss: 0.678858
[2022-06-13 05:26:38 | train] - Train Epoch: [194] [972800/1281167 (76%)]	Loss: 0.613293
[2022-06-13 05:26:58 | train] - Train Epoch: [194] [985600/1281167 (77%)]	Loss: 0.562257
[2022-06-13 05:27:18 | train] - Train Epoch: [194] [998400/1281167 (78%)]	Loss: 0.659794
[2022-06-13 05:27:37 | train] - Train Epoch: [194] [1011200/1281167 (79%)]	Loss: 0.807889
[2022-06-13 05:27:56 | train] - Train Epoch: [194] [1024000/1281167 (80%)]	Loss: 0.705719
[2022-06-13 05:28:16 | train] - Train Epoch: [194] [1036800/1281167 (81%)]	Loss: 0.703249
[2022-06-13 05:28:35 | train] - Train Epoch: [194] [1049600/1281167 (82%)]	Loss: 0.699004
[2022-06-13 05:28:55 | train] - Train Epoch: [194] [1062400/1281167 (83%)]	Loss: 0.696763
[2022-06-13 05:29:14 | train] - Train Epoch: [194] [1075200/1281167 (84%)]	Loss: 0.915955
[2022-06-13 05:29:33 | train] - Train Epoch: [194] [1088000/1281167 (85%)]	Loss: 0.803186
[2022-06-13 05:29:52 | train] - Train Epoch: [194] [1100800/1281167 (86%)]	Loss: 0.762875
[2022-06-13 05:30:11 | train] - Train Epoch: [194] [1113600/1281167 (87%)]	Loss: 0.682680
[2022-06-13 05:30:31 | train] - Train Epoch: [194] [1126400/1281167 (88%)]	Loss: 0.630768
[2022-06-13 05:30:50 | train] - Train Epoch: [194] [1139200/1281167 (89%)]	Loss: 0.765774
[2022-06-13 05:31:10 | train] - Train Epoch: [194] [1152000/1281167 (90%)]	Loss: 0.792024
[2022-06-13 05:31:29 | train] - Train Epoch: [194] [1164800/1281167 (91%)]	Loss: 0.725776
[2022-06-13 05:31:49 | train] - Train Epoch: [194] [1177600/1281167 (92%)]	Loss: 0.764624
[2022-06-13 05:32:09 | train] - Train Epoch: [194] [1190400/1281167 (93%)]	Loss: 0.748162
[2022-06-13 05:32:28 | train] - Train Epoch: [194] [1203200/1281167 (94%)]	Loss: 0.579376
[2022-06-13 05:32:47 | train] - Train Epoch: [194] [1216000/1281167 (95%)]	Loss: 0.708771
[2022-06-13 05:33:07 | train] - Train Epoch: [194] [1228800/1281167 (96%)]	Loss: 0.760243
[2022-06-13 05:33:26 | train] - Train Epoch: [194] [1241600/1281167 (97%)]	Loss: 0.718617
[2022-06-13 05:33:46 | train] - Train Epoch: [194] [1254400/1281167 (98%)]	Loss: 0.931333
[2022-06-13 05:34:05 | train] - Train Epoch: [194] [1267200/1281167 (99%)]	Loss: 0.585778
[2022-06-13 05:34:25 | train] - Train Epoch: [194] [1280000/1281167 (100%)]	Loss: 0.584994
[2022-06-13 05:34:26 | train] - Train Epoch: [194]	 Average Loss: 0.716180	 Total Acc : 82.6257	 Total Top5 Acc : 93.6786
[2022-06-13 05:34:26 | train] - -------194 epoch end-----------
========================================
-------194 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 05:35:56 | train] - 
Epoch [194] Test set: Average loss: 1.4282, Accuracy: 34938/50000 (69.8485%), Top-5 Accuracy: 88.9274%

[2022-06-13 05:35:56 | train] - save intermediate epoch [194] result


[2022-06-13 05:36:20 | train] - -------195 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 05:36:22 | train] - Train Epoch: [195] [0/1281167 (0%)]	Loss: 0.675661
[2022-06-13 05:36:44 | train] - Train Epoch: [195] [12800/1281167 (1%)]	Loss: 0.786818
[2022-06-13 05:37:07 | train] - Train Epoch: [195] [25600/1281167 (2%)]	Loss: 0.635094
[2022-06-13 05:37:29 | train] - Train Epoch: [195] [38400/1281167 (3%)]	Loss: 0.635301
[2022-06-13 05:37:50 | train] - Train Epoch: [195] [51200/1281167 (4%)]	Loss: 0.778210
[2022-06-13 05:38:12 | train] - Train Epoch: [195] [64000/1281167 (5%)]	Loss: 0.718662
[2022-06-13 05:38:33 | train] - Train Epoch: [195] [76800/1281167 (6%)]	Loss: 0.758915
[2022-06-13 05:38:55 | train] - Train Epoch: [195] [89600/1281167 (7%)]	Loss: 0.802787
[2022-06-13 05:39:17 | train] - Train Epoch: [195] [102400/1281167 (8%)]	Loss: 0.989596
[2022-06-13 05:39:39 | train] - Train Epoch: [195] [115200/1281167 (9%)]	Loss: 0.431157
[2022-06-13 05:40:01 | train] - Train Epoch: [195] [128000/1281167 (10%)]	Loss: 0.640518
[2022-06-13 05:40:24 | train] - Train Epoch: [195] [140800/1281167 (11%)]	Loss: 0.835887
[2022-06-13 05:40:47 | train] - Train Epoch: [195] [153600/1281167 (12%)]	Loss: 0.697806
[2022-06-13 05:41:09 | train] - Train Epoch: [195] [166400/1281167 (13%)]	Loss: 0.740511
[2022-06-13 05:41:31 | train] - Train Epoch: [195] [179200/1281167 (14%)]	Loss: 0.949156
[2022-06-13 05:41:54 | train] - Train Epoch: [195] [192000/1281167 (15%)]	Loss: 0.470717
[2022-06-13 05:42:16 | train] - Train Epoch: [195] [204800/1281167 (16%)]	Loss: 0.699143
[2022-06-13 05:42:38 | train] - Train Epoch: [195] [217600/1281167 (17%)]	Loss: 0.475740
[2022-06-13 05:43:01 | train] - Train Epoch: [195] [230400/1281167 (18%)]	Loss: 0.561570
[2022-06-13 05:43:23 | train] - Train Epoch: [195] [243200/1281167 (19%)]	Loss: 0.496390
[2022-06-13 05:43:46 | train] - Train Epoch: [195] [256000/1281167 (20%)]	Loss: 0.706629
[2022-06-13 05:44:09 | train] - Train Epoch: [195] [268800/1281167 (21%)]	Loss: 0.808862
[2022-06-13 05:44:32 | train] - Train Epoch: [195] [281600/1281167 (22%)]	Loss: 0.641018
[2022-06-13 05:44:54 | train] - Train Epoch: [195] [294400/1281167 (23%)]	Loss: 0.747413
[2022-06-13 05:45:16 | train] - Train Epoch: [195] [307200/1281167 (24%)]	Loss: 0.458194
[2022-06-13 05:45:38 | train] - Train Epoch: [195] [320000/1281167 (25%)]	Loss: 0.735087
[2022-06-13 05:46:00 | train] - Train Epoch: [195] [332800/1281167 (26%)]	Loss: 0.955879
[2022-06-13 05:46:23 | train] - Train Epoch: [195] [345600/1281167 (27%)]	Loss: 0.713953
[2022-06-13 05:46:45 | train] - Train Epoch: [195] [358400/1281167 (28%)]	Loss: 0.544066
[2022-06-13 05:47:07 | train] - Train Epoch: [195] [371200/1281167 (29%)]	Loss: 0.554911
[2022-06-13 05:47:29 | train] - Train Epoch: [195] [384000/1281167 (30%)]	Loss: 1.007963
[2022-06-13 05:47:52 | train] - Train Epoch: [195] [396800/1281167 (31%)]	Loss: 0.972890
[2022-06-13 05:48:15 | train] - Train Epoch: [195] [409600/1281167 (32%)]	Loss: 0.731749
[2022-06-13 05:48:37 | train] - Train Epoch: [195] [422400/1281167 (33%)]	Loss: 0.658913
[2022-06-13 05:49:00 | train] - Train Epoch: [195] [435200/1281167 (34%)]	Loss: 0.556235
[2022-06-13 05:49:22 | train] - Train Epoch: [195] [448000/1281167 (35%)]	Loss: 0.799100
[2022-06-13 05:49:45 | train] - Train Epoch: [195] [460800/1281167 (36%)]	Loss: 0.950245
[2022-06-13 05:50:07 | train] - Train Epoch: [195] [473600/1281167 (37%)]	Loss: 0.580151
[2022-06-13 05:50:30 | train] - Train Epoch: [195] [486400/1281167 (38%)]	Loss: 0.645422
[2022-06-13 05:50:52 | train] - Train Epoch: [195] [499200/1281167 (39%)]	Loss: 0.650540
[2022-06-13 05:51:15 | train] - Train Epoch: [195] [512000/1281167 (40%)]	Loss: 0.713223
[2022-06-13 05:51:38 | train] - Train Epoch: [195] [524800/1281167 (41%)]	Loss: 0.715458
[2022-06-13 05:51:59 | train] - Train Epoch: [195] [537600/1281167 (42%)]	Loss: 0.539278
[2022-06-13 05:52:21 | train] - Train Epoch: [195] [550400/1281167 (43%)]	Loss: 0.591014
[2022-06-13 05:52:43 | train] - Train Epoch: [195] [563200/1281167 (44%)]	Loss: 0.919787
[2022-06-13 05:53:05 | train] - Train Epoch: [195] [576000/1281167 (45%)]	Loss: 0.836706
[2022-06-13 05:53:28 | train] - Train Epoch: [195] [588800/1281167 (46%)]	Loss: 0.589747
[2022-06-13 05:53:51 | train] - Train Epoch: [195] [601600/1281167 (47%)]	Loss: 0.692679
[2022-06-13 05:54:13 | train] - Train Epoch: [195] [614400/1281167 (48%)]	Loss: 0.804827
[2022-06-13 05:54:35 | train] - Train Epoch: [195] [627200/1281167 (49%)]	Loss: 0.995977
[2022-06-13 05:54:58 | train] - Train Epoch: [195] [640000/1281167 (50%)]	Loss: 0.910316
[2022-06-13 05:55:20 | train] - Train Epoch: [195] [652800/1281167 (51%)]	Loss: 0.531869
[2022-06-13 05:55:43 | train] - Train Epoch: [195] [665600/1281167 (52%)]	Loss: 0.810392
[2022-06-13 05:56:05 | train] - Train Epoch: [195] [678400/1281167 (53%)]	Loss: 0.917036
[2022-06-13 05:56:26 | train] - Train Epoch: [195] [691200/1281167 (54%)]	Loss: 0.731845
[2022-06-13 05:56:48 | train] - Train Epoch: [195] [704000/1281167 (55%)]	Loss: 0.636811
[2022-06-13 05:57:11 | train] - Train Epoch: [195] [716800/1281167 (56%)]	Loss: 0.690607
[2022-06-13 05:57:32 | train] - Train Epoch: [195] [729600/1281167 (57%)]	Loss: 0.564792
[2022-06-13 05:57:55 | train] - Train Epoch: [195] [742400/1281167 (58%)]	Loss: 0.765640
[2022-06-13 05:58:17 | train] - Train Epoch: [195] [755200/1281167 (59%)]	Loss: 0.888121
[2022-06-13 05:58:39 | train] - Train Epoch: [195] [768000/1281167 (60%)]	Loss: 0.613485
[2022-06-13 05:59:01 | train] - Train Epoch: [195] [780800/1281167 (61%)]	Loss: 0.616791
[2022-06-13 05:59:22 | train] - Train Epoch: [195] [793600/1281167 (62%)]	Loss: 0.708041
[2022-06-13 05:59:44 | train] - Train Epoch: [195] [806400/1281167 (63%)]	Loss: 0.665419
[2022-06-13 06:00:06 | train] - Train Epoch: [195] [819200/1281167 (64%)]	Loss: 0.714944
[2022-06-13 06:00:28 | train] - Train Epoch: [195] [832000/1281167 (65%)]	Loss: 0.805312
[2022-06-13 06:00:50 | train] - Train Epoch: [195] [844800/1281167 (66%)]	Loss: 0.573991
[2022-06-13 06:01:13 | train] - Train Epoch: [195] [857600/1281167 (67%)]	Loss: 0.633988
[2022-06-13 06:01:35 | train] - Train Epoch: [195] [870400/1281167 (68%)]	Loss: 0.595354
[2022-06-13 06:01:57 | train] - Train Epoch: [195] [883200/1281167 (69%)]	Loss: 0.574720
[2022-06-13 06:02:19 | train] - Train Epoch: [195] [896000/1281167 (70%)]	Loss: 0.993234
[2022-06-13 06:02:42 | train] - Train Epoch: [195] [908800/1281167 (71%)]	Loss: 0.565001
[2022-06-13 06:03:04 | train] - Train Epoch: [195] [921600/1281167 (72%)]	Loss: 0.784375
[2022-06-13 06:03:26 | train] - Train Epoch: [195] [934400/1281167 (73%)]	Loss: 0.833021
[2022-06-13 06:03:48 | train] - Train Epoch: [195] [947200/1281167 (74%)]	Loss: 0.886354
[2022-06-13 06:04:11 | train] - Train Epoch: [195] [960000/1281167 (75%)]	Loss: 0.730415
[2022-06-13 06:04:34 | train] - Train Epoch: [195] [972800/1281167 (76%)]	Loss: 0.827244
[2022-06-13 06:04:55 | train] - Train Epoch: [195] [985600/1281167 (77%)]	Loss: 0.566375
[2022-06-13 06:05:17 | train] - Train Epoch: [195] [998400/1281167 (78%)]	Loss: 0.613619
[2022-06-13 06:05:39 | train] - Train Epoch: [195] [1011200/1281167 (79%)]	Loss: 0.341425
[2022-06-13 06:06:02 | train] - Train Epoch: [195] [1024000/1281167 (80%)]	Loss: 0.630260
[2022-06-13 06:06:24 | train] - Train Epoch: [195] [1036800/1281167 (81%)]	Loss: 0.629188
[2022-06-13 06:06:45 | train] - Train Epoch: [195] [1049600/1281167 (82%)]	Loss: 0.750066
[2022-06-13 06:07:06 | train] - Train Epoch: [195] [1062400/1281167 (83%)]	Loss: 0.552803
[2022-06-13 06:07:28 | train] - Train Epoch: [195] [1075200/1281167 (84%)]	Loss: 0.918199
[2022-06-13 06:07:50 | train] - Train Epoch: [195] [1088000/1281167 (85%)]	Loss: 0.631081
[2022-06-13 06:08:12 | train] - Train Epoch: [195] [1100800/1281167 (86%)]	Loss: 0.654003
[2022-06-13 06:08:34 | train] - Train Epoch: [195] [1113600/1281167 (87%)]	Loss: 0.487310
[2022-06-13 06:08:56 | train] - Train Epoch: [195] [1126400/1281167 (88%)]	Loss: 0.980248
[2022-06-13 06:09:18 | train] - Train Epoch: [195] [1139200/1281167 (89%)]	Loss: 0.769992
[2022-06-13 06:09:40 | train] - Train Epoch: [195] [1152000/1281167 (90%)]	Loss: 0.884042
[2022-06-13 06:10:02 | train] - Train Epoch: [195] [1164800/1281167 (91%)]	Loss: 0.928927
[2022-06-13 06:10:24 | train] - Train Epoch: [195] [1177600/1281167 (92%)]	Loss: 0.567666
[2022-06-13 06:10:46 | train] - Train Epoch: [195] [1190400/1281167 (93%)]	Loss: 0.508058
[2022-06-13 06:11:08 | train] - Train Epoch: [195] [1203200/1281167 (94%)]	Loss: 0.699805
[2022-06-13 06:11:29 | train] - Train Epoch: [195] [1216000/1281167 (95%)]	Loss: 0.721357
[2022-06-13 06:11:51 | train] - Train Epoch: [195] [1228800/1281167 (96%)]	Loss: 0.703690
[2022-06-13 06:12:14 | train] - Train Epoch: [195] [1241600/1281167 (97%)]	Loss: 0.581973
[2022-06-13 06:12:35 | train] - Train Epoch: [195] [1254400/1281167 (98%)]	Loss: 0.684036
[2022-06-13 06:12:57 | train] - Train Epoch: [195] [1267200/1281167 (99%)]	Loss: 0.746725
[2022-06-13 06:13:19 | train] - Train Epoch: [195] [1280000/1281167 (100%)]	Loss: 0.562922
[2022-06-13 06:13:21 | train] - Train Epoch: [195]	 Average Loss: 0.717137	 Total Acc : 82.5852	 Total Top5 Acc : 93.6708
[2022-06-13 06:13:21 | train] - -------195 epoch end-----------
========================================
-------195 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 06:14:56 | train] - 
Epoch [195] Test set: Average loss: 1.4367, Accuracy: 34944/50000 (69.8593%), Top-5 Accuracy: 88.9434%

[2022-06-13 06:14:56 | train] - save intermediate epoch [195] result


[2022-06-13 06:15:21 | train] - -------196 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 06:15:23 | train] - Train Epoch: [196] [0/1281167 (0%)]	Loss: 0.844576
[2022-06-13 06:15:45 | train] - Train Epoch: [196] [12800/1281167 (1%)]	Loss: 0.645759
[2022-06-13 06:16:06 | train] - Train Epoch: [196] [25600/1281167 (2%)]	Loss: 0.767999
[2022-06-13 06:16:29 | train] - Train Epoch: [196] [38400/1281167 (3%)]	Loss: 0.677321
[2022-06-13 06:16:50 | train] - Train Epoch: [196] [51200/1281167 (4%)]	Loss: 0.896865
[2022-06-13 06:17:12 | train] - Train Epoch: [196] [64000/1281167 (5%)]	Loss: 0.648800
[2022-06-13 06:17:34 | train] - Train Epoch: [196] [76800/1281167 (6%)]	Loss: 0.900662
[2022-06-13 06:17:56 | train] - Train Epoch: [196] [89600/1281167 (7%)]	Loss: 0.895488
[2022-06-13 06:18:18 | train] - Train Epoch: [196] [102400/1281167 (8%)]	Loss: 0.683366
[2022-06-13 06:18:40 | train] - Train Epoch: [196] [115200/1281167 (9%)]	Loss: 0.820919
[2022-06-13 06:19:02 | train] - Train Epoch: [196] [128000/1281167 (10%)]	Loss: 0.566134
[2022-06-13 06:19:23 | train] - Train Epoch: [196] [140800/1281167 (11%)]	Loss: 0.661955
[2022-06-13 06:19:45 | train] - Train Epoch: [196] [153600/1281167 (12%)]	Loss: 0.924808
[2022-06-13 06:20:07 | train] - Train Epoch: [196] [166400/1281167 (13%)]	Loss: 0.672019
[2022-06-13 06:20:28 | train] - Train Epoch: [196] [179200/1281167 (14%)]	Loss: 0.580897
[2022-06-13 06:20:50 | train] - Train Epoch: [196] [192000/1281167 (15%)]	Loss: 0.886145
[2022-06-13 06:21:12 | train] - Train Epoch: [196] [204800/1281167 (16%)]	Loss: 0.790001
[2022-06-13 06:21:33 | train] - Train Epoch: [196] [217600/1281167 (17%)]	Loss: 0.679460
[2022-06-13 06:21:53 | train] - Train Epoch: [196] [230400/1281167 (18%)]	Loss: 0.612625
[2022-06-13 06:22:15 | train] - Train Epoch: [196] [243200/1281167 (19%)]	Loss: 0.533297
[2022-06-13 06:22:37 | train] - Train Epoch: [196] [256000/1281167 (20%)]	Loss: 0.846639
[2022-06-13 06:22:59 | train] - Train Epoch: [196] [268800/1281167 (21%)]	Loss: 0.477984
[2022-06-13 06:23:20 | train] - Train Epoch: [196] [281600/1281167 (22%)]	Loss: 0.813651
[2022-06-13 06:23:42 | train] - Train Epoch: [196] [294400/1281167 (23%)]	Loss: 0.422957
[2022-06-13 06:24:04 | train] - Train Epoch: [196] [307200/1281167 (24%)]	Loss: 0.823476
[2022-06-13 06:24:26 | train] - Train Epoch: [196] [320000/1281167 (25%)]	Loss: 0.717893
[2022-06-13 06:24:47 | train] - Train Epoch: [196] [332800/1281167 (26%)]	Loss: 0.646032
[2022-06-13 06:25:09 | train] - Train Epoch: [196] [345600/1281167 (27%)]	Loss: 0.821545
[2022-06-13 06:25:30 | train] - Train Epoch: [196] [358400/1281167 (28%)]	Loss: 0.670564
[2022-06-13 06:25:51 | train] - Train Epoch: [196] [371200/1281167 (29%)]	Loss: 0.419086
[2022-06-13 06:26:13 | train] - Train Epoch: [196] [384000/1281167 (30%)]	Loss: 0.915709
[2022-06-13 06:26:35 | train] - Train Epoch: [196] [396800/1281167 (31%)]	Loss: 0.863103
[2022-06-13 06:26:56 | train] - Train Epoch: [196] [409600/1281167 (32%)]	Loss: 0.681720
[2022-06-13 06:27:18 | train] - Train Epoch: [196] [422400/1281167 (33%)]	Loss: 0.644845
[2022-06-13 06:27:40 | train] - Train Epoch: [196] [435200/1281167 (34%)]	Loss: 0.727235
[2022-06-13 06:28:02 | train] - Train Epoch: [196] [448000/1281167 (35%)]	Loss: 0.852734
[2022-06-13 06:28:24 | train] - Train Epoch: [196] [460800/1281167 (36%)]	Loss: 0.780744
[2022-06-13 06:28:46 | train] - Train Epoch: [196] [473600/1281167 (37%)]	Loss: 0.903247
[2022-06-13 06:29:07 | train] - Train Epoch: [196] [486400/1281167 (38%)]	Loss: 0.689997
[2022-06-13 06:29:29 | train] - Train Epoch: [196] [499200/1281167 (39%)]	Loss: 0.714543
[2022-06-13 06:29:51 | train] - Train Epoch: [196] [512000/1281167 (40%)]	Loss: 0.667919
[2022-06-13 06:30:13 | train] - Train Epoch: [196] [524800/1281167 (41%)]	Loss: 0.641015
[2022-06-13 06:30:34 | train] - Train Epoch: [196] [537600/1281167 (42%)]	Loss: 0.718606
[2022-06-13 06:30:57 | train] - Train Epoch: [196] [550400/1281167 (43%)]	Loss: 0.580479
[2022-06-13 06:31:18 | train] - Train Epoch: [196] [563200/1281167 (44%)]	Loss: 0.599719
[2022-06-13 06:31:38 | train] - Train Epoch: [196] [576000/1281167 (45%)]	Loss: 0.566742
[2022-06-13 06:31:59 | train] - Train Epoch: [196] [588800/1281167 (46%)]	Loss: 0.741281
[2022-06-13 06:32:21 | train] - Train Epoch: [196] [601600/1281167 (47%)]	Loss: 0.565629
[2022-06-13 06:32:42 | train] - Train Epoch: [196] [614400/1281167 (48%)]	Loss: 0.705313
[2022-06-13 06:33:04 | train] - Train Epoch: [196] [627200/1281167 (49%)]	Loss: 0.823801
[2022-06-13 06:33:26 | train] - Train Epoch: [196] [640000/1281167 (50%)]	Loss: 0.738837
[2022-06-13 06:33:48 | train] - Train Epoch: [196] [652800/1281167 (51%)]	Loss: 0.769968
[2022-06-13 06:34:10 | train] - Train Epoch: [196] [665600/1281167 (52%)]	Loss: 0.502796
[2022-06-13 06:34:33 | train] - Train Epoch: [196] [678400/1281167 (53%)]	Loss: 0.931684
[2022-06-13 06:34:54 | train] - Train Epoch: [196] [691200/1281167 (54%)]	Loss: 0.630760
[2022-06-13 06:35:16 | train] - Train Epoch: [196] [704000/1281167 (55%)]	Loss: 0.736846
[2022-06-13 06:35:37 | train] - Train Epoch: [196] [716800/1281167 (56%)]	Loss: 0.600301
[2022-06-13 06:35:59 | train] - Train Epoch: [196] [729600/1281167 (57%)]	Loss: 0.745019
[2022-06-13 06:36:21 | train] - Train Epoch: [196] [742400/1281167 (58%)]	Loss: 0.740452
[2022-06-13 06:36:43 | train] - Train Epoch: [196] [755200/1281167 (59%)]	Loss: 0.731275
[2022-06-13 06:37:05 | train] - Train Epoch: [196] [768000/1281167 (60%)]	Loss: 0.691483
[2022-06-13 06:37:27 | train] - Train Epoch: [196] [780800/1281167 (61%)]	Loss: 0.634866
[2022-06-13 06:37:48 | train] - Train Epoch: [196] [793600/1281167 (62%)]	Loss: 0.557548
[2022-06-13 06:38:10 | train] - Train Epoch: [196] [806400/1281167 (63%)]	Loss: 0.746818
[2022-06-13 06:38:31 | train] - Train Epoch: [196] [819200/1281167 (64%)]	Loss: 0.687692
[2022-06-13 06:38:52 | train] - Train Epoch: [196] [832000/1281167 (65%)]	Loss: 0.638622
[2022-06-13 06:39:14 | train] - Train Epoch: [196] [844800/1281167 (66%)]	Loss: 0.691324
[2022-06-13 06:39:35 | train] - Train Epoch: [196] [857600/1281167 (67%)]	Loss: 0.814575
[2022-06-13 06:39:57 | train] - Train Epoch: [196] [870400/1281167 (68%)]	Loss: 0.861395
[2022-06-13 06:40:19 | train] - Train Epoch: [196] [883200/1281167 (69%)]	Loss: 0.892463
[2022-06-13 06:40:40 | train] - Train Epoch: [196] [896000/1281167 (70%)]	Loss: 0.483912
[2022-06-13 06:41:02 | train] - Train Epoch: [196] [908800/1281167 (71%)]	Loss: 0.625585
[2022-06-13 06:41:23 | train] - Train Epoch: [196] [921600/1281167 (72%)]	Loss: 0.703589
[2022-06-13 06:41:45 | train] - Train Epoch: [196] [934400/1281167 (73%)]	Loss: 1.007901
[2022-06-13 06:42:07 | train] - Train Epoch: [196] [947200/1281167 (74%)]	Loss: 0.835312
[2022-06-13 06:42:28 | train] - Train Epoch: [196] [960000/1281167 (75%)]	Loss: 0.567289
[2022-06-13 06:42:49 | train] - Train Epoch: [196] [972800/1281167 (76%)]	Loss: 0.813573
[2022-06-13 06:43:11 | train] - Train Epoch: [196] [985600/1281167 (77%)]	Loss: 0.779911
[2022-06-13 06:43:33 | train] - Train Epoch: [196] [998400/1281167 (78%)]	Loss: 0.634479
[2022-06-13 06:43:54 | train] - Train Epoch: [196] [1011200/1281167 (79%)]	Loss: 0.605951
[2022-06-13 06:44:16 | train] - Train Epoch: [196] [1024000/1281167 (80%)]	Loss: 0.717604
[2022-06-13 06:44:37 | train] - Train Epoch: [196] [1036800/1281167 (81%)]	Loss: 0.787944
[2022-06-13 06:44:59 | train] - Train Epoch: [196] [1049600/1281167 (82%)]	Loss: 0.691752
[2022-06-13 06:45:21 | train] - Train Epoch: [196] [1062400/1281167 (83%)]	Loss: 0.694685
[2022-06-13 06:45:43 | train] - Train Epoch: [196] [1075200/1281167 (84%)]	Loss: 0.656398
[2022-06-13 06:46:05 | train] - Train Epoch: [196] [1088000/1281167 (85%)]	Loss: 0.967595
[2022-06-13 06:46:27 | train] - Train Epoch: [196] [1100800/1281167 (86%)]	Loss: 0.930919
[2022-06-13 06:46:49 | train] - Train Epoch: [196] [1113600/1281167 (87%)]	Loss: 0.915415
[2022-06-13 06:47:10 | train] - Train Epoch: [196] [1126400/1281167 (88%)]	Loss: 0.785300
[2022-06-13 06:47:32 | train] - Train Epoch: [196] [1139200/1281167 (89%)]	Loss: 0.788800
[2022-06-13 06:47:54 | train] - Train Epoch: [196] [1152000/1281167 (90%)]	Loss: 0.654103
[2022-06-13 06:48:15 | train] - Train Epoch: [196] [1164800/1281167 (91%)]	Loss: 0.708753
[2022-06-13 06:48:37 | train] - Train Epoch: [196] [1177600/1281167 (92%)]	Loss: 0.800832
[2022-06-13 06:48:59 | train] - Train Epoch: [196] [1190400/1281167 (93%)]	Loss: 0.582809
[2022-06-13 06:49:20 | train] - Train Epoch: [196] [1203200/1281167 (94%)]	Loss: 0.901136
[2022-06-13 06:49:42 | train] - Train Epoch: [196] [1216000/1281167 (95%)]	Loss: 0.906853
[2022-06-13 06:50:04 | train] - Train Epoch: [196] [1228800/1281167 (96%)]	Loss: 0.598601
[2022-06-13 06:50:26 | train] - Train Epoch: [196] [1241600/1281167 (97%)]	Loss: 0.837251
[2022-06-13 06:50:48 | train] - Train Epoch: [196] [1254400/1281167 (98%)]	Loss: 0.488787
[2022-06-13 06:51:10 | train] - Train Epoch: [196] [1267200/1281167 (99%)]	Loss: 0.680318
[2022-06-13 06:51:32 | train] - Train Epoch: [196] [1280000/1281167 (100%)]	Loss: 0.537509
[2022-06-13 06:51:34 | train] - Train Epoch: [196]	 Average Loss: 0.717629	 Total Acc : 82.6001	 Total Top5 Acc : 93.6650
[2022-06-13 06:51:34 | train] - -------196 epoch end-----------
========================================
-------196 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 06:53:03 | train] - 
Epoch [196] Test set: Average loss: 1.4374, Accuracy: 34967/50000 (69.9029%), Top-5 Accuracy: 88.8691%

[2022-06-13 06:53:03 | train] - save intermediate epoch [196] result


[2022-06-13 06:53:28 | train] - -------197 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 06:53:30 | train] - Train Epoch: [197] [0/1281167 (0%)]	Loss: 0.780288
[2022-06-13 06:53:52 | train] - Train Epoch: [197] [12800/1281167 (1%)]	Loss: 0.817783
[2022-06-13 06:54:14 | train] - Train Epoch: [197] [25600/1281167 (2%)]	Loss: 0.788375
[2022-06-13 06:54:36 | train] - Train Epoch: [197] [38400/1281167 (3%)]	Loss: 0.885521
[2022-06-13 06:54:57 | train] - Train Epoch: [197] [51200/1281167 (4%)]	Loss: 0.676853
[2022-06-13 06:55:19 | train] - Train Epoch: [197] [64000/1281167 (5%)]	Loss: 0.631504
[2022-06-13 06:55:40 | train] - Train Epoch: [197] [76800/1281167 (6%)]	Loss: 0.791875
[2022-06-13 06:56:02 | train] - Train Epoch: [197] [89600/1281167 (7%)]	Loss: 0.607519
[2022-06-13 06:56:23 | train] - Train Epoch: [197] [102400/1281167 (8%)]	Loss: 0.734258
[2022-06-13 06:56:44 | train] - Train Epoch: [197] [115200/1281167 (9%)]	Loss: 0.683293
[2022-06-13 06:57:05 | train] - Train Epoch: [197] [128000/1281167 (10%)]	Loss: 0.784703
[2022-06-13 06:57:27 | train] - Train Epoch: [197] [140800/1281167 (11%)]	Loss: 0.912494
[2022-06-13 06:57:48 | train] - Train Epoch: [197] [153600/1281167 (12%)]	Loss: 0.891754
[2022-06-13 06:58:10 | train] - Train Epoch: [197] [166400/1281167 (13%)]	Loss: 0.574507
[2022-06-13 06:58:32 | train] - Train Epoch: [197] [179200/1281167 (14%)]	Loss: 0.615600
[2022-06-13 06:58:53 | train] - Train Epoch: [197] [192000/1281167 (15%)]	Loss: 0.795353
[2022-06-13 06:59:15 | train] - Train Epoch: [197] [204800/1281167 (16%)]	Loss: 0.618347
[2022-06-13 06:59:36 | train] - Train Epoch: [197] [217600/1281167 (17%)]	Loss: 0.603501
[2022-06-13 06:59:57 | train] - Train Epoch: [197] [230400/1281167 (18%)]	Loss: 0.605682
[2022-06-13 07:00:19 | train] - Train Epoch: [197] [243200/1281167 (19%)]	Loss: 0.996644
[2022-06-13 07:00:42 | train] - Train Epoch: [197] [256000/1281167 (20%)]	Loss: 0.938933
[2022-06-13 07:01:05 | train] - Train Epoch: [197] [268800/1281167 (21%)]	Loss: 0.685807
[2022-06-13 07:01:27 | train] - Train Epoch: [197] [281600/1281167 (22%)]	Loss: 0.596716
[2022-06-13 07:01:48 | train] - Train Epoch: [197] [294400/1281167 (23%)]	Loss: 0.701570
[2022-06-13 07:02:10 | train] - Train Epoch: [197] [307200/1281167 (24%)]	Loss: 0.685172
[2022-06-13 07:02:33 | train] - Train Epoch: [197] [320000/1281167 (25%)]	Loss: 0.789273
[2022-06-13 07:02:55 | train] - Train Epoch: [197] [332800/1281167 (26%)]	Loss: 0.504998
[2022-06-13 07:03:17 | train] - Train Epoch: [197] [345600/1281167 (27%)]	Loss: 0.696971
[2022-06-13 07:03:39 | train] - Train Epoch: [197] [358400/1281167 (28%)]	Loss: 0.736393
[2022-06-13 07:04:01 | train] - Train Epoch: [197] [371200/1281167 (29%)]	Loss: 0.617750
[2022-06-13 07:04:24 | train] - Train Epoch: [197] [384000/1281167 (30%)]	Loss: 0.742086
[2022-06-13 07:04:47 | train] - Train Epoch: [197] [396800/1281167 (31%)]	Loss: 0.680188
[2022-06-13 07:05:09 | train] - Train Epoch: [197] [409600/1281167 (32%)]	Loss: 0.577008
[2022-06-13 07:05:30 | train] - Train Epoch: [197] [422400/1281167 (33%)]	Loss: 0.830659
[2022-06-13 07:05:53 | train] - Train Epoch: [197] [435200/1281167 (34%)]	Loss: 0.800270
[2022-06-13 07:06:15 | train] - Train Epoch: [197] [448000/1281167 (35%)]	Loss: 0.812051
[2022-06-13 07:06:37 | train] - Train Epoch: [197] [460800/1281167 (36%)]	Loss: 0.591984
[2022-06-13 07:06:59 | train] - Train Epoch: [197] [473600/1281167 (37%)]	Loss: 0.571974
[2022-06-13 07:07:21 | train] - Train Epoch: [197] [486400/1281167 (38%)]	Loss: 0.867587
[2022-06-13 07:07:44 | train] - Train Epoch: [197] [499200/1281167 (39%)]	Loss: 0.693005
[2022-06-13 07:08:06 | train] - Train Epoch: [197] [512000/1281167 (40%)]	Loss: 0.777840
[2022-06-13 07:08:28 | train] - Train Epoch: [197] [524800/1281167 (41%)]	Loss: 0.667361
[2022-06-13 07:08:48 | train] - Train Epoch: [197] [537600/1281167 (42%)]	Loss: 0.751531
[2022-06-13 07:09:11 | train] - Train Epoch: [197] [550400/1281167 (43%)]	Loss: 1.134586
[2022-06-13 07:09:33 | train] - Train Epoch: [197] [563200/1281167 (44%)]	Loss: 0.720129
[2022-06-13 07:09:54 | train] - Train Epoch: [197] [576000/1281167 (45%)]	Loss: 0.493798
[2022-06-13 07:10:16 | train] - Train Epoch: [197] [588800/1281167 (46%)]	Loss: 0.675794
[2022-06-13 07:10:38 | train] - Train Epoch: [197] [601600/1281167 (47%)]	Loss: 0.681215
[2022-06-13 07:11:01 | train] - Train Epoch: [197] [614400/1281167 (48%)]	Loss: 0.873352
[2022-06-13 07:11:23 | train] - Train Epoch: [197] [627200/1281167 (49%)]	Loss: 0.714391
[2022-06-13 07:11:45 | train] - Train Epoch: [197] [640000/1281167 (50%)]	Loss: 0.939415
[2022-06-13 07:12:07 | train] - Train Epoch: [197] [652800/1281167 (51%)]	Loss: 0.744838
[2022-06-13 07:12:29 | train] - Train Epoch: [197] [665600/1281167 (52%)]	Loss: 0.774607
[2022-06-13 07:12:51 | train] - Train Epoch: [197] [678400/1281167 (53%)]	Loss: 0.738490
[2022-06-13 07:13:13 | train] - Train Epoch: [197] [691200/1281167 (54%)]	Loss: 0.706326
[2022-06-13 07:13:35 | train] - Train Epoch: [197] [704000/1281167 (55%)]	Loss: 0.767412
[2022-06-13 07:13:56 | train] - Train Epoch: [197] [716800/1281167 (56%)]	Loss: 0.682749
[2022-06-13 07:14:18 | train] - Train Epoch: [197] [729600/1281167 (57%)]	Loss: 0.798834
[2022-06-13 07:14:40 | train] - Train Epoch: [197] [742400/1281167 (58%)]	Loss: 0.989948
[2022-06-13 07:15:02 | train] - Train Epoch: [197] [755200/1281167 (59%)]	Loss: 0.553854
[2022-06-13 07:15:24 | train] - Train Epoch: [197] [768000/1281167 (60%)]	Loss: 0.825205
[2022-06-13 07:15:47 | train] - Train Epoch: [197] [780800/1281167 (61%)]	Loss: 0.587666
[2022-06-13 07:16:09 | train] - Train Epoch: [197] [793600/1281167 (62%)]	Loss: 0.567398
[2022-06-13 07:16:31 | train] - Train Epoch: [197] [806400/1281167 (63%)]	Loss: 0.922903
[2022-06-13 07:16:54 | train] - Train Epoch: [197] [819200/1281167 (64%)]	Loss: 0.950175
[2022-06-13 07:17:16 | train] - Train Epoch: [197] [832000/1281167 (65%)]	Loss: 0.670265
[2022-06-13 07:17:38 | train] - Train Epoch: [197] [844800/1281167 (66%)]	Loss: 0.886747
[2022-06-13 07:18:01 | train] - Train Epoch: [197] [857600/1281167 (67%)]	Loss: 0.752046
[2022-06-13 07:18:23 | train] - Train Epoch: [197] [870400/1281167 (68%)]	Loss: 0.636843
[2022-06-13 07:18:45 | train] - Train Epoch: [197] [883200/1281167 (69%)]	Loss: 0.709490
[2022-06-13 07:19:07 | train] - Train Epoch: [197] [896000/1281167 (70%)]	Loss: 0.818465
[2022-06-13 07:19:29 | train] - Train Epoch: [197] [908800/1281167 (71%)]	Loss: 0.654518
[2022-06-13 07:19:52 | train] - Train Epoch: [197] [921600/1281167 (72%)]	Loss: 0.626140
[2022-06-13 07:20:14 | train] - Train Epoch: [197] [934400/1281167 (73%)]	Loss: 0.685018
[2022-06-13 07:20:37 | train] - Train Epoch: [197] [947200/1281167 (74%)]	Loss: 0.633514
[2022-06-13 07:20:59 | train] - Train Epoch: [197] [960000/1281167 (75%)]	Loss: 0.738115
[2022-06-13 07:21:22 | train] - Train Epoch: [197] [972800/1281167 (76%)]	Loss: 0.699228
[2022-06-13 07:21:45 | train] - Train Epoch: [197] [985600/1281167 (77%)]	Loss: 0.506865
[2022-06-13 07:22:06 | train] - Train Epoch: [197] [998400/1281167 (78%)]	Loss: 0.639352
[2022-06-13 07:22:29 | train] - Train Epoch: [197] [1011200/1281167 (79%)]	Loss: 0.790126
[2022-06-13 07:22:51 | train] - Train Epoch: [197] [1024000/1281167 (80%)]	Loss: 0.633833
[2022-06-13 07:23:13 | train] - Train Epoch: [197] [1036800/1281167 (81%)]	Loss: 0.762457
[2022-06-13 07:23:36 | train] - Train Epoch: [197] [1049600/1281167 (82%)]	Loss: 0.522616
[2022-06-13 07:23:57 | train] - Train Epoch: [197] [1062400/1281167 (83%)]	Loss: 0.671382
[2022-06-13 07:24:20 | train] - Train Epoch: [197] [1075200/1281167 (84%)]	Loss: 0.824101
[2022-06-13 07:24:43 | train] - Train Epoch: [197] [1088000/1281167 (85%)]	Loss: 0.568924
[2022-06-13 07:25:05 | train] - Train Epoch: [197] [1100800/1281167 (86%)]	Loss: 0.702726
[2022-06-13 07:25:28 | train] - Train Epoch: [197] [1113600/1281167 (87%)]	Loss: 0.549245
[2022-06-13 07:25:50 | train] - Train Epoch: [197] [1126400/1281167 (88%)]	Loss: 0.541077
[2022-06-13 07:26:12 | train] - Train Epoch: [197] [1139200/1281167 (89%)]	Loss: 0.504183
[2022-06-13 07:26:35 | train] - Train Epoch: [197] [1152000/1281167 (90%)]	Loss: 0.682790
[2022-06-13 07:26:58 | train] - Train Epoch: [197] [1164800/1281167 (91%)]	Loss: 0.601348
[2022-06-13 07:27:19 | train] - Train Epoch: [197] [1177600/1281167 (92%)]	Loss: 0.678848
[2022-06-13 07:27:42 | train] - Train Epoch: [197] [1190400/1281167 (93%)]	Loss: 0.995618
[2022-06-13 07:28:04 | train] - Train Epoch: [197] [1203200/1281167 (94%)]	Loss: 0.663680
[2022-06-13 07:28:26 | train] - Train Epoch: [197] [1216000/1281167 (95%)]	Loss: 0.904342
[2022-06-13 07:28:49 | train] - Train Epoch: [197] [1228800/1281167 (96%)]	Loss: 0.768568
[2022-06-13 07:29:10 | train] - Train Epoch: [197] [1241600/1281167 (97%)]	Loss: 0.575377
[2022-06-13 07:29:32 | train] - Train Epoch: [197] [1254400/1281167 (98%)]	Loss: 0.710440
[2022-06-13 07:29:55 | train] - Train Epoch: [197] [1267200/1281167 (99%)]	Loss: 0.560301
[2022-06-13 07:30:17 | train] - Train Epoch: [197] [1280000/1281167 (100%)]	Loss: 0.612411
[2022-06-13 07:30:19 | train] - Train Epoch: [197]	 Average Loss: 0.715765	 Total Acc : 82.6525	 Total Top5 Acc : 93.6797
[2022-06-13 07:30:19 | train] - -------197 epoch end-----------
========================================
-------197 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 07:31:53 | train] - 
Epoch [197] Test set: Average loss: 1.4358, Accuracy: 34915/50000 (69.8014%), Top-5 Accuracy: 88.8723%

[2022-06-13 07:31:53 | train] - save intermediate epoch [197] result


[2022-06-13 07:32:18 | train] - -------198 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 07:32:20 | train] - Train Epoch: [198] [0/1281167 (0%)]	Loss: 0.563686
[2022-06-13 07:32:42 | train] - Train Epoch: [198] [12800/1281167 (1%)]	Loss: 0.571065
[2022-06-13 07:33:04 | train] - Train Epoch: [198] [25600/1281167 (2%)]	Loss: 0.627858
[2022-06-13 07:33:25 | train] - Train Epoch: [198] [38400/1281167 (3%)]	Loss: 0.758461
[2022-06-13 07:33:47 | train] - Train Epoch: [198] [51200/1281167 (4%)]	Loss: 0.630657
[2022-06-13 07:34:07 | train] - Train Epoch: [198] [64000/1281167 (5%)]	Loss: 0.733954
[2022-06-13 07:34:29 | train] - Train Epoch: [198] [76800/1281167 (6%)]	Loss: 0.659091
[2022-06-13 07:34:50 | train] - Train Epoch: [198] [89600/1281167 (7%)]	Loss: 0.670864
[2022-06-13 07:35:12 | train] - Train Epoch: [198] [102400/1281167 (8%)]	Loss: 0.942457
[2022-06-13 07:35:33 | train] - Train Epoch: [198] [115200/1281167 (9%)]	Loss: 0.881414
[2022-06-13 07:35:54 | train] - Train Epoch: [198] [128000/1281167 (10%)]	Loss: 0.597795
[2022-06-13 07:36:16 | train] - Train Epoch: [198] [140800/1281167 (11%)]	Loss: 0.799767
[2022-06-13 07:36:38 | train] - Train Epoch: [198] [153600/1281167 (12%)]	Loss: 0.805139
[2022-06-13 07:36:59 | train] - Train Epoch: [198] [166400/1281167 (13%)]	Loss: 0.840237
[2022-06-13 07:37:20 | train] - Train Epoch: [198] [179200/1281167 (14%)]	Loss: 0.606815
[2022-06-13 07:37:42 | train] - Train Epoch: [198] [192000/1281167 (15%)]	Loss: 0.793675
[2022-06-13 07:38:04 | train] - Train Epoch: [198] [204800/1281167 (16%)]	Loss: 0.725823
[2022-06-13 07:38:26 | train] - Train Epoch: [198] [217600/1281167 (17%)]	Loss: 0.620541
[2022-06-13 07:38:48 | train] - Train Epoch: [198] [230400/1281167 (18%)]	Loss: 0.890919
[2022-06-13 07:39:11 | train] - Train Epoch: [198] [243200/1281167 (19%)]	Loss: 0.698372
[2022-06-13 07:39:33 | train] - Train Epoch: [198] [256000/1281167 (20%)]	Loss: 0.810596
[2022-06-13 07:39:56 | train] - Train Epoch: [198] [268800/1281167 (21%)]	Loss: 0.924886
[2022-06-13 07:40:17 | train] - Train Epoch: [198] [281600/1281167 (22%)]	Loss: 0.598351
[2022-06-13 07:40:40 | train] - Train Epoch: [198] [294400/1281167 (23%)]	Loss: 0.784551
[2022-06-13 07:41:02 | train] - Train Epoch: [198] [307200/1281167 (24%)]	Loss: 0.581338
[2022-06-13 07:41:25 | train] - Train Epoch: [198] [320000/1281167 (25%)]	Loss: 0.764301
[2022-06-13 07:41:46 | train] - Train Epoch: [198] [332800/1281167 (26%)]	Loss: 0.952243
[2022-06-13 07:42:08 | train] - Train Epoch: [198] [345600/1281167 (27%)]	Loss: 0.566512
[2022-06-13 07:42:29 | train] - Train Epoch: [198] [358400/1281167 (28%)]	Loss: 0.685746
[2022-06-13 07:42:51 | train] - Train Epoch: [198] [371200/1281167 (29%)]	Loss: 0.790736
[2022-06-13 07:43:13 | train] - Train Epoch: [198] [384000/1281167 (30%)]	Loss: 0.762478
[2022-06-13 07:43:34 | train] - Train Epoch: [198] [396800/1281167 (31%)]	Loss: 0.770250
[2022-06-13 07:43:57 | train] - Train Epoch: [198] [409600/1281167 (32%)]	Loss: 0.899860
[2022-06-13 07:44:19 | train] - Train Epoch: [198] [422400/1281167 (33%)]	Loss: 0.760971
[2022-06-13 07:44:41 | train] - Train Epoch: [198] [435200/1281167 (34%)]	Loss: 0.840630
[2022-06-13 07:45:02 | train] - Train Epoch: [198] [448000/1281167 (35%)]	Loss: 0.845429
[2022-06-13 07:45:23 | train] - Train Epoch: [198] [460800/1281167 (36%)]	Loss: 0.674843
[2022-06-13 07:45:43 | train] - Train Epoch: [198] [473600/1281167 (37%)]	Loss: 0.691425
[2022-06-13 07:46:04 | train] - Train Epoch: [198] [486400/1281167 (38%)]	Loss: 0.780196
[2022-06-13 07:46:24 | train] - Train Epoch: [198] [499200/1281167 (39%)]	Loss: 0.739526
[2022-06-13 07:46:44 | train] - Train Epoch: [198] [512000/1281167 (40%)]	Loss: 0.853801
[2022-06-13 07:47:04 | train] - Train Epoch: [198] [524800/1281167 (41%)]	Loss: 0.687649
[2022-06-13 07:47:26 | train] - Train Epoch: [198] [537600/1281167 (42%)]	Loss: 0.718657
[2022-06-13 07:47:47 | train] - Train Epoch: [198] [550400/1281167 (43%)]	Loss: 0.758841
[2022-06-13 07:48:07 | train] - Train Epoch: [198] [563200/1281167 (44%)]	Loss: 0.810699
[2022-06-13 07:48:27 | train] - Train Epoch: [198] [576000/1281167 (45%)]	Loss: 0.777983
[2022-06-13 07:48:46 | train] - Train Epoch: [198] [588800/1281167 (46%)]	Loss: 0.640261
[2022-06-13 07:49:07 | train] - Train Epoch: [198] [601600/1281167 (47%)]	Loss: 0.969191
[2022-06-13 07:49:27 | train] - Train Epoch: [198] [614400/1281167 (48%)]	Loss: 0.734611
[2022-06-13 07:49:47 | train] - Train Epoch: [198] [627200/1281167 (49%)]	Loss: 0.652137
[2022-06-13 07:50:07 | train] - Train Epoch: [198] [640000/1281167 (50%)]	Loss: 0.571696
[2022-06-13 07:50:27 | train] - Train Epoch: [198] [652800/1281167 (51%)]	Loss: 0.776682
[2022-06-13 07:50:47 | train] - Train Epoch: [198] [665600/1281167 (52%)]	Loss: 0.756916
[2022-06-13 07:51:08 | train] - Train Epoch: [198] [678400/1281167 (53%)]	Loss: 0.836373
[2022-06-13 07:51:28 | train] - Train Epoch: [198] [691200/1281167 (54%)]	Loss: 0.834869
[2022-06-13 07:51:47 | train] - Train Epoch: [198] [704000/1281167 (55%)]	Loss: 0.850818
[2022-06-13 07:52:08 | train] - Train Epoch: [198] [716800/1281167 (56%)]	Loss: 0.651072
[2022-06-13 07:52:29 | train] - Train Epoch: [198] [729600/1281167 (57%)]	Loss: 0.699368
[2022-06-13 07:52:49 | train] - Train Epoch: [198] [742400/1281167 (58%)]	Loss: 0.544186
[2022-06-13 07:53:09 | train] - Train Epoch: [198] [755200/1281167 (59%)]	Loss: 0.875686
[2022-06-13 07:53:30 | train] - Train Epoch: [198] [768000/1281167 (60%)]	Loss: 0.613794
[2022-06-13 07:53:49 | train] - Train Epoch: [198] [780800/1281167 (61%)]	Loss: 0.595869
[2022-06-13 07:54:09 | train] - Train Epoch: [198] [793600/1281167 (62%)]	Loss: 0.665357
[2022-06-13 07:54:29 | train] - Train Epoch: [198] [806400/1281167 (63%)]	Loss: 0.696913
[2022-06-13 07:54:49 | train] - Train Epoch: [198] [819200/1281167 (64%)]	Loss: 0.704569
[2022-06-13 07:55:09 | train] - Train Epoch: [198] [832000/1281167 (65%)]	Loss: 0.783991
[2022-06-13 07:55:30 | train] - Train Epoch: [198] [844800/1281167 (66%)]	Loss: 0.826511
[2022-06-13 07:55:50 | train] - Train Epoch: [198] [857600/1281167 (67%)]	Loss: 0.669951
[2022-06-13 07:56:11 | train] - Train Epoch: [198] [870400/1281167 (68%)]	Loss: 0.847721
[2022-06-13 07:56:30 | train] - Train Epoch: [198] [883200/1281167 (69%)]	Loss: 0.610287
[2022-06-13 07:56:50 | train] - Train Epoch: [198] [896000/1281167 (70%)]	Loss: 0.573288
[2022-06-13 07:57:10 | train] - Train Epoch: [198] [908800/1281167 (71%)]	Loss: 0.719649
[2022-06-13 07:57:31 | train] - Train Epoch: [198] [921600/1281167 (72%)]	Loss: 0.845137
[2022-06-13 07:57:51 | train] - Train Epoch: [198] [934400/1281167 (73%)]	Loss: 0.631049
[2022-06-13 07:58:11 | train] - Train Epoch: [198] [947200/1281167 (74%)]	Loss: 0.777353
[2022-06-13 07:58:31 | train] - Train Epoch: [198] [960000/1281167 (75%)]	Loss: 0.803946
[2022-06-13 07:58:51 | train] - Train Epoch: [198] [972800/1281167 (76%)]	Loss: 0.564853
[2022-06-13 07:59:11 | train] - Train Epoch: [198] [985600/1281167 (77%)]	Loss: 0.706182
[2022-06-13 07:59:31 | train] - Train Epoch: [198] [998400/1281167 (78%)]	Loss: 0.717248
[2022-06-13 07:59:51 | train] - Train Epoch: [198] [1011200/1281167 (79%)]	Loss: 0.539999
[2022-06-13 08:00:11 | train] - Train Epoch: [198] [1024000/1281167 (80%)]	Loss: 0.977861
[2022-06-13 08:00:32 | train] - Train Epoch: [198] [1036800/1281167 (81%)]	Loss: 0.759321
[2022-06-13 08:00:53 | train] - Train Epoch: [198] [1049600/1281167 (82%)]	Loss: 0.523006
[2022-06-13 08:01:13 | train] - Train Epoch: [198] [1062400/1281167 (83%)]	Loss: 0.494542
[2022-06-13 08:01:34 | train] - Train Epoch: [198] [1075200/1281167 (84%)]	Loss: 0.902143
[2022-06-13 08:01:54 | train] - Train Epoch: [198] [1088000/1281167 (85%)]	Loss: 0.892882
[2022-06-13 08:02:14 | train] - Train Epoch: [198] [1100800/1281167 (86%)]	Loss: 0.777133
[2022-06-13 08:02:35 | train] - Train Epoch: [198] [1113600/1281167 (87%)]	Loss: 0.650168
[2022-06-13 08:02:54 | train] - Train Epoch: [198] [1126400/1281167 (88%)]	Loss: 0.692543
[2022-06-13 08:03:14 | train] - Train Epoch: [198] [1139200/1281167 (89%)]	Loss: 0.641178
[2022-06-13 08:03:34 | train] - Train Epoch: [198] [1152000/1281167 (90%)]	Loss: 0.904109
[2022-06-13 08:03:54 | train] - Train Epoch: [198] [1164800/1281167 (91%)]	Loss: 1.027910
[2022-06-13 08:04:15 | train] - Train Epoch: [198] [1177600/1281167 (92%)]	Loss: 0.720801
[2022-06-13 08:04:35 | train] - Train Epoch: [198] [1190400/1281167 (93%)]	Loss: 0.621764
[2022-06-13 08:04:55 | train] - Train Epoch: [198] [1203200/1281167 (94%)]	Loss: 0.746465
[2022-06-13 08:05:16 | train] - Train Epoch: [198] [1216000/1281167 (95%)]	Loss: 0.679687
[2022-06-13 08:05:36 | train] - Train Epoch: [198] [1228800/1281167 (96%)]	Loss: 0.848432
[2022-06-13 08:05:56 | train] - Train Epoch: [198] [1241600/1281167 (97%)]	Loss: 0.658961
[2022-06-13 08:06:16 | train] - Train Epoch: [198] [1254400/1281167 (98%)]	Loss: 0.478482
[2022-06-13 08:06:37 | train] - Train Epoch: [198] [1267200/1281167 (99%)]	Loss: 0.826776
[2022-06-13 08:06:57 | train] - Train Epoch: [198] [1280000/1281167 (100%)]	Loss: 0.739286
[2022-06-13 08:06:59 | train] - Train Epoch: [198]	 Average Loss: 0.715026	 Total Acc : 82.6640	 Total Top5 Acc : 93.7001
[2022-06-13 08:06:59 | train] - -------198 epoch end-----------
========================================
-------198 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 08:08:30 | train] - 
Epoch [198] Test set: Average loss: 1.4378, Accuracy: 34932/50000 (69.8342%), Top-5 Accuracy: 88.8643%

[2022-06-13 08:08:30 | train] - save intermediate epoch [198] result


[2022-06-13 08:08:56 | train] - -------199 epoch start-----------
========================================
----- test end -------------------------


[2022-06-13 08:08:58 | train] - Train Epoch: [199] [0/1281167 (0%)]	Loss: 0.556582
[2022-06-13 08:09:18 | train] - Train Epoch: [199] [12800/1281167 (1%)]	Loss: 0.783344
[2022-06-13 08:09:38 | train] - Train Epoch: [199] [25600/1281167 (2%)]	Loss: 0.873312
[2022-06-13 08:09:57 | train] - Train Epoch: [199] [38400/1281167 (3%)]	Loss: 0.960294
[2022-06-13 08:10:17 | train] - Train Epoch: [199] [51200/1281167 (4%)]	Loss: 0.463707
[2022-06-13 08:10:36 | train] - Train Epoch: [199] [64000/1281167 (5%)]	Loss: 0.919134
[2022-06-13 08:10:56 | train] - Train Epoch: [199] [76800/1281167 (6%)]	Loss: 0.578737
[2022-06-13 08:11:14 | train] - Train Epoch: [199] [89600/1281167 (7%)]	Loss: 0.758704
[2022-06-13 08:11:34 | train] - Train Epoch: [199] [102400/1281167 (8%)]	Loss: 0.616035
[2022-06-13 08:11:54 | train] - Train Epoch: [199] [115200/1281167 (9%)]	Loss: 0.717415
[2022-06-13 08:12:13 | train] - Train Epoch: [199] [128000/1281167 (10%)]	Loss: 0.840799
[2022-06-13 08:12:32 | train] - Train Epoch: [199] [140800/1281167 (11%)]	Loss: 0.754823
[2022-06-13 08:12:52 | train] - Train Epoch: [199] [153600/1281167 (12%)]	Loss: 0.752100
[2022-06-13 08:13:11 | train] - Train Epoch: [199] [166400/1281167 (13%)]	Loss: 0.674985
[2022-06-13 08:13:30 | train] - Train Epoch: [199] [179200/1281167 (14%)]	Loss: 0.555992
[2022-06-13 08:13:49 | train] - Train Epoch: [199] [192000/1281167 (15%)]	Loss: 0.712317
[2022-06-13 08:14:09 | train] - Train Epoch: [199] [204800/1281167 (16%)]	Loss: 0.702365
[2022-06-13 08:14:29 | train] - Train Epoch: [199] [217600/1281167 (17%)]	Loss: 0.790384
[2022-06-13 08:14:48 | train] - Train Epoch: [199] [230400/1281167 (18%)]	Loss: 0.671171
[2022-06-13 08:15:08 | train] - Train Epoch: [199] [243200/1281167 (19%)]	Loss: 0.739662
[2022-06-13 08:15:27 | train] - Train Epoch: [199] [256000/1281167 (20%)]	Loss: 0.783517
[2022-06-13 08:15:47 | train] - Train Epoch: [199] [268800/1281167 (21%)]	Loss: 0.499789
[2022-06-13 08:16:06 | train] - Train Epoch: [199] [281600/1281167 (22%)]	Loss: 0.699578
[2022-06-13 08:16:26 | train] - Train Epoch: [199] [294400/1281167 (23%)]	Loss: 0.431546
[2022-06-13 08:16:45 | train] - Train Epoch: [199] [307200/1281167 (24%)]	Loss: 0.925457
[2022-06-13 08:17:04 | train] - Train Epoch: [199] [320000/1281167 (25%)]	Loss: 0.715376
[2022-06-13 08:17:24 | train] - Train Epoch: [199] [332800/1281167 (26%)]	Loss: 0.620856
[2022-06-13 08:17:44 | train] - Train Epoch: [199] [345600/1281167 (27%)]	Loss: 0.702317
[2022-06-13 08:18:04 | train] - Train Epoch: [199] [358400/1281167 (28%)]	Loss: 0.614641
[2022-06-13 08:18:23 | train] - Train Epoch: [199] [371200/1281167 (29%)]	Loss: 0.561142
[2022-06-13 08:18:43 | train] - Train Epoch: [199] [384000/1281167 (30%)]	Loss: 0.593052
[2022-06-13 08:19:02 | train] - Train Epoch: [199] [396800/1281167 (31%)]	Loss: 0.804468
[2022-06-13 08:19:22 | train] - Train Epoch: [199] [409600/1281167 (32%)]	Loss: 0.592999
[2022-06-13 08:19:41 | train] - Train Epoch: [199] [422400/1281167 (33%)]	Loss: 0.689922
[2022-06-13 08:20:01 | train] - Train Epoch: [199] [435200/1281167 (34%)]	Loss: 0.410981
[2022-06-13 08:20:20 | train] - Train Epoch: [199] [448000/1281167 (35%)]	Loss: 0.563985
[2022-06-13 08:20:40 | train] - Train Epoch: [199] [460800/1281167 (36%)]	Loss: 0.551735
[2022-06-13 08:21:00 | train] - Train Epoch: [199] [473600/1281167 (37%)]	Loss: 0.728470
[2022-06-13 08:21:18 | train] - Train Epoch: [199] [486400/1281167 (38%)]	Loss: 0.889303
[2022-06-13 08:21:38 | train] - Train Epoch: [199] [499200/1281167 (39%)]	Loss: 0.692049
[2022-06-13 08:21:58 | train] - Train Epoch: [199] [512000/1281167 (40%)]	Loss: 0.528028
[2022-06-13 08:22:17 | train] - Train Epoch: [199] [524800/1281167 (41%)]	Loss: 1.050437
[2022-06-13 08:22:37 | train] - Train Epoch: [199] [537600/1281167 (42%)]	Loss: 0.975901
[2022-06-13 08:22:56 | train] - Train Epoch: [199] [550400/1281167 (43%)]	Loss: 0.591846
[2022-06-13 08:23:16 | train] - Train Epoch: [199] [563200/1281167 (44%)]	Loss: 0.596917
[2022-06-13 08:23:36 | train] - Train Epoch: [199] [576000/1281167 (45%)]	Loss: 0.778305
[2022-06-13 08:23:55 | train] - Train Epoch: [199] [588800/1281167 (46%)]	Loss: 0.687005
[2022-06-13 08:24:13 | train] - Train Epoch: [199] [601600/1281167 (47%)]	Loss: 0.822027
[2022-06-13 08:24:33 | train] - Train Epoch: [199] [614400/1281167 (48%)]	Loss: 0.654959
[2022-06-13 08:24:53 | train] - Train Epoch: [199] [627200/1281167 (49%)]	Loss: 0.785186
[2022-06-13 08:25:13 | train] - Train Epoch: [199] [640000/1281167 (50%)]	Loss: 0.825808
[2022-06-13 08:25:32 | train] - Train Epoch: [199] [652800/1281167 (51%)]	Loss: 0.818442
[2022-06-13 08:25:52 | train] - Train Epoch: [199] [665600/1281167 (52%)]	Loss: 0.805422
[2022-06-13 08:26:11 | train] - Train Epoch: [199] [678400/1281167 (53%)]	Loss: 0.698140
[2022-06-13 08:26:31 | train] - Train Epoch: [199] [691200/1281167 (54%)]	Loss: 1.030234
[2022-06-13 08:26:51 | train] - Train Epoch: [199] [704000/1281167 (55%)]	Loss: 0.704320
[2022-06-13 08:27:10 | train] - Train Epoch: [199] [716800/1281167 (56%)]	Loss: 0.801107
[2022-06-13 08:27:30 | train] - Train Epoch: [199] [729600/1281167 (57%)]	Loss: 0.484633
[2022-06-13 08:27:50 | train] - Train Epoch: [199] [742400/1281167 (58%)]	Loss: 0.629497
[2022-06-13 08:28:10 | train] - Train Epoch: [199] [755200/1281167 (59%)]	Loss: 0.816201
[2022-06-13 08:28:29 | train] - Train Epoch: [199] [768000/1281167 (60%)]	Loss: 0.724905
[2022-06-13 08:28:49 | train] - Train Epoch: [199] [780800/1281167 (61%)]	Loss: 0.810943
[2022-06-13 08:29:08 | train] - Train Epoch: [199] [793600/1281167 (62%)]	Loss: 0.798172
[2022-06-13 08:29:27 | train] - Train Epoch: [199] [806400/1281167 (63%)]	Loss: 0.911105
[2022-06-13 08:29:47 | train] - Train Epoch: [199] [819200/1281167 (64%)]	Loss: 0.700655
[2022-06-13 08:30:06 | train] - Train Epoch: [199] [832000/1281167 (65%)]	Loss: 0.667870
[2022-06-13 08:30:25 | train] - Train Epoch: [199] [844800/1281167 (66%)]	Loss: 0.798454
[2022-06-13 08:30:43 | train] - Train Epoch: [199] [857600/1281167 (67%)]	Loss: 0.925086
[2022-06-13 08:31:03 | train] - Train Epoch: [199] [870400/1281167 (68%)]	Loss: 0.653726
[2022-06-13 08:31:22 | train] - Train Epoch: [199] [883200/1281167 (69%)]	Loss: 0.762220
[2022-06-13 08:31:42 | train] - Train Epoch: [199] [896000/1281167 (70%)]	Loss: 0.715226
[2022-06-13 08:32:02 | train] - Train Epoch: [199] [908800/1281167 (71%)]	Loss: 0.683120
[2022-06-13 08:32:21 | train] - Train Epoch: [199] [921600/1281167 (72%)]	Loss: 0.918195
[2022-06-13 08:32:40 | train] - Train Epoch: [199] [934400/1281167 (73%)]	Loss: 0.701825
[2022-06-13 08:33:00 | train] - Train Epoch: [199] [947200/1281167 (74%)]	Loss: 0.923273
[2022-06-13 08:33:19 | train] - Train Epoch: [199] [960000/1281167 (75%)]	Loss: 0.931195
[2022-06-13 08:33:38 | train] - Train Epoch: [199] [972800/1281167 (76%)]	Loss: 0.804170
[2022-06-13 08:33:58 | train] - Train Epoch: [199] [985600/1281167 (77%)]	Loss: 0.614263
[2022-06-13 08:34:18 | train] - Train Epoch: [199] [998400/1281167 (78%)]	Loss: 0.635010
[2022-06-13 08:34:37 | train] - Train Epoch: [199] [1011200/1281167 (79%)]	Loss: 0.629923
[2022-06-13 08:34:57 | train] - Train Epoch: [199] [1024000/1281167 (80%)]	Loss: 0.691844
[2022-06-13 08:35:17 | train] - Train Epoch: [199] [1036800/1281167 (81%)]	Loss: 0.934088
[2022-06-13 08:35:36 | train] - Train Epoch: [199] [1049600/1281167 (82%)]	Loss: 0.594708
[2022-06-13 08:35:56 | train] - Train Epoch: [199] [1062400/1281167 (83%)]	Loss: 0.689338
[2022-06-13 08:36:15 | train] - Train Epoch: [199] [1075200/1281167 (84%)]	Loss: 0.697800
[2022-06-13 08:36:35 | train] - Train Epoch: [199] [1088000/1281167 (85%)]	Loss: 0.851569
[2022-06-13 08:36:54 | train] - Train Epoch: [199] [1100800/1281167 (86%)]	Loss: 0.683504
[2022-06-13 08:37:14 | train] - Train Epoch: [199] [1113600/1281167 (87%)]	Loss: 0.913291
[2022-06-13 08:37:34 | train] - Train Epoch: [199] [1126400/1281167 (88%)]	Loss: 0.618829
[2022-06-13 08:37:53 | train] - Train Epoch: [199] [1139200/1281167 (89%)]	Loss: 1.156762
[2022-06-13 08:38:13 | train] - Train Epoch: [199] [1152000/1281167 (90%)]	Loss: 0.754497
[2022-06-13 08:38:33 | train] - Train Epoch: [199] [1164800/1281167 (91%)]	Loss: 0.475240
[2022-06-13 08:38:52 | train] - Train Epoch: [199] [1177600/1281167 (92%)]	Loss: 0.584427
[2022-06-13 08:39:11 | train] - Train Epoch: [199] [1190400/1281167 (93%)]	Loss: 0.767759
[2022-06-13 08:39:31 | train] - Train Epoch: [199] [1203200/1281167 (94%)]	Loss: 0.560182
[2022-06-13 08:39:50 | train] - Train Epoch: [199] [1216000/1281167 (95%)]	Loss: 0.786113
[2022-06-13 08:40:10 | train] - Train Epoch: [199] [1228800/1281167 (96%)]	Loss: 0.763934
[2022-06-13 08:40:29 | train] - Train Epoch: [199] [1241600/1281167 (97%)]	Loss: 0.705130
[2022-06-13 08:40:48 | train] - Train Epoch: [199] [1254400/1281167 (98%)]	Loss: 0.607941
[2022-06-13 08:41:08 | train] - Train Epoch: [199] [1267200/1281167 (99%)]	Loss: 0.928525
[2022-06-13 08:41:27 | train] - Train Epoch: [199] [1280000/1281167 (100%)]	Loss: 0.951923
[2022-06-13 08:41:29 | train] - Train Epoch: [199]	 Average Loss: 0.715255	 Total Acc : 82.6140	 Total Top5 Acc : 93.7123
[2022-06-13 08:41:29 | train] - -------199 epoch end-----------
========================================
-------199 epoch end  -----------

----- test and print accuracy ------------------
[2022-06-13 08:43:00 | train] - 
Epoch [199] Test set: Average loss: 1.4382, Accuracy: 34918/50000 (69.8062%), Top-5 Accuracy: 88.8603%

[2022-06-13 08:43:00 | train] - save intermediate epoch [199] result


========================================
----- test end -------------------------


